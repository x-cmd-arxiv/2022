"2203.07220","Katrin Heitmann","Bob Blum, Seth W. Digel, Alex Drlica-Wagner, Salman Habib, Katrin
  Heitmann, Mustapha Ishak, Saurabh W. Jha, Steven M. Kahn, Rachel Mandelbaum,
  Phil Marshall, Jeffrey A. Newman, Aaron Roodman, Christopher W. Stubbs","Snowmass2021 Cosmic Frontier White Paper: Rubin Observatory after LSST","Contribution to Snowmass 2021",,,,"astro-ph.CO hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Vera C. Rubin Observatory will begin the Legacy Survey of Space and Time
(LSST) in 2024, spanning an area of 18,000 square degrees in six bands, with
more than 800 observations of each field over ten years. The unprecedented data
set will enable great advances in the study of the formation and evolution of
structure and exploration of physics of the dark universe. The observations
will hold clues about the cause for the accelerated expansion of the universe
and possibly the nature of dark matter. During the next decade, LSST will be
able to confirm or dispute if tensions seen today in cosmological data are due
to new physics. New and unexpected phenomena could confirm or disrupt our
current understanding of the universe. Findings from LSST will guide the path
forward post-LSST. The Rubin Observatory will still be a uniquely powerful
facility even then, capable of revealing further insights into the physics of
the dark universe. These could be obtained via innovative observing strategies,
e.g., targeting new probes at shorter timescales than with LSST, or via modest
instrumental changes, e.g., new filters, or through an entirely new instrument
for the focal plane. This White Paper highlights some of the opportunities in
each scenario from Rubin observations after LSST.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:00:17 GMT""}]","2022-03-15"
"2203.07221","Michael Stessin","Michael Stessin","Spectral analysis and representations]{Spectral analysis near regular
  point of reducibility and representations of Coxeter groups","32 pages",,,,"math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a tuple of square matrices $A_1,...,A_n$ the determinantal hypersurface
is defined as \begin{eqnarray*} &\sigma(A_1,...,A_n)= \\ &\Big\{[x_1:\cdots
:x_n]\in \C{\mathbb P}^{n-1}: det(x_1A_1+\cdots +x_nA_n)=0\Big \}.
\end{eqnarray*} In this paper we develop a local spectral analysis near a
regular point of reducibility of a determinantal hypersurface. We prove a
rigidity type theorem for representations of Coxeter groups as an application
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:00:44 GMT""}]","2022-03-15"
"2203.07222","Anton Bernshteyn","James Anderson, Anton Bernshteyn, Abhishek Dhawan","Coloring graphs with forbidden almost bipartite subgraphs","31 pp",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Alon, Krivelevich, and Sudakov conjectured in 1999 that for every finite
graph $F$, there exists a quantity $c(F)$ such that $\chi(G) \leqslant (c(F) +
o(1)) \Delta / \log\Delta$ whenever $G$ is an $F$-free graph of maximum degree
$\Delta$. The largest class of connected graphs $F$ for which this conjecture
has been verified so far, by Alon, Krivelevich, and Sudakov themselves,
comprises the almost bipartite graphs (i.e., subgraphs of the complete
tripartite graph $K_{1,t,t}$ for some $t \in \mathbb{N}$). However, the optimal
value for $c(F)$ remains unknown even for such graphs. Bollob\'{a}s showed,
using random regular graphs, that $c(F) \geqslant 1/2$ when $F$ contains a
cycle. On the other hand, Davies, Kang, Pirot, and Sereni recently established
an upper bound of $c(K_{1,t,t}) \leqslant t$. We improve this to a constant,
showing $c(F) \leqslant 4$ for every almost bipartite graph $F$. This
surprisingly makes the bound independent of $F$ in all the known cases of the
conjecture, leading us to make a new conjecture that $c(F)$ is always bounded
above by some constant $c$ independent of $F$. We also establish a more general
version of our bound in the setting of DP-coloring (also known as
correspondence coloring) and consider some algorithmic consequences of our
results.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:01:07 GMT""},{""version"":""v2"",""created"":""Fri, 15 Apr 2022 23:06:46 GMT""},{""version"":""v3"",""created"":""Thu, 5 May 2022 16:04:23 GMT""},{""version"":""v4"",""created"":""Wed, 27 Jul 2022 00:21:16 GMT""},{""version"":""v5"",""created"":""Thu, 24 Nov 2022 15:54:29 GMT""}]","2022-11-28"
"2203.07223","Rodrigo Holanda","Kamal Bora and R. F. L. Holanda","The Hubble constant from galaxy cluster scaling-relation and SNe Ia
  observations: a consistency test","8 pages, 5 figures. Version accepted by The European Journal of
  Physics C",,"10.1140/epjc/s10052-023-11424-y",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a self-consistent test for a Hubble constant
estimate using galaxy cluster and type Ia supernovae (SNe Ia) observations. The
approach consists, in a first step, of obtaining the observational value of the
galaxy cluster scaling-relation $Y_{SZE}D_{A}^{2}/C_{XSZ}Y_X = C $ by combining
the X-Ray and SZ observations of galaxy clusters at low redshifts ($z < 0.1$)
from the first {\it Planck mission} all-sky data set ($0.044 \leq z \leq
0.444$), along with SNe Ia observations and making use of the cosmic distance
duality relation validity. Then, by considering a flat $\Lambda$CDM model for
$D_A$, the constant $C$ from the first step and the Planck prior on $\Omega_M$
parameter, we obtain $H_0$ by using the galaxy cluster data with $z>0.1$. As a
result, we obtain $H_0 = 73.014^{+7.435}_{-6.688}$ km/s/Mpc, which represents
$9.7\%$ accuracy measurement on the Hubble constant.. We also compare our
method with that one where the $C$ parameter is obtained from hydrodynamical
simulations of massive galaxy clusters.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:01:52 GMT""},{""version"":""v2"",""created"":""Tue, 21 Mar 2023 12:12:43 GMT""}]","2023-04-19"
"2203.07224","Federico Meloni","Sergo Jindariani, Federico Meloni, Nadia Pastrone, Chiara Aim\`e,
  Nazar Bartosik, Emanuela Barzi, Alessandro Bertolin, Alessandro Braghieri,
  Laura Buonincontri, Simone Calzaferri, Massimo Casarsa, Maria Gabriella
  Catanesi, Alessandro Cerri, Grigorios Chachamis, Anna Colaleo, Camilla
  Curatolo, Giacomo Da Molin, Jean-Pierre Delahaye, Biagio Di Micco, Tommaso
  Dorigo, Filippo Errico, Davide Fiorina, Alessio Gianelle, Carlo Giraldin,
  John Hauptman, Tova Ray Holmes, Karol Krizka, Lawrence Lee, Kenneth Long,
  Donatella Lucchesi, Nikolai Mokhov, Alessandro Montella, Federico Nardi, Niko
  Neufeld, David Neuffer, Simone Pagan Griso, Antonello Pellecchia, Karolos
  Potamianos, Emilio Radicioni, Raffaella Radogna, Cristina Riccardi, Luciano
  Ristori, Lucio Rossi, Paola Salvini, Daniel Schulte, Lorenzo Sestini,
  Vladimir Shiltsev, Federica Maria Simone, Anna Stamerra, Xiaohu Sun, Jian
  Tang, Emily Anne Thompson, Ilaria Vai, Nicolo' Valle, Rosamaria Venditti,
  Piet Verwilligen, Paolo Vitulo, Hannsjorg Weber, Katsuya Yonehara, Angela
  Zaza, Davide Zuliani","Promising Technologies and R&D Directions for the Future Muon Collider
  Detectors","Contribution to Snowmass 2021, 27 pages, 15 figures",,,,"physics.ins-det hep-ex","http://creativecommons.org/licenses/by/4.0/","  Among the post-LHC generation of particle accelerators, the muon collider
represents a unique machine with capability to provide very high energy
leptonic collisions and to open the path to a vast and mostly unexplored
physics programme. However, on the experimental side, such great physics
potential is accompanied by unprecedented technological challenges, due to the
fact that muons are unstable particles. Their decay products interact with the
machine elements and produce an intense flux of background particles that
eventually reach the detector and may degrade its performance. In this paper,
we present technologies that have a potential to match the challenging
specifications of a muon collider detector and outline a path forward for the
future R&D efforts.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:02:55 GMT""}]","2022-03-15"
"2203.07225","Moustafa Rahal","Moustafa Rahal, Beno\^it Denis, Kamran Keykhosravi, Furkan Keskin,
  Bernard Uguen, George C. Alexandropoulos, Henk Wymeersch","Arbitrary Beam Pattern Approximation via RISs with Measured Element
  Responses","6 pages, 6 figures",,,,"eess.SP","http://creativecommons.org/publicdomain/zero/1.0/","  Smart radio environments (SREs) are seen as a key rising concept of next
generation wireless networks, where propagation channels between transmitters
and receivers are purposely controlled. One promising approach to achieve such
channel flexibility relies on semipassive reflective Reconfigurable intelligent
surfaces (RISs), which can shape the bouncing multipath signals for enhancing
communication quality of service, making localization feasible in adverse
operating conditions, or reducing unwanted electromagnetic emissions. This
paper introduces a generic framework that aims at optimizing the end-to-end
precoder controlled by RISs, so that arbitrary beam patterns can be generated,
given a predefined lookup table of RIS element-wise complex reflection
coefficients. This method is validated and illustrated for different targeted
beam patterns in both the far-field and the near-field regimes, while
considering the prior characterization of real-life RIS hardware prototypes.
These results show how, and to which extent, RIS configuration optimization can
approximate the desired beams under realistic hardware limitations and
low-complexity implementation practicability, or conversely, which RIS
elements' lookup tables would be more suitable. The latter can provide useful
guidelines for future RIS hardware designs.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:03:08 GMT""}]","2022-03-15"
"2203.07226","Yatir Halevi","Gabriel Conant, Christian d'Elb\'ee, Yatir Halevi, L\'eo Jimenez,
  Silvain Rideau-Kikuchi","Enriching a predicate and tame expansions of the integers",,,,,"math.LO","http://creativecommons.org/licenses/by/4.0/","  Given a structure $\mathcal{M}$ and a stably embedded $\emptyset$-definable
set $Q$, we prove tameness preservation results when enriching the induced
structure on $Q$ by some further structure $\mathcal{Q}$. In particular, we
show that if $T=\text{Th}(\mathcal{M})$ and $\text{Th}(\mathcal{Q})$ are stable
(resp., superstable, $\omega$-stable), then so is the theory $T[\mathcal{Q}]$
of the enrichment of $\mathcal{M}$ by $\mathcal{Q}$. Assuming simplicity of
$T$, elimination of hyperimaginaries and a further condition on $Q$ related to
the behavior of algebraic closure, we also show that simplicity and NSOP$_1$
pass from $\text{Th}(\mathcal{Q})$ to $T[\mathcal{Q}]$. We then prove several
applications for tame expansions of weakly minimal structures and, in
particular, the group of integers. For example, we construct the first known
examples of strictly stable expansions of $(\mathbb{Z},+)$. More generally, we
show that any stable (resp., superstable, simple, NIP, NTP$_2$, NSOP$_1$)
countable graph can be defined in a stable (resp., superstable, simple, NIP,
NTP$_2$, NSOP$_1$) expansion of $(\mathbb{Z},+)$ by some unary predicate
$A\subseteq\mathbb{N}$.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:03:52 GMT""},{""version"":""v2"",""created"":""Tue, 16 Aug 2022 06:09:39 GMT""}]","2022-08-17"
"2203.07227","Luca Onnis","Luca Onnis","On the general Smarandache's sigma product of digits","14 pages, 12 figures",,,,"math.GM","http://creativecommons.org/licenses/by/4.0/","  This paper investigates the behaviour of one of the most famous Smarandache's
sequence given by A061076 on oeis. In particular we first study the behaviour
of two sequences (A061077, A061078) strictly connected with the main
Smarandache's sigma product of digits. We'll solve some open problems such as
the determination of an upper bound for these sequences (which hold for all
$n\in\mathbb{N}$) and the determination of a closed formula for each $a(n)$ and
$b(n)$. Then combining these results it will be possible to understand the
behaviour of the general sequence $c(n)$. Every result will be accompanied by
Wolfram Mathematica scripts examples in order to support our thesis.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:05:03 GMT""},{""version"":""v2"",""created"":""Wed, 16 Mar 2022 17:59:21 GMT""}]","2022-03-17"
"2203.07228","Ilias Chalkidis","Ilias Chalkidis, Tommaso Pasini, Sheng Zhang, Letizia Tomada,
  Sebastian Felix Schwemer, Anders S{\o}gaard","FairLex: A Multilingual Benchmark for Evaluating Fairness in Legal Text
  Processing","9 pages, long paper at ACL 2022 proceedings",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  We present a benchmark suite of four datasets for evaluating the fairness of
pre-trained language models and the techniques used to fine-tune them for
downstream tasks. Our benchmarks cover four jurisdictions (European Council,
USA, Switzerland, and China), five languages (English, German, French, Italian
and Chinese) and fairness across five attributes (gender, age, region,
language, and legal area). In our experiments, we evaluate pre-trained language
models using several group-robust fine-tuning techniques and show that
performance group disparities are vibrant in many cases, while none of these
techniques guarantee fairness, nor consistently mitigate group disparities.
Furthermore, we provide a quantitative and qualitative analysis of our results,
highlighting open challenges in the development of robustness methods in legal
NLP.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:10:28 GMT""}]","2022-03-15"
"2203.07229","Umberto Michelucci","Francesca Venturini and Michela Sperti and Umberto Michelucci and
  Arnaud Gucciardi and Vanessa M. Martose and Marco A. Deriu","Physico-chemical properties extraction from the fluorescence spectrum
  with 1D-convolutional neural networks: application to olive oil","11 pages",,,,"cs.LG cs.AI eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The olive oil sector produces a substantial impact in the Mediterranean's
economy and lifestyle. Many studies exist which try to optimize the different
steps in the olive oil's production process. One of the main challenges for
olive oil producers is the ability to asses and control the quality during the
production cycle. For this purpose, several parameters need to be determined,
such as the acidity, the UV absorption or the ethyl esters content. To achieve
this, samples must be sent to an approved laboratory for chemical analysis.
This approach is expensive and cannot be performed very frequently, making
quality control of olive oil a real challenge. This work explores a new
approach based on fluorescence spectroscopy and artificial intelligence
(namely, 1-D convolutional neural networks) to predict the five chemical
quality indicators of olive oil (acidity, peroxide value, UV spectroscopic
parameters $K_{270}$ and $K_{232}$, and ethyl esters) from simple fluorescence
spectra. Fluorescence spectroscopy is a very attractive optical technique since
it does not require sample preparation, is non destructive, and, as shown in
this work, can be easily implemented in small and cost-effective sensors. The
results indicate that the proposed approach gives exceptional results in the
quality determination and would make the continuous quality control of olive
oil during and after the production process a reality. Additionally, this novel
methodology presents potential applications as a support for quality
specifications of olive oil, as defined by the European regulation.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:10:55 GMT""},{""version"":""v2"",""created"":""Sat, 9 Apr 2022 19:14:30 GMT""}]","2022-04-12"
"2203.07230","Pablo Villegas G\'ongora","Pablo Villegas, and Tommaso Gili, and Guido Caldarelli, and Andrea
  Gabrielli","Laplacian Renormalization Group for heterogeneous networks","7 pages, 4 figures, and Supplementary Information","Nat. Phys. (2023)","10.1038/s41567-022-01866-8",,"cond-mat.stat-mech cond-mat.dis-nn nlin.AO physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The renormalization group is the cornerstone of the modern theory of
universality and phase transitions, a powerful tool to scrutinize symmetries
and organizational scales in dynamical systems. However, its network
counterpart is particularly challenging due to correlations between intertwined
scales. To date, the explorations are based on hidden geometries hypotheses.
Here, we propose a Laplacian RG diffusion-based picture in complex networks,
defining both the Kadanoff supernodes' concept, the momentum space procedure,
\emph{\'a la Wilson}, and applying this RG scheme to real networks in a natural
and parsimonious way.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:12:53 GMT""}]","2023-01-11"
"2203.07231","Shankar Ghosh","Akash Ghosh, Jaikumar Radhakrishnan, Paul M. Chaikin, Dov Levine,
  Shankar Ghosh","Coupled dynamical phase transitions in driven disk packings",,,"10.1103/PhysRevLett.129.188002",,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Under the influence of oscillatory shear, a mono-layer of frictional granular
disks exhibits two dynamical phase transitions: a transition from an initially
disordered state to an ordered crystalline state, and a dynamic
active-absorbing phase transition. Although there is no reason, {\it a-priori},
for these to be at the same critical point, they are. The transitions may also
be characterized by the disk trajectories, which are non-trivial loops breaking
time-reversal invariance.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:12:55 GMT""}]","2022-11-09"
"2203.07232","Rirong Yuan","Rirong Yuan","The Dirichlet problem for Monge-Amp\`ere equation for $(n-1)$-PSH
  functions on Hermitian manifolds","The main context of this paper is the integration of the second parts
  of [arXiv:2001.09238] and [arXiv:2106.14837], while [arXiv: 2203.03439], and
  the first parts of [arXiv:2001.09238] and [arXiv:2106.14837] are reorganized
  into a separate paper [arXiv:2203.04898]. More precisely, this paper is
  essentially extracted from Section 7 in [arXiv:2001.09238] and Section 4 in
  [arXiv:2106.14837]",,,,"math.AP math.DG","http://creativecommons.org/licenses/by/4.0/","  We solve the Dirichlet problem for Monge-Amp\`ere equation for $(n-1)$-PSH
functions possibly with degenerate right-hand side, through deriving a
quantitative version of boundary estimate under the assumption of $(n-1)$-PSH
subsolutions. In addition, we confirm the subsolution assumption on a product
of a closed balanced manifold with a compact Riemann surface with boundary.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:12:58 GMT""}]","2022-03-15"
"2203.07233","Erick Fernando Alves","Erick Fernando Alves and Louis Polleux and Gilles Guerassimoff and
  Magnus Korp{\aa}s and Elisabetta Tedeschi","Allocation of spinning reserves for autonomous grids subject to
  frequency stability constraints and short-term solar power variations","Preprint submitted to Applied Energy",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by-sa/4.0/","  Low-inertia, isolated power systems face the problem of resiliency to power
variations. The integration of renewable energy sources, such as wind and solar
photovoltaic, pushes the boundaries of this issue further. Higher shares of
renewables requires better evaluations of electrical system stability, to avoid
severe safety and economic consequences. Accounting for frequency stability
requirements and allocating proper spinning reserves, therefore becomes a topic
of pivotal importance in the long-term planning and operational management of
power systems. In this paper, dynamic frequency constraints are proposed to
ensure resiliency during short-term power variations due to, for example, wind
gusts or cloud passage. The use of the proposed constraints is exemplified in a
case study, the constraints being integrated into a mixed-integer linear
programming algorithm for sizing the optimal capacities of solar photovoltaic
and battery energy storage resources in an isolated industrial plant. Outcomes
of this case study show that reductions in the levelized cost of energy and
carbon emissions can be overestimated by 8.0% and 10.8% respectively, where
frequency constraints are neglected. The proposed optimal sizing is validated
using time-domain simulations of the case study. The results indicate that this
optimal system is frequency stable under the worst-case contingency.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:13:16 GMT""},{""version"":""v2"",""created"":""Tue, 4 Oct 2022 17:11:00 GMT""}]","2022-10-05"
"2203.07235","Riccardo Piovani","Riccardo Piovani","Dolbeault Harmonic $(1,1)$-forms on $4$-dimensional compact quotients of
  Lie Groups with a left invariant almost Hermitian structure","20 pages, published version",,"10.1016/j.geomphys.2022.104639",,"math.DG math.CV math.SG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study Dolbeault harmonic $(1,1)$-forms on compact quotients
$M=\Gamma\backslash G$ of $4$-dimensional Lie groups $G$ admitting a left
invariant almost Hermitian structure $(J,\omega)$. In this case, we prove that
the space of Dolbeault harmonic $(1,1)$-forms on $(M,J,\omega)$ has dimension
$b^-+1$ if and only if there exists a left invariant anti self dual
$(1,1)$-form $\gamma$ on $(G,J)$ satisfying $id^c\gamma=d\omega$. Otherwise,
its dimension is $b^-$. In this way, we answer to a question by Zhang.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:14:58 GMT""},{""version"":""v2"",""created"":""Tue, 6 Sep 2022 11:41:31 GMT""}]","2022-09-07"
"2203.07236","Heidi Rzehak","Stefan Dittmaier and Heidi Rzehak","Electroweak renormalization based on gauge-invariant vacuum expectation
  values of non-linear Higgs representations: 1. Standard Model","23 pages",,"10.1007/JHEP05(2022)125","FR-PHENO-2022-02","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The renormalization of vacuum expectation value parameters, such as $v$ in
the Standard Model (SM), is an important ingredient in electroweak
renormalization, where this issue is connected to the treatment of tadpoles.
Tadpole counterterms can be generated in two different ways in the Lagrangian:
in the course of parameter renormalization, or alternatively via Higgs field
redefinitions. The former typically leads to small corrections originating from
tadpoles, but in general suffers from gauge dependences if MSbar
renormalization conditions are used for mass parameters. The latter is free
from gauge dependences, but is prone to very large corrections in MSbar
schemes, jeopardizing perturbative stability in predictions. In this paper we
propose a new scheme for tadpole renormalization, dubbed Gauge-Invariant Vacuum
expectation value Scheme (GIVS), which is a hybrid scheme of the two mentioned
types, with the benefits of being gauge independent and perturbatively stable.
The GIVS is based on the gauge-invariance property of Higgs fields, and the
corresponding parameters like $v$, in non-linear representations of Higgs
multiplets. We demonstrate the perturbative stability of the GIVS in the SM by
discussing the conversion between on-shell and MSbar renormalized masses.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:14:59 GMT""}]","2022-06-08"
"2203.07237","Simone Campana","Simone Campana, Alessandro Di Girolamo, Paul Laycock, Zach Marshall,
  Heidi Schellman, Graeme A Stewart","HEP computing collaborations for the challenges of the next decade","contribution to Snowmass 2021",,,,"physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large High Energy Physics (HEP) experiments adopted a distributed computing
model more than a decade ago. WLCG, the global computing infrastructure for
LHC, in partnership with the US Open Science Grid, has achieved data management
at the many-hundred-Petabyte scale, and provides access to the entire community
in a manner that is largely transparent to the end users. The main computing
challenge of the next decade for the LHC experiments is presented by the HL-LHC
program. Other large HEP experiments, such as DUNE and Belle II, have
large-scale computing needs and afford opportunities for collaboration on the
same timescale. Many of the computing facilities supporting HEP experiments are
shared and face common challenges, and the same is true for software libraries
and services. The LHC experiments and their WLCG- partners, DUNE and Belle II,
are now collaborating to evolve the computing infrastructure and services for
their future needs, facilitated by the WLCG organization, OSG, the HEP Software
Foundation and development projects such as HEP-CCE, IRIS-HEP and SWIFT-HEP. In
this paper we outline the strategy by which the international HEP computing
infrastructure, software and services should evolve through the collaboration
of large and smaller scale HEP experiments, while respecting the specific needs
of each community. We also highlight how the same infrastructure would be a
benefit for other sciences, sharing similar needs with HEP. This proposal is in
line with the OSG/WLCG strategy for addressing computing for HL-LHC and is
aligned with European and other international strategies in computing for large
scale science. The European Strategy for Particle Physics in 2020 agreed to the
principles laid out above, in its final report.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:16:17 GMT""}]","2022-03-15"
"2203.07238","Umberto Martinez-Penas","Umberto Mart\'inez-Pe\~nas","Multilayer crisscross error and erasure correction",,,,,"cs.IT math.IT","http://creativecommons.org/publicdomain/zero/1.0/","  In this work, multilayer crisscross error and erasures are considered, which
affect entire rows and columns in the matrices of a list of matrices. To
measure such errors and erasures, the multi-cover metric is introduced. Several
bounds are derived, including a Singleton bound, and maximum multi-cover
distance (MMCD) codes are defined as those attaining it. Duality, puncturing
and shortening of linear MMCD codes are studied. It is shown that the dual of a
linear MMCD code is not necessarily MMCD, and those satisfying this duality
condition are defined as dually MMCD codes. Finally, some constructions of
codes in the multi-cover metric are given, including dually MMCD codes,
together with efficient decoding algorithms for them.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:17:12 GMT""}]","2022-03-15"
"2203.07239","Ruiwen Li","Ruiwen Li, Zheda Mai, Chiheb Trabelsi, Zhibo Zhang, Jongseong Jang,
  Scott Sanner","TransCAM: Transformer Attention-based CAM Refinement for Weakly
  Supervised Semantic Segmentation",,"Journal of Visual Communication and Image Representation 2023","10.1016/j.jvcir.2023.103800",,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Weakly supervised semantic segmentation (WSSS) with only image-level
supervision is a challenging task. Most existing methods exploit Class
Activation Maps (CAM) to generate pixel-level pseudo labels for supervised
training. However, due to the local receptive field of Convolution Neural
Networks (CNN), CAM applied to CNNs often suffers from partial activation --
highlighting the most discriminative part instead of the entire object area. In
order to capture both local features and global representations, the Conformer
has been proposed to combine a visual transformer branch with a CNN branch. In
this paper, we propose TransCAM, a Conformer-based solution to WSSS that
explicitly leverages the attention weights from the transformer branch of the
Conformer to refine the CAM generated from the CNN branch. TransCAM is
motivated by our observation that attention weights from shallow transformer
blocks are able to capture low-level spatial feature similarities while
attention weights from deep transformer blocks capture high-level semantic
context. Despite its simplicity, TransCAM achieves a new state-of-the-art
performance of 69.3% and 69.6% on the respective PASCAL VOC 2012 validation and
test sets, showing the effectiveness of transformer attention-based refinement
of CAM for WSSS.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:17:18 GMT""}]","2023-03-17"
"2203.07240","Giulia Zanderighi","Luca Buonocore, Mauro Chiesa, Gabri\""el Koole, Daniele Lombardi,
  Javier Mazzitelli, Pier Francesco Monni, Paolo Nason, Emanuele Re, Luca
  Rottoli, Marius Wiesemann, Giulia Zanderighi, Silvia Zanoli","NNLO+PS with MiNNLO$_{\rm PS}$: status and prospects","Contribution to Snowmass 2022",,,,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We summarize the current status and near future prospects for
next-to-next-to-leading order calculations matched to parton shower based on
the MiNNLO$_{\rm PS}$ method. We give a theoretical overview, illustrate
selected results for $ZZ\to 4\ell$ and top-pair production processes at the
LHC, and provide an outlook of the future challenges.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:18:06 GMT""}]","2022-03-15"
"2203.07241","Simon Selg","Simon Selg and Wolfram Schmidt","Proceedings of the International Astronomical Union: Studying Magnetic
  Field Amplification in Interacting Galaxies Using Numerical Simulations","6 pages, 3 figures, to appear in the proceedings of the IAU Symposium
  No. 362 ""The Predictive Power of Computational Astrophysics as a Discovery
  Tool""",,,,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  There are indications that the magnetic field evolution in galaxies might be
massively shaped by tidal interactions and mergers between galaxies. The
details of the connection between the evolution of magnetic fields and that of
their host galaxies is still a field of research. We use a combined approach of
magnetohydrodynamics for the baryons and an N-body scheme for the dark matter
to investigate magnetic field amplification and evolution in interacting
galaxies. We find that, for two colliding equal-mass galaxies and for varying
initial relative spatial orientations, magnetic fields are amplified during
interactions, yet cannot be sustained. Furthermore, we find clues for an active
mean-field dynamo.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:18:40 GMT""}]","2022-03-15"
"2203.07242","Daniel Carney","The Windchime Collaboration: Alaina Attanasio, Sunil A. Bhave, Carlos
  Blanco, Daniel Carney, Marcel Demarteau, Bahaa Elshimy, Michael Febbraro,
  Matthew A. Feldman, Sohitri Ghosh, Abby Hickin, Seongjin Hong, Rafael F.
  Lang, Benjamin Lawrie, Shengchao Li, Zhen Liu, Juan P. A. Maldonado, Claire
  Marvinney, Hein Zay Yar Oo, Yun-Yi Pai, Raphael Pooser, Juehang Qin, Tobias
  J. Sparmann, Jacob M. Taylor, Hao Tian, and Christopher Tunnell","Snowmass 2021 White Paper: The Windchime Project","8 pages, 3 figures. Contribution to the Snowmass 2021 proceedings
  (Cosmic Frontier working groups 1 and 2 - particle and wave-like dark matter)",,,,"hep-ex astro-ph.CO hep-ph","http://creativecommons.org/licenses/by/4.0/","  The absence of clear signals from particle dark matter in direct detection
experiments motivates new approaches in disparate regions of viable parameter
space. In this Snowmass white paper, we outline the Windchime project, a
program to build a large array of quantum-enhanced mechanical sensors. The
ultimate aim is to build a detector capable of searching for Planck mass-scale
dark matter purely through its gravitational coupling to ordinary matter. In
the shorter term, we aim to search for a number of other physics targets,
especially some ultralight dark matter candidates. Here, we discuss the basic
design, open R&D challenges and opportunities, current experimental efforts,
and both short- and long-term physics targets of the Windchime project.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:18:44 GMT""}]","2022-03-15"
"2203.07243","Guolei Zhong","Guolei Zhong","Existence of the equivariant minimal model program for compact K\""ahler
  threefolds with the action of an abelian group of maximal rank","Minor revision, 13 pages, Mathematische Nachrichten (to appear)",,"10.1002/mana.202200127",,"math.AG math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $X$ be a $\mathbb{Q}$-factorial compact K\""ahler klt threefold admitting
an action of a free abelian group $G$, which is of positive entropy and of
maximal rank. After running the $G$-equivariant log minimal model program, we
show that such $X$ is either rationally connected or bimeromorphic to a
$Q$-complex torus. In particular, we fix an issue in the proof of our previous
paper.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:22:01 GMT""},{""version"":""v2"",""created"":""Mon, 30 Jan 2023 01:34:16 GMT""}]","2023-01-31"
"2203.07244","Lei Wang","Lei Wang, Jin Min Yang, Yang Zhang","Two-Higgs-doublet models in light of current experiments: a brief review","32 pages, 10 Figures, 4 Tables. Some discussions are improved and
  added. Published version","Commun. Theor. Phys. 74 (2022), 097202","10.1088/1572-9494/ac7fe9",,"hep-ph hep-ex","http://creativecommons.org/publicdomain/zero/1.0/","  We briefly survey several typical CP-conserving two-Higgs-doublet models
(2HDMs) in light of current experiments. First we derive the masses and
couplings of the mass eigenstates from the Lagrangians. Then we analyze the
constraints from theory and oblique electroweak parameters. Finally, we
delineate the status of 2HDM in light of the LHC searches, the dark matter
detections and the muon $g-2$ measurement.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:23:14 GMT""},{""version"":""v2"",""created"":""Thu, 24 Mar 2022 09:33:50 GMT""},{""version"":""v3"",""created"":""Mon, 10 Apr 2023 15:32:23 GMT""}]","2023-04-11"
"2203.07245","Michael Ten Brink","Michael ten Brink, Stefan Gr\""aber, Miroslav Hopjan, David Jansen, Jan
  Stolpp, Fabian Heidrich-Meisner, Peter E. Bl\""ochl","Real-time non-adiabatic dynamics in the one-dimensional Holstein model:
  Trajectory-based vs exact methods","44 pages, 34 figures. Minor revision due to reviewer comments. The
  data that support the findings of this study are openly available at
  https://doi.org/10.25625/YDU1XT, G\""ottingen Research Online / Data","J. Chem. Phys. 156, 234109 (2022)","10.1063/5.0092063",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We benchmark a set of quantum-chemistry methods, including multitrajectory
Ehrenfest, fewest-switches surface-hopping, and multiconfigurational-Ehrenfest
dynamics, against exact quantum-many-body techniques by studying real-time
dynamics in the Holstein model. This is a paradigmatic model in condensed
matter theory incorporating a local coupling of electrons to Einstein phonons.
For the two-site and three-site Holstein model, we discuss the exact and
quantum-chemistry methods in terms of the Born-Huang formalism, covering
different initial states, which either start on a single Born-Oppenheimer
surface, or with the electron localized to a single site. For extended systems
with up to 51 sites, we address both the physics of single Holstein polarons
and the dynamics of charge-density waves at finite electron densities. For
these extended systems, we compare the quantum-chemistry methods to exact
dynamics obtained from time-dependent density matrix renormalization group
calculations with local basis optimization (DMRG-LBO). We observe that the
multitrajectory Ehrenfest method, in general, only captures the ultrashort time
dynamics accurately. In contrast, the surface-hopping method with suitable
corrections provides a much better description of the long-time behavior but
struggles with the short-time description of coherences between different
Born-Oppenheimer states. We show that the multiconfigurational Ehrenfest method
yields a significant improvement over the multitrajectory Ehrenfest method and
can be converged to the exact results in small systems with moderate
computational efforts. We further observe that for extended systems, this
convergence is slower with respect to the number of configurations. Our
benchmark study demonstrates that DMRG-LBO is a useful tool for assessing the
quality of the quantum-chemistry methods.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:23:20 GMT""},{""version"":""v2"",""created"":""Thu, 30 Jun 2022 11:37:54 GMT""}]","2022-07-01"
"2203.07246","L\'eo Vacher","L. Vacher, J. Aumont, L. Montier, S. Azzoni, F. Boulanger and M.
  Remazeilles (for the LiteBIRD Collaboration)","Contribution to the 2022 Cosmology session of the 56th Rencontres de
  Moriond: Moment expansion of polarized dust SED: A new path towards capturing
  the CMB $B$-modes with LiteBIRD",,,,,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Characterizing accurately the polarized dust emission from our Galaxy will be
decisive for the quest for the Cosmic Microwave Background (CMB) primordial
$B$-modes. The incomplete modeling of its potentially complex spectral
properties could lead to biases in the CMB polarization analyses and to a
spurious detection of the tensor-to-scalar ratio $r$. Variations of the dust
properties along and between lines of sight lead to unavoidable distortions of
the spectral energy distribution (SED) that can not be easily anticipated by
standard component separation methods. This issue can be tackled using a moment
expansion of the dust SED, an innovative parametrization method imposing
minimal assumptions on the sky complexity. In the recent work [Vacher \emph{et
al.} (2022)]\cite{Vacher_2022}, we apply this formalism to the $B$-mode
cross-angular power spectra computed from simulated \lb{} polarization data at
frequencies between 100 and 402\,GHz, containing CMB, dust and instrumental
noise. Thanks to the moment expansion, we can measure an unbiased value of the
tensor-to-scalar ratio with a dispersion compatible with the target values
aimed by the instrument.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:24:02 GMT""}]","2022-03-15"
"2203.07247","Ivan Vovcenko","Vovchenko Ivan, Khamitov Timur","Analytical Approach to Intensity Calculation in Scintillation Detectors",,,,,"physics.ins-det physics.med-ph physics.optics","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Scintillation detectors are widely used in modern physics, including various
medical tomographs. There are two types of position-sensitive scintillation
detectors: pixel arrays of ""scintillator-photomultiplier"" pairs and continuous
scintillator with multiple photomultipliers attached. For the last one, there
are two common ways to calculate the coordinates of the scintillation flash via
detector response in scintillation cameras: Anger's method and Monte-Carlo
simulation. In this article, we develop an analytical approach (so-called
""kaleidoscopic ray-tracing"") to compute the energy outcome from several light
detectors in the scintillation camera with a continuous scintillator, which has
reflective and absorbing faces. We show that Anger's method is just an
approximation of the exact solution. Anger's method requires absorbing faces
only, so our approach covers a more general case. The derived method achieves
results, that are similar to the Monte-Carlo simulation, but it requires fewer
computations.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:24:14 GMT""}]","2022-03-15"
"2203.07248","Stepan Alexandrov","Stepan Alexandrov","Lann\'er diagrams and combinatorial properties of compact hyperbolic
  Coxeter polytopes","20 pages",,,,"math.GT math.CO math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study $\times_0$-products of Lann\'er diagrams. We prove
that every $\times_0$-product of at least four Lann\'er diagrams with at least
one diagram of order $\ge 3$ is superhyperbolic. As a corollary, we obtain that
known classifications exhaust all compact hyperbolic Coxeter polytopes that are
combinatorially equivalent to products of simplices.
  We also consider compact hyperbolic Coxeter polytopes whose every Lann\'er
subdiagram has order $2$. The second result of this paper slightly improves
recent Burcroff's upper bound on the dimension of such polytopes to $12$.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:24:39 GMT""},{""version"":""v2"",""created"":""Wed, 24 Aug 2022 12:56:27 GMT""}]","2022-08-25"
"2203.07249","Steffen Plunder","Steffen Plunder and Bernd Simeon","The mean-field limit for particle systems with uniform full-rank
  constraints","22 pages, 1 figure",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a particle system with uniform coupling between a macroscopic
component and individual particles. The constraint for each particle is of full
rank, which implies that each movement of the macroscopic component leads to a
movement of all particles and vice versa. Skeletal muscle tissues share a
similar property which motivates this work.
  We prove convergence of the mean-field limit, well-posedness and a stability
estimate for the mean-field PDE.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:28:13 GMT""}]","2022-03-15"
"2203.07250","Thomas Cecil","Oliver Buchmueller, Daniel Carney, Thomas Cecil, John Ellis, R.F.
  Garcia Ruiz, Andrew A. Geraci, David Hanneke, Jason Hogan, Nicholas R.
  Hutzler, Andrew Jayich, Shimon Kolkowitz, Gavin W. Morley, Holger Muller,
  Zachary Pagel, Christian Panda, and Marianna S. Safronova","Snowmass 2021: Quantum Sensors for HEP Science -- Interferometers,
  Mechanics, Traps, and Clocks","contribution to Snowmass 2021 18 pages, 3 figures; updated author
  list and references, fixed typos",,,,"quant-ph hep-ex hep-ph physics.atom-ph physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A wide range of quantum sensing technologies are rapidly being integrated
into the experimental portfolio of the high energy physics community. Here we
focus on sensing with atomic interferometers; mechanical devices read out with
optical or microwave fields; precision spectroscopic methods with atomic,
nuclear, and molecular systems; and trapped atoms and ions. We give a variety
of detection targets relevant to particle physics for which these systems are
uniquely poised to contribute. This includes experiments at the precision
frontier like measurements of the electron dipole moment and electromagnetic
fine structure constant and searches for fifth forces and modifications of
Newton's law of gravity at micron-to-millimeter scales. It also includes
experiments relevant to the cosmic frontier, especially searches for
gravitional waves and a wide variety of dark matter candidates spanning heavy,
WIMP-scale, light, and ultra-light mass ranges. We emphasize here the need for
more developments both in sensor technology and integration into the broader
particle physics community.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:29:19 GMT""},{""version"":""v2"",""created"":""Wed, 14 Sep 2022 20:30:38 GMT""}]","2022-09-16"
"2203.07251","Craig Lent","Brendan J. Mahoney and Craig S. Lent","The early-time Lieb-Robinson correlation function for qubit arrays","8 pages, 10 figures",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  The Lieb-Robinson correlation function captures propagation of quantum
correlations in a many-body system. We calculate the value of the leading order
of the correlation function, not its bound, for a system of interacting qubits
at early times. The general analytical result is compared to numerical
calculations and is applied to regular qubit lattices in one, two, and three
dimensions. The Lieb-Robinson velocity and the approximately exponential
leading edge of correlations emerge in the limit of large arrays.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:32:22 GMT""},{""version"":""v2"",""created"":""Thu, 24 Mar 2022 14:07:46 GMT""}]","2022-03-25"
"2203.07252","Yao-Yuan Mao","Yao-Yuan Mao, Annika H. G. Peter, Susmita Adhikari, Keith Bechtol,
  Simeon Bird, Simon Birrer, Jonathan Blazek, Jeffrey L. Carlin, Nushkia
  Chamba, Johann Cohen-Tanugi, Francis-Yan Cyr-Racine, Tansu Daylan, Birendra
  Dhanasingham, Alex Drlica-Wagner, Cora Dvorkin, Christopher Fassnacht, Eric
  Gawiser, Maurizio Giannotti, Vera Gluscevic, Alma Gonzalez-Morales, Renee
  Hlozek, M. James Jee, Stacy Kim, Akhtar Mahmood, Rachel Mandelbaum, Siddharth
  Mishra-Sharma, Marc Moniez, Ethan O. Nadler, Chanda Prescod-Weinstein, J.
  Anthony Tyson, Risa H. Wechsler, Hai-Bo Yu, Gabrijela Zaharijas","Snowmass2021: Vera C. Rubin Observatory as a Flagship Dark Matter
  Experiment","Contribution to Snowmass 2021",,,,"hep-ex astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Establishing that Vera C. Rubin Observatory is a flagship dark matter
experiment is an essential pathway toward understanding the physical nature of
dark matter. In the past two decades, wide-field astronomical surveys and
terrestrial laboratories have jointly created a phase transition in the
ecosystem of dark matter models and probes. Going forward, any robust
understanding of dark matter requires astronomical observations, which still
provide the only empirical evidence for dark matter to date. We have a unique
opportunity right now to create a dark matter experiment with Rubin Observatory
Legacy Survey of Space and Time (LSST). This experiment will be a coordinated
effort to perform dark matter research, and provide a large collaborative team
of scientists with the necessary organizational and funding supports. This
approach leverages existing investments in Rubin. Studies of dark matter with
Rubin LSST will also guide the design of, and confirm the results from, other
dark matter experiments. Supporting a collaborative team to carry out a dark
matter experiment with Rubin LSST is the key to achieving the dark matter
science goals that have already been identified as high priority by the
high-energy physics and astronomy communities.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:33:21 GMT""}]","2022-03-15"
"2203.07253","Jonas Lampart","Jonas Lampart","Hamiltonians for polaron models with subcritical ultraviolet
  singularities",,,,,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We treat the ultraviolet problem for polaron-type models in nonrelativistic
quantum field theory. Assuming that the dispersion relations of particles and
the field have the same growth at infinity, we cover all subcritical
(superrenormalisable) interactions. The Hamiltonian without cutoff is exhibited
as an explicit self-adjoint operator obtained by a finite iteration procedure.
The cutoff Hamiltonians converge to this operator in the strong resolvent sense
after subtraction of a perturbative approximation for the ground-state energy.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:34:03 GMT""}]","2022-03-15"
"2203.07254","Boris Segret","Boris Segret, Youssoupha Diaw and Valery Lainey","Refined Astrometry on Board a CubeSat",,,,,"astro-ph.IM","http://creativecommons.org/licenses/by-sa/4.0/","  Optical navigation on a CubeSat must rely on the best extraction of the
directions of some beacons from on-board images. We present an experiment on
OPS-SAT, a CubeSat of the European Space Agency (ESA), that will characterize
an onboard algorithm to this aim, named Angle-based Correlation (AbC). OPS-SAT
is a 3-unit CubeSat with an Attitude Determination and Control System (ADCS)
and an imager that have proved their reliability with typical performance at
CubeSat scale. We selected a few star-fields that all present enough visible
stars within a 10 ? field of view. When our experiment is run, OPS-SAT is
pointed to the most convenient star-field at that time. There, the star-field
is imaged and subwindows are extracted from the image around the expected
location of each star, based on the attitude-quaternion reported by the ADCS.
The AbC reconstructs the absolute direction of the central body, in principle
unknown, which is the pointed known star in the experiment. The method
intensively uses the quaternion algebra. The beacon location is first
consolidated in the field of view with the AbC. Then, the field of view is
finely positioned against the sky, again with the AbC. A covariance is
associated with the found beacon direction. Our experiment with OPS-SAT manages
the pointing and the imager, and processes the taken images. Then, it downloads
the on-board computed absolute directions and their covariances, to be compared
with the actual directions. After a campaign of intensive use of the
experiment, the statistical performance of the algorithm will be established
and compared to the on-board computed covariances. As a bonus, an assessment of
OPS-SAT's inertial pointing stability will be available. The AbC can
theoretically get rid of the Attitude Control Error (ACE) of the platform and
of the Attitude Knowledge Error (AKE) estimated by the ADCS, and potentially
converge to (...)
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:34:46 GMT""}]","2022-03-15"
"2203.07255","Ola Ahmad","Ola Ahmad and Freddy Lecue","FisheyeHDK: Hyperbolic Deformable Kernel Learning for Ultra-Wide
  Field-of-View Image Recognition","Accepted at AAAI22",,,,"cs.CV","http://creativecommons.org/publicdomain/zero/1.0/","  Conventional convolution neural networks (CNNs) trained on narrow
Field-of-View (FoV) images are the state-of-the-art approaches for object
recognition tasks. Some methods proposed the adaptation of CNNs to ultra-wide
FoV images by learning deformable kernels. However, they are limited by the
Euclidean geometry and their accuracy degrades under strong distortions caused
by fisheye projections. In this work, we demonstrate that learning the shape of
convolution kernels in non-Euclidean spaces is better than existing deformable
kernel methods. In particular, we propose a new approach that learns deformable
kernel parameters (positions) in hyperbolic space. FisheyeHDK is a hybrid CNN
architecture combining hyperbolic and Euclidean convolution layers for
positions and features learning. First, we provide an intuition of hyperbolic
space for wide FoV images. Using synthetic distortion profiles, we demonstrate
the effectiveness of our approach. We select two datasets - Cityscapes and
BDD100K 2020 - of perspective images which we transform to fisheye equivalents
at different scaling factors (analog to focal lengths). Finally, we provide an
experiment on data collected by a real fisheye camera. Validations and
experiments show that our approach improves existing deformable kernel methods
for CNN adaptation on fisheye images.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:37:54 GMT""}]","2022-03-15"
"2203.07256","Andrea Wulzer Dr","Chiara Aim\`e, Aram Apyan, Mohammed Attia Mahmoud, Nazar Bartosik,
  Alessandro Bertolin, Maurizio Bonesini, Salvatore Bottaro, Dario Buttazzo,
  Rodolfo Capdevilla, Massimo Casarsa, Luca Castelli, Maria Gabriella Catanesi,
  Francesco Giovanni Celiberto, Alessandro Cerri, Cari Cesarotti, Grigorios
  Chachamis, Siyu Chen, Yang-Ting Chien, Mauro Chiesa, Gianmaria Collazuol,
  Marco Costa, Nathaniel Craig, David Curtin, Sridhara Dasu, Jorge De Blas,
  Dmitri Denisov, Haluk Denizli, Radovan Dermisek, Luca Di Luzio, Biagio Di
  Micco, Keith Dienes, Tommaso Dorigo, Anna Ferrari, Davide Fiorina, Roberto
  Franceschini, Francesco Garosi, Alfredo Glioti, Mario Greco, Admir Greljo,
  Ramona Groeber, Christophe Grojean, Jiayin Gu, Tao Han, Brian Henning, Keith
  Hermanek, Tova Ray Holmes, Samuel Homiller, Sudip Jana, Sergo Jindariani,
  Yonatan Kahn, Ivan Karpov, Wolfgang Kilian, Kyoungchul Kong, Patrick
  Koppenburg, Karol Krizka, Lawrence Lee, Qiang Li, Ronald Lipton, Zhen Liu,
  Kenneth Long, Ian Low, Donatella Lucchesi, Yang Ma, Lianliang Ma, Fabio
  Maltoni, Bruno Mansoulie, Luca Mantani, David Marzocca, Navin McGinnis,
  Barbara Mele, Federico Meloni, Claudia Merlassino, Alessandro Montella, Marco
  Nardecchia, Federico Nardi, Paolo Panci, Simone Pagan Griso, Giuliano Panico,
  Rocco Paparella, Paride Paradisi, Nadia Pastrone, Fulvio Piccinini, Karolos
  Potamianos, Emilio Radicioni, Riccardo Rattazzi, Diego Redigolo, Laura Reina,
  J\""urgen Reuter, Cristina Riccardi, Lorenzo Ricci, Ursula van Rienen, Luciano
  Ristori, Tania Natalie Robens, Richard Ruiz, Filippo Sala, Jakub Salko, Paola
  Salvini, Ennio Salvioni, Daniel Schulte, Michele Selvaggi, Abdulkadir Senol,
  Lorenzo Sestini, Varun Sharma, Jing Shu, Rosa Simoniello, Giordon Holtsberg
  Stark, Daniel Stolarski, Shufang Su, Wei Su, Olcyr Sumensari, Xiaohu Sun,
  Raman Sundrum, Jian Tang, Andrea Tesi, Brooks Thomas, Riccardo Torre,
  Sokratis Trifinopoulos, Ilaria Vai, Alessandro Valenti, Ludovico Vittorio,
  Liantao Wang, Yongcheng Wu, Andrea Wulzer, Xiaoran Zhao, Jose Zurita","Muon Collider Physics Summary","21 pages, 7 figures; Contribution to Snowmass 2021",,,,"hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  The perspective of designing muon colliders with high energy and luminosity,
which is being investigated by the International Muon Collider Collaboration,
has triggered a growing interest in their physics reach. We present a concise
summary of the muon colliders potential to explore new physics, leveraging on
the unique possibility of combining high available energy with very precise
measurements.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:39:32 GMT""},{""version"":""v2"",""created"":""Fri, 27 May 2022 14:00:53 GMT""}]","2022-05-30"
"2203.07257","F. Javier Garc\'ia de Abajo","Kamran Akbari, Valerio Di Giulio, and F. Javier Garc\'ia de Abajo","Optical manipulation of matter waves","11 pages, 4 figures, 70 references",,,,"physics.optics quant-ph","http://creativecommons.org/licenses/by/4.0/","  Light is extensively used to steer the motion of atoms in free space,
enabling cooling and trapping of matter waves through ponderomotive forces and
Doppler-mediated photon scattering. Likewise, light interaction with free
electrons has recently emerged as a versatile approach to modulate the electron
wave function for applications in ultrafast electron microscopy. Here, we
combine these two worlds by theoretically demonstrating that matter waves can
be optically manipulated via inelastic interactions with optical fields,
allowing us to modulate the translational wave function and produce temporally
and spatially compressed atomic beam pulses. Specifically, we realize such
modulation through stimulated photon absorption and emission by atoms
traversing phase-matching evanescent optical fields generated upon light
scattering by a nanostructure, but also via stimulated Compton scattering in
free space without any assistance from material media. Our results support
optical manipulation of matter waves as a powerful tool for microscopy,
spectroscopy, and the exploration of novel fundamental phenomena associated
with light-atom interactions.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:39:54 GMT""},{""version"":""v2"",""created"":""Tue, 15 Mar 2022 10:48:56 GMT""}]","2022-03-16"
"2203.07258","Kirit Karkare","Kirit S. Karkare, Azadeh Moradinezhad Dizgah, Garrett K. Keating,
  Patrick Breysse, Dongwoo T. Chung (for the Snowmass Cosmic Frontier 5 Topical
  Group)","Snowmass 2021 Cosmic Frontier White Paper: Cosmology with
  Millimeter-Wave Line Intensity Mapping","25 pages, 4 figures. Contribution to Snowmass 2021",,,,"astro-ph.CO hep-ex","http://creativecommons.org/licenses/by/4.0/","  Next-generation tests of fundamental physics and cosmology using large scale
structure require measurements over large volumes of the Universe, including
high redshifts inaccessible to present-day surveys. Line intensity mapping, an
emerging technique that detects the integrated emission of atomic and molecular
lines without resolving sources, can efficiently map cosmic structure over a
wide range of redshifts. Observations at millimeter wavelengths detect far-IR
emission lines such as CO/[CII], and take advantage of observational and
analysis techniques developed by CMB experiments. These measurements can
provide constraints with unprecedented precision on the physics of inflation,
neutrino masses, light relativistic species, dark energy and modified gravity,
and dark matter, among many other science goals. In this white paper we
forecast the sensitivity requirements for future ground-based mm-wave intensity
mapping experiments to enable transformational cosmological constraints. We
outline a staged experimental program to steadily improve sensitivity, and
describe the necessary investments in developing detector technology and
analysis techniques.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:40:17 GMT""}]","2022-03-15"
"2203.07259","Eldar Kurtic","Eldar Kurtic, Daniel Campos, Tuan Nguyen, Elias Frantar, Mark Kurtz,
  Benjamin Fineran, Michael Goin, Dan Alistarh","The Optimal BERT Surgeon: Scalable and Accurate Second-Order Pruning for
  Large Language Models","Accepted to EMNLP 2022",,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Transformer-based language models have become a key building block for
natural language processing. While these models are extremely accurate, they
can be too large and computationally intensive to run on standard deployments.
A variety of compression methods, including distillation, quantization,
structured and unstructured pruning are known to decrease model size and
increase inference speed, with low accuracy loss. In this context, this paper's
contributions are two-fold. We perform an in-depth study of the
accuracy-compression trade-off for unstructured weight pruning of BERT models.
We introduce Optimal BERT Surgeon (oBERT), an efficient and accurate weight
pruning method based on approximate second-order information, which we show to
yield state-of-the-art results in both stages of language tasks: pre-training
and fine-tuning. Specifically, oBERT extends existing work on unstructured
second-order pruning by allowing for pruning blocks of weights, and by being
applicable at the BERT scale. Second, we investigate the impact of this pruning
method when compounding compression approaches to obtain highly compressed but
accurate models for deployment on edge devices. These models significantly push
boundaries of the current state-of-the-art sparse BERT models with respect to
all metrics: model size, inference speed and task accuracy. For example,
relative to the dense BERT-base, we obtain 10x model size compression (in MB)
with < 1% accuracy drop, 10x CPU-inference speedup with < 2% accuracy drop, and
29x CPU-inference speedup with < 7.5% accuracy drop. Our code, fully integrated
with Transformers and SparseML, is available at
https://github.com/neuralmagic/sparseml/tree/main/research/optimal_BERT_surgeon_oBERT.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:40:31 GMT""},{""version"":""v2"",""created"":""Mon, 23 May 2022 14:42:23 GMT""},{""version"":""v3"",""created"":""Mon, 17 Oct 2022 23:24:22 GMT""}]","2022-10-19"
"2203.07260","Rapha\""el Romero","Rapha\""el Romero, Bo Kang, Tijl De Bie","Graph-Survival: A Survival Analysis Framework for Machine Learning on
  Temporal Networks",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Continuous time temporal networks are attracting increasing attention due
their omnipresence in real-world datasets and they manifold applications. While
static network models have been successful in capturing static topological
regularities, they often fail to model effects coming from the causal nature
that explain the generation of networks. Exploiting the temporal aspect of
networks has thus been the focus of various studies in the last decades.
  We propose a framework for designing generative models for continuous time
temporal networks. Assuming a first order Markov assumption on the
edge-specific temporal point processes enables us to flexibly apply survival
analysis models directly on the waiting time between events, while using
time-varying history-based features as covariates for these predictions. This
approach links the well-documented field of temporal networks analysis through
multivariate point processes, with methodological tools adapted from survival
analysis. We propose a fitting method for models within this framework, and an
algorithm for simulating new temporal networks having desired properties. We
evaluate our method on a downstream future link prediction task, and provide a
qualitative assessment of the network simulations.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:40:57 GMT""},{""version"":""v2"",""created"":""Tue, 15 Mar 2022 13:05:13 GMT""}]","2022-03-16"
"2203.07261","Andrea Wulzer Dr","Jorge De Blas, Dario Buttazzo, Rodolfo Capdevilla, David Curtin,
  Roberto Franceschini, Fabio Maltoni, Patrick Meade, Federico Meloni, Shufang
  Su, Eleni Vryonidou, Andrea Wulzer, Chiara Aim\`e, Aram Apyan, Pouya Asadi,
  Mohammed Attia Mahmoud, Aleksandr Azatov, Nazar Bartosik, Alessandro
  Bertolin, Salvatore Bottaro, Laura Buonincontri, Massimo Casarsa, Luca
  Castelli, Maria Gabriella Catanesi, Francesco Giovanni Celiberto, Alessandro
  Cerri, Cari Cesarotti, Grigorios Chachamis, Siyu Chen, Yang-Ting Chien, Mauro
  Chiesa, Marco Costa, Giacomo Da Molin, Sridhara Dasu, Dmitri Denisov, Haluk
  Denizli, Radovan Dermisek, Luca Di Luzio, Biagio Di Micco, Keith Dienes,
  Tommaso Dorigo, Marco Fabbrichesi, Davide Fiorina, Matthew Forslund, Emidio
  Gabrielli, Francesco Garosi, Alfredo Glioti, Mario Greco, Admir Greljo,
  Ramona Groeber, Christophe Grojean, Jiayin Gu, Chengcheng Han, Tao Han, Keith
  Hermanek, Matthew Herndon, Tova Ray Holmes, Samuel Homiller, Guoyuan Huang,
  Sudip Jana, Sergo Jindariani, Yonatan Kahn, Wolfgang Kilian, Patrick
  Koppenburg, Nils Kreher, Karol Krizka, Gordan Krnjaic, Nilanjana Kumar,
  Lawrence Lee, Qiang Li, Zhen Liu, Kenneth Long, Ian Low, Qianshu Lu,
  Donatella Lucchesi, Lianliang Ma, Yang Ma, Luca Mantani, David Marzocca,
  Navin McGinnis, Barbara Mele, Claudia Merlassino, Alessandro Montella, Marco
  Nardecchia, Federico Nardi, Paolo Panci, Simone Pagan Griso, Giuliano Panico,
  Paride Paradisi, Nadia Pastrone, Fulvio Piccinini, Karolos Potamianos, Emilio
  Radicioni, Riccardo Rattazzi, Diego Redigolo, Laura Reina, J\""urgen Reuter,
  Cristina Riccardi, Lorenzo Ricci, Luciano Ristori, Tania Natalie Robens,
  Werner Rodejohann, Richard Ruiz, Farinaldo S. Queiroz, Filippo Sala, Jakub
  Salko, Paola Salvini, Jose Santiago, Ivano Sarra, Daniel Schulte, Michele
  Selvaggi, Abdulkadir Senol, Lorenzo Sestini, Varun Sharma, Rosa Simoniello,
  Giordon Holtsberg Stark, Daniel Stolarski, Wei Su, Olcyr Sumensari, Xiaohu
  Sun, Tim M.P. Tait, Jian Tang, Andrea Tesi, Brooks Thomas, Emily Anne
  Thompson, Riccardo Torre, Sokratis Trifinopoulos, Ilaria Vai, Alessandro
  Valenti, Ludovico Vittorio, Liantao Wang, Yongcheng Wu, Keping Xie, Xiaoran
  Zhao, Jose Zurita","The physics case of a 3 TeV muon collider stage","73 pages, 28 figures; Contribution to Snowmass 2021",,,,"hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  In the path towards a muon collider with center of mass energy of 10 TeV or
more, a stage at 3 TeV emerges as an appealing option. Reviewing the physics
potential of such muon collider is the main purpose of this document. In order
to outline the progression of the physics performances across the stages, a few
sensitivity projections for higher energy are also presented. There are many
opportunities for probing new physics at a 3 TeV muon collider. Some of them
are in common with the extensively documented physics case of the CLIC 3 TeV
energy stage, and include measuring the Higgs trilinear coupling and testing
the possible composite nature of the Higgs boson and of the top quark at the 20
TeV scale. Other opportunities are unique of a 3 TeV muon collider, and stem
from the fact that muons are collided rather than electrons. This is
exemplified by studying the potential to explore the microscopic origin of the
current $g$-2 and $B$-physics anomalies, which are both related with muons.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:41:37 GMT""},{""version"":""v2"",""created"":""Fri, 27 May 2022 13:55:53 GMT""}]","2022-05-30"
"2203.07262","M\'ario Jos\'e de Oliveira","M\'ario J. de Oliveira","Parametric invariance",,,,,"cond-mat.stat-mech physics.class-ph physics.hist-ph quant-ph","http://creativecommons.org/licenses/by/4.0/","  We examine the development of the concept of parametric invariance in
classical mechanics, quantum mechanics, statistical mechanics, and
thermodynamics, and particularly its relation to entropy. The parametric
invariance was used by Ehrenfest as a principle related to the quantization
rules of the old quantum mechanics. It was also considered by Rayleigh in the
determination of pressure caused by vibration, and the general approach we
follow here is based on his. Specific calculation of invariants in classical
and quantum mechanics are determined. The Hertz invariant, which is a volume in
phase space, is extended to the case of a variable number of particles. We show
that the slow parametric change leads to the adiabatic process, allowing the
definition of entropy as a parametric invariance.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:41:46 GMT""}]","2022-03-15"
"2203.07263","Hong-Ye Hu","Hong-Ye Hu and Ryan LaRose and Yi-Zhuang You and Eleanor Rieffel and
  Zhihui Wang","Logical shadow tomography: Efficient estimation of error-mitigated
  observables","7+8 pages. H.-Y.H. and R.L. have equal contributions",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We introduce a technique to estimate error-mitigated expectation values on
noisy quantum computers. Our technique performs shadow tomography on a logical
state to produce a memory-efficient classical reconstruction of the noisy
density matrix. Using efficient classical post-processing, one can mitigate
errors by projecting a general nonlinear function of the noisy density matrix
into the codespace. The subspace expansion and virtual distillation can be
viewed as special cases of the new framekwork. We show our method is favorable
in the quantum and classical resources overhead. Relative to subspace expansion
which requires $O\left(2^{N} \right)$ samples to estimate a logical Pauli
observable with $[[N, k]]$ error correction code, our technique requires only
$O\left(4^{k} \right)$ samples. Relative to virtual distillation, our technique
can compute powers of the density matrix without additional copies of quantum
states or quantum memory. We present numerical evidence using logical states
encoded with up to sixty physical qubits and show fast convergence to
error-free expectation values with only $10^5$ samples under 1% depolarizing
noise.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:42:22 GMT""}]","2022-03-15"
"2203.07264","Shuyan Zhou","Shuyan Zhou and Li Zhang and Yue Yang and Qing Lyu and Pengcheng Yin
  and Chris Callison-Burch and Graham Neubig","Show Me More Details: Discovering Hierarchies of Procedures from
  Semi-structured Web Data","ACL 2022",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Procedures are inherently hierarchical. To ""make videos"", one may need to
""purchase a camera"", which in turn may require one to ""set a budget"". While
such hierarchical knowledge is critical for reasoning about complex procedures,
most existing work has treated procedures as shallow structures without
modeling the parent-child relation. In this work, we attempt to construct an
open-domain hierarchical knowledge-base (KB) of procedures based on wikiHow, a
website containing more than 110k instructional articles, each documenting the
steps to carry out a complex procedure. To this end, we develop a simple and
efficient method that links steps (e.g., ""purchase a camera"") in an article to
other articles with similar goals (e.g., ""how to choose a camera""), recursively
constructing the KB. Our method significantly outperforms several strong
baselines according to automatic evaluation, human judgment, and application to
downstream tasks such as instructional video retrieval.
  A demo with partial data can be found at https://wikihow-hierarchy.github.io.
The code and the data are at https://github.com/shuyanzhou/wikihow_hierarchy.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:42:35 GMT""},{""version"":""v2"",""created"":""Thu, 17 Mar 2022 17:20:15 GMT""}]","2022-03-18"
"2203.07265","David Maurin","D. Maurin, E. Ferronato Bueno, and L. Derome","A simple determination of the halo size $L$ from $^{10}$Be/$^9$Be data","9 pages, 2 tables, 5 figures (matches accepted A&A version):
  comparison to [De21] moved to appendix (also highlight impact of
  reacceleration)","A&A 667, A25 (2022)","10.1051/0004-6361/202243546",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  The AMS-02 and HELIX experiments should soon provide $\mathrm{^{10}Be/^9Be}$
cosmic-ray data of unprecedented precision. We propose an analytical formula to
quickly and accurately determine $L$ from these data. Our formula is validated
against the full calculation performed with the propagation code \usine{}. We
compare the constraints on $L$ set by Be/B and $\mathrm{^{10}Be/^9Be}$, relying
on updated sets of production cross-sections. The best-fit $L$ from AMS-02 Be/B
data is shifted from 5 kpc to 3.8 kpc when using the updated cross-sections. We
obtained consistent results from the Be/B analysis with USINE,
$L=3.8^{+2.8}_{-1.6}$ kpc (data and cross-section uncertainties), and from the
analysis of $\mathrm{^{10}Be/^9Be}$ data with the simplified formula,
$L=4.7\pm0.6$ (data uncertainties) $\pm2$ (cross-section uncertainties) kpc.
The analytical formula indicates that improvements on $L$ thanks to future data
will be limited by production cross-section uncertainties, unless either
$\mathrm{^{10}Be/^9Be}$ measurements are extended up to several tens of GeV/n,
or nuclear data for the production of $\mathrm{^{10}Be}$ and $\mathrm{^9Be}$
are improved; new data for the production cross-section of $\mathrm{^{16}O}$
into Be isotopes above a few GeV/n are especially desired.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:43:19 GMT""},{""version"":""v2"",""created"":""Thu, 1 Sep 2022 05:59:52 GMT""}]","2022-11-02"
"2203.07266","M H Mortad Ph.D.","Souheyb Dehimi, Mohammed Hichem Mortad and Ahmed Bachir","On the commutativity of closed symmetric operators","arXiv admin note: substantial text overlap with arXiv:2201.10604",,,,"math.FA math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we give conditions guaranteeing the commutativity of a
bounded self-adjoint operator with an unbounded closed symmetric operator.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:44:22 GMT""}]","2022-04-13"
"2203.07267","Hai Dinh-Tuan","Hai Dinh-Tuan, Maria Mora-Martinez, Felix Beierle, Sandro Rodriguez
  Garzon","Development Frameworks for Microservice-based Applications: Evaluation
  and Comparison",,,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The microservice architectural style has gained much attention from both
academia and industry recently as a novel way to design, develop, and deploy
cloud-native applications. This concept encourages the decomposition of a
monolith into multiple independently deployable units. A typical
microservices-based application is formed of two service types: functional
services, which provide the core business logic, and infrastructure services,
which provide essential functionalities for a microservices ecosystem. To
improve developers' productivity, many software frameworks have been developed
to provide those reusable infrastructure services, allowing programmers to
focus on implementing microservices in arbitrary ways. In this work, we made
use of four open source frameworks to develop a cloud-based application in
order to compare and evaluate their usability and practicability. While all
selected frameworks promote asynchronous microservice design in general, there
are differences in the ways each implements services. This leads to
interoperability issues, such as message topic naming convention. Additionally,
a key finding is the long startup times of JVM-based services that might reduce
application's resiliency and portability. Some other advantages come directly
from the programming language, such as the ability of Go to generate native
binary executables, which results in very small and compact Docker images (up
to 78\% smaller compared to other languages).
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:45:17 GMT""}]","2022-03-15"
"2203.07268","Bernard Rybo{\l}owicz","Simion Breaz, Tomasz Brzezi\'nski, Bernard Rybo{\l}owicz, and Paolo
  Saracco","Heaps of modules and affine spaces",,,,,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A notion of heaps of modules as an affine version of modules over a ring or,
more generally, over a truss, is introduced and studied. Basic properties of
heaps of modules are derived. Examples arising from geometry (connections,
affine spaces) and algebraic topology (chain contractions) are presented.
Relationships between heaps of modules and modules over a ring and affine
spaces are revealed and analysed.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:45:18 GMT""}]","2022-03-15"
"2203.07269","Moustafa Rahal","Moustafa Rahal, Beno\^it Denis, Kamran Keykhosravi, Furkan Keskin,
  Bernard Uguen, Henk Wymeersch","Constrained RIS Phase Profile Optimization and Time Sharing for
  Near-field Localization","6 pages, 7 figures",,,,"eess.SP","http://creativecommons.org/publicdomain/zero/1.0/","  The rising concept of reconfigurable intelligent surface (RIS) has promising
potential for Beyond 5G localization applications. We herein investigate
different phase profile designs at a reflective RIS, which enable
non-line-of-sight positioning in nearfield from downlink single antenna
transmissions. We first derive the closed-form expressions of the corresponding
Fisher information matrix (FIM) and position error bound (PEB). Accordingly, we
then propose a new localization-optimal phase profile design, assuming prior
knowledge of the user equipment location. Numerical simulations in a canonical
scenario show that our proposal outperforms conventional RIS random and
directional beam codebook designs in terms of PEB. We also illustrate the four
beams allocated at the RIS (i.e., one directional beam, along with its
derivatives with respect to space dimensions) and show how their relative
weights according to the optimal solution can be practically implemented
through time sharing (i.e., considering feasible beams sequentially).
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:45:26 GMT""},{""version"":""v2"",""created"":""Mon, 25 Apr 2022 12:25:26 GMT""},{""version"":""v3"",""created"":""Tue, 26 Apr 2022 08:38:04 GMT""}]","2022-04-27"
"2203.07270","Gabriele Ferretti","Avik Banerjee, Diogo Buarque Franzosi, Giacomo Cacciapaglia, Aldo
  Deandrea, Gabriele Ferretti, Thomas Flacke, Benjamin Fuks, Manuel Kunkel,
  Luca Panizzi, Werner Porod and Leonard Schwarze","Phenomenological aspects of composite Higgs scenarios: exotic scalars
  and vector-like quarks","contribution to Snowmass 2021. V2: Fig. 4 updated, V3: Figures and
  references updated",,,"KIAS-A22001","hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  Composite Higgs models usually contain additional pseudo Nambu Goldstone
bosons and vector-like quarks. We discuss various aspects related to their LHC
phenomenology and provide summary plots of exclusion limits using currently
available information. We also describe a general parametrisation implemented
in a software for Monte Carlo simulations and study the SU(5)/SO(5) scenario as
a concrete example.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:46:44 GMT""},{""version"":""v2"",""created"":""Thu, 31 Mar 2022 14:47:01 GMT""},{""version"":""v3"",""created"":""Mon, 27 Jun 2022 09:31:27 GMT""}]","2022-06-28"
"2203.07271","Joseph Gal","Joseph Gal","Comment on the Evidence of isostructural phase transitions in elemental
  zirconium",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  It is argued that the article by O.Bannon et al. ; High pressure stability of
beta-Zr: no evidence for isostructural phase transitions, published recently
-July 2021 - in High Pressure Research has no experimental foundation and the
statement no evidence is absolutly misleading. Isostructural phase transition
has been reported only in Ce metal, thus, the Beta-Zr to beta prime -Zr
isostructural phase transitions has fundamental interest in condensed matter
physics.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:48:22 GMT""}]","2022-03-15"
"2203.07272","Taikan Suehara","Taikan Suehara","Two-fermion final states at International Linear Collider","Contribution to Snowmass 2021, 4 pages, no figures",,,,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The pair productions of leptons and quarks at $e^+e^-$ Higgs factory are an
important probe for new physics via precise measurements. The discovery and
exclusion limits of $Z^\prime$ models at the International Linear Collider with
$\sqrt{s} = 250$, 500 and 1000 GeV are calculated with selection efficiencies
estimated in the existing full simulation studies. It shows a large potential
of BSM searches with precise measurements at future energy-frontier $e^+e^-$
colliders.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:48:29 GMT""}]","2022-03-15"
"2203.07273","Daniele Zonetti","Daniele Zonetti, Romeo Ortega, Rafael Cisneros, Alexey Bobtsov,
  Fernando Mancilla-David, Oriol Gomis-Bellmunt","An Observer-Based Composite Identifier for Online Estimation of the
  Thevenin Equivalent Parameters of a Power System",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  We consider a Th\'evenin equivalent circuit capturing the dynamics of a power
grid as seen from the point of common coupling with a power electronic
converter, and provide a solution to the problem of online identification of
the corresponding circuit parameters. For this purpose, we first derive a
linear regression model in the conventional abc coordinates and next design a
bounded observer-based composite identifier that requires local measurements
and knowledge of the grid frequency only. An extension that guarantees
exponential convergence of the estimates, under the additional assumption of
knowledge of the grid X/R ratio, is further provided. The performance of the
proposed identifier, which subsumes a conventional gradient descent algorithm,
is illustrated via detailed computer simulations.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:48:41 GMT""}]","2022-03-15"
"2203.07274","Stoyan Stoynev","Stoyan Stoynev","Test samples and infrastructure for accelerator magnet developments","contribution to Snowmass 2021 (AF)",,,,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  LHC still does not operate at full energy due to training features in
magnets. Higher field practical superconductors (Nb3Sn) show much worse
training behavior than NbTi. Most magnet performance issues relate to
quenching, and it is this phenomenon and its dependencies that need to be
understood for us to succeed addressing them in magnets. For pragmatic and
scientific reasons underlying mechanisms are hard to investigate in real
magnets. Available data suggest that emulating local conditions at quench
location may be enough to arrive at a good understanding of what drives
observed behavior. ""Local"" conditions imply emulation by small samples of
cables/""stacks"" powered within a facility with controllable conditions,
including external magnetic and force fields. This paper argues about the
necessity of this approach, while reminding current understanding and
directions of quench studies, and pointing out inadequacy of available
techniques. Improved facilities and change of perspective are required for
consistent and affordable development.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:50:25 GMT""}]","2022-03-15"
"2203.07275","Peter Johnson","Peter D. Johnson, Alexander A. Kunitsa, J\'er\^ome F. Gonthier,
  Maxwell D. Radin, Corneliu Buda, Eric J. Doskocil, Clena M. Abuan, Jhonathan
  Romero","Reducing the cost of energy estimation in the variational quantum
  eigensolver algorithm with robust amplitude estimation","8 pages, 3 figures + appendix",,,,"quant-ph physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum chemistry and materials is one of the most promising applications of
quantum computing. Yet much work is still to be done in matching
industry-relevant problems in these areas with quantum algorithms that can
solve them. Most previous efforts have carried out resource estimations for
quantum algorithms run on large-scale fault-tolerant architectures, which
include the quantum phase estimation algorithm. In contrast, few have assessed
the performance of near-term quantum algorithms, which include the variational
quantum eigensolver (VQE) algorithm. Recently, a large-scale benchmark study
[Gonthier et al. 2020] found evidence that the performance of the variational
quantum eigensolver for a set of industry-relevant molecules may be too
inefficient to be of practical use. This motivates the need for developing and
assessing methods that improve the efficiency of VQE. In this work, we predict
the runtime of the energy estimation subroutine of VQE when using robust
amplitude estimation (RAE) to estimate Pauli expectation values. Under
conservative assumptions, our resource estimation predicts that RAE can reduce
the runtime over the standard estimation method in VQE by one to two orders of
magnitude. Despite this improvement, we find that the runtimes are still too
large to be practical. These findings motivate two complementary efforts
towards quantum advantage: 1) the investigation of more efficient near-term
methods for ground state energy estimation and 2) the development of problem
instances that are of industrial value and classically challenging, but better
suited to quantum computation.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:51:36 GMT""}]","2022-03-15"
"2203.07276","Zishen Wan","Zishen Wan, Aqeel Anwar, Abdulrahman Mahmoud, Tianyu Jia, Yu-Shun
  Hsiao, Vijay Janapa Reddi, Arijit Raychowdhury","FRL-FI: Transient Fault Analysis for Federated Reinforcement
  Learning-Based Navigation Systems","2022 Design Automation and Test in Europe Conference (DATE), March
  14-23, 2022, Virtual",,,,"cs.LG cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Swarm intelligence is being increasingly deployed in autonomous systems, such
as drones and unmanned vehicles. Federated reinforcement learning (FRL), a key
swarm intelligence paradigm where agents interact with their own environments
and cooperatively learn a consensus policy while preserving privacy, has
recently shown potential advantages and gained popularity. However, transient
faults are increasing in the hardware system with continuous technology node
scaling and can pose threats to FRL systems. Meanwhile, conventional
redundancy-based protection methods are challenging to deploy on
resource-constrained edge applications. In this paper, we experimentally
evaluate the fault tolerance of FRL navigation systems at various scales with
respect to fault models, fault locations, learning algorithms, layer types,
communication intervals, and data types at both training and inference stages.
We further propose two cost-effective fault detection and recovery techniques
that can achieve up to 3.3x improvement in resilience with <2.7% overhead in
FRL systems.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:51:41 GMT""}]","2022-03-15"
"2203.07277","Dmitry Ponomarev","Dmitry Ponomarev","A short note on the appearance of the simplest antilinear ODE in several
  physical contexts",,,,,"math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  In this short note, we review several one-dimensional problems such as those
involving linear Schroedinger equation, variable-coefficient Helmholtz
equation, Zakharov-Shabat system and Kubelka-Munk equations. We show that they
all can be reduced to solving one simple antilinear ordinary differential
equation $u^{\prime}\left(x\right)=f\left(x\right)\overline{u\left(x\right)}$
or its nonhomogeneous version
$u^{\prime}\left(x\right)=f\left(x\right)\overline{u\left(x\right)}+g\left(x\right)$,
$x\in\left(0,x_{0}\right)\subset\mathbb{R}$. We point out some of the
advantages of the proposed reformulation and call for further investigation of
the obtained ODE.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:52:57 GMT""},{""version"":""v2"",""created"":""Tue, 29 Mar 2022 12:14:12 GMT""}]","2022-03-30"
"2203.07278","Sergio Munoz","J. Gonz\'alez-Carbajal, Pedro Urda, Sergio Mu\~noz, Jos\'e L. Escalona","Estimation of the trajectory and attitude of railway vehicles using
  inertial sensors with application to track geometry measurement",,,,,"cs.CE","http://creativecommons.org/licenses/by/4.0/","  This paper describes a novel method for the estimation of the trajectory
curve and orientation of a rigid body moving along a railway track. Compared to
other recent developments in the literature, the presented approach has the
significant advantage of tracking the position and orientation of a railway
vehicle using inertial sensors only, excluding global position sensors (GNSS or
total station) and also excluding global orientation sensors (magnetometers or
inclinometers). The algorithm is based on a kinematic model of the relative
motion of the body with respect to the track. This kinematic model is used as
the system equations of a Kalman filter algorithm that includes in the state
vector the coordinates used to define the position and orientation of the body.
Two different Kalman filter approaches are described. In the first one, the
position and orientation are calculated independently. In the second one, both
position and orientation are calculated as a coupled problem. Crucial to the
success of the results of the Kalman filters is the use of the correct
covariance matrices associated with the system process and the measurements.
The calculated trajectory and orientation are applied in this research to the
problem of track geometry measurement. A scale track with known design geometry
and irregularities is used to conduct experiments for tuning and evaluating the
quality of the output of the algorithm. Results show that the developed
algorithm is accurate enough for this application. They also show that, using
either of the two proposed Kalman filtering approaches, the constrained maximum
likelihood method for the estimation of the covariance matrices performs
similarly to the known-output method. This is very convenient because it allows
a straightforward application of the observation model in different scenarios.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:54:00 GMT""}]","2022-03-15"
"2203.07279","Sujoy Sikdar","Hadi Hosseini, Sujoy Sikdar, Rohit Vaish, Lirong Xia","Fairly Dividing Mixtures of Goods and Chores under Lexicographic
  Preferences",,,,,"cs.GT econ.TH","http://creativecommons.org/licenses/by/4.0/","  We study fair allocation of indivisible goods and chores among agents with
\emph{lexicographic} preferences -- a subclass of additive valuations. In sharp
contrast to the goods-only setting, we show that an allocation satisfying
\emph{envy-freeness up to any item} (EFX) could fail to exist for a mixture of
\emph{objective} goods and chores. To our knowledge, this negative result
provides the \emph{first} counterexample for EFX over (any subdomain of)
additive valuations. To complement this non-existence result, we identify a
class of instances with (possibly subjective) mixed items where an EFX and
Pareto optimal allocation always exists and can be efficiently computed. When
the fairness requirement is relaxed to \emph{maximin share} (MMS), we show
positive existence and computation for \emph{any} mixed instance. More broadly,
our work examines the existence and computation of fair and efficient
allocations both for mixed items as well as chores-only instances, and
highlights the additional difficulty of these problems vis-{\`a}-vis their
goods-only counterparts.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:54:09 GMT""}]","2022-03-15"
"2203.07280","Hao-Tsung Yang","Peyman Afshani, Mark de Berg, Kevin Buchin, Jie Gao, Maarten Loffler,
  Amir Nayyeri, Benjamin Raichel, Rik Sarkar, Haotian Wang, Hao-Tsung Yang","On Cyclic Solutions to the Min-Max Latency Multi-Robot Patrolling
  Problem","This paper is accepted in the 38th International Symposium on
  Computational Geometry (SoCG 2022)",,,,"cs.CG cs.AI","http://creativecommons.org/licenses/by/4.0/","  We consider the following surveillance problem: Given a set $P$ of $n$ sites
in a metric space and a set of $k$ robots with the same maximum speed, compute
a patrol schedule of minimum latency for the robots. Here a patrol schedule
specifies for each robot an infinite sequence of sites to visit (in the given
order) and the latency $L$ of a schedule is the maximum latency of any site,
where the latency of a site $s$ is the supremum of the lengths of the time
intervals between consecutive visits to $s$. When $k=1$ the problem is
equivalent to the travelling salesman problem (TSP) and thus it is NP-hard. We
have two main results. We consider cyclic solutions in which the set of sites
must be partitioned into $\ell$ groups, for some~$\ell \leq k$, and each group
is assigned a subset of the robots that move along the travelling salesman tour
of the group at equal distance from each other. Our first main result is that
approximating the optimal latency of the class of cyclic solutions can be
reduced to approximating the optimal travelling salesman tour on some input,
with only a $1+\varepsilon$ factor loss in the approximation factor and an
$O\left(\left( k/\varepsilon \right)^k\right)$ factor loss in the runtime, for
any $\varepsilon >0$. Our second main result shows that an optimal cyclic
solution is a $2(1-1/k)$-approximation of the overall optimal solution. Note
that for $k=2$ this implies that an optimal cyclic solution is optimal overall.
The results have a number of consequences. For the Euclidean version of the
problem, for instance, combining our results with known results on Euclidean
TSP, yields a PTAS for approximating an optimal cyclic solution, and it yields
a $(2(1-1/k)+\varepsilon)$-approximation of the optimal unrestricted solution.
If the conjecture mentioned above is true, then our algorithm is actually a
PTAS for the general problem in the Euclidean setting.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:54:33 GMT""}]","2022-03-15"
"2203.07281","Archiki Prasad","Archiki Prasad, Peter Hase, Xiang Zhou, Mohit Bansal","GrIPS: Gradient-free, Edit-based Instruction Search for Prompting Large
  Language Models","EACL 2023 (20 pages)",,,,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Providing natural language instructions in prompts is a useful new paradigm
for improving task performance of large language models in a zero-shot setting.
Recent work has aimed to improve such prompts via manual rewriting or
gradient-based tuning. However, manual rewriting is time-consuming and requires
subjective interpretation, while gradient-based tuning can be extremely
computationally demanding for large models and may not be feasible for
API-based models. In this work, we introduce Gradient-free Instructional Prompt
Search (GrIPS), a gradient-free, edit-based search approach for improving task
instructions for large language models. GrIPS takes in instructions designed
for humans and automatically returns an improved, edited prompt, while allowing
for API-based tuning. With InstructGPT models, GrIPS improves the average task
performance by up to 4.30 percentage points on eight classification tasks from
the Natural Instructions dataset (with similar improvements for OPT, BLOOM, and
FLAN-T5). We see improvements for both instruction-only prompts and instruction
+ k-shot examples prompts. Notably, GrIPS outperforms manual rewriting and
purely example-based prompts while controlling for the available compute and
data budget. Further, performance of GrIPS is comparable to select
gradient-based tuning approaches. Qualitatively, we show our edits can simplify
instructions and at times make them incoherent but nonetheless improve
accuracy. Our code is available at: https://github.com/archiki/GrIPS
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:54:46 GMT""},{""version"":""v2"",""created"":""Wed, 26 Apr 2023 19:20:57 GMT""}]","2023-04-28"
"2203.07282","Santiago Camara","Santiago Camara","Granular Linkages, Supplier Cost Shocks & Export Performance",,,,,"econ.GN q-fin.EC","http://creativecommons.org/publicdomain/zero/1.0/","  This paper presents evidence on the granular nature of firms' network of
foreign suppliers and studies its implications for the impact of supplier
shocks on domestic firms' performance. To demonstrate this, I use customs level
information on transactions between Argentinean firms and foreign firms. I
highlight two novel stylized facts: (i) the distribution of domestic firms'
number of foreign suppliers is highly skewed with the median firm reporting
linkages with only two, (ii) firms focus imported value on one top-supplier,
even when controlling for firm size. Motivated by these facts I construct a
theoretical framework of heterogeneous firms subject to search frictions in the
market for foreign suppliers. Through a calibration exercise I study the
framework's predictions and test them in the data using a shift-share
identification strategy. Results present evidence of significant frictions in
the market for foreign suppliers and strong import-export complementarities.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:55:16 GMT""}]","2022-03-15"
"2203.07283","Raven Beutner","Raven Beutner, Bernd Finkbeiner","HyperATL*: A Logic for Hyperproperties in Multi-Agent Systems",,,,,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  Hyperproperties are system properties that relate multiple computation paths
in a system and are commonly used to, e.g., define information-flow policies.
In this paper, we study a novel class of hyperproperties that allow reasoning
about strategic abilities in multi-agent systems. We introduce HyperATL*, an
extension of computation tree logic with path variables and strategy
quantifiers. Our logic supports quantification over paths in a system - as is
possible in hyperlogics such as HyperCTL* - but resolves the paths based on the
strategic choices of a coalition of agents. This allows us to capture many
previously studied (strategic) security notions in a unifying hyperlogic.
Moreover, we show that HyperATL* is particularly useful for specifying
asynchronous hyperproperties, i.e., hyperproperties where the execution speed
on the different computation paths depends on the choices of a scheduler. We
show that finite-state model checking of HyperATL* is decidable and present a
model checking algorithm based on alternating automata. We establish that our
algorithm is asymptotically optimal by proving matching lower bounds. We have
implemented a prototype model checker for a fragment of HyperATL* that can
check various security properties in small finite-state systems.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:55:17 GMT""},{""version"":""v2"",""created"":""Mon, 28 Nov 2022 08:48:39 GMT""},{""version"":""v3"",""created"":""Tue, 2 May 2023 09:32:54 GMT""},{""version"":""v4"",""created"":""Tue, 30 May 2023 11:04:48 GMT""}]","2023-05-31"
"2203.07284","Wolfgang Gatterbauer","Wolfgang Gatterbauer, Cody Dunne, Mirek Riedewald","Relational Diagrams: a pattern-preserving diagrammatic representation of
  non-disjunctive Relational Queries","23 pages, 29 figures",,,,"cs.DB cs.LO cs.PL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Analyzing relational languages by their logical expressiveness is well
understood. Something not well understood or even formalized is the vague
concept of relational query patterns. What are query patterns? And how can we
reason about query patterns across different relational languages, irrespective
of their syntax and their procedural or declarative nature? In this paper, we
formalize the concept of query patterns with a variant of pattern-preserving
mappings between the relational atoms of queries. This formalism allows us to
analyze the relative pattern expressiveness of relational query languages and
to create a hierarchy of languages with equal logical expressiveness yet
different pattern expressiveness. In this analysis, relational calculus can
expressive more patterns than the basic operators of relational algebra. We
additionally contribute an intuitive, complete, and sound diagrammatic
representation of safe relational calculus that is not only relationally
complete, but can also express all logical patterns for the large and useful
fragment of non-disjunctive relational calculus. Among all diagrammatic
representations for relational queries that we are aware of, this is the only
one that is relationally complete and that can represent all logical patterns
in the non-disjunctive fragment.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:55:20 GMT""}]","2022-03-15"
"2203.07285","Wenhao Yu","Wenhao Yu, Chenguang Zhu, Lianhui Qin, Zhihan Zhang, Tong Zhao, Meng
  Jiang","Diversifying Content Generation for Commonsense Reasoning with Mixture
  of Knowledge Graph Experts","ACL 2022 (Findings); Code is at https://github.com/DM2-ND/MoKGE",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Generative commonsense reasoning (GCR) in natural language is to reason about
the commonsense while generating coherent text. Recent years have seen a surge
of interest in improving the generation quality of commonsense reasoning tasks.
Nevertheless, these approaches have seldom investigated diversity in the GCR
tasks, which aims to generate alternative explanations for a real-world
situation or predict all possible outcomes. Diversifying GCR is challenging as
it expects to generate multiple outputs that are not only semantically
different but also grounded in commonsense knowledge. In this paper, we propose
MoKGE, a novel method that diversifies the generative reasoning by a mixture of
expert (MoE) strategy on commonsense knowledge graphs (KG). A set of knowledge
experts seek diverse reasoning on KG to encourage various generation outputs.
Empirical experiments demonstrated that MoKGE can significantly improve the
diversity while achieving on par performance on accuracy on two GCR benchmarks,
based on both automatic and human evaluations.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:57:50 GMT""}]","2022-03-15"
"2203.07286","Sergei Chekanov V.","S. V. Chekanov, F.Simon, V. Boudry, W. Chung, P. W. Gorham, M. Nguyen,
  C.G. Tully, S.C. Eno, Y. Lai, A.V. Kotwal, S. Ko, I. Laktineh, S. Lee, J.S.H.
  Lee, M. T. Lucchini, R. Prechelt, H. Yoo, C. -H Yeh, S. -S. Yu, G. S. Varner,
  R. Zhu","Precision timing for collider-experiment-based calorimetry","22 pages, 9 figures, Editors: S. V. Chekanov, F. Simon. Submitted to
  the Proceedings of the US Community Study on the Future of Particle Physics
  (Snowmass 2021)",,,"ANL-HEP-173859, MPP-2022-28","physics.ins-det hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this White Paper for the 2021 Snowmass process, we discuss aspects of
precision timing within electromagnetic and hadronic calorimeter systems for
high-energy physics collider experiments. Areas of applications include
particle identification, event and object reconstruction, and pileup
mitigation. Two different system options are considered, namely cell-level
timing capabilities covering the full detector volume, and dedicated timing
layers integrated in calorimeter systems. A selection of technologies for the
different approaches is also discussed.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:57:56 GMT""}]","2022-03-15"
"2203.07287","Peter Lewis","Andreas L\""oschcke Centeno, Christian Wessel, Peter M. Lewis, Oskar
  Hartbrich, Jochen Kaminski, Carlos Mari\~nas, and Sven Vahsen","A TPC-based tracking system for a future Belle II upgrade","Contribution to Snowmass 2021",,,,"physics.ins-det hep-ex","http://creativecommons.org/licenses/by/4.0/","  In the next decade, intensity frontier experiments will require tracking
systems that are robust against high event and background rates while
maintaining excellent tracking performance. We develop a first conceptual
design of a tracking system for a hypothetical future experiment--here imagined
as a successor to Belle II--built around a time projection chamber (TPC) with
high resolution readout. This choice necessitates a significant expansion of
the silicon vertex detector as well as a new fast timing layer. We simulate the
performance of such a system in the Belle II simulation framework, probe its
major technical challenges, and demonstrate that such a system is suitable for
projected luminosities at the next generation of intensity-frontier colliders.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:57:59 GMT""}]","2022-03-15"
"2203.07288","Daniel Walo Mart\'in","Daniel Walo-Mart\'in, Francesca Pinna, Robert J.J. Grand, Isabel
  P\'erez, Jes\'us Falc\'on-Barroso, Francesca Fragkoudi, Marie Martig","Local variations of the Stellar Velocity Ellipsoid-II: the effect of the
  bar in the inner regions of Auriga galaxies","13 pages, 6 Figures. Accepted for publications in MNRAS",,"10.1093/mnras/stac769",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Theoretical works have shown that off-plane motions of bars can heat stars in
the vertical direction during buckling but is not clear how do they affect the
rest of components of the Stellar Velocity Ellipsoid (SVE). We study the 2D
spatial distribution of the vertical, $\sigma_{z}$, azimuthal, $\sigma_{\phi}$
and radial, $\sigma_{r}$ velocity dispersions in the inner regions of Auriga
galaxies, a set of high-resolution magneto-hydrodynamical cosmological zoom-in
simulations, to unveil the influence of the bar on the stellar kinematics.
$\sigma_{z}$ and $\sigma_{\phi}$ maps exhibit non-axisymmetric features that
closely match the bar light distribution with low $\sigma$ regions along the
bar major axis and high values in the perpendicular direction. On the other
hand, $\sigma_{r}$ velocity dispersion maps present more axisymmetric
distributions. We show that isophotal profile differences best capture the
impact of the bar on the three SVE components providing strong correlations
with bar morphology proxies although there is no relation with individual
$\sigma$. Time evolution analysis shows that these differences are a
consequence of the bar formation and that they tightly coevolve with the
strength of the bar. We discuss the presence of different behaviours of
$\sigma_{z}$ and its connection with observations. This work helps us
understand the intrinsic $\sigma$ distribution and motivates the use of
isophotal profiles as a mean to quantify the effect of bars.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:58:16 GMT""}]","2022-03-30"
"2203.07289","Yu Liu","Jie Sheng, Yue-Chao Wang, Yu Liu, Shuai Wu, Ke Xu, Zi-Hang Chen, Bo
  Sun, Hai-Feng Liu, and Hai-Feng Song","A Phase-field model for simulating hydrogen-induced pitting corrosion
  with solid-solid phase transformation in the metal","11 pages (text), 8 figures (text), 1 table (text), 5 pages (SI), 5
  figures (SI) and 1 table (SI)","Comp. Mater. Sci. 213 (2022) 111663","10.1016/j.commatsci.2022.111663",,"cond-mat.mtrl-sci physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hydrogen-induced pitting corrosion of metallic is a common phenomenon that
damages the integrity and durability of the materials. Its numerical simulation
is still a challenge due to many complex mechanisms, especially solid-solid
phase transformation and mechanical interaction, leading to the anisotropic
growth of hydride and inducing some bulges on the metal surface. In our work,
we propose a phase-field model and numerical technique for simulation of
hydrogen-induced pitting corrosion, and apply it to the system of
$\alpha$-Uranium. In our model, the elastic strain energy is introduced to
approximate the anisotropic pit morphology induced by the mechanical
interaction between metal and hydride. For the numerical technique, the free
boundary condition based on the finite element method is adopted to introduce
the bulges of the metal surface. By the application of our model and numerical
technique, the anisotropic pit morphology with a bulge on the metal surface in
agreement with experiments of $\alpha$-Uranium is obtained. Moreover, the
compression of $\alpha$-Uranium and the dilation of its hydride are discovered,
which develops the deep understanding of hydrogen-induced pitting corrosion.
This model is expected to be applied to the health detection of
hydrogen-induced pitting corrosion of metal in the industry.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 16:59:04 GMT""},{""version"":""v2"",""created"":""Mon, 28 Mar 2022 07:24:31 GMT""}]","2022-12-06"
"2203.07290","Kanishka Ganguly","Kanishka Ganguly, Pavan Mantripragada, Chethan M. Parameshwara,
  Cornelia Ferm\""uller, Nitin J. Sanket, Yiannis Aloimonos","GradTac: Spatio-Temporal Gradient Based Tactile Sensing","12 pages, 12 figures, 1 table Submitted to Frontiers in Robotics and
  AI under Multisensory Perception and Learning towards Dexterous Robot
  Manipulation and Interaction",,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  Tactile sensing for robotics is achieved through a variety of mechanisms,
including magnetic, optical-tactile, and conductive fluid. Currently, the
fluid-based sensors have struck the right balance of anthropomorphic sizes and
shapes and accuracy of tactile response measurement. However, this design is
plagued by a low Signal to Noise Ratio (SNR) due to the fluid based sensing
mechanism ""damping"" the measurement values that are hard to model. To this end,
we present a spatio-temporal gradient representation on the data obtained from
fluid-based tactile sensors, which is inspired from neuromorphic principles of
event based sensing. We present a novel algorithm (GradTac) that converts
discrete data points from spatial tactile sensors into spatio-temporal surfaces
and tracks tactile contours across these surfaces. Processing the tactile data
using the proposed spatio-temporal domain is robust, makes it less susceptible
to the inherent noise from the fluid based sensors, and allows accurate
tracking of regions of touch as compared to using the raw data. We successfully
evaluate and demonstrate the efficacy of GradTac on many real-world experiments
performed using the Shadow Dexterous Hand, equipped with the BioTac SP sensors.
Specifically, we use it for tracking tactile input across the sensor's surface,
measuring relative forces, detecting linear and rotational slip, and for edge
tracking. We also release an accompanying task-agnostic dataset for the BioTac
SP, which we hope will provide a resource to compare and quantify various novel
approaches, and motivate further research.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:00:11 GMT""}]","2022-03-15"
"2203.07291","Kyle Dawson","Kyle Dawson, Andrew Hearin, Katrin Heitmann, Mustapha Ishak, Johannes
  Ulf Lange, Martin White, and Rongpu Zhou","Snowmass2021 Cosmic Frontier White Paper: High Density Galaxy Clustering
  in the Regime of Cosmic Acceleration","Contribution to Snowmass 2022, CF04: Dark energy and cosmic
  acceleration: the modern universe",,,,"astro-ph.CO hep-ex","http://creativecommons.org/licenses/by/4.0/","  Joint studies of imaging and spectroscopic samples, informed by theory and
simulations, offer the potential for comprehensive tests of the cosmological
model over redshifts z<1.5. Spectroscopic galaxy samples at these redshifts can
be increased beyond the planned Dark Energy Spectroscopic Instrument (DESI)
program by at least an order of magnitude, thus offering significantly more
constraining power for these joint studies. Spectroscopic observations of these
galaxies in the latter half of the 2020's and beyond would leverage the theory
and simulation effort in this regime. In turn, these high density observations
will allow enhanced tests of dark energy, physics beyond the standard model,
and neutrino masses that will greatly exceed what is currently possible. Here,
we present a coordinated program of simulations, theoretical modeling, and
future spectroscopy that would enable precise cosmological studies in the
accelerating epoch where the effects of dark energy are most apparent.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:00:44 GMT""}]","2022-03-15"
"2203.07292","Tom\'a\v{s} Bzdu\v{s}ek","David M. Urwyler, Patrick M. Lenggenhager, Igor Boettcher, Ronny
  Thomale, Titus Neupert, Tom\'a\v{s} Bzdu\v{s}ek","Hyperbolic Topological Band Insulators","main text (4 pages incl. 5 figures and 1 table) + references +
  supplementary material (24 pages incl. 13 figures and 2 tables)","Phys. Rev. Lett. 129, 246402 (2022)","10.1103/PhysRevLett.129.246402",,"cond-mat.mes-hall cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, hyperbolic lattices that tile the negatively curved hyperbolic
plane emerged as a new paradigm of synthetic matter, and their energy levels
were characterized by a band structure in a four- (or higher-)dimensional
momentum space. To explore the uncharted topological aspects arising in
hyperbolic band theory, we here introduce elementary models of hyperbolic
topological band insulators: the hyperbolic Haldane model and the hyperbolic
Kane-Mele model; both obtained by replacing the hexagonal cells of their
Euclidean counterparts by octagons. Their non-trivial topology is revealed by
computing topological invariants in both position and momentum space. The
bulk-boundary correspondence is evidenced by comparing bulk and boundary
density of states, by modelling propagation of edge excitations, and by their
robustness against disorder.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:01:33 GMT""},{""version"":""v2"",""created"":""Sun, 8 Jan 2023 20:38:38 GMT""}]","2023-01-10"
"2203.07293","Anna Fr\""uhst\""uck","Anna Fr\""uhst\""uck and Krishna Kumar Singh and Eli Shechtman and Niloy
  J. Mitra and Peter Wonka and Jingwan Lu","InsetGAN for Full-Body Image Generation","Project webpage and video available at
  http://afruehstueck.github.io/insetgan",,,,"cs.CV cs.GR cs.LG","http://creativecommons.org/licenses/by/4.0/","  While GANs can produce photo-realistic images in ideal conditions for certain
domains, the generation of full-body human images remains difficult due to the
diversity of identities, hairstyles, clothing, and the variance in pose.
Instead of modeling this complex domain with a single GAN, we propose a novel
method to combine multiple pretrained GANs, where one GAN generates a global
canvas (e.g., human body) and a set of specialized GANs, or insets, focus on
different parts (e.g., faces, shoes) that can be seamlessly inserted onto the
global canvas. We model the problem as jointly exploring the respective latent
spaces such that the generated images can be combined, by inserting the parts
from the specialized generators onto the global canvas, without introducing
seams. We demonstrate the setup by combining a full body GAN with a dedicated
high-quality face GAN to produce plausible-looking humans. We evaluate our
results with quantitative metrics and user studies.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:01:46 GMT""}]","2022-03-15"
"2203.07294","Silvia Leanza","S. Leanza, C. Pallanca, F. R. Ferraro, B. Lanzoni, E. Dalessandro, L.
  Origlia, A. Mucciarelli, E. Valenti, M. Tiongco, A. L. Varri, E. Vesperini","The ESO-VLT MIKiS survey reloaded: velocity dispersion profile and
  rotation curve of NGC 1904","30 pages, 20 figures, 8 tables, accepted for publication in ApJ",,"10.3847/1538-4357/ac5d4e",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an investigation of the internal kinematic properties of M79 (NGC
1904). Our study is based on radial velocity measurements obtained from the
ESO-VLT Multi-Instrument Kinematic Survey (MIKiS) of Galactic globular clusters
for more than 1700 individual stars distributed between $\sim
0.3^{\prime\prime}$ and $770^{\prime\prime}$ ($\sim14$ three-dimensional
half-mass radii), from the center. Our analysis reveals the presence of ordered
line-of-sight rotation with a rotation axis almost aligned along the East-West
direction and a velocity peak of $1.5$ km s$^{-1}$ at $\sim 70^{\prime\prime}$
from the rotation axis. The velocity dispersion profile is well described by
the same King model that best fits the projected density distribution, with a
constant central plateau at $\sigma_0\sim 6$ km s$^{-1}$. To investigate the
cluster rotation in the plane of the sky, we have analyzed the proper motions
provided by the Gaia EDR3, finding a signature of rotation with a maximum
amplitude of $\sim 2.0$ km s$^{-1}$ at $\sim 80^{\prime\prime}$ from the
cluster center. Analyzing the three-dimensional velocity distribution, for a
sub-sample of 130 stars, we confirm the presence of systemic rotation and find
a rotation axis inclination angle of $37${\deg} with respect to the
line-of-sight. As a final result, the comparison of the observed rotation
curves with the results of a representative N-body simulation of a rotating
star cluster shows that the present-day kinematic properties of NGC 1904 are
consistent with those of a dynamically old system that has lost a significant
fraction of its initial angular momentum.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:03:12 GMT""}]","2022-05-11"
"2203.07295","Tasio Gonzalez-Raya","Tasio Gonzalez-Raya, Mateo Casariego, Florian Fesquet, Michael Renger,
  Vahid Salari, Mikko M\""ott\""onen, Yasser Omar, Frank Deppe, Kirill G.
  Fedorov, Mikel Sanz","Open-Air Microwave Entanglement Distribution for Quantum Teleportation",,"Phys. Rev. Applied 18, 044002 (2022)","10.1103/PhysRevApplied.18.044002",,"quant-ph cond-mat.mes-hall cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Microwave technology plays a central role in current wireless communications,
standing among them mobile communication and local area networks (LANs). The
microwave range shows relevant advantages with respect to other frequencies in
open-air transmission, such as low absorption losses and low energy
consumption, and it is additionally the natural working frequency in
superconducting quantum technologies. Entanglement distribution between
separate parties is at the core of secure quantum communications. Therefore,
understanding its limitations in realistic open-air settings, specially in the
rather unexplored microwave regime, is crucial for transforming microwave
quantum communications into a mainstream technology. Here, we investigate the
feasibility of an open-air entanglement distribution scheme with microwave
two-mode squeezed states. First, we study the reach of direct entanglement
transmission in open-air, obtaining a maximum distance of approximately 500
meters in a realistic setting with state-of-the-art experimental parameters.
Afterwards, we adapt entanglement distillation and entanglement swapping
protocols to microwave technology in order to reduce environmental entanglement
degradation. While entanglement distillation helps to increase quantum
correlations in the short-distance low-squeezing regime by up to $46\%$,
entanglement swapping increases the reach by $14\%$. Then, we compute the
fidelity of a continuous-variable quantum teleportation protocol using
open-air-distributed entanglement as a resource. Finally, we adapt the
machinery to explore the limitations of quantum communication between
satellites, where the thermal noise impact is substantially reduced and
diffraction losses are dominant.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:03:46 GMT""}]","2022-12-20"
"2203.07296","Nico Michele Schiavone","Luca Fanelli, Luz Roncal, Nico Michele Schiavone","Non self-adjoint perturbations of the Heisenberg sublaplacian","22 pages",,,,"math.SP math.AP","http://creativecommons.org/licenses/by/4.0/","  We prove uniform resolvent estimates in weighted $L^2$-spaces for the
sublaplacian $\mathcal{L}$ on the Heisenberg group $\mathbb{H}^d$. The proof
are based on multiplier methods, and strongly rely on the use of horizontal
multipliers and the associated Hardy inequalities. The constants of our
inequalities are explicit and depend only on the dimension $d$. As applications
of this method, we obtain some suitable smallness and repulsivity conditions on
a complex potential $V$ on $\mathbb{H}^d$ such that the spectrum of
$\mathcal{L}+V$ does not contain eigenvalues.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:05:00 GMT""}]","2022-03-15"
"2203.07297","Benedikt Stufler","Benedikt Stufler","First-passage percolation on random simple triangulations",,,,,"math.PR math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study first-passage percolation on random simple triangulations and their
dual maps with independent identically distributed link weights. Our main
result shows that the first-passage percolation distance concentrates in an
$o_p(n^{1/4})$ window around a constant multiple of the graph distance.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:05:09 GMT""}]","2022-03-15"
"2203.07298","Bogeun Gwak","Bogeun Gwak, Naoto Kan, Bum-Hoon Lee, Hocheol Lee","Violation of bound on chaos for charged probe in Kerr-Newman-AdS black
  hole","22 pages, 42 figures","JHEP 09 (2022) 026","10.1007/JHEP09(2022)026",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the conjectured bound on the Lyapunov exponent for a charged
particle with angular motion in the Kerr-Newman-AdS black hole. The Lyapunov
exponent is calculated based on the effective Lagrangian. We show that the
negative cosmological constant reduces the chaotic behavior of the particle,
namely, it decreases the Lyapunov exponent. Hence, the bound is more effective
in the AdS spacetime than in the flat spacetime. Nevertheless, we find that the
bound can be violated when the angular momenta of the black hole are turned on.
Moreover, we show that in an extremal black hole, the bound is more easily
violated compared to the nonextremal black hole.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:05:11 GMT""}]","2022-09-12"
"2203.07299","Jan Lang","Jan Lang and Ale\v{s} Nekvinda","Embedding between Lebesgue and weak Lebesgue sequence spaces is strictly
  singular","10 pages",,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  Given $1< p < q < \infty$ it is well know that the natural embedding of
Lebesgue sequence spaces $\ell_p \hookrightarrow \ell_q$ is strictly singular.
In this paper we extend this classical results and show that even the natural
non-compact embedding between Lebesgue and weak Lebesgue sequence spaces
$\ell_{p}\hookrightarrow \ell_{p,\infty}$ is strictly singular.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:05:50 GMT""}]","2022-03-15"
"2203.07300","Giuseppe Stragapede","Giuseppe Stragapede, Ruben Vera-Rodriguez, Ruben Tolosana, Aythami
  Morales, Alejandro Acien, Gael Le Lan","Mobile Behavioral Biometrics for Passive Authentication",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Current mobile user authentication systems based on PIN codes, fingerprint,
and face recognition have several shortcomings. Such limitations have been
addressed in the literature by exploring the feasibility of passive
authentication on mobile devices through behavioral biometrics. In this line of
research, this work carries out a comparative analysis of unimodal and
multimodal behavioral biometric traits acquired while the subjects perform
different activities on the phone such as typing, scrolling, drawing a number,
and tapping on the screen, considering the touchscreen and the simultaneous
background sensor data (accelerometer, gravity sensor, gyroscope, linear
accelerometer, and magnetometer). Our experiments are performed over HuMIdb,
one of the largest and most comprehensive freely available mobile user
interaction databases to date. A separate Recurrent Neural Network (RNN) with
triplet loss is implemented for each single modality. Then, the weighted fusion
of the different modalities is carried out at score level. In our experiments,
the most discriminative background sensor is the magnetometer, whereas among
touch tasks the best results are achieved with keystroke in a fixed-text
scenario. In all cases, the fusion of modalities is very beneficial, leading to
Equal Error Rates (EER) ranging from 4% to 9% depending on the modality
combination in a 3-second interval.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:05:59 GMT""}]","2022-03-15"
"2203.07301","Fahhad Alharbi","Mohammed Alghadeer and Eid Aldawsari and Raja Selvarajan and Khaled
  Alutaibi and Sabre Kais and Fahhad H Alharbi","Psitrum: An Open Source Simulator for Universal Quantum Computers","28 pages, 11 figures, 2 tables",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum computing is a radical new paradigm for a technology that is capable
to revolutionize information processing. Simulators of universal quantum
computer are important for understanding the basic principles and operations of
the current noisy intermediate-scale quantum (NISQ) processors, and for
building in future fault-tolerant quantum computers. In this work, we present
simulation of universal quantum computers by introducing Psitrum -- a universal
gate-model quantum computer simulator implemented on classical hardware. The
simulator allows to emulate and debug quantum algorithms in form of quantum
circuits for many applications with the choice of adding variety of noise
modules to simulate decoherence in quantum circuits. Psitrum allows to simulate
all basic quantum operations and provides variety of visualization tools. The
simulator allows to trace out all possible quantum states at each stage M of an
N-qubit implemented quantum circuit. Psitrum software and source codes are
freely available at: (github.com/moghadeer/Psitrum).
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:06:06 GMT""},{""version"":""v2"",""created"":""Tue, 24 May 2022 20:40:55 GMT""},{""version"":""v3"",""created"":""Fri, 24 Feb 2023 15:39:11 GMT""}]","2023-02-27"
"2203.07302","Valerio Biscione","Valerio Biscione, Jeffrey S. Bowers","Mixed Evidence for Gestalt Grouping in Deep Neural Networks","Accepted in Computational Brain & Behaviour",,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  Gestalt psychologists have identified a range of conditions in which humans
organize elements of a scene into a group or whole, and perceptual grouping
principles play an essential role in scene perception and object
identification. Recently, Deep Neural Networks (DNNs) trained on natural images
(ImageNet) have been proposed as compelling models of human vision based on
reports that they perform well on various brain and behavioral benchmarks. Here
we test a total of 16 networks covering a variety of architectures and learning
paradigms (convolutional, attention-based, supervised and self-supervised,
feed-forward and recurrent) on dots (Experiment 1) and more complex shapes
(Experiment 2) stimuli that produce strong Gestalts effects in humans. In
Experiment 1 we found that convolutional networks were indeed sensitive in a
human-like fashion to the principles of proximity, linearity, and orientation,
but only at the output layer. In Experiment 2, we found that most networks
exhibited Gestalt effects only for a few sets, and again only at the latest
stage of processing. Overall, self-supervised and Vision-Transformer appeared
to perform worse than convolutional networks in terms of human similarity.
Remarkably, no model presented a grouping effect at the early or intermediate
stages of processing. This is at odds with the widespread assumption that
Gestalts occur prior to object recognition, and indeed, serve to organize the
visual scene for the sake of object recognition. Our overall conclusion is
that, albeit noteworthy that networks trained on simple 2D images support a
form of Gestalt grouping for some stimuli at the output layer, this ability
does not seem to transfer to more complex features. Additionally, the fact that
this grouping only occurs at the last layer suggests that networks learn
fundamentally different perceptual properties than humans.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:06:11 GMT""},{""version"":""v2"",""created"":""Wed, 6 Apr 2022 07:38:50 GMT""},{""version"":""v3"",""created"":""Mon, 20 Feb 2023 10:57:46 GMT""}]","2023-02-21"
"2203.07303","Jinpeng Wang","Alex Jinpeng Wang, Yixiao Ge, Rui Yan, Yuying Ge, Xudong Lin, Guanyu
  Cai, Jianping Wu, Ying Shan, Xiaohu Qie, Mike Zheng Shou","All in One: Exploring Unified Video-Language Pre-training","18 pages. 11 figures. Code: https://github.com/showlab/all-in-one",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mainstream Video-Language Pre-training models \cite{actbert,clipbert,violet}
consist of three parts, a video encoder, a text encoder, and a video-text
fusion Transformer. They pursue better performance via utilizing heavier
unimodal encoders or multimodal fusion Transformers, resulting in increased
parameters with lower efficiency in downstream tasks. In this work, we for the
first time introduce an end-to-end video-language model, namely
\textit{all-in-one Transformer}, that embeds raw video and textual signals into
joint representations using a unified backbone architecture. We argue that the
unique temporal information of video data turns out to be a key barrier
hindering the design of a modality-agnostic Transformer. To overcome the
challenge, we introduce a novel and effective token rolling operation to encode
temporal representations from video clips in a non-parametric manner. The
careful design enables the representation learning of both video-text
multimodal inputs and unimodal inputs using a unified backbone model. Our
pre-trained all-in-one Transformer is transferred to various downstream
video-text tasks after fine-tuning, including text-video retrieval,
video-question answering, multiple choice and visual commonsense reasoning.
State-of-the-art performances with the minimal model FLOPs on nine datasets
demonstrate the superiority of our method compared to the competitive
counterparts. The code and pretrained model have been released in
https://github.com/showlab/all-in-one.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:06:30 GMT""}]","2022-03-15"
"2203.07304","Dario Mazzoleni","Dario Mazzoleni, Giuseppe Savar\'e","$L^2$-Gradient Flows of Spectral Functionals",,,,,"math.AP math.FA math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the $L^2$-gradient flow of functionals $\mathcal F$ depending on the
eigenvalues of Schr\""odinger potentials $V$ for a wide class of differential
operators associated to closed, symmetric, and coercive bilinear forms,
including the case of all the Dirichlet forms (as for second order elliptic
operators in Euclidean domains or Riemannian manifolds).
  We suppose that $\mathcal F$ arises as the sum of a $-\theta$-convex
functional $\mathcal K$ with proper domain $\mathbb{K}\subset L^2$ forcing the
admissible potentials to stay above a constant $V_{\rm min}$ and a term
$\mathcal H(V)=\varphi(\lambda_1(V),\cdots,\lambda_J(V))$ which depends on the
first $J$ eigenvalues associated to $V$ through a $C^1$ function $\varphi$.
  Even if $\mathcal H$ is not a smooth perturbation of a convex functional (and
it is in fact concave in simple important cases as the sum of the first $J$
eigenvalues) and we do not assume any compactness of the sublevels of $\mathcal
K$, we prove the convergence of the Minimizing Movement method to a solution
$V\in H^1(0,T;L^2)$ of the differential inclusion $V'(t)\in
-\partial_L^-\mathcal F(V(t))$, which under suitable compatibility conditions
on $\varphi$ can be written as \[
V'(t)+\sum_{i=1}^J\partial_i\varphi(\lambda_1(V(t)),\dots,
\lambda_J(V(t)))u_i^2(t)\in -\partial_F^-\mathcal K(V(t)) \] where
$(u_1(t),\dots, u_J(t))$ is an orthonormal system of eigenfunctions associated
to the eigenvalues $(\lambda_1(V(t)), ,\dots,\lambda_J(V(t)))$.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:06:46 GMT""},{""version"":""v2"",""created"":""Fri, 12 Aug 2022 06:25:21 GMT""}]","2022-08-15"
"2203.07305","Shuvomoy Das Gupta","Shuvomoy Das Gupta, Bart P. G. Van Parys, Ernest K. Ryu","Branch-and-Bound Performance Estimation Programming: A Unified
  Methodology for Constructing Optimal Optimization Methods","Published in Mathematical Programming Series A",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the Branch-and-Bound Performance Estimation Programming (BnB-PEP),
a unified methodology for constructing optimal first-order methods for convex
and nonconvex optimization. BnB-PEP poses the problem of finding the optimal
optimization method as a nonconvex but practically tractable quadratically
constrained quadratic optimization problem and solves it to certifiable global
optimality using a customized branch-and-bound algorithm. By directly
confronting the nonconvexity, BnB-PEP offers significantly more flexibility and
removes the many limitations of the prior methodologies. Our customized
branch-and-bound algorithm, through exploiting specific problem structures,
outperforms the latest off-the-shelf implementations by orders of magnitude,
accelerating the solution time from hours to seconds and weeks to minutes. We
apply BnB-PEP to several setups for which the prior methodologies do not apply
and obtain methods with bounds that improve upon prior state-of-the-art
results. Finally, we use the BnB-PEP methodology to find proofs with potential
function structures, thereby systematically generating analytical convergence
proofs.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:07:26 GMT""},{""version"":""v2"",""created"":""Fri, 25 Mar 2022 20:25:21 GMT""},{""version"":""v3"",""created"":""Wed, 13 Apr 2022 09:09:33 GMT""},{""version"":""v4"",""created"":""Thu, 19 Jan 2023 15:10:38 GMT""},{""version"":""v5"",""created"":""Thu, 8 Jun 2023 14:22:25 GMT""}]","2023-06-09"
"2203.07306","Benedikt Stufler","Benedikt Stufler","The scaling limit of random cubic planar graphs",,,,,"math.PR math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the random simple connected cubic planar graph $\mathsf{C}_n$ with
an even number $n$ of vertices. We show that the Brownian map arises as
Gromov--Hausdorff--Prokhorov scaling limit of $\mathsf{C}_n$ as $n \in 2 \ndN$
tends to infinity, after rescaling distances by $\gamma n^{-1/4} $ for a
specific constant $\gamma>0$.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:09:31 GMT""}]","2022-03-15"
"2203.07307","Manuel Tran","Manuel Tran, Sophia J. Wagner, Melanie Boxberg, Tingying Peng","S5CL: Unifying Fully-Supervised, Self-Supervised, and Semi-Supervised
  Learning Through Hierarchical Contrastive Learning",,,,,"cs.CV stat.ML","http://creativecommons.org/licenses/by/4.0/","  In computational pathology, we often face a scarcity of annotations and a
large amount of unlabeled data. One method for dealing with this is
semi-supervised learning which is commonly split into a self-supervised pretext
task and a subsequent model fine-tuning. Here, we compress this two-stage
training into one by introducing S5CL, a unified framework for
fully-supervised, self-supervised, and semi-supervised learning. With three
contrastive losses defined for labeled, unlabeled, and pseudo-labeled images,
S5CL can learn feature representations that reflect the hierarchy of distance
relationships: similar images and augmentations are embedded the closest,
followed by different looking images of the same class, while images from
separate classes have the largest distance. Moreover, S5CL allows us to
flexibly combine these losses to adapt to different scenarios. Evaluations of
our framework on two public histopathological datasets show strong improvements
in the case of sparse labels: for a H&E-stained colorectal cancer dataset, the
accuracy increases by up to 9% compared to supervised cross-entropy loss; for a
highly imbalanced dataset of single white blood cells from leukemia patient
blood smears, the F1-score increases by up to 6%.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:10:01 GMT""}]","2022-03-15"
"2203.07308","Junqi Tang","Junqi Tang","Accelerating Plug-and-Play Image Reconstruction via Multi-Stage Sketched
  Gradients",,,,,"eess.IV cs.CV math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we propose a new paradigm for designing fast plug-and-play (PnP)
algorithms using dimensionality reduction techniques. Unlike existing
approaches which utilize stochastic gradient iterations for acceleration, we
propose novel multi-stage sketched gradient iterations which first perform
downsampling dimensionality reduction in the image space, and then efficiently
approximate the true gradient using the sketched gradient in the
low-dimensional space. This sketched gradient scheme can also be naturally
combined with PnP-SGD methods for further improvement on computational
complexity. As a generic acceleration scheme, it can be applied to accelerate
any existing PnP/RED algorithm. Our numerical experiments on X-ray fan-beam CT
demonstrate the remarkable effectiveness of our scheme, that a computational
free-lunch can be obtained using this dimensionality reduction in the image
space.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:12:09 GMT""}]","2022-03-15"
"2203.07309","Alireza Seif","Alireza Seif, Ze-Pei Cian, Sisi Zhou, Senrui Chen, Liang Jiang","Shadow Distillation: Quantum Error Mitigation with Classical Shadows for
  Near-Term Quantum Processors","16 pages, 9 figures",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mitigating errors in quantum information processing devices is especially
important in the absence of fault tolerance. An effective method in suppressing
state-preparation errors is using multiple copies to distill the ideal
component from a noisy quantum state. Here, we use classical shadows and
randomized measurements to circumvent the need for coherent access to multiple
copies at an exponential cost. We study the scaling of resources using
numerical simulations and find that the overhead is still favorable compared to
full state tomography. We optimize measurement resources under realistic
experimental constraints and apply our method to an experiment preparing
Greenberger-Horne-Zeilinger (GHZ) state with trapped ions. In addition to
improving stabilizer measurements, the analysis of the improved results reveals
the nature of errors affecting the experiment. Hence, our results provide a
directly applicable method for mitigating errors in near-term quantum
computers.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:14:56 GMT""}]","2022-03-15"
"2203.07310","Ousmane Ly","Ousmane Ly","Noncollinear antiferromagnetic textures driven high harmonic generation
  from magnetic dynamics in the absence of spin-orbit coupling",,,"10.1088/1361-648X/acb523",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate the generation of high order harmonics in carrier pumping from
precessing ferromagnetic or antiferromagnetic orders, excited via magnetic
resonance, in the presence of topological antiferromagnetic textures. This
results in an enhancement of the carrier dynamics by orders of magnitude.
Interestingly, the generation process occurs in an intrinsic manner, and is
solely governed by the interplay between the s-d exchange coupling underlying
the noncollinear antiferromagnetic order and the dynamical s-d exchange
parameter of the magnetic drive. Therefore, the relativistic spin-orbit
interaction is not required for the emergence of high harmonics in the pumped
currents. Accordingly, the noncollinear topological antiferromagnetic order is
presented as an alternative to spin-orbit interaction for the purpose of
harnessing high harmonic emission in carrier pumping. Our proposal initiates a
tantalizing perspective for the exploitation of topological magnetic textures
in the context of the highly active domain of ultrafast spintronics.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:15:38 GMT""},{""version"":""v2"",""created"":""Wed, 10 Aug 2022 18:10:55 GMT""}]","2023-02-15"
"2203.07311","Randall Kamien","Gareth P. Alexander and Randall D. Kamien","Entanglements and Whitehead Products: Generalizing Kleman's Construction
  to Higher-Dimensional Defects","7 pages, figures, the whole megillah",,,,"cond-mat.soft cond-mat.stat-mech math.GN","http://creativecommons.org/licenses/by/4.0/","  We review the interpretation of Whitehead products in homotopy theory as an
entanglement of topological defects in ordered media.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:17:11 GMT""}]","2022-03-15"
"2203.07312","Prajwal Niraula","Prajwal Niraula, Avi Shporer, Ian Wong, and Julien de Wit","Revisiting Kepler Transiting Systems: Unvetting Planets and Constraining
  Relationships among Harmonics in Phase Curves",,,"10.3847/1538-3881/ac4f64",,"astro-ph.EP astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Space-based photometric missions widely use statistical validation tools for
vetting transiting planetary candidates, particularly when other traditional
methods of planet confirmation are unviable. In this paper, we refute the
planetary nature of three previously validated planets -- Kepler-854~b,
Kepler-840~b, and Kepler-699~b -- and possibly a fourth, Kepler-747~b, using
updated stellar parameters from Gaia and phase-curve analysis. In all four
cases, the inferred physical radii rule out their planetary nature given the
stellar radiation the companions receive. For Kepler-854~b, the mass derived
from the host star's ellipsoidal variation, which had not been part of the
original vetting procedure, similarly points to a non-planetary value. To
contextualize our understanding of the phase curve for stellar mass companions
in particular and extend our understanding of high-order harmonics, we examine
Kepler eclipsing binaries with periods between 1.5 and 10 days. Using a sample
of 20 systems, we report a strong power-law relation between the second cosine
harmonic of the phase-curve signal and the higher cosine harmonics, which
supports the hypothesis that those signals arise from the tidal interaction
between the binary components. We find that the ratio between the second and
third-harmonic amplitudes is $2.24 \pm 0.48$, in good agreement with the
expected value of 2.4 from the classical formalism for the ellipsoidal
distortion.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:18:00 GMT""}]","2022-03-30"
"2203.07313","Ewain Gwynne","Ewain Gwynne and Joshua Pfeffer","Loewner evolution driven by complex Brownian motion (with simulations by
  Minjae Park)","49 pages, 12 figures; to appear in AOP",,,,"math.PR math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the Loewner evolution whose driving function is $W_t = B_t^1 + i
B_t^2$, where $(B^1,B^2)$ is a pair of Brownian motions with a given covariance
matrix. This model can be thought of as a generalization of Schramm-Loewner
evolution (SLE) with complex parameter values. We show that our Loewner
evolutions behave very differently from ordinary SLE. For example, if neither
$B^1$ nor $B^2$ is identically equal to zero, then the set of points
disconnected from $\infty$ by the Loewner hull has non-empty interior at each
time. We also show that our model exhibits three phases analogous to the phases
of SLE: a phase where the hulls have zero Lebesgue measure, a phase where
points are swallowed but not hit by the hulls, and a phase where the hulls are
space-filling. The phase boundaries are expressed in terms of the signs of
explicit integrals. These boundaries have a simple closed form when the
correlation of the two Brownian motions is zero.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:19:48 GMT""},{""version"":""v2"",""created"":""Sun, 10 Apr 2022 03:11:28 GMT""},{""version"":""v3"",""created"":""Sat, 3 Jun 2023 16:16:25 GMT""}]","2023-06-06"
"2203.07314","Tova Holmes","K. F. Di Petrillo, J. N. Farr, C. Guo, T. R. Holmes, J. Nelson, K.
  Pachal","Track-Based Triggers for Exotic Signatures","Snowmass submission",,,,"hep-ex","http://creativecommons.org/licenses/by/4.0/","  Several compelling beyond the Standard Model scenarios predict signals that
result in unconventional charged particle trajectories. Signatures for which
unusual tracks are the most conspicuous feature pose significant challenges for
experiments at the Large Hadron Collider (LHC), particularly for the trigger.
This article presents a study of track-based triggers for a representative set
of long-lived and unconventional signatures at the upcoming High Luminosity
LHC. Scenarios studied include large multiplicities of low momentum tracks
produced in a soft-unclustered-energy-pattern model, displaced leptons and
anomalous prompt tracks predicted in a Supersymmetry model with long-lived
staus, and displaced hadrons predicted in a Higgs portal scenario with
long-lived scalars. Trigger efficiency is measured as a function of the
baseline parameters of a track trigger, including transverse momentum and
impact parameter. Recommendations for future hardware-based track triggers are
presented.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:20:50 GMT""},{""version"":""v2"",""created"":""Tue, 28 Jun 2022 19:10:20 GMT""}]","2022-06-30"
"2203.07315","Mikhail Bondarko","Mikhail V. Bondarko","Producing ""new"" semi-orthogonal decompositions in arithmetic geometry","Lots of minor corrections made",,,,"math.AG math.KT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is devoted to constructing ""new"" admissible subcategories and
semi-orthogonal decompositions of triangulated categories out of ""old"" ones.
For two triangulated subcategories $T$ and $T'$ of a certain $D$ and a
decomposition $(L,R)$ of $T$ we look either for a decomposition $(L',R')$ of
$T'$ such that there are no non-zero $D$-morphisms from $L$ into $L'$ and from
$R$ into $R'$, or for a decomposition $(L_D,R_D)$ of $D$ such that $L_D\cap
T=L$ and $R_D\cap T=R$. We prove some general existence statements (that also
extend to semi-orthogonal decompositions with any number of components) and
apply them to various derived categories of coherent sheaves over a scheme $X$
that is proper over a noetherian ring $R$. This gives a one-to-one
correspondence between semi-orthogonal decompositions of $D_{perf}(X)$ and
$D^b_{coh}(X)$; the latter extend to $D^-_{coh}(X)$, $D^+_{coh}(X)$,
$D_{coh}(X)$ and $D_{qcoh}(X)$ under very mild assumptions. In particular, we
obtain a vast generalization of a theorem of J. Karmazyn, A. Kuznetsov, and E.
Shinder.
  These applications rely on recent results of Neeman that express
$D^b_{coh}(X)$ and $D^-_{coh}(X)$ in terms of $D_{perf}(X)$ along with a
(rather similar) new theorem relating $D^+_{coh}(X)$ and $D_{coh}(X)$ to
homological functors $D_{perf}(X)^{op}\to R-mod$ as well. We also discuss an
application of this theorem to the construction of certain adjoint functors.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:21:04 GMT""},{""version"":""v2"",""created"":""Mon, 11 Jul 2022 17:16:33 GMT""}]","2022-07-12"
"2203.07316","Dean Robinson","Giulio Aielli, Juliette Alimena, James Beacham, Eli Ben-Haim, Martino
  Borsato, Matthew John Charles, Xabier Cid Vidal, Victor Coco, Albert De
  Roeck, Biplab Dey, Raphael Dumps, Vladimir V. Gligorov, Rebeca Gonzalez
  Suarez, Thomas Gorordo, Louis Henry, Philip Ilten, Daniel Johnson, Simon
  Knapen, Olivier Le Dortz, Saul L\'opez Soli\~no, Titus Momb\""acher, Benjamin
  Nachman, David T. Northacker, Michele Papucci, Gabriella P\'asztor, Luca
  Pizzimento, Francesco Polci, Dean J. Robinson, Heinrich Schindler, Michael D.
  Sokoloff, Aditya Suresh, Paul Swallow, Riccardo Vari, G\'abor Veres, Carlos
  V\'azquez Sierra, Nigel Watson, Michael K. Wilkinson, Michael Williams,
  Emilio Xos\'e Rodr\'iguez Fern\'andez","The Road Ahead for CODEX-b","13 pages, 13 figures, Snowmass contribution",,,,"hep-ex hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this Snowmass contribution we present a comprehensive status update on the
progress and plans for the proposed CODEX-b detector, intended to search for
long-lived particles beyond the Standard Model. We review the physics case for
the proposal and present recent progress on optimization strategies for the
detector and shielding design, as well as the development of new fast and full
simulation frameworks. A summary of the technical design for a smaller
demonstrator detector (CODEX-$\beta$) for the upcoming Run~3 of the LHC is also
discussed, alongside the road towards realization of the full experiment at the
High-Luminosity LHC.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:21:48 GMT""}]","2022-03-15"
"2203.07317","Yukun He","Yukun He","Spectral gap and edge universality of dense random regular graphs","33 pages",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\mathcal A$ be the adjacency matrix of a random $d$-regular graph on $N$
vertices, and we denote its eigenvalues by $\lambda_1\geq \lambda_2\cdots \geq
\lambda_{N}$. For $N^{2/3}\ll d\leq N/2$, we prove optimal rigidity estimates
of the extreme eigenvalues of $\mathcal A$, which in particular imply that \[
\max\{|\lambda_N|,\lambda_2\} <2\sqrt{d-1} \] with overwhelming probability. In
the same regime of $d$, we also show that \[
N^{2/3}\bigg(\frac{\lambda_2+d/N}{\sqrt{d(N-d)/N}}-2\bigg)
\overset{d}{\longrightarrow} \mathrm{TW}_1\,, \]where $\mathrm{TW}_1$ is the
Tracy-Widom distribution for GOE; analogues results also hold for other
non-trivial extreme eigenvalues.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:22:17 GMT""},{""version"":""v2"",""created"":""Thu, 17 Mar 2022 04:41:44 GMT""},{""version"":""v3"",""created"":""Fri, 28 Apr 2023 16:02:41 GMT""}]","2023-05-01"
"2203.07318","Mihai Florea","Mihai I. Florea","Gradient Methods with Memory for Minimizing Composite Functions","46 pages, 2 figures",,,,"math.OC eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recently introduced Gradient Methods with Memory use a subset of the past
oracle information to create a model of the objective function, whose accuracy
enables them to surpass the traditional Gradient Methods in practical
performance. The model introduces an overhead that is substantial, unless
dealing with smooth unconstrained problems. In this work, we introduce several
Gradient Methods with Memory that can solve composite problems efficiently,
including unconstrained problems with non-smooth objectives. The auxiliary
problem at each iteration still cannot be solved exactly but we show how to
alter the model and how to initialize the auxiliary problem solver to ensure
that this inexactness does not degrade the convergence guarantees. Moreover, we
dynamically increase the convergence guarantees as to provably surpass those of
their memory-less counterparts. These properties are preserved when applying
acceleration and the containment of inexactness further prevents error
accumulation. Our methods are able to estimate key geometry parameters to
attain state-of-the art worst-case rates on many important subclasses of
composite problems, where the objective smooth part satisfies a strong
convexity condition or a relaxation thereof. In particular, we formulate a
restart strategy applicable to optimization methods with sublinear convergence
guarantees of any order. We support the theoretical results with simulations.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:22:19 GMT""},{""version"":""v2"",""created"":""Mon, 9 May 2022 16:04:44 GMT""}]","2022-05-10"
"2203.07319","Jingwen He","Jingwen He, Wu Shi, Kai Chen, Lean Fu, Chao Dong","GCFSR: a Generative and Controllable Face Super Resolution Method
  Without Facial and GAN Priors","Accepted by CVPR2022",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Face image super resolution (face hallucination) usually relies on facial
priors to restore realistic details and preserve identity information. Recent
advances can achieve impressive results with the help of GAN prior. They either
design complicated modules to modify the fixed GAN prior or adopt complex
training strategies to finetune the generator. In this work, we propose a
generative and controllable face SR framework, called GCFSR, which can
reconstruct images with faithful identity information without any additional
priors. Generally, GCFSR has an encoder-generator architecture. Two modules
called style modulation and feature modulation are designed for the
multi-factor SR task. The style modulation aims to generate realistic face
details and the feature modulation dynamically fuses the multi-level encoded
features and the generated ones conditioned on the upscaling factor. The simple
and elegant architecture can be trained from scratch in an end-to-end manner.
For small upscaling factors (<=8), GCFSR can produce surprisingly good results
with only adversarial loss. After adding L1 and perceptual losses, GCFSR can
outperform state-of-the-art methods for large upscaling factors (16, 32, 64).
During the test phase, we can modulate the generative strength via feature
modulation by changing the conditional upscaling factor continuously to achieve
various generative effects.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:22:19 GMT""}]","2022-03-15"
"2203.07320","Yi Liu","Yi Liu, Lei Xu, Xingliang Yuan, Cong Wang, Bo Li","The Right to be Forgotten in Federated Learning: An Efficient
  Realization with Rapid Retraining","INFOCOM 2022",,"10.1109/INFOCOM48880.2022.9796721",,"cs.CR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In Machine Learning, the emergence of \textit{the right to be forgotten} gave
birth to a paradigm named \textit{machine unlearning}, which enables data
holders to proactively erase their data from a trained model. Existing machine
unlearning techniques focus on centralized training, where access to all
holders' training data is a must for the server to conduct the unlearning
process. It remains largely underexplored about how to achieve unlearning when
full access to all training data becomes unavailable. One noteworthy example is
Federated Learning (FL), where each participating data holder trains locally,
without sharing their training data to the central server. In this paper, we
investigate the problem of machine unlearning in FL systems. We start with a
formal definition of the unlearning problem in FL and propose a rapid
retraining approach to fully erase data samples from a trained FL model. The
resulting design allows data holders to jointly conduct the unlearning process
efficiently while keeping their training data locally. Our formal convergence
and complexity analysis demonstrate that our design can preserve model utility
with high efficiency. Extensive evaluations on four real-world datasets
illustrate the effectiveness and performance of our proposed realization.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:22:40 GMT""}]","2022-07-01"
"2203.07321","Yi Zhou","Rong-Yang Sun, Hui-Ke Jin, Hong-Hao Tu and Yi Zhou","Possible chiral spin liquid state in the $S=1/2$ kagome Heisenberg model","4 pages + appendices, references added",,,,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The nature of the ground state for the $S = 1/2$ kagome Heisenberg
antiferromagnet (KHAF) has been elusive. We revisit this challenging problem
and provide numerical evidence that its ground state might be a chiral spin
liquid. Combining the density matrix renormalization group method and
analytical analyses, we demonstrate that the previously observed chiral spin
liquid phase in the KHAF with longer-range couplings is stable in a broader
region. We characterize the nature of the ground state by computing energy
derivatives, revealing ground-state degeneracy arising from spontaneous
breaking of time-reversal symmetry, and targeting the semion sector. We further
investigate the phase diagram in the vicinity of the KHAF and observe a
$\sqrt{3}\times\sqrt{3}$ magnetically ordered phase and two valence-bond
crystal phases.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:23:27 GMT""},{""version"":""v2"",""created"":""Thu, 24 Mar 2022 12:56:21 GMT""}]","2022-03-25"
"2203.07322","Pier Giuseppe Sessa","Pier Giuseppe Sessa, Maryam Kamgarpour, Andreas Krause","Efficient Model-based Multi-agent Reinforcement Learning via Optimistic
  Equilibrium Computation",,,,,"cs.LG cs.MA","http://creativecommons.org/licenses/by/4.0/","  We consider model-based multi-agent reinforcement learning, where the
environment transition model is unknown and can only be learned via expensive
interactions with the environment. We propose H-MARL (Hallucinated Multi-Agent
Reinforcement Learning), a novel sample-efficient algorithm that can
efficiently balance exploration, i.e., learning about the environment, and
exploitation, i.e., achieve good equilibrium performance in the underlying
general-sum Markov game. H-MARL builds high-probability confidence intervals
around the unknown transition model and sequentially updates them based on
newly observed data. Using these, it constructs an optimistic hallucinated game
for the agents for which equilibrium policies are computed at each round. We
consider general statistical models (e.g., Gaussian processes, deep ensembles,
etc.) and policy classes (e.g., deep neural networks), and theoretically
analyze our approach by bounding the agents' dynamic regret. Moreover, we
provide a convergence rate to the equilibria of the underlying Markov game. We
demonstrate our approach experimentally on an autonomous driving simulation
benchmark. H-MARL learns successful equilibrium policies after a few
interactions with the environment and can significantly improve the performance
compared to non-optimistic exploration methods.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:24:03 GMT""},{""version"":""v2"",""created"":""Sun, 10 Jul 2022 13:31:28 GMT""}]","2022-07-12"
"2203.07323","Alexandre Sousa","M. A. Acero, C. A. Arg\""uelles, M. Hostert, D. Kalra, G. Karagiorgi,
  K. J. Kelly, B. Littlejohn, P. Machado, W. Pettus, M. Toups, M.
  Ross-Lonergan, A. Sousa, P. T. Surukuchi, Y. Y. Y. Wong, W. Abdallah, A. M.
  Abdullahi, R. Akutsu, L. Alvarez-Ruso, D. S. M. Alves, A. Aurisano, A.B.
  Balantekin, J. M. Berryman, T. Bert\'olez-Mart\'inez, J. Brunner, M. Blennow,
  S. Bolognesi, M. Borusinski, D. Cianci, G. Collin, J.M. Conrad, B. Crow, P.
  B. Denton, M. Duvall, E. Fern\'andez-Martinez, C. S. Fong, N. Foppiani, D. V.
  Forero, M. Friend, A. Garc\'ia-Soto, C. Giganti, C. Giunti, R. Gandhi, M.
  Ghosh, J. Hardin, K. M. Heeger, M. Ishitsuka, A. Izmaylov, B. J. P. Jones, J.
  R. Jordan, N. W. Kamp, T. Katori, S. B. Kim, L. W. Koerner, M. Lamoureux, T.
  Lasserre, K.G. Leach, J. Learned, Y. F. Li, J. M. Link, W. C. Louis, K. Mahn,
  P. D. Meyers, J. Maricic, D. Marko, T. Maruyama, S. Mertens, H. Minakata, I.
  Mocioiu, M. Mooney, M.H. Moulai, H. Nunokawa, J. P. Ochoa-Ricoux, Y. M. Oh,
  T. Ohlsson, H. P\""as, D. Pershey, R. G. H. Robertson, S. Rosauro-Alcaraz, C.
  Rott, S. Roy, J. Salvado, M. Scott, S. H. Seo, M. H. Shaevitz, M. Smiley, J.
  Spitz, J. Stachurska, T. Thakore, C.A. Ternes, A. Thompson, S. Tseng, B.
  Vogelaar, T. Weiss, R. A. Wendell, T. Wright, Z. Xin, B. S. Yang, J. Yoo, J.
  Zennamo, J. Zettlemoyer, J. D. Zornoza, S. Ahmad, V. S. Basto-Gonzalez, N. S.
  Bowden, B. C. Ca\~nas, D. Caratelli, C. V. Chang, C. Chen, T. Classen, M.
  Convery, G. S. Davies, S. R. Dennis, Z. Djurcic, R. Dorrill, Y. Du, J.J.
  Evans, U. Fahrendholz, J. A. Formaggio, B. T. Foust, H. Frandini Gatti, D.
  Garcia-Gamez, S. Gariazzo, J. Gehrlein, C. Grant, R. A. Gomes, A. B. Hansell,
  F. Halzen, S. Ho, J. Hoefken Zink, R. S. Jones, P. Kunkle, J.-Y. Li, S. C.
  Li, X. Luo, Yu. Malyshkin, D. Massaro, A. Mastbaum, R. Mohanta, H.P. Mumm, M.
  Nebot-Guinot, R. Neilson, K. Ni, J. Nieves, G. D. Orebi Gann, V. Pandey, S.
  Pascoli, X. Qian, M. Rajaoalisoa, C. Roca, B. Roskovec, E. Saul-Sala, L.
  Salda\~na, K. Scholberg, B. Shakya, P. L. Slocum, E.L. Snider, H. Th. J.
  Steiger, A. F. Steklain, M. R. Stock, F. Sutanto, V. Takhistov, Y.-D. Tsai,
  Y.-T. Tsai, D. Venegas-Vargas, M. Wallbank, E. Wang, P. Weatherly, S.
  Westerdale, E. Worcester, W. Wu, G. Yang, and B. Zamorano","White Paper on Light Sterile Neutrino Searches and Related Phenomenology","Contribution to Snowmass 2021 by the NF02 Topical Group
  (Understanding Experimental Neutrino Anomalies). Submitted to J. Phys. G as a
  Major Report",,,,"hep-ex astro-ph.CO hep-ph physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  This white paper provides a comprehensive review of our present understanding
of experimental neutrino anomalies that remain unresolved, charting the
progress achieved over the last decade at the experimental and phenomenological
level, and sets the stage for future programmatic prospects in addressing those
anomalies. It is purposed to serve as a guiding and motivational ""encyclopedic""
reference, with emphasis on needs and options for future exploration that may
lead to the ultimate resolution of the anomalies. We see the main experimental,
analysis, and theory-driven thrusts that will be essential to achieving this
goal being: 1) Cover all anomaly sectors -- given the unresolved nature of all
four canonical anomalies, it is imperative to support all pillars of a diverse
experimental portfolio, source, reactor, decay-at-rest, decay-in-flight, and
other methods/sources, to provide complementary probes of and increased
precision for new physics explanations; 2) Pursue diverse signatures -- it is
imperative that experiments make design and analysis choices that maximize
sensitivity to as broad an array of these potential new physics signatures as
possible; 3) Deepen theoretical engagement -- priority in the theory community
should be placed on development of standard and beyond standard models relevant
to all four short-baseline anomalies and the development of tools for efficient
tests of these models with existing and future experimental datasets; 4) Openly
share data -- Fluid communication between the experimental and theory
communities will be required, which implies that both experimental data
releases and theoretical calculations should be publicly available; and 5)
Apply robust analysis techniques -- Appropriate statistical treatment is
crucial to assess the compatibility of data sets within the context of any
given model.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:24:50 GMT""},{""version"":""v2"",""created"":""Thu, 18 May 2023 02:06:51 GMT""}]","2023-05-19"
"2203.07324","Amir Rasouli","Amir Rasouli, Iuliia Kotseruba","Intend-Wait-Cross: Towards Modeling Realistic Pedestrian Crossing
  Behavior","8 pages, 8 figures, 2 tables",,,,"cs.RO cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present a microscopic agent-based pedestrian behavior model
Intend-Wait-Cross. The model is comprised of rules representing behaviors of
pedestrians as a series of decisions that depend on their individual
characteristics (e.g. demographics, walking speed, law obedience) and
environmental conditions (e.g. traffic flow, road structure). The model's main
focus is on generating realistic crossing decision-model, which incorporates an
improved formulation of time-to-collision (TTC) computation accounting for
context, vehicle dynamics, and perceptual noise.
  Our model generates a diverse population of agents acting in a highly
configurable environment. All model components, including individual
characteristics of pedestrians, types of decisions they make, and environmental
factors, are motivated by studies on pedestrian traffic behavior. Model
parameters are calibrated using a combination of naturalistic driving data and
estimates from the literature to maximize the realism of the simulated
behaviors. A number of experiments validate various aspects of the model, such
as pedestrian crossing patterns, and individual characteristics of pedestrians.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:26:10 GMT""}]","2022-03-15"
"2203.07325","Philip Mayer","Anna Arutyunova, Anne Driemel, Jan-Henrik Haunert, Herman Haverkort,
  J\""urgen Kusche, Elmar Langetepe, Philip Mayer, Petra Mutzel and Heiko
  R\""oglin","Minimum-Error Triangulations for Sea Surface Reconstruction","42 pages, 36 figures, accepted for SoCG 2022",,,,"cs.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We apply state-of-the-art computational geometry methods to the problem of
reconstructing a time-varying sea surface from tide gauge records. Our work
builds on a recent article by Nitzke et al.~(Computers \& Geosciences,
157:104920, 2021) who have suggested to learn a triangulation $D$ of a given
set of tide gauge stations. The objective is to minimize the misfit of the
piecewise linear surface induced by $D$ to a reference surface that has been
acquired with satellite altimetry. The authors restricted their search to
k-order Delaunay ($k$-OD) triangulations and used an integer linear program in
order to solve the resulting optimization problem.
  In geometric terms, the input to our problem consists of two sets of points
in $\mathbb{R}^2$ with elevations: a set $\mathcal{S}$ that is to be
triangulated, and a set $\mathcal{R}$ of reference points. Intuitively, we
define the error of a triangulation as the average vertical distance of a point
in $\mathcal{R}$ to the triangulated surface that is obtained by interpolating
elevations of $\mathcal{S}$ linearly in each triangle. Our goal is to find the
triangulation of $\mathcal{S}$ that has minimum error with respect to
$\mathcal{R}$.
  In our work, we prove that the minimum-error triangulation problem is NP-hard
and cannot be approximated within any multiplicative factor in polynomial time
unless $P=NP$. At the same time we show that the problem instances that occur
in our application (considering sea level data from several hundreds of tide
gauge stations worldwide) can be solved relatively fast using dynamic
programming when restricted to $k$-OD triangulations for $k\le 7$. In
particular, instances for which the number of connected components of the
so-called $k$-OD fixed-edge graph is small can be solved within few seconds.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:27:43 GMT""}]","2022-03-15"
"2203.07326","Raul Felipe Sosa","Ra\'ul Felipe-Sosa, Andr\'e Fraguela-Collar and Yofre H. Garc\'ia
  G\'omez","On the strong convergence of the Faedo-Galerkin approximations to a
  strong T-periodic solution of the torso-coupled bi-domain model","22 pages",,,,"math.AP","http://creativecommons.org/publicdomain/zero/1.0/","  In this paper, we investigate the convergence of the Faedo-Galerkin
approximations, in a strong sense, to a strong T-periodic solution of the
torso-coupled bidomain model where $T$ is the period of activation of the inner
wall of heart. First, we define the torso-coupled bi-domain operator and prove
some of its more important properties for our work. After, we define the
abstract evolution system of equations associated with torso-coupled bidomain
model and give the definition of strong solution. We prove that the
Faedo-Galerkin's approximations have the regularity of a strong solution, and
we find that some restrictions can be imposed over the initial conditions, so
that this sequence of Faedo-Galerkin fully converge to a global strong solution
of the Cauchy problem. Finally, this results are used for showing the existence
a strong $T$-periodic solution.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:27:47 GMT""},{""version"":""v2"",""created"":""Mon, 20 Jun 2022 15:02:30 GMT""}]","2022-06-22"
"2203.07327","Leevi Kerkel\""a","Leevi Kerkel\""a, Kiran Seunarine, Rafael Neto Henriques, Jonathan D.
  Clayden, and Chris A. Clark","Improved reproducibility of diffusion kurtosis imaging using regularized
  non-linear optimization informed by artificial neural networks",,,,,"physics.med-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Diffusion kurtosis imaging is an extension of diffusion tensor imaging that
provides scientifically and clinically valuable information about brain tissue
microstructure but suffers from poor robustness to noise, especially in voxels
containing tightly packed aligned axons. We present a new algorithm for
estimating diffusion and kurtosis tensors using regularized non-linear
optimization and make it publicly available in an easy-to-use open-source
Python software package. Our approach uses fully-connected feed-forward neural
networks to predict kurtosis values in voxels where the standard non-linear
least squares fit fails. The predicted values are then used in the objective
function to avoid implausible kurtosis values. We show that our algorithm is
more robust than standard non-linear least squares and a previously proposed
regularized non-linear optimization method. The algorithm was then applied on a
multi-site scan-rescan dataset acquired using a clinical scan protocol to
assess the reproducibility of diffusion kurtosis parameter estimation in human
white matter using the proposed algorithm. Our results show that the
reproducibility of diffusion kurtosis parameters is similar to diffusion tensor
parameters.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:30:43 GMT""},{""version"":""v2"",""created"":""Tue, 12 Apr 2022 13:15:57 GMT""}]","2022-04-13"
"2203.07328","Erin Conley","Garvita Agarwal, Joshua L. Barrow, Mateus F. Carneiro, Erin Conley,
  Maria Elidaiana da Silva Pereira, Sam Hedges, Samuel Homiller, Ivan Lepetic,
  Tianhuan Luo","Snowmass 2021 Community Survey Report","Contribution to Snowmass 2021. Submitted by the Snowmass Early Career
  Survey Initiative",,,,"hep-ex astro-ph.IM hep-ph physics.soc-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Snowmass Community Survey was designed by the Snowmass Early Career (SEC)
Survey Core Initiative team between April 2020 and June 2021, and released to
the community on June 28, 2021. It aims to be a comprehensive assessment of the
state of the high-energy particle and astrophysics (HEPA) community, if not the
field, though the Snowmass process is largely based within the United States.
Among other topics, some of the central foci of the Survey were to gather
demographic, career, physics outlook, and workplace culture data on a large
segment of the Snowmass community. With nearly $1500$ total interactions with
the Survey, the SEC Survey team hopes the findings and discussions within this
report will be of service to the community over the next decade. Some
conclusions should reinforce the aspects of HEPA which are already functional
and productive, while others should strengthen arguments for cultural and
policy changes within the field.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:31:04 GMT""},{""version"":""v2"",""created"":""Sat, 23 Jul 2022 15:56:27 GMT""}]","2022-07-26"
"2203.07329","Maike Meier","Maike Meier and Yuji Nakatsukasa","Randomized algorithms for Tikhonov regularization in linear least
  squares",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe two algorithms to efficiently solve regularized linear least
squares systems based on sketching. The algorithms compute preconditioners for
$\min \|Ax-b\|^2_2 + \lambda \|x\|^2_2$, where $A\in\mathbb{R}^{m\times n}$ and
$\lambda>0$ is a regularization parameter, such that LSQR converges in
$\mathcal{O}(\log(1/\epsilon))$ iterations for $\epsilon$ accuracy. We focus on
the context where the optimal regularization parameter is unknown, and the
system must be solved for a number of parameters $\lambda$. Our algorithms are
applicable in both the underdetermined $m\ll n$ and the overdetermined $m\gg n$
setting. Firstly, we propose a Cholesky-based sketch-to-precondition algorithm
that uses a `partly exact' sketch, and only requires one sketch for a set of
$N$ regularization parameters $\lambda$. The complexity of solving for $N$
parameters is $\mathcal{O}(mn\log(\max(m,n)) +N(\min(m,n)^3 +
mn\log(1/\epsilon)))$. Secondly, we introduce an algorithm that uses a sketch
of size $\mathcal{O}(\text{sd}_{\lambda}(A))$ for the case where the
statistical dimension $\text{sd}_{\lambda}(A)\ll\min(m,n)$. The scheme we
propose does not require the computation of the Gram matrix, resulting in a
more stable scheme than existing algorithms in this context. We can solve for
$N$ values of $\lambda_i$ in $\mathcal{O}(mn\log(\max(m,n)) +
\min(m,n)\,\text{sd}_{\min\lambda_i}(A)^2 + Nmn\log(1/\epsilon))$ operations.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:32:36 GMT""}]","2022-03-15"
"2203.07330","Elena Bachini","Elena Bachini and Mario Putti","Convergence analysis of the intrinsic surface finite element method",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Intrinsic Surface Finite Element Method (ISFEM) was recently proposed to
solve Partial Differential Equations (PDEs) on surfaces. ISFEM proceeds by
writing the PDE with respect to a local coordinate system anchored to the
surface and makes direct use of the resulting covariant basis. Starting from a
shape-regular triangulation of the surface, existence of a local
parametrization for each triangle is exploited to approximate relevant
quantities on the local chart. Standard two-dimensional FEM techniques in
combination with surface quadrature rules complete the ISFEM formulation thus
achieving a method that is fully intrinsic to the surface and makes limited use
of the surface embedding only for the definition of linear basis functions.
However, theoretical properties have not yet been proved. In this work, we
complement the original derivation of ISFEM with its complete convergence
theory and propose the analysis of the stability and error estimates by
carefully tracking the role of the geometric quantities in the constants of the
error inequalities. Numerical experiments are included to support the
theoretical results.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:33:37 GMT""}]","2022-03-15"
"2203.07331","Maximilian N\""agele","Maximilian N\""agele, Christian Schweizer, Federico Roy and Stefan
  Filipp","Effective non-local parity-dependent couplings in qubit chains","4 pages, 4 figures","Phys. Rev. Research 4, 033166 (2022)","10.1103/PhysRevResearch.4.033166",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For the efficient implementation of quantum algorithms, practical ways to
generate many-body entanglement are a basic requirement. Specifically, coupling
multiple qubit pairs at once can be advantageous and can lead to multi-qubit
operations useful in the construction of hardware-tailored algorithms. Here we
harness the simultaneous coupling of qubits on a chain and engineer a set of
non-local parity-dependent quantum operations suitable for a wide range of
applications. The resulting effective long-range couplings directly implement a
parametrizable Trotter-step for Jordan-Wigner fermions and can be used for
simulations of quantum dynamics, efficient state generation in variational
quantum eigensolvers, parity measurements for error-correction schemes, and the
generation of efficient multi-qubit gates. Moreover, we present numerical
simulations of the gate operation in a superconducting quantum circuit
architecture, which show a high gate fidelity of $>99.9\%$ for realistic
experimental parameters.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:33:40 GMT""}]","2022-09-30"
"2203.07332","Giovanni Maria Vanacore","Andrea Kone\v{c}n\'a, Enzo Rotunno, Vincenzo Grillo, F. Javier
  Garc\'ia de Abajo, Giovanni Maria Vanacore","Single-Pixel Imaging in Space and Time with Optically-Modulated Free
  Electrons","25 pages, 4 figures, 3 supplementary figures",,,,"physics.optics cond-mat.mes-hall quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Single-pixel imaging, originally developed in light optics, facilitates fast
three-dimensional sample reconstruction, as well as probing with light
wavelengths undetectable by conventional multi-pixel detectors. However, the
spatial resolution of optics-based single-pixel microscopy is limited by
diffraction to hundreds of nanometers. Here, we propose an implementation of
single-pixel imaging relying on attainable modifications of currently available
ultrafast electron microscopes in which optically-modulated electrons are used
instead of photons to achieve sub-nanometer spatially- and temporally-resolved
single-pixel imaging. We simulate electron beam profiles generated by
interaction with the optical field produced by an externally programable
spatial light modulator and demonstrate the feasibility of the method by
showing that the sample image and its temporal evolution can be reconstructed
using realistic imperfect illumination patterns. Electron single-pixel imaging
holds strong potential for application in low-dose probing of beam-sensitive
biological and molecular samples, including rapid screening during in-situ
experiments.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:34:52 GMT""},{""version"":""v2"",""created"":""Tue, 1 Nov 2022 19:28:31 GMT""}]","2022-11-03"
"2203.07333","Sergey Kulagin","S.I. Alekhin, S.A. Kulagin, R. Petti","Nuclear effects in the deuteron and global QCD analyses","30 pages, 14 figures, final version published in PRD",,"10.1103/PhysRevD.105.114037","INR-TH-2022-007","hep-ph nucl-th","http://creativecommons.org/licenses/by/4.0/","  We report the results of a new global QCD analysis, which includes
deep-inelastic $e/\mu$ scattering data off proton and deuterium, as well as
Drell-Yan lepton pair production in proton-proton and proton-deuterium
collisions and $W^\pm/Z$ boson production data from $pp$ and $p \bar p$
collisions at the LHC and Tevatron. Nuclear effects in the deuteron are treated
in terms of a nuclear convolution approach with bound off-shell nucleons within
a weak binding approximation. The off-shell correction is controlled by a
universal function of the Bjorken variable $x$ describing the modification of
parton distributions in bound nucleons, which is determined in our analysis
along with the parton distribution functions of the proton. A number of
systematic studies are performed to estimate the uncertainties arising from the
use of various deuterium datasets, from the modeling of higher twist
contributions to the structure functions, from the treatment of target mass
corrections, as well as from the nuclear corrections in the deuteron. We obtain
predictions for the ratios $F_2^n/F_2^p$, and $d/u$, focusing on the region of
large $x$. We also compare our results with the ones obtained by other QCD
analyses, as well as with the recent data from the MARATHON experiment.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:35:27 GMT""},{""version"":""v2"",""created"":""Thu, 23 Jun 2022 11:21:35 GMT""}]","2022-07-13"
"2203.07334","Miguel Sanz-Novo","M. Sanz-Novo, A. Belloche, V. M. Rivilla, R. T. Garrod, J. L. Alonso,
  P. Redondo, C. Barrientos, L. Kolesnikov\'a, J.C. Valle, L.
  Rodr\'iguez-Almeida, I. Jim\'enez-Serra, J. Mart\'in-Pintado, H.S.P. Muller
  and K. Menten","Toward the limits of complexity of interstellar chemistry: Rotational
  spectroscopy and astronomical search for n- and i-butanal",,"A&A 666, A114 (2022)","10.1051/0004-6361/202142848",,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In recent times, large organic molecules of exceptional complexity have been
found in diverse regions of the interstellar medium. In this context, we aim to
provide accurate frequencies of the ground vibrational state of two key
aliphatic aldehydes, n-butanal and its branched-chain isomer, i-butanal, to
enable their eventual detection in the interstellar medium. We employ a
frequency modulation millimeter-wave absorption spectrometer to measure the
rotational features of n- and i-butanal. We use the spectral line survey ReMoCA
performed with the Atacama Large Millimeter/submillimeter Array to search for
n- and i-butanal toward the star-forming region Sgr B2(N). We also search for
both aldehydes toward the molecular cloud G+0.693-0.027 with IRAM 30 m and
Yebes 40 m observations. Several thousand rotational transitions belonging to
the lowest-energy conformers have been assigned in the laboratory spectra up to
325 GHz. A precise set of the relevant rotational spectroscopic constants has
been determined for each structure. We report non-detections of n- and
i-butanal toward both sources, Sgr B2(N1S) and G+0.693-0.027. We find that n-
and i-butanal are at least 2-6 and 6-18 times less abundant than acetaldehyde
toward Sgr B2(N1S), respectively, and that n-butanal is at least 63 times less
abundant than acetaldehyde toward G+0.693-0.027. Comparison with astrochemical
models indicates good agreement between observed and simulated abundances
(where available). Grain-surface chemistry appears sufficient to reproduce
aldehyde ratios in G+0.693-0.027; gas-phase production may play a more active
role in Sgr B2(N1S). Our astronomical results indicate that the family of
interstellar aldehydes in the Galactic center region is characterized by a drop
of one order of magnitude in abundance at each incrementation in the level of
molecular complexity.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:37:18 GMT""}]","2022-10-19"
"2203.07335","Jelena Sedlar","Martin Knor, Jelena Sedlar, Riste \v{S}krekovski","Remarks on the vertex and the edge metric dimension of 2-connected
  graphs","19 pages, 3 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The vertex (resp. edge) metric dimension of a graph G is the size of a
smallest vertex set in G which distinguishes all pairs of vertices (resp.
edges) in G and it is denoted by dim(G) (resp. edim(G)). The upper bounds
dim(G) <= 2c(G) - 1 and edim(G) <= 2c(G)-1; where c(G) denotes the cyclomatic
number of G, were established to hold for cacti without leaves distinct from
cycles, and moreover all leafless cacti which attain the bounds were
characterized. It was further conjectured that the same bounds hold for general
connected graphs without leaves and this conjecture was supported by showing
that the problem reduces to 2-connected graphs. In this paper we focus on Theta
graphs, as the most simple 2-connected graphs distinct from cycle, and show
that the the upper bound 2c(G) - 1 holds for both metric dimensions of Theta
graphs and we characterize all Theta graphs for which the bound is attained. We
conclude by conjecturing that there are no other extremal graphs for the bound
2c(G) - 1 in the class of leafless graphs besides already known extremal cacti
and extremal Theta graphs mentioned here.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:38:25 GMT""}]","2022-03-15"
"2203.07336","Zhengkang Zhang","Timothy Cohen, Xiaochuan Lu, Zhengkang Zhang","Snowmass White Paper: Effective Field Theory Matching and Applications","contribution to Snowmass 2021; 10 pages",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mapping UV theories onto low energy effective descriptions is a procedure
known as matching. The last decade has seen tremendous progress in the
development of new tools for efficiently performing matching calculations, by
relying on so-called functional methods. This white paper summarizes the status
of functional matching. Specifically, matching for relativistic theories is a
fully solved problem up to one-loop order in perturbation theory, and to
arbitrary order in the effective field theory expansion. A streamlined
prescription that has been partially automated facilitates the application of
functional matching to phenomenological studies in the Standard Model EFT
framework.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:38:37 GMT""}]","2022-03-15"
"2203.07337","Sidak Pal Singh","Sidak Pal Singh, Aurelien Lucchi, Thomas Hofmann, Bernhard Sch\""olkopf","Phenomenology of Double Descent in Finite-Width Neural Networks","Published at ICLR 2022",,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  `Double descent' delineates the generalization behaviour of models depending
on the regime they belong to: under- or over-parameterized. The current
theoretical understanding behind the occurrence of this phenomenon is primarily
based on linear and kernel regression models -- with informal parallels to
neural networks via the Neural Tangent Kernel. Therefore such analyses do not
adequately capture the mechanisms behind double descent in finite-width neural
networks, as well as, disregard crucial components -- such as the choice of the
loss function. We address these shortcomings by leveraging influence functions
in order to derive suitable expressions of the population loss and its lower
bound, while imposing minimal assumptions on the form of the parametric model.
Our derived bounds bear an intimate connection with the spectrum of the Hessian
at the optimum, and importantly, exhibit a double descent behaviour at the
interpolation threshold. Building on our analysis, we further investigate how
the loss function affects double descent -- and thus uncover interesting
properties of neural networks and their Hessian spectra near the interpolation
threshold.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:39:49 GMT""}]","2022-03-15"
"2203.07338","Alex Chan","Alex J. Chan, Alicia Curth, Mihaela van der Schaar","Inverse Online Learning: Understanding Non-Stationary and Reactionary
  Policies",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Human decision making is well known to be imperfect and the ability to
analyse such processes individually is crucial when attempting to aid or
improve a decision-maker's ability to perform a task, e.g. to alert them to
potential biases or oversights on their part. To do so, it is necessary to
develop interpretable representations of how agents make decisions and how this
process changes over time as the agent learns online in reaction to the accrued
experience. To then understand the decision-making processes underlying a set
of observed trajectories, we cast the policy inference problem as the inverse
to this online learning problem. By interpreting actions within a potential
outcomes framework, we introduce a meaningful mapping based on agents choosing
an action they believe to have the greatest treatment effect. We introduce a
practical algorithm for retrospectively estimating such perceived effects,
alongside the process through which agents update them, using a novel
architecture built upon an expressive family of deep state-space models.
Through application to the analysis of UNOS organ donation acceptance
decisions, we demonstrate that our approach can bring valuable insights into
the factors that govern decision processes and how they change over time.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:40:42 GMT""},{""version"":""v2"",""created"":""Fri, 30 Sep 2022 09:18:48 GMT""}]","2022-10-03"
"2203.07339","Cheng-Yang Tan","William Pellico, Chandra Bhat, Jeffrey Eldred, Carol Johnstone, John
  Johnstone, Kiyomi Seiya, Cheng-Yang Tan, Matthew Toups, Richard Van De Water","FNAL PIP-II Accumulator Ring",,,,"FERMILAB-CONF-22-136-AD-ND","physics.acc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The FNAL accelerator complex is poised to reach MW neutrino beams on target
for the exploration of the dark sector physics and rare physics program spaces.
Future operations of the complex will include CW linac operations at beam
intensities that have not been seen before \cite{PIP2,RCS_LOI}. The ambitious
beam program relies on multi-turn H$^{-}$ injection into the FNAL Booster and
then extracted into delivery rings or the Booster Neutrino Beam (BNB) 8 GeV HEP
program. A new rapid-cycling synchrotron (RCS) will be required to reach the
LBNF goal of 2.4 MW because of intense space-charge limitations. There are many
accelerator engineering challenges that are already known and many that will be
discovered. This proposal calls for an intermediate step that will both
facilitate the operation of Booster in the PIP-II era and gain operational
experience associated with high power injection rings. This step includes the
design, construction and installation of a 0.8 GeV accumulator ring
(upgradeable to 1+ GeV) to be located in the PIP-II Booster Transfer Line
(BTL). The PIP-II accumulator ring (PAR) may be primarily designed around
permanent magnets or use standard iron core magnet technology with an aperture
selected to accommodate the desired high intensity protons at 0.8 GeV.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:41:08 GMT""},{""version"":""v2"",""created"":""Tue, 15 Mar 2022 20:17:57 GMT""}]","2022-03-17"
"2203.07340","Samaneh Nasiri","Samaneh Nasiri, Feng Shi, Guang Yang, Erdmann Spiecker, Qianqian Li","An improved approach to manufacture CNT reinforced magnesium AZ91
  composites with increased strength and ductility","20 pages,7 figures, one table",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Multiwalled carbon nanotubes (MWCNTs) are decorated with Pt nanoparticles by
a ""layer-by-layer"" approach using poly (sodium 4-styrene sulfonate) (PSS) and
poly (diallyl dimethylammonium chloride) (PDDA). Transmission electron
microscopy (TEM) images and Energy Dispersive X-Ray (EDX) analysis of the
samples confirm Pt deposition on surfaces of CNTs. Dispersibility and
dispersion stability of MWCNTs in the solvents are enhanced when MWCNTs are
coated with Pt nanoparticles. Mg AZ91 composites reinforced with MWCNTs are
then produced by a melt stirring process. Compression tests of the composites
show that adding 0.05\% wt Pt-coated MWCNTs in AZ91 improves the composite's
mechanical properties compared to the pure AZ91 and pristine MWCNT/AZ91.
Fracture surface analysis of the composite using a scanning electron microscope
(SEM) shows individuals pulled out MWCNTs in the case of the Pt-coated
MWCNT/AZ91 composites. We attribute this finding to the uniform dispersion of
Pt-coated MWCNTs in Mg due to the improved wettability of Pt-coated MWCNTs in
Mg melts. Molecular dynamics (MD) simulations of the interaction between
Pt-coated MWCNTs and Mg support this interpretation.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:41:36 GMT""}]","2022-03-15"
"2203.07341","Giulio Rossolini","Giulio Rossolini, Federico Nesti, Fabio Brau, Alessandro Biondi and
  Giorgio Buttazzo","Defending From Physically-Realizable Adversarial Attacks Through
  Internal Over-Activation Analysis",,,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This work presents Z-Mask, a robust and effective strategy to improve the
adversarial robustness of convolutional networks against physically-realizable
adversarial attacks. The presented defense relies on specific Z-score analysis
performed on the internal network features to detect and mask the pixels
corresponding to adversarial objects in the input image. To this end, spatially
contiguous activations are examined in shallow and deep layers to suggest
potential adversarial regions. Such proposals are then aggregated through a
multi-thresholding mechanism. The effectiveness of Z-Mask is evaluated with an
extensive set of experiments carried out on models for both semantic
segmentation and object detection. The evaluation is performed with both
digital patches added to the input images and printed patches positioned in the
real world. The obtained results confirm that Z-Mask outperforms the
state-of-the-art methods in terms of both detection accuracy and overall
performance of the networks under attack. Additional experiments showed that
Z-Mask is also robust against possible defense-aware attacks.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:41:46 GMT""},{""version"":""v2"",""created"":""Thu, 15 Sep 2022 14:59:20 GMT""}]","2022-09-16"
"2203.07342","Cecilia Balocchi","Cecilia Balocchi and Federico Camerlenghi and Stefano Favaro","A Bayesian Nonparametric Approach to Species Sampling Problems with
  Ordering",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Species-sampling problems (SSPs) refer to a vast class of statistical
problems calling for the estimation of (discrete) functionals of the unknown
species composition of an unobservable population. A common feature of SSPs is
their invariance with respect to species labelling, which is at the core of the
Bayesian nonparametric (BNP) approach to SSPs under the popular Pitman-Yor
process (PYP) prior. In this paper, we develop a BNP approach to SSPs that are
not ""invariant"" to species labelling, in the sense that an ordering or ranking
is assigned to species' labels. Inspired by the population genetics literature
on age-ordered alleles' compositions, we study the following SSP with ordering:
given an observable sample from an unknown population of individuals belonging
to species (alleles), with species' labels being ordered according to weights
(ages), estimate the frequencies of the first $r$ order species' labels in an
enlarged sample obtained by including additional unobservable samples. By
relying on an ordered PYP prior, we obtain an explicit posterior distribution
of the first $r$ order frequencies, with estimates being of easy implementation
and computationally efficient. We apply our approach to the analysis of genetic
variation, showing its effectiveness in estimating the frequency of the oldest
allele, and then we discuss other potential applications.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:42:58 GMT""},{""version"":""v2"",""created"":""Thu, 8 Jun 2023 09:13:45 GMT""}]","2023-06-09"
"2203.07343","Jessica Sorrells","D. Chloe Griffin, Jessica Sorrells","Tile Based Modeling of DNA Self-Assembly for Two Graph Families with
  Appended Paths","37 pages, 27 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Branched molecules of deoxyribonucleic acid (DNA) can self-assemble into
nanostructures through complementary cohesive strand base pairing. The
production of DNA nanostructures is valuable in targeted drug delivery and
biomolecular computing. With theoretical efficiency of laboratory processes in
mind, we use a flexible tile model for DNA assembly. We aim to minimize the
number of different types of branched junction molecules necessary to assemble
certain target structures. We represent target structures as discrete graphs
and branched DNA molecules as vertices with half-edges. We present the minimum
numbers of required branched molecule and cohesive-end types under three levels
of restrictive conditions for the tadpole and lollipop graph families. These
families represent cycle and complete graphs with a path appended via a single
cut-vertex. We include three general lemmas regarding such vertex-induced path
subgraphs. Through proofs and examples, we demonstrate the challenges that can
arise in determining optimal construction strategies.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:43:09 GMT""}]","2022-03-15"
"2203.07344","Maria Vittoria Garzelli","Simone Alioli, Juan Fuster, Maria Vittoria Garzelli, Alessandro
  Gavardi, Adrian Irles, Davide Melini, Sven-Olaf Moch, Peter Uwer, Katharina
  Vo{\ss}","Top-quark mass extraction from $t\bar{t}j +X$ events at the LHC: theory
  predictions","15 pages, 6 Figures, contribution to Snowmass 2021",,,,"hep-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Past work has proven the possibility of extracting the top-quark mass, one of
the fundamental parameters of the Standard Model, from the comparison of theory
predictions and experimental measurements of differential cross-sections for
$t\bar{t} j~+~X$ hadroproduction. Various experimental analyses in this respect
have already been performed, and new ones are in preparation on the basis of
the latest data from $pp$ collisions collected at the Large Hadron Collider. We
have produced and made public a comprehensive set of theoretical predictions
for the relevant differential distributions, ready to be used for presently
ongoing and forthcoming experimental analyses. We investigate the role of
different theoretical inputs, in particular the factorization and
renormalization scales, PDFs and top-quark mass renormalization schemes, and we
quantify the uncertainties related to different choices for these inputs,
providing recommendations.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:44:43 GMT""}]","2022-03-24"
"2203.07345","Hasan Kassem","Hasan Kassem, Deepak Alapatt, Pietro Mascagni, AI4SafeChole
  Consortium, Alexandros Karargyris, Nicolas Padoy","Federated Cycling (FedCy): Semi-supervised Federated Learning of
  Surgical Phases","13 pages, 6 figures",,"10.1109/TMI.2022.3222126",,"cs.CV cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Recent advancements in deep learning methods bring computer-assistance a step
closer to fulfilling promises of safer surgical procedures. However, the
generalizability of such methods is often dependent on training on diverse
datasets from multiple medical institutions, which is a restrictive requirement
considering the sensitive nature of medical data. Recently proposed
collaborative learning methods such as Federated Learning (FL) allow for
training on remote datasets without the need to explicitly share data. Even so,
data annotation still represents a bottleneck, particularly in medicine and
surgery where clinical expertise is often required. With these constraints in
mind, we propose FedCy, a federated semi-supervised learning (FSSL) method that
combines FL and self-supervised learning to exploit a decentralized dataset of
both labeled and unlabeled videos, thereby improving performance on the task of
surgical phase recognition. By leveraging temporal patterns in the labeled
data, FedCy helps guide unsupervised training on unlabeled data towards
learning task-specific features for phase recognition. We demonstrate
significant performance gains over state-of-the-art FSSL methods on the task of
automatic recognition of surgical phases using a newly collected
multi-institutional dataset of laparoscopic cholecystectomy videos.
Furthermore, we demonstrate that our approach also learns more generalizable
features when tested on data from an unseen domain.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:44:53 GMT""},{""version"":""v2"",""created"":""Wed, 28 Dec 2022 05:42:15 GMT""}]","2022-12-29"
"2203.07346","Yizhe Zhu","Ludovic Stephan and Yizhe Zhu","Sparse random hypergraphs: Non-backtracking spectra and community
  detection","57 pages, 5 figures; FOCS 2022 arXiv version. Some typos are fixed,
  references updated. Code for simulation is available with a link on Page 7",,,,"math.PR math.CO stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the community detection problem in a sparse $q$-uniform
hypergraph $G$, assuming that $G$ is generated according to the Hypergraph
Stochastic Block Model (HSBM). We prove that a spectral method based on the
non-backtracking operator for hypergraphs works with high probability down to
the generalized Kesten-Stigum detection threshold conjectured by Angelini et
al. (2015). We characterize the spectrum of the non-backtracking operator for
the sparse HSBM and provide an efficient dimension reduction procedure using
the Ihara-Bass formula for hypergraphs. As a result, community detection for
the sparse HSBM on $n$ vertices can be reduced to an eigenvector problem of a
$2n\times 2n$ non-normal matrix constructed from the adjacency matrix and the
degree matrix of the hypergraph. To the best of our knowledge, this is the
first provable and efficient spectral algorithm that achieves the conjectured
threshold for HSBMs with $r$ blocks generated according to a general symmetric
probability tensor.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:45:03 GMT""},{""version"":""v2"",""created"":""Mon, 29 Aug 2022 15:55:47 GMT""},{""version"":""v3"",""created"":""Tue, 29 Nov 2022 15:29:21 GMT""}]","2022-11-30"
"2203.07347","Zarija Luki\'c","Marcelo A. Alvarez, Arka Banerjee, Simon Birrer, Salman Habib, Katrin
  Heitmann, Zarija Luki\'c, Julian B. Mu\~noz, Yuuki Omori, Hyunbae Park,
  Annika H. G. Peter, Jean Sexton, and Yi-Ming Zhong","Snowmass2021 Computational Frontier White Paper: Cosmological
  Simulations and Modeling","Submitted to the Proceedings of the US Community Study on the Future
  of Particle Physics (Snowmass 2021)",,,,"astro-ph.IM astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Powerful new observational facilities will come online over the next decade,
enabling a number of discovery opportunities in the ""Cosmic Frontier"", which
targets understanding of the physics of the early universe, dark matter and
dark energy, and cosmological probes of fundamental physics, such as neutrino
masses and modifications of Einstein gravity. Synergies between different
experiments will be leveraged to present new classes of cosmic probes as well
as to minimize systematic biases present in individual surveys. Success of this
observational program requires actively pairing it with a well-matched
state-of-the-art simulation and modeling effort. Next-generation cosmological
modeling will increasingly focus on physically rich simulations able to model
outputs of sky surveys spanning multiple wavebands. These simulations will have
unprecedented resolution, volume coverage, and must deliver guaranteed
high-fidelity results for individual surveys as well as for the
cross-correlations across different surveys. The needed advances are as
follows: (1) Development of scientifically rich and broadly-scoped simulations,
which capture the relevant physics and correlations between probes (2) Accurate
translation of simulation results into realistic image or spectral data to be
directly compared with observations (3) Improved emulators and/or data-driven
methods serving as surrogates for expensive simulations, constructed from a
finite set of full-physics simulations (4) Detailed and transparent
verification and validation programs for both simulations and analysis tools.
(Abridged)
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:46:30 GMT""},{""version"":""v2"",""created"":""Tue, 15 Mar 2022 16:52:10 GMT""}]","2022-03-16"
"2203.07348","Sujan K K","Sujan K. K., Vinayak M. Kulkarni, N. S. Vidhyadhiraja, Sudeshna Sen","Emergent soft-gap Anderson models at quantum criticality in a lattice
  Hamiltonian within dynamical mean field theory","16 pages, 16 figures",,"10.1103/PhysRevB.107.205104",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  Local quantum criticality in itinerant fermion systems has been extensively
investigated through the soft-gap Anderson impurity model, wherein a localized,
correlated impurity, hybridizes with a broad conduction band with a singular,
$|\omega|^r$, density of states. However, lattice models hosting quantum
critical points (QCPs), do not appear to have such a spectrum emerging at the
QCP. In this work, we report the emergence of such a singular form of the
density of states in a three-orbital lattice model, within dynamical mean field
theory, precisely at a quantum critical point, separating a gapless, Fermi
liquid, metallic phase from a gapped, Mott insulating phase. A
temperature-dependent exponent, $\alpha$, defined using the corresponding
Matsubara self-energy, is found to vary from $+1$ deep in the FL regime, to
$-1$ in the Mott insulator regime. Interestingly, we find that $\alpha$ becomes
temperature independent, and hence isosbestic, precisely at the QCP. The
isosbestic exponent is shown to lead to an emergent soft-gap spectrum,
$|\omega|^r$ at the QCP, where $r = |\alpha_{\rm iso}|$. We discuss the
implications of our findings for non-Fermi liquid behaviour in the quantum
critical region of the phase diagram.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:46:36 GMT""},{""version"":""v2"",""created"":""Thu, 2 Mar 2023 08:06:34 GMT""},{""version"":""v3"",""created"":""Fri, 3 Mar 2023 05:59:49 GMT""}]","2023-05-05"
"2203.07349","Walter Pettus","Project 8 Collaboration, A. Ashtari Esfahani, S. B\""oser, N. Buzinsky,
  M. C. Carmona-Benitez, C. Claessens, L. de Viveiros, P. J. Doe, S. Enomoto,
  M. Fertl, J. A. Formaggio, J. K. Gaison, M. Grando, K. M. Heeger, X. Huyan,
  A. M. Jones, K. Kazkaz, M. Li, A. Lindman, C. Matth\'e, R. Mohiuddin, B.
  Monreal, R. Mueller, J. A. Nikkel, E. Novitski, N. S. Oblath, J. I. Pe\~na,
  W. Pettus, R. Reimann, R. G. H. Robertson, G. Rybka, L. Salda\~na, M. Schram,
  P. L. Slocum, J. Stachurska, Y.-H. Sun, P. T. Surukuchi, J. R. Tedeschi, A.
  B. Telles, F. Thomas, M. Thomas, L. A. Thorne, T. Th\""ummler, W. Van De
  Pontseele, B. A. VanDevender, T. E. Weiss, T. Wendler, A. Ziegler","The Project 8 Neutrino Mass Experiment","contribution to Snowmass 2021",,,,"nucl-ex physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  Measurements of the $\beta^-$ spectrum of tritium give the most precise
direct limits on neutrino mass. Project 8 will investigate neutrino mass using
Cyclotron Radiation Emission Spectroscopy (CRES) with an atomic tritium source.
CRES is a new experimental technique that has the potential to surmount the
systematic and statistical limitations of current-generation direct measurement
methods. Atomic tritium avoids an irreducible systematic uncertainty associated
with the final states populated by the decay of molecular tritium. Project 8
will proceed in a phased approach toward a goal of 40 meV/c$^2$ neutrino-mass
sensitivity.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:47:38 GMT""}]","2022-03-15"
"2203.07350","Valery V. Ryzhikov","Valery V. Ryzhikov","Spectra of self-similar ergodic actions","1 figure, in Russian language",,,,"math.DS","http://creativecommons.org/licenses/by/4.0/","  This note is devoted to infinite self-similar rank 1 constructions and their
applications to the spectral theory of dynamical systems. The properties of
orthogonal operators induced by self-similar constructions provide some unusual
spectral properties of Gaussian and Poisson suspensions.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:50:52 GMT""}]","2022-03-15"
"2203.07351","Xing Wang","Tao Han, Zhen Liu, Lian-Tao Wang, Xing Wang","WIMP Dark Matter at High Energy Muon Colliders $-$A White Paper for
  Snowmass 2021","15 pages, 4 figures, 2 tables. Contribution to Snowmass 2021",,,"PITT-PACC-2201","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a previous publication, we showed that a high energy muon collider can
make decisive statements about the electroweak (WIMP) Dark Matter (DM),
reaching a DM mass which could give the observed thermal relic abundance. In
this document, we report new studies of the spin-$0$ minimal WIMP DM at high
energy muon colliders, and update our results on the fermionic spin-$1/2$ case.
We find that, by combining multiple inclusive missing mass search channels, it
is possible to fully cover the thermal targets of fermionic and scalar
doublets, and Dirac triplet, with a 10 TeV muon collider. Higher energies, 14
TeV$-$30 TeV, would be able to cover the thermal targets of Majorana and scalar
triplet. For direct discovery of the higher EW multiplets with $n\geq5$, one
may need to go beyond a 30 TeV muon collider to fully cover their thermal mass
expectation.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:51:00 GMT""}]","2022-03-15"
"2203.07352","Giorgio Ambrosio","Giorgio Ambrosio (1), Giorgio Apollinari (1), Vito Lombardo (1),
  Stoyan Stoynev (1), Mauricio Suarez (1), George Velev (1), Paolo Ferracin
  (2), Soren Prestemon (2), GianLuca Sabbi (2), Kathleen Amm (3) ((1) Fermi
  National Accelerator laboratory, (2) Lawrence Berkeley National Laboratory,
  (3) Brookhaven National Laboratory )","Development and demonstration of next generation technology for Nb_3Sn
  accelerator magnets with lower cost, improved performance uniformity, and
  higher operating point in the 12-14 T range","White Paper for Snowmass 2022, 8 pages, 2 tables, 1 figure",,,,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  The scope of the proposal outlined in this white paper is the development and
demonstration of the technology needed for next generation of Nb_3Sn
accelerator magnets in the 12-14 T range. The main goal is to cut magnet
cold-mass cost by a factor 2 or higher with respect to the Nb_3Sn magnets
produced by the US Accelerator Upgrade Project (AUP) for the High-Luminosity
Large Hadron Collider (HL-LHC). This goal will be achieved by significant
reduction of labor hours, higher operating point, and improved performance
uniformity. A key factor will be automation that will be achieved through
industry involvement and benefitting from the experience gained in US national
laboratories through the production of the AUP magnets. This partnership will
enable the development of a technology that will be easily transferable to
industry for mid- and large-scale production of Nb_3Sn accelerator magnets in
the 12-14 T range. This step is essential to enable next generation of
colliders such as the FNAL-proposed Muon Collider, FCC and other HEP hadron
colliders.
  This is a Directed R&D where direction is given by the field range and
industry involvement for high-automation and industry-ready technology. The
plan includes ten milestones, to be achieved in 6-8 years at the cost of 5-7
$M/year.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:51:08 GMT""},{""version"":""v2"",""created"":""Wed, 16 Mar 2022 00:00:49 GMT""},{""version"":""v3"",""created"":""Sun, 9 Oct 2022 00:56:17 GMT""}]","2022-10-11"
"2203.07353","Javier Duarte","Artur Apresyan and Daniel Diaz and Javier Duarte and Sanmay Ganguly
  and Raghav Kansal and Nan Lu and Cristina Mantilla Suarez and Samadrita
  Mukherjee and Crist\'ian Pe\~na and Brian Sheldon and Si Xie","Improving Di-Higgs Sensitivity at Future Colliders in Hadronic Final
  States with Machine Learning","Contribution to Snowmass 2022 Summer Study",,,"FERMILAB-CONF-22-316-PPD-QIS","hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  One of the central goals of the physics program at the future colliders is to
elucidate the origin of electroweak symmetry breaking, including precision
measurements of the Higgs sector. This includes a detailed study of Higgs boson
(H) pair production, which can reveal the H self-coupling. Since the discovery
of the Higgs boson, a large campaign of measurements of the properties of the
Higgs boson has begun and many new ideas have emerged during the completion of
this program. One such idea is the use of highly boosted and merged hadronic
decays of the Higgs boson ($\mathrm{H}\to\mathrm{b}\bar{\mathrm{b}}$,
$\mathrm{H}\to\mathrm{W}\mathrm{W}\to\mathrm{q}\bar{\mathrm{q}}\mathrm{q}\bar{\mathrm{q}}$)
with machine learning methods to improve the signal-to-background
discrimination. In this white paper, we champion the use of these modes to
boost the sensitivity of future collider physics programs to Higgs boson pair
production, the Higgs self-coupling, and Higgs-vector boson couplings. We
demonstrate the potential improvement possible at the Future Circular Collider
in hadron mode, especially with the use of graph neural networks.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:51:52 GMT""},{""version"":""v2"",""created"":""Mon, 4 Apr 2022 15:48:04 GMT""}]","2022-06-17"
"2203.07354","Keith Bechtol","Keith Bechtol, Simon Birrer, Francis-Yan Cyr-Racine, Katelin Schutz,
  Susmita Adhikari, Mustafa Amin, Arka Banerjee, Simeon Bird, Nikita Blinov,
  Kimberly K. Boddy, Celine Boehm, Kevin Bundy, Malte Buschmann, Sukanya
  Chakrabarti, David Curtin, Liang Dai, Alex Drlica-Wagner, Cora Dvorkin,
  Adrienne L. Erickcek, Daniel Gilman, Saniya Heeba, Stacy Kim, Vid
  Ir\v{s}i\v{c}, Alexie Leauthaud, Mark Lovell, Zarija Luki\'c, Yao-Yuan Mao,
  Sidney Mau, Andrea Mitridate, Philip Mocz, Julian B. Mu\~noz, Ethan O.
  Nadler, Annika H. G. Peter, Adrian Price-Whelan, Andrew Robertson, Nashwan
  Sabti, Neelima Sehgal, Nora Shipp, Joshua D. Simon, Rajeev Singh, Ken Van
  Tilburg, Risa H. Wechsler, Axel Widmark, and Hai-Bo Yu","Snowmass2021 Cosmic Frontier White Paper: Dark Matter Physics from Halo
  Measurements","White paper submitted to the Proceedings of the US Community Study on
  the Future of Particle Physics (Snowmass 2021). 88 pages, 9 figures. Comments
  welcome",,,,"hep-ph astro-ph.CO astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The non-linear process of cosmic structure formation produces gravitationally
bound overdensities of dark matter known as halos. The abundances, density
profiles, ellipticities, and spins of these halos can be tied to the underlying
fundamental particle physics that governs dark matter at microscopic scales.
Thus, macroscopic measurements of dark matter halos offer a unique opportunity
to determine the underlying properties of dark matter across the vast landscape
of dark matter theories. This white paper summarizes the ongoing rapid
development of theoretical and experimental methods, as well as new
opportunities, to use dark matter halo measurements as a pillar of dark matter
physics.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:53:02 GMT""},{""version"":""v2"",""created"":""Tue, 25 Apr 2023 02:11:29 GMT""}]","2023-04-26"
"2203.07355","Narges Kazempour","Seyed Reza Hoseini Najarkolaei, Narges Kazempour, Hasti Rostami,
  Mohammad Reza Aref","Information-Theoretic Secure and Private Voting System","13 pages",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present a private voting system that consists of N
authorized voters who may vote to one of the K candidates or vote abstain. Each
voter wants to compute the final tally while staying private and robust against
malicious voters, who try to gain information about the vote of the other
voters beyond the final result, or send incorrect information to affect the
final tally. We design an information-theoretic private voting system based on
Shamir secret sharing, which is secure and robust as long as there are up to
(N-1)/3 malicious voters.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:53:35 GMT""}]","2022-03-15"
"2203.07356","Zachariah Addison","Nishchhal Verma, Zachariah Addison, Mohit Randeria","Unified Theory of the Anomalous and Topological Hall Effects with Phase
  Space Berry Curvatures",,,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Hall experiments in chiral magnets are often analyzed as the sum of an
anomalous Hall effect, dominated by momentum-space Berry curvature, and a
topological Hall effect, arising from the real-space Berry curvature in the
presence of skyrmions, in addition to the ordinary Hall resistivity. This
raises the questions of how one can incorporate, on an equal footing, the
effects of the anomalous velocity and the real space winding of the
magnetization, and when such a decomposition of the resistivity is justified.
We provide definitive answers to these questions by including the effects of
all phase-space Berry curvatures in a semi-classical approach and by solving
the Boltzmann equation in a weak spin-orbit coupling regime when the
magnetization texture varies slowly on the scale of the mean free path. We show
that the Hall resistivity is then just the sum of the anomalous and topological
contributions, with negligible corrections from Berry curvature-independent and
mixed curvature terms. We also use an exact Kubo formalism to numerically
investigate the opposite limit of infinite mean path, and show that the results
are similar to the semi-classical results.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:53:41 GMT""},{""version"":""v2"",""created"":""Tue, 15 Mar 2022 01:36:06 GMT""}]","2022-03-16"
"2203.07357","Danielle Berg","Danielle A. Berg, Bethan L. James, Teagan King, Meaghan Mcdonald, Zuyi
  Chen, John Chisholm, Timothy Heckman, Crystal L. Martin, Dan P. Stark, and
  The Classy Team: Alessandra Aloisi, Ricardo O. Amor\'In, Karla Z.
  Arellano-C\'Ordova, Matthew Bayliss, Rongmon Bordoloi, Jarle Brinchmann,
  St\'Ephane Charlot, Jacopo Chevallard, Ilyse Clark, Dawn K. Erb, Anna Feltre,
  Matthew Hayes, Alaina Henry, Svea Hernandez, Anne Jaskot, Tucker Jones, Lisa
  J. Kewley, Nimisha Kumari, Claus Leitherer, Mario Llerena, Michael Maseda,
  Matilde Mingozzi, Themiya Nanayakkara, Masami Ouchi, Adele Plat, Richard W.
  Pogge, Swara Ravindranath, Jane R. Rigby, Ryan Sanders, Claudia Scarlata,
  Peter Senchyna, Evan D. Skillman, Charles C. Steidel, Allison L. Strom, Yuma
  Sugahara, Stephen M. Wilkins, Aida Wofford, Xinfeng Xu","The COS Legacy Archive Spectroscopy SurveY (CLASSY) Treasury Atlas","Accepted for publication in ApJ",,"10.3847/1538-4365/ac6c03",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Far-ultraviolet (FUV; ~1200-2000 angstroms) spectra are fundamental to our
understanding of star-forming galaxies, providing a unique window on massive
stellar populations, chemical evolution, feedback processes, and reionization.
The launch of JWST will soon usher in a new era, pushing the UV spectroscopic
frontier to higher redshifts than ever before, however, its success hinges on a
comprehensive understanding of the massive star populations and gas conditions
that power the observed UV spectral features. This requires a level of detail
that is only possible with a combination of ample wavelength coverage,
signal-to-noise, spectral-resolution, and sample diversity that has not yet
been achieved by any FUV spectral database.
  We present the COS Legacy Spectroscopic SurveY (CLASSY) treasury and its
first high level science product, the CLASSY atlas. CLASSY builds on the HST
archive to construct the first high-quality (S/N_1500 >~ 5/resel),
high-resolution (R~15,000) FUV spectral database of 45 nearby (0.002 < z <
0.182) star-forming galaxies. The CLASSY atlas, available to the public via the
CLASSY website, is the result of optimally extracting and coadding 170
archival+new spectra from 312 orbits of HST observations.
  The CLASSY sample covers a broad range of properties including stellar mass
(6.2 < logM_star(M_sol) < 10.1), star formation rate (-2.0 < log SFR (M_sol/yr)
< +1.6), direct gas-phase metallicity (7.0 < 12+log(O/H) < 8.8), ionization
(0.5 < O_32 < 38.0), reddening (0.02 < E(B-V < 0.67), and nebular density (10 <
n_e (cm^-3) < 1120). CLASSY is biased to UV-bright star-forming galaxies,
resulting in a sample that is consistent with z~0 mass-metallicity
relationship, but is offset to higher SFRs by roughly 2 dex, similar to z >~2
galaxies. This unique set of properties makes the CLASSY atlas the benchmark
training set for star-forming galaxies across cosmic time.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:54:14 GMT""}]","2022-08-03"
"2203.07358","Maria Chamizo-Llatas","Vladimir N Litvinenko, Nikhil Bachhawat, Maria Chamizo-Llatas,
  Francois Meot and Thomas Roser","CERC -- Circular $e^+e^-$ Collider using Energy-Recovery Linac","contribution to Snowmass 2021",,,,"physics.acc-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a Circular Energy Recovery Collider (CERC) as an alternative
approach for a high-energy high-luminosity electron-positron collider to
current designs for high-energy electron-positron colliders either based on two
storage rings with 100 km circumference or two large linear accelerators. Using
Energy Recovery Linacs (ERL) located in the same-size 100 km tunnel would allow
a large reduction of the beam energy losses, and therefore a reduction of the
power consumption, while providing higher luminosity. It also opens a path for
extending the center-of-mass (CM) energy to 500 GeV, which would enable
double-Higgs production, and even to 600 GeV for production and measurements of
the top Yukawa coupling. Furthermore, this approach would allow recycling of
not only the energy but also of the particles. This feature opens the
possibility for colliding fully polarized electron and positron beams.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:54:57 GMT""}]","2022-03-24"
"2203.07359","Zhang-Wei Hong","Haokuan Luo, Albert Yue, Zhang-Wei Hong, Pulkit Agrawal","Stubborn: A Strong Baseline for Indoor Object Navigation",,,,,"cs.RO cs.AI","http://creativecommons.org/licenses/by/4.0/","  We present a strong baseline that surpasses the performance of previously
published methods on the Habitat Challenge task of navigating to a target
object in indoor environments. Our method is motivated from primary failure
modes of prior state-of-the-art: poor exploration, inaccurate object
identification, and agent getting trapped due to imprecise map construction. We
make three contributions to mitigate these issues: (i) First, we show that
existing map-based methods fail to effectively use semantic clues for
exploration. We present a semantic-agnostic exploration strategy (called
Stubborn) without any learning that surprisingly outperforms prior work. (ii)
We propose a strategy for integrating temporal information to improve object
identification. (iii) Lastly, due to inaccurate depth observation the agent
often gets trapped in small regions. We develop a multi-scale collision map for
obstacle identification that mitigates this issue.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:55:00 GMT""}]","2022-03-15"
"2203.07360","Marcos Santander","Kristi Engel, Jordan Goodman, Petra Huentemeyer, Carolyn Kierans,
  Tiffany R. Lewis, Michela Negro, Marcos Santander, David A. Williams, Alice
  Allen, Tsuguo Aramaki, Rafael Alves Batista, Mathieu Benoit, Peter Bloser,
  Jennifer Bohon, Aleksey E. Bolotnikov, Isabella Brewer, Michael S. Briggs,
  Chad Brisbois, J. Michael Burgess, Eric Burns, Regina Caputo, Gabriella A.
  Carini, S. Bradley Cenko, Eric Charles, Stefano Ciprini, Valerio D'Elia,
  Tansu Daylan, James Distel, Axel Donath, Wade Duvall, Henrike Fleischhack,
  Corinne Fletcher, Wen Fe Fong, Dario Gasparrini, Marco Giardino, Adam
  Goldstein, Sean Griffin, J. Eric Grove, Rachel Hamburg, J. Patrick Harding,
  Jeremy Hare, Boyan Hristov, C. Michelle Hui, Tess Jaffe, Pete Jenke, Oleg
  Kargaltsev, Christopher M. Karwin, Matthew Kerr, Dongsung Kim, Daniel
  Kocevski, John Krizmanic, Ranjan Laha, Niccolo Di Lalla, Jason Legere,
  Cristina Leto, Richard Leys, Fabrizio Lucarelli, Israel Martinez-Castellanos,
  Alessandro Maselli, M. Nicola Mazziotta, Mark McConnell, Julie McEnery,
  Jessica Metcalfe, Manuel Meyer, Alexander A. Moiseev, Reshmi Mukherjee,
  Michela Negro, Keiichi Ogasawara, Nicola Omodei, Ivan Peric, Jeremy S.
  Perkins, Matteo Perri, Carlotta Pittori, Gianluca Polenta, Daniel Poulson,
  Robert Preece, Giacomo Principe, Judith L. Racusin, Oliver Roberts, Nicholas
  L. Rodd, Peter Shawhan, Thomas Shutt, Clio Sleator, Alan Smale, John Smedley,
  Jacob R. Smith, Jay Tasson, Peter Teuben, John Tomsick, Peter Veres,
  Francesco Verrecchia, Zorawar Wadiasingh, Colleen A. Wilson-Hodge, Joshua
  Wood, Richard S. Woolf, Hui Yang, Bing Zhang, Haocheng Zhang, Andreas
  Zoglauer","The Future of Gamma-Ray Experiments in the MeV-EeV Range","Contribution to Snowmass 2021",,,,"astro-ph.HE astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  Gamma-rays, the most energetic photons, carry information from the far
reaches of extragalactic space with minimal interaction or loss of information.
They bring messages about particle acceleration in environments so extreme they
cannot be reproduced on earth for a closer look. Gamma-ray astrophysics is so
complementary with collider work that particle physicists and astroparticle
physicists are often one in the same. Gamma-ray instruments, especially the
Fermi Gamma-ray Space Telescope, have been pivotal in major multi-messenger
discoveries over the past decade. There is presently a great deal of interest
and scientific expertise available to push forward new technologies, to plan
and build space- and ground-based gamma-ray facilities, and to build
multi-messenger networks with gamma rays at their core. It is therefore
concerning that before the community comes together for planning exercises
again, much of that infrastructure could be lost to a lack of long-term
planning for support of gamma-ray astrophysics. Gamma-rays with energies from
the MeV to the EeV band are therefore central to multiwavelength and
multi-messenger studies to everything from astroparticle physics with compact
objects, to dark matter studies with diffuse large scale structure. These goals
and new discoveries have generated a wave of new gamma-ray facility proposals
and programs. This paper highlights new and proposed gamma-ray technologies and
facilities that have each been designed to address specific needs in the
measurement of extreme astrophysical sources that probe some of the most
pressing questions in fundamental physics for the next decade. The proposed
instrumentation would also address the priorities laid out in the recent
Astro2020 Decadal Survey, a complementary study by the astrophysics community
that provides opportunities also relevant to Snowmass.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:55:06 GMT""}]","2022-03-15"
"2203.07361","Louis Strigari","M. Abdullah, H. Abele, D. Akimov, G. Angloher, D. Aristizabal-Sierra,
  C. Augier, A. B. Balantekin, L. Balogh, P. S. Barbeau, L. Baudis, A. L.
  Baxter, C. Beaufort, G. Beaulieu, V. Belov, A. Bento, L. Berge, I. A.
  Bernardi, J. Billard, A. Bolozdynya, A. Bonhomme, G. Bres, J-.L. Bret, A.
  Broniatowski, A. Brossard, C. Buck, M. Cadeddu, M. Calvo, L. Canonica, F.
  Cappella, L. Cardani, N. Casali, A. Cazes, R. Cerulli, D. Chaize, C. Chang,
  M. Chapellier, L. Chaplinsky, G. Chemin, R. Chen, I. Colantoni, J. Colas, P.
  Coloma, E. C. Corcoran, S. Crawford, A. Cruciani, A. Dastgheibi Fard, M. De
  Jesus, P. de Marcillac, V. De Romeri, G. del Castello, M. del
  GalloRoccagiovine, D. Delicato, M. Demarteau, Y. Deng, J. B. Dent, P. B.
  Denton, K. Dering, A. Doblhammer, F. Dordei, S. Dorer, L. Dumoulin, D.
  Dunford, B. Dutta, A. Erhart, O. Exshaw, S. Ferriol, E. Figueroa-Feliciano,
  J. B. Filippini, L .J. Flores, J. A. Formaggio, M. Friedl, S. Fuard, F. Gao,
  A. Garai, E. A. Garces, J. Gascon, J. Gehrlein, G. Gerbier, V. M. Ghete, I.
  Giomataris, G. Giroux, A. Giuliani, C. Giunti, P. Gorel, C. Goupy, J. Goupy,
  C. Goy, M. P. Green, M. Gros, C. Guerin, V. Guidi, O. Guillaudin, E. Guy, C.
  Ha, D. Hauff, J. Hakenmuller, P. M. Harrington, S. Hedges, S. T. Heine, S.
  Hertel, M. Heusch, C. Hoarau, M. Hoferichter, E. W. Hoppe, Z. Hong, S.
  Horiuchi, P. Huber, J. C. Ianigro, N. Jachowicz, E. Jericha, Y. Jin, J. P.
  Johnston, A. Juillard, I. Katsioulas, S. Kazarcev, M. Kaznacheeva, F. Kelly,
  K. J. Kelly, D. Kim, A. Kinast, L. Klinkenberg, H. Kluck, P. Knights, Y. J.
  Ko, T. S. Kosmas, L. Kwon, J. Lamblin, R. F. Lang, A. Langenkamper, S.
  Langrock, T. Lasserre, H. Lattaud, P. Lautridou, H. S. Lee, B. G. Lenardo, D.
  Lhuillier, M. Li, S. C. Li, Y. F. Li, Z. Li, M. Lindner, J. Liu, D. Loomba,
  A. Lubashevskiy, P. A. N. Machado, M. Mancuso, W. Maneschg, D. M. Markoff, S.
  Marnieros, R. Martin, R. D. Martin, B. Mauri, D. W. Mayer, A. Mazzolari, E.
  Mazzucato, J. Menendez, J. Minet, O. G. Miranda, D. Misiak, J.-P. Mols, A.
  Monfardini, F. Mounier, J. F. Muraz, T. Neep, R. Neilson, J. Newby, J. L.
  Newstead, H. Neyrial, K. Ni, K. Nikolopoulos, C. Nones, D. Norcini, V.
  Pandey, P. O'Brien, C. A. J. O'Hare, L. Oberauer, W. Oliver, E. Olivieri, A.
  Onillon, C. Oriol, T. Ortmann, R. Owen, K. J. Palladino, D. K. Papoulias, J.
  C. Park, D. S. Parno, P. K. Patel, L. Pattavina, E. Peinado, E. Perbet, L.
  Peters, F. Petricca, H. D. Pinckney, M.-C. Piro, D. Ponomarev, D. Poda, W.
  Potzel, F. Probst, F. Pucci, F. Rarbi, R. Rapp, H.Ray, J.-S.Real, F. Reindl,
  G.C.Rich, J.S.Ricol, T.Rink, T.Redon, R.Rogly, A.Robert, J.Rothe, S.Rozov,
  I.Rozova, T.Salagnac, E.Sanchez Garcia, G.Sanchez Garcia, O.Sanders,
  V.Sanglard, D.Santos, Y.Sarkis, V.Savu, G.Savvidis, I. Savvidis, N. Schermer,
  J. Schieck, B. Schmidt, S. Schonert, K. Scholberg, A. Schwenk, C. Schwertner,
  L. Scola, Ye. Shevchik, S. Shin, V. Sibille, I. M. Shoemaker, D. P.
  Snowden-Ifft, T. Soldner, G. Soum, N. J. C. Spooner, J. Stachurska, L.
  Stodolsky, R. Strauss, L. E. Strigari, A. Stutz, B. D. Suh, J. Suhonen, Z.
  Tabrizi, V. Takhistov, A. Thompson, C. Tomei, M. Tortola, M. Tripathi, L.
  Vagneron, J. W. F. Valle, K. v. Mirbach, W. Van De Ponteseele, M. Vignati, M.
  Vivier, F. Vazquez de Sola Fernandez, F. Vezzu, M. Vidal, V. Wagner, J. W.
  Walker, R. Ward, A. Wex, L. Winslow, H. T. Wong, M. H. Wood, J. Xu, L. Yang,
  E. Yakushev, M. Zampaolo, J. Zettlemoyer, Y. Y. Zhang, D. Zinatulina","Coherent elastic neutrino-nucleus scattering: Terrestrial and
  astrophysical applications","contribution to Snowmasss 2021. Contact authors: P. S. Barbeau, R.
  Strauss, L. E. Strigari",,,,"hep-ph astro-ph.HE hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Coherent elastic neutrino-nucleus scattering (CE$\nu$NS) is a process in
which neutrinos scatter on a nucleus which acts as a single particle. Though
the total cross section is large by neutrino standards, CE$\nu$NS has long
proven difficult to detect, since the deposited energy into the nucleus is
$\sim$ keV. In 2017, the COHERENT collaboration announced the detection of
CE$\nu$NS using a stopped-pion source with CsI detectors, followed up the
detection of CE$\nu$NS using an Ar target. The detection of CE$\nu$NS has
spawned a flurry of activities in high-energy physics, inspiring new
constraints on beyond the Standard Model (BSM) physics, and new experimental
methods. The CE$\nu$NS process has important implications for not only
high-energy physics, but also astrophysics, nuclear physics, and beyond. This
whitepaper discusses the scientific importance of CE$\nu$NS, highlighting how
present experiments such as COHERENT are informing theory, and also how future
experiments will provide a wealth of information across the aforementioned
fields of physics.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:55:28 GMT""}]","2022-03-15"
"2203.07362","Jens Lemmens","Jens Lemmens, Jens Van Nooten, Tim Kreutz, Walter Daelemans","CoNTACT: A Dutch COVID-19 Adapted BERT for Vaccine Hesitancy and
  Argumentation Detection",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  We present CoNTACT: a Dutch language model adapted to the domain of COVID-19
tweets. The model was developed by continuing the pre-training phase of RobBERT
(Delobelle, 2020) by using 2.8M Dutch COVID-19 related tweets posted in 2021.
In order to test the performance of the model and compare it to RobBERT, the
two models were tested on two tasks: (1) binary vaccine hesitancy detection and
(2) detection of arguments for vaccine hesitancy. For both tasks, not only
Twitter but also Facebook data was used to show cross-genre performance. In our
experiments, CoNTACT showed statistically significant gains over RobBERT in all
experiments for task 1. For task 2, we observed substantial improvements in
virtually all classes in all experiments. An error analysis indicated that the
domain adaptation yielded better representations of domain-specific
terminology, causing CoNTACT to make more accurate classification decisions.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:55:32 GMT""}]","2022-03-15"
"2203.07363","Xuelian Cheng","Xuelian Cheng, Huan Xiong, Deng-Ping Fan, Yiran Zhong, Mehrtash
  Harandi, Tom Drummond, Zongyuan Ge","Implicit Motion Handling for Video Camouflaged Object Detection","Accepted to CVPR 2022; Xuelian Cheng and Huan Xiong made equal
  contributions; Corresponding author: Deng-Ping Fan (dengpfan@gmail.com).
  Dataset: https://xueliancheng.github.io/SLT-Net-project",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new video camouflaged object detection (VCOD) framework that can
exploit both short-term dynamics and long-term temporal consistency to detect
camouflaged objects from video frames. An essential property of camouflaged
objects is that they usually exhibit patterns similar to the background and
thus make them hard to identify from still images. Therefore, effectively
handling temporal dynamics in videos becomes the key for the VCOD task as the
camouflaged objects will be noticeable when they move. However, current VCOD
methods often leverage homography or optical flows to represent motions, where
the detection error may accumulate from both the motion estimation error and
the segmentation error. On the other hand, our method unifies motion estimation
and object segmentation within a single optimization framework. Specifically,
we build a dense correlation volume to implicitly capture motions between
neighbouring frames and utilize the final segmentation supervision to optimize
the implicit motion estimation and segmentation jointly. Furthermore, to
enforce temporal consistency within a video sequence, we jointly utilize a
spatio-temporal transformer to refine the short-term predictions. Extensive
experiments on VCOD benchmarks demonstrate the architectural effectiveness of
our approach. We also provide a large-scale VCOD dataset named MoCA-Mask with
pixel-level handcrafted ground-truth masks and construct a comprehensive VCOD
benchmark with previous methods to facilitate research in this direction.
Dataset Link: https://xueliancheng.github.io/SLT-Net-project.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:55:41 GMT""},{""version"":""v2"",""created"":""Tue, 15 Mar 2022 13:44:01 GMT""}]","2022-03-16"
"2203.07364","Nathan McJames","Nathan McJames, David Malone, Oliver Mason","A Supervised Learning Approach to Rankability","12 pages",,,,"math.CO cs.LG stat.ML","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The rankability of data is a recently proposed problem that considers the
ability of a dataset, represented as a graph, to produce a meaningful ranking
of the items it contains. To study this concept, a number of rankability
measures have recently been proposed, based on comparisons to a complete
dominance graph via combinatorial and linear algebraic methods. In this paper,
we review these measures and highlight some questions to which they give rise
before going on to propose new methods to assess rankability, which are
amenable to efficient estimation. Finally, we compare these measures by
applying them to both synthetic and real-life sports data.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:55:43 GMT""}]","2022-03-15"
"2203.07365","HyeokJun Yang","Hyeok-Jun Yang, Hee Seung Kim, Min Yong Jeong, Yong Baek Kim, Myung
  Joon Han, SungBin Lee","Intertwining orbital current order and superconductivity in Kagome metal","22 pages, 8 figures",,,,"cond-mat.supr-con cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The nature of superconductivity in newly discovered Kagome materials,
$\text{AV}_3\text{Sb}_5$ (A=K, Rb, Cs), has been a subject of intense debate.
Recent experiments suggest the presence of orbital current order on top of the
charge density wave (CDW) and superconductivity. Since the orbital current
order breaks time-reversal symmetry, it may fundamentally affect possible
superconducting states. In this work, we investigate the mutual influence
between the orbital current order and superconductivity in Kagome metal with
characteristic van Hove singularity (vHS). By explicitly deriving the
Landau-Ginzburg theory, we classify possible orbital current order and
superconductivity. It turns out that distinct unconventional
superconductivities are expected, depending on the orbital current ordering
types. Thus, this information can be used to infer the superconducting order
parameter when the orbital current order is identified and vice versa. We also
discuss possible experiments that may distinguish such superconducting states
coexisting with the orbital current order.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:56:00 GMT""},{""version"":""v2"",""created"":""Wed, 14 Sep 2022 07:35:22 GMT""}]","2022-09-15"
"2203.07366","Anant Kale","Anant Kale, Jakob Hendrik Huhn, Muqing Xu, Lev Haldar Kendrick, Martin
  Lebrat, Christie Chiu, Geoffrey Ji, Fabian Grusdt, Annabelle Bohrdt, Markus
  Greiner","Schrieffer-Wolff Transformations for Experiments: Dynamically
  Suppressing Virtual Doublon-Hole Excitations in a Fermi-Hubbard Simulator","18 pages, 4 figures. Updated author list, and revised figures to meet
  submission guidelines","Phys. Rev. A 106, 012428 (2022)","10.1103/PhysRevA.106.012428",,"cond-mat.quant-gas quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In strongly interacting systems with a separation of energy scales,
low-energy effective Hamiltonians help provide insights into the relevant
physics at low temperatures. The emergent interactions in the effective model
are mediated by virtual excitations of high-energy states: For example, virtual
doublon-hole excitations in the Fermi-Hubbard model mediate antiferromagnetic
spin-exchange interactions in the derived effective model, known as the
$t-J-3s$ model. Formally this procedure is described by performing a unitary
Schrieffer-Wolff basis transformation. In the context of quantum simulation, it
can be advantageous to consider the effective model to interpret experimental
results. However, virtual excitations such as doublon-hole pairs can obfuscate
the measurement of physical observables. Here we show that quantum simulators
allow one to access the effective model even more directly by performing
measurements in a rotated basis. We propose a protocol to perform a
Schrieffer-Wolff transformation on Fermi-Hubbard low-energy eigenstates (or
thermal states) to dynamically prepare approximate $t-J-3s$ model states using
fermionic atoms in an optical lattice. Our protocol involves performing a
linear ramp of the optical lattice depth, which is slow enough to eliminate the
virtual doublon-hole fluctuations but fast enough to freeze out the dynamics in
the effective model. We perform a numerical study using exact diagonalization
and find an optimal ramp speed for which the state after the lattice ramp has
maximal overlap with the $t-J-3s$ model state. We compare our numerics to
experimental data from our Lithium-6 fermionic quantum gas microscope and show
a proof-of-principle demonstration of this protocol. More generally, this
protocol can be beneficial to studies of effective models by enabling the
suppression of virtual excitations in a wide range of quantum simulation
experiments.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:56:49 GMT""},{""version"":""v2"",""created"":""Wed, 4 May 2022 15:33:09 GMT""}]","2022-08-12"
"2203.07367","Milan Kornja\v{c}a","Milan Kornja\v{c}a and Rebecca Flint","Algebraic Hastatic Order in One-Dimensional Two-Channel Kondo Lattice","6+5 pages, 4+3 figures",,,,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The two-channel Kondo lattice likely hosts a rich array of phases, including
hastatic order, a channel-symmetry breaking heavy Fermi liquid. We revisit its
one-dimensional phase diagram using density matrix renormalization group. In
contrast to previous work, we find algebraic hastatic orders generically for
strong coupling. These are heavy Tomonaga-Luttinger liquids with
nonanalyticities at Fermi wave-vectors captured by hastatic density waves.
Intriguingly, we find a recently predicted additional order parameter, not
present at large-$N$, arising from RKKY mediated interference between hastatic
spinors, and indications of residual repulsive interactions at strong coupling.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:58:40 GMT""}]","2022-03-15"
"2203.07368","Yuling Yan","Yuling Yan, Gen Li, Yuxin Chen, Jianqing Fan","The Efficacy of Pessimism in Asynchronous Q-Learning",,,,,"cs.LG cs.IT math.IT math.OC math.ST stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is concerned with the asynchronous form of Q-learning, which
applies a stochastic approximation scheme to Markovian data samples. Motivated
by the recent advances in offline reinforcement learning, we develop an
algorithmic framework that incorporates the principle of pessimism into
asynchronous Q-learning, which penalizes infrequently-visited state-action
pairs based on suitable lower confidence bounds (LCBs). This framework leads
to, among other things, improved sample efficiency and enhanced adaptivity in
the presence of near-expert data. Our approach permits the observed data in
some important scenarios to cover only partial state-action space, which is in
stark contrast to prior theory that requires uniform coverage of all
state-action pairs. When coupled with the idea of variance reduction,
asynchronous Q-learning with LCB penalization achieves near-optimal sample
complexity, provided that the target accuracy level is small enough. In
comparison, prior works were suboptimal in terms of the dependency on the
effective horizon even when i.i.d. sampling is permitted. Our results deliver
the first theoretical support for the use of pessimism principle in the
presence of Markovian non-i.i.d. data.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:59:01 GMT""}]","2022-03-15"
"2203.07369","Laurin  E. Fischer","Laurin E. Fischer, Daniel Miller, Francesco Tacchino, Panagiotis Kl.
  Barkoutsos, Daniel J. Egger, Ivano Tavernelli","Ancilla-free implementation of generalized measurements for qubits
  embedded in a qudit space","9+10 pages, 5+5 figures, 1+1 tables","Phys. Rev. Research 4, 033027 (2022)","10.1103/PhysRevResearch.4.033027",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Informationally complete (IC) positive operator-valued measures (POVMs) are
generalized quantum measurements that offer advantages over the standard
computational basis readout of qubits. For instance, IC-POVMs enable efficient
extraction of operator expectation values, a crucial step in many quantum
algorithms. POVM measurements are typically implemented by coupling one
additional ancilla qubit to each logical qubit, thus imposing high demands on
the device size and connectivity. Here, we show how to implement a general
class of IC-POVMs without ancilla qubits. We exploit the higher-dimensional
Hilbert space of a qudit in which qubits are often encoded. POVMs can then be
realized by coupling each qubit to two of the available qudit states, followed
by a projective measurement. We develop the required control pulse sequences
and numerically establish their feasibility for superconducting transmon qubits
through pulse-level simulations. Finally, we present an experimental
demonstration of a qudit-space POVM measurement on IBM Quantum hardware. This
paves the way to making POVM measurements broadly available to quantum
computing applications.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:59:59 GMT""}]","2022-07-27"
"2203.07377","Evan Grohs","Martina Gerbino, Evan Grohs, Massimiliano Lattanzi, Kevork N.
  Abazajian, Nikita Blinov, Thejs Brinckmann, Mu-Chun Chen, Zelimir Djurcic,
  Peizhi Du, Miguel Escudero, Steffen Hagstotz, Kevin J. Kelly, Christiane S.
  Lorenz, Marilena Loverde, Pablo Mart\'inez-Mirav\'e, Olga Mena, Joel Meyers,
  Walter Pettus, Ninetta Saviano, Anna M. Suliga, Volodymyr Takhistov, Mariam
  T\'ortola, Jos\'e W. F. Valle, Benjamin Wallisch","Synergy between cosmological and laboratory searches in neutrino physics","Originally prepared for submission to the Snowmass Community Planning
  Exercise, 2021; Reformatted for submission to Physics of the Dark Universe;
  128 pages; 9 Figures",,,,"hep-ph astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  The intersection of the cosmic and neutrino frontiers is a rich field where
much discovery space still remains. Neutrinos play a pivotal role in the hot
big bang cosmology, influencing the dynamics of the universe over numerous
decades in cosmological history. Recent studies have made tremendous progress
in understanding some properties of cosmological neutrinos, primarily their
energy density. Upcoming cosmological probes will give higher precision on the
energy density, but could also start probing other properties of the neutrino
spectra. When convolved with results from terrestrial experiments, cosmology
can become even more acute at probing new physics related to neutrinos or even
Beyond the Standard Model (BSM). Any discordance between laboratory and
cosmological data sets may reveal new BSM physics or suggest alternative models
of cosmology. We give examples of the intersection between terrestrial and
cosmological probes in the neutrino sector, and briefly discuss the
possibilities of what different experiments may see in conjunction with
cosmological observatories.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:13:30 GMT""},{""version"":""v2"",""created"":""Fri, 24 Feb 2023 22:54:51 GMT""}]","2023-02-28"
"2203.07380","John Sous","C. Zhang, J. Sous, D. R. Reichman, M. Berciu, A. J. Millis, N. V.
  Prokof'ev, B. V. Svistunov","Bipolaronic high-temperature superconductivity","6 pages main text + 12 pages appendices, 5 figures main text + 11
  figures appendices","Phys. Rev. X 13, 011010 (2023)","10.1103/PhysRevX.13.011010",,"cond-mat.supr-con cond-mat.mtrl-sci cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Electron-lattice interactions play a prominent role in quantum materials,
making a deeper understanding of direct routes to phonon-mediated
high-transition-temperature ($T_{\mathrm{c}}$) superconductivity desirable.
However, it has been known for decades that weak electron-phonon coupling gives
rise to low values of $T_{\mathrm{c}}$, while strong electron-phonon coupling
leads to lattice instability or formation of bipolarons, generally assumed to
be detrimental to superconductivity. Thus, the route to high-$T_{\mathrm{c}}$
materials from phonon-mediated mechanisms has heretofore appeared to be limited
to raising the phonon frequency as in the hydrogen sulfides. Here we present a
simple model for phonon-mediated high-$T_{\mathrm{c}}$ superconductivity based
on superfluidity of light bipolarons. In contrast to the widely studied
Holstein model where lattice distortions modulate the electron's potential
energy, we investigate the situation where lattice distortions modulate the
electron hopping. This physics gives rise to small-size, yet light bipolarons,
which we study using an exact sign-problem-free quantum Monte Carlo approach,
demonstrating a new route to phonon-mediated high-$T_\mathrm{c}$
superconductivity. We find that $T_\mathrm{c}$ in our model generically and
significantly exceeds typical upper bounds based on Migdal-Eliashberg theory or
superfluidity of Holstein bipolarons. The key ingredient in this bipolaronic
mechanism that gives rise to high $T_\mathrm{c}$ is the combination of light
mass and small size of bipolarons. Our work establishes principles towards the
design of high-$T_{\mathrm{c}}$ superconductors via functional material
engineering.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:00:00 GMT""},{""version"":""v2"",""created"":""Mon, 21 Mar 2022 22:47:23 GMT""},{""version"":""v3"",""created"":""Thu, 1 Dec 2022 18:27:32 GMT""},{""version"":""v4"",""created"":""Sat, 14 Jan 2023 19:41:00 GMT""},{""version"":""v5"",""created"":""Thu, 2 Feb 2023 04:41:07 GMT""}]","2023-02-03"
"2203.07381","Clara Murgui","Pavel Fileviez Perez and Clara Murgui","Flavor Anomalies and Quark-Lepton Unification","26 pages, 5 figures. v2: new references have been added, the bound on
  the contribution from new physics to \Delta m_{B_s} has been reduced from 50%
  to 10%. PRD version","Phys. Rev. D 106, 035033 (2022)","10.1103/PhysRevD.106.035033",,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that one can explain the neutral and charged anomalies in B-meson
decays in the minimal theory for quark-lepton unification.The implications for
flavor violating processes are discussed in detail. Strikingly, experimental
observations suggest that the unification of quarks and leptons could be
realized below the ${\cal O}(10^2)$ TeV scale.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:00:00 GMT""},{""version"":""v2"",""created"":""Sat, 10 Sep 2022 14:50:48 GMT""}]","2022-09-13"
"2203.07382","Michael Kuhn","Michael A. Kuhn (1), Lynne A. Hillenbrand (1), Eric D. Feigelson (2),
  Ian Fowler (1), Konstantin V. Getman (2), Patrick S. Broos (2), Matthew S.
  Povich (3), Mariusz Gromadzki (4) ((1) Caltech, (2) Pennsylvania State
  University, (3) Cal Poly Pomona, (4) University of Warsaw)","The Effect of Molecular Cloud Properties on the Kinematics of Stars
  Formed in the Trifid Region","Accepted for publication in ApJ. 26 pages, 18 figures, and 4 tables.
  Minor style changes have been applied to match the published version",,"10.3847/1538-4357/ac6fe8",,"astro-ph.GA astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The dynamical states of molecular clouds may affect the properties of the
stars they form. In the vicinity of the Trifid Nebula ($d=1180\pm25$ pc), the
main star cluster (Trifid Main) lies within an expanding section of the
molecular cloud; however, ~0.3 deg to the north (Trifid North), the cloud's
velocity structure is more tranquil. We acquired a Chandra X-ray observation to
identify pre-main-sequence stars in Trifid North, complementing a previous
observation of Trifid Main. In Trifid North, we identified 51 candidate
pre-main-sequence stars, of which 13 are high-confidence Trifid members based
on Gaia EDR3 parallaxes and proper motions. We also re-analyzed membership of
Trifid Main and separated out multiple background stellar associations. Trifid
North represents a stellar population ~10% as rich as Trifid Main that formed
in a separate part of the cloud. The 1D stellar velocity dispersion in Trifid
North ($0.6\pm0.2$ km/s) is three times lower than in Trifid Main ($1.9\pm0.2$
km/s). Furthermore, in Trifid Main, proper motions indicate that the portion of
the star cluster superimposed on the optical nebula is expanding. Expansion of
the HII region around the O-star HD 164492A, and the resulting gas expulsion,
can explain both the motions of the stars and gas in Trifid Main. Contrary to
previous studies, we find no evidence that a cloud-cloud collision triggered
star formation in the region.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:00:00 GMT""},{""version"":""v2"",""created"":""Thu, 24 Mar 2022 18:41:32 GMT""},{""version"":""v3"",""created"":""Thu, 15 Sep 2022 18:45:08 GMT""}]","2022-10-05"
"2203.07383","R\""udiger Pakmor","Ruediger Pakmor, Christine M. Simpson, Freeke van de Voort, Lars
  Hernquist, Lieke van Son, Martyna Chru\'sli\'nska, Rebekka Bieri, Selma E. de
  Mink, Volker Springel","Formation and fate of low metallicity stars in IllustrisTNG50","15 pages, 11 figures, accepted by MNRAS, comments welcome",,"10.1093/mnras/stac717",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Low metallicity stars give rise to unique spectacular transients and are of
immense interest for understanding stellar evolution. Their importance has only
grown further with the recent detections of mergers of stellar mass black holes
that likely originate mainly from low metallicity progenitor systems. Moreover,
the formation of low metallicity stars is intricately linked to galaxy
evolution, in particular to early enrichment and to later accretion and mixing
of lower metallicity gas. Because low metallicity stars are difficult to
observe directly, cosmological simulations are crucial for understanding their
formation. Here we quantify the rates and locations of low metallicity star
formation using the high-resolution TNG50 magnetohydrodynamical cosmological
simulation, and we examine where low metallicity stars end up at $z=0$. We find
that $20\%$ of stars with $Z_*<0.1\,\mathrm{Z_\odot}$ form after $z=2$, and
that such stars are still forming in galaxies of all masses at $z=0$ today.
Moreover, most low-metallicity stars at $z=0$ reside in massive galaxies. We
analyse the radial distribution of low metallicity star formation, and discuss
the curious case of seven galaxies in TNG50 that form stars from primordial gas
even at $z=0$.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:00:00 GMT""}]","2022-03-30"
"2203.07384","Luca Iliesiu","Andreas Blommaert, Luca V. Iliesiu, Jorrit Kruthoff","Alpha states demystified: Towards microscopic models of AdS$_2$
  holography","46 pages, 6 figures",,"10.1007/JHEP08(2022)071",,"hep-th gr-qc","http://creativecommons.org/publicdomain/zero/1.0/","  We continue our study of factorizing theories of dilaton gravity,
characterized by a universal bilocal interaction. All such factorizing theories
can be shown to have discrete spectra, distinguished only by their local
dilaton potentials. We show how such theories can be used to construct all
alpha-states in the Hilbert space of baby universes of ordinary JT gravity.
Large classes of these theories with different local potentials are found to be
non-perturbatively equivalent and have identical discrete spectra. This is a
concrete example of how different bulk descriptions can give rise to the same
boundary theory. Such equivalences manifest themselves as null states, which
have to be quotiented out in order to construct a proper baby universe Hilbert
space. Our results also allow us to revisit the mechanism discussed by Coleman,
Giddings, and Strominger, and concretely link ensemble averaging to the
appearance or disappearance of spacetime wormholes. We then investigate JT
gravity deformed only by the universal bilocal interaction. In this theory, the
only terms that do not cancel in a topological expansion are disks, which
capture perturbative fluctuations around a two-dimensional black hole saddle.
We find that this theory of black holes has an evenly spaced spectrum, instead
of a quantum chaotic one. We present a dual quantum mechanical system with
exactly the same discrete spectrum, and propose that this is an example of a
new holographic duality between a two-dimensional theory of quantum gravity and
a conventional quantum mechanics.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:00:00 GMT""}]","2022-08-24"
"2203.07385","Jenna Samuel","Jenna Samuel, Andrew Wetzel, Isaiah Santistevan, Erik Tollerud, Jorge
  Moreno, Michael Boylan-Kolchin, Jeremy Bailin, Bhavya Pardasani","Extinguishing the FIRE: environmental quenching of satellite galaxies
  around Milky Way-mass hosts in simulations","17 pages, 13 figures, + appendices. Accepted by MNRAS",,"10.1093/mnras/stac1706",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  The star formation and gas content of satellite galaxies around the Milky Way
(MW) and Andromeda (M31) are depleted relative to more isolated galaxies in the
Local Group (LG) at fixed stellar mass. We explore the environmental regulation
of gas content and quenching of star formation in $z=0$ galaxies at
$M*=10^{5-10}\rm{M}_{\odot}$ around 14 MW-mass hosts from the FIRE-2
simulations. Lower-mass satellites ($M*\lesssim10^7\rm{M}_{\odot}$) are mostly
quiescent and higher-mass satellites ($M*\gtrsim10^8\rm{M}_{\odot}$) are mostly
star-forming, with intermediate-mass satellites
($M*\approx10^{7-8}\rm{M}_{\odot}$) split roughly equally between quiescent and
star-forming. Hosts with more gas in their circumgalactic medium have a higher
quiescent fraction of massive satellites ($M*=10^{8-9}\rm{M}_{\odot}$). We find
no significant dependence on isolated versus paired (LG-like) host
environments, and the quiescent fractions of satellites around MW-mass and
LMC-mass hosts from the FIRE-2 simulations are remarkably similar.
Environmental effects that lead to quenching can also occur as preprocessing in
low-mass groups prior to MW infall. Lower-mass satellites typically quenched
before MW infall as central galaxies or rapidly during infall into a low-mass
group or a MW-mass galaxy. Most intermediate- to high-mass quiescent satellites
have experienced $\geq1-2$ pericentre passages ($\approx2.5-5$ Gyr) within a
MW-mass halo. Most galaxies with $M*\gtrsim10^{6.5}\rm{M}_{\odot}$ did not
quench before falling into a host, indicating a possible upper mass limit for
isolated quenching. The simulations reproduce the average trend in the LG
quiescent fraction across the full range of satellite stellar masses. Though
the simulations are consistent with the SAGA survey's quiescent fraction at
$M*\gtrsim10^8\rm{M}_{\odot}$, they do not generally reproduce SAGA's turnover
at lower masses.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:00:01 GMT""},{""version"":""v2"",""created"":""Fri, 17 Jun 2022 18:21:17 GMT""}]","2022-06-22"
"2203.07386","Andrea Fontanella","Andrea Fontanella and Stijn J. van Tongeren","Coset space actions for nonrelativistic strings","28 pages, v3: introduction and references improved, matching the
  published version in JHEP",,"10.1007/JHEP06(2022)080","HU-EP-22/09","hep-th","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We formulate the stringy nonrelativistic limits of the flat space and
AdS$_5\times$S$^5$ string as coset models, based on the string Bargmann and
extended string Newton-Hooke algebras respectively. Our construction mimics the
typical relativistic one, but differs in several interesting ways. Using our
coset formulation we give a Lax representation of the equations of motion of
both models.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:00:01 GMT""},{""version"":""v2"",""created"":""Fri, 18 Mar 2022 20:00:56 GMT""},{""version"":""v3"",""created"":""Tue, 21 Jun 2022 09:55:14 GMT""}]","2022-07-06"
"2203.07387","Mitchell Revalski","Mitchell Revalski, D. Michael Crenshaw, Marc Rafelski, Steven B.
  Kraemer, Garrett E. Polack, Anna Trindade Falc\~ao, Travis C. Fischer, Beena
  Meena, Francisco Martinez, Henrique R. Schmitt, Nicholas R. Collins, Julia
  Falcone","Quantifying Feedback from Narrow Line Region Outflows in Nearby Active
  Galaxies. IV. The Effects of Different Density Estimates on the Ionized Gas
  Masses and Outflow Rates","Accepted for Publication in ApJ on March 11, 2022. The paper has 20
  pages and 8 figures, with results tabulated in the Appendix. Version two
  includes minor corrections to match the journal publication",,"10.3847/1538-4357/ac5f3d",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Active galactic nuclei (AGN) can launch outflows of ionized gas that may
influence galaxy evolution, and quantifying their full impact requires
spatially resolved measurements of the gas masses, velocities, and radial
extents. We previously reported these quantities for the ionized narrow-line
region (NLR) outflows in six low-redshift AGN, where the gas velocities and
extents were determined from Hubble Space Telescope long-slit spectroscopy.
However, calculating the gas masses required multi-component photoionization
models to account for radial variations in the gas densities, which span
$\sim$6 orders of magnitude. In order to simplify this method for larger
samples with less spectral coverage, we compare these gas masses with those
calculated from techniques in the literature. First, we use a recombination
equation with three different estimates for the radial density profiles. These
include constant densities, those derived from [S II], and power-law profiles
based on constant values of the ionization parameter ($U$). Second, we use
single-component photoionization models with power-law density profiles based
on constant $U$, and allow $U$ to vary with radius based on the [O
III]/H$\beta$ ratios. We find that assuming a constant density of $n_\mathrm{H}
=$ 10$^2$ cm$^{-3}$ overestimates the gas masses for all six outflows,
particularly at small radii where the outflow rates peak. The use of [S II]
marginally matches the total gas masses, but also overestimates at small radii.
Overall, single-component photoionization models where $U$ varies with radius
are able to best match the gas mass and outflow rate profiles when there are
insufficient emission lines to construct detailed models.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:00:01 GMT""},{""version"":""v2"",""created"":""Tue, 14 Jun 2022 14:57:26 GMT""}]","2022-06-15"
"2203.07388","Lindsay DeMarchi","Lindsay DeMarchi, R. Margutti, J. Dittman, A. Brunthaler, D.
  Milisavljevic, Michael F. Bietenholz, C. Stauffer, D. Brethauer, D.
  Coppejans, K. Auchettl, K. D. Alexander, C. D. Kilpatrick, Joe S. Bright, L.
  Z. Kelley, Michael C. Stroh, and W. V. Jacobson-Galan","Radio Analysis of SN 2004C Reveals an Unusual CSM Density Profile as a
  Harbinger of Core Collapse","32 pages, 10 figures, submitted to ApJ",,"10.3847/1538-4357/ac8c26",,"astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present extensive multi-frequency VLA and VLBA observations of the
radio-bright supernova (SN) IIb SN 2004C that span $\sim(40-2793)$ days
post-explosion. We interpret the temporal evolution of the radio spectral
energy distribution (SED) in the context of synchrotron self-absorbed (SSA)
emission from the explosion's forward shock as it expands in the circumstellar
medium (CSM) previously sculpted by the mass-loss history of the stellar
progenitor. VLBA observations and modeling of the VLA data point to a blastwave
with average velocity $\sim0.06c$ that carries an energy of $\sim 10^{49}$ erg.
Our modeling further reveals a flat CSM density profile $\rho_{\rm{CSM}}
\propto R^{-0.03 \pm0.22}$ up to a break radius $R_{br} \approx (1.96 \pm 0.10)
\times 10^{16}$ cm, with a steep density gradient following $\rho_{\rm{CSM}}
\propto R^{-2.3 \pm 0.5}$ at larger radii. We infer that the flat part of the
density profile corresponds to a CSM shell with mass $\sim0.021 M_{\odot}$, and
that the progenitor's effective mass-loss rate varied with time over the range
$(50-500) \times 10^{-5} M_{\odot} \rm{yr}^{-1}$ for an adopted wind velocity
$v_w =1000$ km $s^{-1}$ and shock microphysical parameters ${\epsilon}_e = 0.1,
{\epsilon}_B = 0.01$. These results add to the mounting observational evidence
for departures from the traditional single-wind mass-loss scenarios in evolved,
massive stars in the centuries leading up to core collapse. Potentially viable
scenarios include mass loss powered by gravity waves and/or interaction with a
binary companion.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:00:02 GMT""}]","2022-10-26"
"2203.07389","Ena Choi","Ena Choi, Jeremiah P. Ostriker, Michaela Hirschmann, Rachel S.
  Somerville, Thorsten Naab","The Metallicity Distribution Function in Outer Halo Fields of Simulated
  Elliptical Galaxies Compared to Observations of NGC 5128","16 pages, 9 figures, Accepted for publication in ApJ",,"10.3847/1538-4357/ac5d47",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stellar metallicity distribution functions (MDF) have been measured for
resolved stellar populations in the outer halos of many galaxies in nearby
groups. Among them, the MDF of NGC 5128, the central giant elliptical in the
Centaurus group, provides essential constraints for theories of massive galaxy
formation and hierarchical assembly. To investigate the formation and chemical
evolution history of the outer halo of giant elliptical galaxies, we examine
the chemical properties of three zoom-in high resolution cosmological
hydrodynamical simulations of an NGC 5128-like giant elliptical galaxy and
compare their outer halo MDFs to the observed one of NGC 5128. Even though the
simulated galaxies have different merging histories and age distributions, all
predicted MDFs are in good qualitative agreement with the observed one. The
median metallicity of the simulated galaxies is on average $\rm [M/H]=-0.41 \pm
0.06$ compared to the observed value of $\rm [M/H]=-0.38 \pm 0.02$ for NGC
5128, and the dispersion in metallicity is $\sim 0.77$ dex for both observed
and simulated galaxies. We investigate the origin of the stars ending up in the
outer halo field of simulated galaxies and show that most have an `accreted'
origin, formed in other small galaxies and later accreted in mergers. Only
$\sim 15$ percent of the stars are formed `in situ' within the main progenitor
of galaxy and radially migrate outwards. We show that the contribution of
metal-rich in situ stars is sub-dominant in the outer halos of our simulated
galaxies, but can be prominent in the inner regions.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:00:02 GMT""}]","2022-04-27"
"2203.07390","Tatiana Acero Cuellar","Tatiana Acero-Cuellar, Federica Bianco, Gregory Dobler, Masao Sako and
  Helen Qu","What's the Difference? The potential for Convolutional Neural Networks
  for transient detection without template subtraction",,,,,"cs.CV astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  We present a study of the potential for Convolutional Neural Networks (CNNs)
to enable separation of astrophysical transients from image artifacts, a task
known as ""real-bogus"" classification without requiring a template subtracted
(or difference) image which requires a computationally expensive process to
generate, involving image matching on small spatial scales in large volumes of
data. Using data from the Dark Energy Survey, we explore the use of CNNs to (1)
automate the ""real-bogus"" classification, (2) reduce the computational costs of
transient discovery. We compare the efficiency of two CNNs with similar
architectures, one that uses ""image triplets"" (templates, search, and
difference image) and one that takes as input the template and search only. We
measure the decrease in efficiency associated with the loss of information in
input finding that the testing accuracy is reduced from 96% to 91.1%. We
further investigate how the latter model learns the required information from
the template and search by exploring the saliency maps. Our work (1) confirms
that CNNs are excellent models for ""real-bogus"" classification that rely
exclusively on the imaging data and require no feature engineering task; (2)
demonstrates that high-accuracy (> 90%) models can be built without the need to
construct difference images, but some accuracy is lost. Since once trained,
neural networks can generate predictions at minimal computational costs, we
argue that future implementations of this methodology could dramatically reduce
the computational costs in the detection of transients in synoptic surveys like
Rubin Observatory's Legacy Survey of Space and Time by bypassing the Difference
Image Analysis entirely.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:00:03 GMT""},{""version"":""v2"",""created"":""Fri, 2 Jun 2023 18:34:44 GMT""}]","2023-06-06"
"2203.07391","ChangHoon Hahn","ChangHoon Hahn, Peter Melchior","Accelerated Bayesian SED Modeling using Amortized Neural Posterior
  Estimation","21 pages, 5 figures; submitted to ApJ; code available at
  https://changhoonhahn.github.io/SEDflow",,"10.3847/1538-4357/ac7b84",,"astro-ph.GA astro-ph.CO stat.ML","http://creativecommons.org/licenses/by/4.0/","  State-of-the-art spectral energy distribution (SED) analyses use a Bayesian
framework to infer the physical properties of galaxies from observed photometry
or spectra. They require sampling from a high-dimensional space of SED model
parameters and take $>10-100$ CPU hours per galaxy, which renders them
practically infeasible for analyzing the $billions$ of galaxies that will be
observed by upcoming galaxy surveys ($e.g.$ DESI, PFS, Rubin, Webb, and Roman).
In this work, we present an alternative scalable approach to rigorous Bayesian
inference using Amortized Neural Posterior Estimation (ANPE). ANPE is a
simulation-based inference method that employs neural networks to estimate the
posterior probability distribution over the full range of observations. Once
trained, it requires no additional model evaluations to estimate the posterior.
We present, and publicly release, ${\rm SED}{flow}$, an ANPE method to produce
posteriors of the recent Hahn et al. (2022) SED model from optical photometry.
${\rm SED}{flow}$ takes ${\sim}1$ $second~per~galaxy$ to obtain the posterior
distributions of 12 model parameters, all of which are in excellent agreement
with traditional Markov Chain Monte Carlo sampling results. We also apply ${\rm
SED}{flow}$ to 33,884 galaxies in the NASA-Sloan Atlas and publicly release
their posteriors: see https://changhoonhahn.github.io/SEDflow.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:00:03 GMT""}]","2022-10-26"
"2203.07392","Michael Topping","Michael W. Topping, Daniel P. Stark, Ryan Endsley, Rychard J. Bouwens,
  Sander Schouws, Renske Smit, Mauro Stefanon, Hanae Inami, Rebecca A. A.
  Bowler, Pascal Oesch, Valentino Gonzalez, Pratika Dayal, Elisabete da Cunha,
  Hiddo Algera, Paul van der Werf, Andrea Pallottini, Laia Barrufet De Soto,
  Raffaella Schneider, Ilse De Looze, Laura Sommovigo, Lily Whitler, Luca
  Graziani, Yoshinobu Fudamoto, Andrea Ferrara","The ALMA REBELS Survey: Specific Star-Formation Rates in the
  Reionization Era","18 pages, 10 figures, submitted to MNRAS",,"10.1093/mnras/stac2291",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We present specific star-formation rates for 40 UV-bright galaxies at
$z\sim7-8$ observed as part of the Reionization Era Bright Emission Line Survey
(REBELS) ALMA large program. The sSFRs are derived using improved measures of
SFR and stellar masses, made possible by measurements of far-infrared (FIR)
continuum emission and [CII]-based spectroscopic redshifts. For each source in
the sample, we derive stellar masses from SED fitting and total SFRs from
calibrations of the UV and FIR emission. The median sSFR is $18_{-5}^{+7}$
Gyr$^{-1}$, significantly larger than literature measurements lacking
constraints in the FIR. The increase in sSFR reflects the larger obscured SFRs
we derive from the dust continuum relative to that implied by the UV+optical
SED. We suggest that such differences may reflect spatial variations in dust
across these luminous galaxies, with the component dominating the FIR distinct
from that dominating the UV. We demonstrate that the inferred stellar masses
(and hence sSFRs) are strongly-dependent on the assumed star formation history
(SFH) in reionization-era galaxies. When large sSFR galaxies are modeled with
non-parametric SFHs, the derived stellar masses can increase by an order of
magnitude relative to constant star formation models, owing to the presence of
a significant old stellar population that is outshined by the recent burst. The
[CII] line widths in the largest sSFR systems are often very broad, suggesting
dynamical masses that are easily able to accommodate the dominant old stellar
population suggested by non-parametric models. Regardless of these systematic
uncertainties in the derived parameters, we find that the sSFR increases
rapidly toward higher redshifts for massive galaxies ($9.6<\log(\rm
M_*/M_{\odot})<9.8$), with a power law that goes as $(1+z)^{1.7\pm0.3}$,
broadly consistent with expectations from the evolving baryon accretion rates.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:00:03 GMT""}]","2022-08-24"
"2203.07393","Christian Boyd","Christian Boyd, Luke Yeo, Philip W. Phillips","Probing the bulk plasmon continuum of layered materials through electron
  energy loss spectroscopy in a reflection geometry","10 pages, 9 figures. Corrected erroneous Bi-2212 parameters and f-sum
  rule formula (no change to figures)",,"10.1103/PhysRevB.106.155152",,"cond-mat.str-el cond-mat.mes-hall cond-mat.mtrl-sci physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A periodic arrangement of 2D conducting planes is known to host a (bulk)
plasmon dispersion that interpolates between the typical, gapped behavior of 3D
metals and a gapless, acoustic regime as a function of the out-of-plane
wavevector. The semi-infinite system -- the configuration relevant to Electron
Energy Loss Spectroscopy (EELS) in a reflection geometry, as in High Resolution
EELS (HREELS) -- is known to host a surface plasmon that ceases to propagate
below a cutoff wavevector. As the f-sum rule requires a finite response whether
or not there exist sharp excitations, we demonstrate that what remains in the
surface loss function -- the material response probed by HREELS -- is the
contribution from the (bulk) plasmon of the infinite system. In particular, we
provide a one-to-one mapping between the plasmon continuum and the spectral
weight in the surface loss function. In light of this result, we suggest that
HREELS be considered a long wavelength probe of the plasmon continuum in
layered materials.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:00:05 GMT""},{""version"":""v2"",""created"":""Mon, 28 Mar 2022 16:49:00 GMT""},{""version"":""v3"",""created"":""Thu, 18 Aug 2022 15:11:08 GMT""}]","2022-11-09"
"2203.07394","Qingrui Cao","Qingrui Cao, Evan J. Telford, Avishai Benyamini, Ian Kennedy, Amirali
  Zangiabadi, Kenji Watanabe, Takashi Taniguchi, Cory R. Dean, Benjamin M. Hunt","Tunneling Spectroscopy of Two-Dimensional Materials Based on Via
  Contacts",,,"10.1021/acs.nanolett.2c03081",,"cond-mat.mes-hall cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a novel planar tunneling architecture for van der Waals
heterostructures based on via contacts, namely metallic contacts embedded into
through-holes in hexagonal boron nitride ($h$BN). We use the via-based
tunneling method to study the single-particle density of states of two
different two-dimensional (2D) materials, NbSe$_2$ and graphene. In NbSe$_2$
devices, we characterize the barrier strength and interface disorder for
barrier thicknesses of 0, 1 and 2 layers of $h$BN and study the dependence on
tunnel-contact area down to $(44 \pm 14)^2 $ nm$^2$. For 0-layer $h$BN devices,
we demonstrate a crossover from diffusive to point contacts in the
small-contact-area limit. In graphene, we show that reducing the tunnel barrier
thickness and area can suppress effects due to phonon-assisted tunneling and
defects in the $h$BN barrier. This via-based architecture overcomes limitations
of other planar tunneling designs and produces high-quality, ultra-clean
tunneling structures from a variety of 2D materials.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:00:06 GMT""},{""version"":""v2"",""created"":""Tue, 1 Nov 2022 20:47:32 GMT""}]","2022-11-14"
"2203.07395","Roman Stricker","Roman Stricker, Jose Carrasco, Martin Ringbauer, Lukas Postler,
  Michael Meth, Claire Edmunds, Philipp Schindler, Rainer Blatt, Peter Zoller,
  Barbara Kraus, Thomas Monz","Towards experimental classical verification of quantum computation","19 pages, 8 figures",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With today's quantum processors venturing into regimes beyond the
capabilities of classical devices [1-3], we face the challenge to verify that
these devices perform as intended, even when we cannot check their results on
classical computers [4,5]. In a recent breakthrough in computer science [6-8],
a protocol was developed that allows the verification of the output of a
computation performed by an untrusted quantum device based only on classical
resources. Here, we follow these ideas, and demonstrate in a first,
proof-of-principle experiment a verification protocol using only classical
means on a small trapped-ion quantum processor. We contrast this to
verification protocols, which require trust and detailed hardware knowledge, as
in gate-level benchmarking [9], or additional quantum resources in case we do
not have access to or trust in the device to be tested [5]. While our
experimental demonstration uses a simplified version [10] of Mahadev's protocol
[6] we demonstrate the necessary steps for verifying fully untrusted devices. A
scaled-up version of our protocol will allow for classical verification,
requiring no hardware access or detailed knowledge of the tested device. Its
security relies on post-quantum secure trapdoor functions within an interactive
proof [11]. The conceptually straightforward, but technologically challenging
scaled-up version of the interactive proofs, considered here, can be used for a
variety of additional tasks such as verifying quantum advantage [8], generating
[12] and certifying quantum randomness [7], or composable remote state
preparation [13].
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:00:07 GMT""}]","2022-03-16"
"2203.07396","Camilla Juul Hansen","Camilla Juul Hansen","Heavy Elements -- They came out of the blue","14 pages, 5 figures - accepted for publication in Experimental
  Astronomy",,"10.1007/s10686-022-09841-0",,"astro-ph.SR astro-ph.HE nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  How are the heavy elements formed? This has been a key open question in
physics for decades. Recent direct detections of neutron star mergers and
observations of evolved stars show signatures of chemical elements in the blue
range of their spectra that bear witness of recent nuclear processes that led
to heavy element production. The formation of heavy elements typically takes
place through neutron-capture reactions creating radioactive isotopes, which
following beta-decay turn into the stable isotopes we today can measure
indirectly in the surfaces of cool, low-mass stars or meteoritic grains. The
conditions (such as the neutron density or entropy) of these n-capture
reactions remains to date poorly constrained, and only through a
multidisciplinary effort can we, by combining and comparing observations,
experiments, and theoretical predictions, improve on one of the top 10 most
important open physics questions posed at the turn of the century. This
emphasises the need for detailed observations of the near-UV to blue wavelength
region. The shortage of spectrographs and hence spectra covering this range
with high-resolution and high signal-to-noise has for decades played a limiting
factor in our understanding of how heavy elements form in the nuclear reactions
as well as how they behave in the stellar surfaces. With CUBES we can finally
improve the observations, by covering the crucial blue range in more remote
stars and also achieve a higher signal-to-noise ratio (SNR). This is much
needed to detect and accurately deblend the absorption lines and in turn derive
more accurate and precise abundances of the heavy elements.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:00:07 GMT""}]","2022-03-16"
"2203.07397","Felipe Diaz-Jaramillo","Roberto Bonezzi, Felipe Diaz-Jaramillo, Olaf Hohm","The Gauge Structure of Double Field Theory follows from Yang-Mills
  Theory","36 pages, published version",,"10.1103/PhysRevD.106.026004","HU-EP-22/07-RTG","hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that to cubic order double field theory is encoded in Yang-Mills
theory. To this end we use algebraic structures from string field theory as
follows: The $L_{\infty}$-algebra of Yang-Mills theory is the tensor product
${\cal K}\otimes \mathfrak{g}$ of the Lie algebra $\mathfrak{g}$ of the gauge
group and a `kinematic algebra' ${\cal K}$ that is a $C_{\infty}$-algebra. This
structure induces a cubic truncation of an $L_{\infty}$-algebra on the subspace
of level-matched states of the tensor product ${\cal K}\otimes \bar{\cal K}$ of
two copies of the kinematic algebra. This $L_{\infty}$-algebra encodes double
field theory. More precisely, this construction relies on a particular form of
the Yang-Mills $L_{\infty}$-algebra following from string field theory or from
the quantization of a suitable worldline theory.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:00:08 GMT""},{""version"":""v2"",""created"":""Tue, 12 Jul 2022 15:12:50 GMT""}]","2022-07-27"
"2203.07398","Giorgio Francesco Lesci","G. F. Lesci, L. Nanni, F. Marulli, L. Moscardini, A. Veropalumbo, M.
  Maturi, M. Sereno, M. Radovich, F. Bellagamba, M. Roncarelli, S. Bardelli, G.
  Castignani, G. Covone, C. Giocoli, L. Ingoglia, E. Puddu","AMICO galaxy clusters in KiDS-DR3: Constraints on cosmological
  parameters and on the normalisation of the mass-richness relation from
  clustering","8 pages, 5 figures, 1 table. Submitted to A&A","A&A 665, A100 (2022)","10.1051/0004-6361/202243538",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analysed the clustering of a photometric sample of galaxy clusters
selected from the Third Data Release of the Kilo-Degree Survey, focusing on the
redshift-space two-point correlation function (2PCF). We compared our
measurements to theoretical predictions of the standard $\Lambda$ cold dark
matter ($\Lambda$CDM) cosmological model. We measured the 2PCF of the sample in
the cluster centric radial range $r\in[5,80]$ $h^{-1}$Mpc, considering 4934
galaxy clusters with richness $\lambda^*\geq15$ in the redshift range
$z\in[0.1,0.6]$. A Markov chain Monte Carlo analysis has been performed to
constrain the cosmological parameters $\Omega_{\rm m}$, $\sigma_8$, and $S_8
\equiv \sigma_8(\Omega_{\rm m}/0.3)^{0.5}$, assuming Gaussian priors on the
mass-richness relation given by the posteriors obtained from a joint analysis
of cluster counts and weak lensing. In addition, we constrained the
normalisation of the mass-richness relation, $\alpha$, with fixed cosmological
parameters. We obtained $\Omega_{\rm m}=0.28^{+0.05}_{-0.04}$,
$\sigma_8=0.82^{+0.14}_{-0.12}$, and $S_8=0.80^{+0.08}_{-0.08}$. The constraint
on $S_8$ is consistent within 1$\sigma$ with the results from WMAP and Planck.
Furthermore, by fixing the cosmological parameters to those provided by Planck,
we obtained $\alpha=0.12^{+0.06}_{-0.06}$, which is fully consistent with the
result obtained from the joint analysis of cluster counts and weak lensing
performed for this sample.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:00:11 GMT""}]","2022-09-14"
"2203.07399","Quentin Glorieux","Murad Abuzarli, Nicolas Cherroret, Tom Bienaim\'e, Quentin Glorieux","Non-equilibrium pre-thermal states in a two-dimensional photon fluid",,"Phys. Rev. Lett. 129, 100602 (2022)","10.1103/PhysRevLett.129.100602",,"cond-mat.quant-gas quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Thermalization is the dynamical process by which a many-body system evolves
toward a thermal equilibrium state that maximizes its entropy. In certain
cases, however, the establishment of thermal equilibrium is significantly
slowed down and a phenomenon of pre-thermalization can emerge. It describes the
initial relaxation toward a quasi-steady state after a perturbation. While
having similar properties to their thermal counterparts, pre-thermal states
exhibit a partial memory of initial conditions. Here, we observe the dynamical
formation of a pre-thermal state in a non-equilibrium, two-dimensional (2D)
fluid of light after an interaction quench. Direct measurements of the fluid's
first-order correlation function reveal the spontaneous emergence of long-range
algebraic correlations spreading within a light-cone, providing a clear
signature of a quasi steady-state strongly similar to a 2D thermal superfluid.
Detailed experimental characterization of the algebraic order is presented and
a partial memory of the initial conditions is demonstrated, in agreement with
recent theoretical predictions. Furthermore, by a controlled increase of the
fluid fluctuations, we unveil a cross-over from algebraic to short-range
(exponential) correlations, analogous to the celebrated Kosterlitz-Thouless
transition observed at thermal equilibrium. These results suggest the existence
of non-equilibrium precursors for thermodynamic phase transitions.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:00:25 GMT""},{""version"":""v2"",""created"":""Mon, 4 Apr 2022 09:28:20 GMT""}]","2022-09-07"
"2203.07400","Linhu Li","Linhu Li, Wei Xin Teo, Sen Mu, Jiangbin Gong","Direction reversal of non-Hermitian skin effect via coherent coupling","12 pages, 8 figures. Comments are welcome","Phys. Rev. B 106, 085427 (2022)","10.1103/PhysRevB.106.085427",,"quant-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Absolute negative mobility (ANM) in nonequilibrium systems depicts the
possibility of particles propagating toward the opposite direction of an
external force. We uncover in this work a phenomenon analogous to ANM regarding
eigenstate localization and particle transport in non-Hermitian systems under
the influence of the non-Hermitian skin effect (NHSE). A coherent coupling
between two non-Hermitian chains individually possessing the same preferred
direction of NHSE is shown to cause a direction reversal of NHSE for all
eigenmodes. This concept is further investigated in terms of time evolution
dynamics using a non-Hermitian quantum walk platform within reach of current
experiments. Our findings are explained both qualitatively and quantitatively.
The possible direction reversal of NHSE can potentially lead to interesting
applications.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:00:27 GMT""}]","2022-09-01"
"2203.07401","Petra Wolf","Emmanuel Arrighi, Niels Gr\""uttemeier, Nils Morawietz, Frank Sommer,
  Petra Wolf","Multi-Parameter Analysis of Finding Minors and Subgraphs in Edge
  Periodic Temporal Graphs",,,,,"cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the computational complexity of determining structural properties of
edge periodic temporal graphs (EPGs). EPGs are time-varying graphs that
compactly represent periodic behavior of components of a dynamic network, for
example, train schedules on a rail network. In EPGs, for each edge $e$ of the
graph, a binary string $s_e$ determines in which time steps the edge is
present, namely $e$ is present in time step $t$ if and only if $s_e$ contains a
$1$ at position $t \mod |s_e|$. Due to this periodicity, EPGs serve as very
compact representations of complex periodic systems and can even be
exponentially smaller than classic temporal graphs representing one period of
the same system, as the latter contain the whole sequence of graphs explicitly.
In this paper, we study the computational complexity of fundamental questions
of the new concept of EPGs such as what is the shortest traversal time between
two vertices; is there a time step in which the graph (1) is minor-free; (2)
contains a minor; (3) is subgraph-free; (4) contains a subgraph; with respect
to a given minor or subgraph. We give a detailed parameterized analysis for
multiple combinations of parameters for the problems stated above including
several parameterized algorithms.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:03:13 GMT""}]","2022-03-16"
"2203.07402","Arkil Patel","Arkil Patel, Satwik Bhattamishra, Phil Blunsom, Navin Goyal","Revisiting the Compositional Generalization Abilities of Neural Sequence
  Models","ACL 2022",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Compositional generalization is a fundamental trait in humans, allowing us to
effortlessly combine known phrases to form novel sentences. Recent works have
claimed that standard seq-to-seq models severely lack the ability to
compositionally generalize. In this paper, we focus on one-shot primitive
generalization as introduced by the popular SCAN benchmark. We demonstrate that
modifying the training distribution in simple and intuitive ways enables
standard seq-to-seq models to achieve near-perfect generalization performance,
thereby showing that their compositional generalization abilities were
previously underestimated. We perform detailed empirical analysis of this
phenomenon. Our results indicate that the generalization performance of models
is highly sensitive to the characteristics of the training data which should be
carefully considered while designing such benchmarks in future.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:03:21 GMT""}]","2022-03-16"
"2203.07403","Massimiliano Zanin","Massimiliano Zanin, Johann H. Mart\'inez","Analysing international events through the lens of statistical physics:
  the case of Ukraine","7 pages, 5 Figures",,"10.1063/5.0091628",,"physics.soc-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  During the last years, statistical physics has received an increasing
attention as a framework for the analysis of real complex systems; yet, this is
less clear in the case of international political events, partly due to the
complexity in securing relevant quantitative data on them. Here we analyse a
detailed data set of violent events that took place in Ukraine since January
2021, and analyse their temporal and spatial correlations through entropy and
complexity metrics, and functional networks. Results depict a complex scenario,
with events appearing in a non-random fashion, but with eastern-most regions
functionally disconnected from the remainder of the country -- something
opposing the widespread ""two Ukraines"" view. We further draw some lessons and
venues for future analyses.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:05:21 GMT""},{""version"":""v2"",""created"":""Tue, 10 May 2022 11:19:48 GMT""}]","2022-06-08"
"2203.07404","Sifan Wang","Sifan Wang, Shyam Sankaran, Paris Perdikaris","Respecting causality is all you need for training physics-informed
  neural networks","35 pages, 27 figures, 4 tables",,,,"cs.LG cs.NA math.NA nlin.CD physics.flu-dyn stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  While the popularity of physics-informed neural networks (PINNs) is steadily
rising, to this date PINNs have not been successful in simulating dynamical
systems whose solution exhibits multi-scale, chaotic or turbulent behavior. In
this work we attribute this shortcoming to the inability of existing PINNs
formulations to respect the spatio-temporal causal structure that is inherent
to the evolution of physical systems. We argue that this is a fundamental
limitation and a key source of error that can ultimately steer PINN models to
converge towards erroneous solutions. We address this pathology by proposing a
simple re-formulation of PINNs loss functions that can explicitly account for
physical causality during model training. We demonstrate that this simple
modification alone is enough to introduce significant accuracy improvements, as
well as a practical quantitative mechanism for assessing the convergence of a
PINNs model. We provide state-of-the-art numerical results across a series of
benchmarks for which existing PINNs formulations fail, including the chaotic
Lorenz system, the Kuramoto-Sivashinsky equation in the chaotic regime, and the
Navier-Stokes equations in the turbulent regime. To the best of our knowledge,
this is the first time that PINNs have been successful in simulating such
systems, introducing new opportunities for their applicability to problems of
industrial complexity.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:08:18 GMT""}]","2022-03-16"
"2203.07405","Andrew Beckett","Andrew Beckett and Jos\'e Figueroa-O'Farrill","Symplectic Actions and Central Extensions","23 pages, 2 appendices; Section 5.5 added and Appendix A expanded in
  v2",,,"EMPG-22-04","math.SG hep-th math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a proof of the fact that a simply-connected symplectic homogeneous
space $(M,\omega)$ of a connected Lie group $G$ is the universal cover of a
coadjoint orbit of a one-dimensional central extension of $G$. We emphasise the
r\^ole of symplectic group cocycles and the relationship between such cocycles,
left-invariant presymplectic structures on $G$ and central extensions of $G$;
in particular, we show that integrability of a central extension of
$\mathfrak{g}$ to a central extension of $G$ is equivalent to integrability of
a representative Chevalley-Eilenberg 2-cocycle of $\mathfrak{g}$ to a
symplectic cocycle of $G$.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:09:05 GMT""},{""version"":""v2"",""created"":""Fri, 4 Nov 2022 19:08:33 GMT""}]","2022-11-08"
"2203.07406","William Shepherd","William Shepherd","SMEFT at the LHC and Beyond: A Snowmass White Paper","contribution to Snowmass 2021",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  I detail an optimistic future vision for the use of SMEFT at high-energy
colliders, and describe the use of the studies which could result for
interpretation of future models. I also explore some of the potential pitfalls
which could significantly degrade the utility of those results and discuss
approaches to avoid them and ensure that results are actually accurate when
applied to new models.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:10:54 GMT""}]","2022-03-16"
"2203.07407","Manon Blanc","Manon Blanc and Kristoffer Arnsfelt Hansen","Computational Complexity of Multi-Player Evolutionarily Stable
  Strategies",,,,,"cs.CC","http://creativecommons.org/licenses/by/4.0/","  In this paper we study the computational complexity of computing an
evolutionary stable strategy (ESS) in multi-player symmetric games. For
two-player games, deciding existence of an ESS is complete for {\Sigma} 2 , the
second level of the polynomial time hierarchy. We show that deciding existence
of an ESS of a multi-player game is closely connected to the second level of
the real polynomial time hierarchy. Namely, we show that the problem is hard
for a complexity class we denote as \exists D . \forall R and is a member of
\exists\forall R, where the former class restrict the latter by having the
existentially quantified variables be Boolean rather then real-valued. As a
special case of our results it follows that deciding whether a given strategy
is an ESS is complete for \forall R. A concept strongly related to ESS is that
of a locally superior strategy (LSS). We extend our results about ESS and show
that deciding existence of an LSS of a multiplayer game is likewise hard for
\exists D \forall R and a member of \exists\forall R, and as a special case
that deciding whether a given strategy is an LSS is complete for \forall R.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:13:59 GMT""}]","2022-03-16"
"2203.07408","David G. Grier","Jatin Abacousnac and David G. Grier","Dexterous holographic trapping of dark-seeking particles with Zernike
  holograms","9 pages, 4 figures",,"10.1364/OE.458544",,"physics.optics cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  The intensity distribution of a holographically-projected optical trap can be
tailored to the physical properties of the particles it is intended to trap.
Dynamic optimization is especially desirable for manipulating dark-seeking
particles that are repelled by conventional optical tweezers, and even more so
when dark-seeking particles coexist in the same system as light-seeking
particles. We address the need for dexterous manipulation of dark-seeking
particles by introducing a class of ""dark"" traps created from the superposition
of two out-of-phase Gaussian modes with different waist diameters. Interference
in the difference-of-Gaussians (DoG) trap creates a dark central core that is
completely surrounded by light and therefore can trap dark-seeking particles
rigidly in three dimensions. DoG traps can be combined with conventional
optical tweezers and other types of traps for use in heterogeneous samples. The
ideal hologram for a DoG trap being purely real-valued, we introduce a general
method based on the Zernike phase-contrast principle to project real-valued
holograms with the phase-only diffractive optical elements used in standard
holographic optical trapping systems. We demonstrate the capabilities of DoG
traps (and Zernike holograms) through experimental studies on high-index,
low-index and absorbing colloidal particles dispersed in fluid media.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:14:05 GMT""},{""version"":""v2"",""created"":""Thu, 26 May 2022 14:38:09 GMT""}]","2022-06-29"
"2203.07411","Chi-Ken Lu","Chi-Ken Lu and Patrick Shafto","On Connecting Deep Trigonometric Networks with Deep Gaussian Processes:
  Covariance, Expressivity, and Neural Tangent Kernel","version 2 contains new analysis on finite width effect on kernel and
  NTK, and more connection to other works; v3 includes numerical simulation
  connecting exact DGP predictive mean with weight space results",,,,"cs.LG cond-mat.dis-nn stat.ML","http://creativecommons.org/licenses/by/4.0/","  Deep Gaussian Process (DGP) as a model prior in Bayesian learning intuitively
exploits the expressive power in function composition. DGPs also offer diverse
modeling capabilities, but inference is challenging because marginalization in
latent function space is not tractable. With Bochner's theorem, DGP with
squared exponential kernel can be viewed as a deep trigonometric network
consisting of the random feature layers, sine and cosine activation units, and
random weight layers. In the wide limit with a bottleneck, we show that the
weight space view yields the same effective covariance functions which were
obtained previously in function space. Also, varying the prior distributions
over network parameters is equivalent to employing different kernels. As such,
DGPs can be translated into the deep bottlenecked trig networks, with which the
exact maximum a posteriori estimation can be obtained. Interestingly, the
network representation enables the study of DGP's neural tangent kernel, which
may also reveal the mean of the intractable predictive distribution.
Statistically, unlike the shallow networks, deep networks of finite width have
covariance deviating from the limiting kernel, and the inner and outer widths
may play different roles in feature learning. Numerical simulations are present
to support our findings.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:14:59 GMT""},{""version"":""v2"",""created"":""Sat, 4 Jun 2022 20:32:39 GMT""},{""version"":""v3"",""created"":""Sat, 30 Jul 2022 17:27:57 GMT""}]","2022-08-02"
"2203.07412","Utsav Akhaury","F. Nammour, U. Akhaury, J. N. Girard, F. Lanusse, F. Sureau, C. Ben
  Ali, J.-L. Starck","ShapeNet: Shape Constraint for Galaxy Image Deconvolution","6 pages, 6 figures","A&A 663, A69 (2022)","10.1051/0004-6361/202142626",,"astro-ph.IM eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep Learning (DL) has shown remarkable results in solving inverse problems
in various domains. In particular, the Tikhonet approach is very powerful to
deconvolve optical astronomical images (Sureau et al. 2020). Yet, this approach
only uses the $\ell_2$ loss, which does not guarantee the preservation of
physical information (e.g. flux and shape) of the object reconstructed in the
image. In Nammour et al. (2021), a new loss function was proposed in the
framework of sparse deconvolution, which better preserves the shape of galaxies
and reduces the pixel error. In this paper, we extend Tikhonet to take into
account this shape constraint, and apply our new DL method, called ShapeNet, to
optical and radio-interferometry simulated data set. The originality of the
paper relies on i) the shape constraint we use in the neural network framework,
ii) the application of deep learning to radio-interferometry image
deconvolution for the first time, and iii) the generation of a simulated radio
data set that we make available for the community. A range of examples
illustrates the results.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:16:16 GMT""}]","2022-07-20"
"2203.07413","Qinjie Lin","Qinjie Lin, Han Liu, Biswa Sengupta","Switch Trajectory Transformer with Distributional Value Approximation
  for Multi-Task Reinforcement Learning",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We propose SwitchTT, a multi-task extension to Trajectory Transformer but
enhanced with two striking features: (i) exploiting a sparsely activated model
to reduce computation cost in multi-task offline model learning and (ii)
adopting a distributional trajectory value estimator that improves policy
performance, especially in sparse reward settings. These two enhancements make
SwitchTT suitable for solving multi-task offline reinforcement learning
problems, where model capacity is critical for absorbing the vast quantities of
knowledge available in the multi-task dataset. More specifically, SwitchTT
exploits switch transformer model architecture for multi-task policy learning,
allowing us to improve model capacity without proportional computation cost.
Also, SwitchTT approximates the distribution rather than the expectation of
trajectory value, mitigating the effects of the Monte-Carlo Value estimator
suffering from poor sample complexity, especially in the sparse-reward setting.
We evaluate our method using the suite of ten sparse-reward tasks from the
gym-mini-grid environment.We show an improvement of 10% over Trajectory
Transformer across 10-task learning and obtain up to 90% increase in offline
model training speed. Our results also demonstrate the advantage of the switch
transformer model for absorbing expert knowledge and the importance of value
distribution in evaluating the trajectory.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:17:56 GMT""}]","2022-03-16"
"2203.07414","William Matthewson","William L Matthewson, Dennis Stock, Ruth Durrer","Redshift weighted galaxy number counts","28 pages, 7 figures",,"10.1088/1475-7516/2022/09/065",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we introduce the `redshift fluctuation' as a gauge-invariant
cosmological observable and give its fully relativistic expression at first
order in cosmological perturbation theory. We show that this corresponds
effectively to number counts with a radial window function with vanishing mean
which therefore resolve smaller scale radial modes than standard number counts.
In a detailed analysis of the angular power spectrum of this new variable, we
study the relevance of different relativistic contributions, and how it differs
from the conventional observable galaxy number count fluctuations. In order to
investigate its utility for future spectroscopic surveys, we perform Fisher
forecasts for a Euclid-like and an SKAII-like configuration, as examples.
Particular focus is placed on the dependence of the results on the size of the
redshift bins and on the cutoff in $\ell$ adopted in the analysis.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:18:39 GMT""},{""version"":""v2"",""created"":""Fri, 12 Aug 2022 08:08:11 GMT""},{""version"":""v3"",""created"":""Mon, 17 Oct 2022 07:01:55 GMT""}]","2022-10-18"
"2203.07415","Jagannath Sutradhar","Jagannath Sutradhar, Soumi Ghosh, Sthitadhi Roy, David E. Logan,
  Subroto Mukerjee, Sumilan Banerjee","Scaling of Fock-space propagator and multifractality across the
  many-body localization transition",,"Physical Review B 106, 054203 (2022)","10.1103/PhysRevB.106.054203",,"cond-mat.dis-nn cond-mat.stat-mech cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We implement a recursive Green function method to extract the Fock space (FS)
propagator and associated self-energy across the many-body localization (MBL)
transition, for one-dimensional interacting fermions in a random onsite
potential. We show that the typical value of the imaginary part of the local FS
self-energy, \Delta_t, related to the decay rate of an initially localized
state, acts as a probabilistic order parameter for the thermal to MBL phase
transition; and can be used to characterize critical properties of the
transition as well as the multifractal nature of MBL states as a function of
disorder strength W. In particular, we show that a fractal dimension D_s
extracted from \Delta_t jumps discontinuously across the transition, from D_s<1
in the MBL phase to D_s= 1 in the thermal phase. Moreover, \Delta_t follows an
asymmetrical finite-size scaling form across the thermal-MBL transition, where
a non-ergodic volume in the thermal phase diverges with a Kosterlitz-Thouless
like essential singularity at the critical point W_c, and controls the
continuous vanishing of \Delta_t as W_c is approached. In contrast, a
correlation length ({\xi}) extracted from \Delta_t exhibits a power-law
divergence on approaching W_c from the MBL phase.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:19:48 GMT""},{""version"":""v2"",""created"":""Thu, 11 Aug 2022 11:17:58 GMT""}]","2022-08-12"
"2203.07416","Tzvika Geft","Tzvika Geft and Dan Halperin","Refined Hardness of Distance-Optimal Multi-Agent Path Finding","Accepted to Autonomous Agents and Multi-Agent Systems (AAMAS 2022)",,,,"cs.MA cs.CG cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the computational complexity of multi-agent path finding (MAPF).
Given a graph $G$ and a set of agents, each having a start and target vertex,
the goal is to find collision-free paths minimizing the total distance
traveled. To better understand the source of difficulty of the problem, we aim
to study the simplest and least constrained graph class for which it remains
hard. To this end, we restrict $G$ to be a 2D grid, which is a ubiquitous
abstraction, as it conveniently allows for modeling well-structured
environments (e.g., warehouses). Previous hardness results considered highly
constrained 2D grids having only one vertex unoccupied by an agent, while the
most restricted hardness result that allowed multiple empty vertices was for
(non-grid) planar graphs. We therefore refine previous results by
simultaneously considering both 2D grids and multiple empty vertices. We show
that even in this case distance-optimal MAPF remains NP-hard, which settles an
open problem posed by Banfi et al. (2017). We present a reduction directly from
3-SAT using simple gadgets, making our proof arguably more informative than
previous work in terms of potential progress towards positive results.
Furthermore, our reduction is the first linear one for the case where $G$ is
planar, appearing nearly four decades after the first related result. This
allows us to go a step further and exploit the Exponential Time Hypothesis
(ETH) to obtain an exponential lower bound for the running time of the problem.
Finally, as a stepping stone towards our main results, we prove the NP-hardness
of the monotone case, in which agents move one by one with no intermediate
stops.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:23:22 GMT""}]","2022-03-16"
"2203.07417","Martin Obligado","Y. Mezui, M. Obligado, and Alain Cartellier","Buoyancy driven bubbly flows: scaling of velocities in bubble columns
  operated in the heterogeneous regime",,,"10.1017/jfm.2022.833",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The hydrodynamics of bubble columns in the heterogeneous regime is revisited.
Focusing on air-water systems at large aspect ratio, we show from dimensional
analysis that buoyancy equilibrates inertia, and that velocities scale as
$(gD\varepsilon)^{1/2}$, where $D$ is the bubble column diameter, $\varepsilon$
the void fraction and $g$ the gravitational acceleration.
  From new experiments in a $0.4$m diameter column with ${\cal{O}}(10^3)$
particle Reynolds number bubbles and from a detailed analysis of published
data, we confirm the self-organization prevailing in the heterogeneous regime,
and that the liquid flow rate is only set by the column diameter $D$. Besides,
direct liquid and gas velocity measurements demonstrate that the relative
velocity increases above the terminal velocity $U_T$ in the heterogeneous
regime, and that it tends to $\sim 2.4 U_T$ at very large gas superficial
velocities $V_{sg}$. The proposed velocity scaling is shown to hold for liquid
and gas mean velocities and for their standard deviations. Furthermore, it is
found to be valid over a wide range of conditions, corresponding to Froude
numbers $Fr=V_{sg}/(gD)^{1/2}$ from 0.02 to 0.5. Then, the relevance of this
scaling for coalescing media is discussed. Moreover, following the successful
prediction of the void fraction with a Zuber \& Findlay approach at the
beginning of the heterogeneous regime, we show how the void fraction is
correlated with $Fr$. Further investigations are finally suggested to connect
the increase in relative velocity with meso-scale structures known to exist in
the heterogeneous regime.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:24:49 GMT""},{""version"":""v2"",""created"":""Wed, 5 Oct 2022 13:37:36 GMT""}]","2022-12-07"
"2203.07418","Moritz Kassmann","Moritz Kassmann and Marvin Weidner","Nonlocal operators related to nonsymmetric forms I: H\""older estimates",,,,,"math.AP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim of this article is to develop the regularity theory for parabolic
equations driven by nonlocal operators associated with nonsymmetric forms.
H\""older regularity and weak Harnack inequalities are proved using extensions
of recently established nonlocal energy methods. We are able to connect the
theory of nonsymmetric nonlocal operators with the important results of
Aronson-Serrin in the local linear case. This connection is exemplified by
nonlocal-to-local convergence results identifying the limiting class of
operators as second order differential operators with drift terms.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:25:09 GMT""}]","2022-03-16"
"2203.07419","Victor Bovdi A.","Orest Artemovych and Victor Bovdi","Torsion subgroups, solvability and the Engel condition in associative
  rings","19 pages",,,,"math.GR math.RA math.RT","http://creativecommons.org/licenses/by/4.0/","  The connections between the properties of associative rings that are
Lie-solvable (Engel, n-Engel, locally finite, respectively) and the properties
of their adjoin subgroups are investigated.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:27:51 GMT""}]","2022-03-16"
"2203.07420","Gazi Mahamud Hasan","Gazi Mahamud Hasan (1), Mehedi Hasan (1), Peng Liu (1), Mohammad Rad
  (2), Eric Bernier (2) and Trevor James Hall (1) ((1) Photonic Technology
  Laboratory, Centre for Research in Photonics, University of Ottawa, Canada,
  (2) Huawei Technologies Canada)","Optical Wavelength Meter with Machine Learning Enhanced Precision","18 pages, 9 figures, 1 table",,,,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Diverse applications in photonics and microwave engineering require a means
of measurement of the instantaneous frequency of a signal. A photonic
implementation typically applies an interferometer equipped with three or more
output ports to measure the frequency dependent phase shift provided by an
optical delay line. The components constituting the interferometer are prone to
impairments which results in erroneous measurements. It is shown that the
information to be retrieved is encoded by a three-component vector that lies on
a circular cone within a three-dimensional Cartesian object space. The measured
data belongs to the image of the object space under a linear map that describes
the action of the interferometer. Assisted by a learning algorithm, an inverse
map from the image space into the object space is constructed. The inverse map
compensates for a variety of impairments while being robust to noise.
Simulation results demonstrate that, to the extent the interferometer model
captures all significant impairments, a precision limited only by the level of
random noise is attainable. A wavelength meter architecture is fabricated on
Si3N4 photonic integration platform to prove the method experimentally. Applied
to the measured data, greater than an order of magnitude improvement in
precision is achieved by the proposed method compared to the conventional
method.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:29:52 GMT""}]","2022-03-16"
"2203.07421","Don Marolf","Donald Marolf","Gravitational thermodynamics without the conformal factor problem:
  Partition functions and Euclidean saddles from Lorentzian Path Integrals","29 pages + appendix and references",,"10.1007/JHEP07(2022)108",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Thermal partition functions for gravitational systems have traditionally been
studied using Euclidean path integrals. But in Euclidean signature the
gravitational action suffers from the conformal factor problem, which renders
the action unbounded below. This makes it difficult to take the Euclidean
formulation as fundamental. However, despite their familiar association with
periodic imaginary time, thermal gravitational partition functions can also be
described by real-time path integrals over contours defined by real Lorentzian
metrics. The one caveat is that we should allow certain codimension-2
singularities analogous to the familiar Euclidean conical singularities. With
this understanding, we show that the usual Euclidean-signature black holes (or
their complex rotating analogues) define saddle points for the real-time path
integrals that compute our partition functions. Furthermore, when the black
holes have positive specific heat, we provide evidence that a codimension-2
subcontour of our real Lorentz-signature contour of integration can be deformed
so as to show that these black holes saddles contribute with non-zero weight to
the semiclassical limit, and that the same is then true of the remaining two
integrals.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:33:46 GMT""},{""version"":""v2"",""created"":""Thu, 9 Jun 2022 23:18:21 GMT""}]","2022-08-10"
"2203.07422","Siddhant Kumar","Akshay Joshi, Prakash Thakolkaran, Yiwen Zheng, Maxime Escande, Moritz
  Flaschel, Laura De Lorenzis and Siddhant Kumar","Bayesian-EUCLID: discovering hyperelastic material laws with
  uncertainties","36 pages, 17 figures","Computer Methods in Applied Mechanics and Engineering, 398 (2022)
  115225","10.1016/j.cma.2022.115225",,"cs.CE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Within the scope of our recent approach for Efficient Unsupervised
Constitutive Law Identification and Discovery (EUCLID), we propose an
unsupervised Bayesian learning framework for discovery of parsimonious and
interpretable constitutive laws with quantifiable uncertainties. As in
deterministic EUCLID, we do not resort to stress data, but only to
realistically measurable full-field displacement and global reaction force
data; as opposed to calibration of an a priori assumed model, we start with a
constitutive model ansatz based on a large catalog of candidate functional
features; we leverage domain knowledge by including features based on existing,
both physics-based and phenomenological, constitutive models. In the new
Bayesian-EUCLID approach, we use a hierarchical Bayesian model with
sparsity-promoting priors and Monte Carlo sampling to efficiently solve the
parsimonious model selection task and discover physically consistent
constitutive equations in the form of multivariate multi-modal probabilistic
distributions. We demonstrate the ability to accurately and efficiently recover
isotropic and anisotropic hyperelastic models like the Neo-Hookean, Isihara,
Gent-Thomas, Arruda-Boyce, Ogden, and Holzapfel models in both elastostatics
and elastodynamics. The discovered constitutive models are reliable under both
epistemic uncertainties - i.e. uncertainties on the true features of the
constitutive catalog - and aleatoric uncertainties - which arise from the noise
in the displacement field data, and are automatically estimated by the
hierarchical Bayesian model.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:34:58 GMT""},{""version"":""v2"",""created"":""Thu, 20 Oct 2022 20:20:51 GMT""}]","2022-10-24"
"2203.07423","Thomas Roser","Thomas Roser","Sustainability Considerations for Accelerator and Collider Facilities","Contribution to Snowmass 2021. arXiv admin note: substantial text
  overlap with arXiv:2201.07895",,,,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  As the next generation of large accelerator-based facilities are being
considered at the Snowmass 2021 study high priority has to be given to
environmental sustainability including energy consumption, natural resource use
and the environmental impact of effluents. Typically, increased performance -
higher beam energies and intensities - of proposed new facilities have come
with increased electric power consumption. In the following we discuss the most
important areas of development for the sustainability of accelerator-based
research infrastructures in three categories - technologies, concepts and
general aspects. To achieve the goal of increased performance with reduced
energy consumption a focused R&D effort is required with the same or even
higher priority as the traditional performance-related R&D. Such a
recommendation was included in the recent European Strategy for Particle
Physics Accelerator R&D Roadmap.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:35:58 GMT""}]","2022-04-01"
"2203.07424","Liu Ke","Liu Ke, Udit Gupta, Mark Hempstead, Carole-Jean Wu, Hsien-Hsin S. Lee,
  Xuan Zhang","Hercules: Heterogeneity-Aware Inference Serving for At-Scale
  Personalized Recommendation",,,,,"cs.DC","http://creativecommons.org/licenses/by/4.0/","  Personalized recommendation is an important class of deep-learning
applications that powers a large collection of internet services and consumes a
considerable amount of datacenter resources. As the scale of production-grade
recommendation systems continues to grow, optimizing their serving performance
and efficiency in a heterogeneous datacenter is important and can translate
into infrastructure capacity saving. In this paper, we propose Hercules, an
optimized framework for personalized recommendation inference serving that
targets diverse industry-representative models and cloud-scale heterogeneous
systems. Hercules performs a two-stage optimization procedure - offline
profiling and online serving. The first stage searches the large under-explored
task scheduling space with a gradient-based search algorithm achieving up to
9.0x latency-bounded throughput improvement on individual servers; it also
identifies the optimal heterogeneous server architecture for each
recommendation workload. The second stage performs heterogeneity-aware cluster
provisioning to optimize resource mapping and allocation in response to
fluctuating diurnal loads. The proposed cluster scheduler in Hercules achieves
47.7% cluster capacity saving and reduces the provisioned power by 23.7% over a
state-of-the-art greedy scheduler.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:36:19 GMT""}]","2022-03-16"
"2203.07425","Breno Costa","Jo\~ao Bachiega Jr, Breno Costa, and Aleteia P. F. Araujo","Computational Perspective of the Fog Node","Paper presented in the conference '2021 World Congress in Computer
  Science, Computer Engineering, & Applied Computing' (CSCE'21)",,,,"cs.DC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Fog computing is a recent computational paradigm that was proposed to solve
some weaknesses in cloud-based systems. For this reason, this technology has
been extensively studied by several technology areas. It is still in a maturing
stage, so there is no consensus in academia about its concepts and definitions,
and each area adopts the ones that are convenient for each use case. This
article proposes a definition and a classification relying on a computational
perspective for the fog node, which is a fundamental element in a fog computing
environment. In addition, the main challenges related to the fog node are also
presented.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:36:53 GMT""}]","2022-03-16"
"2203.07426","Fanchao Qi","Fanchao Qi, Chuancheng Lv, Zhiyuan Liu, Xiaojun Meng, Maosong Sun,
  Hai-Tao Zheng","Sememe Prediction for BabelNet Synsets using Multilingual and Multimodal
  Information","Accepted by Findings of ACL 2022 as a long paper. Camera-ready
  version",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In linguistics, a sememe is defined as the minimum semantic unit of
languages. Sememe knowledge bases (KBs), which are built by manually annotating
words with sememes, have been successfully applied to various NLP tasks.
However, existing sememe KBs only cover a few languages, which hinders the wide
utilization of sememes. To address this issue, the task of sememe prediction
for BabelNet synsets (SPBS) is presented, aiming to build a multilingual sememe
KB based on BabelNet, a multilingual encyclopedia dictionary. By automatically
predicting sememes for a BabelNet synset, the words in many languages in the
synset would obtain sememe annotations simultaneously. However, previous SPBS
methods have not taken full advantage of the abundant information in BabelNet.
In this paper, we utilize the multilingual synonyms, multilingual glosses and
images in BabelNet for SPBS. We design a multimodal information fusion model to
encode and combine this information for sememe prediction. Experimental results
show the substantial outperformance of our model over previous methods (about
10 MAP and F1 scores). All the code and data of this paper can be obtained at
https://github.com/thunlp/MSGI.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:37:09 GMT""}]","2022-03-16"
"2203.07427","Pedro Harunari","Pedro E. Harunari, Annwesha Dutta, Matteo Polettini, \'Edgar Rold\'an","What to learn from a few visible transitions' statistics?",,,,,"cond-mat.stat-mech physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Interpreting partial information collected from systems subject to noise is a
key problem across scientific disciplines. Theoretical frameworks often focus
on the dynamics of variables that result from coarse-graining the internal
states of a physical system. However, most experimental apparatuses can only
detect a partial set of transitions, while internal states are inaccessible.
Here, we consider an observer who records a time series of occurrences of one
or several transitions performed by a system, under the assumption that its
underlying dynamics is Markovian. We pose the question of how one can use the
transitions' information to make inferences of dynamical, thermodynamical, and
biochemical properties. First, elaborating on first-passage time techniques, we
derive analytical expressions for the probabilities of consecutive transitions
and the time elapsed between them. Second, we derive a lower bound for the
entropy production rate that equals the sum of two non-negative contributions,
one due to the statistics of transitions and a second due to the statistics of
inter-transition times. We also show that when only one current is measured,
our estimate still detects irreversibility even in the absence of net currents.
We illustrate the developed framework in experimentally-validated biophysical
models of kinesin and dynein molecular motors, and in a minimal model for
template-directed polymerization. Our results reveal that while entropy
production is entailed in the statistics of two successive transitions of the
same type, the statistics of two different successive transitions can probe the
existence of an underlying disorder in the motion of a molecular motor. Taken
all together, our results highlight the power of inference from transition
statistics ranging from thermodynamic quantities to network-topology properties
of Markov processes.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:37:28 GMT""},{""version"":""v2"",""created"":""Wed, 17 Aug 2022 14:22:47 GMT""}]","2022-08-18"
"2203.07428","Agnid Banerjee","Vedansh Arya, Agnid Banerjee, Donatella Danielli, Nicola Garofalo","Space-like strong unique continuation for some fractional parabolic
  equations",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we establish the \emph{space-like} strong unique continuation
for nonlocal equations of the type $(\partial_t - \Delta)^s u= Vu$, for $0<s
<1$. The proof of our main result, Theorem 1.1, is achieved via a conditional
elliptic type doubling property for solutions to the appropriate extension
problem, followed by a blowup analysis.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:37:40 GMT""}]","2022-03-16"
"2203.07429","Noel Csomay-Shanklin","Manuel Y. Galliker, Noel Csomay-Shanklin, Ruben Grandia, Andrew J.
  Taylor, Farbod Farshidian, Marco Hutter, Aaron D. Ames","Planar Bipedal Locomotion with Nonlinear Model Predictive Control:
  Online Gait Generation using Whole-Body Dynamics","8 pages, 6 figures, accepted to Humanoids 2022",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ability to generate dynamic walking in real-time for bipedal robots with
input constraints and underactuation has the potential to enable locomotion in
dynamic, complex and unstructured environments. Yet, the high-dimensional
nature of bipedal robots has limited the use of full-order rigid body dynamics
to gaits which are synthesized offline and then tracked online. In this work we
develop an online nonlinear model predictive control approach that leverages
the full-order dynamics to realize diverse walking behaviors. Additionally,
this approach can be coupled with gaits synthesized offline via a desired
reference to enable a shorter prediction horizon and rapid online re-planning,
bridging the gap between online reactive control and offline gait planning. We
demonstrate the proposed method, both with and without an offline gait, on the
planar robot AMBER-3M in simulation and on hardware.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:38:45 GMT""},{""version"":""v2"",""created"":""Thu, 3 Nov 2022 19:50:26 GMT""}]","2022-11-07"
"2203.07430","Mohammad Khajenejad","Mohammad Khajenejad and Sze Zheng Yong","$\mathcal{H}_{\infty}$-optimal Interval Observer Synthesis for Uncertain
  Nonlinear Dynamical Systems via Mixed-Monotone Decompositions","6 pages",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by-sa/4.0/","  This paper introduces a novel $\mathcal{H}_{\infty}$-optimal interval
observer synthesis for bounded-error/uncertain locally Lipschitz nonlinear
continuous-time (CT) and discrete-time (DT) systems with noisy nonlinear
observations. Specifically, using mixed-monotone decompositions, the proposed
observer is correct by construction, i.e., the interval estimates readily frame
the true states without additional constraints or procedures. In addition, we
provide sufficient conditions for input-to-state (ISS) stability of the
proposed observer and for minimizing the $\mathcal{H}_{\infty}$ gain of the
framer error system in the form of semi-definite programs (SDPs) with Linear
Matrix Inequalities (LMIs) constraints. Finally, we compare the performance of
the proposed $\mathcal{H}_{\infty}$-optimal interval observers with some
benchmark CT and DT interval observers.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:39:52 GMT""}]","2022-03-16"
"2203.07431","Youngju Song","Youngju Song, Minki Cho, Dongjae Lee, Chung-Kil Hur","Conditional Contextual Refinement (CCR)",,,,,"cs.PL cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Contextual refinement (CR) is one of the standard notions of specifying open
programs. CR has two main advantages: (i) (horizontal and vertical)
compositionality that allows us to decompose a large contextual refinement into
many smaller ones enabling modular and incremental verification, and (ii) no
restriction on programming features thereby allowing, e.g., mutually recursive,
pointer-value passing, and higher-order functions. However, CR has a downside
that it cannot impose conditions on the context since it quantifies over all
contexts, which indeed plays a key role in support of full compositionality and
programming features.
  In this paper, we address the problem of finding a notion of refinement that
satisfies all three requirements: support of full compositionality, full
(sequential) programming features, and rich conditions on the context. As a
solution, we propose a new theory of refinement, called CCR (Conditional
Contextual Refinement), and develop a verification framework based on it, which
allows us to modularly and incrementally verify a concrete module against an
abstract module under separation-logic-style pre and post conditions about
external modules. It is fully formalized in Coq and provides a proof mode that
combines (i) simulation reasoning about preservation of sideffects such as IO
events and termination and (ii) propositional reasoning about pre and post
conditions. Also, the verification results are combined with CompCert, so that
we formally establish behavioral refinement from top-level abstract programs,
all the way down to their assembly code.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:40:46 GMT""}]","2022-03-16"
"2203.07432","Miguel M. Ugeda","Wen Wan, Darshana Wickramaratne, Paul Dreher, Rishav Harsh, I. I.
  Mazin and Miguel M. Ugeda","Nontrivial doping evolution of electronic properties in
  Ising-superconducting alloys",,"Advanced Materials (2022)","10.1002/adma.202200492",,"cond-mat.mtrl-sci cond-mat.mes-hall cond-mat.str-el cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  Transition metal dichalcogenides offer unprecedented versatility to engineer
2D materials with tailored properties to explore novel structural and
electronic phase transitions. In this work, we present the atomic-scale
evolution of the electronic ground state of a monolayer of
Nb$_{1-\delta}$Mo$_{\delta}$Se$_2$ across the entire alloy composition range (0
< ${\delta}$ < 1) using low-temperature (300 mK) scanning tunneling microscopy
and spectroscopy (STM/STS). In particular, we investigate the atomic and
electronic structure of this 2D alloy throughout the metal to semiconductor
transition (monolayer NbSe$_2$ to MoSe$_2$). Our measurements let us extract
the effective doping of Mo atoms, the bandgap evolution and the band shifts,
which are monotonic with ${\delta}$. Furthermore, we demonstrate that
collective electronic phases (charge density wave and superconductivity) are
remarkably robust against disorder. We further show that the superconducting TC
changes non-monotonically with doping. This contrasting behavior in the normal
and superconducting state is explained using first-principles calculations. We
show that Mo doping decreases the density of states at the Fermi level and the
magnitude of pair-breaking spin fluctuations as a function of Mo content. Our
results paint a detailed picture of the electronic structure evolution in 2D
TMD alloys, which is of utmost relevance for future 2D materials design.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:41:38 GMT""}]","2022-03-16"
"2203.07433","Kristen Engel","Kristen Engel, Yiqing Hua, Taixiang Zeng, Mor Naaman","Characterizing Reddit Participation of Users Who Engage in the QAnon
  Conspiracy Theories","22 pages","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 53
  (April 2022)","10.1145/3512900",,"cs.SI cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Widespread conspiracy theories may significantly impact our society. This
paper focuses on the QAnon conspiracy theory, a consequential conspiracy theory
that started on and disseminated successfully through social media. Our work
characterizes how Reddit users who have participated in QAnon-focused
subreddits engage in activities on the platform, especially outside their own
communities. Using a large-scale Reddit moderation action against QAnon-related
activities in 2018 as the source, we identified 13,000 users active in the
early QAnon communities. We collected the 2.1 million submissions and 10.8
million comments posted by these users across all of Reddit from October 2016
to January 2021. The majority of these users were only active after the
emergence of the QAnon Conspiracy theory and decreased in activity after
Reddit's 2018 QAnon ban. A qualitative analysis of a sample of 915 subreddits
where the ""QAnon-enthusiastic"" users were especially active shows that they
participated in a diverse range of subreddits, often of unrelated topics to
QAnon. However, most of the users' submissions were concentrated in subreddits
that have sympathetic attitudes towards the conspiracy theory, characterized by
discussions that were pro-Trump, or emphasized unconstricted behavior (often
anti-establishment and anti-interventionist). Further study of a sample of
1,571 of these submissions indicates that most consist of links from
low-quality sources, bringing potential harm to the broader Reddit community.
These results point to the likelihood that the activities of early QAnon users
on Reddit were dedicated and committed to the conspiracy, providing
implications on both platform moderation design and future research.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:41:40 GMT""},{""version"":""v2"",""created"":""Wed, 16 Mar 2022 00:55:11 GMT""},{""version"":""v3"",""created"":""Thu, 16 Mar 2023 22:47:54 GMT""}]","2023-03-20"
"2203.07434","Lukas Broers","Lukas Broers and Ludwig Mathey","Floquet Engineering of Non-Equilibrium Superradiance",,"SciPost Phys. 14, 018 (2023)","10.21468/SciPostPhys.14.2.018",,"cond-mat.mes-hall quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate the emergence of a non-equilibrium superradiant phase in the
dissipative Rabi-Dicke model. This phase is characterized by a photonic steady
state that oscillates with a frequency close to the cavity frequency, in
contrast to the constant photonic steady state of the equilibrium superradiant
phase in the Dicke model. We relate this superradiant phase to the population
inversion of Floquet states by introducing a Schwinger representation of the
driven two-level systems in the cavity. This inversion is depleted near Floquet
energies that are resonant with the cavity frequency to sustain a coherent
light-field. In particular, our model applies to solids within a two-band
approximation, in which the electrons act as Schwinger fermions. We propose to
use this Floquet-assisted superradiant phase to obtain controllable optical
gain for a laser-like operation.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:42:32 GMT""}]","2023-02-15"
"2203.07435","Alessia Garofalo","A. Garofalo, H. E. Delgado, L. M. Sarro, G. Clementini, T. Muraveva,
  M. Marconi, V. Ripepi","New LZ and PW(Z) relations of RR Lyrae stars calibrated with Gaia EDR3
  parallaxes","22 pages, 14 figures, accepted for publication in MNRAS",,"10.1093/mnras/stac735",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present new luminosity-metallicity (LZ; MV-[Fe/H] and MG-[Fe/H]) relations
and, for the first time, empirical, Gaia three-band (G,GBP,GRP)
period-Wesenheit-metallicity (PWZ) relations of RR Lyrae stars (RRLs) derived
using a hierarchical Bayesian approach and new accurate parallaxes published
for these variables in the Gaia Early Data Release 3 (EDR3). In a previous
study we obtained Bayesian hierarchically-derived LZ relations from a sample of
about four hundred Milky Way field RRLs with G-band light curves and
trigonometric parallaxes published in the Gaia Data Release 2 (DR2), using V
mean magnitudes, metallicities, absorptions and pulsation periods available in
the literature. We now extend that study in two directions. Firstly, we update
our previous results using trigonometric parallaxes from Gaia EDR3 and
incorporate the Bayesian analysis of a first empirical PWZ relation derived
using those field RRLs with G, GBP and GRP time-series photometry available in
Gaia DR2. Secondly, we use Bayesian inference to derive LZ relations and
empirical PW Gaia three-band relations from 385 RRLs belonging to 15 Milky Way
globular clusters (GC) with literature-compiled spectroscopic metallicities
ranging from -0.36 to -2.39 dex and prior distances extending from 2.2 to 41.2
kpc. From the samples of RRLs analysed in this paper we infer a mean Gaia EDR3
zero-point offset of -0.028 mas with median values ranging from -0.033 (LZ and
PWZ models for field stars) to -0.024 mas (LZ model in the V-band for GC RRLs).
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:44:53 GMT""}]","2022-03-30"
"2203.07436","Alexander Mathis","Shaokai Ye and Anastasiia Filippova and Jessy Lauer and Maxime Vidal
  and Steffen Schneider and Tian Qiu and Alexander Mathis and Mackenzie
  Weygandt Mathis","SuperAnimal models pretrained for plug-and-play analysis of animal
  behavior","Videos are available at deeplabcut.org",,,,"cs.CV cs.AI q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantification of behavior is critical in applications ranging from
neuroscience, veterinary medicine and animal conservation efforts. A common key
step for behavioral analysis is first extracting relevant keypoints on animals,
known as pose estimation. However, reliable inference of poses currently
requires domain knowledge and manual labeling effort to build supervised
models. We present a series of technical innovations that enable a new method,
collectively called SuperAnimal, to develop and deploy deep learning models
that require zero additional human labels and model training. SuperAnimal
allows video inference on over 45 species with only two global classes of
animal pose models. If the models need fine-tuning, we show SuperAnimal models
are 10$\times$ more data efficient and outperform prior transfer learning
approaches. Moreover, we provide a new video-adaptation method to perform
unsupervised refinement of videos, and we illustrate the utility of our model
in behavioral classification. Collectively, this presents a data-efficient,
plug-and-play solution for behavioral analysis.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:46:57 GMT""},{""version"":""v2"",""created"":""Sun, 19 Mar 2023 14:44:32 GMT""}]","2023-03-21"
"2203.07437","Simone Parisotto Dr","Simone Parisotto, Ninetta Leone, Carola-Bibiane Sch\""onlieb,
  Alessandro Launaro","Unsupervised Clustering of Roman Potsherds via Variational Autoencoders","16 pages, 11 figures",,,,"cs.CV cs.AI cs.DB cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we propose an artificial intelligence imaging solution to
support archaeologists in the classification task of Roman commonware
potsherds. Usually, each potsherd is represented by its sectional profile as a
two dimensional black-white image and printed in archaeological books related
to specific archaeological excavations. The partiality and handcrafted variance
of the fragments make their matching a challenging problem: we propose to pair
similar profiles via the unsupervised hierarchical clustering of non-linear
features learned in the latent space of a deep convolutional Variational
Autoencoder (VAE) network. Our contribution also include the creation of a
ROman COmmonware POTtery (ROCOPOT) database, with more than 4000 potsherds
profiles extracted from 25 Roman pottery corpora, and a MATLAB GUI software for
the easy inspection of shape similarities. Results are commented both from a
mathematical and archaeological perspective so as to unlock new research
directions in both communities.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:56:13 GMT""}]","2022-03-16"
"2203.07438","Rene Mendez Dr.","Miguel Videla, Rene A. Mendez, Ruben M. Claveria, Jorge F. Silva,
  Marcos E. Orchard","Bayesian inference in single-line spectroscopic binaries with a visual
  orbit","Accepted for publication to the Astronomical Journal.39 pages, 7
  Tables, 18 Figures, two Appendices",,"10.3847/1538-3881/ac5ab4",,"astro-ph.SR astro-ph.IM physics.comp-ph physics.data-an","http://creativecommons.org/licenses/by/4.0/","  We present a Bayesian inference methodology for the estimation of orbital
parameters on single-line spectroscopic binaries with astrometric data, based
on the No-U-Turn sampler Markov chain Monte Carlo algorithm. Our approach is
designed to provide a precise and efficient estimation of the joint posterior
distribution of the orbital parameters in the presence of partial and
heterogeneous observations. This scheme allows us to directly incorporate prior
information about the system - in the form of a trigonometric parallax, and an
estimation of the mass of the primary component from its spectral type - to
constrain the range of solutions, and to estimate orbital parameters that
cannot be usually determined (e.g. the individual component masses), due to the
lack of observations or imprecise measurements. Our methodology is tested by
analyzing the posterior distributions of well-studied double-line spectroscopic
binaries treated as single-line binaries by omitting the radial velocity data
of the secondary object. Our results show that the system's mass ratio can be
estimated with an uncertainty smaller than 10% using our approach. As a proof
of concept, the proposed methodology is applied to twelve single-line
spectroscopic binaries with astrometric data that lacked a joint
astrometric-spectroscopic solution, for which we provide full orbital elements.
Our sample-based methodology allows us also to study the impact of different
posterior distributions in the corresponding observations space. This novel
analysis provides a better understanding of the effect of the different sources
of information on the shape and uncertainty of the orbit and radial velocity
curve.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:59:57 GMT""}]","2022-04-27"
"2203.07439","Torsten Bringmann","Torsten Bringmann and Joakim Edsj\""o","DarkSUSY 6.3: Freeze-in, out-of-equilibrium freeze-out, cosmic-ray
  upscattering and further new features","17 pages, to appear in the proceedings of the 'Computational Tools
  for High Energy Physics and Cosmology' (CompTools2021) workshop",,,"CERN-TH-2022-031","hep-ph astro-ph.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  DarkSUSY is a versatile tool for precision calculations of a large variety of
dark matter-related signals, ranging from predictions for the dark matter relic
density to dark matter self-interactions and rates relevant for direct and
indirect detection experiments. In all of these areas significant new code
additions have been made in recent years, since the release of DarkSUSY 6 in
2018, which we summarize in this overview. In particular, DarkSUSY now allows
users to compute the relic density for feebly interacting massive particles via
the freeze-in mechanism, but also offers new routines for freeze-out
calculations in the presence of secluded dark sectors as well as for models
where kinetic equilibrium is not fully established during the freeze-out
process. On the direct detection side, the effect of cosmic-ray upscattering of
dark matter has been fully implemented, leading to a subdominant relativistic
component in the expected dark matter flux at Earth. Finally, updated yields
relevant for indirect searches with gamma rays, neutrinos or charged cosmic
rays have been added; the new default spectra are based on a large number of
Pythia 8 runs, but users can also easily switch between various alternative
spectra. Further code details, including a manual and various concrete example
applications, are provided at www.darksusy.org.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:00:00 GMT""}]","2022-03-16"
"2203.07440","Th\'eo Simon","Th\'eo Simon, Guillermo Franco Abell\'an, Peizhi Du, Vivian Poulin and
  Yuhsin Tsai","Constraining decaying dark matter with BOSS data and the effective field
  theory of large-scale structures","30 pages (including appendices), 17 figures. Comments welcome!","Phys.Rev. D 106 (2022), 023516","10.1103/PhysRevD.106.023516",,"astro-ph.CO hep-ph","http://creativecommons.org/licenses/by/4.0/","  We update cosmological constraints on two decaying dark matter models in
light of BOSS-DR12 data analyzed under the Effective Field Theory of
Large-Scale Structures (EFTofLSS) formalism, together with Planck, Pantheon and
other BOSS measurements of the baryonic acoustic oscillation (BAO). In the
first model, a fraction $f_{\rm dcdm}$ of cold dark matter (CDM) decays into
dark radiation (DR) with a lifetime $\tau$. In the second model (recently
suggested as a potential resolution to the $S_8$ tension), all the CDM decays
with a lifetime $\tau$ into DR and a massive warm dark matter (WDM) particle,
with a fraction $\varepsilon$ of the CDM rest mass energy transferred to the
DR. Using numerical codes from the recent literature, we perform the first
calculation of the mildly non-linear (matter and galaxy) power spectra with the
EFTofLSS for these two models. In the case of DR products, we obtain the
constraints $f_{\rm dcdm}\lesssim0.022$ (95\% C.L.) for lifetimes shorter than
the age of the universe, and $\tau/f_{\rm dcdm} \gtrsim 250$ Gyr in the
long-lived regime assuming $f_{\rm dcdm}\to1$. We show that Planck data
contributes the most to these constraints, with EFTofBOSS providing a marginal
improvement over conventional BAO and redshift space distortions ($f\sigma_8$)
data. In the case of DR and WDM decay products, we find that EFTofBOSS data
significantly improves the constraints at 68\% C.L. on the CDM lifetime with a
$S_8$ prior from KiDS-1000. We show that, in order to fit EFTofBOSS data while
lowering $S_8$ to match KiDS-1000, the best-fit model has a longer lifetime
$\tau = 120$ Gyr, with a larger kick velocity $v_{\rm kick}/c \simeq
\varepsilon \simeq 1.2\%$, than that without EFTofBOSS ($\tau = 43$ Gyr,
$\varepsilon =0.6\%$). We anticipate that future surveys will provide exquisite
constraints on such models.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:00:03 GMT""},{""version"":""v2"",""created"":""Wed, 6 Jul 2022 10:29:34 GMT""}]","2023-03-10"
"2203.07441","Luca Pattavina Dr.","J.W. Beeman, G. Benato, C. Bucci, L. Canonica, P. Carniti, E. Celi, M.
  Clemenza, A. D'Addabbo, F.A. Danevich, S. Di Domizio, S. Di Lorenzo, O.M.
  Dubovik, N. Ferreiro Iachellini, F. Ferroni, E. Fiorini, S. Fu, A. Garai, S.
  Ghislandi, L. Gironi, P. Gorla, C. Gotti, P.V. Guillaumon, D.L. Helis, G.P.
  Kovtun, M. Mancuso, L. Marini, M. Olmi, L. Pagnanini, L. Pattavina, G.
  Pessina, F. Petricca, S. Pirro, S. Pozzi, A. Puiu, S. Quitadamo, J. Rothe,
  A.P. Scherban, S. Schoenert, D.A. Solopikhin, R. Strauss, E. Tarabini, V.I.
  Tretyak, I.A. Tupitsyna and V. Wagner","Radiopurity of a kg-scale PbWO$_4$ cryogenic detector produced from
  archaeological Pb for the RES-NOVA experiment","New analysis with high statistic","Eur. Phys. J. C (2022) 82:692","10.1140/epjc/s10052-022-10656-8",,"physics.ins-det astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  RES-NOVA is a newly proposed experiment for the detection of neutrinos from
astrophysical sources, mainly Supernovae, using an array of cryogenic detectors
made of PbWO$_4$ crystals produced from archaeological Pb. This unconventional
material, characterized by intrinsic high radiopurity, enables to achieve
low-background levels in the region of interest for the neutrino detection via
Coherent Elastic neutrino-Nucleus Scattering (CE$\nu$NS). This signal lies at
the detector energy threshold, O(1 keV), and it is expected to be hidden by
naturally occurring radioactive contaminants of the crystal absorber. Here, we
present the results of a radiopurity assay on a 0.84 kg PbWO$_4$ crystal
produced from archaeological Pb operated as a cryogenic detector. The crystal
internal radioactive contaminations are: $^{232}$Th $<$40 $\mu$Bq/kg, $^{238}$U
$<$30 $\mu$Bq/kg, $^{226}$Ra 1.3 mBq/kg and $^{210}$Pb 22.5 mBq/kg. We present
also a background projection for the final experiment and possible mitigation
strategies for further background suppression. The achieved results demonstrate
the feasibility of realizing this new class of detectors.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:00:06 GMT""},{""version"":""v2"",""created"":""Mon, 28 Mar 2022 08:07:51 GMT""}]","2022-08-11"
"2203.07442","Massimo Vaglio","Massimo Vaglio, Costantino Pacilio, Andrea Maselli and Paolo Pani","The multipolar structure of rotating boson stars","11+3 pages, 11 figures, data for the quadrupole and octupole moments
  available at https://web.uniroma1.it/gmunu",,"10.1103/PhysRevD.105.124020",,"gr-qc astro-ph.HE hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The relativistic multipole moments provide a key ingredient to characterize
the gravitational field around compact astrophysical objects. They play a
crucial role in the description of the orbital evolution of coalescing binary
systems and encode valuable information on the nature of the binary's
components, which leaves a measurable imprint in their gravitational-wave
emission. We present a new study on the multipolar structure of a class of
arbitrarily spinning boson stars with quartic self-interactions in the large
coupling limit, where these solutions are expected to be stable. Our results
strengthen and extend previous numerical analyses, showing that even for the
most compact configurations the multipolar structure deviates significantly
from that of a Kerr black hole. We provide accurate data for the multipole
moments as functions of the object's mass and spin, which can be directly used
to construct inspiral waveform approximants and to perform parameter
estimations and searches for boson star binaries.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:00:08 GMT""}]","2022-06-22"
"2203.07443","Giuliano Giudici","Giuliano Giudici, J. Ignacio Cirac, Norbert Schuch","Locality optimization for parent Hamiltonians of Tensor Networks",,"Phys. Rev. B 106, 035109 (2022)","10.1103/PhysRevB.106.035109",,"cond-mat.str-el quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tensor Network states form a powerful framework for both the analytical and
numerical study of strongly correlated phases. Vital to their analytical
utility is that they appear as the exact ground states of associated parent
Hamiltonians, where canonical proof techniques guarantee a controlled ground
space structure. Yet, while those Hamiltonians are local by construction, the
known techniques often yield complex Hamiltonians which act on a rather large
number of spins. In this paper, we present an algorithm to systematically
simplify parent Hamiltonians, breaking them down into any given basis of
elementary interaction terms. The underlying optimization problem is a
semidefinite program, and thus the optimal solution can be found efficiently.
Our method exploits a degree of freedom in the construction of parent
Hamiltonians -- the excitation spectrum of the local terms -- over which it
optimizes such as to obtain the best possible approximation. We benchmark our
method on the AKLT model and the Toric Code model, where we show that the
canonical parent Hamiltonians (acting on 3 or 4 and 12 sites, respectively) can
be broken down to the known optimal 2-body and 4-body terms. We then apply our
method to the paradigmatic Resonating Valence Bond (RVB) model on the kagome
lattice. Here, the simplest previously known parent Hamiltonian acts on all the
12 spins on one kagome star. With our optimization algorithm, we obtain a
vastly simpler Hamiltonian: We find that the RVB model is the exact ground
state of a parent Hamiltonian whose terms are all products of at most four
Heisenberg interactions, and whose range can be further constrained, providing
a major improvement over the previously known 12-body Hamiltonian.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:01:07 GMT""}]","2022-07-12"
"2203.07444","Sandor P. Fekete","S\'andor P. Fekete and Phillip Keldenich and Dominik Krupke and Stefan
  Schirra","Minimum Partition into Plane Subgraphs: The CG:SHOP Challenge 2022","13 pages, 5 figures, 1 table",,,,"cs.CG cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give an overview of the 2022 Computational Geometry Challenge targeting
the problem Minimum Partition into Plane Subsets, which consists of
partitioning a given set of line segments into a minimum number of non-crossing
subsets.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:02:24 GMT""}]","2022-03-16"
"2203.07445","Matteo Mariantoni","J. H. B\'ejanin, Y. Ayadi, X. Xu, C. Zhu, H. R. Mohebbi, and M.
  Mariantoni","Fluctuation Spectroscopy of Two-Level Systems in Superconducting
  Resonators","20 two-column pages (including App. and Supplement), 12 figures, 3
  tables","Phys. Rev. Applied 18, 034009 (2022)","10.1103/PhysRevApplied.18.034009",,"quant-ph cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Superconducting quantum computing is experiencing a tremendous growth.
Although major milestones have already been achieved, useful quantum-computing
applications are hindered by a variety of decoherence phenomena. Decoherence
due to two-level systems (TLSs) hosted by amorphous dielectric materials is
ubiquitous in planar superconducting devices. We use high-quality quasilumped
element resonators as quantum sensors to investigate TLS-induced loss and
noise. We perform two-tone experiments with a probe and pump electric field;
the pump is applied at different power levels and detunings. We measure and
analyze time series of the quality factor and resonance frequency for very long
time periods, up to 1000 h. We additionally carry out simulations based on the
TLS interacting model in presence of a pump field. We find that loss and noise
are reduced at medium and high power, matching the simulations, but not at low
power.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:05:02 GMT""}]","2022-10-21"
"2203.07446","Sibasish Laha","Sibasish Laha (NASA-GSFC), Eileen Meyer, Agniva Roychowdhury, Josefa
  Becerra Gonz\'alez, J. A. Acosta-Pulido, Aditya Thapa, Ritesh Ghosh, Ehud
  Behar, Luigi C. Gallo, Gerard A. Kriss, Francesca Panessa, Stefano Bianchi,
  Fabio La Franca, Nicolas Scepi, Mitchell C. Begelman, Anna Lia Longinotti,
  Elisabeta Lusso, Samantha Oates, Matt Nicholl, and S. Bradley Cenko","A radio, optical, UV and X-ray view of the enigmatic changing look
  Active Galactic Nucleus 1ES~1927+654 from its pre- to post-flare states","Resubmitted to ApJ following minor comments from the referee",,"10.3847/1538-4357/ac63aa",,"astro-ph.HE astro-ph.CO astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  The nearby type-II AGN 1ES1927+654 went through a violent changing-look (CL)
event beginning December 2017 during which the optical and UV fluxes increased
by four magnitudes over a few months, and broad emission lines newly appeared
in the optical/UV. By July 2018 the X-ray coronal emission had completely
vanished, only to reappear a few months later. In this work we report the
evolution of the radio, optical, UV and X-rays from the pre-flare state through
mid-2021 with new and archival data from the Very Long Baseline Array (VLBA),
the European VLBI Network, the Very Large Array (VLA), the Telescopio Nazionale
Galileo (TNG), Gran Telescopio Canarias (GTC), The Neil Gehrels Swift
observatory and XMM-Newton. The main results from our work are: (1) The source
has returned to its pre-CL state in optical, UV, and X-ray; the disk-corona
relation has been re-established as has been in the pre-CL state, with an
$\alpha_{\rm OX}\sim 1.02$. The optical spectra are dominated by narrow
emission lines. (2) The UV light curve follows a shallower slope of $\propto
t^{-0.91\pm 0.04}$ compared to that predicted by a tidal disruption event. We
conjecture that a magnetic flux inversion event is the possible cause for this
enigmatic event. (3) The compact radio emission which we tracked in the pre-CL
(2014), during CL (2018) and post-CL(2021) at spatial scales $<1$ pc was at its
lowest level during the changing look event in 2018, nearly contemporaneous
with a low $2-10$ keV emission. The radio to X-ray ratio of the compact source
$L_{\rm Radio}/L_{\rm X-ray}\sim 10^{-5.5}$, follows the Gudel-Benz relation,
typically found in coronally active stars, and several AGN. (4) We do not
detect any presence of nascent jets at the spatial scales of $\sim 5-10$ pc.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:05:10 GMT""}]","2022-05-25"
"2203.07447","Christophe Letellier","Irene Sendi\~na-Nadal and Christophe Letellier","Observability analysis and observer design of networks of R\""ossler
  systems","14 pages, 13 figures, submitted to Chaos",,,,"nlin.CD","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We address the problem of retrieving the full state of a network of R\""ossler
systems from the knowledge of the actual state of a limited set of nodes. The
selection of the nodes where sensors are placed is carried out in a
hierarchical way through a procedure based on graphical and symbolic
observability approaches. By using a map directly obtained from the governing
equations, we design a nonlinear network observer which is able to unfold the
state of the non measured nodes with minimal error. For sparse networks, the
number of sensors scales with half the network size and node reconstruction
errors are lower in networks with heterogeneous degree distributions. The
method performs well even in the presence of parameter mismatch and
non-coherent dynamics and, therefore, we expect it to be useful for designing
robust network control laws.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:06:43 GMT""}]","2022-03-16"
"2203.07448","Graham Reid","G. H. Reid, Mingwu Lu, A. R. Fritsch, A. M. Pi\~neiro, I. B. Spielman","Observation of dynamical topology in 1D",,"Phys. Rev. Lett. 129, 123202 (2022)","10.1103/PhysRevLett.129.123202",,"cond-mat.quant-gas quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nontrivial topology in lattices is characterized by invariants--such as the
Zak phase for one dimensional (1D) lattices--derived from wave functions
covering the Brillouin zone. We realized the 1D bipartite Rice-Mele (RM)
lattice using ultracold $^{87}$Rb and focus on lattice configurations
possessing various combinations of chiral, time-reversal and particle-hole
symmetries. We quenched between configurations and used a form of quantum state
tomography, enabled by diabatically tuning lattice parameters, to directly
follow the time evolution of the Zak phase as well as a chiral winding number.
The Zak phase evolves continuously; however, when chiral symmetry transiently
appears in the out-of-equilibrium system, the chiral winding number is well
defined and can take on different integer values. When quenching between two
configurations obeying all three symmetries the Zak phase is time independent;
we confirm the contrasting prediction of [M. McGinley and N. R.Cooper, PRL 121
090401 (2018)] that chiral symmetry is periodically restored, at which times
the winding number changes by $\pm 2$, yielding values that are not present in
the native RM Hamiltonian.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:07:43 GMT""},{""version"":""v2"",""created"":""Wed, 20 Apr 2022 20:45:48 GMT""}]","2022-09-19"
"2203.07449","Chandramouli Chowdhury","Chandramouli Chowdhury and Olga Papadoulaki","Recovering information in an asymptotically flat spacetime in quantum
  gravity","26 pages, 1 figure, 1 Mathematica file",,"10.1088/1361-6382/aca192",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As an extension of arXiv:\{2002.02448, 2008.10740\} we present a physical
protocol that a set of observers can use to detect a pure state in the bulk
when they are spread across a small cut near $\mathcal{I}^+_-$ in flat
spacetime. The protocol involves the modification of a bulk state using simple
unitary operators and measurements of the energy of the state. The states that
we study are constructed by acting with low energy operators on a vacuum state
such that a perturbative analysis is valid. We restrict ourselves to $3+1$
dimensional spacetimes and only consider massless excitations. From this
analysis, the principle of holography of information becomes manifest in the
case of asymptotically flat spacetime.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:07:50 GMT""}]","2022-12-07"
"2203.07450","Sowmya Vajjala","Justin Lee and Sowmya Vajjala","A Neural Pairwise Ranking Model for Readability Assessment","to appear in Findings of ACL 2022",,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Automatic Readability Assessment (ARA), the task of assigning a reading level
to a text, is traditionally treated as a classification problem in NLP
research. In this paper, we propose the first neural, pairwise ranking approach
to ARA and compare it with existing classification, regression, and
(non-neural) ranking methods. We establish the performance of our model by
conducting experiments with three English, one French and one Spanish datasets.
We demonstrate that our approach performs well in monolingual single/cross
corpus testing scenarios and achieves a zero-shot cross-lingual ranking
accuracy of over 80% for both French and Spanish when trained on English data.
Additionally, we also release a new parallel bilingual readability dataset in
English and French. To our knowledge, this paper proposes the first neural
pairwise ranking model for ARA, and shows the first results of cross-lingual,
zero-shot evaluation of ARA with neural models.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:11:03 GMT""}]","2022-03-16"
"2203.07451","Marco Serone","Riccardo Ciccone, Lorenzo Di Pietro, Marco Serone","On the Inhomogeneous Phase of the Chiral Gross-Neveu Model","6 pages, one figure; v2: several improvements, matches version
  accepted by PRL",,"10.1103/PhysRevLett.129.071603",,"hep-th hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There is substantial evidence that the ground state of the 2d chiral
Gross-Neveu model, in the presence of a $U(1)$ fermion number chemical
potential $\mu$ and in the large $N$ limit, is given by a {\it chiral spiral}
phase, namely an inhomogeneous phase with a chiral condensate having a
spatially periodic phase. We show that the chiral spiral configuration persists
at finite $N$ and $T=0$ for any $\mu>0$. Our analysis is based on non-abelian
bosonization, that relates the model to a $U(N)_1$ WZW model deformed by
current-current interactions. In this description the appearance of the
inhomogeneous phase is surprisingly simple. We also rederive the phase diagram
of the large $N$ chiral Gross-Neveu model via a direct diagrammatic
computation, finding agreement with previous results in the literature.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:11:15 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jul 2022 08:34:11 GMT""}]","2022-08-31"
"2203.07452","Khaled Benaggoune","Khaled Benaggoune, Zeina Al Masry, Jian Ma, Christine Devalland, L.H
  Mouss and Noureddine Zerhouni","A deep learning pipeline for breast cancer ki-67 proliferation index
  scoring",,,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Ki-67 proliferation index is an essential biomarker that helps
pathologists to diagnose and select appropriate treatments. However, automatic
evaluation of Ki-67 is difficult due to nuclei overlapping and complex
variations in their properties. This paper proposes an integrated pipeline for
accurate automatic counting of Ki-67, where the impact of nuclei separation
techniques is highlighted. First, semantic segmentation is performed by
combining the Squeez and Excitation Resnet and Unet algorithms to extract
nuclei from the background. The extracted nuclei are then divided into
overlapped and non-overlapped regions based on eight geometric and statistical
features. A marker-based Watershed algorithm is subsequently proposed and
applied only to the overlapped regions to separate nuclei. Finally, deep
features are extracted from each nucleus patch using Resnet18 and classified
into positive or negative by a random forest classifier. The proposed
pipeline's performance is validated on a dataset from the Department of
Pathology at H\^opital Nord Franche-Comt\'e hospital.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:13:06 GMT""}]","2022-03-16"
"2203.07453","Spenser Talkington","Spenser Talkington, Martin Claassen","Dissipation Induced Flat Bands","5+10 pages, 2 figures","Phys. Rev. B 106, L161109 (2022)","10.1103/PhysRevB.106.L161109",,"cond-mat.str-el cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Flat bands are an ideal environment to realize unconventional electronic
phases. Here, we show that fermionic systems with dissipation governed by a
Bloch Lindbladian can realize dispersionless bands for sufficiently strong
coupling to an appropriately engineered bath. These flat bands emerge in a
""dark space"" of the system-environment coupling and are long-lived by virtue of
symmetry protection from dissipation. We exhibit the robustness of this
mechanism for general one and two band models with and without spin, and
discuss conditions for their experimental realization such as in a 2D material
on a superconducting substrate.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:16:55 GMT""},{""version"":""v2"",""created"":""Tue, 18 Oct 2022 22:04:46 GMT""}]","2022-10-27"
"2203.07454","Erik Johnson","Erik C. Johnson, Eric Q. Nguyen, Blake Schreurs, Chigozie S. Ewulum,
  Chace Ashcraft, Neil M. Fendley, Megan M. Baker, Alexander New, Gautam K.
  Vallabha","L2Explorer: A Lifelong Reinforcement Learning Assessment Environment","10 Pages submitted to AAAI AI for Open Worlds Symposium 2022",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Despite groundbreaking progress in reinforcement learning for robotics,
gameplay, and other complex domains, major challenges remain in applying
reinforcement learning to the evolving, open-world problems often found in
critical application spaces. Reinforcement learning solutions tend to
generalize poorly when exposed to new tasks outside of the data distribution
they are trained on, prompting an interest in continual learning algorithms. In
tandem with research on continual learning algorithms, there is a need for
challenge environments, carefully designed experiments, and metrics to assess
research progress. We address the latter need by introducing a framework for
continual reinforcement-learning development and assessment using Lifelong
Learning Explorer (L2Explorer), a new, Unity-based, first-person 3D exploration
environment that can be continuously reconfigured to generate a range of tasks
and task variants structured into complex and evolving evaluation curricula. In
contrast to procedurally generated worlds with randomized components, we have
developed a systematic approach to defining curricula in response to controlled
changes with accompanying metrics to assess transfer, performance recovery, and
data efficiency. Taken together, the L2Explorer environment and evaluation
approach provides a framework for developing future evaluation methodologies in
open-world settings and rigorously evaluating approaches to lifelong learning.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:20:26 GMT""}]","2022-03-16"
"2203.07455","Matthew Sullivan","Shekhar Adhikari, Samuel D. Lane, Ian M. Lewis, Matthew Sullivan","Complex Scalar Singlet Model Benchmarks for Snowmass","contribution to Snowmass 2021, 13 pages, 2 figures",,,,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this contribution to Snowmass 2021, we present benchmark parameters for
the general complex scalar singlet model. The complex scalar singlet extension
has three massive scalar states with interesting decay chains which will depend
on the exact mass hierarchy of the system. We find maximum branching ratios for
resonant double Standard Model-like Higgs production, resonant production of a
Standard Model-like Higgs and a new scalar, and double resonant new scalar
production. These branching ratios are between 0.7 and 1. This is particularly
interesting because instead of direct production, the main production of a new
scalar resonance may be from the $s$-channel production and decay of another
scalar resonance. That is, it is still possible for discovery of new scalar
resonances to be from the cascade of one resonance to another. We choose our
benchmark points to have to have a large range of signatures: multi-$b$
production, multi-$W$ and $Z$ production, and multi-125 GeV SM-like Higgs
production. These benchmark points can provide various spectacular signatures
that are consistent with current experimental and theoretical bounds. This is a
summary of results in Ref. [1].
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:21:56 GMT""}]","2022-03-16"
"2203.07456","Connor Yako","Connor L. Yako, Shenli Yuan, J. Kenneth Salisbury","Designing Underactuated Graspers with Dynamically Variable Geometry
  Using Potential Energy Map Based Analysis","7 pages, 7 figures",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we present a potential energy map based approach that provides
a framework for the design and control of a robotic grasper. Unlike other
potential energy map approaches, our framework is able to consider friction for
a more realistic perspective on grasper performance. Our analysis establishes
the importance of including variable geometry in a grasper design, namely with
regards to palm width, link lengths, and transmission ratio. We demonstrate the
use of this method specifically for a two-phalanx tendon-pulley underactuated
grasper, and show how various design parameters - palm width, link lengths, and
transmission ratios - impact the grasping and manipulation performance of a
specific design across a range of object sizes and friction coefficients.
Optimal grasping designs have palms that scale with object size, and
transmission ratios that scale with the coefficient of friction. Using a custom
manipulation metric we compared a grasper that only dynamically varied its
geometry to a grasper with a variable palm and distinct actuation commands. The
analysis revealed the advantage of the compliant reconfiguration ability
intrinsic to underactuated mechanisms; by varying only the geometry of the
grasper, manipulation of a wide range of objects could be performed.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:23:02 GMT""}]","2022-03-16"
"2203.07457","Ping-Han Chu","Pinghan Chu, Michael R. James, Zhehui Wang","Efficiency Studies of Fast Neutron Tracking using MCNP",,"J. Nucl. Eng. 2022, 3(2), 117-127","10.3390/jne3020007","LA-UR-22-22369","physics.ins-det nucl-ex","http://creativecommons.org/licenses/by/4.0/","  Fast neutron identification and spectroscopy is of great interest to nuclear
physics experiments. Using the neutron elastic scattering, the fast neutron
momentum can be measured. (Wang and Morris, 2013) introduced the theoretical
concept that the initial fast neutron momentum can be derived from up to three
consecutive elastic collisions between the neutron and the target, including
the information of two consecutive recoil ion tracks and the vertex position of
the third collision or two consecutive elastic collisions with the timing
information. Here we also include the additional possibility of measuring the
deposited energies from the recoil ions. In this paper, we simulate the neutron
elastic scattering using the Monte Carlo N-Particle Transport Code (MCNP) and
study the corresponding neutron detection and tracking efficiency. The
corresponding efficiency and the scattering distances are simulated with
different target materials, especially natural silicon (92.23$\%$ $^{28}$Si,
4.67$\%$ $^{29}$Si, and 3.1$\%$ $^{30}$Si) and helium-4 ($^4$He). The timing of
collision and the recoil ion energy are also investigated, which are important
characters for the detector design. We also calculate the ion travelling range
for different energies using the software, ""The Stopping and Range of Ions in
Matter (SRIM)"", showing that the ion track can be most conveniently observed in
$^4$He unless sub-micron spatial resolution can be obtained in silicon.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:24:04 GMT""},{""version"":""v2"",""created"":""Wed, 4 May 2022 16:34:44 GMT""}]","2022-05-05"
"2203.07458","Kevin Kamm","Marco Di Francesco and Kevin Kamm","On the deterministic-shift extended CIR model in a negative interest
  rate framework",,,,,"q-fin.TR","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose a new exogenous model to address the problem of
negative interest rates that preserves the analytical tractability of the
original Cox-Ingersoll-Ross (CIR) model with a perfect fit to the observed
term-structure. We use the difference of two independent CIR processes and
apply the deterministic-shift extension technique. To allow for a fast
calibration to the market swaption surface, we apply the Gram-Charlier
expansion to calculate the swaption prices in our model. We run several
numerical tests to demonstrate the strengths of this model by using Monte-Carlo
techniques. In particular, the model produces close Bermudan swaption prices
compared to Bloomberg's Hull-White one-factor model. Moreover, it finds
constant maturity swap (CMS) rates very close to Bloomberg's CMS rates.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:27:04 GMT""}]","2022-03-16"
"2203.07459","Vladimir Shiltsev","Robert Ariniello, Sebastien Corde, Xavier Davoine, Henrik Ekerfelt,
  Frederico Fiuza, Max Gilljohann, Laurent Gremillet, Yuliia Mankovska, Henryk
  Piekarz, Pablo San Miguel Claveria, Vladimir Shiltsev, Peter Taborek, Toshiki
  Tajima","Channeling Acceleration in Crystals and Nanostructures and Studies of
  Solid Plasmas: New Opportunities","submitted to Snowmass'2021 Accelerator Frontier (AF6), 15 pages, 7
  Figs",,,,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  Plasma wakefield acceleration (PWA) has shown illustrious progress over the
past two decades of active research and resulted in an impressive demonstration
of O(10 GeV) particle acceleration in O(1 m) long single structures. While
already potentially sufficient for some applications, like, e.g., FELs, the
traditional laser- and beam-driven acceleration in gaseous plasma faces
enormous challenges when it comes to the design of the PWA-based O(1-10 TeV)
high energy $e^+e^-$ colliders due to the complexity of energy staging, low
average geometric gradients, and unprecedented transverse and longitudinal
stability requirements. Channeling acceleration in solid-state plasma of
crystals or nanostructures, e.g., carbon nanotubes (CNTs) or alumna honeycomb
holes, has the promise of ultra-high accelerating gradients O(1-10 TeV/m),
continuous focusing of channeling particles without need of staging, and
ultimately small equilibrium beam emittances naturally obtained while
accelerating.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:30:05 GMT""}]","2022-03-16"
"2203.07460","Tilman Plehn","Anja Butter (ed), Tilman Plehn (ed), Steffen Schumann (ed), Simon
  Badger, Sascha Caron, Kyle Cranmer, Francesco Armando Di Bello, Etienne
  Dreyer, Stefano Forte, Sanmay Ganguly, Dorival Gon\c{c}alves, Eilam Gross,
  Theo Heimel, Gudrun Heinrich, Lukas Heinrich, Alexander Held, Stefan H\""oche,
  Jessica N. Howard, Philip Ilten, Joshua Isaacson, Timo Jan{\ss}en, Stephen
  Jones, Marumi Kado, Michael Kagan, Gregor Kasieczka, Felix Kling, Sabine
  Kraml, Claudius Krause, Frank Krauss, Kevin Kr\""oninger, Rahool Kumar Barman,
  Michel Luchmann, Vitaly Magerya, Daniel Maitre, Bogdan Malaescu, Fabio
  Maltoni, Till Martini, Olivier Mattelaer, Benjamin Nachman, Sebastian Pitz,
  Juan Rojo, Matthew Schwartz, David Shih, Frank Siegert, Roy Stegeman, Bob
  Stienen, Jesse Thaler, Rob Verheyen, Daniel Whiteson, Ramon Winterhalder, and
  Jure Zupan","Machine Learning and LHC Event Generation","Review article based on a Snowmass 2021 contribution","SciPost Phys. 14, 079 (2023)","10.21468/SciPostPhys.14.4.079",,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  First-principle simulations are at the heart of the high-energy physics
research program. They link the vast data output of multi-purpose detectors
with fundamental theory predictions and interpretation. This review illustrates
a wide range of applications of modern machine learning to event generation and
simulation-based inference, including conceptional developments driven by the
specific requirements of particle physics. New ideas and tools developed at the
interface of particle physics and machine learning will improve the speed and
precision of forward simulations, handle the complexity of collision data, and
enhance inference as an inverse simulation problem.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:36:46 GMT""},{""version"":""v2"",""created"":""Wed, 28 Dec 2022 12:29:21 GMT""}]","2023-04-26"
"2203.07461","Dominic Samra","Dominic Samra, Christiane Helling, Tilman Birnstiel","Mineral Snowflakes on Exoplanets and Brown Dwarfs: Coagulation and
  Fragmentation of Cloud Particles with {\sc HyLandS}","33 pages, 19 figures, accepted for publication in A&A","A&A 663, A47 (2022)","10.1051/0004-6361/202142651",,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Brown dwarfs and exoplanets provide unique atmospheric regimes that hold
information about their formation routes and evolutionary states. Modelling
mineral cloud particle formation is key to prepare for missions and instruments
like CRIRES+, JWST and ARIEL as well as possible polarimetry missions like {\sc
PolStar}. The aim is to support more detailed observations that demand greater
understanding of microphysical cloud processes. We extend our kinetic cloud
formation model that treats nucleation, condensation, evaporation and settling
of mixed material cloud particles to consistently model cloud particle-particle
collisions. The new hybrid code, {\sc HyLandS}, is applied to a grid of {\sc
Drift-Phoenix} (T, p)-profiles. Effective medium theory and Mie theory are used
to investigate the optical properties. Turbulence is the main driving process
of collisions, with collisions becoming the dominant process at the cloud base
($p>10^{-4}\,{\rm bar}$). Collisions produce one of three outcomes: fragmenting
atmospheres ($\log_{10}(g)=3$), coagulating atmospheres ($\log_{10}(g)=5$,
$T_{\rm eff} \leq 1800\, {\rm K}$) and condensational growth dominated
atmospheres ($\log_{10}(g\,)=5$, $T_{\rm eff} > 1800\, {\rm K}$). Cloud
particle opacity slope at optical wavelengths (HST) is increased with
fragmentation, as are the silicate features at mid-infrared wavelengths. The
hybrid moment-bin method {\sc HyLandS} demonstrates the feasibility of
combining a moment and a bin method whilst assuring element conservation. It
provides a powerful and fast tool for capturing general trends of particle
collisions, consistently with other microphysical processes. Collisions are
important in exoplanet and brown dwarf atmospheres but cannot be assumed to be
hit-and-stick only. The spectral effects of collisions complicates inferences
of cloud particle size and material composition from observational data.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:38:51 GMT""}]","2022-07-13"
"2203.07462","Salvatore Rappoccio","Ben Nachman, Salvatore Rappoccio, Nhan Tran, Johan Bonilla, Grigorios
  Chachamis, Barry M. Dillon, Sergei V. Chekanov, Robin Erbacher, Loukas
  Gouskos, Andreas Hinzmann, Stefan H\""oche, B. Todd Huffman, Ashutosh. V.
  Kotwal, Deepak Kar, Roman Kogler, Clemens Lange, Matt LeBlanc, Roy Lemmon,
  Christine McLean, Mark S. Neubauer, Tilman Plehn, Debarati Roy, Giordan
  Stark, Jennifer Roloff, Marcel Vos, Chih-Hsiang Yeh, Shin-Shan Yu","Jets and Jet Substructure at Future Colliders",,,,,"hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  Even though jet substructure was not an original design consideration for the
Large Hadron Collider (LHC) experiments, it has emerged as an essential tool
for the current physics program. We examine the role of jet substructure on the
motivation for and design of future energy frontier colliders. In particular,
we discuss the need for a vibrant theory and experimental research and
development program to extend jet substructure physics into the new regimes
probed by future colliders. Jet substructure has organically evolved with a
close connection between theorists and experimentalists and has catalyzed
exciting innovations in both communities. We expect such developments will play
an important role in the future energy frontier physics program.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:44:41 GMT""}]","2022-03-16"
"2203.07463","Ramin Raziperchikolaei","Ramin Raziperchikolaei and Young-joo Chung","Simultaneous Learning of the Inputs and Parameters in Neural
  Collaborative Filtering",,,,,"cs.IR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Neural network-based collaborative filtering systems focus on designing
network architectures to learn better representations while fixing the input to
the user/item interaction vectors and/or ID. In this paper, we first show that
the non-zero elements of the inputs are learnable parameters that determine the
weights in combining the user/item embeddings, and fixing them limits the power
of the models in learning the representations. Then, we propose to learn the
value of the non-zero elements of the inputs jointly with the neural network
parameters. We analyze the model complexity and the empirical risk of our
approach and prove that learning the input leads to a better generalization
bound. Our experiments on several real-world datasets show that our method
outperforms the state-of-the-art methods, even using shallow network structures
with a smaller number of layers and parameters.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:47:38 GMT""}]","2022-03-16"
"2203.07464","Zhipeng Yang","Vicentiu D. R\u{a}dulescu and Zhipeng Yang","A singularly perturbed fractional Kirchhoff problem","23 pages, comments are welcome",,,,"math.AP math.CA","http://creativecommons.org/licenses/by/4.0/","  In this paper, we first establish the uniqueness and non-degeneracy of
positive solutions to the fractional Kirchhoff problem \begin{equation*}
\Big(a+b{\int_{\mathbb{R}^{N}}}|(-\Delta)^{\frac{s}{2}}u|^2dx\Big)(-\Delta)^su+mu=|u|^{p-2}u,\quad
\text{in}\ \mathbb{R}^{N}, \end{equation*} where $a,b,m>0$,
$0<\frac{N}{4}<s<1$, $2<p<2^*_s=\frac{2N}{N-2s}$ and $(-\Delta )^s$ is the
fractional Laplacian. Then, combining this non-degeneracy result and
Lyapunov-Schmidt reduction method, we derive the existence of semiclassical
solutions to the singularly perturbation problem \begin{equation*}
\Big(\varepsilon^{2s}a+\varepsilon^{4s-N}
b{\int_{\mathbb{R}^{N}}}|(-\Delta)^{\frac{s}{2}}u|^2dx\Big)(-\Delta)^su+V(x)u=|u|^{p-2}u,\quad
\text{in}\ \mathbb{R}^{N}, \end{equation*} for $\varepsilon> 0$ sufficiently
small and a potential function $V$.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:49:58 GMT""}]","2022-03-16"
"2203.07465","Sibasish Laha","Sibasish Laha (NASA-GSFC), George Younes, Zorawar Wadiasingh, Bo-Jun
  Wang, Ke-Jia Lee, Noel Klingler, Bing Zhang, Heng Xu, Chin-Feng Zhang,
  Wei-Wei Zhu, Ritesh Ghosh, Amy Lien, Eleonora Troja, S. Bradley Cenko,
  Samantha Oates, Matt Nicholl, Josefa Becerra Gonz\'alez, Eileen Meyer, Tyler
  Parsotan","Simultaneous view of the FRB~180301 with FAST and NICER during a
  bursting phase","Resubmitted to ApJ following referee's minor comments",,"10.3847/1538-4357/ac63a8",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  FRB180301 is one of the most actively repeating fast radio bursts (FRBs)
which has shown polarization angle changes in its radio burst emission, an
indication for their likely origin in the magnetosphere of a highly-magnetized
neutron star. We carried out a multi-wavelength campaign with the FAST radio
telescope and NICER X-ray observatory to investigate any possible X-ray
emission temporally coincident with the bright radio bursts. The observations
took place on 2021 March 4, 9 and 19. We detected five bright radio bursts with
FAST, four of which were strictly simultaneous with the NICER observations. The
peak flux-density of the radio bursts ranged between $28-105$ mJy, the burst
fluence between $27-170$ mJy-ms, and the burst durations between $1.7-12.3$ ms.
The radio bursts from FRB~180301 exhibited complex time domain structure, and
sub-pulses were detected in individual bursts, with no significant circular
polarisation. The linear degree of polarisation in L-band reduced significantly
compared to the 2019 observations. We do not detect any X-ray emission in
excess of the background during the 5ms, 10ms, 100ms, 1sec and 100sec time
intervals at/around the radio-burst barycenter-corrected arrival times, at a
$>5\sigma$ confidence level. The $5\sigma$ upper limits on the X-ray a)
persistent flux is $<7.64\times 10^{-12}\, \rm erg\, cm^{-2}\, s^{-1}$ ,
equivalent to $L_{\rm X}<2.50 \times 10^{45} \rm erg\, s^{-1}$ and b) 5 ms
fluence is $<2\times 10^{-11} \rm erg\, cm^{-2}$, at the radio burst regions.
Using the $5$ ms X-ray fluence upper limit, we can estimate the radio
efficiency $\eta_{R/X} \equiv L_{\rm Radio}/L_{\rm X-ray} \gtrsim 10^{-8}$. The
derived upper limit on $\eta_{R/X}$ is consistent with both magnetospheric
models and synchrotron maser models involving relativistic shocks.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 19:57:32 GMT""}]","2022-05-25"
"2203.07466","Zhipeng Yang","Vicentiu D. R\u{a}dulescu and Zhipeng Yang","Local uniqueness of semiclassical bounded states for a singularly
  perturbed fractional Kirchhoff problem","28 pages, comments are welcome",,,,"math.AP math.CA","http://creativecommons.org/licenses/by/4.0/","  In this paper, we consider the following singularly perturbed fractional
Kirchhoff problem \begin{equation*} \Big(\varepsilon^{2s}a+\varepsilon^{4s-N}
b{\int_{\mathbb{R}^{N}}}|(-\Delta)^{\frac{s}{2}}u|^2dx\Big)(-\Delta)^su+V(x)u=|u|^{p-2}u,\quad
\text{in}\ \mathbb{R}^{N}, \end{equation*} where $a,b>0$, $2s<N<4s$ with
$s\in(0,1)$, $2<p<2^*_s=\frac{2N}{N-2s}$ and $(-\Delta )^s$ is the fractional
Laplacian. For $\varepsilon> 0$ sufficiently small and a bounded continuous
function $V$, we establish a type of local Pohoz\v{a}ev identity by extension
technique and then we can obtain the local uniqueness of semiclassical bounded
solutions based on our recent results on the uniqueness and non-degeneracy of
positive solutions to the limit problem.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:00:22 GMT""}]","2022-03-16"
"2203.07467","Sigvald Marholm","Sigvald Marholm, Sayan Adhikari and Wojciech J. Miloch","Current-driven Langmuir Oscillations and Streaming Instabilities",,,,,"physics.plasm-ph physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  The Buneman and ion acoustic instabilities are usually associated with
different electron and ion drift velocities, in such a way that there is a
large current through the plasma. However, due to the recently discovered
current-driven Langmuir oscillations (1-3), the relative drift velocity in
these configurations will oscillate at the plasma frequency, and with an
amplitude of at least the initial drift velocity. In contrast, the textbooks
assume a constant drift velocity. Since the growth rates arrived at under that
assumption are far less than the plasma frequency, several oscillation periods
will take place during the linear growth phase, and this will dampen the
instabilities. We provide general theoretical derivations of these
oscillations, and show simulation results of the altered behavior of the
instabilities. Towards the end, we hypothesize that drift-averaging might be a
viable method of calculating the modified growth rates.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:02:24 GMT""}]","2022-03-16"
"2203.07468","Zhipeng Yang","Zhipeng Yang","Local uniqueness of multi-peak positive solutions to a class of
  fractional Kirchhoff equations","38 pages, comments are welcome",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  This paper is twofold. In the first part, combining the nondegeneracy result
and Lyapunov-Schmidt reduction method, we derive the existence of multi-peak
positive solutions to the singularly perturbation problem \begin{equation*}
\Big(\varepsilon^{2s}a+\varepsilon^{4s-N}
b{\int_{\mathbb{R}^{N}}}|(-\Delta)^{\frac{s}{2}}u|^2dx\Big)(-\Delta)^su+V(x)u=u^p,\quad
\text{in}\ \mathbb{R}^{N}, \end{equation*} for $\varepsilon> 0$ sufficiently
small, $2s<N<4s$, $1<p<2^*_s-1$ and some mild assumptions on the function $V$.
The main difficulties are from the nonlocal operator mixed the nonlocal term,
which cause the corresponding unperturbed problem turns out to be a system of
partial differential equations, but not a single fractional Kirchhoff equation.
In the second part, under some assumptions on $V$, we show the local uniqueness
of positive multi-peak solutions by using the local Pohoz\v{a}ev identity.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:07:40 GMT""}]","2022-03-16"
"2203.07469","Rafael Frongillo","Rafael Frongillo","Quantum Information Elicitation",,,,,"cs.GT econ.TH quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the classic scoring rule setting, a principal incentivizes an agent to
truthfully report their probabilistic belief about some future outcome. This
paper addresses the situation when this private belief, rather than a classical
probability distribution, is instead a quantum mixed state. In the resulting
quantum scoring rule setting, the principal chooses both a scoring function and
a measurement function, and the agent responds with their reported density
matrix. Several characterizations of quantum scoring rules are presented, which
reveal a familiar structure based on convex analysis. Spectral scores, where
the measurement function is given by the spectral decomposition of the reported
density matrix, have particularly elegant structure and connect to quantum
information theory. Turning to property elicitation, eigenvectors of the belief
are elicitable, whereas eigenvalues and entropy have maximal elicitation
complexity. The paper concludes with a discussion of other quantum information
elicitation settings and connections to the literature.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:07:47 GMT""}]","2022-03-16"
"2203.07470","Simona Achilli Dr.","Simona Achilli (1), Francesco Tumino (2), Andi Rabia (2), Alessio
  Orbelli Biroli (3,4), Andrea Li Bassi (2), Alberto Bossi (3), Nicola Manini
  (1), Giovanni Onida (1), Guido Fratesi (1), Carlo Spartaco Casari (2) ---
  ((1) ETSF and Dipartimento di Fisica 'Aldo Pontremoli', Universit\`a degli
  Studi di Milano, Milano, Italy, (2) Department of Energy, Politecnico di
  Milano, Milano, Italy, (3) Istituto di Scienze e Tecnologie Chimiche 'G.
  Natta', Consiglio Nazionale delle Ricerche (CNR-SCITEC), Milano, PST via G.
  Fantoli 16/15 - 20138 Milano, SmartMatLab Centre, Milano, Italy, (4)
  Dipartimento di Chimica, Universit\`a di Pavia, Pavia, Italy)","Steric hindrance in the on-surface synthesis of diethynyl-linked
  anthracene polymers",,"Phys. Chem. Chem. Phys., 2022,24, 13616-13624","10.1039/D2CP00730D",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Hybrid sp-sp2 structures can be efficiently obtained on metal substrates via
on-surface synthesis. The choice of both the precursor and of the substrate
impacts on the effectiveness of the process and the stability of the formed
structures. Here we demonstrate that using anthracene-based molecules as
precursor, the formation on Au(111) of polymers hosting sp carbon chains is
affected by the steric hindrance between aromatic groups. In particular, by
scanning tunneling microscopy and density functional theory calculations we
show that the de-metalation of organometallic structures induces a lateral
separation of adjacent polymers preventing the formation of ordered domains.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:12:55 GMT""}]","2022-06-14"
"2203.07471","Chrysostomos Karakasis","Chrysostomos Karakasis, Ioannis Poulakakis, and Panagiotis Artemiadis","Robust Dynamic Walking for a 3D Dual-SLIP Model under One-Step
  Unilateral Stiffness Perturbations: Towards Bipedal Locomotion over Compliant
  Terrain","This work was published in the 30th Mediterranean Conference on
  Control and Automation, MED'22",,,,"cs.RO cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Bipedal walking is one of the most important hallmarks of human that robots
have been trying to mimic for many decades. Although previous control
methodologies have achieved robot walking on some terrains, there is a need for
a framework allowing stable and robust locomotion over a wide range of
compliant surfaces. This work proposes a novel biomechanics-inspired controller
that adjusts the stiffness of the legs in support for robust and dynamic
bipedal locomotion over compliant terrains. First, the 3D Dual-SLIP model is
extended to support for the first time locomotion over compliant surfaces with
variable stiffness and damping parameters. Then, the proposed controller is
compared to a Linear-Quadratic Regulator (LQR) controller, in terms of
robustness on stepping on soft terrain. The LQR controller is shown to be
robust only up to a moderate ground stiffness level of 174 kN/m, while it fails
in lower stiffness levels. On the contrary, the proposed controller can produce
stable gait in stiffness levels as low as 30 kN/m, which results in a vertical
ground penetration of the leg that is deeper than 10% of its rest length. The
proposed framework could advance the field of bipedal walking, by generating
stable walking trajectories for a wide range of compliant terrains useful for
the control of bipeds and humanoids, as well as by improving controllers for
prosthetic devices with tunable stiffness.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:13:02 GMT""},{""version"":""v2"",""created"":""Sat, 9 Jul 2022 11:08:46 GMT""}]","2022-07-12"
"2203.07472","Adam Gleave","Adam Gleave and Geoffrey Irving","Uncertainty Estimation for Language Reward Models","8 pages main paper, 17 pages total",,,,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Language models can learn a range of capabilities from unsupervised training
on text corpora. However, to solve a particular problem (such as text
summarization) it is typically necessary to fine-tune them on a task-specific
dataset. It is often easier for humans to choose between options than to
provide labeled data, and prior work has achieved state-of-the-art performance
by training a reward model from such preference comparisons. However,
collecting a large preference comparison dataset is still expensive -- and the
learned reward models are unreliable out-of-distribution. We seek to address
these problems via uncertainty estimation, which can improve sample efficiency
and robustness using active learning and risk-averse reinforcement learning
(RL). Specifically, we use bootstrap aggregating (bagging) to train an ensemble
of reward models differing in the initialization of their final layer.
Ensembles have proved successful in prior applications of active learning, but
we find that in our setting ensemble active learning does not outperform random
sampling. Further experiments show that while the aggregate predictions are
well-calibrated, the ensemble's estimated epistemic uncertainty is only weakly
correlated with model error. We suspect this is because the ensemble members
are fine-tuned from a single model and so are similar to one another. This
suggests current pre-training methods will need to be modified to support
uncertainty estimation, e.g. by training multiple language models.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:13:21 GMT""}]","2022-03-16"
"2203.07473","Gunnar Kudrjavets","Gunnar Kudrjavets (University of Groningen), Nachiappan Nagappan
  (Microsoft Research), Ayushi Rastogi (University of Groningen)","The Unexplored Treasure Trove of Phabricator Code Review","5 pages. To be published in Proceedings of MSR '22: Proceedings of
  the 19th International Conference on Mining Software Repositories (MSR 2022).
  ACM, New York, NY, USA",,"10.1145/3524842.3528005",,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Phabricator is a modern code collaboration tool used by popular projects like
FreeBSD and Mozilla. However, unlike the other well-known code review
environments, such as Gerrit or GitHub, there is no readily accessible public
code review dataset for Phabricator. This paper describes our experience mining
code reviews from five different projects that use Phabricator (Blender,
FreeBSD, KDE, LLVM, and Mozilla). We discuss the challenges associated with the
data retrieval process and our solutions, resulting in a dataset with details
regarding 317,476 Phabricator code reviews. Our dataset is available in both
JSON and MySQL database dump formats. The dataset enables analyses of the
history of code reviews at a more granular level than other platforms. In
addition, given that the projects we mined are publicly accessible via the
Conduit API, our dataset can be used as a foundation to fetch additional
details and insights.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:14:49 GMT""}]","2022-12-01"
"2203.07474","Saavan Patel","Jorge Gomez, Saavan Patel, Syed Shakib Sarwar, Ziyun Li, Raffaele
  Capoccia, Zhao Wang, Reid Pinkham, Andrew Berkovich, Tsung-Hsun Tsai, Barbara
  De Salvo and Chiao Liu","Distributed On-Sensor Compute System for AR/VR Devices: A
  Semi-Analytical Simulation Framework for Power Estimation","6 pages, 5 figures, TinyML Research Symposium",,,,"cs.AR cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  Augmented Reality/Virtual Reality (AR/VR) glasses are widely foreseen as the
next generation computing platform. AR/VR glasses are a complex ""system of
systems"" which must satisfy stringent form factor, computing-, power- and
thermal- requirements. In this paper, we will show that a novel distributed
on-sensor compute architecture, coupled with new semiconductor technologies
(such as dense 3D-IC interconnects and Spin-Transfer Torque Magneto Random
Access Memory, STT-MRAM) and, most importantly, a full hardware-software
co-optimization are the solutions to achieve attractive and socially acceptable
AR/VR glasses. To this end, we developed a semi-analytical simulation framework
to estimate the power consumption of novel AR/VR distributed on-sensor
computing architectures. The model allows the optimization of the main
technological features of the system modules, as well as the computer-vision
algorithm partition strategy across the distributed compute architecture. We
show that, in the case of the compute-intensive machine learning based Hand
Tracking algorithm, the distributed on-sensor compute architecture can reduce
the system power consumption compared to a centralized system, with the
additional benefits in terms of latency and privacy.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:18:24 GMT""}]","2022-03-16"
"2203.07475","Adam Gleave","Joar Skalse, Matthew Farrugia-Roberts, Stuart Russell, Alessandro
  Abate, Adam Gleave","Invariance in Policy Optimisation and Partial Identifiability in Reward
  Learning","ICML 2023. 9 pages main paper, 26 pages total, 3 figures",,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is often very challenging to manually design reward functions for complex,
real-world tasks. To solve this, one can instead use reward learning to infer a
reward function from data. However, there are often multiple reward functions
that fit the data equally well, even in the infinite-data limit. This means
that the reward function is only partially identifiable. In this work, we
formally characterise the partial identifiability of the reward function given
several popular reward learning data sources, including expert demonstrations
and trajectory comparisons. We also analyse the impact of this partial
identifiability for several downstream tasks, such as policy optimisation. We
unify our results in a framework for comparing data sources and downstream
tasks by their invariances, with implications for the design and selection of
data sources for reward learning.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:19:15 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jun 2023 04:37:57 GMT""}]","2023-06-08"
"2203.07476","Keith Holsapple","Keith A. Holsapple","IMPACTS -- A program to calculate the effects of a hypervelocity impact
  into a Solar System body","12 pages, 1 figure",,,,"astro-ph.EP astro-ph.IM physics.geo-ph","http://creativecommons.org/licenses/by/4.0/","  IMPACTS! is a free web based Javascript application that can be opened and
executed in any standard browser. It can be downloaded from
https://www.dropbox.com/sh/2oanw5vxf09qpl1/AAD8uD-CsWir6slPlWndyUQAa?dl=0. This
program calculates the many characteristics of the craters, ejecta and
disruptions that are created from hypervelocity impacts into the objects of the
Solar System. The code cam also be obtained from the author.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:21:33 GMT""},{""version"":""v2"",""created"":""Wed, 16 Mar 2022 18:33:02 GMT""},{""version"":""v3"",""created"":""Mon, 21 Mar 2022 21:02:08 GMT""}]","2022-03-23"
"2203.07477","Victor Rueskov Christiansen","Victor Rueskov Christiansen, Alexander Holm Kiilerich and Klaus
  M{\o}lmer","Interaction of quantum systems with single pulses of quantized radiation","9 pages, 8 figures",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  The interaction of a propagating pulse of quantum radiation with a localized
quantum system can be described by a cascaded master equation with a distinct
initially populated input and a finally populated output field mode [Phys. Rev.
Lett. 123, 123604 (2019), arXiv:1902.09833v3]. By transformation to an
appropriate interaction picture, we identify the usual Jaynes-Cummings
Hamiltonian between the scatterer and a superposition of the initial and final
mode, with a strength given by the travelling pulse mode amplitude. The
transformation also identifies a coupling of the scatterer with an orthogonal
combination of the two modes. The transformed master equation offers important
insights into the system dynamics and it permits numerically efficient
solutions.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:23:23 GMT""}]","2022-03-16"
"2203.07478","Shivam Vats","Shivam Vats, Oliver Kroemer, Maxim Likhachev","Synergistic Scheduling of Learning and Allocation of Tasks in
  Human-Robot Teams","Camera ready version for ICRA, 2022",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of completing a set of $n$ tasks with a human-robot
team using minimum effort. In many domains, teaching a robot to be fully
autonomous can be counterproductive if there are finitely many tasks to be
done. Rather, the optimal strategy is to weigh the cost of teaching a robot and
its benefit -- how many new tasks it allows the robot to solve autonomously. We
formulate this as a planning problem where the goal is to decide what tasks the
robot should do autonomously (act), what tasks should be delegated to a human
(delegate) and what tasks the robot should be taught (learn) so as to complete
all the given tasks with minimum effort. This planning problem results in a
search tree that grows exponentially with $n$ -- making standard graph search
algorithms intractable. We address this by converting the problem into a mixed
integer program that can be solved efficiently using off-the-shelf solvers with
bounds on solution quality. To predict the benefit of learning, we propose a
precondition prediction classifier. Given two tasks, this classifier predicts
whether a skill trained on one will transfer to the other. Finally, we evaluate
our approach on peg insertion and Lego stacking tasks, both in simulation and
real-world, showing substantial savings in human effort.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:23:28 GMT""},{""version"":""v2"",""created"":""Thu, 7 Jul 2022 00:39:40 GMT""}]","2022-07-08"
"2203.07479","Joshua R. Klein","Joshua R. Klein, Tomi Akindele, Adam Bernstein, Steven Biller,
  Nathaniel Bowden, Jason Brodsky, D.F. Cowen, Michael Ford, Julieta Gruszko,
  Logan Lebenowski, Aobo Li, Viacheslav A. Li, Wei Mu, J. Pedro Ochoa-Ricoux,
  Gabriel D. Orebi Gann, Mayly Sanchez, Robert Svoboda, Matthew Wetstein,
  Michael Wurm, Minfang Yeh","Future Advances in Photon-Based Neutrino Detectors: A SNOWMASS White
  Paper",,,,,"physics.ins-det hep-ex nucl-ex","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We discuss here new, enabling technologies for future photon-based neutrino
detectors. These technologies touch nearly every aspect of such detectors: new
scintillating materials, new methods of loading isotopes, new photon sensors
and collectors, new approaches to simulation and analysis, and new front-end
electronics and DAQ ideas. Of particular interest are technologies that enable
broad physics programs in hybrid Cherenkov/scintillation detectors, such as
slow fluors, water-based liquid scintillator, and spectral sorting of photons.
Several new large-scale detector ideas are also discussed, including hybrid
detectors like Theia, ArTEMIS, and generic slow-fluor detectors, as well as the
very different SLIPs and LiquidO approaches to instrumenting photon-based
detectors. A program of demonstrators for future detectors, including ANNIE,
Eos, and NuDOT are also discussed.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:32:09 GMT""}]","2022-03-16"
"2203.07480","John Arban Lewis","John Arban Lewis, Charles J. Lada, Thomas Dame","Systematic Investigation of Dust and Gaseous CO in 12 Nearby Molecular
  Clouds","27 pages, 19 figures, 5 tables. Accepted ApJL. v2 Corrected bad
  coordinates on Appendix C maps. Brought text into alignment with final ApJL
  version",,"10.3847/1538-4357/ac5d58",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We report the first uniform and systematic study of dust and molecular gas in
nearby molecular clouds. We use surveys of dust extinction and emission to
determine the opacity and map the distribution of the dust within a dozen local
clouds in order to derive a uniform set of basic cloud properties. We find: 1)
the average dust opacity $\langle\kappa_{d,353}\rangle = 0.8\ {\rm cm^{2}\,
g^{-1}}$ with variations of a factor of $\sim$ 2 between clouds, 2) cloud PDFs
are exquisitely described by steeply falling power-laws with a narrow range of
slope, and 3) a tight $M_{\rm GMC} \sim R_{\rm GMC}^2$ scaling relation for the
cloud sample, indicative of a cloud population with an exactingly constant
average surface density above a common fixed boundary. We compare these results
to uniformly analyzed CO surveys. We measure the CO mass conversion factors and
assess the efficacy of CO for tracing the physical properties of molecular
clouds. We find $\langle \alpha_{\rm CO}\rangle = 4.31 \pm 0.67$ M$_\odot$ (K
km s$^{-1}$ pc$^2$)$^{-1}$ (corresponding to $X_{\rm CO}$ = 1.97 $\times$
10$^{20}$ cm$^{-2}$(K km s$^{-1}$)$^{-1}$). We demonstrate that CO observations
are a poor tracer of column density and structure on sub-cloud spatial scales.
On cloud scales, CO observations can provide measurements consistent with those
of the dust, provided data are analyzed in a similar, self-consistent fashion.
Measurements of average GMC surface density are sensitive to choice of cloud
boundary. Care must be exercised to adopt common fixed boundaries when
comparing surface densities for cloud populations within and between galaxies.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:32:10 GMT""},{""version"":""v2"",""created"":""Wed, 30 Mar 2022 19:26:17 GMT""}]","2022-05-25"
"2203.07481","Ruskin Patel","Ruskin Patel and Kaloyan Penev","Constraining Tidal Quality Factor using Spin Period in Eclipsing
  Binaries","This article has been accepted for publication in MNRAS Published by
  Oxford University Press on behalf of the Royal Astronomical Society.
  https://academic.oup.com/mnras/advance-article-abstract/doi/10.1093/mnras/stac203/6517458",,"10.1093/mnras/stac203",,"astro-ph.SR astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  Evolution of binary objects under the influence of tides drastically affects
the expected observational properties of the system. With the discovery of a
large number of close-in hot Jupiter systems and eclipsing binaries from
missions such as Kepler and TESS, it has become imperative to understand the
extent of tidal influence on their formation and observed properties. In the
case of binary systems, an efficient tidal dissipation can lead to either spin
up or spin down of the stars and/or spin-orbit synchronization, depending upon
the exchange of angular momentum between the star and the orbit. We combine the
eclipsing binary systems from the Kepler mission with stellar and orbital
parameters available in the literature to create a catalog of 41 eclipsing
binaries suitable for analysis of tidal dissipation. Empirically, the
efficiency of tidal dissipation is parameterized using a modified Tidal Quality
Factor($Q_{\star}^{'}$). We find constraints on $Q_{\star}^{'}$ using the
observed rotation period of the primary star in the eclipsing binary systems.
We calculate detailed evolutions of binary systems under the combined influence
of tides, stellar evolution, and loss of stellar angular momentum to magnetic
winds, and perform Markov Chain Monte Carlo simulations to account for the
uncertainties in the observed data. Our analysis shows that
$\log_{10}{Q^{'}_{\star}}=7.818\pm0.035$ can reproduce the observed primary
star spin in almost all systems in our sample.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:36:03 GMT""}]","2022-03-16"
"2203.07482","Bj\""orn Schuller","Bj\""orn W. Schuller and Dagmar M. Schuller","Audiovisual Affect Assessment and Autonomous Automobiles: Applications","Originally peer-reviewed and accepted for Machines with Emotion,
  Workshop in conjunction with IROS, MwE 2019 - no proceedings were, however,
  published",,,,"cs.HC cs.AI cs.CY cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Emotion and a broader range of affective driver states can be a life decisive
factor on the road. While this aspect has been investigated repeatedly, the
advent of autonomous automobiles puts a new perspective on the role of
computer-based emotion recognition in the car -- the passenger's one. This
includes amongst others the monitoring of wellbeing during the commute such as
to adjust the driving style or to adapt the info- and entertainment. This
contribution aims to foresee according challenges and provide potential avenues
towards affect modelling in a multimodal ""audiovisual plus x"" on the road
context. From the technical end, this concerns holistic passenger modelling and
reliable diarisation of the individuals in a vehicle. In conclusion, automated
affect analysis has just matured to the point of applicability in autonomous
vehicles in first selected use-cases, which will be discussed towards the end.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:39:02 GMT""}]","2022-03-16"
"2203.07483","Gong Cheng","Gong Cheng and Wei Zhang and Jr-Shin Li","Bilinear Systems Induced by Proper Lie Group Actions",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  In the study of induced bilinear systems, the classical Lie algebra rank
condition (LARC) is known to be impractical since it requires computing the
rank everywhere. On the other hand, the transitive Lie algebra condition, while
more commonly used, relies on the classification of transitive Lie algebras,
which is elusive except for few simple geometric objects such as spheres. We
prove in this note that for bilinear systems induced by proper Lie group
actions, the underlying Lie algebra is closely related to the orbits of the
group action. Knowing the pattern of the Lie algebra rank over the manifold, we
show that the LARC can be relaxed so that it suffices to check the rank at an
arbitrary single point. Moreover, it removes the necessity for classifying
transitive Lie algebras. Finally, this relaxed rank condition also leads to a
characterization of controllable submanifolds by orbits.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:42:11 GMT""}]","2022-03-16"
"2203.07484","Rogerio Riffel","Rog\'erio Riffel, Luis G. Dahmer-Hahn, Rogemar A. Riffel, Thaisa
  Storchi-Bergmann, Natacha Z. Dametto, Richard Davies, Leonard Burtscher,
  Marina Bianchin, Daniel Ruschel-Dutra, Claudio Ricci and David J. Rosario","Gemini NIFS survey of feeding and feedback processes in nearby Active
  Galaxies: VI -- Stellar Populations","Accepted for publication in MNRAS",,"10.1093/mnras/stac740",,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We use Gemini Near-Infrared Integral Field Spectrograph (NIFS) adaptive
optics assisted data-cubes to map the stellar population of the inner few
hundred parsecs of a sample of 18 nearby Seyfert galaxies. The near-infrared
light is dominated by the contribution of young to intermediate old stellar
populations, with light-weighted mean ages $<t>_L\ \lesssim $ 1.5\,Gyr. Hot
dust ($HD$) emission is centrally peaked (in the unresolved nucleus), but it is
also needed to reproduce the continuum beyond the nucleus in nearly half of the
sample. We have analysed the stellar population properties of the nuclear
region and their relation with more global properties of the galaxies. We find
a correlation between the X-ray luminosity and the contributions from the $HD$,
featureless continuum $FC$ and reddening $A_V$. We attribute these correlations
to the fact that all these properties are linked to the mass accretion rate to
the active galactic nuclei (AGN). We also find a correlation of the bolometric
luminosity $log(LBol_{obs})$ with the mass-weighted mean age of the stellar
population, interpreted as due a delay between the formation of new stars and
the triggering/feeding of the AGN. The gas reaching the supermassive black hole
is probably originated from mass loss from the already somewhat evolved
intermediate-age stellar population ($<t>_L \lesssim $ 1.5\,Gyr). In summary,
our results show that there is a significant fraction of young to intermediate
age stellar populations in the inner few 100\,pc of active galaxies, suggesting
that this region is facing a rejuvenation process in which the AGN, once
triggered, precludes further star formation, in the sense that it can be
associated with the lack of new star formation in the nuclear region.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:44:11 GMT""},{""version"":""v2"",""created"":""Fri, 18 Mar 2022 12:50:12 GMT""}]","2022-03-21"
"2203.07485","Claudio Battiloro Mr","L. Giusti, C. Battiloro, P. Di Lorenzo, S. Sardellitti, S. Barbarossa","Simplicial Attention Neural Networks","In V2, we change the title in Simplicial Attention Neural Networks,
  since we discovered the paper 1 that shares the same title of V1 and was
  available on OpenReview a few days before our first submission. In V2, we
  cite 1, clarifying the several differences with our method and adding
  extensive numerical comparisons. 1 Christopher W. et al., Simplicial
  attention networks. Avbl on OpenReview",,,,"cs.LG cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim of this work is to introduce simplicial attention networks (SANs),
i.e., novel neural architectures that operate on data defined on simplicial
complexes leveraging masked self-attentional layers. Hinging on formal
arguments from topological signal processing, we introduce a proper
self-attention mechanism able to process data components at different layers
(e.g., nodes, edges, triangles, and so on), while learning how to weight both
upper and lower neighborhoods of the given topological domain in a totally
task-oriented fashion. The proposed SANs generalize most of the current
architectures available for processing data defined on simplicial complexes.
The proposed approach compares favorably with other methods when applied to
different (inductive and transductive) tasks such as trajectory prediction and
missing data imputations in citation complexes.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:47:31 GMT""},{""version"":""v2"",""created"":""Sat, 26 Mar 2022 11:41:22 GMT""}]","2022-03-29"
"2203.07486","Dorra Ben Khalifa","Dorra Ben Khalifa and Matthieu Martel","Constrained Precision Tuning","8 pages, 3 figures",,,,"cs.SE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Precision tuning or customized precision number representations is emerging,
in these recent years, as one of the most promising techniques that has a
positive impact on the footprint of programs concerning energy consumption,
bandwidth usage and computation time of numerical programs. In contrast to the
uniform precision, mixed precision tuning assigns different finite-precision
types to each variable and arithmetic operation of a program and offers many
additional optimization opportunities. However, this technique introduces new
challenge related to the cost of operations or type conversions which can
overload the program execution after tuning. In this article, we extend our
tool POP (Precision OPtimizer), with efficient ways to limit the number of
drawbacks of mixed precision and to achieve best compromise between performance
and memory consumption. On a popular set of tests from the FPBench suite, we
discuss the results obtained by POP.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:47:33 GMT""}]","2022-03-16"
"2203.07487","Tristan Bereau","Kiran H. Kanekal and Joseph F. Rudzinski and Tristan Bereau","Broad chemical transferability in structure-based coarse-graining","15 pages, 7 figures",,"10.1063/5.0104914",,"physics.chem-ph physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Compared to top-down coarse-grained (CG) models, bottom-up approaches are
capable of offering higher structural fidelity. This fidelity results from the
tight link to a higher-resolution reference, making the CG model chemically
specific. Unfortunately, chemical specificity can be at odds with
compound-screening strategies, which call for transferable parametrizations.
Here we present an approach to reconcile bottom-up, structure-preserving CG
models with chemical transferability. We consider the bottom-up CG
parametrization of 3,441 C$_7$O$_2$ small-molecule isomers. Our approach
combines atomic representations, unsupervised learning, and a large-scale
extended-ensemble force-matching parametrization. We first identify a subset of
19 representative molecules, which maximally encode the local environment of
all gas-phase conformers. Reference interactions between the 19 representative
molecules were obtained from both homogeneous bulk liquids and various binary
mixtures. An extended-ensemble parametrization over all 703 state points leads
to a CG model that is both structure-based and chemically transferable.
Remarkably, the resulting force field is on average more structurally accurate
than single-state-point equivalents. Averaging over the extended ensemble acts
as a mean-force regularizer, smoothing out both force and structural
correlations that are overly specific to a single state point. Our approach
aims at transferability through a set of CG bead types that can be used to
easily construct new molecules, while retaining the benefits of a
structure-based parametrization.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:49:31 GMT""}]","2022-09-21"
"2203.07488","Emilio Ferrara","Emily Chen, Emilio Ferrara","Tweets in Time of Conflict: A Public Dataset Tracking the Twitter
  Discourse on the War Between Ukraine and Russia","Dataset at https://github.com/echen102/ukraine-russia",,,,"cs.SI cs.CY cs.DL","http://creativecommons.org/licenses/by/4.0/","  On February 24, 2022, Russia invaded Ukraine. In the days that followed,
reports kept flooding in from layman to news anchors of a conflict quickly
escalating into war. Russia faced immediate backlash and condemnation from the
world at large. While the war continues to contribute to an ongoing
humanitarian and refugee crisis in Ukraine, a second battlefield has emerged in
the online space, both in the use of social media to garner support for both
sides of the conflict and also in the context of information warfare. In this
paper, we present a collection of over 63 million tweets, from February 22,
2022 through March 8, 2022 that we are publishing for the wider research
community to use. This dataset can be found at
https://github.com/echen102/ukraine-russia and will be maintained and regularly
updated as the war continues to unfold. Our preliminary analysis already shows
evidence of public engagement with Russian state sponsored media and other
domains that are known to push unreliable information; the former saw a spike
in activity on the day of the Russian invasion. Our hope is that this public
dataset can help the research community to further understand the ever evolving
role that social media plays in information dissemination, influence campaigns,
grassroots mobilization, and much more, during a time of conflict.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:52:02 GMT""},{""version"":""v2"",""created"":""Mon, 10 Apr 2023 19:11:55 GMT""}]","2023-04-12"
"2203.07489","Sibasish Laha","Sibasish Laha (NASA-GSFC), Zorawar Wadiasingh, Tyler Parsotan, Amy
  Lien, George Younes, Bing Zhang, S. Bradley Cenko, Eleonora Troja, Samantha
  Oates, Matt Nicholl, Eileen Meyer, Josefa Becerra Gonz\'alez, Ritesh Ghosh,
  Noel Klingler","Limits on the hard X-ray emission from the periodic fast radio burst FRB
  180916.J0158+65","Accepted for publication in ApJ",,"10.3847/1538-4357/ac5f3c",,"astro-ph.HE astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  FRB 180916.J0158+65 is one of the nearest, periodically repeating, and
actively bursting fast radio burst (FRB) which has been localized to the
outskirts of a spiral galaxy. In this work we study the FRB with the hard X-ray
$14-195$ keV data from the Burst Alert Telescope (BAT) on board The Neil
Gehrels Swift Observatory. BAT uses coded mask technology giving a localization
of $\lesssim 3$ arc-minute in the hard X-ray band, along with an accurate
background estimation. BAT has been observing the source location in survey
mode since February 2020. The survey mode observations involves background
subtracted spectra, integrated over a time span ranging $300-2000$ seconds, at
the source location (from Feb 2020-Jan 2022). We analyzed all the $\sim 230$
survey mode observations from BAT and checked for any signal in any of the
observations. We did not detect any signal at $>5\sigma$ confidence level in
any of the observations. We could estimate a $5\sigma$ upper limit on the
$14-195$ keV flux, which ranged between $4.5\times 10^{-10} - 7.6\times
10^{-9}\, \rm erg\, cm^{-2}\, s^{-1}$. At the source distance this relates to a
$5\sigma$ upper limit on luminosity of $5.08\times 10^{44}- 8.5\times 10^{45}
\rm erg\, s^{-1}$. With this estimate, we could rule out any persistent X-ray
emission, at the source location for these snapshots of BAT observations.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:53:02 GMT""}]","2022-05-11"
"2203.07490","Kweku Kwegyir-Aggrey","Kweku Kwegyir-Aggrey, Jessica Dai, A. Feder Cooper, John Dickerson,
  Keegan Hines","Geometric Repair for Fair Classification at Any Decision Threshold",,,,,"cs.LG cs.CY","http://creativecommons.org/licenses/by/4.0/","  We study the problem of post-processing a supervised machine-learned
regressor to maximize fair binary classification at all decision thresholds.
Specifically, we show that by decreasing the statistical distance between each
group's score distributions, we can increase fair performance across all
thresholds at once, and that we can do so without a significant decrease in
accuracy. To this end, we introduce a formal measure of distributional parity,
which captures the degree of similarity in the distributions of classifications
for different protected groups. In contrast to prior work, which has been
limited to studies of demographic parity across all thresholds, our measure
applies to a large class of fairness metrics. Our main result is to put forward
a novel post-processing algorithm based on optimal transport, which provably
maximizes distributional parity. We support this result with experiments on
several fairness benchmarks.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:53:35 GMT""},{""version"":""v2"",""created"":""Tue, 14 Jun 2022 18:41:58 GMT""},{""version"":""v3"",""created"":""Wed, 29 Mar 2023 20:35:22 GMT""}]","2023-03-31"
"2203.07491","Monica Valluri","Monica Valluri, Solene Chabanier, Vid Irsic, Eric Armengaud, Michael
  Walther, Connie Rockosi, Miguel A. Sanchez-Conde, Leandro Beraldo e Silva,
  Andrew P. Cooper, Elise Darragh-Ford, Kyle Dawson, Alis J. Deason, Simone
  Ferraro, Jaime E. Forero-Romero, Antonella Garzilli, Ting Li, Zarija Lukic,
  Christopher J. Manser, Nathalie Palanque-Delabrouille, Corentin Ravoux, Ting
  Tan, Wenting Wang, Risa Wechsler, Andreia Carrillo, Arjun Dey, Sergey E.
  Koposov, Yao-Yuan Mao, Paulo Montero-Camacho, Ekta Patel, Graziano Rossi, L.
  Arturo Urena-Lopez, and Octavio Valenzuela","Snowmass2021 Cosmic Frontier White Paper: Prospects for obtaining Dark
  Matter Constraints with DESI","Contributed white paper to Snowmass 2021, CF03; minor revisions",,,,"astro-ph.CO astro-ph.GA hep-ph","http://creativecommons.org/licenses/by/4.0/","  Despite efforts over several decades, direct-detection experiments have not
yet led to the discovery of the dark matter (DM) particle. This has led to
increasing interest in alternatives to the Lambda CDM (LCDM) paradigm and
alternative DM scenarios (including fuzzy DM, warm DM, self-interacting DM,
etc.). In many of these scenarios, DM particles cannot be detected directly and
constraints on their properties can ONLY be arrived at using astrophysical
observations. The Dark Energy Spectroscopic Instrument (DESI) is currently one
of the most powerful instruments for wide-field surveys. The synergy of DESI
with ESA's Gaia satellite and future observing facilities will yield datasets
of unprecedented size and coverage that will enable constraints on DM over a
wide range of physical and mass scales and across redshifts. DESI will obtain
spectra of the Lyman-alpha forest out to z~5 by detecting about 1 million QSO
spectra that will put constraints on clustering of the low-density
intergalactic gas and DM halos at high redshift. DESI will obtain radial
velocities of 10 million stars in the Milky Way (MW) and Local Group satellites
enabling us to constrain their global DM distributions, as well as the DM
distribution on smaller scales. The paradigm of cosmological structure
formation has been extensively tested with simulations. However, the majority
of simulations to date have focused on collisionless CDM. Simulations with
alternatives to CDM have recently been gaining ground but are still in their
infancy. While there are numerous publicly available large-box and zoom-in
simulations in the LCDM framework, there are no comparable publicly available
WDM, SIDM, FDM simulations. DOE support for a public simulation suite will
enable a more cohesive community effort to compare observations from DESI (and
other surveys) with numerical predictions and will greatly impact DM science.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:58:32 GMT""},{""version"":""v2"",""created"":""Fri, 1 Jul 2022 13:20:40 GMT""}]","2022-07-04"
"2203.07492","Zhengkang Zhang","Andrea Mitridate, Tanner Trickle, Zhengkang Zhang, Kathryn M. Zurek","Snowmass White Paper: Light Dark Matter Direct Detection at the
  Interface With Condensed Matter Physics","contribution to Snowmass 2021; 11 pages, 3 figures",,,,"hep-ph astro-ph.CO cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Direct detection experiments for light (sub-GeV) dark matter are making
enormous leaps in reaching previously unexplored theory space. The need for
accurate characterizations of target responses has led to a growing interplay
between particle and condensed matter physics. This white paper summarizes
recent progress on direct detection calculations that utilize state-of-the-art
numerical tools in condensed matter physics and effective field theory
techniques. These new results provide the theoretical framework for
interpreting ongoing and planned experiments using electronic and collective
excitations, and for optimizing future searches.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:58:53 GMT""}]","2022-03-16"
"2203.07493","Stefano Buzzi","Stefano Buzzi, Carmen D'Andrea, Giovanni Interdonato","Approaching Massive MIMO Performance with Reconfigurable Intelligent
  Surfaces: We Do Not Need Many Antennas","Paper submitted to IEEE for possible publication",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers an antenna structure where a (non-large) array of
radiating elements is placed at short distance in front of a reconfigurable
intelligent surface (RIS). This structure is analyzed as a possible emulator of
a traditional MIMO antenna with a large number of active antenna elements and
RF chains. Focusing on both the cases of active and passive RIS, we tackle the
issues of channel estimation, downlink signal processing, power control, and
RIS configuration optimization. With regard to the last point, an optimization
problem is formulated and solved, both for the cases of active and passive RIS,
aimed at minimizing the channel signatures cross-correlations and thereby
reducing the interference. Downlink spectral efficiency (SE) formulas are also
derived by using the popular hardening lower-bound. Numerical results,
represented with reference to max-fairness power control, show that the
proposed structure is capable of outperforming conventional non-RIS aided MIMO
systems even when the MIMO system has a considerably larger number of antennas
and RF chains. The proposed antenna structure is thus shown to be able to
approach massive MIMO performance levels in a cost-effective way with reduced
hardware resources.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 21:00:55 GMT""}]","2022-03-16"
"2203.07494","Valentina Shumovskaia","Valentina Shumovskaia, Konstantinos Ntemos, Stefan Vlaski, Ali H.
  Sayed","Explainability and Graph Learning from Social Interactions","arXiv admin note: substantial text overlap with arXiv:2203.06007","2022 IEEE Transactions on Signal and Information Processing over
  Networks 8, 946-959","10.1109/TSIPN.2022.3223805",,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Social learning algorithms provide models for the formation of opinions over
social networks resulting from local reasoning and peer-to-peer exchanges.
Interactions occur over an underlying graph topology, which describes the flow
of information among the agents. To account for drifting conditions in the
environment, this work adopts an adaptive social learning strategy, which is
able to track variations in the underlying signal statistics. Among other
results, we propose a technique that addresses questions of explainability and
interpretability of the results when the graph is hidden. Given observations of
the evolution of the beliefs over time, we aim to infer the underlying graph
topology, discover pairwise influences between the agents, and identify
significant trajectories in the network. The proposed framework is online in
nature and can adapt dynamically to changes in the graph topology or the true
hypothesis.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 21:02:58 GMT""},{""version"":""v2"",""created"":""Wed, 16 Nov 2022 12:00:33 GMT""}]","2023-03-15"
"2203.07495","Sri Aditya Gadam","Wolfgang Altmannshofer, Sri Aditya Gadam, Stefano Profumo","Snowmass White Paper: Probing New Physics with $\mu^+ \mu^- \to bs$ at a
  Muon Collider","Contribution to Snowmass 2021",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this white paper for the Snowmass process, we discuss the prospects of
probing new physics explanations of the persistent rare $B$ decay anomalies
with a muon collider. If the anomalies are indirect signs of heavy new physics,
non-standard rates for $\mu^+ \mu^- \to b s$ production should be observed with
high significance at a muon collider with center of mass energy of $\sqrt{s} =
10$ TeV. The forward-backward asymmetry of the $b$-jet provides diagnostics of
the chirality structure of the new physics couplings. In the absence of a
signal, $\mu^+ \mu^- \to b s$ can indirectly probe new physics scales as large
as $86$ TeV. Beam polarization would have an important impact on the new
physics sensitivity.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 21:04:15 GMT""}]","2022-03-16"
"2203.07496","Haim Grebel","H. Grebel, Shupei Yu and Yuanwei Zhang","Active-carbon based supercapacitors with Au colloids: the case for
  placing the colloids at the electrolyte/electrode interface","19 pages; 16 figures",,,,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Supercapacitors (S-C) are short-term energy storage elements that find many
applications, e.g., electronic charging devices and suppressors of power
fluctuations in grids that are interfaced with sustainable sources. The
capacitance of an ordinary capacitor increases when dispersing metallic
colloids in its dielectric. A similar strategy for S-C means a deployment of
nano-scale metal colloids (in our case, Au nano particles, or AuNPs) at the
very narrow interface between an electrolyte and the porous electrode (here,
active-carbon film on a grafoil current collector). This is achieved by making
the ligand that is coating the AuNPs negatively charged. We demonstrated a very
large specific capacitance increase with a minute addition of functionalized
AuNPs to the slurry. For example, C-V data at a scan rate of 20 mV/s indicated
a specific capacitance amplification by a factor of 10 when 30 micro-g of AuNPs
were incorporated with 200 mg of active carbon while using a 1 M Na2SO4
electrolyte and a 5% cellulose acetate butyrate as a binder. We make the case
that the adhesion of the AuNPs to the surface of the electrode was strong: upon
replacing the electrolyte, from 1 M Na2SO4 to 1 M KOH and retaining the same
set of electrodes, the enhancement capacitance factor decreased as compared to
1 M Na2SO4 electrolyte but remained large, ~3, as determined by C-V traces at
the same scan rate of 20 mV/s.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 21:07:12 GMT""},{""version"":""v2"",""created"":""Wed, 27 Apr 2022 19:28:34 GMT""},{""version"":""v3"",""created"":""Thu, 22 Sep 2022 17:49:17 GMT""}]","2022-09-23"
"2203.07499","Ali Devran Kara","Erhan Bayraktar, Ali Devran Kara","Approximate Q-Learning for Controlled Diffusion Processes and its Near
  Optimality","3 figures",,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  We study a Q learning algorithm for continuous time stochastic control
problems. The proposed algorithm uses the sampled state process by discretizing
the state and control action spaces under piece-wise constant control
processes. We show that the algorithm converges to the optimality equation of a
finite Markov decision process (MDP). Using this MDP model, we provide an upper
bound for the approximation error for the optimal value function of the
continuous time control problem. Furthermore, we present provable upper-bounds
for the performance loss of the learned control process compared to the optimal
admissible control process of the original problem. The provided error
upper-bounds are functions of the time and space discretization parameters, and
they reveal the effect of different levels of the approximation: (i)
approximation of the continuous time control problem by an MDP, (ii) use of
piece-wise constant control processes, (iii) space discretization. Finally, we
state a time complexity bound for the proposed algorithm as a function of the
time and space discretization parameters.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 21:10:45 GMT""},{""version"":""v2"",""created"":""Wed, 8 Mar 2023 22:37:33 GMT""}]","2023-03-10"
"2203.07500","Zhong Guo","Zhong Guo, Austin R. Coffman, and Prabir Barooah","Reinforcement Learning for Optimal Control of a District Cooling Energy
  Plant","10 pages, extended ACC2022 version",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  District cooling energy plants (DCEPs) consisting of chillers, cooling
towers, and thermal energy storage (TES) systems consume a considerable amount
of electricity. Optimizing the scheduling of the TES and chillers to take
advantage of time-varying electricity price is a challenging optimal control
problem. The classical method, model predictive control (MPC), requires solving
a high dimensional mixed-integer nonlinear program (MINLP) because of the
on/off actuation of the chillers and charging/discharging of TES, which are
computationally challenging. RL is an attractive alternative to MPC: the real
time control computation is a low-dimensional optimization problem that can be
easily solved. However, the performance of an RL controller depends on many
design choices. In this paper, we propose a Q-learning based reinforcement
learning (RL) controller for this problem. Numerical simulation results show
that the proposed RL controller is able to reduce energy cost over a rule-based
baseline controller by approximately 8%, comparable to savings reported in the
literature with MPC for similar DCEPs. We describe the design choices in the RL
controller, including basis functions, reward function shaping, and learning
algorithm parameters. Compared to existing work on RL for DCEPs, the proposed
controller is designed for continuous state and actions spaces.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 21:13:04 GMT""}]","2022-03-16"
"2203.07501","Stefan Soldner-Rembold","Saba Parsa, Michele Weber, Clara Cuesta, Ines Gil-Botella, Sergio
  Manthey, Andrzej M. Szelc, Shirley Weishi Li, Marco Pallavicini, Justin
  Evans, Roxanne Guenette, David Marsden, Nicola McConkey, Anyssa
  Navrer-Agasson, Guilherme Ruiz, Stefan Soldner-Rembold, Esteban Cristaldo,
  Andrea Falcone, Maritza Delgado Gonzales, Claudio Gotti, Daniele Guffanti,
  Gianluigi Pessina, Francesco Terranova, Marta Torti, Francesco Di Capua,
  Giuliana Fiorillo, John F. Beacom, Francesco Capozzi","SoLAr: Solar Neutrinos in Liquid Argon","Contribution to Snowmass 2022, author name corrected",,,,"hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  SoLAr is a new concept for a liquid-argon neutrino detector technology to
extend the sensitivities of these devices to the MeV energy range - expanding
the physics reach of these next-generation detectors to include solar
neutrinos.
  We propose this novel concept to significantly improve the precision on solar
neutrino mixing parameters and to observe the ""hep branch"" of the proton-proton
fusion chain. The SoLAr detector will achieve flavour-tagging of solar
neutrinos in liquid argon. The SoLAr technology will be based on the concept of
monolithic light-charge pixel-based readout which addresses the main
requirements for such a detector: a low energy threshold with excellent energy
resolution (approximately 7%) and background rejection through pulse-shape
discrimination.
  The SoLAr concept is also timely as a possible technology choice for the DUNE
""Module of Opportunity"", which could serve as a next-generation multi-purpose
observatory for neutrinos from the MeV to the GeV range. The goal of SoLAr is
to observe solar neutrinos in a 10 ton-scale detector and to demonstrate that
the required background suppression and energy resolution can be achieved.
SoLAr will pave the way for a precise measurement of the 8-B flux, an improved
precision on solar neutrino mixing parameters, and ultimately lead to the first
observation of hep neutrinos in the DUNE Module of Opportunity.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 21:17:54 GMT""},{""version"":""v2"",""created"":""Wed, 24 Aug 2022 10:06:16 GMT""}]","2022-08-25"
"2203.07502","Larisa Vodolazhskaya","Larisa N. Vodolazhskaya","Inverted analemmatic sundial of the Bronze Age","29 pages, 22 figures",,,,"physics.hist-ph","http://creativecommons.org/licenses/by/4.0/","  This article describes the study of a Bronze Age limestone slab with cup
marks, discovered during the archaeological excavations of kurgan 1 of the
kurgan grave field Prolom II, located in the Belogorsk region in Crimea.
According to the results of the study, it is concluded that the Belogorsk slab
is a sundial of about the XV - XII centuries BC and belongs to the Srubnaya
culture. By type of sundial, it is closest to the analemmatic sundial. However,
the principle of the hourly markings of the Belogorsk slab is so unique that it
is proposed to separate this type of sundial into a new type - inverted
analemmatic sundial. This type is characterized by the fact that, unlike
typical analemmatic sundials, the gnomon remains motionless throughout the
year, and in accordance with the analemma, the ""dial"" ""moves"" - an ellipse of
hour markers from cup marks, i.e. gnomon and hour markers (cup marks) change
places in terms of mobility. The movement of hour markers on the Belogorsk slab
is not literal, but is imitated by several rows of cup marks, which are
fragments of hour marker ellipses for different months of the year. The idea
behind this type of sundial is so revolutionary that we can talk about the
discovery of a completely new type of sundial, the analogue of which has not
yet been discovered. Keywords: cup marks, sundial, inverted, analemma, true
solar time, mean solar time, hour markers, Srubnaya culture, Bronze Age, kurgan
grave field, slab.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 21:24:57 GMT""}]","2022-03-16"
"2203.07503","Luca Verzeroli","Lorenzo Botti, Luca Verzeroli","BR2 discontinuous Galerkin methods for finite hyperelastic deformations",,,"10.1016/j.jcp.2022.111303",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we introduce a dG framework for nonlinear elasticity based on a
Bassi-Rebay (BR2) formulation. The framework encompasses compressible and
incompressible hyperelastic materials and is capable of dealing with large
deformations. In order to achieve stability, we combine higher-order lifting
operators for the BR2 stabilization term with an adaptive stabilization
strategy which relies on the BR2 Laplace operator stabilization and a penalty
parameter based on the spectrum of the fourth-order elasticity tensor.
Dirichlet boundary conditions for the displacement can be imposed by means of
Lagrange multipliers and Nitsche method. Efficiency of the solution strategy is
achieved by means of state-of-the-art agglomeration based $h$-multigrid
preconditioners and the code implementation supports distributed memory
execution on modern parallel architectures. Several benchmark test cases are
proposed in order to investigate some relevant computational aspects, namely
the performance of the $h$-multigrid iterative solver varying the stabilization
parameters and the influence of Dirichlet boundary conditions on Newton's
method globalisation strategy.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 21:25:07 GMT""}]","2022-06-01"
"2203.07504","Robert Wolfe","Robert Wolfe, Aylin Caliskan","VAST: The Valence-Assessing Semantics Test for Contextualizing Language
  Models","To be published in AAAI 2022",,,,"cs.CL cs.AI cs.CY cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  VAST, the Valence-Assessing Semantics Test, is a novel intrinsic evaluation
task for contextualized word embeddings (CWEs). VAST uses valence, the
association of a word with pleasantness, to measure the correspondence of
word-level LM semantics with widely used human judgments, and examines the
effects of contextualization, tokenization, and LM-specific geometry. Because
prior research has found that CWEs from GPT-2 perform poorly on other intrinsic
evaluations, we select GPT-2 as our primary subject, and include results
showing that VAST is useful for 7 other LMs, and can be used in 7 languages.
GPT-2 results show that the semantics of a word incorporate the semantics of
context in layers closer to model output, such that VAST scores diverge between
our contextual settings, ranging from Pearson's rho of .55 to .77 in layer 11.
We also show that multiply tokenized words are not semantically encoded until
layer 8, where they achieve Pearson's rho of .46, indicating the presence of an
encoding process for multiply tokenized words which differs from that of singly
tokenized words, for which rho is highest in layer 0. We find that a few
neurons with values having greater magnitude than the rest mask word-level
semantics in GPT-2's top layer, but that word-level semantics can be recovered
by nullifying non-semantic principal components: Pearson's rho in the top layer
improves from .32 to .76. After isolating semantics, we show the utility of
VAST for understanding LM semantics via improvements over related work on four
word similarity tasks, with a score of .50 on SimLex-999, better than the
previous best of .45 for GPT-2. Finally, we show that 8 of 10 WEAT bias tests,
which compare differences in word embedding associations between groups of
words, exhibit more stereotype-congruent biases after isolating semantics,
indicating that non-semantic structures in LMs also mask biases.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 21:29:38 GMT""}]","2022-03-16"
"2203.07505","Jochen Stiasny","Jochen Stiasny, Samuel Chevalier, Rahul Nellikkath, Brynjar
  S{\ae}varsson, Spyros Chatzivasileiadis","Closing the Loop: A Framework for Trustworthy Machine Learning in Power
  Systems","In proceedings of the 11th Bulk Power Systems Dynamics and Control
  Symposium (IREP 2022), July 25-30, 2022, Banff, Canada. 21 pages, 12 figures,
  5 tables",,,"IREP2022-57","eess.SY cs.LG cs.SY","http://creativecommons.org/licenses/by/4.0/","  Deep decarbonization of the energy sector will require massive penetration of
stochastic renewable energy resources and an enormous amount of grid asset
coordination; this represents a challenging paradigm for the power system
operators who are tasked with maintaining grid stability and security in the
face of such changes. With its ability to learn from complex datasets and
provide predictive solutions on fast timescales, machine learning (ML) is
well-posed to help overcome these challenges as power systems transform in the
coming decades. In this work, we outline five key challenges (dataset
generation, data pre-processing, model training, model assessment, and model
embedding) associated with building trustworthy ML models which learn from
physics-based simulation data. We then demonstrate how linking together
individual modules, each of which overcomes a respective challenge, at
sequential stages in the machine learning pipeline can help enhance the overall
performance of the training process. In particular, we implement methods that
connect different elements of the learning pipeline through feedback, thus
""closing the loop"" between model training, performance assessments, and
re-training. We demonstrate the effectiveness of this framework, its
constituent modules, and its feedback connections by learning the N-1
small-signal stability margin associated with a detailed model of a proposed
North Sea Wind Power Hub system.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 21:30:43 GMT""},{""version"":""v2"",""created"":""Thu, 14 Jul 2022 16:59:27 GMT""}]","2022-07-15"
"2203.07506","Simone Ferraro","Simone Ferraro, Noah Sailer, Anze Slosar, Martin White","Snowmass2021 Cosmic Frontier White Paper: Cosmology and Fundamental
  Physics from the three-dimensional Large Scale Structure","26 pages, 8 figures; Snowmass2021 Cosmic Frontier White Paper",,,,"astro-ph.CO hep-ex hep-ph","http://creativecommons.org/licenses/by/4.0/","  Advances in experimental techniques make it possible to map the high redshift
Universe in three dimensions at high fidelity in the near future. This will
increase the observed volume by many-fold, while providing unprecedented access
to very large scales, which hold key information about primordial physics.
Recently developed theoretical techniques, together with the smaller size of
non-linearities at high redshift, allow the reconstruction of an order of
magnitude more ""primordial modes"", and should improve our understanding of the
early Universe through measurements of primordial non-Gaussianity and features
in the primordial power spectrum. In addition to probing the first epoch of
accelerated expansion, such measurements can probe the Dark Energy density in
the dark matter domination era, tightly constraining broad classes of dynamical
Dark Energy models. The shape of the matter power spectrum itself has the
potential to detect sub-percent fractional amounts of Early Dark Energy to $z
\sim 10^5$, probing Dark Energy all the way to when the Universe was only a few
years old. The precision of these measurements, combined with CMB observations,
also has the promise of greatly improving our constraints on the effective
number of relativistic species, the masses of neutrinos, the amount of spatial
curvature and the gravitational slip. Studies of linear or quasi-linear
large-scale structure with redshift surveys and the CMB currently provide our
tightest constraints on cosmology and fundamental physics. Pushing the redshift
and volume frontier will provide guaranteed, significant improvements in the
state-of-the-art in a manner that is easy to forecast and optimize.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 21:32:37 GMT""},{""version"":""v2"",""created"":""Fri, 9 Sep 2022 23:10:11 GMT""}]","2022-09-13"
"2203.07507","Izack Cohen","Eli Bogdanov, Izack Cohen, Avigdor Gal","Conformance Checking Over Stochastically Known Logs",,,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the growing number of devices, sensors and digital systems, data logs
may become uncertain due to, e.g., sensor reading inaccuracies or incorrect
interpretation of readings by processing programs. At times, such uncertainties
can be captured stochastically, especially when using probabilistic data
classification models. In this work we focus on conformance checking, which
compares a process model with an event log, when event logs are stochastically
known. Building on existing alignment-based conformance checking fundamentals,
we mathematically define a stochastic trace model, a stochastic synchronous
product, and a cost function that reflects the uncertainty of events in a log.
Then, we search for an optimal alignment over the reachability graph of the
stochastic synchronous product for finding an optimal alignment between a model
and a stochastic process observation. Via structured experiments with two
well-known process mining benchmarks, we explore the behavior of the suggested
stochastic conformance checking approach and compare it to a standard
alignment-based approach as well as to an approach that creates a lower bound
on performance. We envision the proposed stochastic conformance checking
approach as a viable process mining component for future analysis of stochastic
event logs.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 21:33:06 GMT""}]","2022-03-16"
"2203.07508","Utku Kumbul","Utku Kumbul, Nikita Petrov, Cicero S. Vaucher, Alexander Yarovoy","Smoothed Phase-Coded FMCW: Waveform Properties and Transceiver
  Architecture","18 pages, 23 figures",,"10.1109/TAES.2022.3206173",,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Smoothed phase-coded frequency modulated continuous waveform (SPC-FMCW),
which is aimed to improve the coexistence of multiple radars operating within
the same frequency bandwidth, is studied, and the receiving strategy with a low
ADC sampling requirement is investigated. The Gaussian filter is applied to
obtain smooth waveform phase transitions, and then quadratic phase lag
compensation is performed before waveform transmission to enhance decoding. The
proposed waveform is examined in different domains, and its waveform properties
are analysed theoretically and demonstrated experimentally. Both simulation and
experimental results show that the introduced waveform with the investigated
processing steps helps combine all advantages of the FMCW waveform, including
hardware simplicity and small operational bandwidth of the receiver, with the
advantages of phase coding.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 21:33:46 GMT""},{""version"":""v2"",""created"":""Wed, 25 Jan 2023 13:44:47 GMT""}]","2023-01-26"
"2203.07509","David Katz","David Warren Katz","Rank Two Approximations of $2 \times 2 \times 2$ Tensors over
  $\mathbb{R}$",,,,,"math.AG","http://creativecommons.org/licenses/by/4.0/","  We provide a coordinate-free proof that real $2 \times 2 \times 2$ rank three
tensors do not have optimal rank two approximations with respect to the
Frobenius norm. This result was first proved in by considering the
${\text{GL}(V^1) \times \text{GL}(V^2) \times \text{GL}(V^3)}$ orbit classes of
${V^1 \otimes V^2 \otimes V^3}$ and the $2 \times 2 \times 2$ hyperdeterminant.
Our coordinate-free proof expands on this known result by developing a proof
method that can be generalized more readily to higher dimensional $n_1 \times
n_2 \times n_3$ tensor spaces.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 21:41:18 GMT""}]","2022-03-16"
"2203.07510","Hanchen Liu","Hanchen Liu, Tianci Zhou, Xiao Chen","Measurement induced entanglement transition in two dimensional shallow
  circuit",,"Physical Review B 106.14 (2022): 144311","10.1103/PhysRevB.106.144311",,"quant-ph cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prepare two dimensional states generated by shallow circuits composed of
(1) one layer of two-qubit CZ gate or (2) a few layers of two-qubit random
Clifford gate. After measuring all of the bulk qubits, we study the
entanglement structure of the remaining qubits on the one dimensional boundary.
In the first model, we observe that the competition between the bulk X and Z
measurements can lead to an entanglement phase transition between an entangled
volume law phase and a disentangled area law phase. We numerically evaluate the
critical exponents and generalize this idea to other qudit systems with local
Hilbert space dimension larger than 2. In the second model, we observe the
entanglement transition by varying the density of the two-qubit gate in each
layer. We give an interpretation of this transition in terms of random bond
Ising model in a similar shallow circuit composed of random Haar gates.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 21:41:28 GMT""}]","2022-11-08"
"2203.07511","Robert Wolfe","Robert Wolfe, Aylin Caliskan","Contrastive Visual Semantic Pretraining Magnifies the Semantics of
  Natural Language Representations","To be published in ACL 2022",,,,"cs.CL cs.AI cs.CY cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We examine the effects of contrastive visual semantic pretraining by
comparing the geometry and semantic properties of contextualized English
language representations formed by GPT-2 and CLIP, a zero-shot multimodal image
classifier which adapts the GPT-2 architecture to encode image captions. We
find that contrastive visual semantic pretraining significantly mitigates the
anisotropy found in contextualized word embeddings from GPT-2, such that the
intra-layer self-similarity (mean pairwise cosine similarity) of CLIP word
embeddings is under .25 in all layers, compared to greater than .95 in the top
layer of GPT-2. CLIP word embeddings outperform GPT-2 on word-level semantic
intrinsic evaluation tasks, and achieve a new corpus-based state of the art for
the RG65 evaluation, at .88. CLIP also forms fine-grained semantic
representations of sentences, and obtains Spearman's rho = .73 on the
SemEval-2017 Semantic Textual Similarity Benchmark with no fine-tuning,
compared to no greater than rho = .45 in any layer of GPT-2. Finally,
intra-layer self-similarity of CLIP sentence embeddings decreases as the layer
index increases, finishing at .25 in the top layer, while the self-similarity
of GPT-2 sentence embeddings formed using the EOS token increases
layer-over-layer and never falls below .97. Our results indicate that high
anisotropy is not an inevitable consequence of contextualization, and that
visual semantic pretraining is beneficial not only for ordering visual
representations, but also for encoding useful semantic representations of
language, both on the word level and the sentence level.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 21:42:13 GMT""}]","2022-03-16"
"2203.07512","Hugo Schmutz","Hugo Schmutz, Olivier Humbert and Pierre-Alexandre Mattei","Don't fear the unlabelled: safe semi-supervised learning via simple
  debiasing",,,,,"stat.ML cs.AI cs.LG stat.CO stat.ME","http://creativecommons.org/licenses/by/4.0/","  Semi-supervised learning (SSL) provides an effective means of leveraging
unlabelled data to improve a model performance. Even though the domain has
received a considerable amount of attention in the past years, most methods
present the common drawback of lacking theoretical guarantees. Our starting
point is to notice that the estimate of the risk that most discriminative SSL
methods minimise is biased, even asymptotically. This bias impedes the use of
standard statistical learning theory and can hurt empirical performance. We
propose a simple way of removing the bias. Our debiasing approach is
straightforward to implement and applicable to most deep SSL methods. We
provide simple theoretical guarantees on the trustworthiness of these modified
methods, without having to rely on the strong assumptions on the data
distribution that SSL theory usually requires. In particular, we provide
generalisation error bounds for the proposed methods. We evaluate debiased
versions of different existing SSL methods, such as the Pseudo-label method and
Fixmatch, and show that debiasing can compete with classic deep SSL techniques
in various settings by providing better calibrated models. Additionally, we
provide a theoretical explanation of the intuition of the popular SSL methods.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 21:42:21 GMT""},{""version"":""v2"",""created"":""Wed, 16 Mar 2022 11:08:30 GMT""},{""version"":""v3"",""created"":""Fri, 3 Mar 2023 17:30:31 GMT""}]","2023-03-06"
"2203.07513","Kevin Matthew Stangl","Avrim Blum, Kevin Stangl, Ali Vakilian","Multi Stage Screening: Enforcing Fairness and Maximizing Efficiency in a
  Pre-Existing Pipeline",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Consider an actor making selection decisions using a series of classifiers,
which we term a sequential screening process. The early stages filter out some
applicants, and in the final stage an expensive but accurate test is applied to
the individuals that make it to the final stage. Since the final stage is
expensive, if there are multiple groups with different fractions of positives
at the penultimate stage (even if a slight gap), then the firm may naturally
only choose to the apply the final (interview) stage solely to the highest
precision group which would be clearly unfair to the other groups. Even if the
firm is required to interview all of those who pass the final round, the tests
themselves could have the property that qualified individuals from some groups
pass more easily than qualified individuals from others. Thus, we consider
requiring Equality of Opportunity (qualified individuals from each each group
have the same chance of reaching the final stage and being interviewed). We
then examine the goal of maximizing quantities of interest to the decision
maker subject to this constraint, via modification of the probabilities of
promotion through the screening process at each stage based on performance at
the previous stage. We exhibit algorithms for satisfying Equal Opportunity over
the selection process and maximizing precision (the fraction of interview that
yield qualified candidates) as well as linear combinations of precision and
recall (recall determines the number of applicants needed per hire) at the end
of the final stage. We also present examples showing that the solution space is
non-convex, which motivate our exact and (FPTAS) approximation algorithms for
maximizing the linear combination of precision and recall. Finally, we discuss
the `price of' adding additional restrictions, such as not allowing the
decision maker to use group membership in its decision process.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 21:45:01 GMT""}]","2022-03-16"
"2203.07514","David Winn","David Winn, Yasar Onel","Tile Multiple-Readout Compensated Calorimetry","Contribution to Snowmass",,,,"physics.ins-det astro-ph.HE hep-ex nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose extending parallel fiber dual readout calorimetry to tiles, more
applicable to many future experimental requirements, with superior energy
resolution. Monte Carlo (MC) studies indicate that a tile dual calorimeter
including an integral Cerenkov-compensated e-m front end and further
longitudinal segmentation, not possible with parallel fibers, has equivalent or
better resolution. Besides comparison and tuning with dual tile calorimeter
data, a MC can be extended to study other dual and then multiple tile sensors
including tiles with higher contrast to em-hadron shower fluctuations with low
refractive indices (much lower than quartz or plastic), transition radiation,
secondary emission, hydrogenous/non-hydrogenous ionization-sensing, and neutron
and ion-fragment sensing tiles for improving dual readout not available with
fibers, and beyond to triple or more readout. For example, secondary emission
tiles (like dynodes) are very sensitive to ion fragments and low energy
neutrons. We suggest MC studies for adding Cerenkov and other tiles to Particle
Flow/High Granularity tile calorimeters such CALICE and planned in CMS & ATLAS
Phase III upgrades, groups studying future machine(ee,pp,ep) detectors,
b-physics, tagged neutrino experiments, and space-based calorimeters.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 21:48:49 GMT""}]","2022-03-16"
"2203.07515","Michael Eides","Michael I. Eides and Valery A. Shelyuto","Three-Loop Corrections to Lamb Shift in Positronium: Electron Factor and
  Polarization","8 pages, 2 figures",,"10.1016/j.physletb.2022.137247",,"hep-ph physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hard spin-independent three-loop radiative contributions to energy levels in
positronium generated by the two-photon-exchange diagrams with one-loop
radiative insertions in the fermion lines and exchanged photons are calculated.
This is a next step in calculations of all corrections of order $m\alpha^7$
inspired by the new generation of precise $1S-2S$ and $2S-2P$ measurements in
positronium.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 21:49:29 GMT""},{""version"":""v2"",""created"":""Sat, 14 May 2022 18:10:49 GMT""}]","2022-06-15"
"2203.07516","Chang Gao","Qinyu Chen, Chang Gao, Xinyuan Fang, Haitao Luan","Skydiver: A Spiking Neural Network Accelerator Exploiting
  Spatio-Temporal Workload Balance","Accepted to be published in the IEEE Transactions on Computer-Aided
  Design of Integrated Circuits and Systems, 2022",,"10.1109/TCAD.2022.3158834",,"cs.AR cs.CV cs.LG cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spiking Neural Networks (SNNs) are developed as a promising alternative to
Artificial Neural networks (ANNs) due to their more realistic brain-inspired
computing models. SNNs have sparse neuron firing over time, i.e.,
spatio-temporal sparsity; thus, they are useful to enable energy-efficient
hardware inference. However, exploiting spatio-temporal sparsity of SNNs in
hardware leads to unpredictable and unbalanced workloads, degrading the energy
efficiency. In this work, we propose an FPGA-based convolutional SNN
accelerator called Skydiver that exploits spatio-temporal workload balance. We
propose the Approximate Proportional Relation Construction (APRC) method that
can predict the relative workload channel-wisely and a Channel-Balanced
Workload Schedule (CBWS) method to increase the hardware workload balance ratio
to over 90%. Skydiver was implemented on a Xilinx XC7Z045 FPGA and verified on
image segmentation and MNIST classification tasks. Results show improved
throughput by 1.4X and 1.2X for the two tasks. Skydiver achieved 22.6 KFPS
throughput, and 42.4 uJ/Image prediction energy on the classification task with
98.5% accuracy.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 21:52:04 GMT""}]","2022-03-16"
"2203.07517","Felix Fehse","F. Fehse, M. David, M. Pioro-Ladri\`ere, W. A. Coish","Generalized fast quasi-adiabatic population transfer for improved qubit
  readout, shuttling, and noise mitigation","12 pages, 7 figures",,,,"cond-mat.mes-hall quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Population-transfer schemes are commonly used to convert information robustly
stored in some quantum system for manipulation and memory into more macroscopic
degrees of freedom for measurement. These schemes may include, e.g.,
spin-to-charge conversion for spins in quantum dots, detuning of charge qubits
between a noise-insensitive operating point and a measurement point, spatial
shuttling of qubits encoded in spins or ions, and parity-to-charge conversion
schemes for qubits based on Majorana zero modes. A common strategy is to use a
slow (adiabatic) conversion. However, in an adiabatic scheme, the adiabaticity
conditions on the one hand, and accumulation of errors through dephasing,
leakage, and energy relaxation processes on the other hand, limit the fidelity
that can be achieved. Here, we give explicit fast quasi-adiabatic (fast-QUAD)
conversion strategies (pulse shapes) beyond the adiabatic approximation that
allow for optimal state conversion. In contrast with many other approaches,
here we account for a general source of noise in combination with pulse
shaping. Inspired by analytic methods that have been developed for dynamical
decoupling theory, we provide a general framework for unique noise mitigation
strategies that can be tailored to the system and environment of interest.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 21:54:01 GMT""}]","2022-03-16"
"2203.07518","Martin Balko","Martin Balko and Manfred Scheucher and Pavel Valtr","Erd\H{o}s--Szekeres-type problems in the real projective plane","The extended abstract appeared at the 38th International Symposium on
  Computational Geometry (SoCG 2022)",,,,"math.CO cs.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider point sets in the real projective plane $\mathbb{R}P^2$ and
explore variants of classical extremal problems about planar point sets in this
setting, with a main focus on Erd\H{o}s--Szekeres-type problems.
  We provide asymptotically tight bounds for a variant of the
Erd\H{o}s--Szekeres theorem about point sets in convex position in
$\mathbb{R}P^2$, which was initiated by Harborth and M\""oller in 1994. The
notion of convex position in $\mathbb{R}P^2$ agrees with the definition of
convex sets introduced by Steinitz in 1913.
  For $k \geq 3$, an (\affine) $k$-hole in a finite set $S \subseteq
\mathbb{R}^2$ is a set of $k$ points from $S$ in convex position with no point
of $S$ in the interior of their convex hull. After introducing a new notion of
$k$-holes for points sets from $\mathbb{R}P^2$, called projective $k$-holes, we
find arbitrarily large finite sets of points from $\mathbb{R}P^2$ with no
\projective 8-holes, providing an analogue of a classical planar construction
by Horton from 1983. We also prove that they contain only quadratically many
\projective $k$-holes for $k \leq 7$. On the other hand, we show that the
number of $k$-holes can be substantially larger in~$\mathbb{R}P^2$ than in
$\mathbb{R}^2$ by constructing, for every $k \in \{3,\dots,6\}$, sets of $n$
points from $\mathbb{R}^2 \subset \mathbb{R}P^2$ with $\Omega(n^{3-3/5k})$
\projective $k$-holes and only $O(n^2)$ \affine $k$-holes. Last but not least,
we prove several other results, for example about projective holes in random
point sets in $\mathbb{R}P^2$ and about some algorithmic aspects.
  The study of extremal problems about point sets in $\mathbb{R}P^2$ opens a
new area of research, which we support by posing several open problems.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 21:55:08 GMT""},{""version"":""v2"",""created"":""Sat, 3 Sep 2022 11:05:20 GMT""}]","2022-09-07"
"2203.07519","Dong-Ho Lee","Woojeong Jin, Dong-Ho Lee, Chenguang Zhu, Jay Pujara and Xiang Ren","Leveraging Visual Knowledge in Language Tasks: An Empirical Study on
  Intermediate Pre-training for Cross-modal Knowledge Transfer","Accepted to ACL 2022, 13 pages, 4 figures",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pre-trained language models are still far from human performance in tasks
that need understanding of properties (e.g. appearance, measurable quantity)
and affordances of everyday objects in the real world since the text lacks such
information due to reporting bias. In this work, we study whether integrating
visual knowledge into a language model can fill the gap. We investigate two
types of knowledge transfer: (1) text knowledge transfer using image captions
that may contain enriched visual knowledge and (2) cross-modal knowledge
transfer using both images and captions with vision-language training
objectives. On 5 downstream tasks that may need visual knowledge to solve the
problem, we perform extensive empirical comparisons over the presented
objectives. Our experiments show that visual knowledge transfer can improve
performance in both low-resource and fully supervised settings.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 22:02:40 GMT""},{""version"":""v2"",""created"":""Thu, 17 Mar 2022 01:11:42 GMT""}]","2022-03-18"
"2203.07520","Jan Budaj","Jan Budaj, Andrii Maliuk, Ivan Hubeny","WD 1145+017: Alternative models of the atmosphere, dust clouds, and gas
  rings","Eqs.18, 19 in a more elegant form","A&A, 660, A72 (2022)","10.1051/0004-6361/202141924",,"astro-ph.EP astro-ph.SR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  WD 1145+017 is the first white dwarf known to be orbited by disintegrating
exoasteroids. It is a DBZ-type white dwarf with strongly variable broad
circumstellar lines and variable shallow UV transits. Various models of the
dust clouds and gaseous rings have been proposed as an explanation for this
behavior. Here we propose alternative models.The simple radiative transfer code
Shellspec was modified for this purpose and used for testing the new dust cloud
and gas disk models. We used modified TLUSTY and SYNSPEC codes to calculate
atmosphere models assuming the LTE or NLTE, and to calculate the intrinsic
spectrum of the star. We then used these atmosphere models to estimate the mass
of the radiative and convective zones and NLTE spectrum synthesis to estimate
their chemical composition. We offer an alternative explanation of some (not
all) shallow UV transits. These may be naturally caused by the optical
properties of the dust grains: opacities and mainly phase functions as a result
of the forward scattering. The latter is much stronger in UV compared to the
optical region, leaving more UV photons in the original direction during the
transit. We also developed an alternative model of the gaseous disk, consisting
of an inner, hotter, and almost circular disk and an outer, cooler, and
eccentric disk. The structure precesses with a period of $3.83 \pm 0.12$ yr. We
demonstrate that it fits the observed circumstellar lines reasonably well.
These alternative models solve a few drawbacks that might be associated with
the previous models, but they also have their own disadvantages. We confirm
that the chemical composition of the atmosphere is similar to that of CI
chondrites but C, N, and S are significantly underabundant and much closer to
the bulk Earth composition. This is a strong argument that the star has
recently encountered and accreted material from a body of Earth-like
composition.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 22:06:08 GMT""},{""version"":""v2"",""created"":""Tue, 19 Apr 2022 13:24:38 GMT""}]","2022-04-27"
"2203.07521","Dhanoop Karunakaran","Dhanoop Karunakaran, Julie Stephany Berrio, Stewart Worrall, Eduardo
  Nebot","Automatic lane change scenario extraction and generation of scenarios in
  OpenX format from real-world data","Submitted to IEEE IV 22 conference",,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  Autonomous Vehicles (AV)'s wide-scale deployment appears imminent despite
many safety challenges yet to be resolved. The modern autonomous vehicles will
undoubtedly include machine learning and probabilistic techniques that add
significant complexity to the traditional verification and validation methods.
Road testing is essential before the deployment, but scenarios are repeatable,
and it's hard to collect challenging events. Exploring numerous, diverse and
crucial scenarios is a time-consuming and expensive approach. The research
community and industry have widely accepted scenario-based testing in the last
few years. As it is focused directly on the relevant critical road situations,
it can reduce the effort required in testing. The scenario-based testing in
simulation requires the realistic behaviour of the traffic participants to
assess the System Under Test (SUT). It is essential to capture the scenarios
from the real world to encode the behaviour of actual traffic participants.
This paper proposes a novel scenario extraction method to capture the lane
change scenarios using point-cloud data and object tracking information. This
method enables fully automatic scenario extraction compared to similar
approaches in this area. The generated scenarios are represented in OpenX
format to reuse them in the SUT evaluation easily. The motivation of this
framework is to build a validation dataset to generate many critical concrete
scenarios. The code is available online at
https://github.com/dkarunakaran/scenario_extraction_framework.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 22:06:48 GMT""}]","2022-03-16"
"2203.07522","Man Luo","Man Luo, Kazuma Hashimoto, Semih Yavuz, Zhiwei Liu, Chitta Baral,
  Yingbo Zhou","Choose Your QA Model Wisely: A Systematic Study of Generative and
  Extractive Readers for Question Answering",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  While both extractive and generative readers have been successfully applied
to the Question Answering (QA) task, little attention has been paid toward the
systematic comparison of them. Characterizing the strengths and weaknesses of
the two readers is crucial not only for making a more informed reader selection
in practice but also for developing a deeper understanding to foster further
research on improving readers in a principled manner. Motivated by this goal,
we make the first attempt to systematically study the comparison of extractive
and generative readers for question answering. To be aligned with the
state-of-the-art, we explore nine transformer-based large pre-trained language
models (PrLMs) as backbone architectures. Furthermore, we organize our findings
under two main categories: (1) keeping the architecture invariant, and (2)
varying the underlying PrLMs. Among several interesting findings, it is
important to highlight that (1) the generative readers perform better in long
context QA, (2) the extractive readers perform better in short context while
also showing better out-of-domain generalization, and (3) the encoder of
encoder-decoder PrLMs (e.g., T5) turns out to be a strong extractive reader and
outperforms the standard choice of encoder-only PrLMs (e.g., RoBERTa). We also
study the effect of multi-task learning on the two types of readers varying the
underlying PrLMs and perform qualitative and quantitative diagnosis to provide
further insights into future directions in modeling better readers.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 22:07:52 GMT""}]","2022-03-16"
"2203.07523","Yi Zhou","Yi Zhou, Masahiro Kaneko, Danushka Bollegala","Sense Embeddings are also Biased--Evaluating Social Biases in Static and
  Contextualised Sense Embeddings","Accepted to ACL 2022",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sense embedding learning methods learn different embeddings for the different
senses of an ambiguous word. One sense of an ambiguous word might be socially
biased while its other senses remain unbiased. In comparison to the numerous
prior work evaluating the social biases in pretrained word embeddings, the
biases in sense embeddings have been relatively understudied. We create a
benchmark dataset for evaluating the social biases in sense embeddings and
propose novel sense-specific bias evaluation measures. We conduct an extensive
evaluation of multiple static and contextualised sense embeddings for various
types of social biases using the proposed measures. Our experimental results
show that even in cases where no biases are found at word-level, there still
exist worrying levels of social biases at sense-level, which are often ignored
by the word-level bias evaluation measures.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 22:08:37 GMT""},{""version"":""v2"",""created"":""Wed, 16 Mar 2022 10:22:57 GMT""}]","2022-03-17"
"2203.07524","Yong Do Kim","Yong Do Kim and Louis J. Durlofsky","Convolutional-Recurrent Neural Network Proxy for Robust Optimization and
  Closed-Loop Reservoir Management","Corrected a typo (page 9, from '400 bar' to '320 bar')",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Production optimization under geological uncertainty is computationally
expensive, as a large number of well control schedules must be evaluated over
multiple geological realizations. In this work, a convolutional-recurrent
neural network (CNN-RNN) proxy model is developed to predict well-by-well oil
and water rates, for given time-varying well bottom-hole pressure (BHP)
schedules, for each realization in an ensemble. This capability enables the
estimation of the objective function and nonlinear constraint values required
for robust optimization. The proxy model represents an extension of a recently
developed long short-term memory (LSTM) RNN proxy designed to predict well
rates for a single geomodel. A CNN is introduced here to processes permeability
realizations, and this provides the initial states for the RNN. The CNN-RNN
proxy is trained using simulation results for 300 different sets of BHP
schedules and permeability realizations. We demonstrate proxy accuracy for
oil-water flow through multiple realizations of 3D multi-Gaussian permeability
models. The proxy is then incorporated into a closed-loop reservoir management
(CLRM) workflow, where it is used with particle swarm optimization and a
filter-based method for nonlinear constraint satisfaction. History matching is
achieved using an adjoint-gradient-based procedure. The proxy model is shown to
perform well in this setting for five different (synthetic) `true' models.
Improved net present value along with constraint satisfaction and uncertainty
reduction are observed with CLRM. For the robust production optimization steps,
the proxy provides O(100) runtime speedup over simulation-based optimization.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 22:11:17 GMT""},{""version"":""v2"",""created"":""Wed, 1 Jun 2022 16:34:15 GMT""}]","2022-06-02"
"2203.07525","Onofrio M. Marag\`o","Y. Kiasat, M. G. Donato, M. Hinczewski, M. ElKabbash, T. Letsou, R.
  Saija, O. M. Marago, G. Strangi, and N. Engheta","Epsilon-Near-Zero (ENZ)-based Optomechanics","32 pages, 13 figures",,,,"physics.optics cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Optomechanics deals with the control and applications of mechanical effects
of light that stems from the redistribution of photon momenta in light
scattering. Here, we investigate, analytically and numerically, optical forces
on polarizable particles in proximity of epsilon-near-zero (ENZ) metamaterials.
We look at the general features of the repulsive-attractive optomechanics from
the nano to the microscale exploiting different theoretical methods (dipole
approximation, finite elements calculations, transition (T-)matrix). We discuss
the role of realistic layered materials, as our ENZ substrate, on optical
forces and analyze the influence of composition and shape by studying a range
of complex particles (dielectric, core-shell, plasmonic ellipsoids). Physical
insights into the results are discussed and future research directions are
forecasted. Our results provide new possibilities in exploiting engineered
materials and surfaces for the manipulation and tailoring of light-induced
forces in optomechanics.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 22:15:41 GMT""}]","2022-03-16"
"2203.07526","Ignacio Germ\'an Alfaro Ger","Ignacio G. Alfaro, Facundo Rodriguez, Andr\'es N. Ruiz, Heliana E.
  Luparello, and Diego Garcia Lambas","How do galaxies populate halos in extreme density environments? An
  analysis of the Halo Occupation Distribution in SDSS","9 pages, 9 figures. First version. Sent to refereed in A&A","A&A 665, A44 (2022)","10.1051/0004-6361/202243542",,"astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent works have shown that the properties of galaxy populations in dark
matter halos vary with large-scale environments. These results suggest a
variation in the halo occupation distribution (HOD) in extreme density
environments. To analyse these effects, we identify cosmic voids and future
virialised structures (FVS) in the SDSS-DR12 and estimate the HOD within these
superstructures using group catalogues as dark matter halo proxies.
  Our goal is to use observational galaxy data to characterise the HOD within
voids and FVS, explore the different properties of these galaxies populations
and compare them with the general results outside these superstructures.
  Using a galaxy group catalogue we compute the HOD within both types of
superstructures. We also study the dependence on the results on the main void
and FVS properties. We also analysed the mean stellar age of the galaxies
inside these regions. In all cases, we compare the results with those derived
from the Field sample.
  Inside voids, we find a strong decrease in HOD concerning the Field results.
The mean number of satellites fall to 50%. Inside FVS, the HOD shows a
significant increase to the Field, with a 40% excess in the mean number of
satellites. In both regions, the differences with respect to the Field
increases for the extreme values of the density environments. We obtain no
signs of variations related to intrinsic characteristics of voids and FVS. We
find that the cumulative distribution of the mean age of stars of the central
galaxy also varies in these regions. Finally, we explore the HOD for the 25%
youngest (oldest) galaxies. We find that for the low-mass groups the youngest
galaxies are only present inside voids. On the other hand, for the high-mass
groups the FVS environments show the same increase in the HOD concerning the
Field. We find that cosmic voids lack of oldest galaxies.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 22:18:28 GMT""}]","2022-09-07"
"2203.07527","Teng-Hui Huang","Teng-Hui Huang, Aly El Gamal, Hesham El Gamal","A Linearly Convergent Douglas-Rachford Splitting Solver for Markovian
  Information-Theoretic Optimization Problems",,,,,"cs.IT math.IT math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we propose solving the Information bottleneck (IB) and Privacy
Funnel (PF) problems with Douglas-Rachford Splitting methods (DRS). We study a
general Markovian information-theoretic Lagrangian that includes IB and PF into
a unified framework. We prove the linear convergence of the proposed solvers
using the Kurdyka-{\L}ojasiewicz inequality. Moreover, our analysis is beyond
IB and PF and applies to any convex-weakly convex pair objectives. Based on the
results, we develop two types of linearly convergent IB solvers, with one
improves the performance of convergence over existing solvers while the other
can be independent to the relevance-compression trade-off. Moreover, our
results apply to PF, yielding a new class of linearly convergent PF solvers.
Empirically, the proposed IB solvers IB obtain solutions that are comparable to
the Blahut-Arimoto-based benchmark and is convergent for a wider range of the
penalty coefficient than existing solvers. For PF, our non-greedy solvers can
characterize the privacy-utility trade-off better than the clustering-based
greedy solvers.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 22:26:26 GMT""},{""version"":""v2"",""created"":""Sun, 23 Oct 2022 13:48:28 GMT""}]","2022-10-25"
"2203.07528","Jonathan Bauermann","Jonathan Bauermann, Christoph A. Weber, Frank J\""ulicher","Energy and Matter Supply for Active Droplets",,,"10.1002/andp.202200132",,"physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Chemically active droplets provide simple models for cell-like systems that
can grow and divide. Such active droplet systems are driven away from
thermodynamic equilibrium and turn over chemically, which corresponds to a
simple metabolism. We consider two scenarios of non-equilibrium driving. First,
droplets are driven via the system boundaries by external reservoirs that
supply nutrient and remove waste (boundary-driven). Second, droplets are driven
by a chemical energy provided by a fuel in the bulk (bulk-driven). For both
scenarios, we discuss the conservation of energy and matter as well as the
balance of entropy. We use conserved and non-conserved fields to analyze the
non-equilibrium steady states of active droplets. Using an effective droplet
model, we explore droplet stability and instabilities leading to droplet
division. Our work reveals that droplet division occurs quite generally in
active droplet systems. Our results suggest that life-like processes such as
metabolism and division can emerge in simple non-equilibrium systems that
combine the physics of phase separation and chemical reactions.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 22:32:15 GMT""}]","2022-09-28"
"2203.07529","Mattias Birman","Mattias Birman, Benjamin Nachman, Raphael Sebbah, Gal Sela, Ophir
  Turetz, Shikma Bressler","Data-Directed Search for New Physics based on Symmetries of the SM",,"Eur. Phys. J. C 82, 508 (2022)","10.1140/epjc/s10052-022-10454-2",,"hep-ph hep-ex","http://creativecommons.org/publicdomain/zero/1.0/","  We propose exploiting symmetries (exact or approximate) of the Standard Model
(SM) to search for physics Beyond the Standard Model (BSM) using the
data-directed paradigm (DDP). Symmetries are very powerful because they provide
two samples that can be compared without requiring simulation. Focusing on the
data, exclusive selections which exhibit significant asymmetry can be
identified efficiently and marked for further study. Using a simple and generic
test statistic which compares two matrices already provides good sensitivity,
only slightly worse than that of the profile likelihood ratio test statistic
which relies on the exact knowledge of the signal shape. This can be exploited
for rapidly scanning large portions of the measured data, in an attempt to
identify regions of interest. Weakly supervised Neural Networks could be used
for this purpose as well.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 22:32:51 GMT""},{""version"":""v2"",""created"":""Mon, 30 May 2022 08:57:55 GMT""},{""version"":""v3"",""created"":""Wed, 8 Jun 2022 10:48:04 GMT""}]","2022-06-09"
"2203.07530","Levi Burner","Levi Burner, Nitin J. Sanket, Cornelia Ferm\""uller, Yiannis Aloimonos","TTCDist: Fast Distance Estimation From an Active Monocular Camera Using
  Time-to-Contact","19 pages, 24 figures, 1 table. To be published in ICRA 2023",,,,"cs.RO cs.CV","http://creativecommons.org/licenses/by/4.0/","  Distance estimation from vision is fundamental for a myriad of robotic
applications such as navigation, manipulation, and planning. Inspired by the
mammal's visual system, which gazes at specific objects, we develop two novel
constraints relating time-to-contact, acceleration, and distance that we call
the $\tau$-constraint and $\Phi$-constraint. They allow an active (moving)
camera to estimate depth efficiently and accurately while using only a small
portion of the image. The constraints are applicable to range sensing, sensor
fusion, and visual servoing.
  We successfully validate the proposed constraints with two experiments. The
first applies both constraints in a trajectory estimation task with a monocular
camera and an Inertial Measurement Unit (IMU). Our methods achieve 30-70% less
average trajectory error while running 25$\times$ and 6.2$\times$ faster than
the popular Visual-Inertial Odometry methods VINS-Mono and ROVIO respectively.
The second experiment demonstrates that when the constraints are used for
feedback with efference copies the resulting closed loop system's eigenvalues
are invariant to scaling of the applied control signal. We believe these
results indicate the $\tau$ and $\Phi$ constraint's potential as the basis of
robust and efficient algorithms for a multitude of robotic applications.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 22:34:10 GMT""},{""version"":""v2"",""created"":""Fri, 23 Sep 2022 16:45:42 GMT""},{""version"":""v3"",""created"":""Tue, 7 Mar 2023 17:24:32 GMT""}]","2023-03-08"
"2203.07531","Rocco Micciolo","Giulia Fedrizzi, Luisa Canal, Rocco Micciolo","UEFA EURO 2020: a ""pure game of chance""?",,,,,"stat.AP","http://creativecommons.org/licenses/by/4.0/","  We analysed the distribution of the number of goals scored in each of the 51
football matches played in the UEFA EURO 2020 final phase as well as the
waiting times between scores (also considering censored times). We found that
the Poisson model fits the score data and the exponential distribution fits
waiting times quite well. Such a good fit could be considered somewhat
counterintuitive and unrealistic given the memoryless property of the
exponential model. However, some peculiar features of this study have to be
considered: the abilities of the teams were relatively homogeneous; the time
span was short; there was no distinction between home and away games; only the
total number of goals scored in each game was considered. Although UEFA EURO
2020 can certainly not be considered a ""pure game of chance"", this competition
can be seen as an intriguing example of the pervasive real-world ubiquity of
the concept of independence and its ability to encompass complex situations in
a single, parsimonious model.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 22:34:57 GMT""}]","2022-03-16"
"2203.07532","Mark Shattuck","Toufik Mansour and Mark Shattuck","Statistics on bargraphs of inversion sequences of permutations",,"Discrete Math. Letters 4 (2020), 37-44",,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  We consider the joint distribution of the area and perimeter statistics on
the set I_n of inversion sequences of length n represented as bargraphs.
Functional equations for both the ordinary and exponential generating functions
are derived from recurrences satisfied by this distribution. Explicit formulas
are found in some special cases as are expressions for the totals of the
respective statistics on I_n. A similar treatment is provided for the joint
distribution on I_n for the statistics recording the number of levels, descents
and ascents. Some connections are made between specific cases of this latter
distribution and the Stirling numbers of the first kind and Eulerian numbers.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 22:35:15 GMT""}]","2022-03-16"
"2203.07533","Rashmish Mishra","Prateek Agrawal, Cari Cesarotti, Andreas Karch, Rashmish K. Mishra,
  Lisa Randall and Raman Sundrum","Warped Compactifications in Particle Physics, Cosmology and Quantum
  Gravity","12 pages, 3 figures. Contribution to Snowmass 2021",,,,"hep-th hep-ph","http://creativecommons.org/licenses/by/4.0/","  Particle physics has evolved in the past decade through evaluating the
consequences of experimental measurements as well as exploiting theoretical
tools that permit exploration of new model building and cosmological
possibilities. Particularly due to insights from the AdS/CFT correspondence,
higher-dimensional warped compactifications, in particular, have played a big
role in recent developments by allowing a study of regimes of parameters that
would otherwise be intractable. Similarly, theoretical developments in quantum
gravity benefit from the bigger range of possibilities that can be explored
using warped geometry, allowing for constructions of string vacua with positive
cosmological constant and for the exploration of entanglement and information
transfer in arbitrary dimensions. Puzzles remain in both more
phenomenologically oriented and more theoretically oriented contexts which form
the basis for a rich research program in the future as well.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 22:36:27 GMT""}]","2022-03-16"
"2203.07534","Luther Rinehart","Luther Rinehart","Elliptic operators on non-compact manifolds have closed range",,,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We show that a second-order elliptic differential operator $P$, on any
manifold $M$, has closed range in $C^\infty(M)$. If $M$ has no compact
components, then $P$ is surjective on $C^\infty(M)$. Applications to Helmholtz
decomposition are discussed.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 22:38:11 GMT""}]","2022-03-16"
"2203.07535","Matthew Basso","Alexander Albert, Matthew J. Basso, Samuel K. Bright-Thonney,
  Valentina M. M. Cairo, Chris Damerell, Daniel Egana-Ugrinovic, Ulrich
  Einhaus, Ulrich Heintz, Samuel Homiller, Shin-ichi Kawada, Jingyu Luo,
  Chester Mantel, Patrick Meade, Jose Monroy, Meenakshi Narain, Robert S. Orr,
  Joseph Reichert, Anders Ryd, Jan Strube, Dong Su, Ariel G. Schwartzman,
  Tomohiko Tanabe, Junping Tian, Emanuele Usai, Jerry Va'vra, Caterina
  Vernieri, Charles C. Young, and Rui Zou","Strange quark as a probe for new physics in the Higgs sector","V1: 69 pages; V2: 80 pages, updated figures/numbers, additional
  appendices",,,"Report-no: ILD-PHYS-PROC-2022-001","hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper describes a novel algorithm for tagging jets originating from the
hadronisation of strange quarks (strange-tagging) with the future International
Large Detector (ILD) at the International Linear Collider (ILC). It also
presents the first application of such a strange-tagger to a Higgs to strange
($h \rightarrow s\bar{s}$) analysis with the $P(e^-,e^+) = (-80\%,+30\%)$
polarisation scenario, corresponding to 900 fb$^{-1}$ of the initial proposed
2000 fb$^{-1}$ of data which will be collected by ILD during its first 10 years
of data taking at $\sqrt{s} = 250$ GeV. Upper limits on the Standard Model
Higgs-strange coupling strength modifier, $\kappa_s$, are derived at the 95%
confidence level to be 7.14. The paper includes as well a preliminary study of
a Ring Imaging Cherenkov (RICH) system capable of discriminating between kaons
and pions at high momenta (up to 25 GeV), and thus enhancing strange-tagging
performance at future Higgs factory detectors.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 22:40:29 GMT""},{""version"":""v2"",""created"":""Wed, 6 Jul 2022 04:05:34 GMT""}]","2022-07-07"
"2203.07536","Tanvi Pradeep Gujarati","Tanvi P. Gujarati, Mario Motta, Triet Nguyen Friedhoff, Julia E. Rice,
  Nam Nguyen, Panagiotis Kl. Barkoutsos, Richard J. Thompson, Tyler Smith,
  Marna Kagele, Mark Brei, Barbara A. Jones, Kristen Williams","Quantum Computation of Reactions on Surfaces Using Local Embedding","37 pages, 5 figures plus supplementary information",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Quantum computational techniques have been proposed to model electronic
systems. Despite encouraging preliminary results for small molecular species,
the modeling of complex material systems using these techniques is less
understood and established. We outline a workflow for modeling chemical
reactions on surfaces with quantum algorithms, and illustrate it for water
dissociation on a magnesium surface. This is the first example, to the best of
our knowledge, of modeling a reaction on a surface using a quantum computer.
Two local embedding methods for systematic determination of active spaces are
developed and compared. These methods are automated, systematically improvable
and based on the physics of the system. To achieve this goal, they target a
spatially localized region in which electron correlation effects are more
important than in the rest of the system. To reduce finite-size effects, the
local embedding methods are designed to enable Brillouin zone integration.
Ground-state energies of the active-space projected Hamiltonians are computed
with variational quantum algorithms suitable for near-term quantum computers,
using classical simulators and quantum hardware, and the impact of various
approximations is discussed. Results indicate that the system size which can be
feasibly treated with quantum simulations is extended by using local embedding
and Brillouin zone integration methods, as only a local region is correlated by
a quantum simulation.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 22:41:10 GMT""},{""version"":""v2"",""created"":""Thu, 7 Apr 2022 01:17:06 GMT""}]","2022-04-08"
"2203.07537","Francisco Restrepo","Francisco Restrepo, Junjing Zhao, Utpal Chatterjee","Denoising and feature extraction in photoemission spectra with
  variational auto-encoder neural networks","Submitted to Review of Scientific Instruments",,"10.1063/5.0090051",,"physics.ins-det cond-mat.str-el cs.LG","http://creativecommons.org/licenses/by/4.0/","  In recent years, distinct machine learning (ML) models have been separately
used for feature extraction and noise reduction from energy-momentum dispersion
intensity maps obtained from raw angle-resolved photoemission spectroscopy
(ARPES) data. In this work, we employ a shallow variational auto-encoder (VAE)
neural network to demonstrate the prospect of using ML for both denoising of as
well as feature extraction from ARPES dispersion maps.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 22:46:09 GMT""}]","2022-06-29"
"2203.07538","Cristina Gena","Cristina Gena, Claudio Mattutino, Andrea Maieli, Elisabetta Miraglio,
  Giulia Ricciardiello, Rossana Damiano, Alessandro Mazzei","Autistic Children's Mental Model of an Humanoid Robot",,,"10.1145/3450614.3463422",,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This position paper introduces the results of an initial card sorting
experiment based on the reactions and questions of a group of children with
autism working with a humanoid robot in a therapeutic laboratory on autonomy.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 22:49:53 GMT""}]","2022-03-16"
"2203.07539","Subhabrata Sen","Jiaze Qiu and Subhabrata Sen","The TAP free energy for high-dimensional linear regression","36 pages",,,,"math.PR math.ST stat.ML stat.TH","http://creativecommons.org/licenses/by/4.0/","  We derive a variational representation for the log-normalizing constant of
the posterior distribution in Bayesian linear regression with a uniform
spherical prior and an i.i.d. Gaussian design. We work under the ""proportional""
asymptotic regime, where the number of observations and the number of features
grow at a proportional rate. This rigorously establishes the
Thouless-Anderson-Palmer (TAP) approximation arising from spin glass theory,
and proves a conjecture of Krzakala et. al. (2014) in the special case of the
spherical prior.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 22:50:20 GMT""}]","2022-03-16"
"2203.07540","Peter Jansen","Ruoyao Wang, Peter Jansen, Marc-Alexandre C\^ot\'e, Prithviraj
  Ammanabrolu","ScienceWorld: Is your Agent Smarter than a 5th Grader?","Accepted to EMNLP 2022",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by-sa/4.0/","  We present ScienceWorld, a benchmark to test agents' scientific reasoning
abilities in a new interactive text environment at the level of a standard
elementary school science curriculum. Despite the transformer-based progress
seen in question-answering and scientific text processing, we find that current
models cannot reason about or explain learned science concepts in novel
contexts. For instance, models can easily answer what the conductivity of a
known material is but struggle when asked how they would conduct an experiment
in a grounded environment to find the conductivity of an unknown material. This
begs the question of whether current models are simply retrieving answers by
way of seeing a large number of similar examples or if they have learned to
reason about concepts in a reusable manner. We hypothesize that agents need to
be grounded in interactive environments to achieve such reasoning capabilities.
Our experiments provide empirical evidence supporting this hypothesis --
showing that a 1.5 million parameter agent trained interactively for 100k steps
outperforms a 11 billion parameter model statically trained for scientific
question-answering and reasoning from millions of expert demonstrations.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 22:52:34 GMT""},{""version"":""v2"",""created"":""Mon, 14 Nov 2022 17:52:27 GMT""}]","2022-11-15"
"2203.07541","Iryna Chaikovska","L. Bandiera, L. Bomben, R. Camattari, G. Cavoto, I. Chaikovska, R.
  Chehab, D. De Salvador, V. Guidi, V. Haurylavets, E. Lutsenko, V. Mascagna,
  A. Mazzolari, M. Prest, M. Romagnoni, F. Ronchetti, F. Sgarbossa, M. Soldani,
  A. Sytov, M. Tamisari, V. Tikhomirov, E. Vallazza","Crystal-based pair production for a lepton collider positron source",,,"10.1140/epjc/s10052-022-10666-6",,"physics.acc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An intense positron sources is a demanding element in the design of future
lepton colliders. A crystal-based hybrid positron source could be an
alternative to a more conventional scheme based on the electron conversion into
positron in a thick amorphous target. The conceptual idea of the hybrid source
is to have two separate objects, a photon radiator and a photon-to-positron
converter target. In such a scheme an electron beam crosses a thin axially
oriented crystal with the emission of a channeling radiation, characterized by
a considerably larger amount of photons if compared to Bremsstrahlung. The net
result is an increase in the number of produced positrons at the converter
target. In this paper we present the results of a beam test conducted at the
DESY TB 21 with 5.6 GeV electron beam and a crystalline tungsten radiator.
Experimental data clearly highlight an increased production of photons and they
are critically compared with the outcomes of novel method to simulate the
number of radiated photons, showing a very good agreement. Strong of this, the
developed simulation tool has been exploited to design a simple scheme for a
positron source based on oriented crystal, demonstrating the advantages in
terms of reduction of both deposited energy and the peak energy deposition
density if compared to conventional sources. The presented work opens the way
for a realistic and detailed design of a hybrid crystal-based positron source
for future lepton colliders.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 22:52:52 GMT""}]","2022-09-07"
"2203.07542","Auralee Edelen","Auralee Edelen and Christopher Mayes","Neural Network Solver for Coherent Synchrotron Radiation Wakefield
  Calculations in Accelerator-based Charged Particle Beams",,,,,"physics.acc-ph cs.LG physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Particle accelerators support a wide array of scientific, industrial, and
medical applications. To meet the needs of these applications, accelerator
physicists rely heavily on detailed simulations of the complicated particle
beam dynamics through the accelerator. One of the most computationally
expensive and difficult-to-model effects is the impact of Coherent Synchrotron
Radiation (CSR). As a beam travels through a curved trajectory (e.g. due to a
bending magnet), it emits radiation that in turn interacts with the rest of the
beam. At each step through the trajectory, the electromagnetic field introduced
by CSR (called the CSR wakefield) needs to computed and used when calculating
the updates to the positions and momenta of every particle in the beam. CSR is
one of the major drivers of growth in the beam emittance, which is a key metric
of beam quality that is critical in many applications. The CSR wakefield is
very computationally intensive to compute with traditional electromagnetic
solvers, and this is a major limitation in accurately simulating accelerators.
Here, we demonstrate a new approach for the CSR wakefield computation using a
neural network solver structured in a way that is readily generalizable to new
setups. We validate its performance by adding it to a standard beam tracking
test problem and show a ten-fold speedup along with high accuracy.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 22:52:59 GMT""}]","2022-03-16"
"2203.07543","Cristina Gena","Cristina Gena, Claudio Mattutino, Stefania Brighenti, Andrea Meirone,
  Francesco Petriglia, Loredana Mazzotta, Federica Liscio, Matteo Nazzario,
  Valeria Ricci, Camilla Quarato, Cesare Pecone, Giuseppe Piccinni","Sugar, Salt & Pepper -- Humanoid robotics for autism","IUI Workshops 2021",,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  This paper introduces an experimental trial that will take place from
February to June 2021, and which will see the use of the Pepper robot in a
therapeutic laboratory on autonomies that will promote functional acquisitions
in children diagnosed with high functioning autism/Asperger's syndrome.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 23:04:25 GMT""}]","2022-03-16"
"2203.07544","Mikhail Galkin","Charles Tapley Hoyt, Max Berrendorf, Mikhail Galkin, Volker Tresp,
  Benjamin M. Gyori","A Unified Framework for Rank-based Evaluation Metrics for Link
  Prediction in Knowledge Graphs","Accepted at the Workshop on Graph Learning Benchmarks @ The WebConf
  2022",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  The link prediction task on knowledge graphs without explicit negative
triples in the training data motivates the usage of rank-based metrics. Here,
we review existing rank-based metrics and propose desiderata for improved
metrics to address lack of interpretability and comparability of existing
metrics to datasets of different sizes and properties. We introduce a simple
theoretical framework for rank-based metrics upon which we investigate two
avenues for improvements to existing metrics via alternative aggregation
functions and concepts from probability theory. We finally propose several new
rank-based metrics that are more easily interpreted and compared accompanied by
a demonstration of their usage in a benchmarking of knowledge graph embedding
models.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 23:09:46 GMT""},{""version"":""v2"",""created"":""Tue, 19 Apr 2022 16:03:07 GMT""}]","2022-04-20"
"2203.07545","Kenneth Long","L. Alvarez Ruso, T. Alves, S. Boyd, A. Bross, P. R. Hobson, P. Kyberd,
  J. B. Lagrange, K. Long, X.-G. Lu, J. Pasternak, M. Pfaff, C. Rogers (for the
  nuSTORM collaboration)","Neutrinos from Stored Muons (nuSTORM)","Contribution to Snowmass 2021",,,,"hep-ex physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  The 2020 Update of the European Strategy for Particle Physics (ESPP) (see
https://cds.cern.ch/record/2720129 ) recommended that muon beam R\&D should be
considered a high-priority future initiative and that a programme of
experimentation be developed to determine the neutrino cross-sections required
to extract the most physics from the DUNE and Hyper-K long-baseline
experiments. The ENUBET and nuSTORM collaborations have begun to work within
and alongside the CERN Physics Beyond Colliders study group and the
international Muon Collider collaboration to carry out a joint, five-year R\&D
programme to deliver a detailed plan for the implementation of an
infrastructure in which:
  (1) ENUBET and nuSTORM deliver the neutrino cross-section measurement
programme identified in the ESPP and allow sensitive searches for physics
beyond the Standard Model to be carried out; and in which \ (2) A 6D muon
ionisation cooling experiment is delivered as part of the technology
development programme defined by the international Muon Collider collaboration.
  This document summarises the status of development of the nuSTORM and 6D
cooling experiments and identifies opportunities for collaboration in the
development of the initiative outlined above.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 23:12:06 GMT""},{""version"":""v2"",""created"":""Tue, 9 Aug 2022 12:32:58 GMT""}]","2022-08-10"
"2203.07546","Radu Balan","Radu Balan, Naveed Haghani, Maneesh Singh","Permutation Invariant Representations with Applications to Graph Deep
  Learning","43 pages, 13 figures, 16 tables",,,,"math.FA cs.LG","http://creativecommons.org/licenses/by/4.0/","  This paper presents primarily two Euclidean embeddings of the quotient space
generated by matrices that are identified modulo arbitrary row permutations.
The original application is in deep learning on graphs where the learning task
is invariant to node relabeling. Two embedding schemes are introduced, one
based on sorting and the other based on algebras of multivariate polynomials.
While both embeddings exhibit a computational complexity exponential in problem
size, the sorting based embedding is globally bi-Lipschitz and admits a low
dimensional target space. Additionally, an almost everywhere injective scheme
can be implemented with minimal redundancy and low computational cost. In turn,
this proves that almost any classifier can be implemented with an arbitrary
small loss of performance. Numerical experiments are carried out on two data
sets, a chemical compound data set (QM9) and a proteins data set (PROTEINS).
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 23:13:59 GMT""}]","2022-03-16"
"2203.07547","Humphrey Obie","Humphrey O. Obie, Idowu Ilekura, Hung Du, Mojtaba Shahin, John Grundy,
  Li Li, Jon Whittle, Burak Turhan","On the Violation of Honesty in Mobile Apps: Automated Detection and
  Categories","12 pages, Accepted for publication in 2022 IEEE/ACM 19th
  International Conference on Mining Software Repositories (MSR)",,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Human values such as integrity, privacy, curiosity, security, and honesty are
guiding principles for what people consider important in life. Such human
values may be violated by mobile software applications (apps), and the negative
effects of such human value violations can be seen in various ways in society.
In this work, we focus on the human value of honesty. We present a model to
support the automatic identification of violations of the value of honesty from
app reviews from an end-user perspective. Beyond the automatic detection of
honesty violations by apps, we also aim to better understand different
categories of honesty violations expressed by users in their app reviews. The
result of our manual analysis of our honesty violations dataset shows that
honesty violations can be characterised into ten categories: unfair
cancellation and refund policies; false advertisements; delusive subscriptions;
cheating systems; inaccurate information; unfair fees; no service; deletion of
reviews; impersonation; and fraudulent-looking apps. Based on these results, we
argue for a conscious effort in developing more honest software artefacts
including mobile apps, and the promotion of honesty as a key value in software
development practices. Furthermore, we discuss the role of app distribution
platforms as enforcers of ethical systems supporting human values, and
highlight some proposed next steps for human values in software engineering
(SE) research.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 23:15:02 GMT""}]","2022-03-16"
"2203.07548","Sebastian Risi","Kathryn Walker, Rasmus Berg Palm, Rodrigo Moreno Garcia, Andres Faina,
  Kasper Stoy, Sebastian Risi","Physical Neural Cellular Automata for 2D Shape Classification",,,,,"cs.RO cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Materials with the ability to self-classify their own shape have the
potential to advance a wide range of engineering applications and industries.
Biological systems possess the ability not only to self-reconfigure but also to
self-classify themselves to determine a general shape and function. Previous
work into modular robotics systems has only enabled self-recognition and
self-reconfiguration into a specific target shape, missing the inherent
robustness present in nature to self-classify. In this paper we therefore take
advantage of recent advances in deep learning and neural cellular automata, and
present a simple modular 2D robotic system that can infer its own class of
shape through the local communication of its components. Furthermore, we show
that our system can be successfully transferred to hardware which thus opens
opportunities for future self-classifying machines. Code available at
https://github.com/kattwalker/projectcube. Video available at
https://youtu.be/0TCOkE4keyc.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 23:18:13 GMT""},{""version"":""v2"",""created"":""Sun, 31 Jul 2022 20:27:30 GMT""}]","2022-08-02"
"2203.07549","Mohammadali Mohammadi","Mohammadali Mohammadi and Hien Quoc Ngo and Michail Matthaiou","Cell-Free Massive MIMO with OTFS Modulation: Power Control and Resource
  Allocation","Accepted in ICC 2022 Workshop on OTFS and Delay-Doppler Signal
  Processing for 6G and Future High-mobility Communications. arXiv admin note:
  text overlap with arXiv:2112.10869",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  We consider the downlink of cell-free massive multiple-input multiple-output
(MIMO) systems with orthogonal time frequency space (OTFS) modulation. Two
pilot-based channel estimation schemes, namely superimposed pilot-based
(SP-CHE) and embedded pilot-based channel estimation (EP-CHE), are applied to
estimate the channels at the access points (APs). The SP-CHE scheme
superimposes low power pilots onto the data symbols in the delay-Doppler domain
to avoid the spectral efficiency (SE) loss due to null guard intervals used in
the EP-CHE scheme. In the case of SP-CHE scheme, we consider a max-min fairness
optimization problem to jointly optimize the peruser pilot/data power
allocation coefficients and per-AP power control coefficients. The complicated
non-convex problem is then iteratively solved through two decoupled
sub-problems. Moreover, a max-min fairness problem is cast for the EP-CHE
scheme, where the optimization variables are the per-AP power control
coefficients. Numerical results show that the proposed resource allocation
approaches provide at most 42 and 5-fold increase in the 95%-likely per-user SE
for the SP-CHE and EP-CHE scheme, respectively, compared with the uniform power
control and in correlated shadowing fading channels.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 23:21:53 GMT""}]","2022-09-28"
"2203.07550","Igor Halperin","Igor Halperin","Phases of MANES: Multi-Asset Non-Equilibrium Skew Model of a Strongly
  Non-Linear Market with Phase Transitions","38 pages, 11 figures",,,,"q-fin.CP nlin.AO physics.data-an q-fin.GN q-fin.ST","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents an analytically tractable and practically-oriented model
of non-linear dynamics of a multi-asset market in the limit of a large number
of assets. The asset price dynamics are driven by money flows into the market
from external investors, and their price impact. This leads to a model of a
market as an ensemble of interacting non-linear oscillators with the Langevin
dynamics. In a homogeneous portfolio approximation, the mean field treatment of
the resulting Langevin dynamics produces the McKean-Vlasov equation as a
dynamic equation for market returns. Due to the strong non-linearity of the
McKean-Vlasov equation, the resulting dynamics give rise to ergodicity breaking
and first- or second-order phase transitions under variations of model
parameters. Using a tractable potential of the Non-Equilibrium Skew (NES) model
previously suggested by the author for a single-stock case, the new Multi-Asset
NES (MANES) model enables an analytically tractable framework for a multi-asset
market. The equilibrium expected market log-return is obtained as a
self-consistent mean field of the McKean-Vlasov equation, and derived in closed
form in terms of parameters that are inferred from market prices of S&P 500
index options. The model is able to accurately fit the market data for either a
benign or distressed market environments, while using only a single volatility
parameter.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 23:25:53 GMT""}]","2022-03-16"
"2203.07551","Fumitake Kametani","F. Kametani, C. Tarantini, E. Hellstrom","Fe-based high field superconductors for cost-effective future
  accelerator magnets","Contribution to Snowmass 2021 AF07",,,,"cond-mat.supr-con cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  We propose a targeted attack on making the Fe-based superconductor (FBS)
AEFe2As2 (122) (AE = alkaline earth, here Ba or Sr) into a much cheaper, higher
stability margin, round, twisted and effectively isotropic multifilament
conductor suitable for 16-20 T dipole magnet construction. This white paper
urges to greatly accelerate progress by providing a fundamental understanding
of what controls the transport critical current density, Jc, of 122
polycrystals and then in the wire forms. High grain-to-grain Jc is the one key
property not yet fully demonstrated in this new superconductor and this is the
key breakthrough that would make 122 practical. Whereas the intragrain (i.e.
vortex pinning) Jc is already high enough to replace Nb3Sn, our recent work
strongly suggests that unpredictable superconducting connectivity at grain
boundaries (GBs) is the critical problem that limits the long-range Jc. We
strongly emphasize the need to evaluate the true intrinsic nature of GBs in the
polycrystalline forms before focusing on the wire fabrication.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 23:28:21 GMT""},{""version"":""v2"",""created"":""Fri, 18 Mar 2022 15:16:38 GMT""},{""version"":""v3"",""created"":""Tue, 22 Mar 2022 16:02:49 GMT""}]","2022-03-23"
"2203.07552","Michelle Mastrianni","Damir Ferizovi\'c, Julian Hofstadler, Michelle Mastrianni","The Spherical Cap Discrepancy of HEALPix Points",,,,,"math.NA cs.NA math.CA","http://creativecommons.org/licenses/by/4.0/","  In this paper we show that the spherical cap discrepancy of the point set
given by centers of pixels in the HEALPix tessellation (short for Hierarchical,
Equal Area and iso-Latitude Pixelation) of unit $2$-sphere is lower and upper
bounded by order square root of the number of points, and compute explicit
constants. This adds to the known collection of explicitly constructed sets
whose discrepancy converges with order $N^{-1/2}$, matching the asymptotic
order for i.i.d. random point sets. We describe the HEALPix framework in more
detail and give explicit formulas for the boundaries and pixel centers. We then
introduce the notion of an $n$-convex curve and prove an upper bound on how
many fundamental domains are intersected by such curves, and in particular we
show that boundaries of spherical caps have this property. Lastly, we mention
briefly that a jittered sampling technique works in the HEALPix framework as
well.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 23:29:09 GMT""}]","2022-03-16"
"2203.07553","Jisan Mahmud","Jisan Mahmud, Jan-Michael Frahm","VPFusion: Joint 3D Volume and Pixel-Aligned Feature Fusion for Single
  and Multi-view 3D Reconstruction",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a unified single and multi-view neural implicit 3D
reconstruction framework VPFusion. VPFusion attains high-quality reconstruction
using both - 3D feature volume to capture 3D-structure-aware context, and
pixel-aligned image features to capture fine local detail. Existing approaches
use RNN, feature pooling, or attention computed independently in each view for
multi-view fusion. RNNs suffer from long-term memory loss and permutation
variance, while feature pooling or independently computed attention leads to
representation in each view being unaware of other views before the final
pooling step. In contrast, we show improved multi-view feature fusion by
establishing transformer-based pairwise view association. In particular, we
propose a novel interleaved 3D reasoning and pairwise view association
architecture for feature volume fusion across different views. Using this
structure-aware and multi-view-aware feature volume, we show improved 3D
reconstruction performance compared to existing methods. VPFusion improves the
reconstruction quality further by also incorporating pixel-aligned local image
features to capture fine detail. We verify the effectiveness of VPFusion on the
ShapeNet and ModelNet datasets, where we outperform or perform on-par the
state-of-the-art single and multi-view 3D shape reconstruction methods.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 23:30:58 GMT""},{""version"":""v2"",""created"":""Sat, 16 Jul 2022 21:46:06 GMT""}]","2022-07-19"
"2203.07554","Carlos Mastalli","Carlos Mastalli, Wolfgang Merkt, Guiyang Xin, Jaehyun Shim, Michael
  Mistry, Ioannis Havoutis, Sethu Vijayakumar","Agile Maneuvers in Legged Robots: a Predictive Control Approach","20 pages, 16 figures",,,,"cs.RO cs.AI cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Planning and execution of agile locomotion maneuvers have been a longstanding
challenge in legged robotics. It requires to derive motion plans and local
feedback policies in real-time to handle the nonholonomy of the kinetic
momenta. To achieve so, we propose a hybrid predictive controller that
considers the robot's actuation limits and full-body dynamics. It combines the
feedback policies with tactile information to locally predict future actions.
It converges within a few milliseconds thanks to a feasibility-driven approach.
Our predictive controller enables ANYmal robots to generate agile maneuvers in
realistic scenarios. A crucial element is to track the local feedback policies
as, in contrast to whole-body control, they achieve the desired angular
momentum. To the best of our knowledge, our predictive controller is the first
to handle actuation limits, generate agile locomotion maneuvers, and execute
optimal feedback policies for low level torque control without the use of a
separate whole-body controller.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 23:32:17 GMT""},{""version"":""v2"",""created"":""Mon, 18 Jul 2022 13:19:03 GMT""}]","2022-07-19"
"2203.07555","Saber Jafarpour","Saber Jafarpour and Samuel Coogan","Resilience of Input Metering in Dynamic Flow Networks",,,,,"math.OC cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study robustness of input metering policies in dynamic flow
networks in the presence of transient disturbances and attacks. We consider a
compartmental model for dynamic flow networks with a First-In-First-Out (FIFO)
routing rule as found in, e.g., transportation networks. We model the effect of
the transient disturbance as an abrupt change to the state of the network and
use the notion of the region of attraction to measure the resilience of the
network to these changes. For constant and periodic input metering, we
introduce the notion of monotone-invariant points to establish inner-estimates
for the regions of attraction of free-flow equilibrium points and free-flow
periodic orbits using monotone systems theory. These results are applicable to,
e.g., networks with cycles, which have not been considered in prior literature
on dynamic flow networks with FIFO routing. Finally, we propose two approaches
for finding suitable monotone-invariant points in the flow networks with FIFO
rules.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 23:32:50 GMT""}]","2022-03-16"
"2203.07556","Justin Albert","Justin E. Albert, Dmitry Budker, H. R. Sadeghpour","From atomic physics, to upper-atmospheric chemistry, to cosmology: A
  ""laser photometric ratio star"" to calibrate telescopes at major observatories","Brief ""Research Highlight"" and cover article for Natural Sciences
  journal volume 2, issue 2 (Feb. 2022). 3 pages, 2 figures","Nat. Sci. 2, e20220003 (2022)","10.1002/ntls.20220003",,"astro-ph.IM astro-ph.CO physics.atom-ph physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The expansion of our Universe is accelerating, due to dark energy. But the
nature of dark energy has been a mystery since its discovery at the end of the
past century. In Research Highlight https://doi.org/10.1002/ntls.20220003 ,
Justin Albert, Dmitry Budker and Hossein Sadeghpour provide an overview of how
a laser photometric ratio star (a novel light source generated by laser
excitation of the Earth's upper-atmospheric sodium layer, which will radiate
equally brightly at wavelengths of 589 nm and 820 nm) can help us precisely
calibrate telescopes in order to understand the nature of dark energy.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 23:38:10 GMT""}]","2022-03-16"
"2203.07557","Samson Zhou","Raphael A. Meyer, Cameron Musco, Christopher Musco, David P. Woodruff,
  Samson Zhou","Fast Regression for Structured Inputs",,,,,"cs.DS","http://creativecommons.org/licenses/by/4.0/","  We study the $\ell_p$ regression problem, which requires finding
$\mathbf{x}\in\mathbb R^{d}$ that minimizes
$\|\mathbf{A}\mathbf{x}-\mathbf{b}\|_p$ for a matrix $\mathbf{A}\in\mathbb R^{n
\times d}$ and response vector $\mathbf{b}\in\mathbb R^{n}$. There has been
recent interest in developing subsampling methods for this problem that can
outperform standard techniques when $n$ is very large. However, all known
subsampling approaches have run time that depends exponentially on $p$,
typically, $d^{\mathcal{O}(p)}$, which can be prohibitively expensive. We
improve on this work by showing that for a large class of common
\emph{structured matrices}, such as combinations of low-rank matrices, sparse
matrices, and Vandermonde matrices, there are subsampling based methods for
$\ell_p$ regression that depend polynomially on $p$. For example, we give an
algorithm for $\ell_p$ regression on Vandermonde matrices that runs in time
$\mathcal{O}(n\log^3 n+(dp^2)^{0.5+\omega}\cdot\text{polylog}\,n)$, where
$\omega$ is the exponent of matrix multiplication. The polynomial dependence on
$p$ crucially allows our algorithms to extend naturally to efficient algorithms
for $\ell_\infty$ regression, via approximation of $\ell_\infty$ by
$\ell_{\mathcal{O}(\log n)}$. Of practical interest, we also develop a new
subsampling algorithm for $\ell_p$ regression for arbitrary matrices, which is
simpler than previous approaches for $p \ge 4$.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 23:42:06 GMT""}]","2022-03-16"
"2203.07558","Abhishek Paudel","Abhishek Paudel","Learning for Robot Decision Making under Distribution Shift: A Survey","10 pages, 2 figures",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the recent advances in the field of deep learning, learning-based
methods are widely being implemented in various robotic systems that help
robots understand their environment and make informed decisions to achieve a
wide variety of tasks or goals. However, learning-based methods have repeatedly
been shown to have poor generalization when they are presented with inputs that
are different from those during training leading to the problem of distribution
shift. Any robotic system that employs learning-based methods is prone to
distribution shift which might lead the agents to make decisions that lead to
degraded performance or even catastrophic failure. In this paper, we discuss
various techniques that have been proposed in the literature to aid or improve
decision making under distribution shift for robotic systems. We present a
taxonomy of existing literature and present a survey of existing approaches in
the area based on this taxonomy. Finally, we also identify a few open problems
in the area that could serve as future directions for research.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 23:43:28 GMT""}]","2022-03-16"
"2203.07559","Seo Yeon Park","Seo Yeon Park and Cornelia Caragea","On the Calibration of Pre-trained Language Models using Mixup Guided by
  Area Under the Margin and Saliency","Accepted at ACL 2022 main conference",,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A well-calibrated neural model produces confidence (probability outputs)
closely approximated by the expected accuracy. While prior studies have shown
that mixup training as a data augmentation technique can improve model
calibration on image classification tasks, little is known about using mixup
for model calibration on natural language understanding (NLU) tasks. In this
paper, we explore mixup for model calibration on several NLU tasks and propose
a novel mixup strategy for pre-trained language models that improves model
calibration further. Our proposed mixup is guided by both the Area Under the
Margin (AUM) statistic (Pleiss et al., 2020) and the saliency map of each
sample (Simonyan et al.,2013). Moreover, we combine our mixup strategy with
model miscalibration correction techniques (i.e., label smoothing and
temperature scaling) and provide detailed analyses of their impact on our
proposed mixup. We focus on systematically designing experiments on three NLU
tasks: natural language inference, paraphrase detection, and commonsense
reasoning. Our method achieves the lowest expected calibration error compared
to strong baselines on both in-domain and out-of-domain test samples while
maintaining competitive accuracy.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 23:45:08 GMT""}]","2022-03-16"
"2203.07560","Pratyush Tiwary","E. R. Beyerle, Shams Mehdi and Pratyush Tiwary","Quantifying Energetic and Entropic Pathways in Molecular Systems",,,,,"physics.chem-ph physics.bio-ph physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  When examining dynamics occurring at non-zero temperatures, both energy and
entropy must be taken into account while describing activated barrier crossing
events. Furthermore, good reaction coordinates need to be constructed to
describe different metastable states and the transition mechanisms between
them. Here we use a physics-based machine learning method called the State
Predictive Information Bottleneck (SPIB) to find non-linear reaction
coordinates for three systems of varying complexity. The SPIB is able to
predict correctly an entropic bottleneck for an analytical flat-energy
double-well system and identify the entropy- and energy-dominated pathways for
an analytical four-well system. Finally, for a simulation of benzoic acid
permeation through a lipid bilayer, SPIB is able to discover the entropic and
energetic barriers to the permeation process. Given these results, we thus
establish that SPIB is a reasonable and robust method for finding the important
entropy and energy/enthalpy barriers in physical systems, which can then be
used for enhanced understanding and sampling of different activated mechanisms.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 23:47:37 GMT""}]","2022-03-16"
"2203.07561","Luke Koch","Luke Koch, Sean Oesch, Mary Adkisson, Sam Erwin, Brian Weber, Amul
  Chaulagain","Toward the Detection of Polyglot Files",,,,,"cs.CR cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Standardized file formats play a key role in the development and use of
computer software. However, it is possible to abuse standardized file formats
by creating a file that is valid in multiple file formats. The resulting
polyglot (many languages) file can confound file format identification,
allowing elements of the file to evade analysis.This is especially problematic
for malware detection systems that rely on file format identification for
feature extraction. File format identification processes that depend on file
signatures can be easily evaded thanks to flexibility in the format
specifications of certain file formats. Although work has been done to identify
file formats using more comprehensive methods than file signatures, accurate
identification of polyglot files remains an open problem. Since malware
detection systems routinely perform file format-specific feature extraction,
polyglot files need to be filtered out prior to ingestion by these systems.
Otherwise, malicious content could pass through undetected. To address the
problem of polyglot detection we assembled a data set using the mitra tool. We
then evaluated the performance of the most commonly used file identification
tool, file. Finally, we demonstrated the accuracy, precision, recall and F1
score of a range of machine and deep learning models. Malconv2 and Catboost
demonstrated the highest recall on our data set with 95.16% and 95.45%,
respectively. These models can be incorporated into a malware detector's file
processing pipeline to filter out potentially malicious polyglots before file
format-dependent feature extraction takes place.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 23:48:22 GMT""},{""version"":""v2"",""created"":""Wed, 16 Mar 2022 19:29:39 GMT""},{""version"":""v3"",""created"":""Wed, 23 Mar 2022 20:52:30 GMT""},{""version"":""v4"",""created"":""Wed, 13 Apr 2022 02:54:22 GMT""}]","2022-04-14"
"2203.07562","Macheng Shen","Macheng Shen and Jonathan P. How","Safe adaptation in multiagent competition",,,,,"cs.LG cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Achieving the capability of adapting to ever-changing environments is a
critical step towards building fully autonomous robots that operate safely in
complicated scenarios. In multiagent competitive scenarios, agents may have to
adapt to new opponents with previously unseen behaviors by learning from the
interaction experiences between the ego-agent and the opponent. However, this
adaptation is susceptible to opponent exploitation. As the ego-agent updates
its own behavior to exploit the opponent, its own behavior could become more
exploitable as a result of overfitting to this specific opponent's behavior. To
overcome this difficulty, we developed a safe adaptation approach in which the
ego-agent is trained against a regularized opponent model, which effectively
avoids overfitting and consequently improves the robustness of the ego-agent's
policy. We evaluated our approach in the Mujoco domain with two competing
agents. The experiment results suggest that our approach effectively achieves
both adaptation to the specific opponent that the ego-agent is interacting with
and maintaining low exploitability to other possible opponent exploitation.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 23:53:59 GMT""}]","2022-03-16"
"2203.07563","Michael J. Longo","Michael J. Longo","Neutron size from high energy scattering data","Submitted to Physical. Rev. Comments",,,,"hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  Alvarado, Aranda, and Bonilla propose a sub-GeV U(1)R gauge boson model to
explain the proton charge radius discrepancy. Their model assumes opposite sign
U(1)R charge assignments for up and down quarks in the nucleon. I point out
that might cause a difference between neutron and proton mass radii that
contradicts existing p-p and n-p scattering data. Using existing neutron and
proton scattering data I show that the neutron and proton mass radii are equal
within about 2%. This constitutes a challenge to models that attempt to explain
the discrepancy by modifying the quark couplings.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 00:08:57 GMT""}]","2022-03-16"
"2203.07564","Jake Bennett","J. V. Bennett, J. Guilliams, M. Hernandez Villanueva, D. E. Jaffe, P.
  J. Laycock, A. Panta, C. Serfon, I. Ueda","Belle II grid-based user analysis","contribution to Snowmass 2021",,,,"hep-ex","http://creativecommons.org/licenses/by/4.0/","  The Belle II experiment at the SuperKEKB accelerator is a next-generation
B-factory aiming to collect 50 ab$^{-1}$, about 50 times the data collected at
Belle, to study rare processes and make precision measurements that may expose
physics beyond the Standard Model. Corresponding to roughly 100 PB of storage
for raw data, plus dozens of PBs per year for Monte Carlo (MC) and analysis
data, these massive samples require careful planning for the storage,
processing, and analysis of data. This white paper notes some of the challenges
that await grid-based user-analysis at the intensity frontier and invites
further discussion and exploration to improve the tools and techniques
necessary to leverage the massive data samples that will be available at Belle
II as part of the Snowmass process.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 00:09:33 GMT""}]","2022-03-16"
"2203.07565","Christian Glusa","Christian Glusa, Marta D'Elia, Giacomo Capodaglio, Max Gunzburger,
  Pavel B. Bochev","An asymptotically compatible coupling formulation for nonlocal interface
  problems with jumps",,,,"SAND2022-2944 O","math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a mathematically rigorous formulation for a nonlocal interface
problem with jumps and propose an asymptotically compatible finite element
discretization for the weak form of the interface problem. After proving the
well-posedness of the weak form, we demonstrate that solutions to the nonlocal
interface problem converge to the corresponding local counterpart when the
nonlocal data are appropriately prescribed. Several numerical tests in one and
two dimensions show the applicability of our technique, its numerical
convergence to exact nonlocal solutions, its convergence to the local limit
when the horizons vanish, and its robustness with respect to the patch test.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 00:10:08 GMT""}]","2022-03-16"
"2203.07566","Mitchell Black","Mitchell Black, Nello Blaser, Amir Nayyeri, and Erlend Raa V{\aa}gset","ETH-tight algorithms for finding surfaces in simplicial complexes of
  bounded treewidth","This paper contains some material that previously appeared at
  arXiv:2107.10339. The split into two papers reflects new material and a
  change in authorship in this version. Accepted to SoCG 2022",,,,"cs.CG","http://creativecommons.org/licenses/by/4.0/","  Given a simplicial complex with $n$ simplices, we consider the Connected
Subsurface Recognition (c-SR) problem of finding a subcomplex that is
homeomorphic to a given connected surface with a fixed boundary. We also study
the related Sum-of-Genus Subsurface Recognition (SoG) problem, where we instead
search for a surface whose boundary, number of connected components, and total
genus are given.
  For both of these problems, we give parameterized algorithms with respect to
the treewidth $k$ of the Hasse diagram that run in $2^{O(k \log k)}n^{O(1)}$
time. For the SoG problem, we also prove that our algorithm is optimal assuming
the exponential-time hypothesis. In fact, we prove the stronger result that our
algorithm is ETH-tight even without restriction on the total genus.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 00:12:18 GMT""}]","2022-03-16"
"2203.07567","Justin Chan","Justin Chan, Ananditha Raghunath, Kelly E. Michaelsen, and Shyamnath
  Gollakota","Testing a Drop of Liquid Using Smartphone LiDAR","27 pages, 15 figures, accepted at IMWUT",,,,"cs.CY physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the first system to determine fluid properties using the LiDAR
sensors present on modern smartphones. Traditional methods of measuring
properties like viscosity require expensive laboratory equipment or a
relatively large amount of fluid. In contrast, our smartphone-based method is
accessible, contactless and works with just a single drop of liquid. Our design
works by targeting a coherent LiDAR beam from the phone onto the liquid. Using
the phone's camera, we capture the characteristic laser speckle pattern that is
formed by the interference of light reflecting from light-scattering particles.
By correlating the fluctuations in speckle intensity over time, we can
characterize the Brownian motion within the liquid which is correlated with its
viscosity. The speckle pattern can be captured on a range of phone cameras and
does not require external magnifiers. Our results show that we can distinguish
between different fat contents as well as identify adulterated milk. Further,
algorithms can classify between ten different liquids using the smartphone
LiDAR speckle patterns. Finally, we conducted a clinical study with whole blood
samples across 30 patients showing that our approach can distinguish between
coagulated and uncoagulated blood using a single drop of blood.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 00:12:39 GMT""}]","2022-03-16"
"2203.07568","Huanyin Chen","Huanyin Chen, Marjan Sheibani","The g-Drazin invertibility in a Banach algebra",,,,,"math.RA","http://creativecommons.org/licenses/by/4.0/","  We present necessary and sufficient conditions under which the
anti-triangular matrix $\left(
  \begin{array}{cc}
  a&b
  1&0
  \end{array} \right)$ over a Banach algebra has g-Drazin inverse. New additive
results for g-Drazin inverse are obtained. Then we apply our results to
$2\times 2$ operator matrices and generalize many known results,
e.g.,~\cite[Theorem 2.2]{D}, ~\cite[Theorem 2.1]{YL} and \cite[Theorem 4.1]{Y}.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 00:26:01 GMT""}]","2022-03-16"
"2203.07569","Frank Porter","K. Byrum, S. Corrodi, Y. Oksuzian, P. Winter, L. Xia, A. W. J.
  Edmonds, J. P. Miller, J. Mott, W. J. Marciano, R. Szafron, R. Bonventre, D.
  N. Brown, Yu. G. Kolomensky, O. Ning, V. Singh, E. Prebys, L. Borrel, B.
  Echenard, D. G. Hitlin, C. Hu, D. X. Lin, S. Middleton, F. C. Porter, L.
  Zhang, R.-Y. Zhu, D. Ambrose, K. Badgley, R. H. Bernstein, S. Boi, B. C. K.
  Casey, R. Culbertson, A. Gaponenko, H. D. Glass, D. Glenzinski, L.
  Goodenough, A. Hocker, M. Kargiantoulakis, V. Kashikhin, B. Kiburg, R. K.
  Kutschke, P. A. Murat, D. Neuffer, V. S. Pronskikh, D. Pushka, G. Rakness, T.
  Strauss, M. Yucel, C. Bloise, E. Diociaiuti, S. Giovannella, F. Happacher, S.
  Miscetti, I. Sarra, M. Martini, A. Ferrari, S. E. M\""uller, R. Rachamin, E.
  Barlas-Yucel, A. Artikov, N. Atanov, Yu. I. Davydov, V. Glagolev, I. I.
  Vasilyev, D. N. Brown, Y. Uesaka, S. P. Denisov, V. Evdokimov, A. V. Kozelov,
  A. V. Popov, I. A. Vasilyev, G. Tassielli, T. Teubner, R. T. Chislett, G. G.
  Hesketh, M. Lancaster, M. Campbell, K. Ciampa, K. Heller, B. Messerly, M. A.
  C. Cummings, L. Calibbi, G. C. Blazey, M. J. Syphers, V. Zutshi, C. Kampa, M.
  MacKenzie, S. Di Falco, S. Donati, A. Gioiosa, V. Giusti, L. Morescalchi, D.
  Pasciuto, E. Pedreschi, F. Spinella, M. T. Hedges, M. Jones, Z. Y. You, A. M.
  Zanetti, E. V. Valetov, E. C. Dukes, R. Ehrlich, R. C. Group, J. Heeck, P. Q.
  Hung, S. M. Demers, G. Pezzullo, K. R. Lynch and J. L. Popp","Mu2e-II: Muon to electron conversion with PIP-II","Contribution to Snowmass 2021 46 pages 43 figures 7 tables",,,"20220310: [CONF-22-123]","hep-ex","http://creativecommons.org/licenses/by/4.0/","  An observation of Charged Lepton Flavor Violation (CLFV) would be unambiguous
evidence for physics beyond the Standard Model. The Mu2e and COMET experiments,
under construction, are designed to push the sensitivity to CLFV in the mu to e
conversion process to unprecedented levels. Whether conversion is observed or
not, there is a strong case to be made for further improving sensitivity, or
for examining the process on additional target materials. Mu2e-II is a proposed
upgrade to Mu2e, with at least an additional order of magnitude in sensitivity
to the conversion rate over Mu2e. The approach and challenges for this proposal
are summarized. Mu2e-II may be regarded as the next logical step in a continued
high-intensity muon program at FNAL.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 00:31:55 GMT""},{""version"":""v2"",""created"":""Wed, 16 Mar 2022 17:44:28 GMT""}]","2022-03-17"
"2203.07570","Weimin Yi","Weimin Yi, W. N. Brandt, Q. Ni, Luis C. Ho, Bin Luo, Wei Yan, D. P.
  Schneider, Jeremiah D.Paul, Richard M. Plotkin, Jinyi Yang, Feige Wang,
  Zhicheng He, Chen Chen, Xue-Bing Wu, Jin-Ming Bai","A quasar shedding its dust cocoon at redshift 2","11 pages, 6 figures, accepted for publication in ApJ",,"10.3847/1538-4357/ac6109",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We present the first near-IR spectroscopy and joint analyses of
multi-wavelength observations for SDSS J082747.14+425241.1, a dust-reddened,
weak broad emission-line quasar (WLQ) undergoing a remarkable broad absorption
line (BAL) transformation. The systemic redshift is more precisely measured to
be $z=2.070\pm0.001$ using H$\beta$ compared to $z=2.040\pm0.003$ using \mgii\
from the literature, signifying an extreme \mgii\ blueshift of $2140\pm530$
\kms\ relative to H$\beta$. Using the H$\beta$-based single-epoch scaling
relation with a systematic uncertainty of 0.3 dex, its black hole (BH) mass and
Eddington ratio are estimated to be $M_{\rm BH}\sim6.1\times10^8M_\odot$ and
$\lambda_{\rm Edd}\sim0.71$, indicative of being in a rapidly accreting phase.
Our investigations confirm the WLQ nature and the LoBAL$\rightarrow$HiBAL
transformation, along with a factor of 2 increase in the \mgii+\feii\ emission
strength and a decrease of 0.1 in $E(B-V)$ over two decades. The kinetic power
of this LoBAL wind at $R\sim$15 pc from its BH is estimated to be $\sim$43\% of
the Eddington luminosity, sufficient for quasar feedback upon its host galaxy
albeit with an order-of-magnitude uncertainty. This quasar provides a clear
example of the long-sought scenario where LoBAL quasars are surrounded by dust
cocoons, and wide-angle nuclear winds play a key role in the transition for red
quasars evolving into the commonly seen blue quasars.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 00:42:40 GMT""}]","2022-05-11"
"2203.07571","Antonino Paolo Milone","M. V. Legnardi, A. P. Milone, L. Armillotta, A. F. Marino, G. Cordoni,
  A. Renzini, E. Vesperini, F. D'Antona, M. McKenzie, D. Yong, E. Dondoglio, E.
  P. Lagioia, M. Carlos, M. Tailo, S. Jang, A. Mohandasan","Constraining the original composition of the gas forming
  first-generation stars in globular clusters","18 pages, 13 figures, accepted for publication in MNRAS",,"10.1093/mnras/stac734",,"astro-ph.GA astro-ph.SR","http://creativecommons.org/publicdomain/zero/1.0/","  Disentangling distinct stellar populations along the red-giant branches
(RGBs) of Globular Clusters (GCs) is possible by using the pseudo two-color
diagram dubbed chromosome map (ChM). One of the most intriguing findings is
that the so-called first-generation (1G) stars, characterized by the same
chemical composition of their natal cloud, exhibit extended sequences in the
ChM. Unresolved binaries and internal variations in helium or metallicity have
been suggested to explain this phenomenon. Here, we derive high-precision
Hubble Space Telescope photometry of the GCs NGC6362 and NGC6838 and build
their ChMs. We find that both 1G RGB and main-sequence (MS) stars exhibit wider
ChM sequences than those of second-generation (2G). The evidence of this
feature even among unevolved 1G MS stars indicates that chemical
inhomogeneities are imprinted in the original gas. We introduce a pseudo
two-magnitude diagram to distinguish between helium and metallicity, and
demonstrate that star-to-star metallicity variations are responsible for the
extended 1G sequence. Conversely, binaries provide a minor contribution to the
phenomenon. We estimate that the metallicity variations within 1G stars of 55
GCs range from less than [Fe/H]~0.05 to ~0.30 and mildly correlate with cluster
mass. We exploit these findings to constrain the formation scenarios of
multiple populations showing that they are qualitatively consistent with the
occurrence of multiple generations. In contrast, the fact that 2G stars have
more homogeneous iron content than the 1G challenges the scenarios based on
accretion of material processed in massive 1G stars onto existing protostars.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 00:46:10 GMT""}]","2022-04-06"
"2203.07572","Joel Ullom","Joel Ullom, Daniel Schmidt, Simon Bandler, Thomas Stevenson, Mark
  Croce, Katrina Koehler, Matteo De Gerone, Loredana Gastaldo, Christian Enss,
  Geonbo Kim, Angelo Nucciotti, Stefano Ragazzi, Kyle Leach, Diana Parno, Brian
  Mong, Josef Frisch, Christopher Kenney","Measuring the electron neutrino mass using the electron capture decay of
  163Ho","contribution to Snowmass 2021",,,,"nucl-ex hep-ph physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  While the mass differences between neutrino mass states are known, their
absolute masses and mass hierarchy have not yet been determined. Determining
the mass of neutrinos provides access to physics beyond the Standard Model and
the resulting value has implications for the growth of large-scale structure in
the universe over cosmic history. Because of the importance of the topic, a
number of efforts are already underway to determine the mass of neutrinos
including direct kinematic measurements and indirect measurements of
astrophysical phenomena that constrain the sum of the mass eigenstates through
models of cosmic evolution. Here, we advocate for a collaborative international
effort to perform a kinematic determination of the effective electron neutrino
mass using calorimetric measurements of the decay of 163Ho. This effort is
justified by the success of current experiments using the technique, its high
benefit-to-cost ratio, the value of approaches with different systematic
errors, and the value of measuring the electron neutrino mass rather than the
electron anti-neutrino mass.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 00:46:14 GMT""}]","2022-03-16"
"2203.07573","Olga Movilla Miangolarra","Olga Movilla Miangolarra, Amirhossein Taghvaei, Yongxin Chen, Tryphon
  T. Georgiou","Thermodynamic engine powered by anisotropic fluctuations","6 pages, 6 figures, 1 table",,,,"cond-mat.stat-mech cs.SY eess.SY math-ph math.MP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The purpose of this work is to present the concept of an autonomous
Stirling-like engine powered by anisotropy of thermodynamic fluctuations.
Specifically, simultaneous contact of a thermodynamic system with two heat
baths along coupled degrees of freedom generates torque and circulatory
currents -- an arrangement referred to as a Brownian gyrator. The embodiment
that constitutes the engine includes an inertial wheel to sustain rotary motion
and average out the generated fluctuating torque, ultimately delivering power
to an external load. We detail an electrical model for such an engine that
consists of two resistors in different temperatures and three reactive elements
in the form of variable capacitors. The resistors generate Johnson-Nyquist
current fluctuations that power the engine, while the capacitors generate
driving forces via a coupling of their dielectric material with the inertial
wheel. A proof-of-concept is established via stability analysis to ensure the
existence of a stable periodic orbit generating sustained power output. We
conclude by drawing a connection to the dynamics of a damped pendulum with
constant torque and to those of a macroscopic Stirling engine. The sought
insights aim at nano-engines and biological processes that are similarly
powered by anisotropy in temperature and chemical potentials.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 00:46:34 GMT""},{""version"":""v2"",""created"":""Wed, 23 Mar 2022 15:50:06 GMT""}]","2022-03-24"
"2203.07574","Yuya Ohmichi","Yuya Ohmichi, Kohmi Takahashi, Kazuyuki Nakakita","Time-series image denoising of pressure-sensitive paint data by
  projected multivariate singular spectrum analysis",,"Experiments in Fluids 63, 181 (2022)","10.1007/s00348-022-03523-5",,"eess.IV cs.LG physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  Time-series data, such as unsteady pressure-sensitive paint (PSP) measurement
data, may contain a significant amount of random noise. Thus, in this study, we
investigated a noise-reduction method that combines multivariate singular
spectrum analysis (MSSA) with low-dimensional data representation. MSSA is a
state-space reconstruction technique that utilizes time-delay embedding, and
the low-dimensional representation is achieved by projecting data onto the
singular value decomposition (SVD) basis. The noise-reduction performance of
the proposed method for unsteady PSP data, i.e., the projected MSSA, is
compared with that of the truncated SVD method, one of the most employed
noise-reduction methods. The result shows that the projected MSSA exhibits
better performance in reducing random noise than the truncated SVD method.
Additionally, in contrast to that of the truncated SVD method, the performance
of the projected MSSA is less sensitive to the truncation rank. Furthermore,
the projected MSSA achieves denoising effectively by extracting smooth
trajectories in a state space from noisy input data. Expectedly, the projected
MSSA will be effective for reducing random noise in not only PSP measurement
data, but also various high-dimensional time-series data.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 00:49:15 GMT""},{""version"":""v2"",""created"":""Tue, 7 Jun 2022 08:58:06 GMT""},{""version"":""v3"",""created"":""Wed, 20 Jul 2022 09:23:36 GMT""},{""version"":""v4"",""created"":""Fri, 11 Nov 2022 04:51:06 GMT""}]","2022-11-14"
"2203.07575","Jungseek Hwang","Myounghoon Lee, Dongjoon Song, Yu-Seong Seo, Seulki Roh, Seokbae Lee,
  Hirosh Eisaki, and Jungseek Hwang","Electron-hole symmetry in quasiparticle spectral weight of cuprates
  observed via infrared and photoemission spectroscopy","17 pages, 4 figures",,,,"cond-mat.str-el cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  We performed an optical spectroscopy study on single crystals of
Pr$_{0.85}$LaCe$_{0.15}$CuO$_{4-\delta}$ (PLCCO) to revisit the electron-hole
asymmetry, which has been understood as a fundamental property of cuprates.
Four differently annealed samples - as-grown, reduced, optimally oxygenated,
and over-oxygenated samples - were prepared, which have superconducting
transition temperatures, $T_c$ = 0, 15, 24, and 18 K, respectively. We observed
that low-energy quasiparticle spectral weights of all the PLCCO samples are
significantly small in comparison with those of other electron-doped cuprate
families. Instead, they are rather close to those of hole-doped counterpart
La$_{2-x}$Sr$_x$CuO$_4$ (LSCO). Accordingly, estimated effective carrier
numbers per Cu atom ($N_{\mathrm{eff}}$/Cu) of superconducting samples are also
considerably small, despite their relatively high critical temperatures.
Complementary photoemission study reveals that the low-energy quasiparticle
spectral weight of PLCCO is much smaller than that of
Nd$_{1.85}$Ce$_{0.15}$CuO$_{4-\delta}$ (NCCO), consistent with the optical
results. Our observations demonstrate that PLCCO provides the electron-hole
symmetry in quasiparticle spectral weight, and highlight the importance of
Cu3$d$-O2$p$ hybridization to understand the low-energy spectral weight
transfer in doped cuprates.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 00:50:18 GMT""}]","2022-03-16"
"2203.07576","Liang Yu Prof","Liang Yu","Some more results on relativized Chaitin's $\Omega$",,,,,"math.LO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We prove that, assuming $\mathrm{ZF}$, and restricted to any pointed set,
Chaitin's $\Omega_U:x\mapsto
\Omega_U^x=\sum_{U^x(\sigma)\downarrow}2^{-|\sigma|}$ is not injective for any
universal prefix-free Turing machine $U$, and that $\Omega_U^x$ fails to be
degree invariant in a very strong sense, answering several recent questions in
descriptive set theory.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 00:58:04 GMT""}]","2022-03-16"
"2203.07577","Victor Sanches Portella","Laura Greenstreet, Nicholas J. A. Harvey, Victor Sanches Portella","Efficient and Optimal Fixed-Time Regret with Two Experts","29 pages, 13 pages of main text, published in ALT 2022 (PMLR vol.
  167)",,,,"cs.LG math.PR stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Prediction with expert advice is a foundational problem in online learning.
In instances with $T$ rounds and $n$ experts, the classical Multiplicative
Weights Update method suffers at most $\sqrt{(T/2)\ln n}$ regret when $T$ is
known beforehand. Moreover, this is asymptotically optimal when both $T$ and
$n$ grow to infinity. However, when the number of experts $n$ is small/fixed,
algorithms with better regret guarantees exist. Cover showed in 1967 a dynamic
programming algorithm for the two-experts problem restricted to $\{0,1\}$ costs
that suffers at most $\sqrt{T/2\pi} + O(1)$ regret with $O(T^2)$ pre-processing
time. In this work, we propose an optimal algorithm for prediction with two
experts' advice that works even for costs in $[0,1]$ and with $O(1)$ processing
time per turn. Our algorithm builds up on recent work on the experts problem
based on techniques and tools from stochastic calculus.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 01:07:09 GMT""}]","2022-03-16"
"2203.07578","Anton Izosimov","Anton Izosimov and Boris Khesin","Long-diagonal pentagram maps","15 pages, 2 figures; final version accepted to Bulletin of the LMS",,,,"nlin.SI math.MG math.SG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The pentagram map on polygons in the projective plane was introduced by R.
Schwartz in 1992 and is by now one of the most popular and classical discrete
integrable systems. In the present paper we introduce and prove integrability
of long-diagonal pentagram maps on polygons in $\mathbb{R}\mathrm{P}^d$,
encompassing all known integrable cases. We also establish an equivalence of
long-diagonal and bi-diagonal maps and present a simple self-contained
construction of the Lax form for both. Finally, we prove the continuous limit
of all these maps is equivalent to the $ (2,d+1)$-KdV equation, generalizing
the Boussinesq equation for $d=2$.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 01:07:14 GMT""},{""version"":""v2"",""created"":""Wed, 2 Nov 2022 00:04:57 GMT""}]","2022-11-03"
"2203.07579","Aiichi Iwazaki","Aiichi Iwazaki","Radiation Burst by Axion Star Collision with Star in the Andromeda
  Galaxy","7 pages, to be published in Physics Letters B",,"10.1016/j.physletb.2022.137089","Nisho-1-2022","hep-ph","http://creativecommons.org/licenses/by/4.0/","  Axion is a promising candidate of dark matter in the universe. A fraction of
dark matter axion may forms axion star with radius $\sim 10^2$km. We show that
the axion star emits radiation burst by the collision with K and M types main
sequence star in the Andromeda Galaxy. The emission arises in the atmosphere of
the star, in which electrons coherently oscillate due to oscillating electric
field of the axion star. The electric field is produced under magnetic field
$B$ of the star. We estimate the flux density of the radiation $\sim 1.6\times
10^{-3}\mbox{Jy}
(10^{-12}M_{\odot}/M_a)^2(10^{-5}\mbox{eV}/m_a)^3(B/10^2\mbox{G})^2\sqrt{3\times10^3\mbox{K}/T}$
and the rate of the collision per hour $\sim
0.06/\mbox{hour}\,(10^{-12}M_{\odot}/M_a)$ in the galaxy, where $M_a$ ( $m_a$ )
denotes the mass of axion star ( axion ) and $T$ does temperature of the
electrons. We assume the number $10^{11}$ of the stars with $B\sim 10^{2}$G and
radius $\sim 3.5\times10^{5}$km in the galaxy. We also assume that a half of
the dark matter is composed of axion star. We show that the emission of the
radiation burst only arises in the atmosphere in which the plasma frequency
$m_p\simeq m_a$. The duration of the burst lasts for the period which it takes
the axion star to pass the region with $m_p\simeq m_a$. It would be longer than
$1$ second.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 01:07:47 GMT""},{""version"":""v2"",""created"":""Fri, 8 Apr 2022 00:19:19 GMT""}]","2022-04-20"
"2203.07580","Roelien Christien Timmer","Roelien C. Timmer and David Liebowitz and Surya Nepal and Salil
  Kanhere","TSM: Measuring the Enticement of Honeyfiles with Natural Language
  Processing",,,,,"cs.CL cs.CR cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Honeyfile deployment is a useful breach detection method in cyber deception
that can also inform defenders about the intent and interests of intruders and
malicious insiders. A key property of a honeyfile, enticement, is the extent to
which the file can attract an intruder to interact with it. We introduce a
novel metric, Topic Semantic Matching (TSM), which uses topic modelling to
represent files in the repository and semantic matching in an embedding vector
space to compare honeyfile text and topic words robustly. We also present a
honeyfile corpus created with different Natural Language Processing (NLP)
methods. Experiments show that TSM is effective in inter-corpus comparisons and
is a promising tool to measure the enticement of honeyfiles. TSM is the first
measure to use NLP techniques to quantify the enticement of honeyfile content
that compares the essential topical content of local contexts to honeyfiles and
is robust to paraphrasing.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 01:07:51 GMT""}]","2022-03-16"
"2203.07581","D\'avid Kunszenti-Kov\'acs","Panna T\'imea Fekete, D\'avid Kunszenti-Kov\'acs","A Sampling Lemma for unbounded kernels",,,,,"math.PR math.FA","http://creativecommons.org/licenses/by/4.0/","  We present some preliminary results on a First Sampling lemma for unbounded
kernels, showing that with high probability, the cut norm of an $L^m$-kernel
$U$ ($4\leq m<\infty$) and the cut norm of a random $k$-sample have a
difference of order $O(k^{-1/4+\gamma/2}(\ln k)^{1/4})$ provided $m\gamma>2$.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 01:10:55 GMT""}]","2022-03-16"
"2203.07582","Huanyin Chen","Huanyin Chen, Dayong Liu, Marjan Sheibani","Group invertibility of the sum in rings and its applications",,,,,"math.RA","http://creativecommons.org/licenses/by/4.0/","  We present new additive results for the group invertibility in a ring. Then
we apply our results to block operator matrices over Banach spaces and derive
the existence of group inverses of $2\times 2$ block operator matrices. These
generalize many known results, e.g., Benitez, Liu and Zhu(Linear Multilinear
Algebra, {\bf 59}(2011), 279--289) and Zhou, Chen and Zhu(Comm. Algebra, {\bf
48}(2020),676-690).
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 01:11:26 GMT""}]","2022-03-16"
"2203.07583","Zihuai Lin","Zihuai Lin","Distributed Coded Modulation Schemes for Multiple Access Relay Channels",,,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we investigate network nest coded modulation schemes for
multiple access relay channels. The performance of the distributed systems
which are based on distributed convolutional codes with network coded
modulation is presented. An analytical upper bound on bit error probability
performance for the studied distributed systems with Maximum Likelihood
Sequence Detection (MLSD) is derived. The constructured bounds for the
investigated systems are shown to be asymptotically tight for increasing
channel Signal-to-Noise Ratio (SNR) values
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 01:12:06 GMT""}]","2022-03-16"
"2203.07584","Manuel Wettstein","Daniel Rutschmann, Manuel Wettstein","Chains, Koch Chains, and Point Sets with many Triangulations",,,,,"cs.CG","http://creativecommons.org/licenses/by/4.0/","  We introduce the abstract notion of a chain, which is a sequence of $n$
points in the plane, ordered by $x$-coordinates, so that the edge between any
two consecutive points is unavoidable as far as triangulations are concerned. A
general theory of the structural properties of chains is developed, alongside a
general understanding of their number of triangulations.
  We also describe an intriguing new and concrete configuration, which we call
the Koch chain due to its similarities to the Koch curve. A specific
construction based on Koch chains is then shown to have $\Omega(9.08^n)$
triangulations. This is a significant improvement over the previous and
long-standing lower bound of $\Omega(8.65^n)$ for the maximum number of
triangulations of planar point sets.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 01:12:29 GMT""},{""version"":""v2"",""created"":""Mon, 16 May 2022 03:50:51 GMT""},{""version"":""v3"",""created"":""Fri, 24 Feb 2023 20:54:22 GMT""},{""version"":""v4"",""created"":""Tue, 21 Mar 2023 16:11:07 GMT""}]","2023-03-22"
"2203.07585","Suliang Bu","Minta Liu, Suliang Bu","Accelerating Stochastic Probabilistic Inference",,,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, Stochastic Variational Inference (SVI) has been increasingly
attractive thanks to its ability to find good posterior approximations of
probabilistic models. It optimizes the variational objective with stochastic
optimization, following noisy estimates of the natural gradient. However,
almost all the state-of-the-art SVI algorithms are based on first-order
optimization algorithm and often suffer from poor convergence rate. In this
paper, we bridge the gap between second-order methods and stochastic
variational inference by proposing a second-order based stochastic variational
inference approach. In particular, firstly we derive the Hessian matrix of the
variational objective. Then we devise two numerical schemes to implement
second-order SVI efficiently. Thorough empirical evaluations are investigated
on both synthetic and real dataset to backup both the effectiveness and
efficiency of the proposed approach.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 01:19:12 GMT""}]","2022-03-16"
"2203.07586","Bo Pang","Bo Pang, Erik Nijkamp, Wojciech Kry\'sci\'nski, Silvio Savarese,
  Yingbo Zhou, Caiming Xiong","Long Document Summarization with Top-down and Bottom-up Inference","21 pages",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Text summarization aims to condense long documents and retain key
information. Critical to the success of a summarization model is the faithful
inference of latent representations of words or tokens in the source documents.
Most recent models infer the latent representations with a transformer encoder,
which is purely bottom-up. Also, self-attention-based inference models face the
challenge of quadratic complexity with respect to sequence length. We propose a
principled inference framework to improve summarization models on these two
aspects. Our framework assumes a hierarchical latent structure of a document
where the top-level captures the long range dependency at a coarser time scale
and the bottom token level preserves the details. Critically, this hierarchical
structure enables token representations to be updated in both a bottom-up and
top-down manner. In the bottom-up pass, token representations are inferred with
local self-attention to leverage its efficiency. Top-down correction is then
applied to allow tokens to capture long-range dependency. We demonstrate the
effectiveness of the proposed framework on a diverse set of summarization
datasets, including narrative, conversational, scientific documents and news.
Our model achieves (1) competitive or better performance on short documents
with higher memory and compute efficiency, compared to full attention
transformers, and (2) state-of-the-art performance on a wide range of long
document summarization benchmarks, compared to recent efficient transformers.
We also show that our model can summarize an entire book and achieve
competitive performance using $0.27\%$ parameters (464M vs. 175B) and much less
training data, compared to a recent GPT-3-based model. These results indicate
the general applicability and benefits of the proposed framework.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 01:24:51 GMT""}]","2022-03-16"
"2203.07587","Yu Nakayama","Taiga Harada and Yu Nakayama","Further swampland constraint on Dirac Neutrino","11 pages, main results appeared in master's thesis of the first
  author",,"10.1142/S0217732322500778","RUP-22-6","hep-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent studies on swampland conjectures (e.g. non-SUSY AdS conjecture or AdS
distance conjecture) predict that the (lightest) neutrino must be Dirac and the
mass must be cosmologically small $m < c \Lambda^{1/4}_{\text{cc}}\sim 10 \
\text{meV}$. The Dirac neutrino naturally accompanies a $U(1)$ symmetry that
can be embedded in the anomaly-free $U(1)_{B-L}$ global symmetry of the
standard model. We point out that the swampland conjectures applied to a circle
compactification with the $U(1)$ symmetry twisting lead to further constraints.
In particular, the $U(1)$ symmetry must be broken down to
$\mathbb{Z}_4$,$\mathbb{Z}_8$ or $\mathbb{Z}_{10}$ in the case of normal
hierarchy, and $\mathbb{Z}_4$ in the case of inverted hierarchy, providing
evidence for the absence of continuous global symmetry in quantum gravity. We
also predict a more constrained upper bound of the neutrino mass for each case.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 01:24:58 GMT""}]","2022-06-15"
"2203.07588","Mohammadali Mohammadi","Mohammadali Mohammadi and Hien Quoc Ngo and Michail Matthaiou","When Cell-Free Massive MIMO Meets OTFS Modulation: The Downlink Case","6 pages, 2 figures, accepted by IEEE ICC 2022. arXiv admin note:
  substantial text overlap with arXiv:2112.10869",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  We provide a performance evaluation of orthogonal time frequency space (OTFS)
modulation in cell-free massive MIMO (multiple-input multiple-output) systems.
By leveraging the inherent sparsity of the delay-Doppler (DD) representation of
time-varying channels, we apply the embedded pilot-aided channel estimation
method with reduced guard intervals and derive the minimum mean-square error
estimate of the channel gains from received uplink pilots at the access points
(APs). Each AP applies conjugate beamforming to transmit data to the users. We
derive a closed-form expression for the individual user downlink throughput as
a function of the numbers of APs, users and DD channel estimate parameters. We
compare the OTFS performance with that of orthogonal frequency division
multiplexing (OFDM) at high-mobility conditions. Our findings reveal that with
uncorrelated shadowing, cell-free massive MIMO with OTFS modulation achieves up
to 35% gain in 95%-likely per-user throughput, compared with the OFDM
counterpart. Finally, the increase in the per user throughput is more
pronounced at the median rates over the correlated shadowing scenarios.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 01:26:49 GMT""}]","2022-04-13"
"2203.07589","Helei Duan","Helei Duan, Ashish Malik, Jeremy Dao, Aseem Saxena, Kevin Green, Jonah
  Siekmann, Alan Fern, Jonathan Hurst","Sim-to-Real Learning of Footstep-Constrained Bipedal Dynamic Walking","Accepted at ICRA 2022. Video at
  https://www.youtube.com/watch?v=-zim1QQgA2s",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, work on reinforcement learning (RL) for bipedal robots has
successfully learned controllers for a variety of dynamic gaits with robust
sim-to-real demonstrations. In order to maintain balance, the learned
controllers have full freedom of where to place the feet, resulting in highly
robust gaits. In the real world however, the environment will often impose
constraints on the feasible footstep locations, typically identified by
perception systems. Unfortunately, most demonstrated RL controllers on bipedal
robots do not allow for specifying and responding to such constraints. This
missing control interface greatly limits the real-world application of current
RL controllers. In this paper, we aim to maintain the robust and dynamic nature
of learned gaits while also respecting footstep constraints imposed externally.
We develop an RL formulation for training dynamic gait controllers that can
respond to specified touchdown locations. We then successfully demonstrate
simulation and sim-to-real performance on the bipedal robot Cassie. In
addition, we use supervised learning to induce a transition model for
accurately predicting the next touchdown locations that the controller can
achieve given the robot's proprioceptive observations. This model paves the way
for integrating the learned controller into a full-order robot locomotion
planner that robustly satisfies both balance and environmental constraints.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 01:28:14 GMT""},{""version"":""v2"",""created"":""Tue, 3 May 2022 22:39:30 GMT""}]","2022-05-05"
"2203.07590","Tomoyuki Shirai","Makoto Katori and Tomoyuki Shirai","Scaling limit for determinantal point processes on spheres","""Stochastic Analysis on Large Scale Interacting Systems"". November
  5-8, 2018. edited by Ryoki Fukushima, Tadahisa Funaki, Yukio Nagahata,
  Hirofumi Osada and Kenkichi Tsunoda. The papers presented in this volume of
  RIMS K\^oky\^uroku Bessatsu are in final form and refereed.
  http://hdl.handle.net/2433/260647","RIMS K\^oky\^uroku Bessatsu B79 (2020), 123-138",,,"math.PR math-ph math.CV math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The unitary group with the Haar probability measure is called Circular
Unitary Ensemble. All the eigenvalues lie on the unit circle in the complex
plane and they can be regarded as a determinantal point process on
$\mathbb{S}^1$. It is also known that the scaled point processes converge
weakly to the determinantal point process associated with the so-called sine
kernel as the size of matrices tends to $\infty$. We extend this result to the
case of high-dimensional spheres and show that the scaling limit processes are
determinantal point processes associated with the kernels expressed by the
Bessel functions of the first kind.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 01:29:58 GMT""}]","2022-03-16"
"2203.07591","Guannan Geng","Qingyang Xiao, Guannan Geng, Shigan Liu, Jiajun Liu, Xia Meng, Qiang
  Zhang","Spatiotemporal continuous estimates of daily 1-km PM2.5 from 2000 to
  present under the Tracking Air Pollution in China (TAP) framework","29 pages, 1 tables, 8 figures",,,,"physics.ao-ph","http://creativecommons.org/licenses/by/4.0/","  High spatial resolution PM2.5 data covering a long time period are urgently
needed to support population exposure assessment and refined air quality
management. In this study, we provided complete-coverage PM2.5 predictions with
a 1-km spatial resolution from 2000 to the present under the Tracking Air
Pollution in China (TAP, http://tapdata.org.cn/) framework. To support high
spatial resolution modelling, we collected PM2.5 measurements from both
national and local monitoring stations. To correctly reflect the temporal
variations in land cover characteristics that affected the local variations in
PM2.5, we constructed continuous annual geoinformation datasets, including the
road maps and ensemble gridded population maps, in China from 2000 to 2021. We
also examined various model structures and predictor combinations to balance
the computational cost and model performance. The final model fused 10-km TAP
PM2.5 predictions from our previous work, 1-km satellite aerosol optical depth
retrievals and land use parameters with a random forest model. Our annual model
had an out-of-bag R2 ranging between 0.80 and 0.84, and our hindcast model had
a by-year cross-validation R2 of 0.76. This open-access 1-km resolution PM2.5
data product with complete coverage successfully revealed the local-scale
spatial variations in PM2.5 and could benefit environmental studies and
policy-making.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 01:33:37 GMT""},{""version"":""v2"",""created"":""Fri, 6 May 2022 02:18:04 GMT""}]","2022-05-09"
"2203.07592","Jixia Gao","Jixia Gao, Dandan Zhang, Haipeng Qu","A classification of finite $p$-groups with a unique
  $\mathcal{A}_2$-subgroup",,,,,"math.GR","http://creativecommons.org/licenses/by/4.0/","  Finite $p$-groups with a unique $\mathcal{A}_2$-subgroup are classified up to
isomorphism. A problem proposed by Berkovich and Janko is solved.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 01:41:52 GMT""}]","2022-03-16"
"2203.07593","Mehdi Yazdani-Jahromi","Mehdi Yazdani-Jahromi and AmirArsalan Rajabi and Aida Tayebi and Ozlem
  Ozmen Garibay","Distraction is All You Need for Fairness",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Bias in training datasets must be managed for various groups in
classification tasks to ensure parity or equal treatment. With the recent
growth in artificial intelligence models and their expanding role in automated
decision-making, ensuring that these models are not biased is vital. There is
an abundance of evidence suggesting that these models could contain or even
amplify the bias present in the data on which they are trained, inherent to
their objective function and learning algorithms; Many researchers direct their
attention to this issue in different directions, namely, changing data to be
statistically independent, adversarial training for restricting the
capabilities of a particular competitor who aims to maximize parity, etc. These
methods result in information loss and do not provide a suitable balance
between accuracy and fairness or do not ensure limiting the biases in training.
To this end, we propose a powerful strategy for training deep learning models
called the Distraction module, which can be theoretically proven effective in
controlling bias from affecting the classification results. This method can be
utilized with different data types (e.g., Tabular, images, graphs, etc.). We
demonstrate the potency of the proposed method by testing it on UCI Adult and
Heritage Health datasets (tabular), POKEC-Z, POKEC-N and NBA datasets (graph),
and CelebA dataset (vision). Using state-of-the-art methods proposed in the
fairness literature for each dataset, we exhibit our model is superior to these
proposed methods in minimizing bias and maintaining accuracy.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 01:46:55 GMT""},{""version"":""v2"",""created"":""Mon, 17 Oct 2022 04:36:10 GMT""}]","2022-10-18"
"2203.07594","Umananda Dev Goswami","Dhruba Jyoti Gogoi and Umananda Dev Goswami","Quasinormal Modes and Hawking Radiation Sparsity of GUP corrected Black
  Holes in Bumblebee Gravity with Topological Defects","40 pages, 23 figures","JCAP 06 (2022) 029","10.1088/1475-7516/2022/06/029",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have obtained the Generalized Uncertainty Principle (GUP) corrected de
Sitter and anti-de Sitter black hole solutions in bumblebee gravity with a
topological defect. We have calculated the scalar, electromagnetic and
gravitational quasinormal modes for the both vanishing and non-vanishing
effective cosmological constant using Pad\'e averaged sixth order WKB
approximation method. Apart from this, the time evolutions for all three
perturbations are studied, and quasinormal modes are calculated using the time
domain profile. We found that the first order and second order GUP parameters
$\alpha$ and $\beta$, respectively have opposite impacts on the quasinormal
modes. The study also finds that the presence of a global monopole can decrease
the quasinormal frequencies and the decay rate significantly. On the other
hand, Lorentz symmetry violation has noticeable impacts on the quasinormal
frequencies and the decay rate. We have studied the greybody factors, power
spectrum and sparsity of the black hole with the vanishing effective
cosmological constant for all the three perturbations. The presence of Lorentz
symmetry breaking and the GUP parameter $\alpha$ decrease, while other GUP
parameter $\beta$ and the presence of global monopole increase the probability
of Hawking radiation to reach the spatial infinity. The presence of Lorentz
violation can make the black holes less sparse, while the presence of a global
monopole can increase the sparsity of the black holes. Moreover, we have seen
that the black hole area quantization rule is modified by the presence of
Lorentz symmetry breaking.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 01:47:46 GMT""},{""version"":""v2"",""created"":""Sat, 2 Jul 2022 11:05:44 GMT""}]","2022-07-06"
"2203.07595","Tomoyuki Shirai","Makoto Katori and Tomoyuki Shirai","Local universality of determinantal point processes on Riemannian
  manifolds","9 pages",,,,"math.PR cond-mat.stat-mech math-ph math.MP math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the Laplace-Beltrami operator $\Delta_g$ on a smooth, compact
Riemannian manifold $(M,g)$ and the determinantal point process
$\mathcal{X}_{\lambda}$ on $M$ associated with the spectral projection of
$-\Delta_g$ onto the subspace corresponding to the eigenvalues up to
$\lambda^2$. We show that the pull-back of $\mathcal{X}_{\lambda}$ by the
exponential map $\exp_p : T_p^*M \to M$ under a suitable scaling converges
weakly to the universal determinantal point process on $T_p^* M$ as $\lambda
\to \infty$.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 01:48:41 GMT""}]","2022-03-16"
"2203.07596","A. Tuan Nguyen","A. Tuan Nguyen, Ser Nam Lim, Philip Torr","Task-Agnostic Robust Representation Learning",,,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has been reported that deep learning models are extremely vulnerable to
small but intentionally chosen perturbations of its input. In particular, a
deep network, despite its near-optimal accuracy on the clean images, often
mis-classifies an image with a worst-case but humanly imperceptible
perturbation (so-called adversarial examples). To tackle this problem, a great
amount of research has been done to study the training procedure of a network
to improve its robustness. However, most of the research so far has focused on
the case of supervised learning. With the increasing popularity of
self-supervised learning methods, it is also important to study and improve the
robustness of their resulting representation on the downstream tasks. In this
paper, we study the problem of robust representation learning with unlabeled
data in a task-agnostic manner. Specifically, we first derive an upper bound on
the adversarial loss of a prediction model (which is based on the learned
representation) on any downstream task, using its loss on the clean data and a
robustness regularizer. Moreover, the regularizer is task-independent, thus we
propose to minimize it directly during the representation learning phase to
make the downstream prediction model more robust. Extensive experiments show
that our method achieves preferable adversarial performance compared to
relevant baselines.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 02:05:11 GMT""}]","2022-03-16"
"2203.07597","George Jeffreys","George Jeffreys and Siu-Cheong Lau","Quantum Finite Automata and Quiver Algebras",,,,,"cs.FL cs.LG math.AG quant-ph","http://creativecommons.org/licenses/by/4.0/","  We find an application in quantum finite automata for the ideas and results
of [JL21] and [JL22]. We reformulate quantum finite automata with multiple-time
measurements using the algebraic notion of near-ring. This gives a unified
understanding towards quantum computing and deep learning. When the near-ring
comes from a quiver, we have a nice moduli space of computing machines with
metric that can be optimized by gradient descent.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 02:12:13 GMT""},{""version"":""v2"",""created"":""Tue, 19 Apr 2022 19:38:02 GMT""}]","2022-04-21"
"2203.07598","Byoung Ham","B. S. Ham","Understanding of coincidence detection in Franson-type nonlocal
  correlations for second-order quantum superposition","7 pages, 1 figure",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Coincidence detection is a key technique used in nonlocal quantum-correlation
measurements to test Bell inequality violation between remotely separated local
detectors. With individual uniform intensity of local measurements, the
nonlocal correlation fringe is a mysterious quantum feature that cannot be
achieved classically. Here, the coincidence detection is coherently
investigated to understand the fundamental physics of the nonlocal correlation
fringe via second-order quantum superposition between selected nonlocal
measurement events. Because of the coherence feature of paired photons, the
coincidence technique modifies the measurement events for the rule of thumb of
indistinguishability between selected measurement bases of paired photons. This
indistinguishability is quantum superposition between nonlocally detected
events resulting from a selected time slot of coincidence, where coherence
between individually measured photons is an absolute condition.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 02:13:35 GMT""}]","2022-03-16"
"2203.07599","Junzhang Ma Prof.","Junzhang Ma, S.-N. Zhang, J. P. Song, Q.-S. Wu, S. A. Ekahana, M.
  Naamneh, M. Radovic, V. N. Strocov, S.-Y. Gao, T. Qian, H. Ding, K. He, K.
  Manna, C. Felser, N. C. Plumb, O. V. Yazyev, Y.-M. Xiong, M. Shi","Giant Chern number of a Weyl nodal surface without upper limit","22 pages, 3 figures","Physical Review B 105, 115118 (2022)","10.1103/PhysRevB.105.115118",,"cond-mat.mtrl-sci cond-mat.other","http://creativecommons.org/licenses/by/4.0/","  Weyl nodes can be classified into zero-dimensional (0D) Weyl points (WPs), 1D
Weyl nodal lines (WNL) and 2D Weyl nodal surfaces (WNS), which possess finite
Chern numbers. Up to date, the largest Chern number of WPs identified in Weyl
semimetals is 4, which is thought to be a maximal value for linearly crossing
points in solids. On the other hand, whether the Chern numbers of
nonzero-dimensional linear crossing Weyl nodal objects have one upper limit is
still an open question. In this work, combining angle-resolved photoemission
spectroscopy with density functional theory calculations, we show that the
chiral crystal AlPt hosts a cube-shaped charged Weyl nodal surface which is
formed by the linear crossings of two singly-degenerate bands. Different to
conventional Weyl nodes, the cube-shaped nodal surface in AlPt is enforced by
nonsymmorphic chiral symmetries and time reversal symmetry rather than
accidental band crossings, and it possesses a giant Chern number |C| = 26.
Moreover, our results and analysis prove that there is no upper limit for the
Chern numbers of such kind 2D Weyl nodal object.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 02:17:20 GMT""}]","2022-03-16"
"2203.07600","Jialong Tang","Jialong Tang, Hongyu Lin, Meng Liao, Yaojie Lu, Xianpei Han, Le Sun,
  Weijian Xie, Jin Xu","Procedural Text Understanding via Scene-Wise Evolution","9 pages, 2 figures","AAAI 2022",,,"cs.CL","http://creativecommons.org/publicdomain/zero/1.0/","  Procedural text understanding requires machines to reason about entity states
within the dynamical narratives. Current procedural text understanding
approaches are commonly \textbf{entity-wise}, which separately track each
entity and independently predict different states of each entity. Such an
entity-wise paradigm does not consider the interaction between entities and
their states. In this paper, we propose a new \textbf{scene-wise} paradigm for
procedural text understanding, which jointly tracks states of all entities in a
scene-by-scene manner. Based on this paradigm, we propose \textbf{S}cene
\textbf{G}raph \textbf{R}easoner (\textbf{SGR}), which introduces a series of
dynamically evolving scene graphs to jointly formulate the evolution of
entities, states and their associations throughout the narrative. In this way,
the deep interactions between all entities and states can be jointly captured
and simultaneously derived from scene graphs. Experiments show that SGR not
only achieves the new state-of-the-art performance but also significantly
accelerates the speed of reasoning.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 02:17:33 GMT""}]","2022-03-16"
"2203.07601","Naoki Kobayashi","Naoki Kobayashi, Kento Tanahashi, Ryosuke Sato, Takeshi Tsukada","Automatic HFL(Z) Validity Checking for Program Verification","A long version of the paper published in Proceedings of POPL 2023",,,,"cs.PL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose an automated method for checking the validity of a formula of
HFL(Z), a higher-order logic with fixpoint operators and integers. Combined
with Kobayashi et al.'s reduction from higher-order program verification to
HFL(Z) validity checking, our method yields a fully automated, uniform
verification method for arbitrary temporal properties of higher-order
functional programs expressible in the modal mu-calculus, including
termination, non-termination, fair termination, fair non-termination, and also
branching-time properties. We have implemented our method and obtained
promising experimental results.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 02:17:49 GMT""},{""version"":""v2"",""created"":""Fri, 9 Dec 2022 04:59:17 GMT""}]","2022-12-12"
"2203.07602","Fei Hongming","Min Wu, Yibiao Yang, Hongming Fei, Han Lin, Xiaodan Zhao, Lijuan Kang","On-chip ultra-compact hexagonal boron nitride topological ring-resonator
  in visible region","8 pages, 6 figures",,"10.1109/JLT.2022.3203563",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ultra-compact topological ring-resonators with chirality are important
devices for quantum optics. However, there are limited demonstrations of chiral
resonators, especially in the visible region. We proposed a topological
photonic ring-resonator based on hexagonal boron nitride (hBN) valley photonic
crystal (VPC). The spin-valley locking effect in VPC allows achieving robust
unidirectional transmission of edge states in the visible region (600 nm-650
nm). As a result, a high quality factor (679.3) with a free spectral range of
15.2 nm in the visible region can be achieved in a hBN all-pass filter with a
compact size. In addition, we investigated the transmission properties of hBN
ring-resonators with different shapes and combinations, confirming the
flexibility of designing topological ring-resonators based on this principle.
This design can be readily integrated with quantum photonic chips for broad
applications.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 02:24:04 GMT""}]","2022-12-28"
"2203.07603","Chadni Islam","Chadni Islam, M. Ali Babar, Roland Croft and Helge Janicke","SmartValidator: A Framework for Automatic Identification and
  Classification of Cyber Threat Data",,,,,"cs.CR cs.SE","http://creativecommons.org/licenses/by/4.0/","  A wide variety of Cyber Threat Information (CTI) is used by Security
Operation Centres (SOCs) to perform validation of security incidents and
alerts. Security experts manually define different types of rules and scripts
based on CTI to perform validation tasks. These rules and scripts need to be
updated continuously due to evolving threats, changing SOCs' requirements and
dynamic nature of CTI. The manual process of updating rules and scripts delays
the response to attacks. To reduce the burden of human experts and accelerate
response, we propose a novel Artificial Intelligence (AI) based framework,
SmartValidator. SmartValidator leverages Machine Learning (ML) techniques to
enable automated validation of alerts. It consists of three layers to perform
the tasks of data collection, model building and alert validation. It projects
the validation task as a classification problem. Instead of building and saving
models for all possible requirements, we propose to automatically construct the
validation models based on SOC's requirements and CTI. We built a Proof of
Concept (PoC) system with eight ML algorithms, two feature engineering
techniques and 18 requirements to investigate the effectiveness and efficiency
of SmartValidator. The evaluation results showed that when prediction models
were built automatically for classifying cyber threat data, the F1-score of
75\% of the models were above 0.8, which indicates adequate performance of the
PoC for use in a real-world organization. The results further showed that
dynamic construction of prediction models required 99\% less models to be built
than pre-building models for all possible requirements. The framework can be
followed by various industries to accelerate and automate the validation of
alerts and incidents based on their CTI and SOC's preferences.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 02:35:14 GMT""}]","2022-03-16"
"2203.07604","Miho Kitamura","Miho Kitamura (1), Seigo Souma (2 and 3), Asuka Honma (4), Daisuke
  Wakabayashi (1), Hirokazu Tanaka (1), Akio Toyoshima (1), Kenta Amemiya (1),
  Tappei Kawakami (4), Katsuaki Sugawara (2 and 3 and 4 and 5), Kosuke Nakayama
  (4 and 5), Kohei Yoshimatsu (6), Hiroshi Kumigashira (1 and 6), Takafumi Sato
  (2 and 3 and 4), Koji Horiba (1 and 7) ((1) Photon Factory, Institute of
  Materials Structure Science, High Energy Accelerator Research Organization
  (KEK), (2) Center for Spintronics Research Network, Tohoku University, (3)
  Advanced Institute for Materials Research (WPI-AIMR), (4) Department of
  Physics, Graduate School of Science, Tohoku University, (5) Precursory
  Research for Embryonic Science and Technology, Japan Science and Technology
  Agency, (6) Institute of Multidisciplinary Research for Advanced Materials
  (IMRAM), Tohoku University, (7) Institute for Advanced Synchrotron Light
  Source, National Institutes for Quantum Science and Technology (QST))","Development of a versatile micro-focused angle-resolved photoemission
  spectroscopy system with Kirkpatrick-Baez mirror optics","21 pages, 8 figures",,"10.1063/5.0074393",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Angle-resolved photoemission spectroscopy using a micro-focused beam spot
(micro-ARPES) is becoming a powerful tool to elucidate key electronic states of
exotic quantum materials. We have developed a versatile micro-ARPES system
based on synchrotron radiation beam focused with a Kirkpatrick-Baez mirror
optics. The mirrors are monolithically installed on a stage, which is driven
with five-axes motion, and are vibrationally separated from the ARPES
measurement system. Spatial mapping of the Auphotolithography pattern on Si
signifies the beam spot size of 10 $\mu$m (horizontal) x 12 $\mu$m (vertical)
at the sample position, which is well suited to resolve the fine structure in
local electronic states. Utilization of the micro beam and the high precision
sample motion system enables the accurate spatially resolved band-structure
mapping, as demonstrated by the observation of a small band anomaly associated
with tiny sample bending near the edge of a cleaved topological insulator
single crystal.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 02:38:24 GMT""}]","2022-04-13"
"2203.07605","Hanna Sumita","Hanna Sumita, Shinji Ito, Kei Takemura, Daisuke Hatano, Takuro
  Fukunaga, Naonori Kakimura, Ken-ichi Kawarabayashi","Online Task Assignment Problems with Reusable Resources","Appeared in AAAI-22",,,,"cs.DS cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study online task assignment problem with reusable resources, motivated by
practical applications such as ridesharing, crowdsourcing and job hiring. In
the problem, we are given a set of offline vertices (agents), and, at each
time, an online vertex (task) arrives randomly according to a known
time-dependent distribution. Upon arrival, we assign the task to agents
immediately and irrevocably. The goal of the problem is to maximize the
expected total profit produced by completed tasks. The key features of our
problem are (1) an agent is reusable, i.e., an agent comes back to the market
after completing the assigned task, (2) an agent may reject the assigned task
to stay the market, and (3) a task may accommodate multiple agents. The setting
generalizes that of existing work in which an online task is assigned to one
agent under (1).
  In this paper, we propose an online algorithm that is $1/2$-competitive for
the above setting, which is tight. Moreover, when each agent can reject
assigned tasks at most $\Delta$ times, the algorithm is shown to have the
competitive ratio $\Delta/(3\Delta-1)\geq 1/3$. We also evaluate our proposed
algorithm with numerical experiments.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 02:48:13 GMT""}]","2022-03-16"
"2203.07606","Miyu Suzuki","Miyu Suzuki, Satoshi Wakatsuki, Shun'ichi Yokoyama","Distribution of toric periods of modular forms on definite quaternion
  algebras","35 pages, 2 figures available at
  http://wakatsuki.w3.kanazawa-u.ac.jp/Figures.html, minor revision based on
  the referees' comments",,"10.1007/s40993-022-00389-8",,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $D$ be a definite quaternion algebra over $\mathbb{Q}$ and $\mathcal{O}$
an Eichler order in $D$ of square-free level. We study distribution of the
toric periods of algebraic modular forms of level $\mathcal{O}$. We focus on
two problems: non-vanishing and sign changes. Firstly, under certain conditions
on $\mathcal{O}$, we prove the non-vanishing of the toric periods for positive
proportion of imaginary quadratic fields. This improves the known lower bounds
toward Goldfeld's conjecture in some cases and provides evidence for similar
non-vanishing conjectures for central values of twisted automorphic
$L$-functions. Secondly, we show that the sequence of toric periods has
infinitely many sign changes. This proves the sign changes of the Fourier
coefficients $\{a(n)\}_n$ of weight 3/2 modular forms, where $n$ ranges over
fundamental discriminants. In the final section, we present numerical
experiments in some cases and formulate several conjectures based on them.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 02:52:21 GMT""},{""version"":""v2"",""created"":""Wed, 23 Mar 2022 04:44:17 GMT""},{""version"":""v3"",""created"":""Thu, 8 Sep 2022 01:02:00 GMT""}]","2022-10-17"
"2203.07607","Shusaku Imajo","Shusaku Imajo, Naofumi Matsuyama, Toshihiro Nomura, Takumi Kihara,
  Shintao Nakamura, Christophe Marcenat, Thierry Klein, Gabriel Seyfarth,
  Chengchao Zhong, Hiroshi Kageyama, Koichi Kindo, Tsutomu Momoi, Yoshimitsu
  Kohama","Magnetically hidden state on the ground floor of the magnetic Devil's
  staircase",,"Phys. Rev. Lett. 129, 147201 (2022)","10.1103/PhysRevLett.129.147201",,"cond-mat.str-el cond-mat.mtrl-sci cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigated the low-temperature and high-field thermodynamic and
ultrasonic properties of SrCu2(BO3)2, which exhibits various plateaux in its
magnetization curve above 27~T, called a magnetic Devil's staircase. The
results of the present study confirm that magnetic crystallization, the first
step of the staircase, occurs above 27~T as a 1st-order transition accompanied
by a sharp singularity in heat capacity $C_p$ and a kink in the elastic
constant. In addition, we observe a thermodynamic anomaly at lower fields
around 26~T, which has not been previously detected by any magnetic probes. At
low temperatures, this magnetically hidden state has a large entropy and does
not exhibit Schottky-type gapped behavior, which suggests the existence of
low-energy collective excitations. Based on our observations and theoretical
predictions, we propose that magnetic quadrupoles form a spin-nematic state
around 26~T as a hidden state on the ground floor of the magnetic Devil's
staircase.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 02:52:27 GMT""},{""version"":""v2"",""created"":""Mon, 3 Oct 2022 07:15:58 GMT""}]","2022-10-04"
"2203.07608","Zhipan Li","Z. P. Li and D. Vretenar","Model for collective motion","30 pages, 15 figures, Contribution to the ""Handbook of Nuclear
  Physics"", Springer, 2022, edited by I. Tanihata, H. Toki and T. Kajino",,,,"nucl-th","http://creativecommons.org/publicdomain/zero/1.0/","  Collective motion is a manifestation of emergent phenomena in medium-heavy
and heavy nuclei. A relatively large number of constituent nucleons contribute
coherently to nuclear excitations (vibrations, rotations) that are
characterized by large electromagnetic moments and transition rates. Basic
features of collective excitations are reviewed, and a simple model introduced
that describes large-amplitude quadrupole and octupole shape dynamics, as well
as the dynamics of induced fission. Modern implementations of the collective
Hamiltonian model are based on the microscopic framework of energy density
functionals, that provide an accurate global description of nuclear ground
states and collective excitations. Results of illustrative calculations are
discussed in comparison with available data.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 02:52:55 GMT""},{""version"":""v2"",""created"":""Thu, 17 Mar 2022 05:08:02 GMT""}]","2022-03-18"
"2203.07609","Andr\'es Mauricio Rivera Acevedo","Oscar Perdomo, Andr\'es Rivera, John A. Arredondo, Nelson Casta\~neda","Periodic oscillations in a 2N-body problem","20 pages, 15 Figures",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hip-Hop solutions of the $2N$-body problem are solutions that satisfy at
every instance of time, that the $2N$ bodies with the same mass $m$, are at the
vertices of two regular $N$-gons, each one of these $N$-gons are at planes that
are equidistant from a fixed plane $\Pi_0$ forming an antiprism. In this paper,
we first prove that for every $N$ and every $m$ there exists a family of
periodic hip-hop solutions. For every solution in these families the oriented
distance to the plane $\Pi_0$, which we call $d(t)$, is an odd function that is
also even with respect to $t=T$ for some $T>0.$ For this reason we call
solutions in these families, double symmetric solutions. By exploring more
carefully our initial set of periodic solutions, we numerically show that some
of the branches stablished in our existence theorem have bifurcations that
produce branches of solutions with the property that the oriented distance
function $d(t)$ is not even with respect to any $T>0$, we call these solutions
single symmetry solutions. We prove that no single symmetry solution is a
choreography. We also display explicit double symmetric solutions that are
choreographies.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 02:56:28 GMT""}]","2022-03-16"
"2203.07610","Junghyun Lee","Junghyun Lee, Mamiko Tatsuta, Andrew Xu, Erik Bauch, Mark J. H. Ku,
  and Ronald. L. Walsworth","Dressed-state control of effective dipolar interaction between
  strongly-coupled solid-state spins",,,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Strong interactions between spins in many-body solid-state quantum system is
a crucial resource for exploring and applying non-classical states. In
particular, electronic spins associated with defects in diamond system are a
leading platform for the study of collective quantum phenomena and for quantum
technology applications. While such solid-state quantum defect systems have the
advantage of scalability and operation under ambient conditions, they face the
key challenge of controlling interactions between the defects spins, since the
defects are spatially fixed inside the host lattice with relative positions
that cannot be well controlled during fabrication. In this work, we present a
dressed-state approach to control the effective dipolar coupling between
solid-state spins; and then demonstrate this scheme experimentally using two
strongly-coupled nitrogen vacancy (NV) centers in diamond. Including Rabi
driving terms between the m$_s$ = 0 and $\pm$1 states in the NV spin
Hamiltonian allows us to turn on and off or tune the effective dipolar coupling
between two NV spins. Through Ramsey spectroscopy, we detect the change of the
effective dipolar field generated by the control NV spin prepared in different
dressed states. To observe the change of interaction dynamics, we then deploy
spin-lock-based polarization transfer measurements via a Hartmann-Hahn matching
condition between two NV spins in different dressed states. We perform
simulations that indicate the promise for this robust scheme to control the
distribution of interaction strengths in strongly-interacting spin systems,
including interaction strength homogenization in a spin ensemble, which can be
a valuable tool for studying non-equilibrium quantum phases and generating high
fidelity multi-spin correlated states for quantum-enhanced sensing.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 02:58:31 GMT""},{""version"":""v2"",""created"":""Tue, 2 May 2023 13:30:02 GMT""}]","2023-05-03"
"2203.07611","Wenhua Wang","Wenhua Wang and Aiting Wang","The Characterizations of Anisotropic Mixed-Norm Hardy Spaces on
  $\mathbb{R}^n$ by Atoms and Molecules","21",,,,"math.FA math.CA","http://creativecommons.org/licenses/by/4.0/","  Let $\vec{p}\in(0,\,\infty)^n$, $A$ be an expansive dilation on
$\mathbb{R}^n$,and $H^{\vec{p}}_A({\mathbb {R}}^n)$ be the anisotropic
mixed-norm Hardy space defined via the non-tangential grand maximal function
studied by \cite{hlyy20}. In this paper, the authors establish new atomic and
molecular decompositions of $H^{\vec{p}}_A({\mathbb {R}}^n)$. As an
application, the authors obtain a boundedness criterion for a class of linear
operators from $H^{\vec{p}}_{A}(\mathbb{R}^n)$ to
$H^{\vec{p}}_{A}(\mathbb{R}^n)$. Part of results are still new even in the
classical isotropic setting (in the case $A:=2\mathrm I_{n\times n}$,
${\mathrm{I}}_{n\times n}$ denotes the $n\times n$ unit matrix).
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 02:58:57 GMT""}]","2022-03-16"
"2203.07612","Hyun-Sik Jeong","Hyun-Sik Jeong, Keun-Young Kim, Ya-Wen Sun","Holographic entanglement density for spontaneous symmetry breaking","29 pages, 7 figures",,"10.1007/JHEP06(2022)078",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the properties of the holographic entanglement entropy of the
systems in which the $U(1)$ or the translational symmetry is broken
\textit{spontaneously}. For this purpose, we define the entanglement density of
the strip-subsystems and examine both the first law of entanglement entropy
(FLEE) and the area theorem. We classify the conditions that FLEE and/or the
area theorem obey and show that such a classification may be useful for
characterizing the systems. We also find universalities from both FLEE and the
area theorem. In the spontaneous symmetry breaking case, FLEE is always obeyed
regardless of the type of symmetry: $U(1)$ or translation. For the
translational symmetry, the area theorem is always violated when the symmetry
is weakly broken, independent of the symmetry breaking patterns (explicit or
spontaneous). We also argue that the $\log$ contribution of the entanglement
entropy from the Goldstone mode may not appear in the strongly coupled systems.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 03:00:50 GMT""}]","2022-06-29"
"2203.07613","Carlos E. Jimenez","Carlos E. Jimenez, Olga Russakovsky, Karthik Narasimhan","CARETS: A Consistency And Robustness Evaluative Test Suite for VQA","ACL 2022",,,,"cs.CL cs.CV","http://creativecommons.org/licenses/by/4.0/","  We introduce CARETS, a systematic test suite to measure consistency and
robustness of modern VQA models through a series of six fine-grained capability
tests. In contrast to existing VQA test sets, CARETS features balanced question
generation to create pairs of instances to test models, with each pair focusing
on a specific capability such as rephrasing, logical symmetry or image
obfuscation. We evaluate six modern VQA systems on CARETS and identify several
actionable weaknesses in model comprehension, especially with concepts such as
negation, disjunction, or hypernym invariance. Interestingly, even the most
sophisticated models are sensitive to aspects such as swapping the order of
terms in a conjunction or varying the number of answer choices mentioned in the
question. We release CARETS to be used as an extensible tool for evaluating
multi-modal model robustness.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 03:01:03 GMT""}]","2022-03-16"
"2203.07614","Vincent Richard Pascuzzi","Sunanda Banerjee, D. N. Brown, David N. Brown, Paolo Calafiura, Jacob
  Calcutt, Philippe Canal, Miriam Diamond, Daniel Elvira, Thomas Evans, Renee
  Fatemi, Krzysztof Genser, Robert Hatcher, Alexander Himmel, Seth R. Johnson,
  Soon Yung Jun, Michael Kelsey, Evangelos Kourlitis, Robert K. Kutschke,
  Guilherme Lima, Kevin Lynch, Kendall Mahn, Zachary Marshall, Michael Mooney,
  Adam Para, Vincent R. Pascuzzi, Kevin Pedro, Oleg Samoylov, Erica Snider,
  Pavel Snopok, Matthew Szydagis, Hans Wenzel, Leigh H. Whitehead, Tingjun
  Yang, Julia Yarba","Detector and Beamline Simulation for Next-Generation High Energy Physics
  Experiments","Contribution to Snowmass 2021",,,"FERMILAB-FN-1151-ND-PPD-SCD","hep-ex physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The success of high energy physics programs relies heavily on accurate
detector simulations and beam interaction modeling. The increasingly complex
detector geometries and beam dynamics require sophisticated techniques in order
to meet the demands of current and future experiments. Common software tools
used today are unable to fully utilize modern computational resources, while
data-recording rates are often orders of magnitude larger than what can be
produced via simulation. In this paper, we describe the state, current and
future needs of high energy physics detector and beamline simulations and
related challenges, and we propose a number of possible ways to address them.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 03:04:44 GMT""},{""version"":""v2"",""created"":""Wed, 16 Mar 2022 02:17:50 GMT""},{""version"":""v3"",""created"":""Wed, 20 Apr 2022 20:06:49 GMT""}]","2022-04-22"
"2203.07615","Chunbo Lang","Chunbo Lang, Gong Cheng, Binfei Tu, Junwei Han","Learning What Not to Segment: A New Perspective on Few-Shot Segmentation","Accepted to CVPR 2022 Oral",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently few-shot segmentation (FSS) has been extensively developed. Most
previous works strive to achieve generalization through the meta-learning
framework derived from classification tasks; however, the trained models are
biased towards the seen classes instead of being ideally class-agnostic, thus
hindering the recognition of new concepts. This paper proposes a fresh and
straightforward insight to alleviate the problem. Specifically, we apply an
additional branch (base learner) to the conventional FSS model (meta learner)
to explicitly identify the targets of base classes, i.e., the regions that do
not need to be segmented. Then, the coarse results output by these two learners
in parallel are adaptively integrated to yield precise segmentation prediction.
Considering the sensitivity of meta learner, we further introduce an adjustment
factor to estimate the scene differences between the input image pairs for
facilitating the model ensemble forecasting. The substantial performance gains
on PASCAL-5i and COCO-20i verify the effectiveness, and surprisingly, our
versatile scheme sets a new state-of-the-art even with two plain learners.
Moreover, in light of the unique nature of the proposed approach, we also
extend it to a more realistic but challenging setting, i.e., generalized FSS,
where the pixels of both base and novel classes are required to be determined.
The source code is available at github.com/chunbolang/BAM.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 03:08:27 GMT""},{""version"":""v2"",""created"":""Tue, 29 Mar 2022 03:43:38 GMT""}]","2022-03-30"
"2203.07616","Elif Surer","Elif Hilal Korkut, Elif Surer","Visualization in virtual reality: a systematic review",,,,,"cs.HC","http://creativecommons.org/licenses/by/4.0/","  Rapidly growing virtual reality (VR) technologies and techniques have gained
importance over the past few years, and academics and practitioners have been
searching for efficient visualizations in VR. To date, emphasis has been on the
employment of game technologies. Despite the growing interest and discussion,
visualization studies have lacked a common baseline in the transition period of
2D visualizations to immersive ones. To this end, the presented study aims to
provide a systematic literature review that explains the state-of-the-art
research and future trends on visualization in virtual reality. The research
framework is grounded in empirical and theoretical works of visualization. We
characterize the reviewed literature based on three dimensions: (a) Connection
with visualization background and theory, (b) Evaluation and design
considerations for virtual reality visualization, and (c) Empirical studies.
The results from this systematic review suggest that: (1) There are only a few
studies that focus on creating standard guidelines for virtual reality, and
each study individually provides a framework or employs previous studies on
traditional 2D visualizations; (2) With the myriad of advantages provided for
visualization and virtual reality, most of the studies prefer to use game
engines; (3) Although game engines are extensively used, they are not
convenient for critical scientific studies; and (4) 3D versions of traditional
statistical visualization techniques, such as bar plots and scatter plots, are
still commonly used in the data visualization context. This systematic review
attempts to add to the literature a clear picture of the emerging contexts,
different elements, and their interdependencies.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 03:08:39 GMT""}]","2022-03-16"
"2203.07617","Keiji Matsumoto","Keiji Matsumoto","Analogies of Jacobi's formula","26 pages, 3 figures",,,,"math.CA math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  By considering Schwarz's map for the hypergeometric differential equation
with parameters $(a,b,c)=(1/6,1/2,1)$ or $(1/12,5/12,1)$, we give some
analogies of Jacobi's formula $\vartheta_{00}(\tau)^2=
F(1/2,1/2,1;\lambda(\tau))$, where $\vartheta_{00}(\tau)$ and $\lambda(\tau)$
are the theta constant and the lambda function defined on the upper-half plane,
and $F(a,b,c;z)$ is the hypergeometric series defined on the unit disk. As
applications of our formulas, we give several functional equations for
$F(a,b,c;z)$.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 03:11:00 GMT""}]","2022-03-16"
"2203.07618","Jooyoung Lee","Jooyoung Lee, Thai Le, Jinghui Chen, Dongwon Lee","Do Language Models Plagiarize?","Accepted to WWW'23",,"10.1145/3543507.3583199",,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Past literature has illustrated that language models (LMs) often memorize
parts of training instances and reproduce them in natural language generation
(NLG) processes. However, it is unclear to what extent LMs ""reuse"" a training
corpus. For instance, models can generate paraphrased sentences that are
contextually similar to training samples. In this work, therefore, we study
three types of plagiarism (i.e., verbatim, paraphrase, and idea) among GPT-2
generated texts, in comparison to its training data, and further analyze the
plagiarism patterns of fine-tuned LMs with domain-specific corpora which are
extensively used in practice. Our results suggest that (1) three types of
plagiarism widely exist in LMs beyond memorization, (2) both size and decoding
methods of LMs are strongly associated with the degrees of plagiarism they
exhibit, and (3) fine-tuned LMs' plagiarism patterns vary based on their corpus
similarity and homogeneity. Given that a majority of LMs' training data is
scraped from the Web without informing content owners, their reiteration of
words, phrases, and even core ideas from training sets into generated texts has
ethical implications. Their patterns are likely to exacerbate as both the size
of LMs and their training data increase, raising concerns about
indiscriminately pursuing larger models with larger training corpora.
Plagiarized content can also contain individuals' personal and sensitive
information. These findings overall cast doubt on the practicality of current
LMs in mission-critical writing tasks and urge more discussions around the
observed phenomena. Data and source code are available at
https://github.com/Brit7777/LM-plagiarism.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 03:11:11 GMT""},{""version"":""v2"",""created"":""Mon, 13 Feb 2023 21:05:52 GMT""}]","2023-02-15"
"2203.07619","Michael Fuchs","Yu-Sheng Chang, Michael Fuchs, Hexuan Liu, Michael Wallner, Guan-Ru Yu","Enumeration of $d$-combining Tree-Child Networks","Extended abstract which is accepted for presentation at AofA2022; an
  accompanying Maple worksheet can be found in the ancillary file folder",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Tree-child networks are one of the most prominent network classes for
modeling evolutionary processes which contain reticulation events. Several
recent studies have addressed counting questions for {\it bicombining
tree-child networks} which are tree-child networks with every reticulation node
having exactly two parents. In this paper, we extend these studies to {\it
$d$-combining tree-child networks} where every reticulation node has now $d\geq
2$ parents. Moreover, we also give results and conjectures on the
distributional behavior of the number of reticulation nodes of a network which
is drawn uniformly at random from the set of all tree-child networks with the
same number of leaves.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 03:12:46 GMT""}]","2022-03-16"
"2203.07620","David W. Miller","Rainer Bartoldus, Catrin Bernius, David W. Miller","Innovations in trigger and data acquisition systems for next-generation
  physics facilities","Contribution to Snowmass 2021",,,,"hep-ex cs.LG cs.SY eess.SY physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  Data-intensive physics facilities are increasingly reliant on heterogeneous
and large-scale data processing and computational systems in order to collect,
distribute, process, filter, and analyze the ever increasing huge volumes of
data being collected. Moreover, these tasks are often performed in hard
real-time or quasi real-time processing pipelines that place extreme
constraints on various parameters and design choices for those systems.
Consequently, a large number and variety of challenges are faced to design,
construct, and operate such facilities. This is especially true at the energy
and intensity frontiers of particle physics where bandwidths of raw data can
exceed 100 TB/s of heterogeneous, high-dimensional data sourced from 300M+
individual sensors. Data filtering and compression algorithms deployed at these
facilities often operate at the level of 1 part in $10^5$, and once executed,
these algorithms drive the data curation process, further highlighting the
critical roles that these systems have in the physics impact of those
endeavors. This White Paper aims to highlight the challenges that these
facilities face in the design of the trigger and data acquisition
instrumentation and systems, as well as in their installation, commissioning,
integration and operation, and in building the domain knowledge and technical
expertise required to do so.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 03:13:32 GMT""},{""version"":""v2"",""created"":""Thu, 17 Mar 2022 19:50:30 GMT""}]","2022-03-21"
"2203.07621","Kyeongmin Cho","Kyeongmin Cho, Seungmin Jeon, Jeehoon Kang","Practical Detectability for Persistent Lock-Free Data Structures",,,,,"cs.PL cs.DC cs.DS","http://creativecommons.org/licenses/by/4.0/","  Persistent memory (PM) is an emerging class of storage technology that
combines the benefits of DRAM and SSD. This characteristic inspires research on
persistent objects in PM with fine-grained concurrency control. Among such
objects, persistent lock-free data structures (DSs) are particularly
interesting thanks to their efficiency and scalability. One of the most widely
used correctness criteria for persistent lock-free DSs is durable
linearizability (Izraelevitz et. al., DISC 2016). However, durable
linearizability is insufficient to use persistent DSs for fault-tolerant
systems requiring exactly-once semantics for storage systems, because we may
not be able to detect whether an operation is performed when a crash occurs.
  We present a practical programming framework for persistent lock-free DSs
with detectability. In contrast to the prior work on such DSs, our framework
supports (1) primitive detectable operations such as space-efficient
compare-and-swap, insertion, and deletion; (2) systematic transformation of
lock-free DSs in DRAM into those in PM requiring modest efforts; (3) comparable
performance with non-detectable DSs by DRAM scratchpad optimization; and (4)
recovery from both full system and thread crashes. The key idea is memento
objects serving as a lightweight, precise, and per-thread checkpoints in PM. As
a case study, we implement lock-free and combining queues and hash tables with
detectability that outperform (and perform comparably) the state-of-the-art DSs
with (and without, respectively) detectability.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 03:20:08 GMT""}]","2022-03-16"
"2203.07622","Michael E. Peskin","Alexander Aryshev, Ties Behnke, Mikael Berggren, James Brau, Nathaniel
  Craig, Ayres Freitas, Frank Gaede, Spencer Gessner, Stefania Gori, Christophe
  Grojean, Sven Heinemeyer, Daniel Jeans, Katja Kruger, Benno List, Jenny List,
  Zhen Liu, Shinichiro Michizono, David W. Miller, Ian Moult, Hitoshi Murayama,
  Tatsuya Nakada, Emilio Nanni, Mihoko Nojiri, Hasan Padamsee, Maxim
  Perelstein, Michael E. Peskin, Roman Poeschl, Sam Posen, Aidan Robson, Jan
  Strube, Taikan Suehara, Junping Tian, Maxim Titov, Marcel Vos, Andrew White,
  Graham Wilson, Kaoru Yokoya, Aleksander Filip Zarnecki, Ichiro Adachi,
  Kaustubh Agashe, Tatjana Agatonovic Jovin, Hiroaki Aihara, Wolfgang
  Altmannshofer, Daniele Alves, Justin Anguiano, Ken-Ichi Aoki, Masato Aoki,
  Toshihiro Aoki, Yumi Aoki, Yasuo Arai, Hayato Araki, Haruka Asada, Kento
  Asai, Shoji Asai, David Attie, Howard Baer, Jonathan Bagger, Yang Bai, Ian
  Bailey, Ricardo Barrue, Rainer Bartoldus, Emanuela Barzi, Matthew Basso,
  Lothar Bauerdick, Sebastian Baum, Alain Bellerive, Sergey Belomestnykh, Jorge
  Berenguer Antequera, Jakob Beyer, Pushpalatha Bhat, Burak Bilki, Kevin Black,
  Kenneth Bloom, Geoffrey Bodwin, Veronique Boisvert, Fatma Boran, Vincent
  Boudry, Radja Boughezal, Antonio Boveia, Ivanka Bozovic-Jelisavcic,
  Jean-Claude Brient, Stanley Brodsky, Laurent Brunetti, Karsten Buesser,
  Eugene Bulyak, Philip N. Burrows, Graeme C. Burt, Yunhai Cai, Valentina
  Cairo, Anadi Canepa, Francesco Giovanni Celiberto, Enrico Cenni, Zackaria
  Chacko, Iryna Chaikovska, Mattia Checchin, Lisong Chen, Thomas Y. Chen, Hsin
  Chia Cheng, Gi-Chol Cho, Brajesh Choudhary, Jim Clarke, James Cline, Raymond
  Co, Timothy Cohen, Paul Colas, Chris Damerell, Arindam Das, Sridhara Dasu,
  Sally Dawson, Jorge de Blas, Carlos Henrique de Lima, Aldo Deandrea, Klaus
  Dehmelt, Jean Delayen, Carlos Henrique de Lima, Marcel Demarteau, Dmitri
  Denisov, Radovan Dermisek, Angel Dieguez, Takeshi Dohmae, Jens Dopke,
  Katharina Dort, Yong Du, Bohdan Dudar, Bhaskar Dutta, Juhi Dutta, Ulrich
  Einhaus, Eckhard Elsen, Motoi Endo, Grigory Eremeev, Engin Eren, Jens Erler,
  Eric Esarey, Lisa Everett, Angeles Faus Golfe, Marcos Fernandez Garcia, Brian
  Foster, Nicolas Fourches, Mary-Cruz Fouz, Keisuke Fujii, Junpei Fujimoto,
  Esteban Fullan Torregrosa, Kazuro Furukawa, Takahiro Fusayasu, Juan Fuster,
  Serguei Ganjour, Yuanning Gao, Naveen Gaur, Rongli Geng, Howard Georgi, Tony
  Gherghetta, Joel Goldstein, Dorival Goncalves, Julia Gonski, Tomas Gonzalo,
  Takeyoshi Goto, Toru Goto, Norman Graf, Joseph Grames, Paul Grannis, Lindsey
  Gray, Alexander Grohsjean, Jiayin Gu, Yalcin Guler, Phillip Gutierrez, Junji
  Haba, Howard Haber, John Hallford, Koichi Hamaguchi, Tao Han, Kazuhiko Hara,
  Daisuke Harada, Koji Hashimoto, Katsuya Hashino, Masahito Hayashi, Gudrun
  Heinrich, Keisho Hidaka, Takeo Higuchi, Fujio Hinode, Zenro Hioki, Minoru
  Hirose, Nagisa Hiroshima, Junji Hisano, Wolfgang Hollik, Samuel Homiller,
  Sungwoo Hong, Anson Hook, Yasuyuki Horii, Hiroki Hoshina, Ivana Hristova,
  Katri Huitu, Yoshifumi Hyakutake, Toru Iijima, Katsumasa Ikematsu, Anton
  Ilderton, Kenji Inami, Adrian Irles, Akimasa Ishikawa, Koji Ishiwata, Hayato
  Ito, Igor Ivanov, Sho Iwamoto, Toshiyuki Iwamoto, Masako Iwasaki, Yoshihisa
  Iwashita, Haoyi Jia, Fabricio Jimenez Morales, Prakash Joshi, Sunghoon Jung,
  Goran Kacarevic, Michael Kagan, Mitsuru Kakizaki, Jan Kalinowski, Jochen
  Kaminski, Kazuyuki Kanaya, Shinya Kanemura, Hayato Kanno, Yuya Kano, Shigeru
  Kashiwagi, Yukihiro Kato, Nanami Kawada, Shin-ichi Kawada, Kiyotomo Kawagoe,
  Valery Khoze, Hiromichi Kichimi, Doojin Kim, Teppei Kitahara, Ryuichiro
  Kitano, Jan Klamka, Sachio Komamiya, K. C. Kong, Taro Konomi, Katsushige
  Kotera, Emi Kou, Ilya Kravchenko, Kiyoshi Kubo, Takayuki Kubo, Takuya
  Kumaoka, Ashish Kumar, Nilanjana Kumar, Jonas Kunath, Saumyen Kundu, Hiroshi
  Kunitomo, Masakazu Kurata, Masao Kuriki, Alexander Kusenko, Theodota Lagouri,
  Andrew J. Lankford, Gordana Lastovicka-Medin, Francois Le Diberder, Claire
  Lee, Matthias Liepe, Jacob Linacre, Zachary Liptak, Shivani Lomte, Ian Low,
  Yang Ma, Hani Maalouf, David MacFarlane, Brendon Madison, Thomas Madlener,
  Tomohito Maeda, Paul Malek, Sanjoy Mandal, Thomas Markiewicz, John Marshall,
  Aurelien Martens, Victoria Martin, Martina Martinello, Celso Martinez Rivero,
  Nobuhito Maru, John Matheson, Shigeki Matsumoto, Hiroyuki Matsunaga, Yutaka
  Matsuo, Kentarou Mawatari, Johnpaul Mbagwu, Peter McIntosh, Peter McKeown,
  Patrick Meade, Krzysztof Mekala, Petra Merkel, Satoshi Mihara, V\'ictor
  Miralles, Marcos Miralles Lopez, Go Mishima, Satoshi Mishima, Bernhard
  Mistlberger, Alexander Mitov, Kenkichi Miyabayashi, Akiya Miyamoto, Gagan
  Mohanty, Laura Monaco, Myriam Mondragon, Hugh E. Montgomery, Gudrid
  Moortgat-Pick, Nicolas Morange, Mar\'ia Moreno Llacer, Stefano Moretti,
  Toshinori Mori, Toshiyuki Morii, Takeo Moroi, David Morrissey, Benjamin
  Nachman, Kunihiro Nagano, Jurina Nakajima, Eiji Nakamura, Shinya Narita, Pran
  Nath, Timothy Nelson, David Newbold, Atsuya Niki, Yasuhiro Nishimura, Eisaku
  Nishiyama, Yasunori Nomura, Kacper Nowak, Mitsuaki Nozaki, Mar\'ia Teresa
  Nunez Pardo de Vera, Ines Ochoa, Masahito Ogata, Satoru Ohashi, Hikaru Ohta,
  Shigemi Ohta, Norihito Ohuchi, Hideyuki Oide, Nobuchika Okada, Yasuhiro
  Okada, Shohei Okawa, Yuichi Okayasu, Yuichi Okugawa, Toshiyuki Okugi,
  Takemichi Okui, Yoshitaka Okuyama, Mathieu Omet, Tsunehiko Omori, Hiroaki
  Ono, Tomoki Onoe, Wataru Ootani, Hidetoshi Otono, Shuhei Ozawa, Simone Pagan
  Griso, Alessandro Papa, Rocco Paparella, Eun-Kyung Park, Gilad Perez, Abdel
  Perez-Lorenzana, Yvonne Peters, Frank Petriello, Jonatan Piedra, Werner
  Porod, Christopher Potter, Alan Price, Yasser Radkhorrami, Laura Reina,
  Juergen Reuter, Francois Richard, Sabine Riemann, Robert Rimmer, Thomas
  Rizzo, Tania Robens, Roger Ruber, Alberto Ruiz Jimeno, Takayuki Saeki, Ipsita
  Saha, Tomoyuki Saito, Makoto Sakaguchi, Tadakatsu Sakai, Yasuhito Sakaki,
  Kodai Sakurai, Riccardo Salvatico, Fabrizio Salvatore, Yik Chuen San, Pearl
  Sandick, Tomoyuki Sanuki, Kollassery Swathi Sasikumar, Oliver Schaefer, Ruth
  Schaefer, Uwe Schneekloth, Thomas Schoerner-Sadenius, Carl Schroeder, Philip
  Schuster, Ariel Schwartzman, Reinhard Schwienhorst, Felix Sefkow, Yoshihiro
  Seiya, Motoo Sekiguchi, Kazuyuki Sekizawa, Katsumi Senyo, Hale Sert, Danielev
  Sertore, Ronald Settles, Qaisar Shafi, Tetsuo Shahdara, Barmak Shams Es
  Haghi, Ashish Sharma, Jessie Shelton, Claire Shepherd-Themistocleous, Hiroto
  Shibuya, Tetsuo Shidara, Takashi Shimomura, Tetsuo Shindou, Yutaro Shoji,
  Jing Shu, Ian Sievers, Frank Simon, Rajeev Singh, Yotam Soreq, Marcel
  Stanitzki, Steinar Stapnes, Amanda Steinhebel, John Stupak, Shufang Su,
  Fumihiko Suekane, Akio Sugamoto, Yuji Sugawara, Satoru Sugimoto, Yasuhiro
  Sugimoto, Hiroaki Sugiyama, Yukinari Sumino, Raman Sundrum, Atsuto Suzuki,
  Shin Suzuki, Maximilian Swiatlowski, Tim M. P. Tait, Shota Takahashi, Tohru
  Takahashi, Tohru Takeshita, Michihisa Takeuchi, Yosuke Takubo, Tomohiko
  Tanabe, Philip Tanedo, Morimitsu Tanimoto, Shuichiro Tao, Xerxes Tata,
  Toshiaki Tauchi, Geoffrey Taylor, Takahiro Terada, Nobuhiro Terunuma, Jesse
  Thaler, Alessandro Thea, Finn Tillinger, Jan Timmermans, Kohsaku Tobioka,
  Kouichi Toda, Atsushi Tokiyasu, Takashi Toma, Julie Torndal, Mehmet Tosun,
  Yu-Dai Tsai, Shih-Yen Tseng, Koji Tsumura, Douglas Tuckler, Yoshiki Uchida,
  Yusuke Uchiyama, Daiki Ueda, Fumihiko Ukegawa, Kensei Umemori, Junji Urakawa,
  Claude Vallee, Roberto Vega, Liliana Velasco, Silvia Verdu-Andres, Caterina
  Vernieri, Anna Vila, Ivan Vila Alvarez, Joost Vossebeld, Raghava Vsrms,
  Natasa Vukasinovic, Doreen Wackeroth, Moe Wakida, Liantao Wang, Masakazu
  Washio, Takashi Watanabe, Nigel Watson, Gordon Watts, Georg Weiglein, James
  D. Wells, Marc Wenskat, Susanne Westhoff, Glen White, Ciaran Williams,
  Stephane Willocq, Matthew Wing, Alasdair Winter, Marc Winter, Yongcheng Wu,
  Keping Xie, Tao Xu, Vyacheslav Yakovlev, Shuei Yamada, Akira Yamamoto,
  Hitoshi Yamamoto, Kei Yamamoto, Yasuchika Yamamoto, Masato Yamanaka, Satoru
  Yamashita, Masahiro Yamatani, Naoki Yamatsu, Shigehiro Yasui, Takuya Yoda,
  Ryo Yonamine, Keisuke Yoshihara, Masakazu Yoshioka, Tamaki Yoshioka, Fukuko
  Yuasa, Keita Yumino, Dirk Zerwas, Ya-Juan Zheng, Jia Zhou, Hua Xing Zhu,
  Mikhail Zobov, Fabian Zomer","The International Linear Collider: Report to Snowmass 2021","356 pages, Large pdf file (40 MB) submitted to Snowmass 2021; v2
  references to Snowmass contributions added, additional authors; v3 references
  added, some updates, additional authors",,,"DESY-22-045, IFT--UAM/CSIC--22-028, KEK Preprint 2021-61,
  PNNL-SA-160884, SLAC-PUB-17662","physics.acc-ph hep-ex hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The International Linear Collider (ILC) is on the table now as a new global
energy-frontier accelerator laboratory taking data in the 2030s. The ILC
addresses key questions for our current understanding of particle physics. It
is based on a proven accelerator technology. Its experiments will challenge the
Standard Model of particle physics and will provide a new window to look beyond
it. This document brings the story of the ILC up to date, emphasizing its
strong physics motivation, its readiness for construction, and the opportunity
it presents to the US and the global particle physics community.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 03:35:19 GMT""},{""version"":""v2"",""created"":""Thu, 14 Jul 2022 07:17:32 GMT""},{""version"":""v3"",""created"":""Mon, 16 Jan 2023 19:33:46 GMT""}]","2023-01-18"
"2203.07623","Shawn Westerdale","Daniel Baxter, Raymond Bunker, Sally Shaw, Shawn Westerdale, Isaac
  Arnquist, Daniel S. Akerib, Rob Calkins, Susana Cebri\'an, James B. Dent,
  Maria Laura di Vacri, Jim Dobson, Daniel Egana-Ugrinovic, Andrew Erlandson,
  Chamkaur Ghag, Carter Hall, Jeter Hall, Scott Haselschwardt, Eric Hoppe,
  Chris M. Jackson, Yonatan Kahn, Alvine Kamaha, Mike Kelsey, Alexander Kish,
  Noah Kurinsky, Matthias Laubenstein, Eric H. Miller, Eric Morrison, Brianna
  Mount, Jayden L. Newstead, Stefano Nisi, Ibles Olcina, John Orrell, Sergey
  Pereverzev, Emily Perry, Andreas Piepke, Sagar Sharma Poudel, Karthik
  Ramanathan, Juergen Reichenbacher, Tarek Saab, Richard Saldanha, Claudio
  Savarese, Richard Schnee, Silvia Scorza, Rajeev Singh, Kelly Stifter,
  Burkhant Suerfu, Matthew Szydagis, Dylan J. Temples, Anthony Villano, David
  Woodward, Jingke Xu","Snowmass2021 Cosmic Frontier White Paper: Calibrations and backgrounds
  for dark matter direct detection","Solicited community whitepaper for the Snowmass2021 process (Cosmic
  frontier, particle dark matter working group)",,,,"hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Future dark matter direct detection experiments will reach unprecedented
levels of sensitivity. Achieving this sensitivity will require more precise
models of signal and background rates in future detectors. Improving the
precision of signal and background modeling goes hand-in-hand with novel
calibration techniques that can probe rare processes and lower threshold
detector response. The goal of this white paper is to outline community needs
to meet the background and calibration requirements of next-generation dark
matter direct detection experiments.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 03:41:53 GMT""},{""version"":""v2"",""created"":""Sun, 1 May 2022 05:20:37 GMT""}]","2022-05-03"
"2203.07624","Isabel Garcia Garcia","Patrick Draper, Isabel Garcia Garcia, and Matthew Reece","Snowmass White Paper: Implications of Quantum Gravity for Particle
  Physics","Contribution to Snowmass 2021; 11 pages + references",,,,"hep-ph gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum gravity places important consistency conditions on low-energy
effective field theory, such as the absence of global symmetries. These may
have important consequences in the search for particle physics beyond the
Standard Model. We review some of these conditions and their phenomenological
implications for the strong CP problem, the weak scale, new gauge interactions,
and cosmology. We also offer some general comments on how these ideas can guide
model building.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 03:43:18 GMT""}]","2022-03-16"
"2203.07625","Hamid Ben Yakkou","Hamid Ben Yakkou","On non-monogenic number fields defined by trinomials of type $x^n
  +ax^m+b$","Submitted 15 March 2022",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $K=\Q(\theta)$ be a number field generated by a complex root $\th$ of a
monic irreducible trinomial $F(x) = x^n+ax^{m}+b \in \Z[x]$. In this paper, we
deal with the problem of the non-monogenity of $K$. More precisely, we provide
some explicit conditions on $a$, $b$, $n$, and $m$ for which $K$ is not
monogenic. As application, we show that there are infinite families of
non-monogenic number fields defined by trinomials of degree $n=2^r\cdot3^k$
with $r$ and $k$ are positive integers. We also give two infinite families of
non-monogenic number fields defined by trinomials of degree $6$. Finally, we
illustrate our results by giving some examples.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 03:44:58 GMT""}]","2022-03-16"
"2203.07626","Caterina Vernieri","Nicole Apadula, Whitney Armstrong, James Brau, Martin Breidenbach, R.
  Caputo, Gabriella Carinii, Alberto Collu, Marcel Demarteau, Grzegorz Deptuch,
  Angelo Dragone, Gabriele Giacomini, Carl Grace, Norman Graf, Leo Greiner,
  Ryan Herbst, Gunther Haller, Manoj Jadhav, Sylvester Joosten, Christopher J.
  Kenney, C. Kierans, Jihee Kim, Thomas Markiewicz, Yuan Mei, Jessica Metcalfe,
  Zein-Eddine Meziani, Tim K. Nelson, Chao Peng, Giovanni Pinaroli, Paul E.
  Reimer, Lorenzo Rota, Marshall Scott, Julie Segal, Ernst Sichterman, Nikolai
  Sinev, A. Steinhebel, David Strom, Alessandro Tricoli, Caterina Vernieri,
  Charles Young, Maria Zurek","Monolithic Active Pixel Sensors on CMOS technologies","25 pages, 18 figures, contribution to Snowmass 2021",,,,"physics.ins-det hep-ex nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Collider detectors have taken advantage of the resolution and accuracy of
silicon detectors for at least four decades. Future colliders will need large
areas of silicon sensors for low mass trackers and sampling calorimetry.
Monolithic Active Pixel Sensors (MAPS), in which Si diodes and readout
circuitry are combined in the same pixels, and can be fabricated in some of
standard CMOS processes, are a promising technology for high-granularity and
light detectors. In this paper we review 1) the requirements on MAPS for
trackers and electromagnetic calorimeters (ECal) at future colliders
experiments, 2) the ongoing efforts towards dedicated MAPS for the Electron-Ion
Collider (EIC) at BNL, for which the EIC Silicon Consortium was already
instantiated, and 3) space-born applications for MeV $\gamma$-ray experiments
with MAPS based trackers (AstroPix).
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 03:47:39 GMT""},{""version"":""v2"",""created"":""Tue, 29 Mar 2022 03:31:09 GMT""}]","2022-03-30"
"2203.07627","Yong Cheng","Yong Cheng, Ankur Bapna, Orhan Firat, Yuan Cao, Pidong Wang, Wolfgang
  Macherey","Multilingual Mix: Example Interpolation Improves Multilingual Neural
  Machine Translation","ACL 2022",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multilingual neural machine translation models are trained to maximize the
likelihood of a mix of examples drawn from multiple language pairs. The
dominant inductive bias applied to these models is a shared vocabulary and a
shared set of parameters across languages; the inputs and labels corresponding
to examples drawn from different language pairs might still reside in distinct
sub-spaces. In this paper, we introduce multilingual crossover encoder-decoder
(mXEncDec) to fuse language pairs at an instance level. Our approach
interpolates instances from different language pairs into joint `crossover
examples' in order to encourage sharing input and output spaces across
languages. To ensure better fusion of examples in multilingual settings, we
propose several techniques to improve example interpolation across dissimilar
languages under heavy data imbalance. Experiments on a large-scale WMT
multilingual dataset demonstrate that our approach significantly improves
quality on English-to-Many, Many-to-English and zero-shot translation tasks
(from +0.5 BLEU up to +5.5 BLEU points). Results on code-switching sets
demonstrate the capability of our approach to improve model generalization to
out-of-distribution multilingual examples. We also conduct qualitative and
quantitative representation comparisons to analyze the advantages of our
approach at the representation level.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 03:56:22 GMT""}]","2022-03-16"
"2203.07628","Wenkang Shan","Wenkang Shan, Zhenhua Liu, Xinfeng Zhang, Shanshe Wang, Siwei Ma, Wen
  Gao","P-STMO: Pre-Trained Spatial Temporal Many-to-One Model for 3D Human Pose
  Estimation","ECCV 2022",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces a novel Pre-trained Spatial Temporal Many-to-One
(P-STMO) model for 2D-to-3D human pose estimation task. To reduce the
difficulty of capturing spatial and temporal information, we divide this task
into two stages: pre-training (Stage I) and fine-tuning (Stage II). In Stage I,
a self-supervised pre-training sub-task, termed masked pose modeling, is
proposed. The human joints in the input sequence are randomly masked in both
spatial and temporal domains. A general form of denoising auto-encoder is
exploited to recover the original 2D poses and the encoder is capable of
capturing spatial and temporal dependencies in this way. In Stage II, the
pre-trained encoder is loaded to STMO model and fine-tuned. The encoder is
followed by a many-to-one frame aggregator to predict the 3D pose in the
current frame. Especially, an MLP block is utilized as the spatial feature
extractor in STMO, which yields better performance than other methods. In
addition, a temporal downsampling strategy is proposed to diminish data
redundancy. Extensive experiments on two benchmarks show that our method
outperforms state-of-the-art methods with fewer parameters and less
computational overhead. For example, our P-STMO model achieves 42.1mm MPJPE on
Human3.6M dataset when using 2D poses from CPN as inputs. Meanwhile, it brings
a 1.5-7.1 times speedup to state-of-the-art methods. Code is available at
https://github.com/paTRICK-swk/P-STMO.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 04:00:59 GMT""},{""version"":""v2"",""created"":""Fri, 29 Jul 2022 03:59:40 GMT""}]","2022-08-01"
"2203.07629","Liam McAllister","Raphael Flauger, Victor Gorbenko, Austin Joyce, Liam McAllister, Gary
  Shiu, Eva Silverstein","Snowmass White Paper: Cosmology at the Theory Frontier","Contribution to Snowmass 2021",,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The precision cosmological model describing the origin and expansion history
of the universe, with observed structure seeded at the inflationary cosmic
horizon, demands completion in the ultraviolet and in the infrared. The
dynamics of the cosmic horizon also suggests an associated entropy, again
requiring a microphysical theory. Recent years have seen enormous progress in
understanding the structure of de Sitter space and inflation in string theory,
and of cosmological observables captured by quantum field theory and solvable
deformations thereof. The resulting models admit ongoing observational tests
through measurements of the cosmic microwave background and large-scale
structure, as well as through analyses of theoretical consistency by means of
thought experiments. This paper, prepared for the TF01 and TF09 conveners of
the Snowmass 2021 process, provides a synopsis of this important area, focusing
on ongoing developments and opportunities.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 04:04:54 GMT""}]","2022-03-16"
"2203.07630","Jie Hong","Jie Hong, Mats Carlsson, M. D. Ding","An approximate recipe of chromospheric radiative losses for solar flares","7 pages, 6 figures, 2 tables. A&A accepted. The lookup tables of the
  fitted curves are available in http://sdc.nju.edu.cn/d/8f8ef25c91684926ae3c","A&A 661, A77 (2022)","10.1051/0004-6361/202142839",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Radiative losses in the chromosphere are very important in the energy
balance. There have been efforts to make simple lookup tables for chromospheric
radiative losses in the quiet Sun. During solar flares, the atmospheric
conditions are quite different, and the currently available recipe of Gan &
Fang (1990) is constructed from semi-empirical models. It remains to be
evaluated how these recipes work in flare conditions. We aim to construct an
approximate recipe of chromospheric radiative losses for solar flares. We
follow the method of Carlsson & Leenaarts (2012) to tabulate the optically thin
radiative loss, escape probability, and ionization fraction, while using a grid
of flare models from radiative hydrodynamic simulations as our dataset. We
provide new lookup tables to calculate chromospheric radiative losses for
flares. Compared with previous recipes, our recipe provides a better
approximation to the detailed radiative losses for flares.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 04:05:28 GMT""}]","2022-05-04"
"2203.07631","Takahiro Chiba","Takahiro Chiba, Ryo Iguchi, Takashi Komine, Yasuhiro Hasegawa,
  Ken-ichi Uchida","Temperature profile of the Thomson-effect-induced heat
  release/absorption in junctionless single conductors","15 pages, 7 figures, 2 tables","Japanese Journal of Applied Physics 2023","10.35848/1347-4065/acc3e6",,"cond-mat.mtrl-sci cond-mat.mes-hall physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Thomson effect induces heat release or absorption under the simultaneous
application of a charge current and a temperature gradient to conductors. Here,
we theoretically investigate the temperature profile due to the
Thomson-effect-induced heat release/absorption in junctionless single
conductors which can be a simple temperature modulator. We also perform
analysis of the temperature profile for realistic conductors. As a result, we
find that, for a conductor with a large Thomson coefficient, the temperature
derivative of the Seebeck coefficient, the Thomson-effect-induced heat
absorption overcomes the Joule heating, resulting in current-induced cooling in
the bulk region. We also elucidate that a feedback effect of the Thomson effect
stabilizes the system temperature to one-side of the heat bath, which reflects
the fact that the Thomson effect is dependent on the position and proportional
to the local temperature gradient. This work will be the basis for thermal
management utilizing the Thomson effect.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 04:08:58 GMT""},{""version"":""v2"",""created"":""Thu, 5 Jan 2023 02:30:46 GMT""},{""version"":""v3"",""created"":""Thu, 16 Mar 2023 01:42:40 GMT""}]","2023-03-17"
"2203.07632","Tiantian Chen","Tiantian Chen, Jianxiong Guo and Weili Wu","Graph Representation Learning for Popularity Prediction Problem: A
  Survey","30 pages, 4 figures","Discrete Mathematics, Algorithms and Applications, 2022","10.1142/S179383092230003X",,"cs.SI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The online social platforms, like Twitter, Facebook, LinkedIn and WeChat,
have grown really fast in last decade and have been one of the most effective
platforms for people to communicate and share information with each other. Due
to the ""word of mouth"" effects, information usually can spread rapidly on these
social media platforms. Therefore, it is important to study the mechanisms
driving the information diffusion and quantify the consequence of information
spread. A lot of efforts have been focused on this problem to help us better
understand and achieve higher performance in viral marketing and advertising.
On the other hand, the development of neural networks has blossomed in the last
few years, leading to a large number of graph representation learning (GRL)
models. Compared to traditional models, GRL methods are often shown to be more
effective. In this paper, we present a comprehensive review for existing works
using GRL methods for popularity prediction problem, and categorize related
literatures into two big classes, according to their mainly used model and
techniques: embedding-based methods and deep learning methods. Deep learning
method is further classified into six small classes: convolutional neural
networks, graph convolutional networks, graph attention networks, graph neural
networks, recurrent neural networks, and reinforcement learning. We compare the
performance of these different models and discuss their strengths and
limitations. Finally, we outline the challenges and future chances for
popularity prediction problem.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 04:11:46 GMT""},{""version"":""v2"",""created"":""Fri, 1 Jul 2022 18:05:37 GMT""}]","2023-05-17"
"2203.07633","Jun Gao","Jun Gao, Wei Wang, Changlong Yu, Huan Zhao, Wilfred Ng, Ruifeng Xu","Improving Event Representation via Simultaneous Weakly Supervised
  Contrastive Learning and Clustering","ACL 2022",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Representations of events described in text are important for various tasks.
In this work, we present SWCC: a Simultaneous Weakly supervised Contrastive
learning and Clustering framework for event representation learning. SWCC
learns event representations by making better use of co-occurrence information
of events. Specifically, we introduce a weakly supervised contrastive learning
method that allows us to consider multiple positives and multiple negatives,
and a prototype-based clustering method that avoids semantically related events
being pulled apart. For model training, SWCC learns representations by
simultaneously performing weakly supervised contrastive learning and
prototype-based clustering. Experimental results show that SWCC outperforms
other baselines on Hard Similarity and Transitive Sentence Similarity tasks. In
addition, a thorough analysis of the prototype-based clustering method
demonstrates that the learned prototype vectors are able to implicitly capture
various relations between events.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 04:12:00 GMT""}]","2022-03-16"
"2203.07634","Fernando Comer\'on","F. Comer\'on, A.A. Djupvik, N. Schneider","The extended population associated with W40","Submitted to Astronomy and Astrophysics",,"10.1051/0004-6361/202243416",,"astro-ph.SR astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  W40 is a heavily obscured bipolar HII region projected in the direction of
the Aquila Rift and ionized by hot stars in a central, partly embedded cluster.
The study of the cluster and its surroundings has been greatly hampered thus
far by the strong extinction in the region. We use the Gaia eDR3 catalog to
establish astrometric membership criteria based on the population of the W40
central cluster, reassess the distance of the region, and identify in this way
new members, both inside and outside the cluster. We obtain visible
spectroscopy in the red spectral region to classify both known and new members,
complemented with Gaia and Spitzer photometry to assess the evolutionary status
of the stellar population. We derive a high-confidence geometric distance to
the W40 region of 502 pc $\pm$ 4 pc and confirm the presence of a comoving
extended population of stars at the same distance, spreading over the whole
projected area of the HII region and beyond. Spectral classifications are
presented for 21 members of the W40 region, 10 of them belonging to the central
cluster. One of the newly identified B stars in the extended population is
clearly interacting with the shell surrounding the HII region, giving rise to a
small arc-shaped nebula that traces a bow shock. The infrared excess properties
suggest that the extended population is significantly older ($\sim 3$ Myr) than
the W40 central cluster ($< 1$ Myr). The area currently occupied by the W40 HII
region and its surroundings has a history of star formation extending at least
several million years in the past, of which the formation of the W40 central
cluster and the subsequent HII region is one of the latest episodes. The newly
determined distance suggests that W40 is behind, and physically detached from,
a pervasive large dust layer which is some 60 pc foreground to it as determined
by previous studies.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 04:13:47 GMT""}]","2022-09-21"
"2203.07635","Libao Shi","Haoxin Wang, Libao Shi","A theoretical framework and some promising findings of grey wolf
  optimizer, part I: analytical model of sampling distribution and stability
  analysis","34 pages,13 figures",,,,"math.OC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper proposes a theoretical framework of the grey wolf optimizer (GWO)
based on several interesting theoretical findings, involving sampling
distribution, order-1 and order-2 stability, and global convergence analysis.
In the part I of the paper, the characteristics of the sampling distribution of
the new solution and the probabilistic stability of the GWO are carefully
discussed based on the well-known stagnation assumption for simplification
purposes. Firstly, the characteristics of the sampling distribution of the new
solution, mainly related to the shape of the joint probability density function
(PDF), are discussed under the assumption that the original solution before
updating is constant. Then, the assumption that the original solution is
constant is eliminated to perform the sampling distribution analysis, based on
which several characteristics of the new solution are provided, containing the
shape of the joint PDF and central moments of any positive integer order.
Finally, the order-1 and order-2 stability of the GWO under stagnation
assumption is introduced and proved as the inference of conclusions above,
which are all verified by numerical simulations.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 04:17:55 GMT""}]","2022-03-16"
"2203.07636","Libao Shi","Haoxin Wang, Libao Shi","A theoretical framework and some promising findings of grey wolf
  optimizer, part II: global convergence analysis","29 pages,10 figures",,,,"math.OC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper proposes a theoretical framework of the grey wolf optimizer (GWO)
based on several interesting theoretical findings, involving sampling
distribution, order-1 and order-2 stability, and global convergence analysis.
In the part II of the paper, the global convergence analysis is carried out
based on the well-known stagnation assumption for simplification purposes.
Firstly, the global convergence property of the GWO under stagnation assumption
is abstracted and modelled into two propositions, corresponding to global
searching ability analysis and probability-1 global convergence analysis. Then,
the global searching ability analysis is carried out. Next, based on a
characteristic of the central moments of the new solution of the GWO under
stagnation assumption, the probability-1 global convergence property of the GWO
under stagnation assumption is proved. Finally, all conclusions are verified by
numerical simulations, and the corresponding discussions that the global
convergence property can still be guaranteed in the original GWO without
stagnation assumption are given.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 04:21:20 GMT""}]","2022-03-16"
"2203.07637","Ilqar Ramazanli","Ilqar Ramazanli","Lifelong Matrix Completion with Sparsity-Number",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Matrix completion problem has been previously studied under various adaptive
and passive settings. Previously, researchers have proposed passive, two-phase
and single-phase algorithms using coherence parameter, and multi phase
algorithm using sparsity-number. It has been shown that the method using
sparsity-number reaching to theoretical lower bounds in many conditions.
However, the aforementioned method is running in many phases through the matrix
completion process, therefore it makes much more informative decision at each
stage. Hence, it is natural that the method outperforms previous algorithms. In
this paper, we are using the idea of sparsity-number and propose and
single-phase column space recovery algorithm which can be extended to two-phase
exact matrix completion algorithm. Moreover, we show that these methods are as
efficient as multi-phase matrix recovery algorithm. We provide experimental
evidence to illustrate the performance of our algorithm.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 04:27:52 GMT""},{""version"":""v2"",""created"":""Wed, 16 Mar 2022 00:51:44 GMT""}]","2022-03-17"
"2203.07638","Clarence Chang","Clarence L. Chang, Kevin M. Huffenberger, Bradford A. Benson, Federico
  Bianchini, Jens Chluba, Jacques Delabrouille, Raphael Flauger, Shaul Hanany,
  William C. Jones, Alan J. Kogut, Jeffrey J. McMahon, Joel Meyers, Neelima
  Sehgal, Sara M. Simon, Caterina Umilta, Kevork N. Abazajian, Zeeshan Ahmed,
  Yashar Akrami, Adam J. Anderson, Behzad Ansarinejad, Jason Austermann, Carlo
  Baccigalupi, Denis Barkats, Darcy Barron, Peter S. Barry, Nicholas Battaglia,
  Eric Baxter, Dominic Beck, Amy N. Bender, Charles Bennett, Benjamin Beringue,
  Colin Bischoff, Lindsey Bleem, James Bock, Boris Bolliet, J Richard Bond,
  Julian Borrill, Thejs Brinckmann, Michael L. Brown, Erminia Calabrese, John
  Carlstrom, Anthony Challinor, Chihway Chang, Yuji Chinone, Susan E. Clark,
  William Coulton, Ari Cukierman, Francis-Yan Cyr-Racine, Shannon M. Duff, Cora
  Dvorkin, Alexander van Engelen, Josquin Errard, Johannes R. Eskilt, Thomas
  Essinger-Hileman, Giulio Fabbian, Chang Feng, Simone Ferraro, Jeffrey
  Filippini, Katherine Freese, Nicholas Galitzki, Eric Gawiser, Daniel Grin,
  Daniel Grin, Evan Grohs, Alessandro Gruppuso, Jon E. Gudmundsson, Nils W.
  Halverson, Jean-Christophe Hamilton, Kathleen Harrington, Sophie
  Henrot-Versill\'e, Brandon Hensley, J. Colin Hill, Adam D. Hincks, Renee
  Hlozek, William Holzapfel, Selim C. Hotinli, Howard Hui, Ayodeji Ibitoye,
  Matthew Johnson, Bradley R. Johnson, Jae Hwan Kang, Kirit S. Karkare, Lloyd
  Knox, John Kovac, Kenny Lau, Louis Legrand, Marilena Loverde, Philip Lubin,
  Yin-Zhe Ma, Tony Mroczkowski, Suvodip Mukherjee, Moritz M\""unchmeyer, Daisuke
  Nagai, Johanna Nagy, Michael Niemack, Valentine Novosad, Yuuki Omori, Giorgio
  Orlando, Zhaodi Pan, Laurence Perotto, Matthew A. Petroff, Levon Pogosian,
  Clem Pryke, Alexandra Rahlin, Marco Raveri, Christian L. Reichardt, Mathieu
  Remazeilles, Yoel Rephaeli, John Ruhl, Emmanuel Schaan, Sarah Shandera, Meir
  Shimon, Ahmed Soliman, Antony A. Stark, Glenn D. Starkman, Radek Stompor,
  Ritoban Basu Thakur, Cynthia Trendafilova, Matthieu Tristram, Pranjal
  Trivedi, Gregory Tucker, Eleonora Di Valentino, Joaquin Vieira, Abigail
  Vieregg, Gensheng Wang, Scott Watson, Lukas Wenzl, Edward J. Wollack, W.L.
  Kimmy Wu, Zhilei Xu, David Zegeye, Cheng Zhang","Snowmass2021 Cosmic Frontier: Cosmic Microwave Background Measurements
  White Paper","contribution to Snowmass 2021",,,,"astro-ph.CO astro-ph.IM gr-qc hep-ex hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This is a solicited whitepaper for the Snowmass 2021 community planning
exercise. The paper focuses on measurements and science with the Cosmic
Microwave Background (CMB). The CMB is foundational to our understanding of
modern physics and continues to be a powerful tool driving our understanding of
cosmology and particle physics. In this paper, we outline the broad and unique
impact of CMB science for the High Energy Cosmic Frontier in the upcoming
decade. We also describe the progression of ground-based CMB experiments, which
shows that the community is prepared to develop the key capabilities and
facilities needed to achieve these transformative CMB measurements.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 04:30:40 GMT""}]","2022-03-16"
"2203.07639","Kai Wu","Kai Wu and J. Andrew Zhang and Y. Jay Guo","Fast and Accurate Linear Fitting for Incompletely Sampled Gaussian
  Function With a Long Tail","7 pages; 3 figures; 2 tables; accepted to be published in IEEE Signal
  Processing Magazine. Simulation codes can be downloaded from the link
  provided in the paper. Should you use the codes in any way, please cite this
  work. Thanks for your interest",,"10.1109/MSP.2022.3194692",,"eess.SP cs.NA math.NA physics.ins-det","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Fitting experiment data onto a curve is a common signal processing technique
to extract data features and establish the relationship between variables.
Often, we expect the curve to comply with some analytical function and then
turn data fitting into estimating the unknown parameters of a function. Among
analytical functions for data fitting, Gaussian function is the most widely
used one due to its extensive applications in numerous science and engineering
fields. To name just a few, Gaussian function is highly popular in statistical
signal processing and analysis, thanks to the central limit theorem [1];
Gaussian function frequently appears in the quantum harmonic oscillator,
quantum field theory, optics, lasers, and many other theories and models in
Physics [2]; moreover, Gaussian function is widely applied in chemistry for
depicting molecular orbitals, in computer science for imaging processing and in
artificial intelligence for defining neural networks.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 04:30:45 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jul 2022 12:10:52 GMT""}]","2022-11-23"
"2203.07640","Rishabh Joshi","Rishabh Joshi and Vidhisha Balachandran and Emily Saldanha and Maria
  Glenski and Svitlana Volkova and Yulia Tsvetkov","Unsupervised Keyphrase Extraction via Interpretable Neural Networks","Accepted at EACL 2023",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Keyphrase extraction aims at automatically extracting a list of ""important""
phrases representing the key concepts in a document. Prior approaches for
unsupervised keyphrase extraction resorted to heuristic notions of phrase
importance via embedding clustering or graph centrality, requiring extensive
domain expertise. Our work presents a simple alternative approach which defines
keyphrases as document phrases that are salient for predicting the topic of the
document. To this end, we propose INSPECT -- an approach that uses
self-explaining models for identifying influential keyphrases in a document by
measuring the predictive impact of input phrases on the downstream task of the
document topic classification. We show that this novel method not only
alleviates the need for ad-hoc heuristics but also achieves state-of-the-art
results in unsupervised keyphrase extraction in four datasets across two
domains: scientific publications and news articles.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 04:30:47 GMT""},{""version"":""v2"",""created"":""Fri, 17 Feb 2023 17:43:18 GMT""}]","2023-02-20"
"2203.07641","Fernando Comer\'on","F. Comer\'on, N. Schneider, A.A. Djupvik","Star formation in two irradiated globules around Cygnus OB2","Accepted for publication by Astronomy and Astrophysics",,"10.1051/0004-6361/202243142",,"astro-ph.SR astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We investigate the young stellar populations associated with DR 18 and ECX
6-21, which are two isolated globules irradiated by the O-type stars of the
Cygnus OB2 association. Both are HII regions containing obvious tracers of
recent and ongoing star formation. We also study smaller isolated molecular
structures in their surroundings. Both globules contain their own embedded
populations, with a higher fraction of the less-evolved classes. Masses and
temperatures are estimated under the assumption of a common age of 1 Myr, which
has been found to appropriately represent the general Cygnus OB2 YSO population
but is most probably an overestimate for both globules, especially ECX 6-21.
The early-B star responsible for the erosion of DR 18 is found to be part of a
small aggregate of intermediate-mass stars still embedded in the cloud, which
probably contains a second site of recent star formation, also with
intermediate-mass stars. We confirm the two main star forming sites embedded in
ECX 6-21 described in previous works, with the southern site being more evolved
than the northern site. We also discuss the small globule ECX 6-21-W ($=
G79.8+1.2$), and propose that its non thermal radio spectrum is due to
synchrotron emission from an embedded jet, whose existence is suggested by our
observations. The extreme youth of some of the YSOs suggests that star
formation in both globules started after they became externally irradiated. The
populations of both globules are not found to be particularly rich, but they
contain stars with estimated masses similar or above that of the Sun in numbers
that hint at some differences with respect to the star formation process taking
place in more quiescent regions where low-mass stars dominate, which deeper
observations may confirm.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 04:34:16 GMT""}]","2022-04-27"
"2203.07642","Matthew Belyakov","Matthew Belyakov, Pedro H. Bernardinelli and Michael E. Brown","Limits on the Detection of Planet Nine in the Dark Energy Survey","8 pages, 5 figures. Accepted for publication in AJ",,"10.3847/1538-3881/ac5c56",,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  Studies of the clustering of the most distant Kuiper belt objects in the
outer solar system have hinted at the possible existence of a planet beyond
Neptune referred to as Planet Nine (P9). Recent efforts have constrained the
parameter space of the orbital elements of P9, allowing for the creation of a
synthetic catalog of hypothetical P9s. By examining the potential recovery of
such a catalog within numerous sky surveys, it is possible to further constrain
the parameter space for P9, providing direction for a more targeted search. We
examine the ability of the full six years of the Dark Energy Survey (DES) to
recover a synthetic Planet Nine population presented in Brown and Batygin
(2021a) [arXiv:2108.09868]. We find that out of 100,000 simulated objects,
11,709 cross the wide DES survey footprint of which 10,187 (87.0%) are
recovered. This rules out an additional 5% of the parameter space after
accounting for Planets Nine that would have been detected by both the Zwicky
Transient Facility and DES.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 04:35:50 GMT""}]","2022-04-20"
"2203.07643","Eleftheria Briakou","Eleftheria Briakou and Marine Carpuat","Can Synthetic Translations Improve Bitext Quality?","ACL 2022",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Synthetic translations have been used for a wide range of NLP tasks primarily
as a means of data augmentation. This work explores, instead, how synthetic
translations can be used to revise potentially imperfect reference translations
in mined bitext. We find that synthetic samples can improve bitext quality
without any additional bilingual supervision when they replace the originals
based on a semantic equivalence classifier that helps mitigate NMT noise. The
improved quality of the revised bitext is confirmed intrinsically via human
evaluation and extrinsically through bilingual induction and MT tasks.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 04:36:29 GMT""}]","2022-03-16"
"2203.07644","Xiangyang Mou","Xiangyang Mou, Mo Yu, Bingsheng Yao, Lifu Huang","Efficient Long Sequence Encoding via Synchronization","5 pages, short paper",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Pre-trained Transformer models have achieved successes in a wide range of NLP
tasks, but are inefficient when dealing with long input sequences. Existing
studies try to overcome this challenge via segmenting the long sequence
followed by hierarchical encoding or post-hoc aggregation. We propose a
synchronization mechanism for hierarchical encoding. Our approach first
identifies anchor tokens across segments and groups them by their roles in the
original input sequence. Then inside Transformer layer, anchor embeddings are
synchronized within their group via a self-attention module. Our approach is a
general framework with sufficient flexibility -- when adapted to a new task, it
is easy to be enhanced with the task-specific anchor definitions. Experiments
on two representative tasks with different types of long input texts,
NarrativeQA summary setting and wild multi-hop reasoning from HotpotQA,
demonstrate that our approach is able to improve the global information
exchange among segments while maintaining efficiency.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 04:37:02 GMT""}]","2022-03-16"
"2203.07645","Maria Elena Monzani","Dave Casper, Maria Elena Monzani, Benjamin Nachman, Costas
  Andreopoulos, Stephen Bailey, Deborah Bard, Wahid Bhimji, Giuseppe Cerati,
  Grigorios Chachamis, Jacob Daughhetee, Miriam Diamond, V. Daniel Elvira,
  Alden Fan, Krzysztof Genser, Paolo Girotti, Scott Kravitz, Robert Kutschke,
  Vincent R. Pascuzzi, Gabriel N. Perdue, Erica Snider, Elizabeth
  Sexton-Kennedy, Graeme Andrew Stewart, Matthew Szydagis, Eric Torrence,
  Christopher Tunnell","Software and Computing for Small HEP Experiments","Contribution to Snowmass 2021",,,"FERMILAB-CONF-22-138","hep-ex physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  This white paper briefly summarized key conclusions of the recent US
Community Study on the Future of Particle Physics (Snowmass 2021) workshop on
Software and Computing for Small High Energy Physics Experiments.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 04:40:18 GMT""},{""version"":""v2"",""created"":""Mon, 28 Mar 2022 02:01:14 GMT""},{""version"":""v3"",""created"":""Tue, 27 Dec 2022 18:25:45 GMT""}]","2022-12-29"
"2203.07646","Caterina Vernieri","Sridhara Dasu, Emilio A. Nanni, Michael E. Peskin, Caterina Vernieri
  and Tim Barklow, Rainer Bartoldus, Pushpalatha C. Bhat, Kevin Black, Jim
  Brau, Martin Breidenbach, Nathaniel Craig, Dmitri Denisov, Lindsey Gray,
  Philip C. Harris, Michael Kagan, Zhen Liu, Patrick Meade, Nathan Majernik,
  Sergei Nagaitsev, Isobel Ojalvo, Christoph Paus, Carl Schroeder, Ariel G.
  Schwartzman, Jan Strube, Su Dong, Sami Tantawi, LianTao Wang, Andy White,
  Graham W. Wilson","Strategy for Understanding the Higgs Physics: The Cool Copper Collider","11 pages, 2 figures, contribution to Snowmass 2021",,,"SLAC-PUB-17661","hep-ex physics.acc-ph physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A program to build a lepton-collider Higgs factory, to precisely measure the
couplings of the Higgs boson to other particles, followed by a higher energy
run to establish the Higgs self-coupling and expand the new physics reach, is
widely recognized as a primary focus of modern particle physics. We propose a
strategy that focuses on a new technology and preliminary estimates suggest
that can lead to a compact, affordable machine. New technology investigations
will provide much needed enthusiasm for our field, resulting in trained
workforce. This cost-effective, compact design, with technologies useful for a
broad range of other accelerator applications, could be realized as a project
in the US. Its technology innovations, both in the accelerator and the
detector, will offer unique and exciting opportunities to young scientists.
Moreover, cost effective compact designs, broadly applicable to other fields of
research, are more likely to obtain financial support from our funding
agencies.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 04:48:05 GMT""},{""version"":""v2"",""created"":""Tue, 7 Jun 2022 17:13:03 GMT""}]","2022-06-08"
"2203.07647","Salvador Barraza-Lopez","Joseph E. Roll, John M. Davis, John W. Villanova, and Salvador
  Barraza-Lopez","Elasticity of 2D ferroelectrics across their paraelectric phase
  transformation","5 pages, 4 figures. Originally submitted on January 11, 2022","Phys Rev B 105, 214105 (2022)","10.1103/PhysRevB.105.214105",,"cond-mat.mtrl-sci cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  The mechanical behavior of two-dimensional (2D) materials across 2D phase
changes is unknown, and the finite temperature ($T$) elasticity of paradigmatic
SnSe monolayers -- ferroelectric 2D materials turning paraelectric as their
unit cell (u.c.) turns from a rectangle onto a square -- is described here in a
progressive manner. To begin with, their zero$-T$ {\em elastic energy
landscape} gives way to (Boltzmann-like) averages from which the elastic
behavior is determined. These estimates are complemented with results from the
strain-fluctuation method, which employs the energy landscape or {\em ab
initio} molecular dynamics (MD) data. Both approaches capture the coalescence
of elastic moduli $\langle C_{11}(T)\rangle=\langle C_{22}(T)\rangle$ due to
the structural transformation. The broad evolution and sudden changes of
elastic parameters $\langle C_{11}(T)\rangle$, $\langle C_{22}(T)\rangle$, and
$\langle C_{12}(T)\rangle$ of these atomically-thin phase-change membranes
establishes a heretofore overlooked connection among 2D materials and soft
matter.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 04:59:11 GMT""}]","2022-06-15"
"2203.07648","Chiyu Zhang","Chiyu Zhang, Muhammad Abdul-Mageed, Ganesh Jawahar","Contrastive Learning of Sociopragmatic Meaning in Social Media","Final camera-ready version for ACL2023",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Recent progress in representation and contrastive learning in NLP has not
widely considered the class of \textit{sociopragmatic meaning} (i.e., meaning
in interaction within different language communities). To bridge this gap, we
propose a novel framework for learning task-agnostic representations
transferable to a wide range of sociopragmatic tasks (e.g., emotion, hate
speech, humor, sarcasm). Our framework outperforms other contrastive learning
frameworks for both in-domain and out-of-domain data, across both the general
and few-shot settings. For example, compared to two popular pre-trained
language models, our method obtains an improvement of $11.66$ average $F_1$ on
$16$ datasets when fine-tuned on only $20$ training samples per dataset.Our
code is available at: https://github.com/UBC-NLP/infodcl
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 05:07:04 GMT""},{""version"":""v2"",""created"":""Wed, 25 May 2022 04:33:07 GMT""},{""version"":""v3"",""created"":""Fri, 14 Oct 2022 04:33:54 GMT""},{""version"":""v4"",""created"":""Wed, 3 May 2023 07:59:12 GMT""},{""version"":""v5"",""created"":""Thu, 25 May 2023 00:33:47 GMT""}]","2023-05-26"
"2203.07649","Shunsuke Sato","Wenwen Mao and Angel Rubio and Shunsuke A. Sato","Terahertz-induced high-order harmonic generation and nonlinear charge
  transport in graphene",,"Phys. Rev. B 106, 024313 (2022)","10.1103/PhysRevB.106.024313",,"cond-mat.mes-hall physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We theoretically study the THz-induced high-order harmonic generation (HHG)
and nonlinear electric transport in graphene based on the quantum master
equation with the relaxation time approximation. To obtain microscopic insight
into the phenomena, we compare the results of the fully dynamical calculations
with those under a quasi-static approximation, where the electronic system is
approximated as a nonequilibrium steady state. As a result, we find that the
THz-induced electron dynamics in graphene can be accurately modeled with the
nonequilibrium steady-state at each instance. The population distribution
analysis further clarifies that the THz-induced HHG in graphene originates from
the reduction of effective conductivity due to a large displacement of
electrons in the Brillouin zone. By comparing the present nonequilibrium
picture with a thermodynamic picture, we explore the role of the nonequilibrium
nature of electron dynamics on the extremely nonlinear optical and transport
phenomena in graphene.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 05:07:53 GMT""},{""version"":""v2"",""created"":""Mon, 1 Aug 2022 02:14:46 GMT""}]","2022-08-02"
"2203.07650","Daren Chen","Daren Chen","Floer lasagna modules from link Floer homology","26 pages, 19 figures",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we introduce the notion of Floer lasagna modules, which is
inspired by the construction of skein lasagna module in [MWW19] by Morrison,
Walker and Wedrich. Here we use link Floer homology instead of
Khovanov-Rozansky homology. We give a description of the Floer lasagna module
for 4-manifolds obtained by adding 2-handles to the 4-ball and we compute some
examples.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 05:18:57 GMT""}]","2022-03-16"
"2203.07651","Corrado Gatto","REDTOP Collaboration","The REDTOP experiment: Rare $\eta/\eta^{\prime}$ Decays To Probe New
  Physics","Contribution to Snowmass 2021",,,,"hep-ex hep-ph","http://creativecommons.org/licenses/by/4.0/","  The $\eta$ and $\eta^{\prime}$ mesons are nearly unique in the particle
universe since they are almost Goldstone bosons and the dynamics of their
decays are strongly constrained. The integrated $\eta$-meson samples collected
in earlier experiments amount to $\sim10^{9}$ events. A new experiment, REDTOP
(Rare Eta Decays To Probe New Physics), is being proposed, with the intent of
collecting a data sample of order 10$^{14}$ $\eta$ (10$^{12}$ $\eta^{\prime}$)
for studying very rare decays. Such statistics are sufficient for investigating
several symmetry violations, and for searching for particles and fields beyond
the Standard Model. In this work we present several studies evaluating REDTOP
sensitivity to processes that couple the Standard Model to New Physics through
all four of the so-called \emph{portals}: the Vector, the Scalar, the Axion and
the Heavy Lepton portal. The sensitivity of the experiment is also adequate for
probing several conservation laws, in particular $CP$, $T$ and Lepton
Universality, and for the determination of the $\eta$ form factors, which is
crucial for the interpretation of the recent measurement of muon $g-2$.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 05:23:38 GMT""},{""version"":""v2"",""created"":""Sat, 16 Jul 2022 17:22:13 GMT""},{""version"":""v3"",""created"":""Wed, 7 Sep 2022 11:57:17 GMT""}]","2022-09-08"
"2203.07652","Vieri Mastropietro","Vieri Mastropietro","Nonperturbative renormalization of the lattice Sommerfield vector model","4 pages, 2 pictures; accepted version by Phys Rev D",,"10.1103/PhysRevD.105.114502",,"hep-th math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  The lattice Sommerfield model, describing a massive vector gauge field
coupled to a light fermion in 2d, is an ideal candidate to verify perturbative
conclusions. In contrast with continuum exact solutions, we prove that there is
no infinite field renormalization, implying the reduction of the degree of the
ultraviolet divergence, and that anomalies are non renormalized. Such features
are the counterpart of analogue properties at the basis of the Standard model
perturbative renormalizability. The results are non-perturbative, in the sense
that the averages of gauge invariant observables are expressed in terms of
convergent expansions uniformly in the lattice and volume.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 05:25:41 GMT""},{""version"":""v2"",""created"":""Fri, 22 Apr 2022 12:27:36 GMT""}]","2022-06-15"
"2203.07653","Swaroop Mishra","Tejas Gokhale, Swaroop Mishra, Man Luo, Bhavdeep Singh Sachdeva and
  Chitta Baral","Generalized but not Robust? Comparing the Effects of Data Modification
  Methods on Out-of-Domain Generalization and Adversarial Robustness","ACL 2022 Findings",,,,"cs.CL cs.AI cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data modification, either via additional training datasets, data
augmentation, debiasing, and dataset filtering, has been proposed as an
effective solution for generalizing to out-of-domain (OOD) inputs, in both
natural language processing and computer vision literature. However, the effect
of data modification on adversarial robustness remains unclear. In this work,
we conduct a comprehensive study of common data modification strategies and
evaluate not only their in-domain and OOD performance, but also their
adversarial robustness (AR). We also present results on a two-dimensional
synthetic dataset to visualize the effect of each method on the training
distribution. This work serves as an empirical study towards understanding the
relationship between generalizing to unseen domains and defending against
adversarial perturbations. Our findings suggest that more data (either via
additional datasets or data augmentation) benefits both OOD accuracy and AR.
However, data filtering (previously shown to improve OOD accuracy on natural
language inference) hurts OOD accuracy on other tasks such as question
answering and image classification. We provide insights from our experiments to
inform future work in this direction.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 05:32:44 GMT""}]","2022-03-16"
"2203.07654","Giorgio Apollinari","G. Ambrosio, G. Apollinari, M. Baldini, R. Carcagno, C. Boffo, B.
  Claypool, S. Feher, S. Hays, D. Hoang, V. Kashikhin, V.V. Kashikhin, S.
  Krave, M. Kufer, J. Lee, V. Lombardo, V. Marinozzi, F. Nobrega, X. Peng, H.
  Piekarz, V. Shiltsev, S. Stoynev, T. Strauss, N. Tran, G. Velev, X. Xu, A.
  Zlobin (Fermi National Accelerator Laboratory, Batavia, IL) K. Amm, M.
  Anerella, A. Ben Yahia, R. Gupta, P. Joshi, B. Parker, J. Schmalzle
  (Brookhaven National Laboratory, Upton, NY) P. Ferracin, I. Pong, S.
  Prestemon, X. Wang, G. Sabbi, T. Shen (Lawrence Berkeley National Laboratory,
  Berkeley, CA) L. Cooley (Florida State University and NHFML, Tallahassee, FL)
  J. Rochester, M.D. Sumption (The Ohio State University, Columbus, OH)","White Paper on Leading-Edge technology And Feasibility-directed (LEAF)
  Program aimed at readiness demonstration for Energy Frontier Circular
  Colliders by the next decade","Contribution to Snowmass 2021, 19 pages, 5 figures. Corresponding
  Author: G. Apollinari apollina@fnal.gov",,,,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  In this White Paper for the Snowmass 2021 Process, we propose the
establishment of a magnet Leading-Edge technology And Feasibility-directed
Program (LEAF Program) to achieve readiness for a future collider decision on
the timescale of the next decade.
  The LEAF Program would rely on, and be synergetic with, generic R&D efforts
presently covered - in the US - by the Magnet Development Program (MDP), the
Conductor Procurement and R&D (CPRD) Program and other activities in the Office
of HEP supported by Early Career Awards (ECA) or Lab Directed R&D (LDRD) funds.
Where possible, ties to synergetic efforts in other Offices of DOE or NSF are
highlighted and suggested as wider Collaborative efforts on the National scale.
International efforts are also mentioned as potential partners in the LEAF
Program.
  We envision the LEAF Program to concentrate on demonstrating the feasibility
of magnets for muon colliders as well as next generation high energy hadron
colliders, pursuing, where necessary and warranted by the nature of the
application, the transition from R&D models to long models/prototypes. The LEAF
Program will naturally drive accelerator-quality and experiment-interface
design considerations. LEAF will also concentrate, where necessary, on cost
reduction and/or industrialization steps.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 05:34:14 GMT""}]","2022-03-16"
"2203.07655","Aykut Koc","B\""unyamin Kartal, Eray \""Ozg\""unay, Aykut Ko\c{c}","Joint Time-Vertex Fractional Fourier Transform","12 pages, 6 figures",,,,"eess.SP cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graphs signal processing successfully captures high-dimensional data on
non-Euclidean domains by using graph signals defined on graph vertices.
However, data sources on each vertex can also continually provide time-series
signals such that graph signals on each vertex are now time-series signals.
Joint time-vertex Fourier transform (JFT) and the associated framework of
time-vertex signal processing enable us to study such signals defined on joint
time-vertex domains by providing spectral analysis. Just as the fractional
Fourier transform (FRT) generalizes the ordinary Fourier transform (FT), we
propose the joint time-vertex fractional Fourier transform (JFRT) as a
generalization to the JFT. JFRT provides an additional fractional analysis tool
for joint time-vertex processing by extending both temporal and vertex domain
Fourier analysis to fractional orders. We theoretically show that the proposed
JFRT generalizes the JFT and satisfies the properties of index additivity,
reversibility, reduction to identity, and unitarity (for certain graph
topologies). We provide theoretical derivations for JFRT-based denoising as
well as computational cost analysis. Results of numerical experiments are also
presented to demonstrate the benefits of JFRT.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 05:36:14 GMT""}]","2022-03-16"
"2203.07656","Yuqian Fu","Yuqian Fu, Yu Xie, Yanwei Fu, Jingjing Chen, Yu-Gang Jiang","Wave-SAN: Wavelet based Style Augmentation Network for Cross-Domain
  Few-Shot Learning",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Previous few-shot learning (FSL) works mostly are limited to natural images
of general concepts and categories. These works assume very high visual
similarity between the source and target classes. In contrast, the recently
proposed cross-domain few-shot learning (CD-FSL) aims at transferring knowledge
from general nature images of many labeled examples to novel domain-specific
target categories of only a few labeled examples. The key challenge of CD-FSL
lies in the huge data shift between source and target domains, which is
typically in the form of totally different visual styles. This makes it very
nontrivial to directly extend the classical FSL methods to address the CD-FSL
task. To this end, this paper studies the problem of CD-FSL by spanning the
style distributions of the source dataset. Particularly, wavelet transform is
introduced to enable the decomposition of visual representations into
low-frequency components such as shape and style and high-frequency components
e.g., texture. To make our model robust to visual styles, the source images are
augmented by swapping the styles of their low-frequency components with each
other. We propose a novel Style Augmentation (StyleAug) module to implement
this idea. Furthermore, we present a Self-Supervised Learning (SSL) module to
ensure the predictions of style-augmented images are semantically similar to
the unchanged ones. This avoids the potential semantic drift problem in
exchanging the styles. Extensive experiments on two CD-FSL benchmarks show the
effectiveness of our method. Our codes and models will be released.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 05:36:41 GMT""}]","2022-03-16"
"2203.07657","Maximillian Chen","Maximillian Chen, Weiyan Shi, Feifan Yan, Ryan Hou, Jingwen Zhang,
  Saurav Sahay, Zhou Yu","Seamlessly Integrating Factual Information and Social Content with
  Persuasive Dialogue","To appear in Proceedings of AACL-IJCNLP 2022; 16 pages, 4 figures, 7
  tables",,,,"cs.CL cs.AI cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Complex conversation settings such as persuasion involve communicating
changes in attitude or behavior, so users' perspectives need to be addressed,
even when not directly related to the topic. In this work, we contribute a
novel modular dialogue system framework that seamlessly integrates factual
information and social content into persuasive dialogue. Our framework is
generalizable to any dialogue tasks that have mixed social and task contents.
We conducted a study that compared user evaluations of our framework versus a
baseline end-to-end generation model. We found our framework was evaluated more
favorably in all dimensions including competence and friendliness, compared to
the end-to-end model which does not explicitly handle social content or factual
questions.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 05:38:34 GMT""},{""version"":""v2"",""created"":""Wed, 16 Mar 2022 03:21:12 GMT""},{""version"":""v3"",""created"":""Fri, 23 Sep 2022 17:06:33 GMT""}]","2022-09-26"
"2203.07658","Tran Minh Quan","Pham Ngoc Huy and Tran Minh Quan","Neural Radiance Projection","Accepted to IEEE ISBI 2022","10.1109/ISBI52829.2022.9761457","10.1109/ISBI52829.2022.9761457","10.1109/ISBI52829.2022.9761457","eess.IV cs.CV cs.GR","http://creativecommons.org/licenses/by/4.0/","  The proposed method, Neural Radiance Projection (NeRP), addresses the three
most fundamental shortages of training such a convolutional neural network on
X-ray image segmentation: dealing with missing/limited human-annotated
datasets; ambiguity on the per-pixel label; and the imbalance across positive-
and negative- classes distribution. By harnessing a generative adversarial
network, we can synthesize a massive amount of physics-based X-ray images,
so-called Variationally Reconstructed Radiographs (VRRs), alongside their
segmentation from more accurate labeled 3D Computed Tomography data. As a
result, VRRs present more faithfully than other projection methods in terms of
photo-realistic metrics. Adding outputs from NeRP also surpasses the vanilla
UNet models trained on the same pairs of X-ray images.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 05:39:04 GMT""}]","2022-05-03"
"2203.07659","Zihao Shang","Hong Liu, Wen-Dong Xu, Zi-Hao Shang, Xiang-Dong Wang, Hai-Yan Zhou,
  Ke-Wen Ma, Huan Zhou, Jia-Lin Qi, Jia-Rui Jiang, Li-Lan Tan, Hui-Min Zeng,
  Hui-Juan Cai, Kuan-Song Wang and Yue-Liang Qian","Breast Cancer Molecular Subtypes Prediction on Pathological Images with
  Discriminative Patch Selecting and Multi-Instance Learning",,,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Molecular subtypes of breast cancer are important references to personalized
clinical treatment. For cost and labor savings, only one of the patient's
paraffin blocks is usually selected for subsequent immunohistochemistry (IHC)
to obtain molecular subtypes. Inevitable sampling error is risky due to tumor
heterogeneity and could result in a delay in treatment. Molecular subtype
prediction from conventional H&E pathological whole slide images (WSI) using AI
method is useful and critical to assist pathologists pre-screen proper paraffin
block for IHC. It's a challenging task since only WSI level labels of molecular
subtypes can be obtained from IHC. Gigapixel WSIs are divided into a huge
number of patches to be computationally feasible for deep learning. While with
coarse slide-level labels, patch-based methods may suffer from abundant noise
patches, such as folds, overstained regions, or non-tumor tissues. A weakly
supervised learning framework based on discriminative patch selecting and
multi-instance learning was proposed for breast cancer molecular subtype
prediction from H&E WSIs. Firstly, co-teaching strategy was adopted to learn
molecular subtype representations and filter out noise patches. Then, a
balanced sampling strategy was used to handle the imbalance in subtypes in the
dataset. In addition, a noise patch filtering algorithm that used local outlier
factor based on cluster centers was proposed to further select discriminative
patches. Finally, a loss function integrating patch with slide constraint
information was used to finetune MIL framework on obtained discriminative
patches and further improve the performance of molecular subtyping. The
experimental results confirmed the effectiveness of the proposed method and our
models outperformed even senior pathologists, with potential to assist
pathologists to pre-screen paraffin blocks for IHC in clinic.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 05:40:03 GMT""}]","2022-03-16"
"2203.07660","Eiji Yamamura","Eiji Yamamura, Youki Koska, Yoshiro Tsutsui, Fumio Ohtake","Effect of the COVID-19 vaccine on preventive behaviors: Evidence from
  Japan",,,,,"econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Vaccination against the coronavirus disease 2019 (COVID-19) is a key measure
to reduce the probability of getting infected with the disease. Accordingly,
this might significantly change an individuals perception and decision-making
in daily life. For instance, it is predicted that with widespread vaccination,
individuals will exhibit less rigid preventive behaviors, such as staying at
home, frequently washing hands, and wearing a mask. We observed the same
individuals on a monthly basis for 18 months, from March 2020 (the early stage
of the COVID-19 pandemic) to September 2021, in Japan to independently
construct large sample panel data (N=54,007). Using the data, we compare the
individuals preventive behaviors before and after they got vaccinated;
additionally, we compare their behaviors with those individuals who did not get
vaccinated. Furthermore, we compare the effect of vaccination on the
individuals less than or equal to 40 years of age with those greater than 40
years old. The major findings determined after controlling for individual
characteristics using the fixed effects model and various factors are as
follows. First, as opposed to the prediction, based on the whole sample, the
vaccinated people were observed to stay at home and did not change their habits
of frequently washing hands and wearing a mask. Second, using the sub-sample of
individuals aged equal to or below 40, we find that the vaccinated people are
more likely to go out. Third, the results obtained using a sample comprising
people aged over 40 are similar to those obtained using the whole sample.
Preventive behaviors are affecting oneself and generating externalities on
others during this pandemic. Informal social norms motivate people to increase
or maintain preventive behaviors even after being vaccinated in societies where
such behaviors are not enforced.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 05:47:18 GMT""}]","2022-03-16"
"2203.07661","Hidekatsu Nemura","Hidekatsu Nemura","Lambda-Nucleon and Sigma-Nucleon potentials from space-time correlation
  function on the lattice","Talk presented at the 38th International Symposium on Lattice Field
  Theory, LATTICE2021, Zoom/Gather@Massachusetts Institute of Technology, July
  26-30, 2021, 9 pages, 11 figures",,,,"hep-lat nucl-th","http://creativecommons.org/licenses/by/4.0/","  The hyperon-nucleon interaction with the strangeness $S=-1$ region is
complicated and difficult to investigate because its flavor sector involves all
the irreducible representation except the flavor singlet and has the worst
signal-to-noise ratio among the strangeness regions. In order to overcome such
difficulties the content of this report is twofold: (i) We present an
implementation of extended effective baryon block algorithm. This is a
straightforward extension of the original which was reported in LATTICE 2013.
(ii) We perform single channel analysis for the $\Lambda N$ system at nearly
physical quark masses corresponding to $(m_\pi,m_K)\approx(146,525)$~MeV and
large volume $(La)^4=(96a)^4\approx$ (8.1 fm)$^4$. Scattering phase shifts for
$\Lambda N$ system are presented.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 05:51:28 GMT""}]","2022-03-16"
"2203.07662","Dimity Miller","Dimity Miller, Peyman Moghadam, Mark Cox, Matt Wildie, Raja Jurdak","What's in the Black Box? The False Negative Mechanisms Inside Object
  Detectors","8 pages, 5 figures. Contact emails: d24.miller@qut.edu.au,
  peyman.moghadam@data61.csiro.au, mark.cox@data61.csiro.au,
  matt.wildie@data61.csiro.au, r.jurdak@qut.edu.au","IEEE Robotics and Automation Letters (July 2022), Volume 7, Issue
  3, pages 8510-8517","10.1109/LRA.2022.3187831",,"cs.CV cs.AI cs.LG cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In object detection, false negatives arise when a detector fails to detect a
target object. To understand why object detectors produce false negatives, we
identify five 'false negative mechanisms', where each mechanism describes how a
specific component inside the detector architecture failed. Focusing on
two-stage and one-stage anchor-box object detector architectures, we introduce
a framework for quantifying these false negative mechanisms. Using this
framework, we investigate why Faster R-CNN and RetinaNet fail to detect objects
in benchmark vision datasets and robotics datasets. We show that a detector's
false negative mechanisms differ significantly between computer vision
benchmark datasets and robotics deployment scenarios. This has implications for
the translation of object detectors developed for benchmark datasets to
robotics applications. Code is publicly available at
https://github.com/csiro-robotics/fn_mechanisms
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 05:51:40 GMT""},{""version"":""v2"",""created"":""Tue, 7 Jun 2022 22:45:37 GMT""},{""version"":""v3"",""created"":""Mon, 27 Jun 2022 06:00:58 GMT""},{""version"":""v4"",""created"":""Mon, 1 Aug 2022 01:27:54 GMT""}]","2022-08-02"
"2203.07663","Eiji Yamamura","Eiji Yamamura, Youki Kosaka, Yoshiro Tsutsui, Fumio Ohtake","Gender differences of the effect of vaccination on perceptions of
  COVID-19 and mental health in Japan",,,,,"econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Vaccination has been promoted to mitigate the spread of the coronavirus
disease 2019 (COVID-19). Vaccination is expected to reduce the probability of
and alleviate the seriousness of COVID-19 infection. Accordingly, this might
significantly change an individuals subjective well-being and mental health.
However, it is unknown how vaccinated people perceive the effectiveness of
COVID-19 and how their subjective well-being and mental health change after
vaccination. We thus observed the same individuals on a monthly basis from
March 2020 to September 2021 in all parts of Japan. Then, large sample panel
data (N=54,007) were independently constructed. Using the data, we compared the
individuals perceptions of COVID-19, subjective well-being, and mental health
before and after vaccination. Furthermore, we compared the effect of
vaccination on the perceptions of COVID-19 and mental health for females and
males. We used the fixed-effects model to control for individual time-invariant
characteristics. The major findings were as follows: First, the vaccinated
people perceived the probability of getting infected and the seriousness of
COVID-19 to be lower than before vaccination. This was observed not only when
we used the whole sample, but also when we used sub-samples. Second, using the
whole sample, subjective well-being and mental health improved. The same
results were also observed using the sub-sample of females, whereas the
improvements were not observed using a sub-sample of males.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 05:57:01 GMT""}]","2022-03-16"
"2203.07664","Sai Raam Venkatraman","Sai Raam Venkatraman, Rishi Rao, S. Balasubramanian, Chandra Sekhar
  Vorugunti, R. Raghunatha Sarma","Can you even tell left from right? Presenting a new challenge for VQA",,,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Visual Question Answering (VQA) needs a means of evaluating the strengths and
weaknesses of models. One aspect of such an evaluation is the evaluation of
compositional generalisation, or the ability of a model to answer well on
scenes whose scene-setups are different from the training set. Therefore, for
this purpose, we need datasets whose train and test sets differ significantly
in composition. In this work, we present several quantitative measures of
compositional separation and find that popular datasets for VQA are not good
evaluators. To solve this, we present Uncommon Objects in Unseen Configurations
(UOUC), a synthetic dataset for VQA. UOUC is at once fairly complex while also
being well-separated, compositionally. The object-class of UOUC consists of 380
clasess taken from 528 characters from the Dungeons and Dragons game. The train
set of UOUC consists of 200,000 scenes; whereas the test set consists of 30,000
scenes. In order to study compositional generalisation, simple reasoning and
memorisation, each scene of UOUC is annotated with up to 10 novel questions.
These deal with spatial relationships, hypothetical changes to scenes,
counting, comparison, memorisation and memory-based reasoning. In total, UOUC
presents over 2 million questions. UOUC also finds itself as a strong challenge
to well-performing models for VQA. Our evaluation of recent models for VQA
shows poor compositional generalisation, and comparatively lower ability
towards simple reasoning. These results suggest that UOUC could lead to
advances in research by being a strong benchmark for VQA.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 05:58:21 GMT""}]","2022-03-16"
"2203.07665","Christopher Clarke","Christopher Clarke, Joseph Joshua Peper, Karthik Krishnamurthy, Walter
  Talamonti, Kevin Leach, Walter Lasecki, Yiping Kang, Lingjia Tang, Jason Mars","One Agent To Rule Them All: Towards Multi-agent Conversational AI",,,,,"cs.CL cs.AI cs.IR","http://creativecommons.org/licenses/by/4.0/","  The increasing volume of commercially available conversational agents (CAs)
on the market has resulted in users being burdened with learning and adopting
multiple agents to accomplish their tasks. Though prior work has explored
supporting a multitude of domains within the design of a single agent, the
interaction experience suffers due to the large action space of desired
capabilities. To address these problems, we introduce a new task BBAI:
Black-Box Agent Integration, focusing on combining the capabilities of multiple
black-box CAs at scale. We explore two techniques: question agent pairing and
question response pairing aimed at resolving this task. Leveraging these
techniques, we design One For All (OFA), a scalable system that provides a
unified interface to interact with multiple CAs. Additionally, we introduce
MARS: Multi-Agent Response Selection, a new encoder model for question response
pairing that jointly encodes user question and agent response pairs. We
demonstrate that OFA is able to automatically and accurately integrate an
ensemble of commercially available CAs spanning disparate domains.
Specifically, using the MARS encoder we achieve the highest accuracy on our
BBAI task, outperforming strong baselines.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 06:07:17 GMT""}]","2022-03-16"
"2203.07666","Naoya Tajima","A. Mori, Y. Kawasugi, R. Doi, T. Naito, R. Kato, Y. Nishio, and N.
  Tajima","Narrow Zero Mode in Organic Massless Dirac Electron System
  $\alpha$-(BEDT-TTF)$_2$I$_3$","6 pages, 1 figures","J. Phys. Soc. Jpn., 91, 045001 (2022)","10.7566/JPSJ.91.045001",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigated the interlayer magnetoresistance in an organic massless Dirac
electron system $\alpha$-(BEDT-TTF)$_2$I$_3$ under pressure. We experimentally
demonstrate that the width of the zero mode owing to carrier scattering is much
narrower than that of the other Landau levels.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 06:09:13 GMT""}]","2022-03-23"
"2203.07667","Yiqiao Qiu","Yiqiao Qiu, Yixing Shen, Zhuohao Sun, Yanchong Zheng, Xiaobin Chang,
  Weishi Zheng, and Ruixuan Wang","SATS: Self-Attention Transfer for Continual Semantic Segmentation","Published in Pattern Recognition Journal","Pattern Recognition (2023) 109383","10.1016/j.patcog.2023.109383",,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Continually learning to segment more and more types of image regions is a
desired capability for many intelligent systems. However, such continual
semantic segmentation suffers from the same catastrophic forgetting issue as in
continual classification learning. While multiple knowledge distillation
strategies originally for continual classification have been well adapted to
continual semantic segmentation, they only consider transferring old knowledge
based on the outputs from one or more layers of deep fully convolutional
networks. Different from existing solutions, this study proposes to transfer a
new type of information relevant to knowledge, i.e. the relationships between
elements (Eg. pixels or small local regions) within each image which can
capture both within-class and between-class knowledge. The relationship
information can be effectively obtained from the self-attention maps in a
Transformer-style segmentation model. Considering that pixels belonging to the
same class in each image often share similar visual properties, a
class-specific region pooling is applied to provide more efficient relationship
information for knowledge transfer. Extensive evaluations on multiple public
benchmarks support that the proposed self-attention transfer method can further
effectively alleviate the catastrophic forgetting issue, and its flexible
combination with one or more widely adopted strategies significantly
outperforms state-of-the-art solutions.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 06:09:28 GMT""},{""version"":""v2"",""created"":""Mon, 28 Nov 2022 18:01:05 GMT""},{""version"":""v3"",""created"":""Mon, 13 Feb 2023 08:54:29 GMT""}]","2023-02-14"
"2203.07668","Daniel Jeans","Keita Yumino, Daniel Jeans","Measuring the tau polarization at ILC","contribution to Snowmass 2021",,,,"hep-ex hep-ph","http://creativecommons.org/licenses/by/4.0/","  Measurement of the tau lepton polarization in \eett\ is an important
electro-weak measurement at ILC and other future electron-positron colliders.
In this paper we discuss several methods to extract polarimeter information for
\eett\ events at the nominal centre-of-mass energy, and develop a new method,
based on charged particle impact parameter measurement, which can accurately
reconstruct tau momenta even in events with significant Initial State
Radiation.
  In future work we will extend the study to estimate the precision with which
the tau polarization can be measured at ILC-250, both for high-mass tau pairs
and for those which radiatively return to the $Z^0$ peak. This will complement
our past study which showed that the tau polarization can be measured to better
than 1\% at the ILC-500.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 06:11:13 GMT""}]","2022-03-16"
"2203.07669","Anlin Zheng","Anlin Zheng, Yuang Zhang, Xiangyu Zhang, Xiaojuan Qi, Jian Sun","Progressive End-to-End Object Detection in Crowded Scenes",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose a new query-based detection framework for crowd
detection. Previous query-based detectors suffer from two drawbacks: first,
multiple predictions will be inferred for a single object, typically in crowded
scenes; second, the performance saturates as the depth of the decoding stage
increases. Benefiting from the nature of the one-to-one label assignment rule,
we propose a progressive predicting method to address the above issues.
Specifically, we first select accepted queries prone to generate true positive
predictions, then refine the rest noisy queries according to the previously
accepted predictions. Experiments show that our method can significantly boost
the performance of query-based detectors in crowded scenes. Equipped with our
approach, Sparse RCNN achieves 92.0\% $\text{AP}$, 41.4\% $\text{MR}^{-2}$ and
83.2\% $\text{JI}$ on the challenging CrowdHuman \cite{shao2018crowdhuman}
dataset, outperforming the box-based method MIP \cite{chu2020detection} that
specifies in handling crowded scenarios. Moreover, the proposed method, robust
to crowdedness, can still obtain consistent improvements on moderately and
slightly crowded datasets like CityPersons \cite{zhang2017citypersons} and COCO
\cite{lin2014microsoft}. Code will be made publicly available at
https://github.com/megvii-model/Iter-E2EDET.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 06:12:00 GMT""},{""version"":""v2"",""created"":""Sat, 19 Mar 2022 09:38:03 GMT""},{""version"":""v3"",""created"":""Sat, 30 Apr 2022 16:09:38 GMT""}]","2022-05-03"
"2203.07670","Yazhou Tu","Yazhou Tu, Sara Rampazzi, Xiali Hei","Towards Adversarial Control Loops in Sensor Attacks: A Case Study to
  Control the Kinematics and Actuation of Embedded Systems",,,,,"cs.CR cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent works investigated attacks on sensors by influencing analog sensor
components with acoustic, light, and electromagnetic signals. Such attacks can
have extensive security, reliability, and safety implications since many types
of the targeted sensors are also widely used in critical process control,
robotics, automation, and industrial control systems. While existing works
advanced our understanding of the physical-level risks that are hidden from a
digital-domain perspective, gaps exist in how the attack can be guided to
achieve system-level control in real-time, continuous processes. This paper
proposes an adversarial control loop-based approach for real-time attacks on
control systems relying on sensors. We study how to utilize the system feedback
extracted from physical-domain signals to guide the attacks. In the attack
process, injection signals are adjusted in real time based on the extracted
feedback to exert targeted influence on a victim control system that is
continuously affected by the injected perturbations and applying changes to the
physical environment. In our case study, we investigate how an external
adversarial control system can be constructed over sensor-actuator systems and
demonstrate the attacks with program-controlled processes to manipulate the
victim system without accessing its internal statuses.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 06:12:09 GMT""}]","2022-03-16"
"2203.07671","Chenxi Yang","Chenxi Yang, Swarat Chaudhuri","Safe Neurosymbolic Learning with Differentiable Symbolic Execution","Accepted as a poster at ICLR 2022",,,,"cs.LG cs.AI cs.PL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of learning worst-case-safe parameters for programs that
use neural networks as well as symbolic, human-written code. Such neurosymbolic
programs arise in many safety-critical domains. However, because they can use
nondifferentiable operations, it is hard to learn their parameters using
existing gradient-based approaches to safe learning. Our approach to this
problem, Differentiable Symbolic Execution (DSE), samples control flow paths in
a program, symbolically constructs worst-case ""safety losses"" along these
paths, and backpropagates the gradients of these losses through program
operations using a generalization of the REINFORCE estimator. We evaluate the
method on a mix of synthetic tasks and real-world benchmarks. Our experiments
show that DSE significantly outperforms the state-of-the-art DiffAI method on
these tasks.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 06:13:17 GMT""}]","2022-03-28"
"2203.07672","Da Xu","Da Xu, Bo Yang","On the Advances and Challenges of Adaptive Online Testing",,,,,"stat.ME cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, the interest in developing adaptive solutions for online
testing has grown significantly in the industry. While the advances related to
this relative new technology have been developed in multiple domains, it lacks
in the literature a systematic and complete treatment of the procedure that
involves exploration, inference, and analysis. This short paper aims to develop
a comprehensive understanding of adaptive online testing, including various
building blocks and analytical results. We also address the latest
developments, research directions, and challenges that have been less mentioned
in the literature.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 06:14:07 GMT""}]","2022-03-16"
"2203.07673","Aydin Buluc","Vivek Bharadwaj, Aydin Bulu\c{c}, James Demmel","Distributed-Memory Sparse Kernels for Machine Learning","To appear at the 36th IEEE International Parallel & Distributed
  Processing Symposium (IPDPS'22). 12 pages, 9 figures",,,,"cs.DC cs.LG","http://creativecommons.org/licenses/by/4.0/","  Sampled Dense Times Dense Matrix Multiplication (SDDMM) and Sparse Times
Dense Matrix Multiplication (SpMM) appear in diverse settings, such as
collaborative filtering, document clustering, and graph embedding. Frequently,
the SDDMM output becomes the input sparse matrix for a subsequent SpMM
operation. Existing work has focused on shared memory parallelization of these
primitives. While there has been extensive analysis of communication-minimizing
distributed 1.5D algorithms for SpMM, no such analysis exists for SDDMM or the
back-to-back sequence of SDDMM and SpMM, termed FusedMM. We show that
distributed memory 1.5D and 2.5D algorithms for SpMM can be converted to
algorithms for SDDMM with identical communication costs and input / output data
layouts. Further, we give two communication-eliding strategies to reduce costs
further for FusedMM kernels: either reusing the replication of an input dense
matrix for the SDDMM and SpMM in sequence, or fusing the local SDDMM and SpMM
kernels.
  We benchmark FusedMM algorithms on Cori, a Cray XC40 at LBNL, using
Erdos-Renyi random matrices and large real-world sparse matrices. On 256 nodes
with 68 cores each, 1.5D FusedMM algorithms using either communication eliding
approach can save at least 30% of time spent exclusively in communication
compared to executing a distributed-memory SpMM and SDDMM kernel in sequence.
On real-world matrices with hundreds of millions of edges, all of our
algorithms exhibit at least a 10x speedup over the SpMM algorithm in PETSc. On
these matrices, our communication-eliding techniques exhibit runtimes up to 1.6
times faster than an unoptimized sequence of SDDMM and SpMM. We embed and test
the scaling of our algorithms in real-world applications, including
collaborative filtering via alternating-least-squares and inference for
attention-based graph neural networks.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 06:34:39 GMT""},{""version"":""v2"",""created"":""Fri, 18 Mar 2022 19:29:15 GMT""}]","2022-03-22"
"2203.07674","Chusei Kiumi","Chusei Kiumi, Norio Konno, Shunya Tamura","Return probability of quantum and correlated random walks","15pages","Entropy 2022, 24(5), 584","10.3390/e24050584",,"math-ph math.MP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The analysis of the return probability is one of the most essential and
fundamental topics in the study of classical random walks. In this paper, we
study the return probability of quantum and correlated random walks in the
one-dimensional integer lattice by the path counting method. We show that the
return probability of both quantum and correlated random walks can be expressed
in terms of the Legendre polynomial. Moreover, the generating function of the
return probability can be written in terms of elliptic integrals of the first
and second kinds for the quantum walk.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 06:35:09 GMT""},{""version"":""v2"",""created"":""Fri, 22 Apr 2022 02:01:04 GMT""}]","2022-04-25"
"2203.07675","Garreth Martin","G. Martin, A. E. Bazkiaei, M. Spavone, E. Iodice, J. C. Mihos, M.
  Montes, J. A. Benavides, S. Brough, J. L. Carlin, C. A. Collins, P. A. Duc,
  F. A. G\'omez, G. Galaz, H. M. Hern\'andez-Toledo, R. A. Jackson, S. Kaviraj,
  J. H. Knapen, C. Mart\'inez-Lombilla, S. McGee, D. O'Ryan, D. J. Prole, R. M.
  Rich, J. Rom\'an, E. A. Shah, T. K. Starkenburg, A. E. Watkins, D. Zaritsky,
  C. Laigle, C. Pichon, L. Armus, M. Bianconi, F. Buitrago, I. Bus\'a, F.
  Davis, R. Demarco, A. Desmons, P. Garc\'ia, A. W. Graham, B. Holwerda, D. S.
  -H. Hon, A. Khalid, J. Klehammer, D. Y. Klutse, I. Lazar, P. Nair, E. A.
  Noakes-Kettel, M. Rutkowski, K. Saha, N. Sahu, E. Sola, J. A. V\'azquez-Mata,
  A. Vera-Casanova, I. Yoon","Preparing for low surface brightness science with the Vera C. Rubin
  Observatory: characterisation of tidal features from mock images","29 pages, 25 figures; accepted for publication in MNRAS following
  minor corrections","Monthly Notices of the Royal Astronomical Society, Volume 513,
  Issue 1, June 2022, Pages 1459-1487,","10.1093/mnras/stac1003",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tidal features in the outskirts of galaxies yield unique information about
their past interactions and are a key prediction of the hierarchical structure
formation paradigm. The Vera C. Rubin Observatory is poised to deliver deep
observations for potentially of millions of objects with visible tidal
features, but the inference of galaxy interaction histories from such features
is not straightforward. Utilising automated techniques and human visual
classification in conjunction with realistic mock images produced using the
NEWHORIZON cosmological simulation, we investigate the nature, frequency and
visibility of tidal features and debris across a range of environments and
stellar masses. In our simulated sample, around 80 per cent of the flux in the
tidal features around Milky Way or greater mass galaxies is detected at the
10-year depth of the Legacy Survey of Space and Time (30-31 mag / sq. arcsec),
falling to 60 per cent assuming a shallower final depth of 29.5 mag / sq.
arcsec. The fraction of total flux found in tidal features increases towards
higher masses, rising to 10 per cent for the most massive objects in our sample
(M*~10^{11.5} Msun). When observed at sufficient depth, such objects frequently
exhibit many distinct tidal features with complex shapes. The interpretation
and characterisation of such features varies significantly with image depth and
object orientation, introducing significant biases in their classification.
Assuming the data reduction pipeline is properly optimised, we expect the Rubin
Observatory to be capable of recovering much of the flux found in the outskirts
of Milky Way mass galaxies, even at intermediate redshifts (z<0.2).
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 06:35:41 GMT""},{""version"":""v2"",""created"":""Sat, 7 May 2022 13:46:26 GMT""}]","2022-05-10"
"2203.07676","Axel Plinge","Lukas M. Schmidt, Johanna Brosig, Axel Plinge, Bjoern M. Eskofier,
  Christopher Mutschler","An Introduction to Multi-Agent Reinforcement Learning and Review of its
  Application to Autonomous Mobility","8 pages, 2 figures",,,,"cs.AI cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many scenarios in mobility and traffic involve multiple different agents that
need to cooperate to find a joint solution. Recent advances in behavioral
planning use Reinforcement Learning to find effective and performant behavior
strategies. However, as autonomous vehicles and vehicle-to-X communications
become more mature, solutions that only utilize single, independent agents
leave potential performance gains on the road. Multi-Agent Reinforcement
Learning (MARL) is a research field that aims to find optimal solutions for
multiple agents that interact with each other. This work aims to give an
overview of the field to researchers in autonomous mobility. We first explain
MARL and introduce important concepts. Then, we discuss the central paradigms
that underlie MARL algorithms, and give an overview of state-of-the-art methods
and ideas in each paradigm. With this background, we survey applications of
MARL in autonomous mobility scenarios and give an overview of existing
scenarios and implementations.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 06:40:28 GMT""},{""version"":""v2"",""created"":""Tue, 2 Aug 2022 07:23:21 GMT""}]","2022-08-03"
"2203.07677","Xiang Chen","Xiang Chen, Zhentao Fan, Pengpeng Li, Longgang Dai, Caihua Kong,
  Zhuoran Zheng, Yufeng Huang, Yufeng Li","Unpaired Deep Image Dehazing Using Contrastive Disentanglement Learning",,,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We offer a practical unpaired learning based image dehazing network from an
unpaired set of clear and hazy images. This paper provides a new perspective to
treat image dehazing as a two-class separated factor disentanglement task, i.e,
the task-relevant factor of clear image reconstruction and the task-irrelevant
factor of haze-relevant distribution. To achieve the disentanglement of these
two-class factors in deep feature space, contrastive learning is introduced
into a CycleGAN framework to learn disentangled representations by guiding the
generated images to be associated with latent factors. With such formulation,
the proposed contrastive disentangled dehazing method (CDD-GAN) employs
negative generators to cooperate with the encoder network to update
alternately, so as to produce a queue of challenging negative adversaries. Then
these negative adversaries are trained end-to-end together with the backbone
representation network to enhance the discriminative information and promote
factor disentanglement performance by maximizing the adversarial contrastive
loss. During the training, we further show that hard negative examples can
suppress the task-irrelevant factors and unpaired clear exemples can enhance
the task-relevant factors, in order to better facilitate haze removal and help
image restoration. Extensive experiments on both synthetic and real-world
datasets demonstrate that our method performs favorably against existing
unpaired dehazing baselines.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 06:45:03 GMT""},{""version"":""v2"",""created"":""Tue, 12 Jul 2022 10:24:08 GMT""}]","2022-07-13"
"2203.07678","Wei Ye","Wei Ye, Jiayi Yang, Sourav Medya, Ambuj Singh","Incorporating Heterophily into Graph Neural Networks for Graph
  Classification","12 pages",,,,"cs.LG cs.SI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Graph neural networks (GNNs) often assume strong homophily in graphs, seldom
considering heterophily which means connected nodes tend to have different
class labels and dissimilar features. In real-world scenarios, graphs may have
nodes that exhibit both homophily and heterophily. Failing to generalize to
this setting makes many GNNs underperform in graph classification. In this
paper, we address this limitation by identifying two useful designs and develop
a novel GNN architecture called IHGNN (Incorporating Heterophily into Graph
Neural Networks). These designs include integration and separation of the ego-
and neighbor-embeddings of nodes; and concatenation of all the node embeddings
as the final graph-level readout function. In the first design, integration is
combined with separation by an injective function which is the composition of
the MLP and the concatenation function. The second design enables the
graph-level readout function to differentiate between different node
embeddings. As the functions used in both the designs are injective, IHGNN,
while being simple, has an expressiveness as powerful as the 1-WL. We
empirically validate IHGNN on various graph datasets and demonstrate that it
achieves state-of-the-art performance on the graph classification task.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 06:48:35 GMT""}]","2022-03-16"
"2203.07679","Dongseok Im","Dongseok Im, Gwangtae Park, Zhiyong Li, Junha Ryu, and Hoi-Jun Yoo","Energy-efficient Dense DNN Acceleration with Signed Bit-slice
  Architecture",,,,,"cs.AR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As the number of deep neural networks (DNNs) to be executed on a mobile
system-on-chip (SoC) increases, the mobile SoC suffers from the real-time DNN
acceleration within its limited hardware resources and power budget. Although
the previous mobile neural processing units (NPUs) take advantage of low-bit
computing and exploitation of the sparsity, it is incapable of accelerating
high-precision and dense DNNs. This paper proposes energy-efficient signed
bit-slice architecture which accelerates both high-precision and dense DNNs by
exploiting a large number of zero values of signed bit-slices. Proposed signed
bit-slice representation (SBR) changes signed $1111_{2}$ bit-slice to
$0000_{2}$ by borrowing a $1$ value from its lower order of bit-slice. As a
result, it generates a large number of zero bit-slices even in dense DNNs.
Moreover, it balances the positive and negative values of 2's complement data,
allowing bit-slice based output speculation which pre-computes high order of
bit-slices and skips the remaining dense low order of bit-slices. The signed
bit-slice architecture compresses and skips the zero input signed bit-slices,
and the zero skipping unit also supports the output skipping by masking the
speculated inputs as zero. Additionally, the heterogeneous network-on-chip
(NoC) benefits the exploitation of data reusability and reduction of
transmission bandwidth. The paper introduces a specialized instruction set
architecture (ISA) and a hierarchical instruction decoder for the control of
the signed bit-slice architecture. Finally, the signed bit-slice architecture
outperforms the previous bit-slice accelerator, Bit-fusion, over $\times3.65$
higher area-efficiency, $\times3.88$ higher energy-efficiency, and $\times5.35$
higher throughput.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 06:49:57 GMT""}]","2022-03-16"
"2203.07680","Zeyu Xia","Cheng Wang, Jilu Wang, Zeyu Xia, and Liwei Xu","Optimal error estimates of a Crank--Nicolson finite element projection
  method for magnetohydrodynamic equations","arXiv admin note: substantial text overlap with arXiv:2011.14511",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose and analyze a fully discrete finite element
projection method for the magnetohydrodynamic (MHD) equations. A modified
Crank--Nicolson method and the Galerkin finite element method are used to
discretize the model in time and space, respectively, and appropriate
semi-implicit treatments are applied to the fluid convection term and two
coupling terms. These semi-implicit approximations result in a linear system
with variable coefficients for which the unique solvability can be proved
theoretically. In addition, we use a second-order decoupling projection method
of the Van Kan type \cite{vankan1986} in the Stokes solver, which computes the
intermediate velocity field based on the gradient of the pressure from the
previous time level, and enforces the incompressibility constraint via the
Helmholtz decomposition of the intermediate velocity field. The energy
stability of the scheme is theoretically proved, in which the decoupled Stokes
solver needs to be analyzed in details. Error estimates are proved in the
discrete $L^\infty(0,T;L^2)$ norm for the proposed decoupled finite element
projection scheme. Numerical examples are provided to illustrate the
theoretical results.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 06:50:59 GMT""}]","2022-04-13"
"2203.07681","Wei Fan","Wei Fan, Shun Zheng, Xiaohan Yi, Wei Cao, Yanjie Fu, Jiang Bian,
  Tie-Yan Liu","DEPTS: Deep Expansion Learning for Periodic Time Series Forecasting","ICLR22 Spotlight",,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Periodic time series (PTS) forecasting plays a crucial role in a variety of
industries to foster critical tasks, such as early warning, pre-planning,
resource scheduling, etc. However, the complicated dependencies of the PTS
signal on its inherent periodicity as well as the sophisticated composition of
various periods hinder the performance of PTS forecasting. In this paper, we
introduce a deep expansion learning framework, DEPTS, for PTS forecasting.
DEPTS starts with a decoupled formulation by introducing the periodic state as
a hidden variable, which stimulates us to make two dedicated modules to tackle
the aforementioned two challenges. First, we develop an expansion module on top
of residual learning to perform a layer-by-layer expansion of those complicated
dependencies. Second, we introduce a periodicity module with a parameterized
periodic function that holds sufficient capacity to capture diversified
periods. Moreover, our two customized modules also have certain interpretable
capabilities, such as attributing the forecasts to either local momenta or
global periodicity and characterizing certain core periodic properties, e.g.,
amplitudes and frequencies. Extensive experiments on both synthetic data and
real-world data demonstrate the effectiveness of DEPTS on handling PTS. In most
cases, DEPTS achieves significant improvements over the best baseline.
Specifically, the error reduction can even reach up to 20% for a few cases.
Finally, all codes are publicly available.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 06:51:58 GMT""}]","2022-03-16"
"2203.07682","Jinsu Yoo","Jinsu Yoo, Taehoon Kim, Sihaeng Lee, Seung Hwan Kim, Honglak Lee, Tae
  Hyun Kim","Enriched CNN-Transformer Feature Aggregation Networks for
  Super-Resolution","WACV 2023",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent transformer-based super-resolution (SR) methods have achieved
promising results against conventional CNN-based methods. However, these
approaches suffer from essential shortsightedness created by only utilizing the
standard self-attention-based reasoning. In this paper, we introduce an
effective hybrid SR network to aggregate enriched features, including local
features from CNNs and long-range multi-scale dependencies captured by
transformers. Specifically, our network comprises transformer and convolutional
branches, which synergetically complement each representation during the
restoration procedure. Furthermore, we propose a cross-scale token attention
module, allowing the transformer branch to exploit the informative
relationships among tokens across different scales efficiently. Our proposed
method achieves state-of-the-art SR results on numerous benchmark datasets.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 06:52:25 GMT""},{""version"":""v2"",""created"":""Wed, 16 Mar 2022 11:52:47 GMT""},{""version"":""v3"",""created"":""Thu, 20 Oct 2022 06:29:16 GMT""}]","2022-10-21"
"2203.07683","Huanyin Chen","Huanyin Chen, Marjan Sheibani","The group inverse of the sum in a Banach algebra",,,,,"math.FA math.RA","http://creativecommons.org/licenses/by/4.0/","  In this paper, we present new necessary and sufficient conditions under which
the sum of two group invertible elements in a Banach algebra has group inverse.
We then apply these results to block operator matrices over Banach spaces. The
group inverses of certain operator block matrices are thereby obtained.
Additionally, this paper extends the results obtained in \cite{L}.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 06:53:17 GMT""}]","2022-03-16"
"2203.07684","Lu Zhang","Zehua Zhang, Lu Zhang, Xuyi Zhuang, Yukun Qian, Heng Li, Mingjiang
  Wang","FB-MSTCN: A Full-Band Single-Channel Speech Enhancement Method Based on
  Multi-Scale Temporal Convolutional Network","Accepted by ICASSP 2022, Deep Noise Suppression Challenge",,,,"eess.AS","http://creativecommons.org/licenses/by/4.0/","  In recent years, deep learning-based approaches have significantly improved
the performance of single-channel speech enhancement. However, due to the
limitation of training data and computational complexity, real-time enhancement
of full-band (48 kHz) speech signals is still very challenging. Because of the
low energy of spectral information in the high-frequency part, it is more
difficult to directly model and enhance the full-band spectrum using neural
networks. To solve this problem, this paper proposes a two-stage real-time
speech enhancement model with extraction-interpolation mechanism for a
full-band signal. The 48 kHz full-band time-domain signal is divided into three
sub-channels by extracting, and a two-stage processing scheme of `masking +
compensation' is proposed to enhance the signal in the complex domain. After
the two-stage enhancement, the enhanced full-band speech signal is restored by
interval interpolation. In the subjective listening and word accuracy test, our
proposed model achieves superior performance and outperforms the baseline model
overall by 0.59 MOS and 4.0% WAcc for the non-personalized speech denoising
task.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 06:55:55 GMT""}]","2022-03-16"
"2203.07685","Philipp Maass","So-Kumneth Sim, Joachim Peinke, and Philipp Maass","Signatures of geostrophic turbulence in power spectra and
  third-order-structure function of offshore wind speed fluctuation","10 pages, 4 figures",,,,"physics.flu-dyn physics.ao-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze offshore wind speeds with a time resolution of one second over a
long period of 20 months for different heights above the sea level. Power
spectra extending over more than seven decades give a comprehensive picture of
wind fluctuations, including intermittency effects at small length scales and
synoptic weather phenomena at large scales. The spectra $S(f)$ show a scaling
behavior consistent with three-dimensional turbulence at high frequencies $f$,
followed by a regime at lower frequencies, where $fS(f)$ varies weakly.
Lowering the frequency below a crossover frequency $f_{\rm\scriptscriptstyle
2D}$, a rapid rise of $fS(f)$ occurs. An analysis of the third-order structure
function $D_3(\tau)$ of wind speed differences for a given time lag $\tau$
shows a rapid change from negative to positive values of $D_3(\tau)$ at
$\tau\simeq 1/f_{\rm\scriptscriptstyle 2D}$. Remarkably, after applying
Taylor's hypothesis locally, we find the third-order structure function to
exhibit a behavior very similar to that obtained previously from aircraft
measurements at much higher altitudes in the atmosphere. In particular, the
third-order structure function grows linearly with the separation distance for
negative $D_3$, and with the third power for positive $D_3$. This allows us to
estimate energy and enstrophy dissipation rates for offshore wind. The
crossover from negative to positive values occurs at about the same separation
distance of 400 km as found from the aircraft measurements, suggesting that
this length is independent of the altitude in the atmosphere.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 06:58:41 GMT""},{""version"":""v2"",""created"":""Sun, 5 Mar 2023 10:19:06 GMT""}]","2023-03-07"
"2203.07686","Abhiruk Lahiri","Zdenek Dvor\'ak, Daniel Goncalves, Abhiruk Lahiri, Jane Tan, Torsten
  Ueckerdt","On Comparable Box Dimension","23 pages, 1 figure, accepted for presentation at SoCG 2022",,,,"cs.DM cs.DS math.CO","http://creativecommons.org/licenses/by/4.0/","  Two boxes in $\mathbb{R}^d$ are comparable if one of them is a subset of a
translation of the other one. The comparable box dimension of a graph $G$ is
the minimum integer $d$ such that $G$ can be represented as a touching graph of
comparable axis-aligned boxes in $\mathbb{R}^d$. We show that proper
minor-closed classes have bounded comparable box dimensions and explore further
properties of this notion.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:00:12 GMT""}]","2022-03-16"
"2203.07687","Xuandong Zhao","Xuandong Zhao, Zhiguo Yu, Ming Wu, Lei Li","Compressing Sentence Representation for Semantic Retrieval via
  Homomorphic Projective Distillation","Findings of ACL 2022",,,,"cs.CL cs.IR","http://creativecommons.org/licenses/by/4.0/","  How to learn highly compact yet effective sentence representation?
Pre-trained language models have been effective in many NLP tasks. However,
these models are often huge and produce large sentence embeddings. Moreover,
there is a big performance gap between large and small models. In this paper,
we propose Homomorphic Projective Distillation (HPD) to learn compressed
sentence embeddings. Our method augments a small Transformer encoder model with
learnable projection layers to produce compact representations while mimicking
a large pre-trained language model to retain the sentence representation
quality. We evaluate our method with different model sizes on both semantic
textual similarity (STS) and semantic retrieval (SR) tasks. Experiments show
that our method achieves 2.7-4.5 points performance gain on STS tasks compared
with previous best representations of the same size. In SR tasks, our method
improves retrieval speed (8.2$\times$) and memory usage (8.0$\times$) compared
with state-of-the-art large models.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:05:43 GMT""}]","2022-03-16"
"2203.07688","Ke Zhang","Junwei Yang, Ke Zhang, Zhaolin Cui, Jinming Su, Junfeng Luo, and
  Xiaolin Wei","InsCon:Instance Consistency Feature Representation via Self-Supervised
  Learning","16 pages, 3 figures, 9 tables",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Feature representation via self-supervised learning has reached remarkable
success in image-level contrastive learning, which brings impressive
performances on image classification tasks. While image-level feature
representation mainly focuses on contrastive learning in single instance, it
ignores the objective differences between pretext and downstream prediction
tasks such as object detection and instance segmentation. In order to fully
unleash the power of feature representation on downstream prediction tasks, we
propose a new end-to-end self-supervised framework called InsCon, which is
devoted to capturing multi-instance information and extracting cell-instance
features for object recognition and localization. On the one hand, InsCon
builds a targeted learning paradigm that applies multi-instance images as
input, aligning the learned feature between corresponding instance views, which
makes it more appropriate for multi-instance recognition tasks. On the other
hand, InsCon introduces the pull and push of cell-instance, which utilizes cell
consistency to enhance fine-grained feature representation for precise boundary
localization. As a result, InsCon learns multi-instance consistency on semantic
feature representation and cell-instance consistency on spatial feature
representation. Experiments demonstrate the method we proposed surpasses MoCo
v2 by 1.1% AP^{bb} on COCO object detection and 1.0% AP^{mk} on COCO instance
segmentation using Mask R-CNN R50-FPN network structure with 90k iterations,
2.1% APbb on PASCAL VOC objection detection using Faster R-CNN R50-C4 network
structure with 24k iterations.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:09:00 GMT""}]","2022-03-16"
"2203.07689","Mohsen Nejad-Asghar","Hamed Vahdanian, Mohsen Nejad-Asghar","Some Aspects of Rotation and Magnetic Field Morphology in the Infrared
  Dark Cloud G34.43+00.24","23 pages, 8 figures, accepted for publication in MNRAS",,"10.1093/mnras/stac745",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The infrared dark clouds (IRDCs) are molecular clouds with relatively greater
values in their magnetic field strengths. For example, the IRDC G34.43+00.24
(G34) has magnetic field strength of the order of a few hundred micro-Gauss. In
this study, we investigate if the dynamic motions of charged particles in an
IRDC such as G34 can produce this magnetic field strength inside it. The
observations show that the line-of-sight velocity of G34 has global gradient.
We assume that the measured global velocity gradient can correspond to the
cloud rotation. We attribute a large-scale current density to this rotating
cloud by considering a constant value for the incompleteness of charge
neutrality and the velocity differences between the positive and negative
particles with very low ionization fractions. We use the numerical package
FISHPACK to obtain the magnetic field strength and its morphology on the
plane-of-sky within G34. The results show that the magnetic field strengths are
of the order of several hundred micro-Gauss, and its morphology in the
plane-of-sky is somewhat consistent with the observational results. We also
obtain the relationship between magnetic field strength and density in G34. The
results show that with increasing density, the magnetic field strength
increases approximately as a power-law function. The amount of power is
approximately equal to 0.45, which is suitable for molecular clouds with strong
magnetic fields. Therefore, we can conclude that the dynamical motion of IRDCs,
and especially their rotations, can amplify the magnetic field strengths within
them.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:17:06 GMT""}]","2022-03-30"
"2203.07690","Banibrata Mukhopadhyay","Arghya Ranjan Das and Banibrata Mukhopadhyay","Asymptotically flat vacuum solution for a rotating black hole in a
  modified gravity theory","12 pages including 6 figures and 2 tables; some typos corrected;
  version published in European Physical Journal C (EPJC)","Eur. Phys. J. C 82 (2022) 939","10.1140/epjc/s10052-022-10899-5",,"gr-qc astro-ph.HE hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The theory of f(R)-gravity is one of the theories of modified Einstein
gravity. The vacuum solution, on the other hand, of the field equation is the
solution for black hole geometry. We establish here an asymptotically flat
rotating black hole solution in an f(R)-gravity. This essentially leads to the
modified solution to the Kerr black hole. This solution exhibits the change in
fundamental properties of the black hole and its geometry. It particularly
shows that radii of marginally stable and bound orbits and black hole event
horizon increase compared to those in Einstein gravity, depending on the
modified gravity parameter. It further argues for faster spinning black holes
with spin (Kerr) parameter greater than unity, without any naked singularity.
This supports the weak cosmic censorship hypothesis.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:18:41 GMT""},{""version"":""v2"",""created"":""Thu, 3 Nov 2022 09:41:57 GMT""}]","2022-11-07"
"2203.07691","Minglong Lei","Hao Jia, Junzhong Ji, and Minglong Lei","Supervised Contrastive Learning with Structure Inference for Graph
  Classification",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Advanced graph neural networks have shown great potentials in graph
classification tasks recently. Different from node classification where node
embeddings aggregated from local neighbors can be directly used to learn node
labels, graph classification requires a hierarchical accumulation of different
levels of topological information to generate discriminative graph embeddings.
Still, how to fully explore graph structures and formulate an effective graph
classification pipeline remains rudimentary. In this paper, we propose a novel
graph neural network based on supervised contrastive learning with structure
inference for graph classification. First, we propose a data-driven graph
augmentation strategy that can discover additional connections to enhance the
existing edge set. Concretely, we resort to a structure inference stage based
on diffusion cascades to recover possible connections with high node
similarities. Second, to improve the contrastive power of graph neural
networks, we propose to use a supervised contrastive loss for graph
classification. With the integration of label information, the one-vs-many
contrastive learning can be extended to a many-vs-many setting, so that the
graph-level embeddings with higher topological similarities will be pulled
closer. The supervised contrastive loss and structure inference can be
naturally incorporated within the hierarchical graph neural networks where the
topological patterns can be fully explored to produce discriminative graph
embeddings. Experiment results show the effectiveness of the proposed method
compared with recent state-of-the-art methods.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:18:46 GMT""}]","2022-03-16"
"2203.07692","Abinash Sahu","Abinash Sahu, Sreeram PG, and Vaibhav Madhok","Effect of chaos on information gain in quantum tomography","11 pages, 6 figures, published version with modified title","Phys. Rev. E 106, 024209 (2022)","10.1103/PhysRevE.106.024209",,"quant-ph nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Does chaos in the dynamics enable information gain in quantum tomography or
impede it? We address this question by considering continuous measurement
tomography in which the measurement record is obtained as a sequence of
expectation values of a Hermitian observable evolving under the repeated
application of the Floquet map of the quantum kicked top. For a given dynamics
and Hermitian observables, we observe completely opposite behavior in the
tomography of well-localized spin coherent states compared to random states. As
the chaos in the dynamics increases, the reconstruction fidelity of spin
coherent states decreases. This contrasts with the previous results connecting
information gain in tomography of random states with the degree of chaos in the
dynamics that drives the system. The rate of information gain and hence the
fidelity obtained in tomography depends not only on the degree of chaos in the
dynamics and to what extent it causes the initial observable to spread in
various directions of the operator space but, more importantly, how well these
directions are aligned with the density matrix to be estimated. Our study also
gives an operational interpretation for operator spreading in terms of fidelity
gain in an actual quantum information tomography protocol.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:19:34 GMT""},{""version"":""v2"",""created"":""Sat, 27 Aug 2022 06:57:44 GMT""}]","2022-08-30"
"2203.07693","Swarna Kanti Ghosh","S. K. Ghosh (1 and 4), S. N. Tandon (2 and 5), S. K. Singh (3), D. S.
  Shelat (3 and 4), P. Tahlani (3), A. K. Singh (3), T. P. Srinivasan (3), P.
  Joseph (5), A. Devaraj (5), K. George (5 and 6), R. Mohan (3), J. Postma (7),
  and C. S. Stalin (5) ((1) Tata Institute of Fundamental Research, Mumbai,
  India, (2) Inter-University Centre for Astronomy and Astrophysics, Pune,
  India, (3) Space Application Centre (ISRO), Ahmedabad, India, (4) National
  Centre for Radio-Astrophysics (NCRA-TIFR), Pune, India (5) Indian Institute
  of Astrophysics, Bengaluru, India, (6) Ludwig-Maximilians-Universit\""at,
  Munich, Germany (7) University of Calgary, Calgary, Canada)","An Automated Pipeline for Ultra-Violet Imaging Telescope (UVIT)","Accepted for publication in Journal of Astrophysics & Astronomy, 50
  pages, 16 figures",,"10.1007/s12036-022-09842-7",,"astro-ph.IM","http://creativecommons.org/publicdomain/zero/1.0/","  We describe a versatile pipeline for processing the data collected by the
Ultra-Violet Imaging Telescope (UVIT) on board Indian Multi-wavelength
astronomical satellite AstroSat.The UVIT instrument carries out simultaneous
astronomical imaging through selected filters / gratings in Far-Ultra-Violet
(FUV), Near-Ultra-Violet & visible (VIS) bands of the targeted circular sky
field (~ 0.5 deg dia). This pipeline converts the data (Level-1) emanating from
UVIT in their raw primitive format supplemented by inputs from the spacecraft
sub-systems into UV sky images (& slitless grating spectra) and associated
products readily usable by astronomers (Level-2). The primary products include
maps of Intensity (rate of photon arrival), error on Intensity and effective
Exposure. The pipeline is open source, extensively user configurable with many
selectable parameters and its execution is fully automated. The key ingredients
of the pipeline includes - extraction of drift in pointing of the spacecraft,
and disturbances in pointing due to internal movements; application of various
corrections to measured position in the detector for each photon - e.g.
differential pointing with respect to a reference frame for shift and add
operation, systematic effects and artifacts in the optics of the telescopes and
detectors, exposure tracking on the sky, alignment of sky products from
multi-episode exposures to generate a consolidated set and astrometry. Detailed
logs of operations and intermediate products for every processing stage are
accessible via user selectable options. While large number of selectable
parameters are available for the user, a well characterized standard default
set is used for executing this pipeline at the Payload Operation Centre (POC)
for UVIT and selected products are archived and disseminated by the Indian
Space Research Organization (ISRO) through its ISSDC portal.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:20:23 GMT""}]","2022-10-26"
"2203.07694","Ramana Sundararaman","Ramana Sundararaman, Gautam Pai, Maks Ovsjanikov","Implicit field supervision for robust non-rigid shape matching","ECCV 2022",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Establishing a correspondence between two non-rigidly deforming shapes is one
of the most fundamental problems in visual computing. Existing methods often
show weak resilience when presented with challenges innate to real-world data
such as noise, outliers, self-occlusion etc. On the other hand, auto-decoders
have demonstrated strong expressive power in learning geometrically meaningful
latent embeddings. However, their use in \emph{shape analysis} has been
limited. In this paper, we introduce an approach based on an auto-decoder
framework, that learns a continuous shape-wise deformation field over a fixed
template. By supervising the deformation field for points on-surface and
regularising for points off-surface through a novel \emph{Signed Distance
Regularisation} (SDR), we learn an alignment between the template and shape
\emph{volumes}. Trained on clean water-tight meshes, \emph{without} any
data-augmentation, we demonstrate compelling performance on compromised data
and real-world scans.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:22:52 GMT""},{""version"":""v2"",""created"":""Wed, 16 Mar 2022 14:01:00 GMT""},{""version"":""v3"",""created"":""Thu, 21 Jul 2022 10:24:23 GMT""}]","2022-07-22"
"2203.07695","Emmanuel Michta","Emmanuel Michta","The scaling limit of the weakly self-avoiding walk on a high-dimensional
  torus","14 pages",,,,"math.PR math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  We prove that the scaling limit of the weakly self-avoiding walk on a
$d$-dimensional discrete torus is Brownian motion on the continuum torus if the
length of the rescaled walk is $o(V^{1/2})$ where $V$ is the volume (number of
points) of the torus and if $d>4$. We also prove that the diffusion constant of
the resulting torus Brownian motion is the same as the diffusion constant of
the scaling limit of the usual weakly self-avoiding walk on $\mathbb{Z}^d$.
This provides further manifestation of the fact that the weakly self-avoiding
walk model on the torus does not feel that it is on the torus up until it
reaches about $V^{1/2}$ steps which we believe is sharp.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:27:33 GMT""}]","2022-03-16"
"2203.07696","Michael Levitin","Nikolay Filonov, Michael Levitin, Iosif Polterovich, and David A. Sher","P\'olya's conjecture for Euclidean balls","v.4: some corrections and presentation changes. 34 pages, six
  figures, one table",,,,"math.SP math.CA math.NT","http://creativecommons.org/licenses/by/4.0/","  The celebrated P\'{o}lya's conjecture (1954) in spectral geometry states that
the eigenvalue counting functions of the Dirichlet and Neumann Laplacian on a
bounded Euclidean domain can be estimated from above and below, respectively,
by the leading term of Weyl's asymptotics. P\'{o}lya's conjecture is known to
be true for domains which tile Euclidean space, and, in addition, for some
special domains in higher dimensions. In this paper, we prove P\'{o}lya's
conjecture for the disk, making it the first non-tiling planar domain for which
the conjecture is verified. We also confirm P\'{o}lya's conjecture for
arbitrary planar sectors, and, in the Dirichlet case, for balls of any
dimension. Along the way, we develop the known links between the spectral
problems in the disk and certain lattice counting problems. A key novel
ingredient is the observation, made in recent work of the last named author,
that the corresponding eigenvalue and lattice counting functions are related
not only asymptotically, but in fact satisfy certain uniform bounds. Our proofs
are purely analytic, except for a rigorous computer-assisted argument needed to
cover the short interval of values of the spectral parameter in the case of the
Neumann problem in the disk.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:29:28 GMT""},{""version"":""v2"",""created"":""Fri, 1 Apr 2022 15:20:57 GMT""},{""version"":""v3"",""created"":""Sat, 17 Dec 2022 12:11:09 GMT""},{""version"":""v4"",""created"":""Tue, 9 May 2023 02:32:09 GMT""}]","2023-05-10"
"2203.07697","Zitian Wang","Zitian Wang, Xuecheng Nie, Xiaochao Qu, Yunpeng Chen, Si Liu","Distribution-Aware Single-Stage Models for Multi-Person 3D Pose
  Estimation","To appear in CVPR 2022. Code will be released",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present a novel Distribution-Aware Single-stage (DAS) model
for tackling the challenging multi-person 3D pose estimation problem. Different
from existing top-down and bottom-up methods, the proposed DAS model
simultaneously localizes person positions and their corresponding body joints
in the 3D camera space in a one-pass manner. This leads to a simplified
pipeline with enhanced efficiency. In addition, DAS learns the true
distribution of body joints for the regression of their positions, rather than
making a simple Laplacian or Gaussian assumption as previous works. This
provides valuable priors for model prediction and thus boosts the
regression-based scheme to achieve competitive performance with volumetric-base
ones. Moreover, DAS exploits a recursive update strategy for progressively
approaching to regression target, alleviating the optimization difficulty and
further lifting the regression performance. DAS is implemented with a fully
Convolutional Neural Network and end-to-end learnable. Comprehensive
experiments on benchmarks CMU Panoptic and MuPoTS-3D demonstrate the superior
efficiency of the proposed DAS model, specifically 1.5x speedup over previous
best model, and its stat-of-the-art accuracy for multi-person 3D pose
estimation.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:30:27 GMT""},{""version"":""v2"",""created"":""Wed, 16 Mar 2022 03:11:43 GMT""},{""version"":""v3"",""created"":""Fri, 18 Mar 2022 12:37:25 GMT""},{""version"":""v4"",""created"":""Wed, 23 Mar 2022 03:38:07 GMT""}]","2022-03-24"
"2203.07698","Alexander Urban","Michael F. Lichtenegger, Jan Drewniok, Andreas Bornschlegl, Carola
  Lampe, Andreas Singldinger, Nina A. Henke, Alexander S. Urban","Electron-Hole Binding Governs Carrier Transport in Halide Perovskite
  Nanocrystal Thin Films","accepted in ACS Nano (final version pre-acceptance)",,,,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Two-dimensional halide perovskite nanoplatelets (NPLs) have exceptional
light-emitting properties, including wide spectral tunability, ultrafast
radiative decays, high quantum yields (QY), and oriented emission. To realize
efficient devices, it is imperative to understand how exciton transport
progresses in NPL thin films. Due to the high binding energies of electron-hole
pairs, excitons are generally considered the dominant species responsible for
carrier transfer. We employ spatially and temporally resolved optical
microscopy to map exciton diffusion in perovskite nanocrystal (NC) thin films
between 15 {\deg}C and 50 {\deg}C. At room temperature (RT), we find the
diffusion length to be inversely correlated to the thickness of the
nanocrystals (NCs). With increasing temperatures, exciton diffusion declines
for all NC films, but at different rates. This leads to specific temperature
turnover points, at which thinner NPLs exhibit higher diffusion lengths. We
attribute this anomalous diffusion behavior to the coexistence of excitons and
free electron hole-pairs inside the individual NCs within our temperature
range. The organic ligand shell surrounding the NCs prevents charge transfer.
Accordingly, any time an electron-hole pair spends in the unbound state reduces
the FRET-mediated inter-NC transfer rates and consequently the overall
diffusion. These results clarify how exciton diffusion progresses in strongly
confined halide perovskite NC films, emphasizing critical considerations for
optoelectronic devices.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:31:09 GMT""}]","2022-03-16"
"2203.07699","Cintia Pacchiano Camacho","Antonella Nastasi, Cintia Pacchiano Camacho","Higher integrability and stability of $(p,q)$-quasiminimizers",,,"10.1016/j.jde.2022.09.031",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using purely variational methods, we prove local and global higher
integrability results for upper gradients of quasiminimizers of a
$(p,q)$-Dirichlet integral with fixed boundary data, assuming it belongs to a
slightly better Newtonian space. We also obtain a stability property with
respect to the varying exponents $p$ and $q$. The setting is a doubling metric
measure space supporting a Poincar\'e inequality.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:31:20 GMT""}]","2023-05-01"
"2203.07700","Maria Elena Monzani","Yonatan Kahn, Maria Elena Monzani, Kimberly J. Palladino, Tyler
  Anderson, Deborah Bard, Daniel Baxter, Micah Buuck, Concetta Cartaro, Juan I.
  Collar, Miriam Diamond, Alden Fan, Simon Knapen, Scott Kravitz, Rafael F.
  Lang, Benjamin Nachman, Ibles Olcina Samblas, Igor Ostrovskiy, Aditya Parikh,
  Quentin Riffard, Amy Roberts, Kelly Stifter, Matthew Szydagis, Christopher
  Tunnell, Belina von Krosigk, Dennis Wright, Tien-Tien Yu, Dan Akerib, Ray
  Bunker, Thomas Y. Chen, Graciela B. Gelmini, Doojin Kim, Jong-Chul Park,
  Tarek Saab, Rajeev Singh, Shufang Su, Yu-Dai Tsai, Shawn Westerdale","Snowmass2021 Cosmic Frontier: Modeling, statistics, simulations, and
  computing needs for direct dark matter detection","Contribution to Snowmass 2021",,,,"hep-ex physics.comp-ph physics.data-an","http://creativecommons.org/licenses/by/4.0/","  This paper summarizes the modeling, statistics, simulation, and computing
needs of direct dark matter detection experiments in the next decade.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:34:01 GMT""},{""version"":""v2"",""created"":""Tue, 27 Dec 2022 18:19:30 GMT""}]","2022-12-29"
"2203.07701","Shingo Saito","Minoru Hirose, Hideki Murahara, Shingo Saito","$t$-adic symmetric multiple zeta values for indices in which $1$ and $3$
  appear alternately","23 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the symmetric multiple zeta values in $\mathcal{S}_m$ without
modulo $\pi^2$ reduction for indices in which $1$ and $3$ appear alternately.
We investigate those values that can be expressed as a polynomial of the
Riemann zeta values, and give a conjecturally complete list of explicit
formulas for such values.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:36:32 GMT""},{""version"":""v2"",""created"":""Thu, 14 Apr 2022 02:26:08 GMT""}]","2022-04-15"
"2203.07702","Tilahun Getachew Woreta","T. Getachew-Woreta, M. Povic, J. Masegosa, J. Perea, Z. Beyoro-Amado,
  and Isabel Marquez","Effect of AGN on the morphological properties of their host galaxies in
  the local Universe","15 pages, 15 figures of MN-21-2415-MJ.R2",,"10.1093/mnras/stac851",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  The morphological classification of active galaxies may be affected by the
presence of active galactic nuclei (AGN). In this paper, we provide the most
detailed analysis on how different AGN contributions, from 5% to 75%, to the
total optical light may affect six commonly used morphological parameters and
the final classification of AGN host galaxies at z$\sim$0. We used a local
sample of >2000 visually classified non-active galaxies, to quantify how the
contribution of a bright nuclear point source of different intensity could
affect morphological parameters such as: asymmetry, Abraham concentration
index, Gini, M20 moment of light, smoothness, and Concelice-Bershady
concentration index. We found that most of the morphological parameters are
affected by AGN contributions above 25%, with late-type galaxies being more
affected than early-types. We found that Gini, Abraham concentration index and
asymmetry are the most stable parameters even for AGN contributions above 25%,
in comparison to Concelice-Bershady concentration index and M20 moment of
light. Smoothness parameter shall be avoided when classifying AGN host
galaxies, or at least it shall be used simultaneously in combination with
several other parameters.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:44:17 GMT""}]","2022-04-13"
"2203.07703","Jinxiang Song Mr.","Jinxiang Song, Christian H\""ager, Jochen Schr\""oder, Timothy J.
  O'Shea, Erik Agrell, Henk Wymeersch","Benchmarking and Interpreting End-to-end Learning of MIMO and Multi-User
  Communication","Accepted to Transaction on Wireless Communications",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  End-to-end autoencoder (AE) learning has the potential of exceeding the
performance of human-engineered transceivers and encoding schemes, without a
priori knowledge of communication-theoretic principles. In this work, we aim to
understand to what extent and for which scenarios this claim holds true when
comparing with fair benchmarks. Our particular focus is on memoryless
multiple-input multiple-output (MIMO) and multi-user (MU) systems. Four case
studies are considered: two point-to-point (closed-loop and open-loop MIMO) and
two MU scenarios (MIMO broadcast and interference channels). For the
point-to-point scenarios, we explain some of the performance gains observed in
prior work through the selection of improved baseline schemes that include
geometric shaping as well as bit and power allocation. For the MIMO broadcast
channel, we demonstrate the feasibility of a novel AE method with centralized
learning and decentralized execution. Interestingly, the learned scheme
performs close to nonlinear vector-perturbation precoding and significantly
outperforms conventional zero-forcing. Lastly, we highlight potential pitfalls
when interpreting learned communication schemes. In particular, we show that
the AE for the considered interference channel learns to avoid interference,
albeit in a rotated reference frame. After de-rotating the learned signal
constellation of each user, the resulting scheme corresponds to conventional
time sharing with geometric shaping.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:45:26 GMT""}]","2022-03-16"
"2203.07704","Fengming Dong","Meiqiao Zhang and Fengming Dong","DP color functions versus chromatic polynomials (II)","24 pages, 8 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For any connected graph $G$, let $P(G,m)$ and $P_{DP}(G,m)$ denote the
chromatic polynomial and DP color function of $G$, respectively. It is known
that $P_{DP}(G,m)\le P(G,m)$ holds for every positive integer $m$. Let
$DP_\approx$ (resp. $DP_<$) be the set of graphs $G$ for which there exists an
integer $M$ such that $P_{DP}(G,m)=P(G,m)$ (resp. $P_{DP}(G,m)<P(G,m)$) holds
for all integers $m \ge M$. Determining the sets $DP_\approx$ and $DP_<$ is a
key problem on the study of the DP color function. For any edge set $E_0$ of
$G$, let $\ell_G(E_0)$ be the length of a shortest cycle $C$ in $G$ such that
$|E(C)\cap E_0|$ is odd whenever such a cycle exists, and $\ell_G(E_0)=\infty$
otherwise. Write $\ell_G(E_0)$ as $\ell_G(e)$ if $E_0=\{e\}$.
  In this paper, we prove that if $G$ has a spanning tree $T$ such that
$\ell_G(e)$ is odd for each $e\in E(G)\setminus E(T)$, the edges in
$E(G)\setminus E(T)$ can be labeled as $e_1,e_2,\cdots, e_q$ with
$\ell_G(e_i)\le \ell_G(e_{i+1})$ for all $1\le i\le q-1$ and each edge $e_i$ is
contained in a cycle $C_i$ of length $\ell_G(e_i)$ with $E(C_i)\subseteq
E(T)\cup \{e_j: 1\le j\le i\}$, then $G$ is a graph in $DP_{\approx}$. As a
direct application of this conclusion, all plane near-triangulations and
complete multipartite graphs with at least three partite sets belong to
$DP_{\approx}$. We also show that if $E^*$ is an edge set of $G$ such that
$\ell_{G}(E^*)$ is even and $E^*$ satisfies certain conditions, then $G$
belongs to $DP_<$. In particular, if $\ell_G(E^*)=4$, where $E^*$ is a set of
edges between two disjoint vertex subsets of $G$, then $G$ belongs to $DP_<$.
Both results extend known ones in [DP color functions versus chromatic
polynomials, $Advances\ in\ Applied\ Mathematics$ 134 (2022), article 102301].
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:45:51 GMT""}]","2022-03-16"
"2203.07705","Yangming Shi","Yangming Shi, Haisong Ding, Kai Chen, Qiang Huo","APRNet: Attention-based Pixel-wise Rendering Network for Photo-Realistic
  Text Image Generation",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Style-guided text image generation tries to synthesize text image by
imitating reference image's appearance while keeping text content unaltered.
The text image appearance includes many aspects. In this paper, we focus on
transferring style image's background and foreground color patterns to the
content image to generate photo-realistic text image. To achieve this goal, we
propose 1) a content-style cross attention based pixel sampling approach to
roughly mimicking the style text image's background; 2) a pixel-wise style
modulation technique to transfer varying color patterns of the style image to
the content image spatial-adaptively; 3) a cross attention based multi-scale
style fusion approach to solving text foreground misalignment issue between
style and content images; 4) an image patch shuffling strategy to create style,
content and ground truth image tuples for training. Experimental results on
Chinese handwriting text image synthesis with SCUT-HCCDoc and CASIA-OLHWDB
datasets demonstrate that the proposed method can improve the quality of
synthetic text images and make them more photo-realistic.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:48:34 GMT""}]","2022-03-16"
"2203.07706","Ziyang Song","Liang Xu, Ziyang Song, Dongliang Wang, Jing Su, Zhicheng Fang,
  Chenjing Ding, Weihao Gan, Yichao Yan, Xin Jin, Xiaokang Yang, Wenjun Zeng,
  Wei Wu","ActFormer: A GAN-based Transformer towards General Action-Conditioned 3D
  Human Motion Generation",,,,,"cs.CV cs.GR cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a GAN-based Transformer for general action-conditioned 3D human
motion generation, including not only single-person actions but also
multi-person interactive actions. Our approach consists of a powerful
Action-conditioned motion TransFormer (ActFormer) under a GAN training scheme,
equipped with a Gaussian Process latent prior. Such a design combines the
strong spatio-temporal representation capacity of Transformer, superiority in
generative modeling of GAN, and inherent temporal correlations from the latent
prior. Furthermore, ActFormer can be naturally extended to multi-person motions
by alternately modeling temporal correlations and human interactions with
Transformer encoders. To further facilitate research on multi-person motion
generation, we introduce a new synthetic dataset of complex multi-person combat
behaviors. Extensive experiments on NTU-13, NTU RGB+D 120, BABEL and the
proposed combat dataset show that our method can adapt to various human motion
representations and achieve superior performance over the state-of-the-art
methods on both single-person and multi-person motion generation tasks,
demonstrating a promising step towards a general human motion generator.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:50:12 GMT""},{""version"":""v2"",""created"":""Wed, 23 Nov 2022 05:27:11 GMT""}]","2022-11-24"
"2203.07707","Prakash Chandra Chhipa","Prakash Chandra Chhipa, Richa Upadhyay, Gustav Grund Pihlgren,
  Rajkumar Saini, Seiichi Uchida and Marcus Liwicki","Magnification Prior: A Self-Supervised Method for Learning
  Representations on Breast Cancer Histopathological Images","Accepted to IEEE/CVF Winter Conference on Applications of Computer
  Vision (WACV 2023)",,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  This work presents a novel self-supervised pre-training method to learn
efficient representations without labels on histopathology medical images
utilizing magnification factors. Other state-of-theart works mainly focus on
fully supervised learning approaches that rely heavily on human annotations.
However, the scarcity of labeled and unlabeled data is a long-standing
challenge in histopathology. Currently, representation learning without labels
remains unexplored for the histopathology domain. The proposed method,
Magnification Prior Contrastive Similarity (MPCS), enables self-supervised
learning of representations without labels on small-scale breast cancer dataset
BreakHis by exploiting magnification factor, inductive transfer, and reducing
human prior. The proposed method matches fully supervised learning
state-of-the-art performance in malignancy classification when only 20% of
labels are used in fine-tuning and outperform previous works in fully
supervised learning settings. It formulates a hypothesis and provides empirical
evidence to support that reducing human-prior leads to efficient representation
learning in self-supervision. The implementation of this work is available
online on GitHub -
https://github.com/prakashchhipa/Magnification-Prior-Self-Supervised-Method
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:54:20 GMT""},{""version"":""v2"",""created"":""Thu, 8 Sep 2022 10:46:17 GMT""}]","2022-09-09"
"2203.07708","Chiranjeeb Singha","Chiranjeeb Singha, Sumanta Chakraborty, Naresh Dadhich","Strong cosmic censorship conjecture for a charged BTZ black hole","20 pages, 6 figures","JHEP06(2022)028","10.1007/JHEP06(2022)028",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The strong cosmic censorship conjecture, whose validation asserts the
deterministic nature of general relativity, has been studied for charged BTZ
black holes in three dimensional general relativity, as well as for Nth order
pure Lovelock gravity in d=2N+1 spacetime dimensions. Through both analytical
and numerical routes, we have computed the ratio of the imaginary part of the
quasi-normal mode frequencies with the surface gravity at the Cauchy horizon.
The lowest of which corresponds to the key parameter associated with violation
of strong cosmic censorship conjecture. Our results demonstrate that this
parameter is always less than the critical value $(1/2)$, thereby respecting
the strong cosmic censorship conjecture. This is in complete contrast to the
four or, higher dimensional black holes, as well as for rotating BTZ black
hole, where the violation of strong cosmic censorship conjecture exists.
Implications and possible connection with the stability of the photon orbits
have been discussed.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:56:24 GMT""},{""version"":""v2"",""created"":""Mon, 21 Mar 2022 10:24:52 GMT""},{""version"":""v3"",""created"":""Tue, 7 Jun 2022 06:06:58 GMT""}]","2022-06-08"
"2203.07709","Rui Gao","Shuaijun Wang, Rui Gao, Ruihua Han, Shengduo Chen, Chengyang Li and Qi
  Hao","Adaptive Environment Modeling Based Reinforcement Learning for Collision
  Avoidance in Complex Scenes","accepted by IROS2022",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The major challenges of collision avoidance for robot navigation in crowded
scenes lie in accurate environment modeling, fast perceptions, and trustworthy
motion planning policies. This paper presents a novel adaptive environment
model based collision avoidance reinforcement learning (i.e., AEMCARL)
framework for an unmanned robot to achieve collision-free motions in
challenging navigation scenarios. The novelty of this work is threefold: (1)
developing a hierarchical network of gated-recurrent-unit (GRU) for environment
modeling; (2) developing an adaptive perception mechanism with an attention
module; (3) developing an adaptive reward function for the reinforcement
learning (RL) framework to jointly train the environment model, perception
function and motion planning policy. The proposed method is tested with the
Gym-Gazebo simulator and a group of robots (Husky and Turtlebot) under various
crowded scenes. Both simulation and experimental results have demonstrated the
superior performance of the proposed method over baseline methods.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:57:39 GMT""},{""version"":""v2"",""created"":""Thu, 27 Oct 2022 15:23:44 GMT""}]","2022-10-28"
"2203.07710","Dragan Stankov","Dragan Stankov","The number of nonunimodular roots of a reciprocal polynomial","15 pages, 1 figure, 2 tables",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  We introduce a sequence P_d of monic reciprocal polynomials with integer
coefficients having the central coefficients fixed as well as the peripheral
coefficients. We prove that the ratio between number of nonunimodular roots of
P_d and its degree d has a limit L when d tends to infinity. We show that if
the coefficients of a polynomial can be arbitrarily large in modulus then L can
be arbitrarily close to 0. It seems reasonable to believe that if the
coefficients are bounded then the analogue of Lehmer's Conjecture is true:
either L = 0 or there exists a gap so that L could not be arbitrarily close to
0. We present an algorithm for calculation the limit ratio and a numerical
method for its approximation. We estimated the limit ratio for a family of
polynomials. We calculated the limit ratio of polynomials correlated to many
bivariate polynomials having small Mahler measure.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:58:22 GMT""}]","2022-03-16"
"2203.07711","Xin Sun","Xin Sun, Chenchen Wu, Dachuan Xu, Yang Zhou","Maximizing Modular plus Non-monotone Submodular Functions","21 pages",,,,"cs.DS math.OC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The research problem in this work is the relaxation of maximizing
non-negative submodular plus modular with the entire real number domain as its
value range over a family of down-closed sets. We seek a feasible point
$\mathbf{x}^*$ in the polytope of the given constraint such that
$\mathbf{x}^*\in\arg\max_{\mathbf{x}\in\mathcal{P}\subseteq[0,1]^n}F(\mathbf{x})+L(\mathbf{x})$,
where $F$, $L$ denote the extensions of the underlying submodular function $f$
and modular function $\ell$. We provide an approximation algorithm named
\textsc{Measured Continuous Greedy with Adaptive Weights}, which yields a
guarantee $F(\mathbf{x})+L(\mathbf{x})\geq
\left(1/e-\mathcal{O}(\epsilon)\right)\cdot
f(OPT)+\left(\frac{\beta-e}{e(\beta-1)}-\mathcal{O}(\epsilon)\right)\cdot\ell(OPT)$
under the assumption that the ratio of non-negative part within $\ell(OPT)$ to
the absolute value of its negative part is demonstrated by a parameter
$\beta\in[0, \infty]$, where $OPT$ is the optimal integral solution for the
discrete problem. It is obvious that the factor of $\ell(OPT)$ is $1$ when
$\beta=0$, which means the negative part is completely dominant at this time;
otherwise the factor is closed to $1/e$ whe $\beta\rightarrow\infty$. Our work
first breaks the restriction on the specific value range of the modular
function without assuming non-positivity or non-negativity as previous results
and quantifies the relative variation of the approximation guarantee for
optimal solutions with arbitrary structure. Moreover, we also give an analysis
for the inapproximability of the problem we consider. We show a hardness result
that there exists no polynomial algorithm whose output $S$ satisfies
$f(S)+\ell(S)\geq0.478\cdot f(OPT)+\ell(OPT)$.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:59:47 GMT""},{""version"":""v2"",""created"":""Tue, 12 Apr 2022 07:46:03 GMT""}]","2022-04-13"
"2203.07712","Mohammed Bahutair Mr.","Mohammed Bahutair, Athman Bouguettaya, and Azadeh Ghari Neiat","Multi-Use Trust in Crowdsourced IoT Services","14 pages, accepted and to appear in IEEE Ttransactions on Services
  Computing",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the concept of adaptive trust in crowdsourced IoT services. It
is a customized fine-grained trust tailored for specific IoT consumers. Usage
patterns of IoT consumers are exploited to provide an accurate trust value for
service providers. A novel adaptive trust management framework is proposed to
assess the dynamic trust of IoT services. The framework leverages a novel
detection algorithm to obtain trust indicators that are likely to influence the
trust level of a specific IoT service type. Detected trust indicators are then
used to build service-to-indicator model to evaluate a service's trust at each
indicator. Similarly, a usage-to-indicator model is built to obtain the
importance of each trust indicator for a particular usage scenario. The
per-indicator trust and the importance of each trust indicator are utilized to
obtain an overall value of a given service for a specific consumer. We conduct
a set of experiments on a real dataset to show the effectiveness of the
proposed framework.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 08:00:46 GMT""}]","2022-03-16"
"2203.07713","Zhongzhi Yu","Zhongzhi Yu, Yonggan Fu, Shang Wu, Mengquan Li, Haoran You, Yingyan
  Lin","LDP: Learnable Dynamic Precision for Efficient Deep Neural Network
  Training and Inference",,,,,"cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  Low precision deep neural network (DNN) training is one of the most effective
techniques for boosting DNNs' training efficiency, as it trims down the
training cost from the finest bit level. While existing works mostly fix the
model precision during the whole training process, a few pioneering works have
shown that dynamic precision schedules help DNNs converge to a better accuracy
while leading to a lower training cost than their static precision training
counterparts. However, existing dynamic low precision training methods rely on
manually designed precision schedules to achieve advantageous efficiency and
accuracy trade-offs, limiting their more comprehensive practical applications
and achievable performance. To this end, we propose LDP, a Learnable Dynamic
Precision DNN training framework that can automatically learn a temporally and
spatially dynamic precision schedule during training towards optimal accuracy
and efficiency trade-offs. It is worth noting that LDP-trained DNNs are by
nature efficient during inference. Furthermore, we visualize the resulting
temporal and spatial precision schedule and distribution of LDP trained DNNs on
different tasks to better understand the corresponding DNNs' characteristics at
different training stages and DNN layers both during and after training,
drawing insights for promoting further innovations. Extensive experiments and
ablation studies (seven networks, five datasets, and three tasks) show that the
proposed LDP consistently outperforms state-of-the-art (SOTA) low precision DNN
training techniques in terms of training efficiency and achieved accuracy
trade-offs. For example, in addition to having the advantage of being
automated, our LDP achieves a 0.31\% higher accuracy with a 39.1\% lower
computational cost when training ResNet-20 on CIFAR-10 as compared with the
best SOTA method.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 08:01:46 GMT""}]","2022-03-16"
"2203.07714","Peng Shi","Peng Shi","Wave and Navier-Stokes equations derived under new motion description","30 pages, 4 figures",,,,"physics.class-ph physics.app-ph","http://creativecommons.org/publicdomain/zero/1.0/","  The study shows that the divergence of stress tensor expressed with
displacement and velocity in continuum mechanics has the motion of continuum
exceed the hypothesis of particle motion and a new motion hypothesis is needed
to get traditional defined wave and Navier-Stokes equations. The study points
out that under the traditional understanding of the stress distribution on
material element, the limitation of the conservation of angular momentum of
material element on the stress field changes with the reference point selected
for linearly expanding the stress field, and the calculation of the stress on
an inclined plane is equivalent to denying the necessity of body force in
Cauchy's equation of motion and deeming no waves in elastic media. In
accordance with the form of wave equation and Navier-Stokes equation, a new
motion hypothesis of classical continuum is proposed, which shows that stress
tensor is unnecessary to be symmetric. In the study, the relationship between
the properties of a vector field and its gradient is analyzed, which shows that
the divergence of stress tensor can be expressed with a vector. Then
traditional defined wave equation and Navier-Stokes equation are derived based
on the new motion assumption. The study reveals that the local rigid body
rotation contributes stress and the viscous force defined by Newton is
essentially different from that based on traditional deformation theory.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 08:10:35 GMT""},{""version"":""v2"",""created"":""Wed, 30 Mar 2022 01:52:09 GMT""},{""version"":""v3"",""created"":""Wed, 22 Jun 2022 09:00:34 GMT""},{""version"":""v4"",""created"":""Mon, 8 Aug 2022 02:10:43 GMT""},{""version"":""v5"",""created"":""Thu, 9 Mar 2023 03:01:23 GMT""}]","2023-03-10"
"2203.07715","Yuta  Michimoto","Yuta Michimoto","On fullness of von Neumann algebras associated with non-singular Borel
  equivalence relations","15 pages",,,,"math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is shown by Houdayer-Isono that a group measure space von Neumann algebra
is a full factor if the group is countable discrete and bi-exact, and the
action is strongly ergodic, essentially free and non-singular. Recently,
bi-exactness for locally compact groups was introduced by Brothier-Deprez-Vaes.
In this paper, we will show that Houdayer-Isono type result holds for bi-exact
locally compact groups.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 08:12:13 GMT""}]","2022-03-16"
"2203.07716","Xu Chen","Xu Chen, Wei Feng, Ning Ge and Yan Zhang","Zero Trust Architecture for 6G Security",,,,,"cs.NI cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The upcoming sixth generation (6G) network is envisioned to be more open and
heterogeneous than earlier generations. This challenges conventional security
architectures, which typically rely on the construction of a security perimeter
at network boundaries. In this article, we propose a software-defined zero
trust architecture (ZTA) for 6G networks, which is promising for establishing
an elastic and scalable security regime. This architecture achieves secure
access control through adaptive collaborations among the involved control
domains, and can effectively prevent malicious access behaviors such as
distributed denial of service (DDoS) attacks, malware spread, and zero-day
exploits. We also introduce key design aspects of this architecture and show
the simulation results of a case study, which shows the effectiveness and
robustness of ZTA for 6G. Furthermore, we discuss open issues to further
promote this new architecture.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 08:13:29 GMT""}]","2022-03-16"
"2203.07717","D\'aniel Marx","D\'aniel Marx","Modern Lower Bound Techniques in Database Theory and Constraint
  Satisfaction","PODS 2021 Tutorial",,"10.1145/3452021.3458814",,"cs.CC cs.DB","http://creativecommons.org/licenses/by/4.0/","  Conditional lower bounds based on $P\neq NP$, the Exponential-Time Hypothesis
(ETH), or similar complexity assumptions can provide very useful information
about what type of algorithms are likely to be possible. Ideally, such lower
bounds would be able to demonstrate that the best known algorithms are
essentially optimal and cannot be improved further. In this tutorial, we
overview different types of lower bounds, and see how they can be applied to
problems in database theory and constraint satisfaction.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 08:16:21 GMT""}]","2022-03-16"
"2203.07718","Shivoh Chirayil Nandakumar","Shivoh Chirayil Nandakumar, Samuel Harper, Daniel Mitchell, Jamie
  Blanche, Theodore Lim, Ikuo Yamamoto and David Flynn","Bio-inspired Multi-robot Autonomy","A preprint submit to IROS 2022",,,,"cs.RO eess.IV","http://creativecommons.org/licenses/by/4.0/","  Increasingly, high value industrial markets are driving trends for improved
functionality and resilience from resident autonomous systems. This led to an
increase in multi-robot fleets that aim to leverage the complementary
attributes of the diverse platforms. In this paper we introduce a novel
bio-inspired Symbiotic System of Systems Approach (SSOSA) for designing the
operational governance of a multi-robot fleet consisting of ground-based
quadruped and wheeled platforms. SSOSA couples the MR-fleet to the resident
infrastructure monitoring systems into one collaborative digital commons. The
hyper visibility of the integrated distributed systems, achieved through a
latency bidirectional communication network, supports collaboration,
coordination and corroboration (3C) across the integrated systems. In our
experiment, we demonstrate how an operator can activate a pre-determined
autonomous mission and utilize SSOSA to overcome intrinsic and external risks
to the autonomous missions. We demonstrate how resilience can be enhanced by
local collaboration between SPOT and Husky wherein we detect a replacement
battery, and utilize the manipulator arm of SPOT to support a Clearpath Husky
A200 wheeled robotic platform. This allows for increased resilience of an
autonomous mission as robots can collaborate to ensure the battery state of the
Husky robot. Overall, these initial results demonstrate the value of a SSOSA
approach in addressing a key operational barrier to scalable autonomy, the
resilience.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 08:17:30 GMT""}]","2022-03-16"
"2203.07719","Jose Luis Hernandez-Pastora","J.L. Hernandez-Pastora","Whom actually do multipole moments belong to?",,"The European Physical Journal C, Eur. Phys. J. C (2022) 82:224","10.1140/epjc/s10052-022-10190-7",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using an integral definition to calculate the relativistic multipole moments
(RMM), and the ensuing generalized relativistic Gauss theorem, we prove that
the evaluation of that volume integral in Erez-Rosen coordinates, leads to a
specific link between the RMM and the source of the exterior space--time,
provided we have a global static axisymmetric metric in that coordinate system
for any Weyl exterior field. This result allows to establish a relationship
between the RMM and certain volume integral expressions involving the material
content of the source from its energy-momentum tensor as well as the interior
metric. In particular the relativistic quadrupole moment for the Erez-Rosen
space-time is obtained.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 08:17:59 GMT""}]","2022-03-16"
"2203.07720","Guanyu Cai","Guanyu Cai, Yixiao Ge, Binjie Zhang, Alex Jinpeng Wang, Rui Yan,
  Xudong Lin, Ying Shan, Lianghua He, Xiaohu Qie, Jianping Wu, Mike Zheng Shou","Revitalize Region Feature for Democratizing Video-Language Pre-training
  of Retrieval",,,,,"cs.CV","http://creativecommons.org/publicdomain/zero/1.0/","  Recent dominant methods for video-language pre-training (VLP) learn
transferable representations from the raw pixels in an end-to-end manner to
achieve advanced performance on downstream video-language retrieval. Despite
the impressive results, VLP research becomes extremely expensive with the need
for massive data and a long training time, preventing further explorations. In
this work, we revitalize region features of sparsely sampled video clips to
significantly reduce both spatial and temporal visual redundancy towards
democratizing VLP research at the same time achieving state-of-the-art results.
Specifically, to fully explore the potential of region features, we introduce a
novel bidirectional region-word alignment regularization that properly
optimizes the fine-grained relations between regions and certain words in
sentences, eliminating the domain/modality disconnections between pre-extracted
region features and text. Extensive results of downstream video-language
retrieval tasks on four datasets demonstrate the superiority of our method on
both effectiveness and efficiency, \textit{e.g.}, our method achieves competing
results with 80\% fewer data and 85\% less pre-training time compared to the
most efficient VLP method so far \cite{lei2021less}. The code will be available
at \url{https://github.com/showlab/DemoVLP}.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 08:18:27 GMT""},{""version"":""v2"",""created"":""Sat, 19 Mar 2022 08:14:27 GMT""},{""version"":""v3"",""created"":""Tue, 7 Feb 2023 07:54:51 GMT""}]","2023-02-08"
"2203.07721","Amin Salehi","Muhammad Yarahmadi and Amin Salehi","Comparison of the interaction between scalar fields as dark energy with
  neutrinos and put constraint on neutrino mass in these models","17 pages , 7 figures",,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we considered the interaction neutrino with three scalar
fields(phantom, quintessence, and quintom model) and put constraints on the
total mass of neutrinos, and comparison the interaction constant $ \beta $ in
these models. The data were used in this paper are supernova type Ia(pantheon
catalog), CMB and BAO data. For each model, we first investigate the results
obtained from Pantheon data, then survey the CMB and BAO data, and finally, the
total data from these catalogs. It seems that using a combination of data
produces more favorable results. For combination data, we find that the total
mass of neutrino $\sum m_{\nu}< 0.121 eV$ $(95\% $ Confidence Level (C.L.) for
quintom model and $\sum m_{\nu}< 0.19 eV$ $(95\% $ Confidence Level (C.L.) for
phantom model and $\sum m_{\nu}< 0.124 eV$ $(95\% $ Confidence Level (C.L.) for
quintessence model. These results are in good agreement with the results of
Planck 2018 where the limit of the total neutrino mass is $\sum m_{\nu}<0.12
eV$ ($95\%$ C.L., TT, TE, EE+lowE+lensing+BAO)
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 08:24:01 GMT""}]","2022-03-16"
"2203.07722","Shuai Lu","Shuai Lu, Nan Duan, Hojae Han, Daya Guo, Seung-won Hwang, Alexey
  Svyatkovskiy","ReACC: A Retrieval-Augmented Code Completion Framework","Published in ACL 2022",,,,"cs.SE cs.AI cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Code completion, which aims to predict the following code token(s) according
to the code context, can improve the productivity of software development.
Recent work has proved that statistical language modeling with transformers can
greatly improve the performance in the code completion task via learning from
large-scale source code datasets. However, current approaches focus only on
code context within the file or project, i.e. internal context. Our distinction
is utilizing ""external"" context, inspired by human behaviors of copying from
the related code snippets when writing code. Specifically, we propose a
retrieval-augmented code completion framework, leveraging both lexical copying
and referring to code with similar semantics by retrieval. We adopt a
stage-wise training approach that combines a source code retriever and an
auto-regressive language model for programming language. We evaluate our
approach in the code completion task in Python and Java programming languages,
achieving a state-of-the-art performance on CodeXGLUE benchmark.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 08:25:08 GMT""}]","2022-03-16"
"2203.07723","Qi'an Guan","Qi'an Guan, Zhitong Mi, Zheng Yuan","Boundary points, minimal $L^2$ integrals and concavity property II: on
  weakly pseudoconvex K\""ahler manifolds","65 pages, some typos are corrected",,,,"math.CV math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we consider minimal $L^2$ integrals on the sublevel sets of
plurisubharmonic functions on weakly pseudoconvex K\""ahler manifolds with
Lebesgue measurable gain related to modules at boundary points of the sublevel
sets, and establish a concavity property of the minimal $L^2$ integrals. As
applications, we present a necessary condition for the concavity degenerating
to linearity, a concavity property related to modules at inner points of the
sublevel sets, an optimal support function related to the modules, a strong
openness property of the modules and a twisted version, an effectiveness result
of the strong openness property of the modules.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 08:32:07 GMT""},{""version"":""v2"",""created"":""Thu, 17 Mar 2022 01:25:58 GMT""},{""version"":""v3"",""created"":""Sat, 21 May 2022 13:25:34 GMT""},{""version"":""v4"",""created"":""Fri, 3 Jun 2022 04:33:15 GMT""}]","2022-06-06"
"2203.07724","Kaican Li","Kaican Li, Kai Chen, Haoyu Wang, Lanqing Hong, Chaoqiang Ye, Jianhua
  Han, Yukuai Chen, Wei Zhang, Chunjing Xu, Dit-Yan Yeung, Xiaodan Liang,
  Zhenguo Li, Hang Xu","CODA: A Real-World Road Corner Case Dataset for Object Detection in
  Autonomous Driving","ECCV 2022",,,,"cs.CV cs.LG cs.RO","http://creativecommons.org/licenses/by/4.0/","  Contemporary deep-learning object detection methods for autonomous driving
usually assume prefixed categories of common traffic participants, such as
pedestrians and cars. Most existing detectors are unable to detect uncommon
objects and corner cases (e.g., a dog crossing a street), which may lead to
severe accidents in some situations, making the timeline for the real-world
application of reliable autonomous driving uncertain. One main reason that
impedes the development of truly reliably self-driving systems is the lack of
public datasets for evaluating the performance of object detectors on corner
cases. Hence, we introduce a challenging dataset named CODA that exposes this
critical problem of vision-based detectors. The dataset consists of 1500
carefully selected real-world driving scenes, each containing four object-level
corner cases (on average), spanning more than 30 object categories. On CODA,
the performance of standard object detectors trained on large-scale autonomous
driving datasets significantly drops to no more than 12.8% in mAR. Moreover, we
experiment with the state-of-the-art open-world object detector and find that
it also fails to reliably identify the novel objects in CODA, suggesting that a
robust perception system for autonomous driving is probably still far from
reach. We expect our CODA dataset to facilitate further research in reliable
detection for real-world autonomous driving. Our dataset will be released at
https://coda-dataset.github.io.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 08:32:56 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jul 2022 15:32:48 GMT""},{""version"":""v3"",""created"":""Sat, 17 Sep 2022 04:52:35 GMT""}]","2022-09-20"
"2203.07725","Yiming Lei","Yiming Lei, Haiping Zhu, Junping Zhang, Hongming Shan","Meta Ordinal Regression Forest for Medical Image Classification with
  Ordinal Labels",,"IEEE/CAA Journal of Automatica Sinica 2022","10.1109/JAS.2022.105668","9(7):1233-1247","cs.CV","http://creativecommons.org/licenses/by/4.0/","  The performance of medical image classification has been enhanced by deep
convolutional neural networks (CNNs), which are typically trained with
cross-entropy (CE) loss. However, when the label presents an intrinsic ordinal
property in nature, e.g., the development from benign to malignant tumor, CE
loss cannot take into account such ordinal information to allow for better
generalization. To improve model generalization with ordinal information, we
propose a novel meta ordinal regression forest (MORF) method for medical image
classification with ordinal labels, which learns the ordinal relationship
through the combination of convolutional neural network and differential forest
in a meta-learning framework. The merits of the proposed MORF come from the
following two components: a tree-wise weighting net (TWW-Net) and a grouped
feature selection (GFS) module. First, the TWW-Net assigns each tree in the
forest with a specific weight that is mapped from the classification loss of
the corresponding tree. Hence, all the trees possess varying weights, which is
helpful for alleviating the tree-wise prediction variance. Second, the GFS
module enables a dynamic forest rather than a fixed one that was previously
used, allowing for random feature perturbation. During training, we
alternatively optimize the parameters of the CNN backbone and TWW-Net in the
meta-learning framework through calculating the Hessian matrix. Experimental
results on two medical image classification datasets with ordinal labels, i.e.,
LIDC-IDRI and Breast Ultrasound Dataset, demonstrate the superior performances
of our MORF method over existing state-of-the-art methods.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 08:43:57 GMT""}]","2022-07-05"
"2203.07726","Wolfgang Altmannshofer","Wolfgang Altmannshofer, Jure Zupan","Snowmass White Paper: Flavor Model Building","34 pages, 2 figures; contribution to Snowmass 2021; solicited
  whitepaper for TF08; comments are welcome; v2: references added; v3: more
  references added; v4: figure 1 corrected, more references added; v5: typos
  corrected",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this white paper for the Snowmass process, we summarize the role flavor
model building plays in the quest for new physics. We review approaches to
address the non-generic flavor structure of the Standard Model and discuss how
new physics models can be made compatible with the stringent constraints from
flavor changing processes that indirectly probe very high scales. We also give
an overview of the persistent anomalies in B decays and the anomalous magnetic
moment of the muon and some of their most popular new physics explanations.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 08:47:33 GMT""},{""version"":""v2"",""created"":""Mon, 11 Apr 2022 16:29:44 GMT""},{""version"":""v3"",""created"":""Thu, 2 Jun 2022 00:28:03 GMT""},{""version"":""v4"",""created"":""Tue, 30 Aug 2022 19:22:12 GMT""},{""version"":""v5"",""created"":""Wed, 22 Mar 2023 18:29:17 GMT""}]","2023-03-24"
"2203.07727","Xiangzhong Zeng","Xiangzhong Zeng, Lyuzhou Ye, Long Cao, Rui-Xue Xu, Xiao Zheng, and
  Massimiliano Di Ventra","Kondo cooling in quantum impurity systems","6 pages, 4 figures",,,,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Peltier effect is the reverse phenomenon of the Seebeck effect, and has
been observed experimentally in nanoscale junctions. However, despite its
promising applications in local cooling of nanoelectronic devices, the role of
strong electron correlations on such a phenomenon is still unclear. Here, by
analyzing the thermoelectric properties of quantum impurity systems out of
equilibrium, we unveil the essential role of electron-electron interactions and
quantum resonant states in Peltier cooling, leading to the prediction of the
Kondo cooling phenomenon. The existence of such Kondo cooling is validated by a
reverse heat current and a lowered local temperature in a model junction. The
discovery of this unconventional Peltier cooling offers a new approach toward
nano-refrigeration, and highlights the unique role of strong electron
correlations in nonequilibrium quantum systems.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 08:48:33 GMT""}]","2022-03-16"
"2203.07728","Wadii Boulila Prof.","Wadii Boulila, Adel Ammar, Bilel Benjdira, Anis Koubaa","Securing the Classification of COVID-19 in Chest X-ray Images: A
  Privacy-Preserving Deep Learning Approach",,,,,"eess.IV cs.CR cs.CV","http://creativecommons.org/licenses/by/4.0/","  Deep learning (DL) is being increasingly utilized in healthcare-related
fields due to its outstanding efficiency. However, we have to keep the
individual health data used by DL models private and secure. Protecting data
and preserving the privacy of individuals has become an increasingly prevalent
issue. The gap between the DL and privacy communities must be bridged. In this
paper, we propose privacy-preserving deep learning (PPDL)-based approach to
secure the classification of Chest X-ray images. This study aims to use Chest
X-ray images to their fullest potential without compromising the privacy of the
data that it contains. The proposed approach is based on two steps: encrypting
the dataset using partially homomorphic encryption and training/testing the DL
algorithm over the encrypted images. Experimental results on the COVID-19
Radiography database show that the MobileNetV2 model achieves an accuracy of
94.2% over the plain data and 93.3% over the encrypted data.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 08:48:47 GMT""}]","2022-03-16"
"2203.07729","Tarik Akan","Tarik Akan, Elif Cincioglu, Altug Ozpineci, Adnan Tegmen","Semileptonic B_c decays to P-wave charmonia in the light-cone QCDSR","25 pages, 9 figures, 7 tables, minor changes, typos corrected",,"10.1016/j.nuclphysa.2023.122642",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  B_c mesons are laboratories for probing heavy quark physics. Furthermore,
they decay into charmonia and hence their decays can be used to analyze
possible exotic charmonium. In this work, the semileptonic decays of B_c mesons
into P wave charmonia are analysed using light cone QCD sum rules (LCSR). The
distributions amplitudes for the charmonia are taken from a quark model
computation. The obtained decay rates for the ground state and excited
charmonia are compared with the results found in the literature.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 08:49:40 GMT""},{""version"":""v2"",""created"":""Tue, 6 Sep 2022 07:54:01 GMT""},{""version"":""v3"",""created"":""Mon, 27 Mar 2023 11:32:53 GMT""}]","2023-03-28"
"2203.07730","Karol Duda","Karol Duda, Aleksander Ivanov","Computable paradoxical decompositions","Overlap with Sections 6-8 of arXiv:1904.02640. To be published in
  International Journal of Algebra and Computation",,,,"math.LO math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a computable version of Hall's Harem Theorem and apply it to
computable versions of Tarski's alternative theorem.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 08:53:05 GMT""}]","2022-03-16"
"2203.07731","Rini Anggrainingsih","Rini Anggrainingsih, Ghulam Mubashar Hassan and Amitava Datta","Evaluating BERT-based Pre-training Language Models for Detecting
  Misinformation","17 pages, 2 figures, 10 tables",,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  It is challenging to control the quality of online information due to the
lack of supervision over all the information posted online. Manual checking is
almost impossible given the vast number of posts made on online media and how
quickly they spread. Therefore, there is a need for automated rumour detection
techniques to limit the adverse effects of spreading misinformation. Previous
studies mainly focused on finding and extracting the significant features of
text data. However, extracting features is time-consuming and not a highly
effective process. This study proposes the BERT- based pre-trained language
models to encode text data into vectors and utilise neural network models to
classify these vectors to detect misinformation. Furthermore, different
language models (LM) ' performance with different trainable parameters was
compared. The proposed technique is tested on different short and long text
datasets. The result of the proposed technique has been compared with the
state-of-the-art techniques on the same datasets. The results show that the
proposed technique performs better than the state-of-the-art techniques. We
also tested the proposed technique by combining the datasets. The results
demonstrated that the large data training and testing size considerably
improves the technique's performance.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 08:54:36 GMT""}]","2022-03-16"
"2203.07732","Abdallah Dib","Abdallah Dib, Junghyun Ahn, Cedric Thebault, Philippe-Henri Gosselin,
  Louis Chevallier","S2F2: Self-Supervised High Fidelity Face Reconstruction from Monocular
  Image","24 Pages, 22 Figures",,,,"cs.CV cs.GR cs.LG","http://creativecommons.org/licenses/by/4.0/","  We present a novel face reconstruction method capable of reconstructing
detailed face geometry, spatially varying face reflectance from a single
monocular image. We build our work upon the recent advances of DNN-based
auto-encoders with differentiable ray tracing image formation, trained in
self-supervised manner. While providing the advantage of learning-based
approaches and real-time reconstruction, the latter methods lacked fidelity. In
this work, we achieve, for the first time, high fidelity face reconstruction
using self-supervised learning only. Our novel coarse-to-fine deep architecture
allows us to solve the challenging problem of decoupling face reflectance from
geometry using a single image, at high computational speed. Compared to
state-of-the-art methods, our method achieves more visually appealing
reconstruction.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 08:55:45 GMT""},{""version"":""v2"",""created"":""Tue, 5 Apr 2022 11:52:51 GMT""}]","2022-04-06"
"2203.07733","Shikhar Mittal","Shikhar Mittal (TIFR) and Girish Kulkarni (TIFR)","Implications of the cosmological 21-cm absorption profile for
  high-redshift star formation and deep JWST surveys","Published in MNRAS","MNRAS 515 (2022) 2901","10.1093/mnras/stac1961","TIFR/TH/22-14","astro-ph.CO astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Apart from its anomalously large depth, the cosmological 21-cm absorption
signal measured by the EDGES collaboration also has a shape that is distinctly
different from theoretical predictions. Models with non-traditional components
such as super-adiabatic baryonic cooling or an excess radio background explain
the depth of the observed profile, but still conspicuously fail to explain its
shape. In this paper, we quantify the requirements imposed by the EDGES
measurement on sources of Ly $\alpha$ and X-ray photons in the presence of
excess radio background at cosmic dawn. In extreme cases, the Ly $\alpha$ and
X-ray emissivities require to be enhanced by up to an order of magnitude
relative to traditional models. Furthermore, this enhancement needs to be
active only for a short duration. We find that under conventional assumptions
for the cosmic star formation rate density, standard stellar populations are
incapable of meeting these conditions. Only highly unusual models of massive
metal-free stars seem to provide a possible mechanism. Conversely, if the
sources of Ly $\alpha$ and X-ray photons are compelled to have standard
properties, the EDGES measurement puts strong demands on the cosmic star
formation rate density. This provides interesting falsifiable predictions for
high-redshift galaxy surveys enabled by \textit{James Webb Space Telescope}
(\textit{JWST}). We derive predictions for galaxy UV luminosity functions and
number densities, and show that a deep \textit{JWST} survey with a limiting UV
magnitude of $m_\mathrm{UV,lim}=32$ would potentially be able to rule out the
predictions enforced by the EDGES measurement.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 08:57:07 GMT""},{""version"":""v2"",""created"":""Mon, 11 Jul 2022 16:18:36 GMT""},{""version"":""v3"",""created"":""Tue, 2 Aug 2022 14:59:42 GMT""}]","2022-08-03"
"2203.07734","David Izquierdo-Villalba","David Izquierdo-Villalba, Silvia Bonoli, Yetli Rosas-Guevara, Volker
  Springel, Simon D.M. White, Tommaso Zana, Massimo Dotti, Daniele Spinoso,
  Matteo Bonetti, Alessandro Lupi","Disc instability and bar formation: view from the IllustrisTNG
  simulations","15 pages, 12 Figures, Accepted by MNRAS",,"10.1093/mnras/stac1413",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We make use of z = 0 samples of strongly barred and unbarred disc galaxies
from the TNG100 and TNG50 cosmological hydrodynamical simulations to assess the
performance of the simple disc instability criterion proposed by Efstathiou,
Lake & Negroponte (1982) (ELN-criterion). We find that strongly barred galaxies
generally assemble earlier, are more star-dominated in their central regions,
and have more massive and more compact discs than unbarred galaxies. The
ELN-criterion successfully identifies ~75% and ~80% of the strongly barred and
the unbarred galaxies, respectively. Strongly barred galaxies that the
criterion fails to identify tend to have more extended discs, higher spin
values and bars that assembled later than is typical for the bulk of the barred
population. The bars in many of these cases appear to be produced by an
interaction with a close neighbour (i.e. to be externally triggered) rather
than to result from secular growth in the disc. On the other hand, we find that
unbarred galaxies misclassified as barred by the ELN-criterion typically have
stellar discs similar to those of barred galaxies, although more extended in
the vertical direction and less star-dominated in their central regions,
possibly reflecting later formation times. In addition, the bulge component of
these galaxies is significantly more prominent at early times than in the
strongly barred sample. Thus, the ELN-criterion robustly identifies secular bar
instabilities in most simulated disc galaxies, but additional environmental
criteria are needed to account for interaction-induced bar formation.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 09:00:19 GMT""},{""version"":""v2"",""created"":""Thu, 19 May 2022 10:18:40 GMT""}]","2022-06-01"
"2203.07735","Soyeong Jeong","Soyeong Jeong, Jinheon Baek, Sukmin Cho, Sung Ju Hwang, Jong C. Park","Augmenting Document Representations for Dense Retrieval with
  Interpolation and Perturbation","ACL 2022",,,,"cs.IR cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dense retrieval models, which aim at retrieving the most relevant document
for an input query on a dense representation space, have gained considerable
attention for their remarkable success. Yet, dense models require a vast amount
of labeled training data for notable performance, whereas it is often
challenging to acquire query-document pairs annotated by humans. To tackle this
problem, we propose a simple but effective Document Augmentation for dense
Retrieval (DAR) framework, which augments the representations of documents with
their interpolation and perturbation. We validate the performance of DAR on
retrieval tasks with two benchmark datasets, showing that the proposed DAR
significantly outperforms relevant baselines on the dense retrieval of both the
labeled and unlabeled documents.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 09:07:38 GMT""},{""version"":""v2"",""created"":""Wed, 16 Mar 2022 09:29:55 GMT""}]","2022-03-17"
"2203.07736","Yi Cheng","Yi Cheng, Li Kuang","CSRS: Code Search with Relevance Matching and Semantic Matching",,,,,"cs.SE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Developers often search and reuse existing code snippets in the process of
software development. Code search aims to retrieve relevant code snippets from
a codebase according to natural language queries entered by the developer. Up
to now, researchers have already proposed information retrieval (IR) based
methods and deep learning (DL) based methods. The IR-based methods focus on
keyword matching, that is to rank codes by relevance between queries and code
snippets, while DL-based methods focus on capturing the semantic correlations.
However, the existing methods do not consider capturing two matching signals
simultaneously. Therefore, in this paper, we propose CSRS, a code search model
with relevance matching and semantic matching. CSRS comprises (1) an embedding
module containing convolution kernels of different sizes which can extract
n-gram embeddings of queries and codes, (2) a relevance matching module that
measures lexical matching signals, and (3) a co-attention based semantic
matching module to capture the semantic correlation. We train and evaluate CSRS
on a dataset with 18.22M and 10k code snippets. The experimental results
demonstrate that CSRS achieves an MRR of 0.614, which outperforms two
state-of-the-art models DeepCS and CARLCS-CNN by 33.77% and 18.53%
respectively. In addition, we also conducted several experiments to prove the
effectiveness of each component of CSRS.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 09:10:18 GMT""},{""version"":""v2"",""created"":""Sat, 26 Mar 2022 06:43:18 GMT""},{""version"":""v3"",""created"":""Wed, 30 Mar 2022 07:58:02 GMT""},{""version"":""v4"",""created"":""Wed, 27 Apr 2022 06:56:00 GMT""}]","2022-04-28"
"2203.07737","Haofeng Liu","Heng Li, Haofeng Liu, Yan Hu, Huazhu Fu, Yitian Zhao, Hanpei Miao,
  Jiang Liu","An Annotation-free Restoration Network for Cataractous Fundus Images","Copyright 2022 IEEE. Personal use of this material is permitted.
  Permission from IEEE must be obtained for all other uses, in any current or
  future media, including reprinting/republishing this material for advertising
  or promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works","IEEE Transactions on Medical Imaging,2022, 41(7), 1699-1710","10.1109/TMI.2022.3147854",,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cataracts are the leading cause of vision loss worldwide. Restoration
algorithms are developed to improve the readability of cataract fundus images
in order to increase the certainty in diagnosis and treatment for cataract
patients. Unfortunately, the requirement of annotation limits the application
of these algorithms in clinics. This paper proposes a network to
annotation-freely restore cataractous fundus images (ArcNet) so as to boost the
clinical practicability of restoration. Annotations are unnecessary in ArcNet,
where the high-frequency component is extracted from fundus images to replace
segmentation in the preservation of retinal structures. The restoration model
is learned from the synthesized images and adapted to real cataract images.
Extensive experiments are implemented to verify the performance and
effectiveness of ArcNet. Favorable performance is achieved using ArcNet against
state-of-the-art algorithms, and the diagnosis of ocular fundus diseases in
cataract patients is promoted by ArcNet. The capability of properly restoring
cataractous images in the absence of annotated data promises the proposed
algorithm outstanding clinical practicability.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 09:11:48 GMT""}]","2022-10-19"
"2203.07738","Shuai Shao","Shuai Shao, Lei Xing, Weifeng Liu, Yanjiang Wang, and Baodi Liu","GCT: Graph Co-Training for Semi-Supervised Few-Shot Learning",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Few-shot learning (FSL), purposing to resolve the problem of data-scarce, has
attracted considerable attention in recent years. A popular FSL framework
contains two phases: (i) the pre-train phase employs the base data to train a
CNN-based feature extractor. (ii) the meta-test phase applies the frozen
feature extractor to novel data (novel data has different categories from base
data) and designs a classifier for recognition. To correct few-shot data
distribution, researchers propose Semi-Supervised Few-Shot Learning (SSFSL) by
introducing unlabeled data. Although SSFSL has been proved to achieve
outstanding performances in the FSL community, there still exists a fundamental
problem: the pre-trained feature extractor can not adapt to the novel data
flawlessly due to the cross-category setting. Usually, large amounts of noises
are introduced to the novel feature. We dub it as Feature-Extractor-Maladaptive
(FEM) problem. To tackle FEM, we make two efforts in this paper. First, we
propose a novel label prediction method, Isolated Graph Learning (IGL). IGL
introduces the Laplacian operator to encode the raw data to graph space, which
helps reduce the dependence on features when classifying, and then project
graph representation to label space for prediction. The key point is that: IGL
can weaken the negative influence of noise from the feature representation
perspective, and is also flexible to independently complete training and
testing procedures, which is suitable for SSFSL. Second, we propose Graph
Co-Training (GCT) to tackle this challenge from a multi-modal fusion
perspective by extending the proposed IGL to the co-training framework. GCT is
a semi-supervised method that exploits the unlabeled samples with two modal
features to crossly strengthen the IGL classifier.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 09:13:35 GMT""},{""version"":""v2"",""created"":""Sat, 15 Oct 2022 05:12:13 GMT""},{""version"":""v3"",""created"":""Sat, 22 Oct 2022 16:01:30 GMT""}]","2022-10-26"
"2203.07739","Doyeol (David) Ahn","Byeongyong Park, Doyeol (David) Ahn","T-count optimization of approximate quantum Fourier transform",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The quantum Fourier transform (QFT) is a ubiquitous quantum operation that is
used in numerous quantum computing applications. The major obstacle to
constructing a QFT circuit is that numerous elementary gates are required.
Among the elementary gates, T gates dominate the cost of fault-tolerant
implementation. Currently, the smallest-known T-count required to construct an
n-qubit QFT circuit approximated to error O(\varepsilon) is
~8nlog_2(n/\varepsilon). Moreover, the depth of T gates (T-depth) in the
approximate QFT circuit is ~2nlog_2(n/\varepsilon). This approximate QFT
circuit was constructed using Toffoli gates and quantum adders. In this study,
we present a new n-qubit QFT circuit approximated to error O(\varepsilon). Our
approximate QFT circuit shows a T-count of ~4nlog_2(n/\varepsilon) and a
T-depth of ~nlog_2(n/\varepsilon). Toffoli gates, which account for half of the
T-count in the approximate QFT circuit reported in the previous study, are
unnecessary in our construction. Quantum adders, which dominate the leading
order term of T-depth in our approximate QFT circuit, are arranged in parallel
to reduce T-depth.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 09:13:51 GMT""},{""version"":""v2"",""created"":""Mon, 4 Jul 2022 04:17:23 GMT""},{""version"":""v3"",""created"":""Thu, 28 Jul 2022 11:34:09 GMT""},{""version"":""v4"",""created"":""Sun, 22 Jan 2023 06:35:02 GMT""}]","2023-01-24"
"2203.07740","Yabin Zhang","Yabin Zhang, Minghan Li, Ruihuang Li, Kui Jia, Lei Zhang","Exact Feature Distribution Matching for Arbitrary Style Transfer and
  Domain Generalization","To appear in CVPR2022; codes and supplementary material are available
  at: https://github.com/YBZh/EFDM","CVPR2022 camera ready",,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Arbitrary style transfer (AST) and domain generalization (DG) are important
yet challenging visual learning tasks, which can be cast as a feature
distribution matching problem. With the assumption of Gaussian feature
distribution, conventional feature distribution matching methods usually match
the mean and standard deviation of features. However, the feature distributions
of real-world data are usually much more complicated than Gaussian, which
cannot be accurately matched by using only the first-order and second-order
statistics, while it is computationally prohibitive to use high-order
statistics for distribution matching. In this work, we, for the first time to
our best knowledge, propose to perform Exact Feature Distribution Matching
(EFDM) by exactly matching the empirical Cumulative Distribution Functions
(eCDFs) of image features, which could be implemented by applying the Exact
Histogram Matching (EHM) in the image feature space. Particularly, a fast EHM
algorithm, named Sort-Matching, is employed to perform EFDM in a plug-and-play
manner with minimal cost. The effectiveness of our proposed EFDM method is
verified on a variety of AST and DG tasks, demonstrating new state-of-the-art
results. Codes are available at https://github.com/YBZh/EFDM.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 09:18:14 GMT""},{""version"":""v2"",""created"":""Fri, 25 Mar 2022 02:40:25 GMT""}]","2022-03-28"
"2203.07741","Maxim Malyshev","A.V. Lipatov, G.I. Lykasov, M.A. Malyshev, S.M. Turchikhin","Probing the proton structure with associated vector boson and heavy
  flavor jet production at the LHC","15 pages, 5 figures",,"10.1103/PhysRevD.106.054017",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We consider the production of $Z$ bosons associated with heavy (charm and
beauty) jets at the LHC energies using two scenarios based on the transverse
momentum dependent (TMD) parton densities in a proton. The first of them
employs the Catani-Ciafaloni-Fiorani-Marchesini gluon evolution and is
implemented in the Monte-Carlo event generator PEGASUS. Here, the heavy quarks
are always produced in the hard partonic scattering. The second scheme is based
on the parton branching approach, currently implemented into the Monte-Carlo
event generator CASCADE. In this scenario, the $Z$ + jets sample is generated
and then events containing the heavy flavor jet in a final state are selected.
We compare the predictions obtained within these two TMD-based approaches to
each other, investigate their sensitivity to the TMD gluon densities in a
proton and estimate the effects coming from parton showers and double parton
scattering mechanism. Additionally, we compare our predictions with the results
of traditional (collinear) pQCD calculations performed at NLO accuracy. It is
shown that the TMD-based results agree with the LHC experimental data collected
at $\sqrt s = 8$ and $13$ TeV. We discuss the sensitivity of observables to the
quark distributions in a proton and present predictions to search for the
intrinsic charm signal in forthcoming analyses of the LHC experimental data.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 09:19:55 GMT""}]","2022-10-05"
"2203.07742","Nguyen Phi","Phi Nguyen Van, Tung Cao Hoang, Dung Nguyen Manh, Quan Nguyen Minh,
  Long Tran Quoc","ViWOZ: A Multi-Domain Task-Oriented Dialogue Systems Dataset For
  Low-resource Language",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Most of the current task-oriented dialogue systems (ToD), despite having
interesting results, are designed for a handful of languages like Chinese and
English. Therefore, their performance in low-resource languages is still a
significant problem due to the absence of a standard dataset and evaluation
policy. To address this problem, we proposed ViWOZ, a fully-annotated
Vietnamese task-oriented dialogue dataset. ViWOZ is the first multi-turn,
multi-domain tasked oriented dataset in Vietnamese, a low-resource language.
The dataset consists of a total of 5,000 dialogues, including 60,946 fully
annotated utterances. Furthermore, we provide a comprehensive benchmark of both
modular and end-to-end models in low-resource language scenarios. With those
characteristics, the ViWOZ dataset enables future studies on creating a
multilingual task-oriented dialogue system.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 09:22:04 GMT""}]","2022-03-16"
"2203.07743","Michael Baake","Michael Baake, Franz G\""ahler, Jan Maz\'a\v{c}","Fibonacci direct product variation tilings","15 pages, 7 figures; revised version with minor improvements","J. Math. Phys. 63 (2022) 082702:1-13","10.1063/5.0091099",,"math.DS math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The direct product of two Fibonacci tilings can be described as a genuine
stone inflation rule with four prototiles. This rule admits various
modifications, which lead to 48 different inflation rules, known as the direct
product variations. They all result in tilings that are measure-theoretically
isomorphic by the Halmos--von Neumann theorem. They can be described as cut and
project sets with characteristic windows in a two-dimensional Euclidean
internal space. Here, we analyse and classify them further, in particular with
respect to topological conjugacy.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 09:30:07 GMT""},{""version"":""v2"",""created"":""Mon, 8 Aug 2022 11:59:31 GMT""}]","2022-10-19"
"2203.07744","M. Rashed Khan","Momena Monwar, Gerra Licup, M. Rashed Khan","Confining Eutectic Gallium Indium (eGaIn) in Expired Artificial Kidneys
  to Unveil Nanoporous Conductive Wires",,,,,"physics.med-ph cond-mat.soft","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Nanoporous membranes have gained considerable interest in drug delivery1, ion
transportation2, micro/nanofluidics3, molecular sensing4, and separation
science5. Artificial kidneys, also known as dialyzers, reject pathogens and
other unwanted substances from the blood, utilize hundreds of soft and
nanoporous polymeric microtubes, and slowly become a burden to the environment
with the growing number of dialysis patients worldwide. We demonstrate the
fabrication of nanoporous conductive wires utilizing empty polysulfone
microtubes collected from expired and unused artificial kidneys, also known as
medical wastes. Injecting a fluidic, highly conductive, and room temperature
liquid alloy (eutectic gallium indium-eGaIn$_6$, 75% Ga, 25% In) into
microtubes of a twenty years old dialyzer, here, we have revealed a new class
of nanoporous and conductive functional materials. These conductive fibers
upcycle a medical waste, do not require expensive and conventional fabrication
processes, and still provide the quintessential metal-oxide/metal framework due
to the presence of the native surface oxide (i.e., Gallium Oxide, Ga2O3) of
eGaIn at the nanoconfinement (i.e., nanopores) for nano/biosensing. We
harnessed these new materials to sense and differentiate microliter volumes of
deionized (DI) water, 1M hydrochloric acid (HCl), and 95% ethanol (EtOH),
leveraging their electrical signatures. This new class of soft nanomaterials
has the potential to become the paradigm-shift platforms for the
next-generation of biomedical, bioelectronics, nanoelectronics, and sensor
devices.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 09:30:52 GMT""}]","2022-03-16"
"2203.07745","Hugo Roussille","Hugo Roussille","A new look on black hole perturbations in modified gravity","Contribution to the 2022 Gravitation session of the 56th Rencontres
  de Moriond",,,,"gr-qc hep-th","http://creativecommons.org/publicdomain/zero/1.0/","  We study the linear perturbations about a nonrotating black hole solution of
Horndeski's theory, using a systematic approach that extracts the asymptotic
behaviour of perturbations (at spatial infinity and near the horizon) directly
from the first-order radial differential system governing these perturbations
instead of finding Schr\""odinger-like equations for their dynamics. We
illustrate this method in the case of a specific black hole solution. The
knowledge of the asymptotic behaviours of the perturbations paves the way for a
numerical computation of the quasinormal modes. Finally, the asymptotic form of
the modes also signals some pathologies in the scalar sector of the solution
considered here.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 09:35:04 GMT""},{""version"":""v2"",""created"":""Wed, 16 Mar 2022 17:04:02 GMT""}]","2022-03-17"
"2203.07746","Peter Klimek","Michaela Kaleta, Jana Lasser, Elma Dervic, Liuhuaying Yang, Johannes
  Sorger, Ruggiero Lo Sardo, Stefan Thurner, Alexandra Kautzky-Willer, Peter
  Klimek","Stress-testing the Resilience of the Austrian Healthcare System Using
  Agent-Based Simulation","See also the dashboard under
  https://vis.csh.ac.at/care-network-resilience/",,"10.1038/s41467-022-31766-7",,"physics.soc-ph cs.SI","http://creativecommons.org/licenses/by/4.0/","  Patients do not access physicians at random but rather via naturally emerging
networks of patient flows between them. As retirements, mass quarantines and
absence due to sickness during pandemics, or other shocks thin out these
networks, the system might be pushed closer to a tipping point where it loses
its ability to deliver care to the population. Here we propose a data-driven
framework to quantify the regional resilience to such shocks of primary and
secondary care in Austria via an agent-based model. For each region and medical
specialty we construct detailed patient-sharing networks from administrative
data and stress-test these networks by removing increasing numbers of
physicians from the system. This allows us to measure regional resilience
indicators describing how many physicians can be removed from a certain area
before individual patients won't be treated anymore. We find that such tipping
points do indeed exist and that regions and medical specialties differ
substantially in their resilience. These systemic differences can be related to
indicators for individual physicians by quantifying how much their hypothetical
removal would stress the system (risk score) or how much of the stress from the
removal of other physicians they would be able to absorb (benefit score). Our
stress-testing framework could enable health authorities to rapidly identify
bottlenecks in access to care as well as to inspect these naturally emerging
physician networks and how potential absences would impact them.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 09:36:36 GMT""}]","2022-10-12"
"2203.07747","Tim Salzmann","Tim Salzmann, Elia Kaufmann, Jon Arrizabalaga, Marco Pavone, Davide
  Scaramuzza, Markus Ryll","Real-time Neural-MPC: Deep Learning Model Predictive Control for
  Quadrotors and Agile Robotic Platforms",,"IEEE Robotics and Automation Letters (Volume: 8, Issue: 4, April
  2023)","10.1109/LRA.2023.3246839",,"cs.RO cs.LG cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Model Predictive Control (MPC) has become a popular framework in embedded
control for high-performance autonomous systems. However, to achieve good
control performance using MPC, an accurate dynamics model is key. To maintain
real-time operation, the dynamics models used on embedded systems have been
limited to simple first-principle models, which substantially limits their
representative power. In contrast to such simple models, machine learning
approaches, specifically neural networks, have been shown to accurately model
even complex dynamic effects, but their large computational complexity hindered
combination with fast real-time iteration loops. With this work, we present
Real-time Neural MPC, a framework to efficiently integrate large, complex
neural network architectures as dynamics models within a model-predictive
control pipeline. Our experiments, performed in simulation and the real world
onboard a highly agile quadrotor platform, demonstrate the capabilities of the
described system to run learned models with, previously infeasible, large
modeling capacity using gradient-based online optimization MPC. Compared to
prior implementations of neural networks in online optimization MPC we can
leverage models of over 4000 times larger parametric capacity in a 50Hz
real-time window on an embedded platform. Further, we show the feasibility of
our framework on real-world problems by reducing the positional tracking error
by up to 82% when compared to state-of-the-art MPC approaches without neural
network dynamics.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 09:38:15 GMT""},{""version"":""v2"",""created"":""Sat, 3 Sep 2022 07:30:19 GMT""},{""version"":""v3"",""created"":""Sat, 18 Feb 2023 01:35:16 GMT""},{""version"":""v4"",""created"":""Fri, 14 Apr 2023 11:06:01 GMT""}]","2023-04-17"
"2203.07748","Saurabh K. Shukla","Ketan M. Patel, Saurabh K. Shukla","Anatomy of scalar mediated proton decays in $SO(10)$ models","34 pages, 4 tables, 3 captioned figures. Version published in JHEP","JHEP 08 (2022) 042","10.1007/JHEP08(2022)042",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  Realistic models based on the renormalizable grand unified theories have
varieties of scalars, many of which are capable of mediating baryon ($B$) and
lepton ($L$) number non-conserving processes. We identify all such scalar
fields residing in ${\bf 10}$, $\overline{\bf 126}$ and ${\bf 120}$ dimensional
irreps of $SO(10)$ which can induce baryon and lepton number violating
interactions through the leading order $d=6$ and $d=7$ operators. Explicitly
computing their couplings with the standard model fermions, we derive the
effective operators including the possibility of mixing between the scalars
stemming from a given representation. We find that such interactions at $d=6$
are mediated by only three sets of scalars: $T(3,1,-1/3)$, ${\cal T}
(3,1,-4/3)$ and $\mathbb{T}(3,3,-1/3)$ and their conjugates. In the models with
${\bf 10}$ and $\overline{\bf 126}$, only the first has appropriate couplings
to mediate the proton decay. While ${\cal T}$ and $\mathbb{T}$ can induce
baryon number violating interactions when ${\bf 120}$ is present, ${\cal T}$
does not contribute to the proton decay at tree level because of its flavour
antisymmetric coupling. Three additional colour triplets and their conjugates
can mediate nucleon decay via $d=7$ operators which violate also the $B-L$. We
give general expressions for partial widths of proton in terms of the
fundamental Yukawa couplings and use these results to explicitly compute the
proton lifetime and branching ratios for the minimal non-supersymmetric
$SO(10)$ model based on ${\bf 10}$ and $\overline{\bf 126}$ Higgs. We find that
the proton preferably decays into $\overline{\nu}\, K^+$ or $\mu^+\, K^0$ and
list several distinct features of scalar mediated proton decay. If the latter
dominates over the gauge mediated contributions, the proton decay spectrum
provides a direct probe to the flavour structure of the underlying grand
unified theory.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 09:44:35 GMT""},{""version"":""v2"",""created"":""Thu, 4 Aug 2022 13:21:49 GMT""}]","2022-08-05"
"2203.07749","Xu-Fei Yin","Xu-Fei Yin, Yuxuan Du, Yue-Yang Fei, Rui Zhang, Li-Zheng Liu, Yingqiu
  Mao, Tongliang Liu, Min-Hsiu Hsieh, Li Li, Nai-Le Liu, Dacheng Tao, Yu-Ao
  Chen, and Jian-Wei Pan","Efficient Bipartite Entanglement Detection Scheme with a Quantum
  Adversarial Solver","7 pages, 3 figures","Phys. Rev. Lett. 128, 110501 (2022)","10.1103/PhysRevLett.128.110501",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recognition of entanglement states is a notoriously difficult problem
when no prior information is available. Here, we propose an efficient quantum
adversarial bipartite entanglement detection scheme to address this issue. Our
proposal reformulates the bipartite entanglement detection as a two-player
zero-sum game completed by parameterized quantum circuits, where a two-outcome
measurement can be used to query a classical binary result about whether the
input state is bipartite entangled or not. In principle, for an $N$-qubit
quantum state, the runtime complexity of our proposal is $O(\text{poly}(N)T)$
with $T$ being the number of iterations. We experimentally implement our
protocol on a linear optical network and exhibit its effectiveness to
accomplish the bipartite entanglement detection for 5-qubit quantum pure states
and 2-qubit quantum mixed states. Our work paves the way for using near-term
quantum machines to tackle entanglement detection on multipartite entangled
quantum systems.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 09:46:45 GMT""}]","2022-03-16"
"2203.07750","Christina Zugschwert","C. Zugschwert, S. G\""oschl, F. Martin Ibanez and K. Pettinger","Development of a multi-timescale method for classifying hybrid energy
  storage systems in grid applications",,,"10.1109/eGRID52793.2021.9662136",,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An extended use of renewable energies and a trend towards increasing energy
consumption lead to challenges such as temporal and spatial decoupling of
energy generation and consumption. This work evaluates the possible
applications and advantages of hybrid energy storage systems compared to
conventional, single energy storage applications. In a mathematical approach,
evaluation criteria such as frequency, probability of power transients, as well
as absolute power peaks are combined to identify suitable thresholds for energy
management systems on a multi-timescale basis. With experimental load profiles
from a municipal application, an airport, and an industrial application, four
categories, clustering similar roles of the VRFB and the SC, are developed.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 09:47:48 GMT""}]","2022-03-16"
"2203.07751","Hans Zwart","Mir Mamunuzzaman and Hans Zwart","Structure preserving model order reduction of port-Hamiltonian systems",,,,,"math.OC math.CA","http://creativecommons.org/licenses/by/4.0/","  This work proposes a structure-preserving model reduction method for linear,
time-invariant port-Hamiltonian systems. We show that a low order system of the
same type can be constructed which interpolates the original transfer function
in a given set of frequencies.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 09:51:46 GMT""}]","2022-03-16"
"2203.07752","Vittorio Erba","Emanuele Troiani, Vittorio Erba, Florent Krzakala, Antoine Maillard,
  Lenka Zdeborov\'a","Optimal denoising of rotationally invariant rectangular matrices",,"Proceedings of Mathematical and Scientific Machine Learning
  (MSML), PMLR 190:97-112, 2022",,,"cond-mat.dis-nn cond-mat.stat-mech cs.IT math.IT math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this manuscript we consider denoising of large rectangular matrices: given
a noisy observation of a signal matrix, what is the best way of recovering the
signal matrix itself? For Gaussian noise and rotationally-invariant signal
priors, we completely characterize the optimal denoiser and its performance in
the high-dimensional limit, in which the size of the signal matrix goes to
infinity with fixed aspects ratio, and under the Bayes optimal setting, that is
when the statistician knows how the signal and the observations were generated.
Our results generalise previous works that considered only symmetric matrices
to the more general case of non-symmetric and rectangular ones. We explore
analytically and numerically a particular choice of factorized signal prior
that models cross-covariance matrices and the matrix factorization problem. As
a byproduct of our analysis, we provide an explicit asymptotic evaluation of
the rectangular Harish-Chandra-Itzykson-Zuber integral in a special case.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 09:52:04 GMT""}]","2022-10-03"
"2203.07753","Alexandra Blenkinsop","Alexandra Blenkinsop, M\'elodie Monod, Ard van Sighem, Nikos Pantazis,
  Daniela Bezemer, Eline Op de Coul, Thijs van de Laar, Christophe Fraser,
  Maria Prins, Peter Reiss, Godelieve de Bree, Oliver Ratmann","Estimating the potential to prevent locally acquired HIV infections in a
  UNAIDS Fast-Track City, Amsterdam",,,,,"q-bio.PE stat.AP","http://creativecommons.org/licenses/by-sa/4.0/","  Amsterdam and other UNAIDS Fast-Track cities aim for zero new HIV infections.
Utilising molecular and clinical data of the ATHENA observational HIV cohort,
our primary aims are to estimate the proportion of undiagnosed HIV infections
and the proportion of locally acquired infections in Amsterdam in 2014-2018,
both in MSM and heterosexuals and Dutch-born and foreign-born individuals.
  We located diagnosed HIV infections in Amsterdam using postcode data at time
of registration to the cohort, and estimated their date of infection using
clinical HIV data. We then inferred the proportion undiagnosed from the
estimated times to diagnosis. To determine sources of Amsterdam infections, we
used HIV sequences of people living with HIV (PLHIV) within a background of
other Dutch and international sequences to phylogenetically reconstruct
transmission chains. Frequent late diagnoses indicate that more recent
phylogenetically observed chains are increasingly incomplete, and we use a
Bayesian model to estimate the actual growth of Amsterdam transmission chains,
and the proportion of locally acquired infections.
  We estimate that 20% [95% CrI 18-22%] of infections acquired among MSM
between 2014-2018 were undiagnosed by the start of 2019, and 44% [37-50%] among
heterosexuals, with variation by place of birth. The estimated proportion of
MSM infections in 2014-2018 that were locally acquired was 68% [61-74%], with
no substantial differences by region of birth. In heterosexuals, this was 57%
[41-71%] overall, with heterogeneity by place of birth.
  The data indicate substantial potential to further curb local transmission,
in both MSM and heterosexual Amsterdam residents. In 2014-2018 the largest
proportion of local transmissions in Amsterdam are estimated to have occurred
in foreign-born MSM, who would likely benefit most from intensified
interventions.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 09:59:50 GMT""}]","2022-03-16"
"2203.07754","Mirco Siercke","S. Xu, P. Kaebert, M. Stepanova, T. Poll, M. Siercke and S. Ospelkaus","Engineering the sub-Doppler force in molecular magneto-optical traps","14 pages, 6 figures",,"10.1103/PhysRevResearch.4.L042036",,"physics.atom-ph","http://creativecommons.org/licenses/by/4.0/","  Current dual-frequency magneto-optical traps for ultracold molecules are
plagued by sub-Doppler heating effects, making them vastly inferior to standard
atomic MOTs. Here we demonstrate theoretically that the sub-Doppler effects in
such a MOT can be engineered to provide cooling instead of heating. We give an
intuitive picture how to achieve such cooling and show the cooling and trapping
force results of the 16 level optical Bloch equations for the case of CaF
molecules. From three-dimensional Monte Carlo simulations we estimate the
temperature and density of our MOT to be $40 \mu K$ and $4 \times 10^8 cm^{-3}$
respectively for a molecule number of $10^5$.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:02:12 GMT""}]","2023-04-06"
"2203.07755","Manuel Marschall","Manuel Marschall, Gerd W\""ubbeler, Franko Schm\""ahling, Clemens Elster","Generative models and Bayesian inversion using Laplace approximation",,,,,"stat.ML cs.LG math.ST stat.TH","http://creativecommons.org/licenses/by-sa/4.0/","  The Bayesian approach to solving inverse problems relies on the choice of a
prior. This critical ingredient allows the formulation of expert knowledge or
physical constraints in a probabilistic fashion and plays an important role for
the success of the inference. Recently, Bayesian inverse problems were solved
using generative models as highly informative priors. Generative models are a
popular tool in machine learning to generate data whose properties closely
resemble those of a given database. Typically, the generated distribution of
data is embedded in a low-dimensional manifold. For the inverse problem, a
generative model is trained on a database that reflects the properties of the
sought solution, such as typical structures of the tissue in the human brain in
magnetic resonance (MR) imaging. The inference is carried out in the
low-dimensional manifold determined by the generative model which strongly
reduces the dimensionality of the inverse problem. However, this proceeding
produces a posterior that admits no Lebesgue density in the actual variables
and the accuracy reached can strongly depend on the quality of the generative
model. For linear Gaussian models we explore an alternative Bayesian inference
based on probabilistic generative models which is carried out in the original
high-dimensional space. A Laplace approximation is employed to analytically
derive the required prior probability density function induced by the
generative model. Properties of the resulting inference are investigated.
Specifically, we show that derived Bayes estimates are consistent, in contrast
to the approach employing the low-dimensional manifold of the generative model.
The MNIST data set is used to construct numerical experiments which confirm our
theoretical findings.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:05:43 GMT""},{""version"":""v2"",""created"":""Mon, 7 Nov 2022 11:40:36 GMT""}]","2022-11-08"
"2203.07756","Yuda Song","Yuda Song, Hui Qian, Xin Du","Multi-Curve Translator for High-Resolution Photorealistic Image
  Translation",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The dominant image-to-image translation methods are based on fully
convolutional networks, which extract and translate an image's features and
then reconstruct the image. However, they have unacceptable computational costs
when working with high-resolution images. To this end, we present the
Multi-Curve Translator (MCT), which not only predicts the translated pixels for
the corresponding input pixels but also for their neighboring pixels. And if a
high-resolution image is downsampled to its low-resolution version, the lost
pixels are the remaining pixels' neighboring pixels. So MCT makes it possible
to feed the network only the downsampled image to perform the mapping for the
full-resolution image, which can dramatically lower the computational cost.
Besides, MCT is a plug-in approach that utilizes existing base models and
requires only replacing their output layers. Experiments demonstrate that the
MCT variants can process 4K images in real-time and achieve comparable or even
better performance than the base models on various photorealistic
image-to-image translation tasks.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:06:39 GMT""},{""version"":""v2"",""created"":""Sat, 9 Jul 2022 09:25:11 GMT""}]","2022-07-12"
"2203.07757","Alberto Dinelli","Alberto Dinelli and J\'er\'emy O'Byrne and Agnese Curatolo and
  Yongfeng Zhao and Peter Sollich and Julien Tailleur","Non-reciprocity across scales in active mixtures","6 pages, 3 figures",,,,"cond-mat.stat-mech cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  In active matter, the lack of momentum conservation makes non-reciprocal
interactions the rule rather than the exception. They lead to a rich set of
emerging behaviors that are hard to account for and to predict starting from
the microscopic scale, due to the absence of a generic theoretical framework
out of equilibrium. Here we consider bacterial mixtures that interact via
mediated, non-reciprocal interactions like quorum-sensing and chemotaxis. By
explicity relating microscopic and macroscopic dynamics, we show that
non-reciprocity may fade as coarse-graining proceeds, leading to large-scale
bona fide equilibrium descriptions. In turns, this allows us to account
quantitatively, and without fitting parameters, for the rich behaviors observed
in microscopic simulations including phase separation, demixing or multi-phase
coexistence. We also derive the condition under which non-reciprocity is strong
enough to survive coarse-graining, leading to a wealth of dynamical patterns.
Again, the explicit coarse-graining of the dynamics allows us to predict the
phase diagram of the system starting from its microscopic description. All in
all, our work demonstrates that the fate of non-reciprocity across scales is a
subtle and important question.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:08:21 GMT""},{""version"":""v2"",""created"":""Fri, 23 Dec 2022 00:39:36 GMT""}]","2022-12-26"
"2203.07758","David Fern\'andez-Duque","David Fern\'andez-Duque and Andreas Weiermann","Fundamental sequences and fast-growing hierarchies for the
  Bachmann-Howard ordinal",,,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that Buchholz's system of fundamental sequences for the $\vartheta$
function enjoys various regularity conditions, including the Bachmann property.
We partially extend these results to variants of the $\vartheta$ function,
including a version without addition for countable ordinals. We conclude that
the Hardy functions based on these notation systems enjoy natural monotonicity
properties and majorize all functions defined by primitive recursion along
$\vartheta(\varepsilon_{\Omega+1})$.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:09:08 GMT""},{""version"":""v2"",""created"":""Sun, 3 Jul 2022 14:10:15 GMT""},{""version"":""v3"",""created"":""Wed, 14 Sep 2022 16:15:40 GMT""},{""version"":""v4"",""created"":""Fri, 16 Sep 2022 09:21:52 GMT""}]","2022-09-19"
"2203.07759","Ulas Ozdem","U. Ozdem","Magnetic dipole moments of $B_{(s)}^{(*)}B_{(s)}^{(*)}$ states","12 pages, 2 tables and 2 figures","Chin. Phys. C 46, 113106 (2022)","10.1088/1674-1137/ac8653",,"hep-ph hep-lat","http://creativecommons.org/licenses/by/4.0/","  We systematically study the magnetic dipole moments of multiquark states. In
this study, the magnetic dipole moments of possible $B^- B^{*-}$, $B^0 B^{*-}$,
$B^- B^{*0} $, $B^0 B^{*0}$, $B_s^0 B^{*-}$, $B^- B_s^{*0}$, $B_s^{0} B^{*0}$,
$B^0 B_s^{*0}$ and $B^0_s B_s^{*0}$ states are extracted using light-cone sum
rules. We explore magnetic dipole moments of these states as molecular picture
with spin-parity $J^P = 1^+$. The magnetic dipole moments of hadrons include
useful information on the distributions of internal charge and magnetization,
which can be used to understand their geometrical shapes and quark-gluon
organization. The results of the present study along with the spectroscopic
parameters may help the future theoretical and experimental research on the
characteristics of doubly-bottom tetraquark states.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:11:11 GMT""},{""version"":""v2"",""created"":""Fri, 29 Jul 2022 08:17:14 GMT""},{""version"":""v3"",""created"":""Tue, 6 Sep 2022 09:16:34 GMT""}]","2022-09-07"
"2203.07760","Jose M. Maz\'on","Jos\'e M. Maz\'on","The Cheeger Cut and Cheeger Problem in Metric Graphs",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For discrete weighted graphs there is sufficient literature about the Cheeger
cut and the Cheeger problem, but for metric graphs there are few results about
these problems. Our aim is to study the Cheeger cut and the Cheeger problem in
metric graphs. For that, we use the concept of total variation and perimeter in
metric graphs introduced in \cite{Mazon}, which takes into account the jumps at
the vertices of the functions of bounded variation. Moreover, we study the
eigenvalue problem for the minus $1$-Laplacian operator in metric graphs,
whereby we give a method to solve the optimal Cheeger cut problem.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:12:59 GMT""}]","2022-03-16"
"2203.07761","Hadi Beik-Mohammadi","Hadi Beik-Mohammadi, S{\o}ren Hauberg, Georgios Arvanitidis, Gerhard
  Neumann, Leonel Rozo","Reactive Motion Generation on Learned Riemannian Manifolds",,,,,"cs.RO cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent decades, advancements in motion learning have enabled robots to
acquire new skills and adapt to unseen conditions in both structured and
unstructured environments. In practice, motion learning methods capture
relevant patterns and adjust them to new conditions such as dynamic obstacle
avoidance or variable targets. In this paper, we investigate the robot motion
learning paradigm from a Riemannian manifold perspective. We argue that
Riemannian manifolds may be learned via human demonstrations in which geodesics
are natural motion skills. The geodesics are generated using a learned
Riemannian metric produced by our novel variational autoencoder (VAE), which is
especially intended to recover full-pose end-effector states and joint space
configurations. In addition, we propose a technique for facilitating on-the-fly
end-effector/multiple-limb obstacle avoidance by reshaping the learned manifold
using an obstacle-aware ambient metric. The motion generated using these
geodesics may naturally result in multiple-solution tasks that have not been
explicitly demonstrated previously. We extensively tested our approach in task
space and joint space scenarios using a 7-DoF robotic manipulator. We
demonstrate that our method is capable of learning and generating motion skills
based on complicated motion patterns demonstrated by a human operator.
Additionally, we assess several obstacle avoidance strategies and generate
trajectories in multiple-mode settings.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:28:16 GMT""}]","2022-03-16"
"2203.07762","Yu Li","Yu Li, Wenjia Zhang","Rigidity of complex projective spaces in Ricci shrinkers","33 pages",,,,"math.DG","http://creativecommons.org/publicdomain/zero/1.0/","  In this paper, we prove that any Ricci shrinker that is sufficiently close to
$(\mathbb C P^N,g_{FS})$ in the Gromov-Hausdorff sense must itself be isometric
to $(\mathbb C P^N,g_{FS})$.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:36:06 GMT""},{""version"":""v2"",""created"":""Wed, 10 May 2023 14:52:01 GMT""}]","2023-05-11"
"2203.07763","Paolo Leonetti","Simone Cerreia-Vioglio and Paolo Leonetti and Fabio Maccheroni","A Characterization of the Vector Lattice of Measurable Functions","13 pp",,,,"math.FA math.CA math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a probability measure space $(X,\Sigma,\mu)$, it is well known that the
Riesz space $L^0(\mu)$ of equivalence classes of measurable functions $f: X \to
\mathbf{R}$ is universally complete and the constant function $\mathbf{1}$ is a
weak order unit. Moreover, the linear functional $L^\infty(\mu)\to \mathbf{R}$
defined by $f \mapsto \int f\,\mathrm{d}\mu$ is strictly positive and order
continuous. Here we show, in particular, that the converse holds true, i.e.,
any universally complete Riesz space $E$ with a weak order unit $e>0$ which
admits a strictly positive order continuous linear functional on the principal
ideal generated by $e$ is lattice isomorphic onto $L^0(\mu)$, for some
probability measure space $(X,\Sigma,\mu)$.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:36:51 GMT""}]","2022-03-16"
"2203.07764","Jieli Qin","Jieli Qin, Lu Zhou, Guangjiong Dong","Imaginary spin-orbital coupling in parity-time symmetric systems with
  momentum-dependent gain and loss","13 pages, 3 figures",,"10.1088/1367-2630/ac7606",,"cond-mat.quant-gas quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spin-orbital coupling (SOC) and parity-time ($\mathcal{PT}$) symmetry both
have attracted paramount research interest in condensed matter physics, cold
atom physics, optics and acoustics to develop spintronics, quantum computation,
precise sensors and novel functionalities. Natural SOC is an intrinsic
relativistic effect. However, there is an increasing interest in synthesized
SOC nowadays. Here, we show that in a $\mathcal{PT}$-symmetric spin-1/2 system,
the momentum-dependent balanced gain and loss can synthesize a new type of SOC,
which we call imaginary SOC. The imaginary SOC can substantially change the
energy spectrum of the system. Firstly, we show that it can generate a pure
real energy spectrum with a double-valleys structure. Therefore, it has the
ability to generate supersolid stripe states. Especially, the imaginary SOC
stripe state can have a high contrast of one. Moreover, the imaginary SOC can
also generate a spectrum with tunable complex energy band, in which the waves
are either amplifying or decaying. Thus, the imaginary SOC would also find
applications in the engineering of $\mathcal{PT}$-symmetry-based coherent wave
amplifiers/absorbers. Potential experimental realizations of imaginary SOC are
proposed in cold atomic gases and systems of coupled waveguides constituted of
nonlocal gain and loss.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:37:03 GMT""}]","2022-06-29"
"2203.07765","Emilio Benenati","Emilio Benenati, Wicak Ananduta, Sergio Grammatico","Optimal selection and tracking of generalized Nash equilibria in
  monotone games",,,,,"eess.SY cs.SY math.OC","http://creativecommons.org/licenses/by/4.0/","  A fundamental open problem in monotone game theory is the computation of a
specific generalized Nash equilibrium (GNE) among all the available ones, e.g.
the optimal equilibrium with respect to a system-level objective. The existing
GNE seeking algorithms have in fact convergence guarantees toward an arbitrary,
possibly inefficient, equilibrium. In this paper, we solve this open problem by
leveraging results from fixed-point selection theory and in turn derive
distributed algorithms for the computation of an optimal GNE in monotone games.
We then extend the technical results to the time-varying setting and propose an
algorithm that tracks the sequence of optimal equilibria up to an asymptotic
error, whose bound depends on the local computational capabilities of the
agents.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:38:19 GMT""}]","2022-03-16"
"2203.07766","Hamdi Zorgati","Hamdi Zorgati","Asymptotic analysis for a second order curved thin film",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a second order thin curved film whose behavior is governed by an
energy made up of a first order nonlinear part depending on the gradient of the
deformation augmented by a quadratic second order part depending on the tensor
of second derivatives of the deformation. We carry out a 3D-2D analysis through
an asymptotic expansion in powers of the thickness of the film as it tends to
zero.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:38:24 GMT""}]","2022-03-16"
"2203.07767","Nathalie Wahl","Nathalie Wahl","Homological stability: a tool for computations","Contribution to the Proceedings of the 2022 ICM",,,"CPH-GeoTop-DNRF151","math.AT math.GT","http://creativecommons.org/licenses/by/4.0/","  Homological stability has shown itself to be a powerful tool for the
computation of homology of families of groups such as general linear groups,
mapping class groups or automorphisms of free groups. We survey here tools and
techniques for proving homological stability theorems and for computing the
stable homology, and illustrate the method through the computation of the
homology of Higman-Thompson groups.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:38:28 GMT""}]","2022-03-16"
"2203.07768","Peter Frankl","Peter Frankl","Graphs without rainbow triangles",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let F,G,H be three graphs on the same n vertices. We consider the maximum of
the sum and product of the number of their edges subject to the condition in
the title.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:41:30 GMT""}]","2022-03-16"
"2203.07769","Olga Mula","Olga Mula","Inverse Problems: A Deterministic Approach using Physics-Based Reduced
  Models",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  These lecture notes summarize various summer schools that I have given on the
topic of solving inverse problems (state and parameter estimation) by combining
optimally measurement observations and parametrized PDE models. After defining
a notion of optimal performance in terms of the smallest reconstruction error
that any reconstruction algorithm can achieve, the notes present practical
numerical algorithms based on nonlinear reduced models for which one can prove
that they can deliver a performance close to optimal. We also discuss
algorithms for sensor placement with the approach. The proposed concepts may be
viewed as exploring alternatives to Bayesian inversion in favor of more
deterministic notions of accuracy quantification.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:42:06 GMT""}]","2022-03-16"
"2203.07770","Heesung Shin","Seunghyun Seo and Heesung Shin","On Delannoy paths without peaks and valleys","13 pages, 2 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A lattice path is called \emph{Delannoy} if its every step belongs to
$\left\{N, E, D\right\}$, where $N=(0,1)$, $E=(1,0)$, and $D=(1,1)$ steps.
\emph{Peak}, \emph{valley}, and \emph{deep valley} mean $NE$, $EN$, and $EENN$
on the lattice path, respectively.
  In this paper, we find a bijection between $\mathcal{P}_{n,m}(NE, EN)$ and a
specific subset of ${\mathcal{P}_{n,m}}(D, EENN)$, where $\mathcal{P}_{n,m}(NE,
EN)$ is the set of Delannoy paths from the origin to the points $(n,m)$ without
peaks and valleys and ${\mathcal{P}_{n,m}}(D, EENN)$ is the set of Delannoy
lattice paths from the origin to the points $(n,m)$ without diagonal steps and
deep valleys. We also enumerate the number of Delannoy paths without peaks and
valleys on the restricted region $\left\{ (x,y) \in \mathbb{Z}^2 : y \ge k x
\right\}$ for a positive integer $k$.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:44:36 GMT""},{""version"":""v2"",""created"":""Wed, 29 Jun 2022 05:07:32 GMT""}]","2022-06-30"
"2203.07771","Xinyuan Zhang","Xiaoyu Chen, Weiming Feng, Yitong Yin, Xinyuan Zhang","Optimal mixing for two-state anti-ferromagnetic spin systems",,,,,"math-ph cs.DS math.MP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove an optimal $\Omega(n^{-1})$ lower bound for modified log-Sobolev
(MLS) constant of the Glauber dynamics for anti-ferromagnetic two-spin systems
with $n$ vertices in the tree uniqueness regime. Specifically, this optimal MLS
bound holds for the following classes of two-spin systems in the tree
uniqueness regime:
  $\bullet$ all strictly anti-ferromagnetic two-spin systems (where both edge
parameters $\beta,\gamma<1$), which cover the hardcore models and the
anti-ferromagnetic Ising models;
  $\bullet$ general anti-ferromagnetic two-spin systems on regular graphs.
  Consequently, an optimal $O(n\log n)$ mixing time holds for these
anti-ferromagnetic two-spin systems when the uniqueness condition is satisfied.
These MLS and mixing time bounds hold for any bounded or unbounded maximum
degree, and the constant factors in the bounds depend only on the gap to the
uniqueness threshold. We prove this by showing a boosting theorem for MLS
constant for distributions satisfying certain spectral independence and
marginal stability properties.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:46:11 GMT""}]","2022-03-16"
"2203.07772","St\'ephane Cuenat","St\'ephane Cuenat, Louis Andr\'eoli, Antoine N. Andr\'e, Patrick
  Sandoz, Guillaume J. Laurent, Rapha\""el Couturier and Maxime Jacquot","Fast Autofocusing using Tiny Transformer Networks for Digital
  Holographic Microscopy",,,"10.1364/OE.458948",,"eess.IV cs.CV physics.optics","http://creativecommons.org/licenses/by/4.0/","  The numerical wavefront backpropagation principle of digital holography
confers unique extended focus capabilities, without mechanical displacements
along z-axis. However, the determination of the correct focusing distance is a
non-trivial and time consuming issue. A deep learning (DL) solution is proposed
to cast the autofocusing as a regression problem and tested over both
experimental and simulated holograms. Single wavelength digital holograms were
recorded by a Digital Holographic Microscope (DHM) with a 10$\mathrm{x}$
microscope objective from a patterned target moving in 3D over an axial range
of 92 $\mu$m. Tiny DL models are proposed and compared such as a tiny Vision
Transformer (TViT), tiny VGG16 (TVGG) and a tiny Swin-Transfomer (TSwinT). The
proposed tiny networks are compared with their original versions (ViT/B16,
VGG16 and Swin-Transformer Tiny) and the main neural networks used in digital
holography such as LeNet and AlexNet. The experiments show that the predicted
focusing distance $Z_R^{\mathrm{Pred}}$ is accurately inferred with an accuracy
of 1.2 $\mu$m in average in comparison with the DHM depth of field of 15
$\mu$m. Numerical simulations show that all tiny models give the
$Z_R^{\mathrm{Pred}}$ with an error below 0.3 $\mu$m. Such a prospect would
significantly improve the current capabilities of computer vision position
sensing in applications such as 3D microscopy for life sciences or
micro-robotics. Moreover, all models reach an inference time on CPU, inferior
to 25 ms per inference. In terms of occlusions, TViT based on its Transformer
architecture is the most robust.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:52:58 GMT""},{""version"":""v2"",""created"":""Sat, 19 Mar 2022 15:12:18 GMT""},{""version"":""v3"",""created"":""Wed, 30 Mar 2022 06:19:08 GMT""},{""version"":""v4"",""created"":""Fri, 20 May 2022 10:56:45 GMT""}]","2022-07-13"
"2203.07773","Johan Sundin","Johan Sundin and Shervin Bagheri","Slip of submerged two-dimensional liquid-infused surfaces in the
  presence of surfactants","34 pages, 13 figures",,"10.1017/jfm.2022.835",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using numerical simulations, we investigate the effects of Marangoni stresses
induced by surfactants on the effective slip length of liquid-infused surfaces
(LIS) with transverse grooves. The surfactants are assumed soluble in the
external liquid shearing the surface and can adsorb onto the interfaces. Two
different adsorption models are used: a classical Frumkin model and a more
advanced model that better describes the decrease of surface tension for
minuscule concentrations. The simulations show that LIS may face even more
severe effects of surfactants than previously investigated superhydrophobic
surfaces. Constructing an analytical model for the effective slip length, we
can predict the critical surfactant concentration for which the slip length
decreases significantly. This analytical model describes both adsorption models
of LIS on a unified framework if properly adjusted. We also advance the
understanding of when surfactant advection gives rise to highly skewed
interfacial concentrations - the so-called partial stagnant cap regime. To a
good approximation, this regime can only exist below a specific surfactant
concentration given by the Marangoni number and the strength of the
surfactants.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:53:55 GMT""},{""version"":""v2"",""created"":""Sat, 1 Oct 2022 12:27:12 GMT""}]","2022-11-09"
"2203.07774","Lioba Heimbach","Jan Arvid Berg, Robin Fritsch, Lioba Heimbach, Roger Wattenhofer","An Empirical Study of Market Inefficiencies in Uniswap and SushiSwap",,,,,"cs.CE q-fin.TR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Decentralized exchanges are revolutionizing finance. With their ever-growing
increase in popularity, a natural question that begs to be asked is: how
efficient are these new markets?
  We find that nearly 30% of analyzed trades are executed at an unfavorable
rate. Additionally, we observe that, especially during the DeFi summer in 2020,
price inaccuracies across the market plagued DEXes. Uniswap and SushiSwap,
however, quickly adapt to their increased volumes. We see an increase in market
efficiency with time during the observation period. Nonetheless, the DEXes
still struggle to track the reference market when cryptocurrency prices are
highly volatile. During such periods of high volatility, we observe the market
becoming less efficient - manifested by an increased prevalence in cyclic
arbitrage opportunities.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:55:12 GMT""},{""version"":""v2"",""created"":""Fri, 20 May 2022 10:44:33 GMT""}]","2022-05-23"
"2203.07775","Rahul Kumar","Sushant G. Ghosh and Rahul Kumar Walia","Shadows of Kerr-like black holes in $4D$ Einstein-Gauss-Bonnet gravity
  and constraints from EHT observations","15 pages and 6 figures. Matched with the published version in
  proceedings of the Sixteenth Marcel Grossmann Meeting - MG16, July 5-10, 2021","Proceedings of the MG16 Meeting on General Relativity, Remo
  Ruffini, Gregory Vereshchagin (eds.) (World Scientific, 2023)","10.1142/9789811269776_0084","MG16 Proceedings","gr-qc","http://creativecommons.org/licenses/by/4.0/","  The M87* black hole shadow observation by the Event Horizon Telescope (EHT)
has enabled us to test the modified gravity theories in the extreme-field
regime and estimating the black hole parameters. Having this assertion, we
investigate the Kerr-like rotating black holes in $4D$ Einstein-Gauss-Bonnet
(EGB) gravity and deduce their shadows. Considering the inclination angle
$\theta_0=17^o$, we show that the EGB black hole shadows are smaller and more
distorted than for the Kerr black holes. Modelling the M87* black hole as the
EGB black hole, we predict the shadow angular size $35.7888\mu as\leq
\theta_d\leq 39.6192\mu as$. The M87* black hole shadow angular size
$\theta_d=42\pm 3\mu as$, within the 1$\sigma$ region, constrains the GB
coupling parameter and the black hole spin parameter. Interestingly, the
circularity deviation of the EGB black hole shadows is smaller than the bounded
deduced for the M87* black hole.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:55:36 GMT""},{""version"":""v2"",""created"":""Fri, 3 Feb 2023 18:00:44 GMT""}]","2023-02-06"
"2203.07776","Claudia Nagel","Claudia Nagel, Cristian Barrios Espinosa, Karli Gillette, Matthias
  A.F. Gsell, Jorge S\'anchez, Gernot Plank, Olaf D\""ossel, Axel Loewe","Comparison of propagation models and forward calculation methods on
  cellular, tissue and organ scale atrial electrophysiology","This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible",,,,"physics.med-ph eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Objective: The bidomain model and the finite element method are an
established standard to mathematically describe cardiac electrophysiology, but
are both suboptimal choices for fast and large-scale simulations due to high
computational costs. We investigate to what extent simplified approaches for
propagation models (monodomain, reaction-eikonal and eikonal) and forward
calculation (boundary element and infinite volume conductor) deliver markedly
accelerated, yet physiologically accurate simulation results in atrial
electrophysiology. Methods: We compared action potential durations, local
activation times (LATs), and electrocardiograms (ECGs) for sinus rhythm
simulations on healthy and fibrotically infiltrated atrial models. Results: All
simplified model solutions yielded LATs and P waves in accurate accordance with
the bidomain results. Only for the eikonal model with pre-computed action
potential templates shifted in time to derive transmembrane voltages,
repolarization behavior notably deviated from the bidomain results. ECGs
calculated with the boundary element method were characterized by correlation
coefficients >0.9 compared to the finite element method. The infinite volume
conductor method led to lower correlation coefficients caused predominantly by
systematic overestimations of P wave amplitudes in the precordial leads.
Conclusion: Our results demonstrate that the eikonal model yields accurate LATs
and combined with the boundary element method precise ECGs compared to markedly
more expensive full bidomain simulations. However, for an accurate
representation of atrial repolarization dynamics, diffusion terms must be
accounted for in simplified models. Significance: Simulations of atrial LATs
and ECGs can be notably accelerated to clinically feasible time frames at high
accuracy by resorting to the eikonal and boundary element methods.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:55:41 GMT""}]","2022-03-16"
"2203.07777","Davide Grossi","Davide Grossi","Social Choice Around the Block: On the Computational Social Choice of
  Blockchain","Paper appears in the proceedings of AAMAS'22, Blue Sky Ideas track",,,,"cs.GT cs.AI","http://creativecommons.org/licenses/by/4.0/","  One of the most innovative aspects of blockchain technology consists in the
introduction of an incentive layer to regulate the behavior of distributed
protocols. The designer of a blockchain system faces therefore issues that are
akin to those relevant for the design of economic mechanisms, and faces them in
a computational setting. From this perspective the present paper argues for the
importance of computational social choice in blockchain research. It identifies
a few challenges at the interface of the two fields that illustrate the strong
potential for cross-fertilization between them.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:56:10 GMT""}]","2022-03-16"
"2203.07778","Hee Sok Chung","Nora Brambilla, Hee Sok Chung, Antonio Vairo, Xiang-Peng Wang","Production and polarization of $S$-wave quarkonia in potential
  nonrelativistic QCD","6 pages, 2 figures, 2 tables, minor corrections, version published as
  a Letter in Phys. Rev. D","Phys. Rev. D 105, L111503 (2022)","10.1103/PhysRevD.105.L111503","TUM-EFT 168/22","hep-ph hep-ex hep-lat nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Based on the potential nonrelativistic QCD formalism, we compute the
nonrelativistic QCD long-distance matrix elements (LDMEs) for inclusive
production of $S$-wave heavy quarkonia. This greatly reduces the number of
nonperturbative unknowns and brings in a substantial enhancement in the
predictive power of the nonrelativistic QCD factorization formalism. We obtain
improved determinations of the LDMEs and find cross sections and polarizations
of $J/\psi$, $\psi(2S)$, and excited $\Upsilon$ states that agree well with LHC
data. Our results may have important implications in pinning down the heavy
quarkonium production mechanism.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:58:01 GMT""},{""version"":""v2"",""created"":""Mon, 27 Jun 2022 05:04:14 GMT""}]","2022-06-28"
"2203.07779","Erin Koos","Jens Allard and Sanne Burgers and Miriam Candelaria Rodr\'iguez
  Gonz\'alez and Yanshen Zhu and Steven De Feyter and Erin Koos","Effects of particle roughness on the rheology and structure of capillary
  suspensions",,"Colloids and Surfaces A 648, 129224 (2022)","10.1016/j.colsurfa.2022.129224",,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that particle roughness leads to changes in the number, shape and
resulting capillary force of liquid bridges in capillary suspensions. We
created fluorescently labeled, raspberry-like particles with varying roughness
by electrostatically adsorbing silica nanoparticles with sizes between 40 nm
and 250 nm on silica microparticles. Rougher particles require more liquid to
fill the surface asperities before they form pendular bridges, resulting in
smaller and weaker bridges. In a system where the effective bridge volume is
adjusted, higher particle roughness leads to less clustered networks, which
show a higher yield strain for a matching storage modulus compared to the
smooth particle networks. This finding suggests that the particle-particle
frictional contacts also affects the strength of capillary suspensions. Using
asymptotically nonlinear oscillatory rheology, we corroborate the non-cubical
power law scaling of the third harmonic in the shear stress response that
results from both Hertzian contacts and friction between particles connected by
capillary bridges. We demonstrate that the repulsive Hertzian contact parameter
$A$ is sensitive to the liquid bridge strength and that roughness appears to
shift the relative scaling of the power law exponents from adhesive-controlled
friction to load-controlled friction.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:00:58 GMT""},{""version"":""v2"",""created"":""Wed, 11 May 2022 07:53:09 GMT""}]","2022-05-23"
"2203.07780","Noa Zilberman","Noa Zilberman, Marc Casals, Amos Ori and Adrian C. Ottewill","Two-point function of a quantum scalar field in the interior region of a
  Kerr black hole",,,"10.1103/PhysRevD.106.125011",,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  Quantum field effects on a classical background spacetime may be obtained
from the semiclassical equations of General Relativity with the expectation
value of the stress-energy tensor of the quantum field as a source. This
expectation value can be calculated from Hadamard's elementary two-point
function, which in practice is given in terms of sums of products of field
modes evaluated at two spacetime points. We derive expressions for the
two-point function for a massless scalar field in the Unruh state on a Kerr
black hole spacetime. Our main result in this paper is a novel expression valid
when the two points lie inside the black hole; we also (re-)derive, using a new
method, the known expression valid when the two points lie outside the black
hole. We achieve these expressions by finding relationships between Unruh
modes, defined in terms of the retarded Kruskal coordinate, and Eddington
modes, defined in terms of the Eddington coordinates. While our starting
expression for the two-point function is written in terms of the Unruh modes,
we give our final expression in terms of the Eddington modes, which have the
computational advantage that they decompose into factors that obey ordinary
differential equations. In an appendix we also derive expressions for the bare
mode contributions to the flux components of the stress-energy tensor for a
minimally-coupled massless scalar field inside the black hole. Our results thus
lay the groundwork for future calculations of quantum effects inside a Kerr
black hole.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:01:49 GMT""}]","2023-01-04"
"2203.07781","Longxu Dou","Longxu Dou, Yan Gao, Mingyang Pan, Dingzirui Wang, Wanxiang Che,
  Dechen Zhan, Jian-Guang Lou","UniSAr: A Unified Structure-Aware Autoregressive Language Model for
  Text-to-SQL","Codes and checkpoints are available at
  https://github.com/microsoft/ContextualSP/tree/master/unified_parser_text_to_sql",,,,"cs.CL cs.AI cs.DB","http://creativecommons.org/licenses/by/4.0/","  Existing text-to-SQL semantic parsers are typically designed for particular
settings such as handling queries that span multiple tables, domains or turns
which makes them ineffective when applied to different settings. We present
UniSAr (Unified Structure-Aware Autoregressive Language Model), which benefits
from directly using an off-the-shelf language model architecture and
demonstrates consistently high performance under different settings.
Specifically, UniSAr extends existing autoregressive language models to
incorporate three non-invasive extensions to make them structure-aware: (1)
adding structure mark to encode database schema, conversation context, and
their relationships; (2) constrained decoding to decode well structured SQL for
a given database schema; and (3) SQL completion to complete potential missing
JOIN relationships in SQL based on database schema. On seven well-known
text-to-SQL datasets covering multi-domain, multi-table and multi-turn, UniSAr
demonstrates highly comparable or better performance to the most advanced
specifically-designed text-to-SQL models. Importantly, our UniSAr is
non-invasive, such that other core model advances in text-to-SQL can also adopt
our extensions to further enhance performance.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:02:55 GMT""},{""version"":""v2"",""created"":""Wed, 13 Apr 2022 08:48:09 GMT""}]","2022-04-14"
"2203.07782","Zixuan Li","Zixuan Li, Saiping Guan, Xiaolong Jin, Weihua Peng, Yajuan Lyu, Yong
  Zhu, Long Bai, Wei Li, Jiafeng Guo and Xueqi Cheng","Complex Evolutional Pattern Learning for Temporal Knowledge Graph
  Reasoning","ACL 2022 main conference",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A Temporal Knowledge Graph (TKG) is a sequence of KGs corresponding to
different timestamps. TKG reasoning aims to predict potential facts in the
future given the historical KG sequences. One key of this task is to mine and
understand evolutional patterns of facts from these sequences. The evolutional
patterns are complex in two aspects, length-diversity and time-variability.
Existing models for TKG reasoning focus on modeling fact sequences of a fixed
length, which cannot discover complex evolutional patterns that vary in length.
Furthermore, these models are all trained offline, which cannot well adapt to
the changes of evolutional patterns from then on. Thus, we propose a new model,
called Complex Evolutional Network (CEN), which uses a length-aware
Convolutional Neural Network (CNN) to handle evolutional patterns of different
lengths via an easy-to-difficult curriculum learning strategy. Besides, we
propose to learn the model under the online setting so that it can adapt to the
changes of evolutional patterns over time. Extensive experiments demonstrate
that CEN obtains substantial performance improvement under both the traditional
offline and the proposed online settings.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:02:55 GMT""},{""version"":""v2"",""created"":""Sun, 20 Mar 2022 11:39:19 GMT""}]","2022-03-22"
"2203.07783","Julio Lopez","Julio A. L\'opez-Sald\'ivar, Vladimir I. Man'ko, Margarita A. Man'ko","Symplectic tomographic probability distribution of crystallized
  Schr\""odinger cat states",,"Physics Letters A, Volume 434, 128044, 2022","10.1016/j.physleta.2022.128044",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Within the framework of the probability representation of quantum mechanics,
we study a superposition of generic Gaussian states associated to symmetries of
a regular polygon of n sides; in other words, the cyclic groups (containing the
rotational symmetries) and dihedral groups (containing the rotational and
inversion symmetries). We obtain the Wigner functions and tomographic
probability distributions (symplectic and optical tomograms) determining the
density matrices of the states explicitly as the sums of Gaussian terms. The
obtained Wigner functions demonstrate nonclassical behavior, i.e., contain
negative values, while the tomograms show a series of maxima and minima
different for each state, where the number of the critical points reflects the
order of the group defining the states. We discuss general properties of such a
generalization of normal probability distributions.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:03:47 GMT""}]","2022-03-16"
"2203.07784","Xue-Jia Yu","Zheng-Xin Guo, Xue-Jia Yu, Xi-Dan Hu, and Zhi Li","Emergent phase transition in Cluster Ising model with dissipation","published version","Phys. Rev. A 105, 053311 (2022)","10.1103/PhysRevA.105.053311",,"cond-mat.stat-mech cond-mat.quant-gas","http://creativecommons.org/licenses/by/4.0/","  We study a cluster Ising model with non-Hermitian external field which can be
exactly solved in the language of free fermions. By investigating the second
derivative of energy density and fidelity, the possible new critical points are
tentatively located. String order parameter and staggered magnetization are
then detected to reveal emergent phases of brand new characteristics. To
categorize the exotic phases and phase transitions induced by non-Hermiticity,
we calculate the variation mode of spin correlation function as well as string
parameter, which characterize the emergent phases and critical points with
different patterns of decay and critical exponents. With the help of string
order parameter and staggered magnetization, we find that there are four phases
after introducing the non-Hermiticity -- the cluster phase, the gapless phase,
the paramagnetic (PM) phase and the antiferromagnetic (AF) phase. A phase
diagram is then presented to graphically illustrate, based on two ""KT-like""
phase transitions and an Ising phase transition, respectively, the generation
of three critical lines as non-Hermitian strength increases. Our theoretical
work is expected to be realized in the experiment of ultra-cold atoms, pushing
for progress in exploring novel phases and phase transitions.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:05:17 GMT""},{""version"":""v2"",""created"":""Sat, 26 Mar 2022 09:45:55 GMT""},{""version"":""v3"",""created"":""Mon, 25 Apr 2022 08:36:44 GMT""},{""version"":""v4"",""created"":""Sat, 28 May 2022 10:31:55 GMT""}]","2022-05-31"
"2203.07785","Rebecca Lynn Johnson Ms","Rebecca L Johnson, Giada Pistilli, Natalia Men\'edez-Gonz\'alez,
  Leslye Denisse Dias Duran, Enrico Panai, Julija Kalpokiene, Donald Jay
  Bertulfo","The Ghost in the Machine has an American accent: value conflict in GPT-3","There are a total of 15 pages of the PDF including 8 pages of the
  main manuscript, 3 pages of references, and 4 pages of appendices. The paper
  is currently under review by a conference",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  The alignment problem in the context of large language models must consider
the plurality of human values in our world. Whilst there are many resonant and
overlapping values amongst the world's cultures, there are also many
conflicting, yet equally valid, values. It is important to observe which
cultural values a model exhibits, particularly when there is a value conflict
between input prompts and generated outputs. We discuss how the co-creation of
language and cultural value impacts large language models (LLMs). We explore
the constitution of the training data for GPT-3 and compare that to the world's
language and internet access demographics, as well as to reported statistical
profiles of dominant values in some Nation-states. We stress tested GPT-3 with
a range of value-rich texts representing several languages and nations;
including some with values orthogonal to dominant US public opinion as reported
by the World Values Survey. We observed when values embedded in the input text
were mutated in the generated outputs and noted when these conflicting values
were more aligned with reported dominant US values. Our discussion of these
results uses a moral value pluralism (MVP) lens to better understand these
value mutations. Finally, we provide recommendations for how our work may
contribute to other current work in the field.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:06:54 GMT""}]","2022-03-16"
"2203.07786","Sumit Ghosh","Bhaskar Dutta, Sumit Ghosh and Jason Kumar","$U(1)_{T3R}$ Extension of Standard Model: A Sub-GeV Dark Matter Model","Contribution to SNOWMASS 2021",,,,"hep-ph astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  We present a model based on a $U(1)_{T3R}$ extension of the Standard Model.
The model addresses the mass hierarchy between the third generation and the
first two generation fermions. $U(1)_{T3R}$ is spontaneously broken at $\sim
1-10$ GeV. The model contains a sub-GeV dark matter candidate and two sub-GeV
light scalar and vector mediators. The model explains the thermal dark matter
abundance, measurements of the muon g-2 and $R_{K^{(\ast)}}$ anomalies. The
model can be probed at the LHC, FASER, dark matter experiments and various
beam-dump based neutrino facilities, e.g., COHERENT, CCM, MicroBooNE, SBND,
ICARUS, DUNE etc.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:06:57 GMT""}]","2022-03-16"
"2203.07787","Nuno Freitas","Lassina Demb\'el\'e, Nuno Freitas and John Voight","On Galois inertial types of elliptic curves over $\mathbb{Q}_\ell$","improved exposition;",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide a complete, explicit description of the inertial Weil--Deligne
types arising from elliptic curves over $\mathbb{Q}_\ell$ for $\ell$ prime.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:07:14 GMT""},{""version"":""v2"",""created"":""Mon, 17 Oct 2022 07:24:24 GMT""}]","2022-10-18"
"2203.07788","Yikai Wang","Yikai Wang, Xinwei Sun, and Yanwei Fu","Scalable Penalized Regression for Noise Detection in Learning with Noisy
  Labels","To appear in CVPR2022. Code and pretrained models will be released
  after going through necessary procedures",,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Noisy training set usually leads to the degradation of generalization and
robustness of neural networks. In this paper, we propose using a theoretically
guaranteed noisy label detection framework to detect and remove noisy data for
Learning with Noisy Labels (LNL). Specifically, we design a penalized
regression to model the linear relation between network features and one-hot
labels, where the noisy data are identified by the non-zero mean shift
parameters solved in the regression model. To make the framework scalable to
datasets that contain a large number of categories and training data, we
propose a split algorithm to divide the whole training set into small pieces
that can be solved by the penalized regression in parallel, leading to the
Scalable Penalized Regression (SPR) framework. We provide the non-asymptotic
probabilistic condition for SPR to correctly identify the noisy data. While SPR
can be regarded as a sample selection module for standard supervised training
pipeline, we further combine it with semi-supervised algorithm to further
exploit the support of noisy data as unlabeled data. Experimental results on
several benchmark datasets and real-world noisy datasets show the effectiveness
of our framework. Our code and pretrained models are released at
https://github.com/Yikai-Wang/SPR-LNL.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:09:58 GMT""},{""version"":""v2"",""created"":""Sat, 19 Mar 2022 03:00:44 GMT""}]","2022-03-22"
"2203.07789","Daphne Tuncer","Daphne Tuncer, Oytun Babacan, Raoul Guiazon, Halima Abu Ali, Josephine
  Conway, Sebastian Kern, Ana Teresa Moreno, Max Peel, Arthur Pereira, Nadia
  Assad, Giulia Franceschini, Margrethe Gjerull, Anna Hardisty, Imran Marwa,
  Blanca Alvarez Lopez, Ariella Shalev, Christopher D' Cruz Tambua, Hapsari
  Damayanti, Paul Frapart, Sacha Lepoutre, Peer Novak","Engineering data-driven solutions for future mobility: perspectives and
  challenges",,,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The automotive industry is currently undergoing major changes. These include
a general shift towards decarbonised mode of transportation, the implementation
of mobility as an end-to-end service, and the transition to vehicles that
increasingly rely on software and digital tools to function. Digitalisation is
expected to play a key role in shaping the future of mobility ecosystems by
fostering the integration of traditionally independent system domains in the
energy, transportation and information sectors. This report discusses
opportunities and challenges for engineering data-driven solutions that support
the requirements of future digitalised mobility systems based on three use
cases for electric vehicle public charging infrastructures, services and
security.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:10:02 GMT""}]","2022-03-16"
"2203.07790","Nicholas Crisp","Sabrina Livadiotti, Nicholas H. Crisp, Peter C.E. Roberts, Vitor T.A.
  Oiko, Simon Christensen, Rosa Maria Dominguez, Georg H. Herdrich","Uncertainties and Design of Active Aerodynamic Attitude Control in Very
  Low Earth Orbit","33 pages, 14 figures, 3 tables, accepted for publication in AIAA
  Journal of Guidance, Control, and Dynamics (2022-01-04)",,"10.2514/1.G005999",,"physics.space-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper discusses the design and the performance achievable with active
aerodynamic attitude control in very low Earth orbit, i.e. below 450 km in
altitude. A novel real-time algorithm is proposed for selecting the angles of
deflection of aerodynamic actuators providing the closest match to the control
signal computed by a selected control law. The algorithm is based on a panel
method for the computation of the aerodynamic coefficients and relies on
approximate environmental parameters estimation and worst-case scenario
assumptions for the re-emission properties of space materials. Discussion of
results is performed by assuming two representative pointing manoeuvres, for
which momentum wheels and aerodynamic actuators are used synergistically. A
quaternion feedback PID controller implemented in discrete time is assumed to
determine the control signal at a sampling frequency of 1 Hz. The outcome of a
Monte Carlo analysis, performed for a wide range of orbital conditions, shows
that the target attitude is successfully achieved for the vast majority of the
cases, thus proving the robustness of the approach in the presence of
environmental uncertainties and realistic attitude hardware limitations.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:12:38 GMT""}]","2022-03-16"
"2203.07791","Guang-Ming Zhang","Qi Zhang and Guang-Ming Zhang","Noisy induced entanglement transition in one-dimensional random quantum
  circuits","6 pages, 4 figures, a few typos are removed","Chinese Physical Letters 39, 050302 (2022)","10.1088/0256-307X/39/5/050302",,"quant-ph cond-mat.dis-nn cond-mat.stat-mech","http://creativecommons.org/publicdomain/zero/1.0/","  Random quantum circuit is a minimally structured model to study the
entanglement dynamics of many-body quantum systems. In this paper, we
considered a one-dimensional quantum circuit with noisy Haar-random unitary
gates using density matrix operator and tensor contraction methods. It is shown
that the entanglement evolution of the random quantum circuits is properly
characterized by the logarithmic entanglement negativity. By performing exact
numerical calculations, we found that, as the physical error rate is decreased
below a critical value $p_c\approx 0.056$, the logarithmic entanglement
negativity changes from the area law to the volume law, giving rise to an
entanglement transition. The critical exponent of the correlation length can be
determined from the finite-size scaling analysis, revealing the universal
dynamic property of the noisy intermediate-scale quantum devices.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:15:11 GMT""},{""version"":""v2"",""created"":""Fri, 8 Apr 2022 07:07:58 GMT""}]","2022-05-16"
"2203.07792","Bilel Benjdira Dr.","Bilel Benjdira, Anis Koubaa, Wadii Boulila and Adel Ammar","Parking Analytics Framework using Deep Learning",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the number of vehicles continuously increasing, parking monitoring and
analysis are becoming a substantial feature of modern cities. In this study, we
present a methodology to monitor car parking areas and to analyze their
occupancy in real-time. The solution is based on a combination between image
analysis and deep learning techniques. It incorporates four building blocks put
inside a pipeline: vehicle detection, vehicle tracking, manual annotation of
parking slots, and occupancy estimation using the Ray Tracing algorithm. The
aim of this methodology is to optimize the use of parking areas and to reduce
the time wasted by daily drivers to find the right parking slot for their cars.
Also, it helps to better manage the space of the parking areas and to discover
misuse cases. A demonstration of the provided solution is shown in the
following video link: https://www.youtube.com/watch?v=KbAt8zT14Tc.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:16:59 GMT""}]","2022-03-16"
"2203.07793","George Gordon","Ahmed Osman, Jane Crowley, George Gordon","Training Generative Adversarial Networks for Optical Property Mapping
  using Synthetic Image Data","17 pages","Biomedical Optics Express 2022","10.1364/BOE.458554",,"eess.IV","http://creativecommons.org/licenses/by/4.0/","  We demonstrate training of a Generative Adversarial Network (GAN) for
prediction of optical property maps (scattering and absorption) using spatial
frequency domain imaging (SFDI) image data sets generated synthetically with
free open-source 3D modelling and rendering software, Blender. The flexibility
of Blender is exploited to simulate 3 models with real-life relevance to
clinical SFDI of diseased tissue: flat samples, flat samples with spheroidal
tumours and cylindrical samples with spheroidal tumours representing imaging
inside a tubular organ e.g. the gastro-intestinal tract. In all 3 scenarios we
show the GAN provides accurate reconstruction of optical properties from single
SFDI images with mean normalised error ranging from 1-1.2% for absorption and
0.7-1.2% for scattering, resulting in visually improved contrast for tumour
spheroid structures. This compares favourably with 25% absorption error and 10%
scattering error achieved using GANs on experimental SFDI data. However, some
of this improvement is due to lower noise and availability of perfect ground
truths so we therefore cross-validate our synthetically-trained GAN with a GAN
trained on experimental data and observe visually accurate results with error
of <40% for absorption and <25% for scattering, due largely to the presence of
spatial frequency mismatch artefacts. Our synthetically trained GAN is
therefore highly relevant to real experimental samples, but provides
significant added benefits of large training datasets, perfect ground-truths
and the ability to test realistic imaging geometries, e.g. inside cylinders,
for which no conventional single-shot demodulation algorithms exist. In future
we expect that application of techniques such as domain adaptation or training
on hybrid real-synthetic datasets will create a powerful tool for fast,
accurate production of optical property maps from real clinical imaging
systems.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:19:14 GMT""},{""version"":""v2"",""created"":""Mon, 3 Oct 2022 11:04:35 GMT""}]","2022-10-04"
"2203.07794","Luiz Alb\'erico Da Silva Lima","Luiz A. Silva-Lima, Lucimara P. Martins, Paula R. T. Coelho, Dimitri
  A. Gadotti","Revisiting the role of bars in AGN fuelling with propensity score sample
  matching",,"A&A 661, A105 (2022)","10.1051/0004-6361/202142432",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  The high luminosity displayed by an active galactic nucleus (AGN) requires
that gas be transported to the centre of the galaxy by some mechanism.
Bar-driven processes are often pointed out in this context and a number of
studies have addressed the bar-AGN connection, but with conflicting results.
Some of the inconsistencies can be explained by the different spatial- and
timescales involved in bar-driven gas inflows, accretion by the central black
hole, and AGN emission. However, the discrepant results could also be due to
sample biases, because both the AGN activity determination and the bar
detection are influenced by the method employed. We revisit the bar-AGN
connection in a sample of galaxies from SDSS, looking for evidence of the
influence of bars on AGN activity. We determine AGN activity by emission line
diagnostics and the properties of the bar were previously estimated with
\texttt{BUDDA}, which performs 2D bulge-bar-disk decomposition. Before
comparing active and inactive galaxies, we made a careful selection of the
sample to minimise selection biases. We created control samples by matching
them with the AGN sample using propensity score matching. This technique offers
an analytical approach for creating control samples given some object
parameters. We find that AGN are preferentially found in barred galaxies and
that the accretion rate is higher in barred galaxies, but only when different
M-$\sigma$ relations are used to estimate the black hole mass M$_\bullet$ in
barred and unbarred galaxies (from the central velocity dispersion $\sigma$).
On the other hand, we find no correlation between activity level and bar
strength. Altogether, our results strengthen theoretical predictions that the
bar is an important mechanism in disc galaxies, creating a gas reservoir to
feed AGN, but they also indicate that other mechanisms can play a major role,
particularly at scales <~100 pc.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:21:18 GMT""}]","2022-05-11"
"2203.07795","Keiichi Nagao","Keiichi Nagao, Holger Bech Nielsen","Reality from maximizing overlap in the periodic complex action theory","Latex 14 pages, typos corrected, presentation improved, the final
  version to appear in Prog.Theor.Exp.Phys",,"10.1093/ptep/ptac102",,"quant-ph hep-th","http://creativecommons.org/licenses/by/4.0/","  We study the periodic complex action theory (CAT) by imposing a periodic
condition in the future-included CAT where the time integration is performed
from the past to the future, and extend a normalized matrix element of an
operator $\hat{\mathcal O}$, which is called the weak value in the real action
theory, to another expression $\langle \hat{\mathcal O}
\rangle_{\mathrm{periodic}~\mathrm{time}}$. We present two theorems stating
that $\langle \hat{\mathcal O} \rangle_{\mathrm{periodic}~\mathrm{time}}$
becomes real for $\hat{\mathcal O}$ being Hermitian with regard to a modified
inner product that makes a given non-normal Hamiltonian $\hat{H}$ normal. The
first theorem holds for a given period $t_p$ in a case where the number of
eigenstates having the maximal imaginary part $B$ of the eigenvalues of
$\hat{H}$ is just one, while the second one stands for $t_p$ selected such that
the absolute value of the transition amplitude is maximized in a case where $B
\leq 0$ and $|B|$ is much smaller than the distances between any two real parts
of the eigenvalues of $\hat{H}$. The latter proven via a number-theoretical
argument suggests that, if our universe is periodic, then even the period could
be an adjustment parameter to be determined in the Feynman path integral. This
is a variant type of the maximization principle that we previously proposed.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:22:24 GMT""},{""version"":""v2"",""created"":""Sun, 14 Aug 2022 19:10:17 GMT""}]","2022-08-16"
"2203.07796","Bin Li","Bin Li, Dong Hao, Dengji Zhao","Multi-Unit Diffusion Auctions with Intermediaries",,,,,"cs.GT cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies multi-unit auctions powered by intermediaries, where each
intermediary owns a private set of unit-demand buyers and all intermediaries
are networked with each other. Our goal is to incentivize the intermediaries to
diffuse the auction information to individuals they can reach, including their
private buyers and neighboring intermediaries, so that more potential buyers
are able to participate in the auction. To this end, we build a diffusion-based
auction framework which incorporates the strategic interaction of
intermediaries. It is showed that the classic Vickrey-Clarke-Groves (VCG)
mechanism within the framework can achieve the maximum social welfare, but it
may decrease the seller's revenue or even lead to a deficit. To overcome the
revenue issue, we propose a novel auction, called critical neighborhood
auction, which not only maximizes the social welfare, but also improves the
seller's revenue comparing to the VCG mechanism with/without intermediaries.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:25:32 GMT""}]","2022-03-16"
"2203.07797","Michael Voit","Martin Auer, Michael Voit, Jeannette H.C. Woerner","Wigner- and Marchenko-Pastur-type limits for Jacobi processes",,,,,"math.PR math-ph math.CA math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study Jacobi processes $(X_{t})_{t\ge0}$ on the compact spaces $[-1,1]^N$
and on the noncompact spaces $[1,\infty[^N$ which are motivated by the
Heckman-Opdam theory for the root systems of type BC and associated integrable
particle systems. These processes depend on three positive parameters and
degenerate in the freezing limit to solutions of deterministic dynamical
systems. In the compact case, these models tend for $t\to\infty$ to the
distributions of the $\beta$-Jacobi ensembles and, in the freezing case, to
vectors consisting of ordered zeros of one-dimensional Jacobi polynomials.
Representing these processes by stochastic differential equations, we derive
almost sure analogues of Wigner's semicircle and Marchenko-Pastur limit laws
for $N\to\infty$ for the empirical distributions of the $N$ particles on some
local scale. We there allow for arbitrary initial conditions, which enter the
limiting distributions via free convolutions These results generalize
corresponding stationary limit results in the compact case for $\beta$-Jacobi
ensembles and, in the deterministic case, for the empirical distributions of
the ordered zeros of Jacobi polynomials by Dette and Studden. The results are
also related to free limit theorems for multivariate Bessel processes,
$\beta$-Hermite and $\beta$-Laguerre ensembles, and the asymptotic empirical
distributions of the zeros of Hermite and Laguerre polynomials for
$N\to\infty$.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:25:33 GMT""}]","2022-03-16"
"2203.07798","Eduardo Dadalto Camara Gomes","Eduardo Dadalto Camara Gomes, Florence Alberge, Pierre Duhamel and
  Pablo Piantanida","Igeood: An Information Geometry Approach to Out-of-Distribution
  Detection","Accepted in ICLR 2022",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reliable out-of-distribution (OOD) detection is fundamental to implementing
safer modern machine learning (ML) systems. In this paper, we introduce Igeood,
an effective method for detecting OOD samples. Igeood applies to any
pre-trained neural network, works under various degrees of access to the ML
model, does not require OOD samples or assumptions on the OOD data but can also
benefit (if available) from OOD samples. By building on the geodesic
(Fisher-Rao) distance between the underlying data distributions, our
discriminator can combine confidence scores from the logits outputs and the
learned features of a deep neural network. Empirically, we show that Igeood
outperforms competing state-of-the-art methods on a variety of network
architectures and datasets.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:26:35 GMT""}]","2022-03-16"
"2203.07799","Ken-Ichi Sasaki","Matthias Mentink, Ken-ichi Sasaki, Benoit Cure, Nikkie Deelen, Alexey
  Dudarev, Mitsushi Abe, Masami Iio, Yasuhiro Makida, Takahiro Okamura, Toru
  Ogitsu, Naoyuki Sumi, Akira Yamamoto, Makoto Yoshida and Hiromi Iinuma","Superconducting detector magnets for high energy physics","35 pages, 35 figures, 8 tables, contribution to Snowmass 2021",,,,"physics.ins-det physics.acc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Various superconducting detector solenoids for particle physics have been
developed in the world. The key technology is the aluminum-stabilized
superconducting conductor for almost all the detector magnets in particle
physics experiments. With the progress of the conductor, the coil fabrication
technology has progressed as well, such as the inner coil winding technique,
indirect cooling, transparent vacuum vessel, quench protection scheme using
pure aluminum strips and so on. The detector solenoids design study is in
progress for future big projects in Japan and Europe, that is, ILC, FCC and
CLIC, based on the technologies established over many years. The combination of
good mechanical properties and keeping a high RRR is a key point for the
development of Al-stabilized conductor. The present concern for the detector
solenoid development is to have been gradually losing the key technologies and
experiences, because large-scale detector magnets with Al-stabilized conductor
has not been fabricated after the success of CMS and ATLAS-CS in LHC.
Complementary efforts are needed to resume an equivalent level of expertise, to
extend the effort on research and to develop these technologies and apply them
to future detector magnet projects. Especially, further effort is necessary for
the industrial technology of Al-stabilized superconductor production. The
worldwide collaboration with relevant institutes and industries will be
critically important to re-realize and validate the required performances. Some
detector solenoids for mid-scale experiment wound with conventional
copper-stabilized Nb-Ti conductor require precise control of magnetic field
distribution. The development efforts are on-going in terms of the magnetic
field design technology with high precision simulation, coil fabrication
technology and control method of magnetic field distribution.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:31:09 GMT""}]","2022-03-16"
"2203.07800","Walaa I. Eshraim","Walaa I. Eshraim","Masses of vector and pseudovector hybrid mesons in a chiral symmetric
  model","6 pages, 1 table, Contribution to the XXXIII International Workshop
  on High Energy Physics ""Hard Problems of Hadron Physics: Non-Perturbative QCD
  & Related Quests"", 08-12 November 2021",,,,"hep-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We enlarge the chiral model, the so-called extended Linear Sigma Model
(eLSM), by including the low-lying hybrid nonet with exotic quantum numbers
$J^{PC}=1^{-+}$ and the nonet of their chiral partners with $J^{PC}=1^{+-}$ to
a global $U(3)_r \times U(3)_l$ chiral symmetry. We use the assignment of the
$\pi_1^{hyb}= \pi_1(1600)$ as input to determine the unknown parameters. Then,
we compute the lightest vector and pseudovector hybrid masses that could guide
ongoing and upcoming experiments in searching for hybrids.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:32:27 GMT""},{""version"":""v2"",""created"":""Fri, 15 Apr 2022 06:03:23 GMT""}]","2022-04-18"
"2203.07801","Rakesh Pawar","Chetan Balwe, Amit Hogadi and Rakesh Pawar","Milnor-Witt cycle modules over an excellent DVR","research grant support details added",,,,"math.AG","http://creativecommons.org/licenses/by/4.0/","  The definition of Milnor-Witt cycle modules in [Feld, N., Milnor-Witt cycle
modules, Journal of Pure and Applied Algebra 224 (2020) 106298] can easily be
adapted over general regular base schemes. However, there are simple examples
to show that Gersten complex fails to be exact for cycle modules in general if
the base is not a field. The goal of this article is to show that, for a
restricted class of Milnor-Witt cycle modules over an excellent DVR satisfying
an extra axiom, called here as R5, the expected properties of exactness of
Gersten complex and $\mathbb{A}^1$-invariance hold. Moreover R5 is vacuously
satisfied when the base is a perfect field and it is also satisfied by $K^{MW}$
over any base. As a corollary, we obtain the strict $\mathbb{A}^1$-invariance
and the exactness of Gersten complex for $K^{MW}$ over an excellent DVR.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:33:49 GMT""},{""version"":""v2"",""created"":""Sun, 3 Apr 2022 10:35:53 GMT""},{""version"":""v3"",""created"":""Thu, 14 Jul 2022 11:15:11 GMT""}]","2022-07-15"
"2203.07802","Gabriele Santin","Gabriele Santin and Inna Skarbovsky and Fabiana Fournier and Bruno
  Lepri","A Framework for Verifiable and Auditable Federated Anomaly Detection",,,"10.1109/ACCESS.2022.3196391",,"cs.LG cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Federated Leaning is an emerging approach to manage cooperation between a
group of agents for the solution of Machine Learning tasks, with the goal of
improving each agent's performance without disclosing any data. In this paper
we present a novel algorithmic architecture that tackle this problem in the
particular case of Anomaly Detection (or classification or rare events), a
setting where typical applications often comprise data with sensible
information, but where the scarcity of anomalous examples encourages
collaboration. We show how Random Forests can be used as a tool for the
development of accurate classifiers with an effective insight-sharing mechanism
that does not break the data integrity. Moreover, we explain how the new
architecture can be readily integrated in a blockchain infrastructure to ensure
the verifiable and auditable execution of the algorithm. Furthermore, we
discuss how this work may set the basis for a more general approach for the
design of federated ensemble-learning methods beyond the specific task and
architecture discussed in this paper.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:34:02 GMT""}]","2022-08-09"
"2203.07803","Oliver Johnson","Letian Yu and Fraser Daly and Oliver Johnson","A negative binomial approximation in group testing",,,,,"math.PR cs.IT math.IT math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  We consider the problem of group testing (pooled testing), first introduced
by Dorfman. For non-adaptive testing strategies, we refer to a non-defective
item as `intruding' if it only appears in positive tests. Such items cause
mis-classification errors in the well-known COMP algorithm, and can make other
algorithms produce an error. It is therefore of interest to understand the
distribution of the number of intruding items. We show that, under Bernoulli
matrix designs, this distribution is well approximated in a variety of senses
by a negative binomial distribution, allowing us to understand the performance
of the two-stage conservative group testing algorithm of Aldridge.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:37:32 GMT""},{""version"":""v2"",""created"":""Fri, 26 Aug 2022 08:32:45 GMT""}]","2022-08-29"
"2203.07804","Massimo Giovannozzi","M. Benedikt, A. Chance, B. Dalena, D. Denisov, M. Giovannozzi, J.
  Gutleber, R. Losito, M. Mangano, T. Raubenheimer, W. Riegler, V. Shiltsev, D.
  Schulte, D. Tommasini, F. Zimmermann","Future Circular Hadron Collider FCC-hh: Overview and Status","Contribution to Snowmass 2021",,,,"physics.acc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Future Circular Collider (FCC) study was launched as a world-wide
international collaboration hosted by CERN. Its goal is to push the field to
the next energy frontier beyond LHC, increasing by an order of magnitude the
mass of particles that could be directly produced, and decreasing by an order
of magnitude the subatomic distances to be studied. The FCC study covers two
accelerators, namely, an energy-frontier hadron collider (FCC-hh) and a highest
luminosity, high-energy lepton collider (FCC-ee). Both rings are hosted in the
same 100 km tunnel infrastructure, replicating the CERN strategy for LEP and
LHC, i.e. developing a lepton and a hadron ring sharing the same tunnel. This
paper is devoted to the FCC-hh and summarizes the key features of the FCC-hh
accelerator design, performance reach, and underlying technologies. The
material presented in this paper builds on the conceptual design report
published in 2019, and extends it, including also the progress made and the
results achieved since then.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:37:42 GMT""}]","2022-03-16"
"2203.07805","Marcos Faundez-Zanuy","Marcos Faundez-Zanuy, Ji\v{r}\'i Mekyska, Virginia Espinosa-Duro","On the focusing of thermal images","11 pages, published in Pattern Recognition Letters, Volume 32, Issue
  11, 2011, Pages 1548-1557","Pattern Recognition Letters, Volume 32, Issue 11, 2011, Pages
  1548-1557, ISSN 0167-8655","10.1016/j.patrec.2011.04.022",,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper we present a new thermographic image database suitable for the
analysis of automatic focus measures. This database consists of 8 different
sets of scenes, where each scene contains one image for 96 different focus
positions. Using this database we evaluate the usefulness of six focus measures
with the goal to determine the optimal focus position. Experimental results
reveal that an accurate automatic detection of optimal focus position is
possible, even with a low computational burden. We also present an acquisition
tool able to help the acquisition of thermal images. To the best of our
knowledge, this is the first study about automatic focus of thermal images.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:41:07 GMT""}]","2022-03-16"
"2203.07806","Sandra Siby","Sandra Siby, Ludovic Barman, Christopher Wood, Marwan Fayed, Nick
  Sullivan, Carmela Troncoso","You get PADDING, everybody gets PADDING! You get privacy? Evaluating
  practical QUIC website fingerprinting protections for the masses",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Website fingerprinting (WF) is a well-know threat to users' web privacy. New
internet standards, such as QUIC, include padding to support defenses against
WF. Previous work only analyzes the effectiveness of defenses when users are
behind a VPN. Yet, this is not how most users browse the Internet. In this
paper, we provide a comprehensive evaluation of QUIC-padding-based defenses
against WF when users directly browse the web. We confirm previous claims that
network-layer padding cannot provide good protection against powerful
adversaries capable of observing all traffic traces. We further demonstrate
that such padding is ineffective even against adversaries with constraints on
traffic visibility and processing power. At the application layer, we show that
defenses need to be deployed by both first and third parties, and that they can
only thwart traffic analysis in limited situations. We identify challenges to
deploy effective WF defenses and provide recommendations to address them.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:41:43 GMT""},{""version"":""v2"",""created"":""Thu, 15 Dec 2022 10:57:55 GMT""}]","2022-12-16"
"2203.07807","Sylvain Chevallier","Quentin Barth\'elemy, Sylvain Chevallier, Rapha\""elle Bertrand-Lalo,
  Pierre Clisson","End-to-end P300 BCI using Bayesian accumulation of Riemannian
  probabilities","9 pages, 7 figures, 3 tables",,"10.1080/2326263X.2022.2140467",,"cs.LG cs.HC eess.SP","http://creativecommons.org/licenses/by-sa/4.0/","  In brain-computer interfaces (BCI), most of the approaches based on
event-related potential (ERP) focus on the detection of P300, aiming for single
trial classification for a speller task. While this is an important objective,
existing P300 BCI still require several repetitions to achieve a correct
classification accuracy. Signal processing and machine learning advances in
P300 BCI mostly revolve around the P300 detection part, leaving the character
classification out of the scope. To reduce the number of repetitions while
maintaining a good character classification, it is critical to embrace the full
classification problem. We introduce an end-to-end pipeline, starting from
feature extraction, and is composed of an ERP-level classification using
probabilistic Riemannian MDM which feeds a character-level classification using
Bayesian accumulation of confidence across trials. Whereas existing approaches
only increase the confidence of a character when it is flashed, our new
pipeline, called Bayesian accumulation of Riemannian probabilities (ASAP),
update the confidence of each character after each flash. We provide the proper
derivation and theoretical reformulation of this Bayesian approach for a
seamless processing of information from signal to BCI characters. We
demonstrate that our approach performs significantly better than standard
methods on public P300 datasets.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:47:59 GMT""},{""version"":""v2"",""created"":""Fri, 30 Sep 2022 17:49:43 GMT""},{""version"":""v3"",""created"":""Tue, 15 Nov 2022 09:50:29 GMT""}]","2022-11-16"
"2203.07808","Paul Wimmer","Paul Wimmer, Jens Mehnert and Alexandru Paul Condurache","Interspace Pruning: Using Adaptive Filter Representations to Improve
  Training of Sparse CNNs","Accepted as conference paper for CVPR 2022",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unstructured pruning is well suited to reduce the memory footprint of
convolutional neural networks (CNNs), both at training and inference time. CNNs
contain parameters arranged in $K \times K$ filters. Standard unstructured
pruning (SP) reduces the memory footprint of CNNs by setting filter elements to
zero, thereby specifying a fixed subspace that constrains the filter.
Especially if pruning is applied before or during training, this induces a
strong bias. To overcome this, we introduce interspace pruning (IP), a general
tool to improve existing pruning methods. It uses filters represented in a
dynamic interspace by linear combinations of an underlying adaptive filter
basis (FB). For IP, FB coefficients are set to zero while un-pruned
coefficients and FBs are trained jointly. In this work, we provide mathematical
evidence for IP's superior performance and demonstrate that IP outperforms SP
on all tested state-of-the-art unstructured pruning methods. Especially in
challenging situations, like pruning for ImageNet or pruning to high sparsity,
IP greatly exceeds SP with equal runtime and parameter costs. Finally, we show
that advances of IP are due to improved trainability and superior
generalization ability.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:50:45 GMT""}]","2022-03-16"
"2203.07809","Dmitry V. Dylov","Segrey Kastryulin and Jamil Zakirov and Nicola Pezzotti and Dmitry V.
  Dylov","Image Quality Assessment for Magnetic Resonance Imaging","13 pages, 8 figures, V2: under review in Medical Image Analysis
  (revised)","IEEE Access, V.11 pp. 14154-14168, 2023","10.1109/ACCESS.2023.3243466",,"eess.IV cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Image quality assessment (IQA) algorithms aim to reproduce the human's
perception of the image quality. The growing popularity of image enhancement,
generation, and recovery models instigated the development of many methods to
assess their performance. However, most IQA solutions are designed to predict
image quality in the general domain, with the applicability to specific areas,
such as medical imaging, remaining questionable. Moreover, the selection of
these IQA metrics for a specific task typically involves intentionally induced
distortions, such as manually added noise or artificial blurring; yet, the
chosen metrics are then used to judge the output of real-life computer vision
models. In this work, we aspire to fill these gaps by carrying out the most
extensive IQA evaluation study for Magnetic Resonance Imaging (MRI) to date
(14,700 subjective scores). We use outputs of neural network models trained to
solve problems relevant to MRI, including image reconstruction in the scan
acceleration, motion correction, and denoising. Our emphasis is on reflecting
the radiologist's perception of the reconstructed images, gauging the most
diagnostically influential criteria for the quality of MRI scans:
signal-to-noise ratio, contrast-to-noise ratio, and the presence of artifacts.
Seven trained radiologists assess these distorted images, with their verdicts
then correlated with 35 different image quality metrics (full-reference,
no-reference, and distribution-based metrics considered). The top performers --
DISTS, HaarPSI, VSI, and FID-VGG16 -- are found to be efficient across three
proposed quality criteria, for all considered anatomies and the target tasks.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:52:29 GMT""},{""version"":""v2"",""created"":""Fri, 1 Jul 2022 12:17:59 GMT""}]","2023-02-17"
"2203.07810","Alexandre Sukhov","Alexandre Sukhov","On boundary properties of asymptotically holomorphic functions","12 pages. arXiv admin note: substantial text overlap with
  arXiv:1808.04266, arXiv:2202.02538, arXiv:1807.09763",,,,"math.CV","http://creativecommons.org/licenses/by/4.0/","  We prove a Fatou type theorem for bounded functions with d_J -bar
differential of a controled growth on smoothly bounded domains in an almost
complex manifold.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:55:34 GMT""}]","2022-04-13"
"2203.07811","Andre Ran","Andre Ran and Michal Wojtylak","Global properties of eigenvalues of parametric rank one perturbations
  for unstructured and structured matrices II","12 pages 6 figures",,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  We present in this note a correction to Theorem 17 in our earlier paper
""Global properties of eigenvalues of parametric rank one perturbations for
structured and unstructured matrices"" and sharpen the estimates for eigenvalues
of parametric rank one perturbations given in that theorem.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:56:34 GMT""}]","2022-03-16"
"2203.07812","Xian-Li Yin","Xian-Li Yin, Yu-Hong Liu, Jin-Feng Huang, Jie-Qiao Liao","Single-photon scattering in a giant-molecule waveguide-QED system","14 pages, 9 figures","Phys. Rev. A 106, 013715 (2022)","10.1103/PhysRevA.106.013715",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the coherent single-photon scattering in a one-dimensional waveguide
coupled to a giant artificial molecule consisting of two coupled giant atoms.
Since each giant atom couples to the waveguide via two coupling points, the
couplings of the molecule with the waveguide have three different coupling
configurations: the separated-, braided-, and nested-coupling cases. We obtain
the exact expressions of the single-photon transmission and reflection
amplitudes with the real-space approach. It is found that the behavior of the
scattering spectra depends on the phase shift between two neighboring coupling
points, the coupling configuration, and the coupling between the two giant
atoms. Concretely, we study the photon scattering in both the Markovian and
non-Markovian regimes, in which the photon propagating time between two
neighboring coupling points is neglected and considered, respectively. Under
the Markovian limit, the asymmetric Fano line shapes in different coupling
configurations of the giant-molecule waveguide-QED system can be obtained by
choosing proper phase shift, and the transmission window can be adjusted by the
coupling strength between the two giant atoms in these three coupling
configurations. In particular, multiple reflection peaks and dips in these
configurations are revived in the non-Markovian regime. This paper will pave
the way for the study of controllable single-photon devices based on the
giant-molecule waveguide-QED systems.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:01:03 GMT""},{""version"":""v2"",""created"":""Sun, 31 Jul 2022 14:29:19 GMT""}]","2022-08-02"
"2203.07813","Liqiang Zhang","Li-qiang Zhang and Deng-hui Yu and Chang-shui Yu","The optimal approximation of qubit states with limited quantum states","6 figures","Physics Letters A Volume 398, 17 May 2021, 127286","10.1016/j.physleta.2021.127286",,"quant-ph math-ph math.MP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Measuring the closest distance between two states is an alternative and
significant approach in the resource quantification, which is the core task in
the resource theory. Quite limited progress has been made for this approach
even in simple systems due to the various potential complexities. Here we
analytically solve the optimal scheme to find out the closest distance between
the objective qubit state and all the possible states convexly mixed by some
limited states, namely, to optimally construct the objective qubit state using
the quantum states within any given state set. In particular, we find the least
number of (not more than four) states within a given set to optimally construct
the objective state and also find that any state can be optimally established
by at most four quantum states of the set. The examples in various cases are
presented to verify our analytic solutions further.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:01:41 GMT""}]","2022-03-16"
"2203.07815","Tian Xia","Tian Xia, Pedro Sanchez, Chen Qin, Sotirios A. Tsaftaris","Adversarial Counterfactual Augmentation: Application in Alzheimer's
  Disease Classification",,,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Due to the limited availability of medical data, deep learning approaches for
medical image analysis tend to generalise poorly to unseen data. Augmenting
data during training with random transformations has been shown to help and
became a ubiquitous technique for training neural networks. Here, we propose a
novel adversarial counterfactual augmentation scheme that aims at finding the
most \textit{effective} synthesised images to improve downstream tasks, given a
pre-trained generative model. Specifically, we construct an adversarial game
where we update the input \textit{conditional factor} of the generator and the
downstream \textit{classifier} with gradient backpropagation alternatively and
iteratively. This can be viewed as finding the `\textit{weakness}' of the
classifier and purposely forcing it to \textit{overcome} its weakness via the
generative model. To demonstrate the effectiveness of the proposed approach, we
validate the method with the classification of Alzheimer's Disease (AD) as a
downstream task. The pre-trained generative model synthesises brain images
using age as conditional factor. Extensive experiments and ablation studies
have been performed to show that the proposed approach improves classification
performance and has potential to alleviate spurious correlations and
catastrophic forgetting. Code will be released upon acceptance.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:11:05 GMT""},{""version"":""v2"",""created"":""Sat, 1 Oct 2022 23:41:00 GMT""}]","2022-10-04"
"2203.07816","Liqiang Zhang","Li-qiang Zhang and Deng-hui Yu and Chang-shui Yu","The best approximation of a given qubit state with the limited
  pure-state set","18 pages","2021 J. Phys. A: Math. Theor. 54 085205","10.1088/1751-8121/abdcd0",,"quant-ph math-ph math.MP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The preparation of quantum states lies at the foundation in the quantum
information processing. The convex mixing of some existing quantum states is
one of the effective candidate. In this paper, we mainly study how a target
quantum state can be optimally prepared by not more than three given pure
states. The analytic optimal distance based on the fidelity is found. We also
show that the preparation with more than four states can be essentially
converted to the case with not more than four states, which can be similarly
solved as the case with three states. The validity is illustrated by the
comparison of our analytical and numerical results.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:14:45 GMT""}]","2022-03-16"
"2203.07817","Bedangadas Mohanty Dr.","A. Pandav, D. Mallick, and B. Mohanty","Search for the QCD Critical Point in High Energy Nuclear Collisions","Contribution to Progress in Particle and Nuclear Physics. 56 pages
  and 36 figures",,"10.1016/j.ppnp.2022.103960",,"nucl-ex hep-ex nucl-th","http://creativecommons.org/licenses/by/4.0/","  QCD critical point is a landmark region in the QCD phase diagram outlined by
temperature as a function of baryon chemical potential. To the right of this
second-order phase transition point, one expects first order quark-hadron phase
transition boundary, towards the left a crossover region, top of it lies the
quark gluon plasma phase and below it the hadronic phase. Hence locating the
QCD critical point through relativistic heavy-ion collision experiments is an
active area of research. Cumulants of conserved quantities in strong
interaction, such as net-baryon, net-charge, and net-strangeness, are suggested
to be sensitive to the physics of QCD critical point and are therefore useful
observables in the study of the phase transition between quark-gluon plasma and
hadronic matter. We review the experimental status of the search for the QCD
critical point via the measurements of cumulants of net-particle distributions
in heavy ion collisions. We discuss various experimental challenges and
associated corrections in such fluctuation measurements. We also comment on the
physics implications of the measurements by comparing them with theoretical
calculations. This is followed by a discussion on future experiments and
measurements related to high baryonic density QCD matter.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:15:13 GMT""}]","2022-05-25"
"2203.07818","Yun Zheng","Yun Zheng, Jing Wang, Judith Irwin, Jayanne English, Qingchuan Ma, Ran
  Wang, Ke Wang, Q. Daniel Wang, Marita Krause, Toky H. Randriamampandry,
  Jiangtao Li, and Rainer Beck","CHANG-ES XXV: HI Imaging of Nearby Edge-on Galaxies -- Data Release 4","27 pages, 10 figures, accepted for publication in MNRAS",,"10.1093/mnras/stac760",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the HI distribution of galaxies from the Continuum Halos in Nearby
Galaxies - an EVLA Survey (CHANG-ES). Though the observational mode was not
optimized for detecting HI, we successfully produce HI cubes for 19 galaxies.
The moment-0 maps from this work are available on CHANG-ES data release
website, i.e., https://www.queensu.ca/changes. Our sample is dominated by
star-forming, HI-rich galaxies at distances from 6.27 to 34.1 Mpc. HI
interferometric images on two of these galaxies (NGC 5792 and UGC 10288) are
presented here for the first time, while 12 of our remaining sample galaxies
now have better HI spatial resolutions and/or sensitivities of intensity maps
than those in existing publications. We characterize the average scale heights
of the HI distributions for a subset of most inclined galaxies (inclination >
80 deg), and compare them to the radio continuum intensity scale heights, which
have been derived in a similar way. The two types of scale heights are well
correlated, with similar dependence on disk radial extension and star formation
rate surface density but different dependence on mass surface density. This
result indicates that the vertical distribution of the two components may be
governed by similar fundamental physics but with subtle differences.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:16:35 GMT""}]","2022-03-30"
"2203.07819","Javad Bagherian","Allen Herman, Javad Bagherian, Hanieh Memarzadeh","The generalized X-join of Cayley graphs",,,,,"math.CO math.GR","http://creativecommons.org/licenses/by/4.0/","  As a main result of this paper we give conditions under which the generalized
$X$-join of Cayley graphs is a Cayley graph. In particular, we show that
$X$-join of isomorphic Cayley graphs is a Cayley grpah. To do this, new
properties for a generalized wreath product of permutation groups are given in
the case where the base group acts regularly. These are used to give conditions
for the generalized wreath product to contain a regular subgroup, which are
then applied to generalized $X$-joins of Cayley graphs. Along the way, it is
shown that the generalized $X$-join of isomorphic Cayley graphs will always be
a vertex transitive graph.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:20:47 GMT""}]","2022-03-16"
"2203.07820","Phani Motamarri","Sambit Das, Phani Motamarri, Vishal Subramanian, David M. Rogers,
  Vikram Gavini","DFT-FE 1.0: A massively parallel hybrid CPU-GPU density functional
  theory code using finite-element discretization","55 pages, 7 figures, 7 Tables",,"10.1016/j.cpc.2022.108473",,"physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present DFT-FE 1.0, building on DFT-FE 0.6 [Comput. Phys. Commun. 246,
106853 (2020)], to conduct fast and accurate large-scale density functional
theory (DFT) calculations (reaching ~ $100,000$ electrons) on both many-core
CPU and hybrid CPU-GPU computing architectures. This work involves improvements
in the real-space formulation -- via an improved treatment of the electrostatic
interactions that substantially enhances the computational efficiency -- as
well high-performance computing aspects, including the GPU acceleration of all
the key compute kernels in DFT-FE. We demonstrate the accuracy by comparing the
ground-state energies, ionic forces and cell stresses on a wide-range of
benchmark systems against those obtained from widely used DFT codes. Further,
we demonstrate the numerical efficiency of our implementation, which yields
$\sim 20 \times$ CPU-GPU speed-up by using GPU acceleration on hybrid CPU-GPU
nodes. Notably, owing to the parallel-scaling of the GPU implementation, we
obtain wall-times of $80-140$ seconds for full ground-state calculations, with
stringent accuracy, on benchmark systems containing ~ $6,000-15,000$ electrons.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:20:47 GMT""},{""version"":""v2"",""created"":""Mon, 21 Mar 2022 06:17:49 GMT""}]","2022-08-31"
"2203.07821","Andre Ran","G.J. Groenewald, M.A. Kaashoek, A.C.M. Ran","Wiener-Hopf factorization indices of rational matrix functions with
  respect to the unit circle in terms of realization",,,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  As in the paper [G. Groenewald, M.A. Kaashoek, A.C.M. Ran, Wiener-Hopf
indices of unitary functions on the unit circle in terms of realizations and
related results on Toeplitz operators. \emph{Indag. Math.} 28 (2017) 694--710]
our aim is to obtain explicitly the Wiener-Hopf indices of a rational $m\times
m$ matrix function $R(z)$ that has no poles and no zeros on the unit circle
$\mathbb{T}$ but, in contrast with that paper, the function $R(z)$ is not
required to be unitary on the unit circle. On the other hand, using a
Douglas-Shapiro-Shields type of factorization, we show that $R(z)$ factors as
$R(z)=\Xi(z)\Psi(z)$, where $\Xi(z)$ and $\Psi(z)$ are rational $m\times m$
matrix functions, $\Xi(z)$ is unitary on the unit circle and $\Psi(z)$ is an
invertible outer function. Furthermore, the fact that $\Xi(z)$ is unitary on
the unit circle allows us to factor as $\Xi(z) =V(z)W^*(z)$ where $V(z)$ and
$W(z)$ are rational bi-inner $m\times m$ matrix functions. The latter allows us
to solve the Wiener-Hopf indices problem. To derive explicit formulas for the
functions $V(z)$ and $W(z)$ requires additional realization properties of the
function $\Xi(z)$ which are given in the last two sections.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:23:06 GMT""},{""version"":""v2"",""created"":""Sun, 27 Nov 2022 07:08:24 GMT""}]","2022-11-29"
"2203.07822","Peigen Cao","Peigen Cao","On exchange matrices from string diagrams","17 pages. Version 2: Minor changes and Example 3.6 added",,,,"math.RT math.CO","http://creativecommons.org/licenses/by/4.0/","  Inspired by Fock-Goncharov's amalgamation procedure
\cite{Fock-Goncharov-2006}, Shen-Weng introduced string diagrams in
\cite{Shen-Weng-2021}, which are very useful to describe many interesting
skew-symmetrizable matrices closely related with Lie theory. In this paper, we
prove that the skew-symmetrizable matrices from string diagrams are in the
smallest class $\mathcal P^\prime$ of skew-symmetrizable matrices containing
the $1\times 1$ zero matrix and closed under mutations and source-sink
extensions. This result applies to the exchange matrices of cluster algebras
from double Bruhat cells, unipotent cells, double Bott-Samelson cells and so
on.
  Our main result can be used to explain why many skew-symmetrizable matrices
from Lie theory have reddening sequences. It can be also used to prove some
interesting results regarding non-degenerate potentials on many quivers from
Lie theory.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:23:29 GMT""},{""version"":""v2"",""created"":""Mon, 28 Mar 2022 14:43:36 GMT""}]","2022-03-29"
"2203.07823","Victor Tsebro","V.I. Tsebro, E.G. Nikolaev, L.B. Lugansky, M.S. Kutuzov, R.A.
  Khmel'nitskii, A.A. Tonkikh, A.I. Khar'kovskii","Activated hopping transport in nematic conducting aerogel at low
  temperatures","15 pages, 11 figures, 4 tables","Journal of Experimental and Theoretical Physics (JETP), Vol. 134,
  No. 2, pp. 222-234 (2022)","10.1134/S106377612202008X",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The transport properties of nematic aerogels, which consist of highly
oriented Al$_2$O$_3\cdot$SiO$_2$ nanofibers coated with a graphene shell with a
large number of defects, are studied. The temperature dependences of the
electrical resistivity in the range of 9-40K strictly follow the formula
derived to describe the variable range hopping (VRH) conductivity, in which
exponent $\alpha$ changes from 0.4 to 0.9 when the number of layers in the
graphene shell decreases from 4-6 to 1-2. The dependence of $\alpha$ on the
shell thickness can be explained by a simultaneous change in the dimensionality
of hopping transport and the character of the energy dependence of the density
of localized states near the Fermi level. The fact that $\alpha$ approaches
unity at the minimum graphene shell thickness indicates a gradual transition
from VRH transport to nearest neighbor hopping (NNH) transport. The
magnetoresistance measured at T = 4.2 K is negative, increases significantly
with decreasing graphene shell thickness, and is approximated by a formula for
the case of weak localization with a good accuracy. The phase coherence lengths
are in a reasonable relation with the graphene grain sizes. The conducting
aerogels under study complement the well-known set of materials that exhibit
hopping electron transport at low temperatures, which is characteristic of
media with strong carrier localization, and also a negative magnetoresistance,
which usually manifests itself under weak localization conditions.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:25:19 GMT""}]","2022-03-16"
"2203.07824","Toufiq Parag","Susmit Agrawal, Prabhat Kumar, Siddharth Seth, Toufiq Parag, Maneesh
  Singh, Venkatesh Babu","SISL:Self-Supervised Image Signature Learning for Splicing Detection and
  Localization",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Recent algorithms for image manipulation detection almost exclusively use
deep network models. These approaches require either dense pixelwise
groundtruth masks, camera ids, or image metadata to train the networks. On one
hand, constructing a training set to represent the countless tampering
possibilities is impractical. On the other hand, social media platforms or
commercial applications are often constrained to remove camera ids as well as
metadata from images. A self-supervised algorithm for training manipulation
detection models without dense groundtruth or camera/image metadata would be
extremely useful for many forensics applications. In this paper, we propose
self-supervised approach for training splicing detection/localization models
from frequency transforms of images. To identify the spliced regions, our deep
network learns a representation to capture an image specific signature by
enforcing (image) self consistency . We experimentally demonstrate that our
proposed model can yield similar or better performances of multiple existing
methods on standard datasets without relying on labels or metadata.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:26:29 GMT""}]","2022-03-16"
"2203.07825","Shidi Li","Shidi Li, Christian Walder, Miaomiao Liu","SPA-VAE: Similar-Parts-Assignment for Unsupervised 3D Point Cloud
  Generation",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper addresses the problem of unsupervised parts-aware point cloud
generation with learned parts-based self-similarity. Our SPA-VAE infers a set
of latent canonical candidate shapes for any given object, along with a set of
rigid body transformations for each such candidate shape to one or more
locations within the assembled object. In this way, noisy samples on the
surface of, say, each leg of a table, are effectively combined to estimate a
single leg prototype. When parts-based self-similarity exists in the raw data,
sharing data among parts in this way confers numerous advantages: modeling
accuracy, appropriately self-similar generative outputs, precise in-filling of
occlusions, and model parsimony. SPA-VAE is trained end-to-end using a
variational Bayesian approach which uses the Gumbel-softmax trick for the
shared part assignments, along with various novel losses to provide appropriate
inductive biases. Quantitative and qualitative analyses on ShapeNet demonstrate
the advantage of SPA-VAE.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:26:32 GMT""},{""version"":""v2"",""created"":""Mon, 29 Aug 2022 01:04:23 GMT""}]","2022-08-30"
"2203.07826","Henrik Garde","Horia D. Cornean, Henrik Garde, Arne Jensen","Discrete approximations to Dirac operators and norm resolvent
  convergence",,,,,"math-ph cs.NA math.MP math.NA math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider continuous Dirac operators defined on $\mathbf{R}^d$,
$d\in\{1,2,3\}$, together with various discrete versions of them. Both
forward-backward and symmetric finite differences are used as approximations to
partial derivatives. We also allow a bounded, H\""older continuous, and
self-adjoint matrix-valued potential, which in the discrete setting is
evaluated on the mesh. Our main goal is to investigate whether the proposed
discrete models converge in norm resolvent sense to their continuous
counterparts, as the mesh size tends to zero and up to a natural embedding of
the discrete space into the continuous one. In dimension one we show that
forward-backward differences lead to norm resolvent convergence, while in
dimension two and three they do not. The same negative result holds in all
dimensions when symmetric differences are used. On the other hand, strong
resolvent convergence holds in all these cases. Nevertheless, and quite
remarkably, a rather simple but non-standard modification to the discrete
models, involving the mass term, ensures norm resolvent convergence in general.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:26:54 GMT""},{""version"":""v2"",""created"":""Sat, 18 Jun 2022 13:13:03 GMT""}]","2022-06-22"
"2203.07827","Wolfgang Sch\""afer","Anna Cisek, Wolfgang Sch\""afer, Antoni Szczurek","Structure and production mechanism of the enigmatic $X(3872)$ in
  high-energy hadronic reactions","17 pages, 7 figures, v2: references added, v3: a diagram added, minor
  changes",,"10.1140/epjc/s10052-022-11029-x",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We calculate the total cross section and transverse momentum distributions
for the production of enigmatic $\chi_{c,1}(3872)$ (or X(3872)) assuming
different scenarios: $c \bar c$ state and $D^{0*} {\bar D}^0 + D^0 {\bar
D}^{0*}$ molecule. The derivative of the $c \bar c$ wave function needed in the
first scenario is taken from a potential model calculations. Compared to
earlier calculation of molecular state we include not only single parton
scattering (SPS) but also double parton scattering (DPS) contributions. The
latter one seems to give smaller contribution than the SPS one. The upper limit
for the DPS production of $\chi_{c,1}(3872)$ is much below the CMS data. We
compare results of our calculations with existing experimental data of CMS,
ATLAS and LHCb collaborations. Reasonable cross sections can be obtained in
either $c \bar c$ or molecular $D {\bar D}^*$ scenarios for $X(3872)$. Also a
hybrid scenario is not excluded.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:30:01 GMT""},{""version"":""v2"",""created"":""Mon, 21 Mar 2022 08:30:50 GMT""},{""version"":""v3"",""created"":""Fri, 20 May 2022 08:57:52 GMT""}]","2022-12-14"
"2203.07828","Taichi Iki","Taichi Iki and Akiko Aizawa","Do BERTs Learn to Use Browser User Interface? Exploring Multi-Step Tasks
  with Unified Vision-and-Language BERTs","Work in Progress",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Pre-trained Transformers are good foundations for unified multi-task models
owing to their task-agnostic representation. Pre-trained Transformers are often
combined with text-to-text framework to execute multiple tasks by a single
model. Performing a task through a graphical user interface (GUI) is another
candidate to accommodate various tasks, including multi-step tasks with vision
and language inputs. However, few papers combine pre-trained Transformers with
performing through GUI. To fill this gap, we explore a framework in which a
model performs a task by manipulating the GUI implemented with web pages in
multiple steps. We develop task pages with and without page transitions and
propose a BERT extension for the framework. We jointly trained our BERT
extension with those task pages, and made the following observations. (1) The
model learned to use both task pages with and without page transition. (2) In
four out of five tasks without page transitions, the model performs greater
than 75% of the performance of the original BERT, which does not use browsers.
(3) The model did not generalize effectively on unseen tasks. These results
suggest that we can fine-tune BERTs to multi-step tasks through GUIs, and there
is room for improvement in their generalizability. Code will be available
online.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:32:28 GMT""}]","2022-03-16"
"2203.07829","Marco Valentini","Marco Valentini, Maksim Borovkov, Elsa Prada, Sara Marti-Sanchez, Marc
  Botifoll, Andrea Hofmann, Jordi Arbiol, Ramon Aguado, Pablo San-Jose,
  Georgios Katsaros","Majorana-like Coulomb spectroscopy in the absence of zero bias peaks",,,"10.1038/s41586-022-05382-w",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Hybrid semiconductor-superconductor devices hold great promise for realizing
topological quantum computing with Majorana zero modes (MZMs). However,
multiple claims of Majorana detection, based on either tunneling or Coulomb
blockade (CB) spectroscopy, remain disputed. Here we devise an experimental
protocol that allows to perform both types of measurements on the same hybrid
island by adjusting its charging energy via tunable junctions to the normal
leads. This method reduces ambiguities of Majorana detections by checking the
consistency between CB spectroscopy and zero bias peaks (ZBPs) in non-blockaded
transport.Specifically, we observe junction-dependent, even-odd modulated,
single-electron CB peaks in InAs/Al hybrid nanowires (NWs) without concomitant
low-bias peaks in tunneling spectroscopy. We provide a theoretical
interpretation of the experimental observations in terms of low-energy,
longitudinally-confined island states rather than overlapping Majorana modes.
Our results highlight the importance of combined measurements on the same
device for the identification of topological MZMs.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:32:44 GMT""},{""version"":""v2"",""created"":""Fri, 25 Mar 2022 14:18:18 GMT""},{""version"":""v3"",""created"":""Tue, 11 Oct 2022 19:55:35 GMT""}]","2022-12-28"
"2203.07830","Shashikiran Venkatesha","Shashikiran Venkatesha and Ranjani Parthasarathi","A Survey of fault models and fault tolerance methods for 2D bus-based
  multi-core systems and TSV based 3D NOC many-core systems","An Elaborate survey on fault models and fault tolerant designs for
  multi-core and many-core systems",,,,"cs.AR","http://creativecommons.org/licenses/by/4.0/","  Reliability has taken centre stage in the development of high-performance
computing processors. A Surge of interest is noticeable in recent times in
formulating fault and failure models, understanding failure mechanism and
strategizing fault mitigation methods for improving the reliability of the
system. The article presents a congregation of concepts illustrated one after
the other for a better understanding of damages caused by radiation, relevant
fault models, and effects of faults. We examine the state of art fault
mitigation techniques at the logical layer for digital CMOS based design and
SRAM based FPGA. CMOS SRAM structure is the same for both digital CMOS and
FPGA. Understanding of resilient SRAM based FPGA is necessary for developing
resilient prototypes and it facilitates a faster integration of digital CMOS
designs. At the micro-architectural and architectural layer, error detection
and recovery methods are discussed for bus-based multi-core systems. The
Through silicon via based 3D Network on chip is the prospective solution for
integrating many cores on single die. A suitable interconnection approach for
petascale computing on many-core systems. The article presents an elaborate
discussion on fault models, failure mechanisms, resilient 3D routers, defect
tolerance methods for the TSV based 3D NOC many-core systems. Core redundancy,
self-diagnosis and distributed diagnosis at the hardware level are examined for
many-core systems. The article presents a gamut of fault tolerance solutions
from logic level to processor core level in a multi-core and many-core
scenario.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:36:14 GMT""}]","2022-03-16"
"2203.07831","Xinjue Wang","Xinjue Wang, Esa Ollila and Sergiy A. Vorobyov","Graph Neural Network Sensitivity Under Probabilistic Error Model","7 pages, 3 figures",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph convolutional networks (GCNs) can successfully learn the graph signal
representation by graph convolution. The graph convolution depends on the graph
filter, which contains the topological dependency of data and propagates data
features. However, the estimation errors in the propagation matrix (e.g., the
adjacency matrix) can have a significant impact on graph filters and GCNs. In
this paper, we study the effect of a probabilistic graph error model on the
performance of the GCNs. We prove that the adjacency matrix under the error
model is bounded by a function of graph size and error probability. We further
analytically specify the upper bound of a normalized adjacency matrix with
self-loop added. Finally, we illustrate the error bounds by running experiments
on a synthetic dataset and study the sensitivity of a simple GCN under this
probabilistic error model on accuracy.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:40:10 GMT""},{""version"":""v2"",""created"":""Mon, 6 Jun 2022 09:20:07 GMT""}]","2022-06-07"
"2203.07832","Biswa Sengupta","Guo Ye and Han Liu and Biswa Sengupta","Learning to Infer Belief Embedded Communication",,,,,"cs.LG cs.AI cs.MA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In multi-agent collaboration problems with communication, an agent's ability
to encode their intention and interpret other agents' strategies is critical
for planning their future actions. This paper introduces a novel algorithm
called Intention Embedded Communication (IEC) to mimic an agent's language
learning ability. IEC contains a perception module for decoding other agents'
intentions in response to their past actions. It also includes a language
generation module for learning implicit grammar during communication with two
or more agents. Such grammar, by construction, should be compact for efficient
communication. Both modules undergo conjoint evolution - similar to an infant's
babbling that enables it to learn a language of choice by trial and error. We
utilised three multi-agent environments, namely predator/prey, traffic junction
and level-based foraging and illustrate that such a co-evolution enables us to
learn much quicker (50%) than state-of-the-art algorithms like MADDPG. Ablation
studies further show that disabling the inferring belief module, communication
module, and the hidden states reduces the model performance by 38%, 60% and
30%, respectively. Hence, we suggest that modelling other agents' behaviour
accelerates another agent to learn grammar and develop a language to
communicate efficiently. We evaluate our method on a set of cooperative
scenarios and show its superior performance to other multi-agent baselines. We
also demonstrate that it is essential for agents to reason about others' states
and learn this ability by continuous communication.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:42:10 GMT""}]","2022-03-16"
"2203.07833","Bretislav Friedrich","Horst Schmidt-B\""ocking and Bretislav Friedrich","One hundred years ago Alfred Land\'e unriddled the Anomalous Zeeman
  Effect and presaged Electron Spin",,,"10.1088/1402-4896/ac9c9b",,"physics.hist-ph","http://creativecommons.org/licenses/by/4.0/","  In order to commemorate Alfred Land\'e's unriddling of the anomalous Zeeman
Effect a century ago, we reconstruct his seminal contribution to atomic physics
in light of the atomic models available at the time. Land\'e recognized that
the coupling of quantized electronic angular momenta via their vector addition
within an atom was the origin of all the apparent mysteries of atomic structure
as manifested by the anomalous Zeeman effect. We show to which extent Land\'e's
ideas influenced the development of quantum physics, particularly Wolfgang
Pauli's path to the exclusion principle. We conclude with Land\'e's brief
biography.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:42:50 GMT""},{""version"":""v2"",""created"":""Sat, 26 Mar 2022 22:49:33 GMT""}]","2022-12-28"
"2203.07834","Masud Ehsani","Masud Ehsani, J\""urgen Jost","Scale Free Avalanches in Excitatory-Inhibitory Populations of Spiking
  Neurons with Conductance Based Synaptic Currents",,,,,"physics.bio-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We investigate spontaneous critical dynamics of excitatory and inhibitory
(EI) sparsely connected populations of spiking leaky integrate-and-fire neurons
with conductance-based synapses. We use a bottom-up approach to derive a single
neuron gain function and a linear Poisson neuron approximation which we use to
study mean-field dynamics of the EI population and its bifurcations. In the low
firing rate regime, the quiescent state loses stability due to saddle-node or
Hopf bifurcations. In particular, at the Bogdanov-Takens (BT) bifurcation point
which is the intersection of the Hopf bifurcation and the saddle-node
bifurcation lines of the 2D dynamical system, the network shows avalanche
dynamics with power-law avalanche size and duration distributions. This matches
the characteristics of low firing spontaneous activity in the cortex. By
linearizing gain functions and excitatory and inhibitory nullclines, we can
approximate the location of the BT bifurcation point. This point in the control
parameter phase space corresponds to the internal balance of excitation and
inhibition and a slight excess of external excitatory input to the excitatory
population. Due to the tight balance of average excitation and inhibition
currents, the firing of the individual cells is fluctuation-driven. Around the
BT point, the spiking of neurons is a Poisson process and the population
average membrane potential of neurons is approximately at the middle of the
operating interval $[V_{Rest}, V_{th}]$. Moreover, the EI network is close to
both oscillatory and active-inactive phase transition regimes.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:43:35 GMT""},{""version"":""v2"",""created"":""Mon, 4 Apr 2022 15:11:55 GMT""}]","2022-04-05"
"2203.07835","Florian Buettner","Sebastian G. Gruber and Florian Buettner","Better Uncertainty Calibration via Proper Scores for Classification and
  Beyond","Published at NeurIPS 2022",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With model trustworthiness being crucial for sensitive real-world
applications, practitioners are putting more and more focus on improving the
uncertainty calibration of deep neural networks. Calibration errors are
designed to quantify the reliability of probabilistic predictions but their
estimators are usually biased and inconsistent. In this work, we introduce the
framework of proper calibration errors, which relates every calibration error
to a proper score and provides a respective upper bound with optimal estimation
properties. This relationship can be used to reliably quantify the model
calibration improvement. We theoretically and empirically demonstrate the
shortcomings of commonly used estimators compared to our approach. Due to the
wide applicability of proper scores, this gives a natural extension of
recalibration beyond classification.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:46:08 GMT""},{""version"":""v2"",""created"":""Mon, 19 Sep 2022 15:43:32 GMT""},{""version"":""v3"",""created"":""Mon, 30 Jan 2023 14:54:41 GMT""}]","2023-01-31"
"2203.07836","Xuefeng Bai","Xuefeng Bai, Yulong Chen, Yue Zhang","Graph Pre-training for AMR Parsing and Generation","ACL2022 camera-ready final version",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Abstract meaning representation (AMR) highlights the core semantic
information of text in a graph structure. Recently, pre-trained language models
(PLMs) have advanced tasks of AMR parsing and AMR-to-text generation,
respectively. However, PLMs are typically pre-trained on textual data, thus are
sub-optimal for modeling structural knowledge. To this end, we investigate
graph self-supervised training to improve the structure awareness of PLMs over
AMR graphs. In particular, we introduce two graph auto-encoding strategies for
graph-to-graph pre-training and four tasks to integrate text and graph
information during pre-training. We further design a unified framework to
bridge the gap between pre-training and fine-tuning tasks. Experiments on both
AMR parsing and AMR-to-text generation show the superiority of our model. To
our knowledge, we are the first to consider pre-training on semantic graphs.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:47:00 GMT""},{""version"":""v2"",""created"":""Tue, 22 Mar 2022 16:16:16 GMT""},{""version"":""v3"",""created"":""Thu, 31 Mar 2022 15:17:02 GMT""},{""version"":""v4"",""created"":""Wed, 4 May 2022 17:02:23 GMT""}]","2022-05-05"
"2203.07837","JongMok Kim","JongMok Kim, Hwijun Lee, Jaeseung Lim, Jongkeun Na, Nojun Kwak, Jin
  Young Choi","Pose-MUM : Reinforcing Key Points Relationship for Semi-Supervised Human
  Pose Estimation",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  A well-designed strong-weak augmentation strategy and the stable teacher to
generate reliable pseudo labels are essential in the teacher-student framework
of semi-supervised learning (SSL). Considering these in mind, to suit the
semi-supervised human pose estimation (SSHPE) task, we propose a novel approach
referred to as Pose-MUM that modifies Mix/UnMix (MUM) augmentation. Like MUM in
the dense prediction task, the proposed Pose-MUM makes strong-weak augmentation
for pose estimation and leads the network to learn the relationship between
each human key point much better than the conventional methods by adding the
mixing process in intermediate layers in a stochastic manner. In addition, we
employ the exponential-moving-average-normalization (EMAN) teacher, which is
stable and well-suited to the SSL framework and furthermore boosts the
performance. Extensive experiments on MS-COCO dataset show the superiority of
our proposed method by consistently improving the performance over the previous
methods following SSHPE benchmark.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:48:40 GMT""}]","2022-03-16"
"2203.07838","Vivekanand Shukla Dr.","Deobrat Singh, Vivekanand Shukla, Nabil Khossossi, Per Hyldgaard, and
  Rajeev Ahuja","Stability of and conduction in single-walled Si$_2$BN nanotubes","14 pages, 8 figures",,,,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore the possibility and potential benefit of rolling a Si2BN sheet
into single-walled nanotubes (NTs). Using density functional theory (DFT), we
consider both structural stability and the impact on the nature of chemical
bonding and conduction. The structure is similar to carbon NTs and hexagonal
boron-nitride (hBN) NTs and we consider both armchair and zigzag Si2BN
configurations with varying diameters. The stability of these Si$_2$BN NTs is
confirmed by first-principles molecular dynamics calculations, by an exothermal
formation, an absence of imaginary modes in the phonon spectra. Also, we find
the nature of conduction varies semiconducting, from semi-metallic to metallic,
reflecting differences in armchair/zigzag-type structures, curvature effects,
and the effect of quantum confinement. We present the detailed characterization
of how these properties lead to differences in both the bonding nature and
electronic structures
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:49:29 GMT""}]","2022-03-16"
"2203.07839","Ivan Kokurin","I.A. Kokurin","Comment on ""HADOKEN: An open-source software package for predicting
  electron confinement effects in various nanowire geometries and
  configurations""","Comment on arXiv:2203.05233, 2 pages",,,,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a recent work [C. Chevalier, B. M. Wong, Comput. Phys. Commun. ${\bf
274}$, 108299 (2022); arXiv: 2203.05233 [cond-mat.mes-hall]] the interesting
and popular problem was considered. Authors attempted to solve the
self-consistent Schr\""{o}dinger-Poisson problem for an effective mass electron
in a core-shell semiconductor nanowire. The corresponding MATLAB-based software
package was presented. However, an incorrect solution of the Schr\""{o}dinger
equation invalidates the whole result. Here we point out the corresponding
error and possible ways to fix it.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:50:25 GMT""}]","2022-03-16"
"2203.07841","Masud Ehsani","Masud Ehsani, J\""urgen Jost","Self Organized Criticality in a Mesoscopic Model of
  Excitatory-Inhibitory Neuronal Populations by Short-term and Long-term
  Synaptic Plasticity",,,,,"physics.bio-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In [1], we have shown that the dynamics of an interconnected population of
excitatory and inhibitory spiking neurons wandering around a Bogdanov-Takens
(BT)bifurcation point can generate the observed scale-free avalanches at the
population level and the highly variable spike patterns of individual neurons.
These characteristics match experimental findings for spontaneous intrinsic
activity in the brain. In this paper, we address the mechanisms causing the
system to get and remain near this BT point. We propose an effective stochastic
neural field model which captures the dynamics of the mean-field model. We show
how the network tunes itself through local long-term synaptic plasticity by
STDP and short-term synaptic depression to be close to this bifurcation point.
The mesoscopic model that we derive matches the directed percolation model at
the absorbing state phase transition.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:52:47 GMT""},{""version"":""v2"",""created"":""Mon, 4 Apr 2022 15:36:56 GMT""}]","2022-04-05"
"2203.07842","Nilesh Pandey","Nilesh Pandey and Yogesh Singh Chauhan","Static negative susceptibility in ferromagnetic material induced by
  domain wall motion: an aspect of superconductor state",,,,,"physics.app-ph cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  Domain wall motion in magnetic materiel induces the negative susceptibility
leading to a perfect diamagnetism state. The local susceptibility is calculated
by the derivative of magnetization ($\vec{M}$) vector w.r.t. magnetic field
strength ($\vec{H}$) vector. In the transient region from the upward domain to
the downward domain (domain wall width), local $\vec{M}$ and $\vec{H}$ vectors
exhibit opposite slopes, which leads to a negative susceptibility value. A
negative susceptibility value induces the diamagnetism effect leading to a
relative permeability value $<$ 1 $\left(\mu _r < 1\right)$. This diamagnetism
sate originates due to the domain wall motion, which is an entirely different
mechanism from the electron motion's induced diamagnetism. Furthermore, the
strength of the diamagnetism state can be enhanced by tuning the gradient
energy of a domain that may correspond to a perfect diamagnetism state
$\left(\chi _v \approx -1 \Rightarrow \mu _r \rightarrow 0\right)$. Besides, we
believe that there may be a possibility of sustaining such a diamagnetic state
(domain wall induced) in a ferromagnetic material that is utterly contradictory
to the conventional theory.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:54:51 GMT""}]","2022-03-16"
"2203.07843","Felix Scholz","Chiu Ling Chan, Felix Scholz, Thomas Takacs","Locally refined quad meshing for linear elasticity problems based on
  convolutional neural networks",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we propose a method to generate suitably refined finite element
meshes using neural networks. As a model problem we consider a linear
elasticity problem on a planar domain (possibly with holes) having a polygonal
boundary. We impose boundary conditions by fixing the position of a part of the
boundary and applying a force on another part of the boundary. The resulting
displacement and distribution of stresses depend on the geometry of the domain
and on the boundary conditions. When applying a standard Galerkin
discretization using quadrilateral finite elements, one usually has to perform
adaptive refinement to properly resolve maxima of the stress distribution. Such
an adaptive scheme requires a local error estimator and a corresponding local
refinement strategy. The overall costs of such a strategy are high. We propose
to reduce the costs of obtaining a suitable discretization by training a neural
network whose evaluation replaces this adaptive refinement procedure. We set up
a single network for a large class of possible domains and boundary conditions
and not on a single domain of interest. The computational domain and boundary
conditions are interpreted as images, which are suitable inputs for convolution
neural networks. We use the U-net architecture and we devise training
strategies by dividing the possible inputs into different categories based on
their overall geometric complexity. Thus, we compare different training
strategies based on varying geometric complexity. One of the advantages of the
proposed approach is the interpretation of input and output as images, which do
not depend on the underlying discretization scheme. Another is the
generalizability and geometric flexibility. The network can be applied to
previously unseen geometries, even with different topology and level of detail.
Thus, training can easily be extended to other classes of geometries.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:59:37 GMT""}]","2022-03-16"
"2203.07844","Rohaifa Khaldi","Rohaifa Khaldi, Abdellatif El Afia, Raddouane Chiheb, Siham Tabik","What is the best RNN-cell structure for forecasting each time series
  behavior?",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is unquestionable that time series forecasting is of paramount importance
in many fields. The most used machine learning models to address time series
forecasting tasks are Recurrent Neural Networks (RNNs). Typically, those models
are built using one of the three most popular cells, ELMAN, Long-Short Term
Memory (LSTM), or Gated Recurrent Unit (GRU) cells, each cell has a different
structure and implies a different computational cost. However, it is not clear
why and when to use each RNN-cell structure. Actually, there is no
comprehensive characterization of all the possible time series behaviors and no
guidance on what RNN cell structure is the most suitable for each behavior. The
objective of this study is two-fold: it presents a comprehensive taxonomy of
all-time series behaviors (deterministic, random-walk, nonlinear, long-memory,
and chaotic), and provides insights into the best RNN cell structure for each
time series behavior. We conducted two experiments: (1) The first experiment
evaluates and analyzes the role of each component in the LSTM-Vanilla cell by
creating 11 variants based on one alteration in its basic architecture
(removing, adding, or substituting one cell component). (2) The second
experiment evaluates and analyzes the performance of 20 possible RNN-cell
structures. Our results showed that the MGU-SLIM3 cell is the most recommended
for deterministic and nonlinear behaviors, the MGU-SLIM2 cell is the most
suitable for random-walk behavior, FB1 cell is advocated for long-memory
behavior, and LSTM-SLIM1 for chaotic behavior.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:00:41 GMT""}]","2022-03-16"
"2203.07845","Yuanhan Zhang","Yuanhan Zhang, Qinghong Sun, Yichun Zhou, Zexin He, Zhenfei Yin, Kun
  Wang, Lu Sheng, Yu Qiao, Jing Shao, Ziwei Liu","Bamboo: Building Mega-Scale Vision Dataset Continually with
  Human-Machine Synergy","Bamboo is available at https://github.com/ZhangYuanhan-AI/Bamboo",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Large-scale datasets play a vital role in computer vision. But current
datasets are annotated blindly without differentiation to samples, making the
data collection inefficient and unscalable. The open question is how to build a
mega-scale dataset actively. Although advanced active learning algorithms might
be the answer, we experimentally found that they are lame in the realistic
annotation scenario where out-of-distribution data is extensive. This work thus
proposes a novel active learning framework for realistic dataset annotation.
Equipped with this framework, we build a high-quality vision dataset -- Bamboo,
which consists of 69M image classification annotations with 119K categories and
28M object bounding box annotations with 809 categories. We organize these
categories by a hierarchical taxonomy integrated from several knowledge bases.
The classification annotations are four times larger than ImageNet22K, and that
of detection is three times larger than Object365. Compared to ImageNet22K and
Objects365, models pre-trained on Bamboo achieve superior performance among
various downstream tasks (6.2% gains on classification and 2.1% gains on
detection). We believe our active learning framework and Bamboo are essential
for future work.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:01:00 GMT""},{""version"":""v2"",""created"":""Wed, 24 Aug 2022 01:41:45 GMT""}]","2022-08-26"
"2203.07847","Tassilo Klein","Tassilo Klein, Moin Nabi","SCD: Self-Contrastive Decorrelation for Sentence Embeddings","To appear at ACL 2022",,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose Self-Contrastive Decorrelation (SCD), a
self-supervised approach. Given an input sentence, it optimizes a joint
self-contrastive and decorrelation objective. Learning a representation is
facilitated by leveraging the contrast arising from the instantiation of
standard dropout at different rates. The proposed method is conceptually simple
yet empirically powerful. It achieves comparable results with state-of-the-art
methods on multiple benchmarks without using contrastive pairs. This study
opens up avenues for efficient self-supervised learning methods that are more
robust than current contrastive methods.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:02:10 GMT""}]","2022-03-16"
"2203.07848","Sergey Eliseev","Klaus Blaum and Sergey Eliseev and Sven Sturm","Perspectives on testing fundamental physics with highly charged ions in
  Penning traps","6 figures, 1 table, 111 references","Quantum Sci. Technol. 6 (2021) 014002","10.1088/2058-9565/abbc75",,"physics.atom-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In Penning traps electromagnetic forces are used to confine charged particles
under well-controlled conditions for virtually unlimited time. Sensitive
detection methods have been developed to allow observation of single stored
ions. Various cooling methods can be employed to reduce the energy of the
trapped particle to nearly at rest. In this review we summarize how highly
charged ions offer unique possibilities for precision measurements in Penning
traps. Precision atomic and nuclear masses as well as magnetic moments of bound
electrons allow among others to determine fundamental constants like the mass
of the electron or to perform stringent tests of fundamental interactions like
bound-state quantum electrodynamics. Recent results and future perspectives in
high-precision Penning-trap spectroscopy with highly charged ions will be
discussed.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:04:33 GMT""}]","2022-03-16"
"2203.07850","Yu. A. Simonov","Yu. A. Simonov","The colormagnetic confinement in QCD","21 pages,2 figures",,"10.1134/S1063778823010532",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Colormagnetic confinement as a natural component of the QCD confinement is
explained and treated in the framework of the Field Correlator Method. For
quarks and gluons in hadrons the effects of the colormagnetic confinement are
discussed at zero temperature, where it contributes to the spectrum properties
and can create its own bound states, while at nonzero temperature in the EoS of
the quark gluon plasma the colormagnetic confinement plays a dominating role.
Its properties in the QCD thermodynamics are discussed in detail.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:05:08 GMT""},{""version"":""v2"",""created"":""Wed, 1 Jun 2022 13:08:43 GMT""},{""version"":""v3"",""created"":""Thu, 14 Jul 2022 09:06:31 GMT""}]","2023-03-29"
"2203.07851","Matias Bargheer","Steffen Peer Zeuschner, Xi-Guang Wang, Marwan Deb, Elena Popova,
  Gregory Malinowski, Michel Hehn, Niels Keller, Jamal Berakdar and Matias
  Bargheer","Standing spin wave excitation in Bi:YIG films via temperature induced
  anisotropy changes and magnetoacoustic coupling","11 pages, 4 figures",,,,"cond-mat.other","http://creativecommons.org/licenses/by/4.0/","  Based on micromagnetic simulations and experimental observations of the
magnetization and lattice dynamics following the direct optical excitation of
the magnetic insulator Bi:YIG or indirect excitation via an optically opaque
Pt/Cu double layer, we disentangle the dynamical effects of magnetic anisotropy
and magnetoelastic coupling. The strain and temperature of the lattice are
quantified via modeling ultrafast x-ray diffraction data. Measurements of the
time-resolved magneto-optical Kerr effect agree well with the magnetization
dynamics simulated according to the excitation via two mechanisms: The
magneto-acoustic coupling to the experimentally verified strain dynamics and
the ultrafast temperature-induced transient change in the magnetic anisotropy.
The numerical modeling proves that for direct excitation both mechanisms drive
the fundamental mode with opposite phase. The relative ratio of standing
spin-wave amplitudes of higher order modes indicates that both mechanisms are
substantially active.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:05:45 GMT""}]","2022-03-16"
"2203.07853","Lan Truong","Lan V. Truong, Giuseppe Cocco, Josep Font-Segura, Albert Guill\'en i
  F\`abregas","Concentration Properties of Random Codes","98 pages",,,,"cs.IT math.IT math.PR math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  This paper studies the concentration properties of random codes.
Specifically, we show that, for discrete memoryless channels, the error
exponent of a randomly generated code with pairwise-independent codewords
converges in probability to its expectation -- the typical error exponent. For
high rates, the result is a consequence of the fact that the random-coding
error exponent and the sphere-packing error exponent coincide. For low rates,
instead, the convergence is based on the fact that the union bound accurately
characterizes the probability of error. The paper also zooms into the behavior
at asymptotically low rates and shows that the error exponent converges in
distribution to a Gaussian-like distribution. Finally, we present several
results on the convergence of the error probability and error exponent for
generic ensembles and channels.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:06:09 GMT""}]","2022-03-16"
"2203.07855","Marius K\""oppel","Marius K\""oppel","Mu3e Integration Run 2021",,,,,"physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  The Mu3e experiment at the Paul Scherrer Institute searches for the charged
lepton flavor violating decay $\mu^+ \rightarrow e^+ e^+ e^-$. The experiment
aims for an ultimate sensitivity of one in $10^{16}$ $\mu$ decays. The first
phase of the experiment, currently under construction, will reach a branching
ratio sensitivity of $2.5\times10^{-15}$ by observing $10^{8}$ $\mu$ decays per
second over a year of data taking. The highly granular detector based on thin
high-voltage monolithic active pixel sensors (HV-MAPS) and scintillating timing
detectors will produce about 100 GB/s of data at these particle rates. The
Field Programmable Gate Array (FPGA) based Mu3e Data Acquisition System will
read out this data from the detector and reduce the event rate to 100 MB/s by
selecting interesting events using a filter farm of graphics processing units.
The paper presents the status of the data acquisition system (DAQ) and first
results from the 2021 integration run, which for the first time operated a
slice of the Mu3e detector at the $\pi$E5 muon beam line at the Paul Scherrer
Institute (PSI).
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:07:05 GMT""}]","2022-03-16"
"2203.07856","Ilias Chalkidis","Ilias Chalkidis and Anders S{\o}gaard","Improved Multi-label Classification under Temporal Concept Drift:
  Rethinking Group-Robust Algorithms in a Label-Wise Setting","9 pages, long paper at ACL 2022 Findings",,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  In document classification for, e.g., legal and biomedical text, we often
deal with hundreds of classes, including very infrequent ones, as well as
temporal concept drift caused by the influence of real world events, e.g.,
policy changes, conflicts, or pandemics. Class imbalance and drift can
sometimes be mitigated by resampling the training data to simulate (or
compensate for) a known target distribution, but what if the target
distribution is determined by unknown future events? Instead of simply
resampling uniformly to hedge our bets, we focus on the underlying optimization
algorithms used to train such document classifiers and evaluate several
group-robust optimization algorithms, initially proposed to mitigate
group-level disparities. Reframing group-robust algorithms as adaptation
algorithms under concept drift, we find that Invariant Risk Minimization and
Spectral Decoupling outperform sampling-based approaches to class imbalance and
concept drift, and lead to much better performance on minority classes. The
effect is more pronounced the larger the label set.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:08:03 GMT""}]","2022-03-16"
"2203.07857","Peng Zhao","Peng Zhao, Teng Ma, Yirong Jin, and Haifeng Yu","Combating fluctuations in relaxation times of fixed-frequency transmon
  qubits with microwave-dressed states","12 pages,9 figures",,"10.1103/PhysRevA.105.062605",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the long coherence time, the fixed-frequency transmon qubit is a
promising qubit modality for quantum computing. Currently, diverse qubit
architectures that utilize fixed-frequency transmon qubits have been
demonstrated with high-fidelity gate performance. Nevertheless, the relaxation
times of transmon qubits can have large temporal fluctuations, causing
instabilities in gate performance. The fluctuations are often believed to be
caused by nearly on-resonance couplings with sparse two-level-system (TLS)
defects. To mitigate their impact on qubit coherence and gate performance, one
direct approach is to tune the qubits away from these TLSs. In this work, to
combat the potential TLS-induced performance fluctuations in a tunable-bus
architecture unitizing fixed-frequency transmon qubits, we explore the
possibility of using an off-resonance microwave drive to effectively tuning the
qubit frequency through the ac-Stark shift while implementing universal gate
operations on the microwave-dressed qubit. We show that the qubit frequency can
be tuned up to 20 MHz through the ac-stark shift while keeping minimal impacts
on the qubit control. Besides passive approaches that aim to remove these TLSs
through more careful treatments of device fabrications, this work may offer an
active approach towards mitigating the TLS-induced performance fluctuations in
fixed-frequency transmon qubit devices.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:08:28 GMT""},{""version"":""v2"",""created"":""Wed, 8 Jun 2022 15:13:50 GMT""}]","2022-06-29"
"2203.07860","Lihu Chen","Lihu Chen and Ga\""el Varoquaux and Fabian M. Suchanek","Imputing Out-of-Vocabulary Embeddings with LOVE Makes Language Models
  Robust with Little Cost","Long paper accepted by ACL main conference. 17 pages",,,,"cs.CL","http://creativecommons.org/licenses/by-sa/4.0/","  State-of-the-art NLP systems represent inputs with word embeddings, but these
are brittle when faced with Out-of-Vocabulary (OOV) words. To address this
issue, we follow the principle of mimick-like models to generate vectors for
unseen words, by learning the behavior of pre-trained embeddings using only the
surface form of words. We present a simple contrastive learning framework,
LOVE, which extends the word representation of an existing pre-trained language
model (such as BERT), and makes it robust to OOV with few additional
parameters. Extensive evaluations demonstrate that our lightweight model
achieves similar or even better performances than prior competitors, both on
original datasets and on corrupted variants. Moreover, it can be used in a
plug-and-play fashion with FastText and BERT, where it significantly improves
their robustness.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:11:07 GMT""},{""version"":""v2"",""created"":""Mon, 21 Mar 2022 14:47:58 GMT""}]","2022-03-22"
"2203.07863","Richard Paris","R B Paris","An asymptotic approximation for the Riemann zeta function revisited","8 pages, 0 figures",,,,"math.CA","http://creativecommons.org/licenses/by/4.0/","  We revisit a representation for the Riemann zeta function $\zeta(s)$
expressed in terms of normalised incomplete gamma functions given by the author
and S. Cang in Methods Appl. Anal. {\bf 4} (1997) 449--470. Use of the uniform
asymptotics of the incomplete gamma function produces an asymptotic-like
expansion for $\zeta(s)$ on the critical line $s=1/2+it$ as $t\to+\infty$. The
main term involves the original Dirichlet series smoothed by a complementary
error function of appropriate argument together with a series of correction
terms. It is the aim here to present these correction terms in a more
user-friendly format by expressing then in inverse powers of $\omega$, where
$\omega^2=\pi s/(2i)$, multiplied by coefficients involving trigonometric
functions of argument $\omega$.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:12:03 GMT""},{""version"":""v2"",""created"":""Fri, 6 May 2022 14:10:57 GMT""}]","2022-05-09"
"2203.07864","An\v{z}e Slosar","Adrian Liu, Laura Newburgh, Benjamin Saliwanchik, An\v{z}e Slosar","Snowmass2021 Cosmic Frontier White Paper: 21cm Radiation as a Probe of
  Physics Across Cosmic Ages","Snowmass 2021 Solicited White Paper by the Cosmic Frontier 5 Topical
  Group",,,,"astro-ph.CO astro-ph.IM hep-ex hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The 21cm line refers to a forbidden transition in neutral hydrogen associated
with alignment of spins of the proton and electron. It is a very low energy
transition that is emitted whenever there is neutral hydrogen in the Universe.
Since baryons are mostly (~75%) hydrogen, one can in principle detect this
emission throughout much of the history of the Universe. The dominant emission
mechanism is different across cosmic ages. Before the photons decouple from
matter, hydrogen is in an ionized state and does not emit in 21cm. After
recombination and during the Dark Ages, at z ~ 30-1000, the 21cm emission is
associated with density fluctuations in the neutral hydrogen medium. After the
first stars turn on and galaxies begin to form, the 21cm emission traces
bubbles of ionized hydrogen in the sea of the neutral medium. This epoch,
spanning z ~ 6-30, is often referred to as cosmic dawn and the Epoch of
Reionization (EoR). At redshifts below z<6, the intergalactic medium is largely
ionized, but pockets of self-shielded neutral gas form in dense galactic
environments and 21cm emission traces the distribution of galaxies. The vastly
different emission mechanisms allow us to probe very different physics at
different redshifts, corresponding to different observational frequencies. The
instrumental challenges, namely building very sensitive and exquisitely
calibrated radio telescopes, however, share many commonalities across frequency
bands. The potential of the 21cm probe has been recognized by the Decadal
Survey of Astronomy & Astrophysics, whose Panel on Cosmology identified the
Dark Ages as its sole discovery area. We argue that HEP should recognize the
potential of 21cm as a probe of fundamental physics across many axes and invest
in the technology development that will enable full exploitation of this rich
technique.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:13:02 GMT""}]","2022-04-12"
"2203.07865","Guillaume Coqueret","Guillaume Coqueret","Characteristics-driven returns in equilibrium",,,,,"q-fin.GN q-fin.PM q-fin.PR q-fin.RM","http://creativecommons.org/licenses/by/4.0/","  We reverse-engineer the equilibrium construction process of asset prices in
order to obtain returns which depend on firm characteristics, possibly in a
linear fashion. One key requirement is that agents must have demands that rely
separately on firm characteristics and on the log-price of assets. Market
clearing via exogenous (non-factor driven) supply, combined with linear demands
in characteristics, yields the sought form. The coefficients in the resulting
linear expressions are scaled net aggregate demands for characteristics, as
well as their variations, and both can be jointly estimated via panel
regressions. Conditions underpinning asset pricing anomalies are derived and
underline the theoretical importance of the links between characteristics.
Empirically, when the number of characteristics is small, the value and
momentum anomalies are mostly driven by firm-specific fixed-effects, i.e.,
latent demands, which highlights the shortcomings of low-dimensional models.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:13:17 GMT""}]","2022-03-16"
"2203.07875","Hung Tran-The","Hung Tran-The and Sunil Gupta and Santu Rana and Svetha Venkatesh","Regret Bounds for Expected Improvement Algorithms in Gaussian Process
  Bandit Optimization","AISTATS 2022",,,,"cs.LG math.OC","http://creativecommons.org/licenses/by/4.0/","  The expected improvement (EI) algorithm is one of the most popular strategies
for optimization under uncertainty due to its simplicity and efficiency.
Despite its popularity, the theoretical aspects of this algorithm have not been
properly analyzed. In particular, whether in the noisy setting, the EI strategy
with a standard incumbent converges is still an open question of the Gaussian
process bandit optimization problem. We aim to answer this question by
proposing a variant of EI with a standard incumbent defined via the GP
predictive mean. We prove that our algorithm converges, and achieves a
cumulative regret bound of $\mathcal O(\gamma_T\sqrt{T})$, where $\gamma_T$ is
the maximum information gain between $T$ observations and the Gaussian process
model. Based on this variant of EI, we further propose an algorithm called
Improved GP-EI that converges faster than previous counterparts. In particular,
our proposed variants of EI do not require the knowledge of the RKHS norm and
the noise's sub-Gaussianity parameter as in previous works. Empirical
validation in our paper demonstrates the effectiveness of our algorithms
compared to several baselines.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:17:53 GMT""}]","2022-03-16"
"2203.07878","Davide Modesti","Davide Modesti and Sergio Pirozzoli","Direct numerical simulation of forced thermal convection in square ducts
  up to $Re_\tau \approx 2000$",,,"10.1017/jfm.2022.294",,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  We carry out direct numerical simulation (DNS) of flow in a turbulent square
duct by focusing on heat transfer effects, considering the case of unit Prandtl
number. Reynolds numbers up to $Re_\tau \approx 2000$ are considered which are
much higher than in previous studies, and which yield clear scale separation
between inner- and outer-layer dynamics. Close similarity between the behavior
of the temperature and the streamwise velocity fields is confirmed as in
previous studies related to plane channels and pipes. Just like the mean
velocity, the mean temperature is found to exhibit logarithmic layers as a
function of the nearest wall, however with a different slope. The most
important practical implication is the validity of the traditional hydraulic
diameter as the correct reference length for reporting heat transfer data, as
we rigorously show here. Temperature and velocity fluctuations also have
similar behavior, but apparently logarithmic growth of their inner-scaled peak
variances is not observed here unlike in canonical wall-bounded flows. Analysis
of the split contributions to the heat transfer coefficient shows that mean
cross-stream convection associated with secondary motions is responsible for
about $5\%$ of the total. Finally, we use the DNS database to highlight
shortcomings of traditional linear closures for the turbulent heat flux, and
show that substantial modeling improvement may be in principle obtained by
retaining at least the three terms in the vector polynomial integrity basis
expansion.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:20:44 GMT""}]","2022-05-11"
"2203.07880","Max Bramberger","Max Bramberger, Benjamin Bacq-Labreuil, Martin Grundner, Silke
  Biermann, Ulrich Schollw\""ock, Sebastian Paeckel, Benjamin Lenz","Formation of CuO$_2$ sublattices by suppression of interlattice
  correlations in tetragonal CuO","30 pages, 11 figures","SciPost Phys. 14, 010 (2023)","10.21468/SciPostPhys.14.1.010",,"cond-mat.str-el cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the tetragonal phase of the binary transition metal oxide CuO
(t-CuO) within the context of cellular dynamical mean-field theory. Due to its
strong antiferromagnetic correlations and simple structure, analysing the
physics of t-CuO is of high interest as it may pave the way towards a more
complete understanding of high temperature superconductivity in hole-doped
antiferromagnets. In this work we give a formal justification for the weak
coupling assumption that has previously been made for the interconnected
sublattices within a single layer of t-CuO by studying the non-local
self-energies of the system. We compute momentum-resolved spectral functions
using a Matrix Product State (MPS)-based impurity solver directly on the real
axis, which does not require any numerically ill-conditioned analytic
continuation. The agreement with photoemission spectroscopy indicates that a
single band Hubbard model is sufficient to capture the material's low energy
physics. We perform calculations on a range of different temperatures, finding
two magnetic regimes, for which we identify the driving mechanism behind their
respective insulating state. Finally, we show that in the hole-doped regime the
sublattice structure of t-CuO has interesting consequences on the symmetry of
the superconducting state.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:22:09 GMT""},{""version"":""v2"",""created"":""Tue, 31 Jan 2023 18:40:05 GMT""}]","2023-03-07"
"2203.07881","Emre Aksan","Emre Aksan, Shugao Ma, Akin Caliskan, Stanislav Pidhorskyi, Alexander
  Richard, Shih-En Wei, Jason Saragih, Otmar Hilliges","LiP-Flow: Learning Inference-time Priors for Codec Avatars via
  Normalizing Flows in Latent Space",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Neural face avatars that are trained from multi-view data captured in camera
domes can produce photo-realistic 3D reconstructions. However, at inference
time, they must be driven by limited inputs such as partial views recorded by
headset-mounted cameras or a front-facing camera, and sparse facial landmarks.
To mitigate this asymmetry, we introduce a prior model that is conditioned on
the runtime inputs and tie this prior space to the 3D face model via a
normalizing flow in the latent space. Our proposed model, LiP-Flow, consists of
two encoders that learn representations from the rich training-time and
impoverished inference-time observations. A normalizing flow bridges the two
representation spaces and transforms latent samples from one domain to another,
allowing us to define a latent likelihood objective. We trained our model
end-to-end to maximize the similarity of both representation spaces and the
reconstruction quality, making the 3D face model aware of the limited driving
signals. We conduct extensive evaluations where the latent codes are optimized
to reconstruct 3D avatars from partial or sparse observations. We show that our
approach leads to an expressive and effective prior, capturing facial dynamics
and subtle expressions better.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:22:57 GMT""}]","2022-03-16"
"2203.07882","Michele Ricciardi","Michele Ricciardi","The Convergence Problem in Mean Field Games with Neumann Boundary
  Conditions","27 pages, no figures",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article we study the convergence of the Nash Equilibria in a N-player
differential game towards the optimal strategies in the Mean Field Games, when
the dynamic of the generic player includes a reflection process which
guarantees the invariance of the state space. The well-posedness of the Master
Equation allows us to use its solution U in order to construct finite
dimensional projections, which will converge, in some suitable spaces, to the
solution of the Nash system.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:32:41 GMT""}]","2022-03-16"
"2203.07883","Wei Su","Ankit Beniwal, Filip Rajec, Markus Tobias Prim, Pat Scott, Wei Su,
  Martin White, Anthony G. Williams, and Alex Woodcock","Global fit of 2HDM with future collider results","9 pages, 3 plots, contribution to Snowmass 2021",,,"KIAS--P22014, gambit-proceedings-2022","hep-ph","http://creativecommons.org/licenses/by/4.0/","  In this work, we summarize a global fit study of Type-II two Higgs doublet
models (2HDM), and explore the impact of future SM-like Higgs and Z-pole
precision measurements on the allowed parameter space. The work is based on the
study results of a global fit of 2HDMs with the tool GAMBIT, utilising various
current constraints including theoretical constraints (unitarity,
perturbativity and vacuum stability), Higgs searches at colliders, electroweak
physics and flavour constraints. We further investigate the ability of future
facilities, such as the HL-LHC, CEPC, ILC and FCC-ee to explore the 2HDM
parameter space.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:32:44 GMT""}]","2022-06-01"
"2203.07884","Wei Wang","Wei Wang, Barak Hoffer, Tzofnat Greenberg-Toledo, Yang Li, Minhui Zou,
  Eric Herbelin, Ronny Ronen, Xiaoxin Xu, Yulin Zhao, Jianguo Yang, and Shahar
  Kvatinsky","Efficient Training of the Memristive Deep Belief Net Immune to
  Non-Idealities of the Synaptic Devices",,"Adv. Intell. Syst. 2100249 (2022)","10.1002/aisy.202100249",,"eess.SP cond-mat.dis-nn cs.SY eess.SY physics.app-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The tunability of conductance states of various emerging non-volatile
memristive devices emulates the plasticity of biological synapses, making it
promising in the hardware realization of large-scale neuromorphic systems. The
inference of the neural network can be greatly accelerated by the vector-matrix
multiplication (VMM) performed within a crossbar array of memristive devices in
one step. Nevertheless, the implementation of the VMM needs complex peripheral
circuits and the complexity further increases since non-idealities of
memristive devices prevent precise conductance tuning (especially for the
online training) and largely degrade the performance of the deep neural
networks (DNNs). Here, we present an efficient online training method of the
memristive deep belief net (DBN). The proposed memristive DBN uses
stochastically binarized activations, reducing the complexity of peripheral
circuits, and uses the contrastive divergence (CD) based gradient descent
learning algorithm. The analog VMM and digital CD are performed separately in a
mixed-signal hardware arrangement, making the memristive DBN high immune to
non-idealities of synaptic devices. The number of write operations on
memristive devices is reduced by two orders of magnitude. The recognition
accuracy of 95%~97% can be achieved for the MNIST dataset using pulsed synaptic
behaviors of various memristive synaptic devices.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:32:46 GMT""}]","2022-03-18"
"2203.07885","Amit Bashyal","Amit Bashyal, Peter Van Gemmeren, Saba Sehrish, Kyle Knoepfel, Suren
  Byna and Qiao Kang","Data Storage for HEP Experiments in the Era of High-Performance
  Computing","7 pages, 2 figures, contribution to Snowmass 2021",,,,"hep-ex physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  As particle physics experiments push their limits on both the energy and the
intensity frontiers, the amount and complexity of the produced data are also
expected to increase accordingly. With such large data volumes, next-generation
efforts like the HL-LHC and DUNE will rely even more on both high-throughput
(HTC) and high-performance (HPC) computing clusters. Full utilization of HPC
resources requires scalable and efficient data-handling and I/O. For the last
few decades, ROOT has been used by most HEP experiments to store data. However,
other storage technologies like HDF5 may perform better in HPC environments.
Initial explorations with HDF5 have begun using ATLAS, CMS and DUNE data; the
DUNE experiment has also adopted HDF5 for its data-acquisition system. This
paper presents the future outlook of the HEP computing and the role of HPC, and
a summary of ongoing and future works to use HDF5 as a possible data storage
technology for the HEP experiments to use in HPC environments.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:33:22 GMT""}]","2022-03-16"
"2203.07886","Corentin Ravoux","Corentin Ravoux","Lyman-alpha forest tomography and cross-correlation with cosmic voids","4 pages, 2 figures, contribution to the 2022 Cosmology session of the
  56th Rencontres de Moriond",,,,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Lyman-alpha forest is a unique probe of large-scale matter density
fluctuations at high redshift (z > 2). It is possible to obtain 3D maps of the
matter distribution from Lyman-alpha data, using tomographic reconstruction
methods. Here, we present the largest tomographic map of matter fluctuations at
z > 2, over the Gpc^3 volume covered by Lyman-alpha forest from SDSS-IV quasar
spectra in the Stripe 82 field. We present a catalog of high-redshift voids
constructed from this map. The measurement of the cross-correlation between
these voids and the Lyman-alpha forest provides the first observation of the
matter velocity flow around voids, through the RSD effect, at such high
redshift. The data is in good agreement with simulations and is well adjusted
with a linear, Kaiser velocity model.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:34:07 GMT""}]","2022-03-16"
"2203.07887","Hiroaki  Ito","Hiroaki Ito","Self-duality of multidimensional continued fractions","20pages",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  F.~Schweiger introduced the fibred system in \cite{Schweiger-MCF}, to unify
and generalize many known continued fraction algorithms. An advantage of a
fibred system is that it often provides a systematic construction of absolutely
continuous invariant density. In this paper, we define and study the
self-duality of fibred systems, a strong symmetry of a given system. We show
that explicit algebraic self-duality holds in many systems and presents a
curious system with ""partial"" self-duality.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:34:31 GMT""},{""version"":""v2"",""created"":""Wed, 27 Jul 2022 02:36:14 GMT""}]","2022-07-28"
"2203.07888","Thomas Kroc","Thomas Kroc, Vyacheslav Yakovlev, Charles Thangaraj, Brian Chase, Ram
  Dhuley","The Need for Further Development of Magnetrons as RF Sources for HEP","contribution to Snowmass 2021",,,"FERMILAB-CONF-22-142-AD-DI-TD","physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  Proposal to develop magnetrons as RF sources for HEP
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:36:58 GMT""}]","2022-03-16"
"2203.07889","Etor Arza Gonzalez","Etor Arza, Josu Ceberio, Ekhi\~ne Irurozki, Aritz P\'erez","Comparing Two Samples Through Stochastic Dominance: A Graphical Approach",,"Etor Arza, Josu Ceberio, Ekhi\~ne Irurozki & Aritz P\'erez (2022)
  Comparing Two Samples Through Stochastic Dominance: A Graphical Approach,
  Journal of Computational and Graphical Statistics","10.1080/10618600.2022.2084405",,"stat.ML cs.LG stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Non-deterministic measurements are common in real-world scenarios: the
performance of a stochastic optimization algorithm or the total reward of a
reinforcement learning agent in a chaotic environment are just two examples in
which unpredictable outcomes are common. These measures can be modeled as
random variables and compared among each other via their expected values or
more sophisticated tools such as null hypothesis statistical tests. In this
paper, we propose an alternative framework to visually compare two samples
according to their estimated cumulative distribution functions. First, we
introduce a dominance measure for two random variables that quantifies the
proportion in which the cumulative distribution function of one of the random
variables stochastically dominates the other one. Then, we present a graphical
method that decomposes in quantiles i) the proposed dominance measure and ii)
the probability that one of the random variables takes lower values than the
other. With illustrative purposes, we re-evaluate the experimentation of an
already published work with the proposed methodology and we show that
additional conclusions (missed by the rest of the methods) can be inferred.
Additionally, the software package RVCompare was created as a convenient way of
applying and experimenting with the proposed framework.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:37:03 GMT""},{""version"":""v2"",""created"":""Thu, 26 May 2022 21:50:46 GMT""},{""version"":""v3"",""created"":""Mon, 29 Aug 2022 10:24:07 GMT""},{""version"":""v4"",""created"":""Tue, 30 Aug 2022 15:25:54 GMT""}]","2022-08-31"
"2203.07890","Kohei Uehara","Kohei Uehara, Tatsuya Harada","K-VQG: Knowledge-aware Visual Question Generation for Common-sense
  Acquisition",,,,,"cs.CV cs.CL","http://creativecommons.org/licenses/by/4.0/","  Visual Question Generation (VQG) is a task to generate questions from images.
When humans ask questions about an image, their goal is often to acquire some
new knowledge. However, existing studies on VQG have mainly addressed question
generation from answers or question categories, overlooking the objectives of
knowledge acquisition. To introduce a knowledge acquisition perspective into
VQG, we constructed a novel knowledge-aware VQG dataset called K-VQG. This is
the first large, humanly annotated dataset in which questions regarding images
are tied to structured knowledge. We also developed a new VQG model that can
encode and use knowledge as the target for a question. The experiment results
show that our model outperforms existing models on the K-VQG dataset.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:38:10 GMT""}]","2022-03-16"
"2203.07891","Gennaro Infante","Gennaro Infante","On the solvability of a parameter-dependent cantilever-type BVP","9 pages, 1 figure",,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss the solvability of a parameter dependent cantilever-type boundary
value problem. We provide an existence and localization result for the positive
solutions via a Birkhoff-Kellogg type theorem. We also obtain, under additional
growth conditions, upper and lower bounds for the involved parameters. An
example is presented in order to illustrate the theoretical results.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:39:00 GMT""}]","2022-03-16"
"2203.07892","Yixuan Zhang","Yixuan Zhang, Ruiwen Xie, Teng Long, Damian G\""unzing, Heiko Wende,
  Katharina J. Ollefs, Hongbin Zhang","Autonomous atomic Hamiltonian construction and active sampling of x-ray
  absorption spectroscopy by adversarial Bayesian optimization","25 pages, 6 figures, 2 table",,,,"cond-mat.mtrl-sci physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  X-ray absorption spectroscopy (XAS) is a well-established method for in-depth
characterization of the electronic structure due to its sensitivity to the
local coordination and electronic states of the active ions. In practice
hundreds of energy points should be sampled during the XAS measurement, most of
which are redundant and do not contain important information. In addition, it
is also a tedious procedure to estimate reasonable parameters in the atomic
Hamiltonian for mechanistic understanding. We implemented an Adversarial
Bayesian optimization (ABO) algorithm comprising two coupled BOs to
automatically fit the multiplet model Hamiltonian and meanwhile to sample
effectively based on active learning. Taking NiO as an example, for simulated
spectra which can be well fitted by the atomic model, we found that less than
30 sampling points are enough to obtain the complete XAS with the corresponding
crystal field or charge transfer model, which can be selected based on
intuitive hypothesis learning. Further application on the experimental spectra,
it revealed that less than 80 sampling points can already give reasonable XAS
and reliable atomic model parameters. Our ABO algorithm has a great potential
for future application in automated physics-driven XAS analysis and active
learning sampling.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:39:05 GMT""},{""version"":""v2"",""created"":""Wed, 1 Feb 2023 14:23:05 GMT""}]","2023-02-02"
"2203.07893","Shun Shao","Shun Shao, Yftah Ziser, Shay B. Cohen","Gold Doesn't Always Glitter: Spectral Removal of Linear and Nonlinear
  Guarded Attribute Information","Accepted to the Conference of the European Chapter of the Association
  for Computational Linguistics (EACL), 2023; 12 pages (minor formatting
  corrections)",,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe a simple and effective method (Spectral Attribute removaL; SAL)
to remove private or guarded information from neural representations. Our
method uses matrix decomposition to project the input representations into
directions with reduced covariance with the guarded information rather than
maximal covariance as factorization methods normally use. We begin with linear
information removal and proceed to generalize our algorithm to the case of
nonlinear information removal using kernels. Our experiments demonstrate that
our algorithm retains better main task performance after removing the guarded
information compared to previous work. In addition, our experiments demonstrate
that we need a relatively small amount of guarded attribute data to remove
information about these attributes, which lowers the exposure to sensitive data
and is more suitable for low-resource scenarios. Code is available at
https://github.com/jasonshaoshun/SAL.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:40:22 GMT""},{""version"":""v2"",""created"":""Wed, 15 Feb 2023 16:00:14 GMT""},{""version"":""v3"",""created"":""Tue, 28 Feb 2023 10:50:17 GMT""},{""version"":""v4"",""created"":""Thu, 20 Apr 2023 13:04:15 GMT""}]","2023-04-21"
"2203.07896","Hans-Bert Rademacher","Hans-Bert Rademacher","Two short closed geodesics on a sphere of odd dimension","16 pages, revised version, to appear in ""Calc.Var.Partial Diff. Equ.""",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that for an open and dense set non-reversible Finsler metrics on a
sphere of odd dimension $n=2m-1 \ge 3$ there is a second closed geodesic with
Morse index $\le 4(m+2)(m-1)+2.$
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:43:22 GMT""},{""version"":""v2"",""created"":""Wed, 18 Jan 2023 13:19:32 GMT""}]","2023-01-19"
"2203.07898","Andr\'e Nusser","Karl Bringmann, S\'andor Kisfaludi-Bak, Marvin K\""unnemann, D\'aniel
  Marx, Andr\'e Nusser","Dynamic Time Warping Under Translation: Approximation Guided by
  Space-Filling Curves","Full version of SoCG '22 paper",,,,"cs.CG cs.DS","http://creativecommons.org/licenses/by/4.0/","  The Dynamic Time Warping (DTW) distance is a popular measure of similarity
for a variety of sequence data. For comparing polygonal curves $\pi, \sigma$ in
$\mathbb{R}^d$, it provides a robust, outlier-insensitive alternative to the
Fr\'echet distance. However, like the Fr\'echet distance, the DTW distance is
not invariant under translations. Can we efficiently optimize the DTW distance
of $\pi$ and $\sigma$ under arbitrary translations, to compare the curves'
shape irrespective of their absolute location?
  There are surprisingly few works in this direction, which may be due to its
computational intricacy: For the Euclidean norm, this problem contains as a
special case the geometric median problem, which provably admits no exact
algebraic algorithm (that is, no algorithm using only addition, multiplication,
and $k$-th roots). We thus investigate exact algorithms for non-Euclidean norms
as well as approximation algorithms for the Euclidean norm:
  - For the $L_1$ norm in $\mathbb{R}^d$, we provide an
$\mathcal{O}(n^{2(d+1)})$-time algorithm, i.e., an exact polynomial-time
algorithm for constant $d$. Here and below, $n$ bounds the curves'
complexities.
  - For the Euclidean norm in $\mathbb{R}^2$, we show that a simple
problem-specific insight leads to a $(1+\varepsilon)$-approximation in time
$\mathcal{O}(n^3/\varepsilon^2)$. We then show how to obtain a subcubic
$\widetilde{\mathcal{O}}(n^{2.5}/\varepsilon^2)$ time algorithm with
significant new ideas; this time comes close to the well-known quadratic time
barrier for computing DTW for fixed translations. Technically, the algorithm is
obtained by speeding up repeated DTW distance estimations using a dynamic data
structure for maintaining shortest paths in weighted planar digraphs.
Crucially, we show how to traverse a candidate set of translations using
space-filling curves in a way that incurs only few updates to the data
structure.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:43:33 GMT""},{""version"":""v2"",""created"":""Wed, 16 Mar 2022 14:22:20 GMT""}]","2022-03-17"
"2203.07899","Constantin Traub","Constantin Traub, Stefanos Fasoulas, Georg H. Herdrich","A planning tool for optimal three-dimensional formation flight maneuvers
  of satellites in VLEO using aerodynamic lift and drag via yaw angle
  deviations",,,"10.1016/j.actaastro.2022.04.010",,"physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Differential drag is a promising option to control the relative motion of
distributed satellites in the Very Low Earth Orbit regime which are not
equipped with dedicated thrusting devices. A major downside of the methodology,
however, is that its control authority is (mainly) limited to the in-plane
relative motion control. By additionally applying differential lift, however,
all three translational degrees-of-freedom become controllable. In this
article, we present a tool to flexibly plan optimal three-dimensional formation
flight maneuvers via differential lift and drag. In the planning process, the
most significant perturbing effects in this orbital regime, namely the J2
effect and atmospheric forces, are taken into account. Moreover, varying
atmospheric densities as well as the co-rotation of the atmosphere are
considered. Besides its flexible and high-fidelity nature, the major assets of
the proposed methodology are that the in-and out-of-plane relative motion are
controlled simultaneously via deviations in the yaw angles of the respective
satellites and that the planned trajectory is optimal in a sense that the
overall decay during the maneuver is minimized. Thereby, the remaining lifetime
of the satellites is maximized and the practicability and sustainability of the
methodology significantly increased. To the best of the authors knowledge, a
tool with the given capabilities has not yet been presented in literature. The
resulting trajectories for three fundamentally different relevant formation
flight maneuvers are presented and discussed in detail in order to indicate the
vast range of applicability of the tool.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:43:36 GMT""}]","2022-07-13"
"2203.07900","Isabela Santiago De Matos","Isabela S. Matos","Constraining modified gravity with gravitational wave distance
  measurements","4 pages, 1 figure, contribution to the 2022 Cosmology session of the
  56th Rencontres de Moriond",,,,"astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has been shown in the literature that detections of gravitational waves
(GWs) emitted by binary sources can provide measurements of luminosity
distance. The events followed by electromagnetic counterparts are, then,
suitable for probing the distance-redshift relation and doing cosmological
parameter estimation, as well as investigating modified gravity (MG) models. In
the context of effective approaches to MG equivalent to Horndeski, this GW
distance differs from the standard electromagnetic luminosity distance due to
the presence of a modified friction in the wave propagation. Here, we
investigate how precisely the future-planned interferometer Einstein Telescope
will probe such deviations from General Relativity, considering
phenomenological parametrizations for both the dark energy equation of state
and the GW friction. Despite being an independent test of gravity, for $f(R)$
in particular, we conclude that it may provide weaker constraints than the
current available ones.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:44:08 GMT""}]","2022-03-16"
"2203.07901","Junhui Liao","Junhui Liao, Yuanning Gao, Zhuo Liang, Zebang Ouyang, Zhaohua Peng,
  Lifeng Zhang, Lei Zhang, Jian Zheng, Jiangfeng Zhou","Introduction to a low-mass dark matter project, ALETHEIA: A Liquid
  hElium Time projection cHambEr In dArk matter","arXiv admin note: substantial text overlap with arXiv:2103.02161.
  substantial text overlap with arXiv:2209.02320",,,,"astro-ph.IM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Dark Matter (DM) is one of the most critical questions to be understood and
answered in fundamental physics today. Plenty of astronomical and cosmological
observations have already pinned down that DM exists in the Universe, the Milky
Way, and the Solar System. However, understanding DM with the language of
elementary physics is still in progress. DM direct detection tests the
interactive cross-section between galactic DM particles and an underground
detector's nucleons. WIMPs is the most discussed DM candidate. After decades of
hunting, a convincing WIMPs signal is still at large. Relatively, the low-mass
WIMPs region ($\sim$ 10 MeV/c$^2$ - 10 GeV/c$^2$) has not been fully exploited
compared to high-mass WIMPs ($\sim$ 10 GeV/c$^2$ - 10 TeV/c$^2$). By filling
the arguably cleanest bulk material, LHe, into the arguably most competitive
detector in the field, TPCs, ALETHEIA is supposed to achieve an extremely
low-level background; therefore, to help answer one of the most pressing
physical questions today: the nature of DM. In this paper, we briefly go
through the physics motivation of low-mass DM, the ALETHEIA detector's design,
possible analysis channels available for DM searches, and the progress we have
made since the project launched in the summer of 2020.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:44:48 GMT""},{""version"":""v2"",""created"":""Mon, 12 Sep 2022 09:42:24 GMT""}]","2022-09-13"
"2203.07902","Antoine Brochard","Antoine Brochard, Sixin Zhang, St\'ephane Mallat","Generalized Rectifier Wavelet Covariance Models For Texture Synthesis","To be published as a conference paper at the International Conference
  on Learning Representations (ICLR) 2022",,,,"cs.CV cs.LG eess.IV eess.SP stat.ML","http://creativecommons.org/licenses/by-sa/4.0/","  State-of-the-art maximum entropy models for texture synthesis are built from
statistics relying on image representations defined by convolutional neural
networks (CNN). Such representations capture rich structures in texture images,
outperforming wavelet-based representations in this regard. However, conversely
to neural networks, wavelets offer meaningful representations, as they are
known to detect structures at multiple scales (e.g. edges) in images. In this
work, we propose a family of statistics built upon non-linear wavelet based
representations, that can be viewed as a particular instance of a one-layer
CNN, using a generalized rectifier non-linearity. These statistics
significantly improve the visual quality of previous classical wavelet-based
models, and allow one to produce syntheses of similar quality to
state-of-the-art models, on both gray-scale and color textures.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:07:40 GMT""}]","2022-03-16"
"2203.07906","Jintao Zhang Dr","Zheng Wang, Jintao Zhang, Xiaojuan Feng, Li Xing","Microwave heating effect on diamond sample of NV centers",,,,,"cond-mat.mes-hall physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Diamond samples of defects with negative charged nitrogen-vacancy (NV)
centers are promising solid state spin sensors suitable for quantum information
processing, high sensitive measurements of magnetic, electric and thermal
fields in nanoscale. The diamond defect with a NV center is unique for its
robust temperature-dependent zero field splitting Dgs of the triplet ground
state. This property enables optical readout of electron spin states through
manipulation of the ground triplet state using microwave resonance with Dgs
from 100 K to about 600 K. Thus, prohibiting Dgs from unwanted external thermal
disturbances is crucial for an accurate measurement using diamond NV sensors.
Our observation demonstrates the existence of a prominent microwave heating
effect on the diamond samples of NV centers. The effect is inevitable to shift
Dgs and cause measurement errors. The temperature increment caused by the
effect monotonically depends on the power and the duration of microwave
irradiation. The effect is obvious with the microwave irradiation in the
continuous mode and some pulse sequence modes, but is neglectable for the
quantum lock-in XY8-N method.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:47:03 GMT""}]","2022-03-16"
"2203.07907","Robert Szafron","Melissa van Beekveld, Sebastian Jaskiewicz, Tao Liu, Xiaohui Liu, Duff
  Neill, Alexander Penin, Felix Ringer, Robert Szafron, Leonardo Vernazza,
  Gherardo Vita, Jian Wang","Snowmass 2021 White Paper: Resummation for future colliders","Contribution to Snowmass 2021",,,"IPPP/22/11, SLAC-PUB-17664, YITP-SB-2022-06","hep-ph","http://creativecommons.org/licenses/by/4.0/","  Resummation techniques are essential for high-precision phenomenology at
current and future high-energy collider experiments. Perturbative computations
of cross sections often suffer from large logarithmic corrections, which must
be resummed to all orders to restore the reliability of predictions from first
principles. The precise understanding of the all-order structure of field
theories allows for fundamental tests of the Standard Model and new physics
searches. In this white paper, we review recent progress in modern resummation
techniques and outline future directions. In particular, we focus on the
resummation beyond leading power, the joint resummation of different classes of
logarithms relevant for jets and their substructure, small-$x$ resummation in
the high-energy regime and the QCD fragmentation process in the small-$z_h$
limit.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:47:37 GMT""},{""version"":""v2"",""created"":""Mon, 9 May 2022 15:30:31 GMT""}]","2022-05-10"
"2203.07908","Josip \v{S}ari\'c","Josip \v{S}ari\'c, Marin Or\v{s}i\'c, Sini\v{s}a \v{S}egvi\'c","Panoptic SwiftNet: Pyramidal Fusion for Real-time Panoptic Segmentation","Code available at: https://github.com/jsaric/panoptic-swiftnet","Remote Sensing. 2023, 15(8), 1968;","10.3390/rs15081968",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dense panoptic prediction is a key ingredient in many existing applications
such as autonomous driving, automated warehouses or remote sensing. Many of
these applications require fast inference over large input resolutions on
affordable or even embedded hardware. We propose to achieve this goal by
trading off backbone capacity for multi-scale feature extraction. In comparison
with contemporaneous approaches to panoptic segmentation, the main novelties of
our method are efficient scale-equivariant feature extraction, cross-scale
upsampling through pyramidal fusion and boundary-aware learning of
pixel-to-instance assignment. The proposed method is very well suited for
remote sensing imagery due to the huge number of pixels in typical city-wide
and region-wide datasets. We present panoptic experiments on Cityscapes,
Vistas, COCO and the BSB-Aerial dataset. Our models outperform the state of the
art on the BSB-Aerial dataset while being able to process more than a hundred
1MPx images per second on a RTX3090 GPU with FP16 precision and TensorRT
optimization.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:47:40 GMT""},{""version"":""v2"",""created"":""Tue, 18 Apr 2023 14:46:07 GMT""}]","2023-04-19"
"2203.07909","Farhang Hadad-Farshi","Farhang Hadad Farshi and Silvia DeBianchi","An Epistemic Analysis of Time Phenomenon",,,"10.1007/s10701-022-00583-9",,"physics.hist-ph","http://creativecommons.org/publicdomain/zero/1.0/","  In this work we present an epistemic analysis of time phenomenon using the
mathematical machinery of information theory and modular theory. By adopting
limited commitment to the ontology of time evolution, and instead by mainly
relying on the information that is in principle accessible to the observer, we
find that the most primary aspect of the temporal experience, the perceived
distinctiveness across the states of the world, emerges as a purely epistemic
function. By analyzing the mathematical properties of this epistemic function,
we interpret it to be in principle insensitive to any ontic state of the world,
which leads to the conclusion that the observer is subject to temporal
experience irrespective of whether the underlying state of the world is
dynamical or invariant. On the ground of the presented analysis, we also
provide a solution to the conceptual challenge of non-equilibrium phenomena
that faces the thermal time hypothesis.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:47:41 GMT""}]","2022-06-09"
"2203.07911","Bhargav Srinivasa Desikan","Mark Chu, Bhargav Srinivasa Desikan, Ethan O. Nadler, D. Ruggiero Lo
  Sardo, Elise Darragh-Ford, and Douglas Guilbeault","Signal in Noise: Exploring Meaning Encoded in Random Character Sequences
  with Character-Aware Language Models",,,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Natural language processing models learn word representations based on the
distributional hypothesis, which asserts that word context (e.g.,
co-occurrence) correlates with meaning. We propose that $n$-grams composed of
random character sequences, or $garble$, provide a novel context for studying
word meaning both within and beyond extant language. In particular, randomly
generated character $n$-grams lack meaning but contain primitive information
based on the distribution of characters they contain. By studying the
embeddings of a large corpus of garble, extant language, and pseudowords using
CharacterBERT, we identify an axis in the model's high-dimensional embedding
space that separates these classes of $n$-grams. Furthermore, we show that this
axis relates to structure within extant language, including word
part-of-speech, morphology, and concept concreteness. Thus, in contrast to
studies that are mainly limited to extant language, our work reveals that
meaning and primitive information are intrinsically linked.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:48:38 GMT""},{""version"":""v2"",""created"":""Wed, 20 Apr 2022 16:06:48 GMT""}]","2022-04-21"
"2203.07912","Sijia Li","Sijia Li, Mart\'in L\'opez-Garc\'ia, Neil D. Lawrence, Luisa Cutillo","Scalable Bigraphical Lasso: Two-way Sparse Network Inference for Count
  Data",,,,,"stat.ML cs.LG stat.AP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Classically, statistical datasets have a larger number of data points than
features ($n > p$). The standard model of classical statistics caters for the
case where data points are considered conditionally independent given the
parameters. However, for $n\approx p$ or $p > n$ such models are poorly
determined. Kalaitzis et al. (2013) introduced the Bigraphical Lasso, an
estimator for sparse precision matrices based on the Cartesian product of
graphs. Unfortunately, the original Bigraphical Lasso algorithm is not
applicable in case of large p and n due to memory requirements. We exploit
eigenvalue decomposition of the Cartesian product graph to present a more
efficient version of the algorithm which reduces memory requirements from
$O(n^2p^2)$ to $O(n^2 + p^2)$. Many datasets in different application fields,
such as biology, medicine and social science, come with count data, for which
Gaussian based models are not applicable. Our multi-way network inference
approach can be used for discrete data. Our methodology accounts for the
dependencies across both instances and features, reduces the computational
complexity for high dimensional data and enables to deal with both discrete and
continuous data. Numerical studies on both synthetic and real datasets are
presented to showcase the performance of our method.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:50:49 GMT""}]","2022-03-16"
"2203.07913","Tania Robens","Jan Kalinowski, Tania Robens, Aleksander Filip Zarnecki","New Physics with missing energy at future lepton colliders -- Snowmass
  White Paper","15 pages, 9 figures; contribution to Snowmass 2021",,,"RBI-ThPhys-2022-9, CERN-TH-2022-041","hep-ph","http://creativecommons.org/licenses/by/4.0/","  Two models that extend the particle content of the SM and provide dark matter
candidates, namely the Inert Doublet Model and the Two-Higgs Doublet model with
additional pseudoscalar, are confronted with current experimental and
theoretical constraints and predictions for production cross sections for
various standard pair-production modes within these models at future lepton
colliders are presented.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:53:37 GMT""}]","2022-03-24"
"2203.07914","Xian-Hui Ge","Qing-Bing Wang, Ming-Hui Yu and Xian-Hui Ge","Scrambling time for analogue black holes embedded in AdS space","1+18 pages, 3 figures, published version","Eur. Phys. J. C 82 (2022) 468","10.1140/epjc/s10052-022-10438-2",,"hep-th gr-qc","http://creativecommons.org/licenses/by/4.0/","  We propose a gedanken experiment on realizing thermofield double state (TFD)
by using analog black holes and provide an approach to test the scrambling
time. Through this approach, we demonstrate clearly how shock wave changes the
TFD state as time evolves. As the whole system evolves forward in time, the
perturbation of space-time geometry will increase exponentially. Finally, it
will destroy the entanglement between the two states of the thermal field, and
the mutual information between them is reduced to zero in the time scale of
scrambling. The results show that for perturbations of analogue black holes
embedded in AdS space, the scale of the scrambling time is closely related to
the logarithm of entropy of the black hole. The results provide further
theoretical argument for the scrambling time, which can be further falsified in
experiments.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:54:27 GMT""},{""version"":""v2"",""created"":""Sat, 30 Apr 2022 16:00:03 GMT""},{""version"":""v3"",""created"":""Tue, 24 May 2022 13:46:44 GMT""}]","2022-05-25"
"2203.07915","Mohamed Abdelhamid","Mohamed Abdelhamid and Aleksander Czekanski","Topology Optimization of Fluid-Structure Interaction Problems with Total
  Stress Equilibrium",,,,,"math.NA cs.NA physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  This work extends force coupling in the topology optimization of
fluid-structure interaction problems from hydrostatic to total stresses through
the inclusion of viscous stress components. The superconvergent patch recovery
technique is implemented to remove the discontinuities in velocity derivatives
over the finite elements boundaries. The sensitivity analysis is derived
analytically for the superconvergent patch recovery approach and further
verified through the use of the complex-step derivative approximation method.
Numerical examples demonstrate a differentiation in the optimized designs using
pressure vs. total stress coupling depending on the flow characteristics of the
design problem.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:54:44 GMT""},{""version"":""v2"",""created"":""Wed, 9 Nov 2022 15:30:18 GMT""},{""version"":""v3"",""created"":""Tue, 9 May 2023 15:30:45 GMT""}]","2023-05-10"
"2203.07916","Florian Besau","Florian Besau, Anna Gusakova, Matthias Reitzner, Carsten Sch\""utt,
  Christoph Th\""ale, Elisabeth Werner","Spherical convex hull of random points on a wedge","21 pages, 5 figures",,,,"math.PR math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consider two half-spaces $H_1^+$ and $H_2^+$ in $\mathbb{R}^{d+1}$ whose
bounding hyperplanes $H_1$ and $H_2$ are orthogonal and pass through the
origin. The intersection $\mathbb{S}_{2,+}^d:=\mathbb{S}^d\cap H_1^+\cap H_2^+$
is a spherical convex subset of the $d$-dimensional unit sphere $\mathbb{S}^d$,
which contains a great subsphere of dimension $d-2$ and is called a spherical
wedge. Choose $n$ independent random points uniformly at random on
$\mathbb{S}_{2,+}^d$ and consider the expected facet number of the spherical
convex hull of these points. It is shown that, up to terms of lower order, this
expectation grows like a constant multiple of $\log n$. A similar behaviour is
obtained for the expected facet number of a homogeneous Poisson point process
on $\mathbb{S}_{2,+}^d$. The result is compared to the corresponding behaviour
of classical Euclidean random polytopes and of spherical random polytopes on a
half-sphere.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:55:24 GMT""}]","2022-03-16"
"2203.07917","Valeria Bertini","Valeria Bertini, Franco Giovenzana","Hodge structure of O'Grady's singular moduli spaces","34 pages, comments welcome",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the Hodge structure of the singular O'Grady's six and ten
dimensional examples of irreducible symplectic varieties. In particular, we
compute some of their Betti numbers and their Euler characteristic. As
consequence, we deduce that these varieties do not have finite quotient
singularities answering a question of Bakker and Lehn.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:57:34 GMT""},{""version"":""v2"",""created"":""Fri, 25 Mar 2022 15:49:38 GMT""}]","2022-03-28"
"2203.07918","Ruida Zhang","Yan Di, Ruida Zhang, Zhiqiang Lou, Fabian Manhardt, Xiangyang Ji,
  Nassir Navab and Federico Tombari","GPV-Pose: Category-level Object Pose Estimation via Geometry-guided
  Point-wise Voting","CVPR 2022",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  While 6D object pose estimation has recently made a huge leap forward, most
methods can still only handle a single or a handful of different objects, which
limits their applications. To circumvent this problem, category-level object
pose estimation has recently been revamped, which aims at predicting the 6D
pose as well as the 3D metric size for previously unseen instances from a given
set of object classes. This is, however, a much more challenging task due to
severe intra-class shape variations. To address this issue, we propose
GPV-Pose, a novel framework for robust category-level pose estimation,
harnessing geometric insights to enhance the learning of category-level
pose-sensitive features. First, we introduce a decoupled confidence-driven
rotation representation, which allows geometry-aware recovery of the associated
rotation matrix. Second, we propose a novel geometry-guided point-wise voting
paradigm for robust retrieval of the 3D object bounding box. Finally,
leveraging these different output streams, we can enforce several geometric
consistency terms, further increasing performance, especially for non-symmetric
categories. GPV-Pose produces superior results to state-of-the-art competitors
on common public benchmarks, whilst almost achieving real-time inference speed
at 20 FPS.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:58:50 GMT""},{""version"":""v2"",""created"":""Thu, 17 Mar 2022 14:12:21 GMT""}]","2022-03-18"
"2203.07919","Daniel Winklehner","Daniel Winklehner, Andreas Adelmann, Jose R. Alonso, Luciano
  Calabretta, Hiroki Okuno, Thomas Planche, Malek Haj Tahar","Report of the Snowmass'21 Workshop on High-Power Cyclotrons and FFAs","contribution to Snowmass 2021",,,,"physics.acc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This whitepaper summarizes and the state of the field of high-power
cyclotrons and FFAs as discussed by international experts during a three-day
workshop of the same name. The workshop was held online from Sep 7 to Sep 9,
2021 as part of the US Snowmass'21 Community Exercise, specifically the
Accelerator Frontier (AF) and the subpanel Accelerators for Neutrinos (AF02).
Thus, we put emphasis on the application of high-power cyclotrons in particle
physics, specifically neutrino physics, and as drivers for muon production. In
the introduction, we discuss the role of cyclotrons for particle physics, and
later we highlight existing and planned experiments in the corresponding
sections. However, as these same accelerators have important applications in
the fields of isotope production - both for research and medicine - and
possibly even in energy research, by providing beam to demonstrator experiments
in the areas of Accelerator Driven Systems (ADS), we include these far-reaching
topics to provide a full picture of the status and applications of high-power
cyclotrons. Furthermore, Fixed Field Alternating Gradient accelerators (FFAs)
have recently seen renewed interest. They are in many respects (basic operating
principles) similar to cyclotrons and have thus been included in this workshop
and whitepaper as well. We are discussing current projects and whether FFAs
have the prospect of becoming high-intensity machines.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 13:59:14 GMT""}]","2022-03-16"
"2203.07920","Jingxiong Gao","Zichen Xu, Yunxiao Du, Kanqi Zhang, Jiacheng Huang, Jie Liu, Jingxiong
  Gao, Christopher Stewart","Cost-effective BlackWater Raft on Highly Unreliable Nodes at Scale Out","18 pages, 26 figures, We are already revising the Camera Ready
  version of IEEE Transaction on Cloud Computing",,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Raft algorithm maintains strong consistency across data replicas in
Cloud. This algorithm divides nodes into leaders and followers, to satisfy
read/write requests spanning geo-diverse sites. With the increase of workload,
Raft shall provide scale-out performance in proportion. However, traditional
scale-out techniques encounter bottlenecks in Raft, and when the provisioned
sites exhaust local resources, the performance loss will grow exponentially. To
provide scalability in Raft, this paper proposes a cost-effective mechanism for
elastic auto-scaling in Raft, called BlackWater-Raft or BW-Raft. BW-Raft
extends the original Raft with the following abstractions: (1) secretary nodes
that take over expensive log synchronization operations from the leader,
relaxing the performance constraints on locks. (2) massive low cost observer
nodes that handle reads only, improving throughput for typical data intensive
services. These abstractions are stateless, allowing elastic scale-out on
unreliable yet cheap spot instances. In theory, we demonstrate that BW-Raft can
maintain Raft's strong consistency guarantees when scaling out, processing a
50X increase in the number of nodes compared to the original Raft. We have
prototyped the BW-Raft on key-value services and evaluated it with many
state-of-the-arts on Amazon EC2 and Alibaba Cloud. Our results show that within
the same budget, BW-Raft's resource footprint increments are 5-7X smaller than
Multi-Raft, and 2X better than original Raft. Using spot instances, BW-Raft can
reduces costs by 84.5\% compared to Multi-Raft. In the real world experiments,
BW-Raft improves goodput of the 95th-percentile SLO by 9.4X, thus serving as an
alternative for services scaling out with strong consistency.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:00:17 GMT""}]","2022-03-16"
"2203.07921","Somnath Basu Roy Chowdhury","Somnath Basu Roy Chowdhury, Chao Zhao, Snigdha Chaturvedi","Unsupervised Extractive Opinion Summarization Using Sparse Coding","Accepted at ACL 2022",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Opinion summarization is the task of automatically generating summaries that
encapsulate information from multiple user reviews. We present Semantic
Autoencoder (SemAE) to perform extractive opinion summarization in an
unsupervised manner. SemAE uses dictionary learning to implicitly capture
semantic information from the review and learns a latent representation of each
sentence over semantic units. A semantic unit is supposed to capture an
abstract semantic concept. Our extractive summarization algorithm leverages the
representations to identify representative opinions among hundreds of reviews.
SemAE is also able to perform controllable summarization to generate
aspect-specific summaries. We report strong performance on SPACE and AMAZON
datasets, and perform experiments to investigate the functioning of our model.
Our code is publicly available at https://github.com/brcsomnath/SemAE.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:03:35 GMT""},{""version"":""v2"",""created"":""Thu, 21 Apr 2022 17:14:52 GMT""},{""version"":""v3"",""created"":""Thu, 19 May 2022 03:31:33 GMT""}]","2022-05-20"
"2203.07922","Dat Thanh Tran","Dat Thanh Tran, Juho Kanniainen, Alexandros Iosifidis","How informative is the Order Book Beyond the Best Levels? Machine
  Learning Perspective","NeurIPS 2021 Workshop on Machine Learning meets Econometrics
  (MLECON2021)",,,,"cs.CE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Research on limit order book markets has been rapidly growing and nowadays
high-frequency full order book data is widely available for researchers and
practitioners. However, it is common that research papers use the best level
data only, which motivates us to ask whether the exclusion of the quotes deeper
in the book over multiple price levels causes performance degradation. In this
paper, we address this question by using modern Machine Learning (ML)
techniques to predict mid-price movements without assuming that limit order
book markets represent a linear system. We provide a number of results that are
robust across ML prediction models, feature selection algorithms, data sets,
and prediction horizons. We find that the best bid and ask levels are
systematically identified not only as the most informative levels in the order
books, but also to carry most of the information needed for good prediction
performance. On the other hand, even if the top-of-the-book levels contain most
of the relevant information, to maximize models' performance one should use all
data across all the levels. Additionally, the informativeness of the order book
levels clearly decreases from the first to the fourth level while the rest of
the levels are approximately equally important.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:04:01 GMT""}]","2022-03-16"
"2203.07923","Olli Saari","David Beltran and Olli Saari","$L^p-L^q$ local smoothing estimates for the wave equation via $k$-broad
  Fourier restriction","Final version with referee's comments incorporated; to appear in J.
  Fourier Anal. Appl","J. Fourier Anal. Appl. 28 (2022), Paper No. 76","10.1007/s00041-022-09968-w",,"math.AP math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore the connection between $k$-broad Fourier restriction estimates and
sharp regularity $L^p-L^q$ local smoothing estimates for the solutions of the
wave equation in $\mathbb{R}^{n}\times \mathbb{R}$ for all $n \geq 3$ via a
Bourgain--Guth broad-narrow analysis. An interesting feature is that local
smoothing estimates for $e^{i t \sqrt{-\Delta}}$ are not invariant under
Lorentz rescaling.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:04:39 GMT""},{""version"":""v2"",""created"":""Wed, 17 Aug 2022 09:44:56 GMT""}]","2022-10-31"
"2203.07924","Pierre Gabriel","Bertrand Cloez (MISTEA), Pierre Gabriel (UVSQ)","Fast, slow convergence, and concentration in the house of cards
  replicator-mutator model",,,,"MISTEA - Axe syst{\`e}mes dynamiques","math.AP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a fine analysis of the various possible long time behaviours of
the solutions of the replicator-mutator equation with so-called Kingman's house
of cards mutations. In particular, we give what is to our knowledge the first
concentration result for this model.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:05:35 GMT""},{""version"":""v2"",""created"":""Tue, 6 Dec 2022 08:35:07 GMT""}]","2022-12-07"
"2203.07925","Thomas Juffmann","Marius Constantin Chirita Mihaila, Philipp Weber, Matthias Schneller,
  Lucas Grandits, Stefan Nimmrichter, Thomas Juffmann","Transverse Electron Beam Shaping with Light","13 pages, 9 figures",,,,"physics.optics physics.ins-det quant-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Interfacing electrons and light enables ultrafast electron microscopy,
quantum control of electrons, as well as new optical elements for high
sensitivity imaging. Here we demonstrate for the first time programmable
transverse electron beam shaping in free space based on ponderomotive
potentials from short intense laser pulses. We can realize both convex and
concave electron lenses with a focal length of a few millimeters, comparable to
those in state-of-the-art electron microscopes. We further show that we can
realize almost arbitrary deflection patterns by shaping the ponderomotive
potentials using a spatial light modulator. Our modulator is lossless,
programmable, has unity fill factor, and could pave the way to electron
wavefront shaping with hundreds of individually addressable pixels.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:06:19 GMT""}]","2022-03-16"
"2203.07926","Eduardo Bittencourt","Eduardo Bittencourt, Leandro G. Gomes, Grasiele B. Santos","On the intrinsically flat cosmological models in a lattice","16 pages, 3 figures",,"10.1088/1361-6382/ac96c3",,"gr-qc hep-th math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  In this manuscript we investigate the intrinsically flat (space-flat)
spacetimes as viable cosmological models. We show that they have a natural
geometric structure which is suitable to describe inhomogeneous matter
distributions forming a periodic pattern throughout the space. We prove
theorems for their local representation and for existence and uniqueness of the
Einstein's equations with these periodic boundary conditions. We also find an
interesting class of exact solutions, which illustrates the applicability of
such spacetimes in cosmology, with an early time behavior close to homogeneity
and isotropy and a late time aspect with peaks and voids in the matter
distribution.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:07:04 GMT""}]","2022-12-07"
"2203.07927","Yuichi Itto","Yuichi Itto","Conditional entropic approach to nonequilibrium complex systems with
  weak fluctuation correlation","32 pages, no figures. The title changed, the discussion developed
  further, and some references added. Published version","Entropy 2023, 25, 556","10.3390/e25040556",,"cond-mat.stat-mech physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A conditional entropic approach is discussed for nonequilibrium complex
systems with a weak correlation between spatiotemporally fluctuating quantities
on a large time scale. The weak correlation is found to constitute the
fluctuation distribution that maximizes the entropy associated with the
conditional fluctuations. The approach is illustrated in diffusion phenomenon
of proteins inside bacteria. A further possible illustration is also presented
for membraneless organelles in embryos and beads in cell extracts, which share
common natures of fluctuations in their diffusion.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:08:15 GMT""},{""version"":""v2"",""created"":""Sun, 2 Apr 2023 22:24:38 GMT""}]","2023-04-04"
"2203.07928","Werner Vogelsang","Maurizio Abele, Daniel de Florian, Werner Vogelsang","Threshold resummation at N$^{3}$LL accuracy and approximate N$^{3}$LO
  corrections to semi-inclusive DIS","25 pages, 2 figures",,"10.1103/PhysRevD.106.014015",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We advance the threshold resummation formalism for semi-inclusive
deep-inelastic scattering (SIDIS) to next-to-next-to-next-to-leading
logarithmic (N$^{3}$LL) order, including the three-loop hard factor. We expand
the results in the strong coupling to obtain approximate
next-to-next-to-next-to-leading order (N$^{3}$LO) corrections for the SIDIS
cross section. In Mellin moment space, these corrections include all terms that
are logarithmically enhanced at threshold, or that are constant. We also
consider a set of corrections that are suppressed near threshold. Our numerical
estimates show modest changes of the cross section by the approximate N$^{3}$LO
terms, suggesting a very good perturbative stability of the SIDIS process.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:09:28 GMT""}]","2022-08-31"
"2203.07929","Gaotian Wang","Zhanchi Wang, Gaotian Wang, Xiaoping Chen, and Nikolaos M. Freris","Dynamical Modeling and Control of Soft Robots with Non-constant
  Curvature Deformation","the paper is not ready and need to be reviewed",,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  The Piecewise Constant Curvature (PCC) model is the most widely used soft
robotic modeling and control. However, the PCC fails to accurately describe the
deformation of the soft robots when executing dynamic tasks or interacting with
the environment. This paper presents a simple threedimensional (3D) modeling
method for a multi-segment soft robotic manipulator with non-constant curvature
deformation. We devise kinematic and dynamical models for soft manipulators by
modeling each segment of the manipulator as two stretchable links connected by
a universal joint. Based on that, we present two controllers for dynamic
trajectory tracking in confguration space and pose control in task space,
respectively. Model accuracy is demonstrated with simulations and experimental
data. The controllers are implemented on a four-segment soft robotic
manipulator and validated in dynamic motions and pose control with unknown
loads. The experimental results show that the dynamic controller enables a
stable reference trajectory tracking at speeds up to 7m/s.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:13:28 GMT""},{""version"":""v2"",""created"":""Sat, 19 Mar 2022 09:14:04 GMT""}]","2022-03-22"
"2203.07930","Daniel Barath","Daniel Barath, Zuzana Kukelova","Relative Pose from SIFT Features",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  This paper proposes the geometric relationship of epipolar geometry and
orientation- and scale-covariant, e.g., SIFT, features. We derive a new linear
constraint relating the unknown elements of the fundamental matrix and the
orientation and scale. This equation can be used together with the well-known
epipolar constraint to, e.g., estimate the fundamental matrix from four SIFT
correspondences, essential matrix from three, and to solve the semi-calibrated
case from three correspondences. Requiring fewer correspondences than the
well-known point-based approaches (e.g., 5PT, 6PT and 7PT solvers) for epipolar
geometry estimation makes RANSAC-like randomized robust estimation
significantly faster. The proposed constraint is tested on a number of problems
in a synthetic environment and on publicly available real-world datasets on
more than 80000 image pairs. It is superior to the state-of-the-art in terms of
processing time while often leading to more accurate results.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:16:39 GMT""}]","2022-03-16"
"2203.07931","Zi Wang","Zanwei Zhou, Zi Wang, Shunyu Yao, Yichao Yan, Chen Yang, Guangtao
  Zhai, Junchi Yan, Xiaokang Yang","DialogueNeRF: Towards Realistic Avatar Face-to-face Conversation Video
  Generation",,,,,"cs.CV eess.IV","http://creativecommons.org/licenses/by/4.0/","  Conversation is an essential component of virtual avatar activities in the
metaverse. With the development of natural language processing, textual and
vocal conversation generation has achieved a significant breakthrough.
Face-to-face conversations account for the vast majority of daily
conversations. However, this task has not acquired enough attention. In this
paper, we propose a novel task that aims to generate a realistic human avatar
face-to-face conversation process and present a new dataset to explore this
target. To tackle this novel task, we propose a new framework that utilizes a
series of conversation signals, e.g. audio, head pose, and expression, to
synthesize face-to-face conversation videos between human avatars, with all the
interlocutors modeled within the same network. Our method is evaluated by
quantitative and qualitative experiments in different aspects, e.g. image
quality, pose sequence trend, and naturalness of the rendering videos. All the
code, data, and models will be made publicly available.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:16:49 GMT""}]","2022-04-12"
"2203.07932","Xueqi Hu","Xueqi Hu, Qiusheng Huang, Zhengyi Shi, Siyuan Li, Changxin Gao, Li
  Sun, Qingli Li","Style Transformer for Image Inversion and Editing","Accepted by CVPR 2022",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Existing GAN inversion methods fail to provide latent codes for reliable
reconstruction and flexible editing simultaneously. This paper presents a
transformer-based image inversion and editing model for pretrained StyleGAN
which is not only with less distortions, but also of high quality and
flexibility for editing. The proposed model employs a CNN encoder to provide
multi-scale image features as keys and values. Meanwhile it regards the style
code to be determined for different layers of the generator as queries. It
first initializes query tokens as learnable parameters and maps them into W+
space. Then the multi-stage alternate self- and cross-attention are utilized,
updating queries with the purpose of inverting the input by the generator.
Moreover, based on the inverted code, we investigate the reference- and
label-based attribute editing through a pretrained latent classifier, and
achieve flexible image-to-image translation with high quality results.
Extensive experiments are carried out, showing better performances on both
inversion and editing tasks within StyleGAN.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:16:57 GMT""}]","2022-03-16"
"2203.07933","Zuoguang Wang","Zuoguang Wang, Yimo Ren, Hongsong Zhu, Limin Sun","Threat Detection for General Social Engineering Attack Using Machine
  Learning Techniques",,,,,"cs.CR cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper explores the threat detection for general Social Engineering (SE)
attack using Machine Learning (ML) techniques, rather than focusing on or
limited to a specific SE attack type, e.g. email phishing. Firstly, this paper
processes and obtains more SE threat data from the previous Knowledge Graph
(KG), and then extracts different threat features and generates new datasets
corresponding with three different feature combinations. Finally, 9 types of ML
models are created and trained using the three datasets, respectively, and
their performance are compared and analyzed with 27 threat detectors and 270
times of experiments. The experimental results and analyses show that: 1) the
ML techniques are feasible in detecting general SE attacks and some ML models
are quite effective; ML-based SE threat detection is complementary with
KG-based approaches; 2) the generated datasets are usable and the SE domain
ontology proposed in previous work can dissect SE attacks and deliver the SE
threat features, allowing it to be used as a data model for future research.
Besides, more conclusions and analyses about the characteristics of different
ML detectors and the datasets are discussed.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:18:22 GMT""},{""version"":""v2"",""created"":""Thu, 17 Mar 2022 00:01:19 GMT""}]","2022-03-18"
"2203.07934","Tobias Pfandzelter","Tobias Pfandzelter, Trever Schirmer, David Bermbach","Towards Distributed Coordination for Fog Platforms","Accepted for publication at the 22nd IEEE/ACM International Symposium
  on Cluster, Cloud and Internet Computing (CCGrid 2022) Poster Track",,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Distributed fog and edge applications communicate over unreliable networks
and are subject to high communication delays. This makes using existing
distributed coordination technologies from cloud applications infeasible, as
they are built on the assumption of a highly reliable, low-latency datacenter
network to achieve strict consistency with low overheads. To help implement
configuration and state management for fog platforms and applications, we
propose a novel decentralized approach that lets systems specify coordination
strategies and membership for different sets of coordination data.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:20:15 GMT""}]","2022-03-16"
"2203.07935","Peter Massopust","Peter R. Massopust","Fractal Interpolation over Nonlinear Partitions",,,"10.1016/j.chaos.2022.112503",,"math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces the fractal interpolation problem defined over domains
with a nonlinear partition. This setting generalizes known methodologies
regarding fractal functions and provides a new holistic approach to fractal
interpolation. In this context, perturbations of nonlinear partition functions
are considered and sufficient conditions for the existence of a unique solution
of the underlying fractal interpolation problem for some classes of function
spaces are given.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:20:30 GMT""}]","2022-08-31"
"2203.07936","Leonardo Chimirri","Leonardo Chimirri, Rainer Sommer","Investigation of the Perturbative Expansion of Moments of Heavy Quark
  Correlators for $N_f=0$",,,,,"hep-lat","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The QCD-coupling is a necessary input in the computation of many observables,
and the parametric error on input parameters can be a dominant source of
uncertainty. The coupling can be extracted by comparing high order perturbative
computations and lattice evaluated moments of mesonic two-point functions with
heavy quarks, which provide a high energy scale for perturbation theory. The
truncation of the perturbative series is an important systematic uncertainty.
We report on our attempt to study this issue by measuring pseudo-scalar
two-point functions in volumes of $L=2\, \text{fm}$ with twisted-mass Wilson
fermions in the quenched approximation. We use full twist, the non-perturbative
clover term and lattice spacings down to $a=0.015\,\text{fm}$ to tame the
sizable discretization effects. Our preliminary results indicate that either
higher order perturbative corrections or the continuum limit are not under
sufficient control despite our small lattice spacings and quark masses
extending beyond $2\,m_{\text{charm}}$.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:20:31 GMT""}]","2022-03-16"
"2203.07937","Hanzhi Wang","Hanzhi Wang, Zhewei Wei, Junhao Gan, Ye Yuan, Xiaoyong Du and Ji-Rong
  Wen","Edge-based Local Push for Personalized PageRank","VLDB 2022, volume 15, issue 7",,"10.14778/3523210.3523216",,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Personalized PageRank (PPR) is a popular node proximity metric in graph
mining and network research. Given a graph G=(V,E) and a source node $s \in V$,
a single-source PPR (SSPPR) query asks for the PPR value $\vpi(u)$ with respect
to s, which represents the relative importance of node u in the context of the
source node s. Among existing algorithms for SSPPR queries, LocalPush is a
fundamental method which serves as a cornerstone for subsequent algorithms. In
LocalPush, a push operation is a crucial primitive operation, which distributes
the probability at a node u to ALL u's neighbors via the corresponding edges.
Although this push operation works well on unweighted graphs, unfortunately, it
can be rather inefficient on weighted graphs. In particular, on unbalanced
weighted graphs where only a few of these edges take the majority of the total
weight among them, the push operation would have to distribute insignificant
probabilities along those edges which just take the minor weights, resulting in
expensive overhead.
  To resolve this issue, we propose the EdgePush algorithm, a novel method for
computing SSPPR queries on weighted graphs. EdgePush decomposes the
aforementioned push operations in edge-based push, allowing the algorithm to
operate at the edge level granularity. Hence, it can flexibly distribute the
probabilities according to edge weights. Furthermore, our EdgePush allows a
fine-grained termination threshold for each individual edge, leading to a
superior complexity over LocalPush. Notably, we prove that EdgePush improves
the theoretical query cost of LocalPush by an order of up to O(n) when the
graph's weights are unbalanced, both in terms of $\ell_1$-error and normalized
additive error. Our experimental results demonstrate that EdgePush
significantly outperforms state-of-the-art baselines in terms of query
efficiency on large motif-based and real-world weighted graphs.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:21:08 GMT""},{""version"":""v2"",""created"":""Sat, 7 May 2022 14:31:30 GMT""}]","2022-05-10"
"2203.07938","Richard Culpan","Richard Culpan, Stephan Geier, Ingrid Pelisoli, Nicole Reindl, Nicola
  Gentile Fusillo, Alina Vorontseva","The population of hot subdwarf stars studied with Gaia -- IV. Catalogues
  of hot subluminous stars based on Gaia EDR3","20 pages, 18 figures, catalogues available as digital data files","A&A 662, A40 (2022)","10.1051/0004-6361/202243337",,"astro-ph.SR astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  In light of substantial new discoveries of hot subdwarfs by ongoing
spectroscopic surveys and the availability of the Gaia mission Early Data
Release 3 (EDR3), we compiled new releases of two catalogues of hot subluminous
stars: The data release 3 (DR3) catalogue of the known hot subdwarf stars
contains 6,616 unique sources and provides multi-band photometry, and
astrometry from Gaia EDR3 as well as classifications based on spectroscopy and
colours. This is an increase of 742 objects over the DR2 catalogue. This new
catalogue provides atmospheric parameters for 3,087 stars and radial velocities
for 2,791 stars from the literature. In addition, we have updated the Gaia Data
Release 2 (DR2) catalogue of hot subluminous stars using the improved accuracy
of the Gaia EDR3 data set together with updated quality and selection criteria
to produce the Gaia EDR3 catalogue of 61,585 hot subluminous stars,
representing an increase of 21,785 objects. The improvements in Gaia EDR3
astrometry and photometry compared to Gaia DR2 have enabled us to define more
sophisticated selection functions. In particular, we improved hot subluminous
star detection in the crowded regions of the Galactic plane as well as in the
direction of the Magellanic Clouds by including sources with close apparent
neighbours but with flux levels that dominate the neighbourhood.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:21:16 GMT""}]","2022-06-15"
"2203.07939","Myriam Lewkowicz","Myriam Lewkowicz (LIST3N, Tech-CICO)","Strategic Thinking for Sustainable Practice-Centered Computing",,,,,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This book was a trigger for me to reflect on all the projects we have
conducted at the local, regional, national, and European levels around
healthcare, addressing the social isolation of elderlies, the social support
among caregivers, and the coordination issues of professionals willing to take
care for patients at their home. Since Ina Wagner interviewed me in Paris, the
situation evolved in France as a new healthcare law was voted that emphasizes
the importance of cooperation among healthcare practitioners, the need for IT
support, and the key role of local territories (which is not obvious in France,
that is a very centralized country). The reflection that started with this book
definitely helped me to make decisions in this evolving context, and I am
grateful to Claudia M{\""u}ller who, through an interview, facilitated me to
realize what are, from my experience, the main issues that have to be dealt
with when aiming at ensuring a sustainable practice-based computing approach.
In this epilogue, I briefly list and illustrate these main issues, hoping they
could support other sustainable experiences.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:23:25 GMT""}]","2022-03-16"
"2203.07940","Anantya Bhatnagar","Anantya Bhatnagar, Dimitri D. Vvedensky","Quantum effects in an expanded Black-Scholes model","11 pages, 3 figures (Supplement - 26 pages, 20 figures)","Eur. Phys. J. B, 95:138 (2022)","10.1140/epjb/s10051-022-00402-0",,"q-fin.PR quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The limitations of the classical Black-Scholes model are examined by
comparing calculated and actual historical prices of European call options on
stocks from several sectors of the S&P 500. Persistent differences between the
two prices point to an expanded model proposed by Segal and Segal (1998) in
which information not simultaneously observable or actionable with public
information can be represented by an additional pseudo-Wiener process. A real
linear combination of the original and added processes leads to a commutation
relation analogous to that between a boson field and its canonical momentum in
quantum field theory. The resulting pricing formula for a European call option
replaces the classical volatility with the norm of a complex quantity, whose
imaginary part is shown to compensate for the disparity between prices obtained
from the classical Black-Scholes model and actual prices of the test call
options. This provides market evidence for the influence of a non-classical
process on the price of a security based on non-commuting operators.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:24:07 GMT""}]","2022-08-30"
"2203.07941","Marco S\""alzer","Marco S\""alzer and Martin Lange","Reachability In Simple Neural Networks","arXiv admin note: substantial text overlap with arXiv:2108.13179",,,,"cs.CC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the complexity of the reachability problem for (deep) neural
networks: does it compute valid output given some valid input? It was recently
claimed that the problem is NP-complete for general neural networks and
specifications over the input/output dimension given by conjunctions of linear
inequalities. We recapitulate the proof and repair some flaws in the original
upper and lower bound proofs. Motivated by the general result, we show that
NP-hardness already holds for restricted classes of simple specifications and
neural networks. Allowing for a single hidden layer and an output dimension of
one as well as neural networks with just one negative, zero and one positive
weight or bias is sufficient to ensure NP-hardness. Additionally, we give a
thorough discussion and outlook of possible extensions for this direction of
research on neural network verification.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:25:44 GMT""},{""version"":""v2"",""created"":""Tue, 7 Jun 2022 13:29:41 GMT""},{""version"":""v3"",""created"":""Tue, 4 Apr 2023 06:29:36 GMT""}]","2023-04-05"
"2203.07942","Julien Sedro","Julien Sedro","Pre-threshold fractional susceptibility function: holomorphy and
  response formula","The main argument in the construction of the parameter set in Theorem
  1 is flawed",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For certain smooth unimodal families with negative Schwarzian derivative, we
construct a set of Collet-Eckmann and subexponentially recurrent parameters
$\Omega$, whose complement set has sufficiently fast decaying density, on which
exponential mixing with uniform rates occurs. We use this construction to
establish holomorphy of the true fractional susceptibility function of the
logistic family, in a disk of radius larger than one, for differentiation index
$0\le\eta<1/2$, as recently conjectured by Baladi and Smania. We also obtain a
fractional response formula.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:26:30 GMT""},{""version"":""v2"",""created"":""Fri, 2 Sep 2022 22:42:19 GMT""}]","2022-09-07"
"2203.07943","Cora Dvorkin","Cora Dvorkin, Joel Meyers, Peter Adshead, Mustafa Amin, Carlos A.
  Arg\""uelles, Thejs Brinckmann, Emanuele Castorina, Timothy Cohen, Nathaniel
  Craig, David Curtin, Francis-Yan Cyr-Racine, Peizhi Du, Lloyd Knox, Bohua Li,
  Marilena Loverde, Kaloian Lozanov, Julian B. Mu\~noz, Katelin Schutz, Paul
  Shapiro, Benjamin Wallisch, Zachary J. Weiner, and Weishuang Linda Xu","The Physics of Light Relics","Contribution to Snowmass 2021. 59 pages, 12 figures",,,,"hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many well-motivated extensions of the Standard Model predict the existence of
new light species that may have been produced in the early universe. Prominent
examples include axions, sterile neutrinos, gravitinos, dark photons, and more.
The gravitational influence of light relics leaves imprints in the cosmic
microwave background fluctuations, the large-scale structure of the universe
and the primordial element abundances. In this paper, we detail the physics of
cosmological light relics, and describe how measurements of their relic density
and mass serve as probes of physics beyond the Standard Model. A measurement of
the light relic density at the precision of upcoming cosmological surveys will
point the way toward new physics or severely constrain the range of viable
extensions to the Standard Model.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:26:56 GMT""}]","2022-03-16"
"2203.07944","Takahiro Mizuno","Takahiro Mizuno, Keisuke Fujii, Junping Tian","Measurement of $A_{LR}$ using radiative return at ILC 250","contribution to Snowmass 2021",,,,"hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For the precision study at the ILC 250, measurement of $A_{LR}$ is important
as it can constrain SMEFT parameters. The current best measured $A_{LR}$ value
is $A_{LR} = 0.1514 \pm 0.0019\,(stat) \pm 0.0011\,(syst)$ which was measured
at the SLC, and a more precise value is required for the global fit for the new
physics search in TeV-scale. At the ILC, we can use the $e^+ e^- \to \gamma Z$
process to evaluate the $A_{LR}$. We performed a full simulation study of the
$e^+ e^- \to \gamma Z$ process at the center-of-mass energy of 250 GeV and
evaluated how much we can improve the precision of this observable. The
statistical error on $A_{LR}$ at the ILC 250 turned out to be $1.8 \times
10^{-4}$. Major source of the systematic error was error from the beam
polarization. As other sources of the systematic error, the uncorrelated parts
of error on the product of luminosity and selection efficiency for each
polarization combination contribute. Including those systematic errors, total
absolute error on $A_{LR}$ was estimated to be 0.00025, 8.8 times better
precision than that from the SLC (0.00219).
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:27:34 GMT""}]","2022-03-16"
"2203.07945","Andrey Yachmenev","Andrey Yachmenev, Guang Yang, Emil Zak, Sergei Yurchenko, Jochen
  K\""upper","The nuclear-spin-forbidden rovibrational transitions of water from first
  principles",,,"10.1063/5.0090771",,"physics.atom-ph physics.atm-clus","http://creativecommons.org/licenses/by/4.0/","  The water molecule occurs in two nuclear-spin isomers that differ by the
value of the total nuclear spin of the hydrogen atoms, i.e., $I=0$ for
para-H$_2$O and $I=1$ for ortho-H$_2$O. Spectroscopic transitions between
rovibrational states of ortho and para water are extremely weak due to the tiny
hyperfine nuclear-spin-rotation interaction of only $\sim30$ kHz and so far
were not observed. We report the first comprehensive theoretical investigation
of the hyperfine effects and ortho-para transitions in H$_2$$^{16}$O due to
nuclear-spin-rotation and spin-spin interactions. We also present the details
of our newly developed general variational approach to the simulation of
hyperfine effects in polyatomic molecules. Our results for water suggest that
the strongest ortho-para transitions with room-temperature intensities on the
order of $10^{-31}$ cm/molecule are about an order of magnitude larger than
previously predicted values and should be detectable in the mid-infrared
$\nu_2$ and near-infrared $2\nu_1+\nu_2$ and $\nu_1+\nu_2+\nu_3$ bands by
current spectroscopy experiments.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:27:42 GMT""}]","2022-06-08"
"2203.07946","Raphael Flauger","Mustafa A. Amin, Francis-Yan Cyr-Racine, Tim Eifler, Raphael Flauger,
  Mikhail M. Ivanov, Marilena LoVerde, Caio B. de S. Nascimento, Annika H. G.
  Peter, Mark Vogelsberger, Scott Watson, Risa Wechsler","Snowmass2021 Theory Frontier White Paper: Data-Driven Cosmology","Contribution to Snowmass 2021",,,,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Over the past few decades, astronomical and cosmological data sets firmly
established the existence of physics beyond the Standard Model of particle
physics by providing strong evidence for the existence of dark matter, dark
energy, and non-zero neutrino mass. In addition, the generation of primordial
perturbations most likely also relies on physics beyond the Standard Model of
particle physics. Theory work, ranging from models of the early universe in
string theory that that led to novel phenomenological predictions to the
development of effective field theories to large-scale cosmological simulations
that include the physics of galaxy evolution, has played a key role in
analyzing and interpreting these data sets and in suggesting novel paths
forward to isolate the origins of this new physics. Over the next decade, even
more sensitive surveys are beginning to take data and are being planned. In
this white paper, we describe key areas of the theory program that will be
needed to optimize the physics return on investment from these new
observational opportunities.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:29:12 GMT""}]","2022-03-16"
"2203.07947","Randy Price","Harbir Antil, Rainald L\""ohner, Randy Price","NINNs: Nudging Induced Neural Networks","20 pages",,,,"cs.LG cs.NA math.NA math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  New algorithms called nudging induced neural networks (NINNs), to control and
improve the accuracy of deep neural networks (DNNs), are introduced. The NINNs
framework can be applied to almost all pre-existing DNNs, with forward
propagation, with costs comparable to existing DNNs. NINNs work by adding a
feedback control term to the forward propagation of the network. The feedback
term nudges the neural network towards a desired quantity of interest. NINNs
offer multiple advantages, for instance, they lead to higher accuracy when
compared with existing data assimilation algorithms such as nudging. Rigorous
convergence analysis is established for NINNs. The algorithmic and theoretical
findings are illustrated on examples from data assimilation and chemically
reacting flows.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:29:26 GMT""}]","2022-03-16"
"2203.07948","Xunzhao Yin","Xunzhao Yin, Franz M\""uller, Qingrong Huang, Chao Li, Mohsen Imani,
  Zeyu Yang, Jiahao Cai, Maximilian Lederer, Ricardo Olivo, Nellie Laleni, Shan
  Deng, Zijian Zhao, Cheng Zhuo, Thomas K\""ampfe, Kai Ni","An Ultra-Compact Single FeFET Binary and Multi-Bit Associative Search
  Engine","20 pages, 14 figures",,,,"cs.ET eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Content addressable memory (CAM) is widely used in associative search tasks
for its highly parallel pattern matching capability. To accommodate the
increasingly complex and data-intensive pattern matching tasks, it is critical
to keep improving the CAM density to enhance the performance and area
efficiency. In this work, we demonstrate: i) a novel ultra-compact 1FeFET CAM
design that enables parallel associative search and in-memory hamming distance
calculation; ii) a multi-bit CAM for exact search using the same CAM cell; iii)
compact device designs that integrate the series resistor current limiter into
the intrinsic FeFET structure to turn the 1FeFET1R into an effective 1FeFET
cell; iv) a successful 2-step search operation and a sufficient sensing margin
of the proposed binary and multi-bit 1FeFET1R CAM array with sizes of practical
interests in both experiments and simulations, given the existing unoptimized
FeFET device variation; v) 89.9x speedup and 66.5x energy efficiency
improvement over the state-of-the art alignment tools on GPU in accelerating
genome pattern matching applications through the hyperdimensional computing
paradigm.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:29:28 GMT""}]","2022-03-16"
"2203.07949","Keyi Li","Keyi Li, Sen Yang, Travis M. Sullivan, Randall S. Burd, Ivan Marsic","Generating Privacy-Preserving Process Data with Deep Generative Models","9 pages, 6 figures",,,,"cs.LG cs.AI cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Process data with confidential information cannot be shared directly in
public, which hinders the research in process data mining and analytics. Data
encryption methods have been studied to protect the data, but they still may be
decrypted, which leads to individual identification. We experimented with
different models of representation learning and used the learned model to
generate synthetic process data. We introduced an adversarial generative
network for process data generation (ProcessGAN) with two Transformer networks
for the generator and the discriminator. We evaluated ProcessGAN and
traditional models on six real-world datasets, of which two are public and four
are collected in medical domains. We used statistical metrics and supervised
learning scores to evaluate the synthetic data. We also used process mining to
discover workflows for the authentic and synthetic datasets and had medical
experts evaluate the clinical applicability of the synthetic workflows. We
found that ProcessGAN outperformed traditional sequential models when trained
on small authentic datasets of complex processes. ProcessGAN better represented
the long-range dependencies between the activities, which is important for
complicated processes such as the medical processes. Traditional sequential
models performed better when trained on large data of simple processes. We
conclude that ProcessGAN can generate a large amount of sharable synthetic
process data indistinguishable from authentic data.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:29:54 GMT""}]","2022-03-16"
"2203.07950","Francois Vigneron","Nicolas Lerner (IMJ-PRG (UMR\_7586)), Fran\c{c}ois Vigneron (LMR)","On some properties of the curl operator and their consequences for the
  Navier-Stokes system",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate some geometric properties of the $\operatorname{curl}$
operator, based on its diagonalizationand its expression as a non-local
symmetry of the pseudo-derivative $(-\Delta)^{1/2}$ among divergence-free
vector fieldswith finite energy. In this context, we introduce the notion of
spin-definite fields, i.e. eigenvectorsof
$(-\Delta)^{-1/2}\operatorname{curl}$.The two spin-definite components of a
general 3D incompressible flow untangle the right-handed motion from the
left-handed one. Having observed that the non-linearity of Navier-Stokes has
the structure of a cross-productand its weak (distributional) form is a
determinant that involves the vorticity, the velocity and a test function,we
revisit the conservation of energy and the balance of helicity in a geometrical
fashion. We show that in the caseof a finite-time blow-up, both spin-definite
components of the flow will explose simultaneously and with equal rates,i.e.
singularities in 3D are the result of a conflict of spin, which is impossible
in the poorer geometry of 2D flows.We investigate the role of the local and
non-local determinants $$\int_0^T\int_{\mathbb{R}^3}\det(\operatorname{curl} u,
u, (-\Delta)^{\theta} u)$$ and their spin-definite counterparts, which drive
the enstrophy and, more generally, are responsible forthe regularity of the
flow and the emergence of singularities or quasi-singularities.As such, they
are at the core of turbulence phenomena.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:30:31 GMT""}]","2022-03-16"
"2203.07951","Oliver Rice","Oliver E.K. Rice and Anthony R. Yeates","Eruptivity Criteria for Two-dimensional Magnetic Flux Ropes in the Solar
  Corona","25 pages, 11 figures. To be published in 'Frontiers in Astronomy and
  Space Sciences', accepted for publication 8th March 2022",,,,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We apply the magneto-frictional approach to investigate which quantity or
quantities can best predict the loss of equilibrium of a
translationally-invariant magnetic flux rope. The flux rope is produced
self-consistently by flux cancellation combined with gradual footpoint shearing
of a coronal arcade which is open at the outer boundary. This models the
magnetic field in decaying active regions on the Sun. Such a model permits two
types of eruption: episodic small events caused by shearing and relaxation of
the overlying arcade, and major eruptions of the main low-lying coronal flux
rope. Through a parameter study, we find that the major eruptions are best
predicted not by individual quantities but by thresholds in the ratios of
squared rope current to either magnetic energy or relative magnetic helicity.
We show how to appropriately define the latter quantity for
translationally-invariant magnetic fields, along with a related eruptivity
index that has recently been introduced for three-dimensional magnetic fields.
In contrast to previous configurations studied, we find that the eruptivity
index has only a weak predictive skill, and in fact is lower prior to eruption,
rather than higher. This is because the overlying background magnetic field has
the same direction as the arcade itself. Thus we propose that there are a whole
class of solar eruptions that cannot be predicted by a high eruptivity index.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:31:21 GMT""}]","2022-03-16"
"2203.07952","Edward Baker Iii","Edward B. Baker III","Causal and self-dual morphisms in four complex dimensions","11 pages",,,,"math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  We define a class of maps between holomorphically embedded null curves which
generalize conformal transformations, and can be defined in any complex
dimension. In four dimensions, we can also define a similar map between
self-dual surfaces, which generalize flat $\alpha$-planes. These maps are
respectively called causal and self-dual morphisms. It is shown that there
exist an infinite class of non-trivial examples for both types of maps in four
dimensions.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:32:15 GMT""},{""version"":""v2"",""created"":""Sun, 27 Mar 2022 19:58:57 GMT""}]","2022-03-29"
"2203.07953","Ludovic Courtes","Ludovic Court\`es (SED)","Reproducibility and Performance: Why Choose?",,"Computing in Science and Engineering, Institute of Electrical and
  Electronics Engineers, In press",,,"cs.DC cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Research processes often rely on high-performance computing (HPC), but HPC is
often seen as antithetical to ""reproducibility"": one would have to choose
between software that achieves high performance, and software that can be
deployed in a reproducible fashion. However, by giving up on reproducibility we
would give up on verifiability, a foundation of the scientific process. How can
we conciliate performance and reproducibility? This article looks at two
performance-critical aspects in HPC: message passing (MPI) and CPU
micro-architecture tuning. Engineering work that has gone into performance
portability has already proved fruitful, but some areas remain unaddressed when
it comes to CPU tuning. We propose package multi-versioning, a technique
developed for GNU Guix, a tool for reproducible software deployment, and show
that it allows us to implement CPU tuning without compromising on
reproducibility and provenance tracking.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:32:41 GMT""}]","2022-03-16"
"2203.07954","Liyun Chen","Li-Yun Chen, Cheng-Cheng Guo, Ming-Ming Pan, Chen Lai, Yun-Xia Wang,
  Guo-Cai Liao, Zi-Wei Ma, Fan-Wei Zhang, Jagadeesh Suriyaprakash, Lijing Guo,
  Eser Akinoglu, Qiang Li, and Li-Jun Wu","Sub-40nm Nanogratings Self-Organized in PVP-based Polymer Composite Film
  by Photoexcitation and Two Sequent Splitting under Femtosecond Laser
  Irradiation",,,"10.1016/j.apsusc.2022.155395",,"physics.optics physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Laser-induced periodic surface structures (LIPSSs) on various materials have
been extensively investigated because of their wide applications. The
combination of different materials allows for greater freedom in tailoring
their functions and achieving responses not possible in a homogeneous material.
By utilizing a femtosecond (fs) laser to irradiate the Fe-doped Polyvinyl
Pyrrolidone (PVP) composite film, highly regular ultrafine nanogratings
(U-nanogratings) with a period as small as 35.0 ($\pm$ 2.0) nm can be
self-organized on the surface with extremely high efficiency. The period of the
U-nanogratings can be controlled by varying the scanning speed of the laser
beam (deposited energy) and the thickness of the composite film. Based on the
experimental, theoretical, and simulation results, we propose a two-step
formation mechanism: composite film excitation and two sequent
grating-splitting. The high photosensitivity and low glass transition
temperature of the composite film facilitate the fabrication of the ultrafine
nanostructures. The proposed design method for the composite material and
fabrication process could not only provide a strategy for obtaining highly
regular U-nanogratings, but also offer a platform to explore the interaction
physics between ultra-short pulses and matter under extreme conditions.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:33:57 GMT""}]","2022-11-09"
"2203.07955","David Egger","Thomas M. Brenner, Manuel Grumet, Paul Till, Maor Asher, Wolfgang G.
  Zeier, David A. Egger, Omer Yaffe","Anharmonic Lattice Dynamics in Sodium Ion Conductors",,,"10.1021/acs.jpclett.2c00904",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  We employ THz-range temperature-dependent Raman spectroscopy and
first-principles lattice-dynamical calculations to show that the undoped sodium
ion conductors Na$_3$PS$_4$ and isostructural Na$_3$PSe$_4$ both exhibit
anharmonic lattice dynamics. The anharmonic effects in the compounds involve
coupled host lattice -- Na$^+$ ion dynamics that drive the tetragonal-to-cubic
phase transition in both cases, but with a qualitative difference in the
anharmonic character of the transition. Na$_3$PSe$_4$ shows almost purely
displacive character with the soft modes disappearing in the cubic phase as the
change of symmetry shifts these modes to the Raman-inactive Brillouin zone
boundary. Na$_3$PS$_4$ instead shows order-disorder character in the cubic
phase, with the soft modes persisting through the phase transition and
remaining active in Raman in the cubic phase, violating Raman selection rules
for that phase. Our findings highlight the important role of coupled host
lattice -- mobile ion dynamics in vibrational instabilities that are coincident
with the exceptional conductivity in these Na$^+$ ion conductors.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:37:10 GMT""}]","2022-08-09"
"2203.07956","Michael Zacharias","Michael Zacharias, Anita Reimer, Catherine Boisson, Andreas Zech","ExHaLe-jet: An extended hadro-leptonic jet model for blazars. I. Code
  description and initial results","26 pages, 12 figues, accepted for publication in MNRAS","2022, MNRAS, 512, 3948","10.1093/mnras/stac754",,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The processes operating in blazar jets are still an open question. Modeling
the radiation emanating from an extended part of the jet allows one to capture
these processes on all scales. Kinetic codes solving the Fokker-Planck equation
along the jet flow are well suited to this task, as they can efficiently derive
the radiation and particle spectra without the need for computationally
demanding plasma-physical simulations. Here, we present a new extended
hadro-leptonic jet code -- ExHaLe-jet -- which considers simultaneously the
processes of relativistic protons and electrons. Within a pre-set geometry and
bulk flow, the particle evolution is derived self-consistently. Highly
relativistic secondary electrons (and positrons) are created through
$\gamma$-$\gamma$ pair production, Bethe-Heitler pair production, and pion/muon
decay. These secondaries are entrained in the jet flow decreasing the ratio of
protons to electrons with distance from the jet base. For particle-photon
interactions, we consider all internal and many external photon fields, such as
the accretion disk, broad-line region, and the dusty torus. The external fields
turn out to be the most important source for particle-photon interactions
governing the resulting photon and neutrino spectra. In this paper, we present
the code and an initial parameter study, while in follow-up works we present
extensions of the code and more specific applications.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:39:14 GMT""}]","2022-04-11"
"2203.07957","Raffaele Marotta","Raffaele Marotta","Soft-Theorems for Scalar Particles: The Dilatons Story","17 pages, 1 figure; article prepared for Symmetry, Special Issue
  ""Advances in Theoretical High Energy Physics - Solving Quantum Field Theory""","Symmetry 2022, 14(3), 574","10.3390/sym14030574",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  We summarize recent results regarding single and double soft theorems of two
different particles named dilatons, the Nambu-Goldstone boson of the
spontaneously broken conformal field theories and the massless scalar particle
of the closed string theories. Similarities and differences between the soft
theorems of these two particles are discussed as well as their connections with
the symmetries of the theories.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:40:51 GMT""}]","2022-03-16"
"2203.07958","Rafael Stekolshchik","Rafael Stekolshchik","Transitions between root subsets associated with Carter diagrams","42 pages, 47 figures, 11 tables. Added some figures, updated
  introduction, abstract and title",,,,"math.RT","http://creativecommons.org/licenses/by/4.0/","  For any two root subsets associated with two Carter diagrams that have the
same $ADE$ type and the same size, we construct the transition matrix that maps
one subset to the other. The transition between these two subsets is carried
out in some canonical way affecting exactly one root, so that this root is
mapped to the minimal element in some root subsystem. The constructed
transitions are involutions. It is shown that all root subsets associated with
the given Carter diagram are conjugate under the action of the Weyl group. A
numerical relationship is observed between enhanced Dynkin diagrams
$\Delta(E_6)$, $\Delta(E_7)$ and $\Delta(E_8)$ (introduced by Dynkin-Minchenko)
and Carter diagrams. This relationship echoes the $2-4-8$ assertions obtained
by Ringel, Rosenfeld and Baez in completely different contexts regarding the
Dynkin diagrams $E_6$, $E_7$, $E_8$.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:41:38 GMT""},{""version"":""v2"",""created"":""Mon, 25 Apr 2022 19:48:09 GMT""},{""version"":""v3"",""created"":""Sun, 3 Jul 2022 13:38:58 GMT""}]","2022-07-05"
"2203.07959","Jordy Timo van Velthoven","Jordy Timo van Velthoven, Felix Voigtlaender","Coorbit spaces and dual molecules: The quasi-Banach case",,,,,"math.FA math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper provides a self-contained exposition of coorbit spaces associated
with integrable group representations and quasi-Banach function spaces. It
extends the theory in [Studia Math., 180(3):237-253, 2007] to locally compact
groups that do not necessarily possess a compact, conjugation-invariant unit
neighborhood. Furthermore, the present paper establishes the existence of dual
molecules of frames and Riesz sequences as in [J. Funct. Anal., 280(10):56,
2021] for the setting of quasi-Banach spaces. To ensure the direct
applicability to various well-studied examples, the theory is developed for
possibly projective and reducible unitary representations.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:42:20 GMT""}]","2022-03-16"
"2203.07960","Zili Huang","Zili Huang, Shinji Watanabe, Shu-wen Yang, Paola Garcia, Sanjeev
  Khudanpur","Investigating self-supervised learning for speech enhancement and
  separation","To appear in ICASSP 2022",,,,"eess.AS","http://creativecommons.org/licenses/by/4.0/","  Speech enhancement and separation are two fundamental tasks for robust speech
processing. Speech enhancement suppresses background noise while speech
separation extracts target speech from interfering speakers. Despite a great
number of supervised learning-based enhancement and separation methods having
been proposed and achieving good performance, studies on applying
self-supervised learning (SSL) to enhancement and separation are limited. In
this paper, we evaluate 13 SSL upstream methods on speech enhancement and
separation downstream tasks. Our experimental results on Voicebank-DEMAND and
Libri2Mix show that some SSL representations consistently outperform baseline
features including the short-time Fourier transform (STFT) magnitude and log
Mel filterbank (FBANK). Furthermore, we analyze the factors that make existing
SSL frameworks difficult to apply to speech enhancement and separation and
discuss the representation properties desired for both tasks. Our study is
included as the official speech enhancement and separation downstreams for
SUPERB.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:43:02 GMT""}]","2022-03-16"
"2203.07961","Hippolyte Verdier","Hippolyte Verdier, Fran\c{c}ois Laurent, Alhassan Cass\'e, Christian
  Vestergaard, Jean-Baptiste Masson","Variational inference of fractional Brownian motion with linear
  computational complexity",,,"10.1103/PhysRevE.106.055311",,"cs.LG physics.bio-ph physics.data-an q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a simulation-based, amortised Bayesian inference scheme to infer
the parameters of random walks. Our approach learns the posterior distribution
of the walks' parameters with a likelihood-free method. In the first step a
graph neural network is trained on simulated data to learn optimized
low-dimensional summary statistics of the random walk. In the second step an
invertible neural network generates the posterior distribution of the
parameters from the learnt summary statistics using variational inference. We
apply our method to infer the parameters of the fractional Brownian motion
model from single trajectories. The computational complexity of the amortized
inference procedure scales linearly with trajectory length, and its precision
scales similarly to the Cram{\'e}r-Rao bound over a wide range of lengths. The
approach is robust to positional noise, and generalizes well to trajectories
longer than those seen during training. Finally, we adapt this scheme to show
that a finite decorrelation time in the environment can furthermore be inferred
from individual trajectories.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:43:16 GMT""},{""version"":""v2"",""created"":""Mon, 21 Mar 2022 09:27:31 GMT""},{""version"":""v3"",""created"":""Thu, 22 Sep 2022 16:40:02 GMT""},{""version"":""v4"",""created"":""Fri, 23 Sep 2022 06:30:36 GMT""}]","2022-12-07"
"2203.07962","Konstantinos Balaskas","Konstantinos Balaskas, Georgios Zervakis, Hussam Amrouch, Joerg
  Henkel, Kostas Siozios","Automated Design Approximation to Overcome Circuit Aging",,"IEEE Transactions on Circuits and Systems I: Regular Papers
  (Volume: 68, Issue: 11, Date: Nov. 2021, Pages: 4710 - 4721)","10.1109/TCSI.2021.3106149",,"cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transistor aging phenomena manifest themselves as degradations in the main
electrical characteristics of transistors. Over time, they result in a
significant increase of cell propagation delay, leading to errors due to timing
violations, since the operating frequency becomes unsustainable as the circuit
ages. Conventional techniques employ timing guardbands to mitigate
aging-induced delay increase, which leads to considerable performance losses
from the beginning of the circuit's lifetime. Leveraging the inherent error
resilience of a vast number of application domains, approximate computing was
recently introduced as an aging mitigation mechanism. In this work, we present
the first automated framework for generating aging-aware approximate circuits.
Our framework, by applying directed gate-level netlist approximation, induces a
small functional error and recovers the delay degradation due to aging. As a
result, our optimized circuits eliminate aging-induced timing errors.
Experimental evaluation over a variety of arithmetic circuits and image
processing benchmarks demonstrates that for an average error of merely
$5\times10^{-3}$, our framework completely eliminates aging-induced timing
guardbands. Compared to the respective baseline circuits without timing
guardbands (i.e., iso-performance evaluation), the error of the circuits
generated by our framework is $1208$x smaller.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:43:32 GMT""}]","2022-03-16"
"2203.07963","Alexandru Ionut","Alexandru Ionut","On the spherical clothoid","12 pages, 2 figures",,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  We revisit a nonlinear spline primitive for 3-space first studied by Even
Mehlum. It is the spherical clothoid, the spherical curve with geodesic
curvature a linear function of arc length. We present its Cartesian coordinate
functions using confluent hypergeometric functions (the Kummer functions) and
its stereographic projection onto the complex plane. New Humbert series results
are also presented along with generating function formulas related to the
associated Meixner-Pollaczek polynomials.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:48:04 GMT""},{""version"":""v2"",""created"":""Tue, 22 Mar 2022 00:47:13 GMT""}]","2022-03-23"
"2203.07964","Simone Pagan Griso","Nazar Bartosik, Karol Krizka, Simone Pagan Griso, Chiara Aim\`e, Aram
  Apyan, Mohammed Attia Mahmoud, Alessandro Bertolin, Alessandro Braghieri,
  Laura Buonincontri, Simone Calzaferri, Massimo Casarsa, Luca Castelli, Maria
  Gabriella Catanesi, Francesco Giovanni Celiberto, Alessandro Cerri, Grigorios
  Chachamis, Anna Colaleo, Camilla Curatolo, Giacomo Da Molin, Sridhara Dasu,
  Dmitri Desinov, Haluk Denizli, Biagio Di Micco, Tommaso Dorigo, Filippo
  Errico, Anna Ferrari, Davide Fiorina, Luca Giambastiani, Alessio Gianelle,
  Carlo Giraldin, Matthew Herndon, Tova Ray Holmes, Sergo Jindariani, Georgios
  Krintiras, Lawrence Lee, Qiang Li, Ronald Lipton, S. Lomte, Kenneth Long,
  Donatella Lucchesi, Paola Mastrapasqua, Federico Meloni, Alessandro Montella,
  Federico Nardi, Nadia Pastrone, Antonello Pellecchia, Karolos Potamianos,
  Emilio Radicioni, Raffaella Radogna, Cristina Riccardi, Luciano Ristori,
  Paola Salvini, I. Sarra, Daniel Schulte, Abdulkadir Senol, Lorenzo Sestini,
  Federica Maria Simone, Rosa Simoniello, Anna Stamerra, Xiaohu Sun, Maximilian
  J Swiatlowski, Jian Tang, Emily Anne Thompson, Ilaria Vai, Marco Valente,
  Nicolo' Valle, Rosamaria Venditti, Piet Verwilligen, Hannsjorg Weber, Angela
  Zaza, Davide Zuliani","Simulated Detector Performance at the Muon Collider","contribution to Snowmass 2021",,,,"hep-ex hep-ph","http://creativecommons.org/licenses/by/4.0/","  In this paper we report on the current status of studies on the expected
performance for a detector designed to operate in a muon collider environment.
Beam-induced backgrounds (BIB) represent the main challenge in the design of
the detector and the event reconstruction algorithms. The current detector
design aims to show that satisfactory performance can be achieved, while
further optimizations are expected to significantly improve the overall
performance. We present the characterization of the expected beam-induced
background, describe the detector design and software used for detailed event
simulations taking into account BIB effects. The expected performance of
charged-particle reconstruction, jets, electrons, photons and muons is
discussed, including an initial study on heavy-flavor jet tagging. A simple
method to measure the delivered luminosity is also described. Overall, the
proposed design and reconstruction algorithms can successfully reconstruct the
high transverse-momentum objects needed to carry out a broad physics program.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:48:13 GMT""},{""version"":""v2"",""created"":""Fri, 12 Aug 2022 23:29:31 GMT""}]","2022-08-16"
"2203.07965","Ian Tillman","Ian J. Tillman, Allison Rubenok, Saikat Guha, Kaushik P. Seshadreesan","Supporting multiple entanglement flows through a continuous-variable
  quantum repeater","10 pages, 4 figures. Minor edits suggested by referees","Phys. Rev. A 106, 062611 (2022)","10.1103/PhysRevA.106.062611",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum repeaters are critical to the development of quantum networks,
enabling rates of entanglement distribution beyond those attainable by direct
transmission. We consider multiple continuous-variable, squeezed light-based
entanglement flows through a repeater involving noiseless linear amplification
and dual homodyne detection. By analyzing a single-repeater-enhanced channel
model with asymmetric losses across the repeater, we determine optimal
placements of the central repeater hub in a 4-user hub-and-spoke network such
that the rate of each entanglement flow through the hub is enhanced.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:50:09 GMT""},{""version"":""v2"",""created"":""Thu, 13 Oct 2022 20:11:32 GMT""}]","2023-01-24"
"2203.07966","Bishwadeep Das","Bishwadeep Das, Elvin Isufi","Learning Expanding Graphs for Signal Interpolation",,,,,"eess.SP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Performing signal processing over graphs requires knowledge of the underlying
fixed topology. However, graphs often grow in size with new nodes appearing
over time, whose connectivity is typically unknown; hence, making more
challenging the downstream tasks in applications like cold start
recommendation. We address such a challenge for signal interpolation at the
incoming nodes blind to the topological connectivity of the specific node.
Specifically, we propose a stochastic attachment model for incoming nodes
parameterized by the attachment probabilities and edge weights. We estimate
these parameters in a data-driven fashion by relying only on the attachment
behaviour of earlier incoming nodes with the goal of interpolating the signal
value. We study the non-convexity of the problem at hand, derive conditions
when it can be marginally convexified, and propose an alternating projected
descent approach between estimating the attachment probabilities and the edge
weights. Numerical experiments with synthetic and real data dealing in cold
start collaborative filtering corroborate our findings.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:51:29 GMT""}]","2022-03-16"
"2203.07967","Daniel Grittner","Lukas Koestler, Daniel Grittner, Michael Moeller, Daniel Cremers,
  Zorah L\""ahner","Intrinsic Neural Fields: Learning Functions on Manifolds",,,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural fields have gained significant attention in the computer vision
community due to their excellent performance in novel view synthesis, geometry
reconstruction, and generative modeling. Some of their advantages are a sound
theoretic foundation and an easy implementation in current deep learning
frameworks. While neural fields have been applied to signals on manifolds,
e.g., for texture reconstruction, their representation has been limited to
extrinsically embedding the shape into Euclidean space. The extrinsic embedding
ignores known intrinsic manifold properties and is inflexible wrt. transfer of
the learned function. To overcome these limitations, this work introduces
intrinsic neural fields, a novel and versatile representation for neural fields
on manifolds. Intrinsic neural fields combine the advantages of neural fields
with the spectral properties of the Laplace-Beltrami operator. We show
theoretically that intrinsic neural fields inherit many desirable properties of
the extrinsic neural field framework but exhibit additional intrinsic
qualities, like isometry invariance. In experiments, we show intrinsic neural
fields can reconstruct high-fidelity textures from images with state-of-the-art
quality and are robust to the discretization of the underlying manifold. We
demonstrate the versatility of intrinsic neural fields by tackling various
applications: texture transfer between deformed shapes & different shapes,
texture reconstruction from real-world images with view dependence, and
discretization-agnostic learning on meshes and point clouds.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:52:52 GMT""},{""version"":""v2"",""created"":""Thu, 17 Mar 2022 13:07:55 GMT""},{""version"":""v3"",""created"":""Wed, 23 Mar 2022 13:46:13 GMT""}]","2022-03-24"
"2203.07968","Hayato Arai","Hayato Arai and Masahito Hayashi","Pseudo standard entanglement structure cannot be distinguished from
  standard entanglement structure","The previous version contains two wrong statements (Theorem3 and
  existence of G-symmetric self-dual models in the previous version). In order
  to replace them with correct statements, we revise mainly the following three
  points from the previous version. 1. Definition of pseudo standard
  entanglement structure. 2. Construction of our examples. 3. Statements and
  proofs for discrimination",,"10.1088/1367-2630/acb565",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An experimental verification of the maximally entangled state ensures that
the constructed state is close to the maximally entangled state, but it does
not guarantee that the state is exactly the same as the maximally entangled
state. Further, the entanglement structure is not uniquely determined in
general probabilistic theories even if we impose that the local subsystems are
fully equal to quantum systems. Therefore, the existence of the maximally
entangled state depends on whether the standard entanglement structure is
valid. To examine this issue, we introduce pseudo standard entanglement
structure as a structure of quantum composite system under natural assumptions
based on the existence of projective measurements and the existence of
approximations of all maximally entangled standard states. Surprisingly, there
exist infinitely many pseudo standard entanglement structures different from
the standard entanglement structure. In our setting, any maximally entangled
state can be arbitrarily approximated by an entangled state that belongs to our
obtained pseudo standard entanglement structure. That is, experimental
verification does not exclude the possibility of our obtained pseudo standard
entanglement structure that is different from the standard entanglement
structure. On the other hand, such pseudo structures never possess global
unitary symmetry, i.e., global unitary symmetry is essential condition for the
standard entanglement structure.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:56:43 GMT""},{""version"":""v2"",""created"":""Wed, 25 May 2022 22:03:25 GMT""},{""version"":""v3"",""created"":""Fri, 23 Dec 2022 01:23:55 GMT""}]","2023-02-22"
"2203.07969","Mohamed Nabeel","Udesh Kumarasinghe, Fatih Deniz, Mohamed Nabeel","PDNS-Net: A Large Heterogeneous Graph Benchmark Dataset of Network
  Resolutions for Graph Learning","Workshop on Graph Learning Benchmark 2022",,,,"cs.LG cs.CR","http://creativecommons.org/licenses/by/4.0/","  In order to advance the state of the art in graph learning algorithms, it is
necessary to construct large real-world datasets. While there are many
benchmark datasets for homogeneous graphs, only a few of them are available for
heterogeneous graphs. Furthermore, the latter graphs are small in size
rendering them insufficient to understand how graph learning algorithms perform
in terms of classification metrics and computational resource utilization. We
introduce, PDNS-Net, the largest public heterogeneous graph dataset containing
447K nodes and 897K edges for the malicious domain classification task.
Compared to the popular heterogeneous datasets IMDB and DBLP, PDNS-Net is 38
and 17 times bigger respectively. We provide a detailed analysis of PDNS-Net
including the data collection methodology, heterogeneous graph construction,
descriptive statistics and preliminary graph classification performance. The
dataset is publicly available at https://github.com/qcri/PDNS-Net. Our
preliminary evaluation of both popular homogeneous and heterogeneous graph
neural networks on PDNS-Net reveals that further research is required to
improve the performance of these models on large heterogeneous graphs.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:57:20 GMT""}]","2022-03-16"
"2203.07970","Arunav Bordoloi","Arunav Bordoloi, Valentina Zannier, Lucia Sorba, Christian
  Sch\""onenberger, Andreas Baumgartner","Spin Cross-Correlation Experiments in an Electron Entangler",,"Nature 612, 454-458 (2022)","10.1038/s41586-022-05436-z",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Correlations are fundamental in describing many body systems - not only in
natural sciences. However, in experiments, correlations are notoriously
difficult to assess on the microscopic scale, especially for electron spins.
Here, we demonstrate a direct measurement of the spin cross-correlations
between the currents of a Cooper pair splitter, an electronic device that emits
electrons originating from Cooper pairs in a superconductor. While it is firmly
established theoretically that these electron pairs form maximally
spin-entangled singlet states with opposite spin projections, no spin
correlation experiments have been demonstrated so far. We use ferromagnetic
sidegates, compatible with superconducting electronic structures, to
individually spin polarize the transmissions of two quantum dots fabricated in
the two electronic paths, which act as tunable spin filters. The signals are
detected in standard transport and in highly sensitive transconductance
experiments. We find that the spin-cross correlation is negative, compatible
with spin singlet emission, and deviates from the ideal value mostly due to a
finite overlap of the Zeeman split quantum dot states. Our results demonstrate
a new route to perform spin auto- and cross correlation experiments in
nanometer scaled electronic devices, especially suitable for those relying on
magnetic field sensitive superconducting elements, like unconventional, triplet
or topologically non-trivial superconductors, or to perform Bell tests with
massive particles, like electrons.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:57:50 GMT""}]","2022-12-20"
"2203.07971","Konstantin G. Wirth","Konstantin G. Wirth, Jonas B. Hauck, Alexander Rothstein, Hristiyana
  Kyoseva, Dario Siebenkotten, Lukas Conrads, Lennart Klebl, Ammon Fischer,
  Bernd Beschoten, Christoph Stampfer, Dante M. Kennes, Lutz Waldecker, Thomas
  Taubner","Experimental observation of ABCB stacked tetralayer graphene",,"ACS Nano 2022, 16, 10, 16617-16623","10.1021/acsnano.2c06053",,"cond-mat.mes-hall physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In tetralayer graphene, three inequivalent layer stackings should exist,
however, only rhombohedral (ABCA) and Bernal (ABAB) stacking have so far been
observed. The three stacking sequences differ in their electronic structure,
with the elusive third stacking (ABCB) being unique as it is predicted to
exhibit an intrinsic bandgap as well as locally flat bands around the K points.
Here, we use scattering-type scanning near-field optical microscopy and
confocal Raman microscopy to identify and characterize domains of ABCB stacked
tetralayer graphene. We differentiate between the three stacking sequences by
addressing characteristic interband contributions in the optical conductivity
between 0.28 and 0.56 eV with amplitude and phase-resolved near-field
nano-spectroscopy. By normalizing adjacent flakes to each other, we achieve
good agreement between theory and experiment, allowing for the unambiguous
assignment of ABCB domains in tetralayer graphene. These results establish
near-field spectroscopy at the interband transitions as a semi-quantitative
tool, enabling the recognition of ABCB domains in tetralyer graphene flakes and
therefore, providing a basis to study correlation physics of this exciting
phase.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:58:34 GMT""},{""version"":""v2"",""created"":""Thu, 15 Sep 2022 16:10:07 GMT""}]","2022-12-09"
"2203.07972","Vuk Mandic","Robert Caldwell, Yanou Cui, Huai-Ke Guo, Vuk Mandic, Alberto Mariotti,
  Jose Miguel No, Michael J. Ramsey-Musolf, Mairi Sakellariadou, Kuver Sinha,
  Lian-Tao Wang, Graham White, Yue Zhao, Haipeng An, Chiara Caprini, Sebastien
  Clesse, James Cline, Giulia Cusin, Ryusuke Jinno, Benoit Laurent, Noam Levi,
  Kunfeng Lyu, Mario Martinez, Andrew Miller, Diego Redigolo, Claudia Scarlata,
  Alexander Sevrin, Barmak Shams Es Haghi, Jing Shu, Xavier Siemens, Daniele A.
  Steer, Raman Sundrum, Carlos Tamarit, David J. Weir, Bartosz Fornal, Ke-Pan
  Xie, Fengwei Yang, Siyi Zhou","Detection of Early-Universe Gravitational Wave Signatures and
  Fundamental Physics","contribution to Snowmass 2021; 3 figures, 67 pages","Gen Relativ Gravit 54, 156 (2022)","10.1007/s10714-022-03027-x",,"gr-qc hep-ph hep-th","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Detection of a gravitational-wave signal of non-astrophysical origin would be
a landmark discovery, potentially providing a significant clue to some of our
most basic, big-picture scientific questions about the Universe. In this white
paper, we survey the leading early-Universe mechanisms that may produce a
detectable signal -- including inflation, phase transitions, topological
defects, as well as primordial black holes -- and highlight the connections to
fundamental physics. We review the complementarity with collider searches for
new physics, and multimessenger probes of the large-scale structure of the
Universe.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:01:12 GMT""},{""version"":""v2"",""created"":""Thu, 22 Dec 2022 19:44:37 GMT""}]","2022-12-26"
"2203.07973","Luca Ciampi","Donato Cafarelli and Luca Ciampi and Lucia Vadicamo and Claudio
  Gennaro and Andrea Berton and Marco Paterni and Chiara Benvenuti and Mirko
  Passera and Fabrizio Falchi","MOBDrone: a Drone Video Dataset for Man OverBoard Rescue","Accepted at ICIAP 2021",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Modern Unmanned Aerial Vehicles (UAV) equipped with cameras can play an
essential role in speeding up the identification and rescue of people who have
fallen overboard, i.e., man overboard (MOB). To this end, Artificial
Intelligence techniques can be leveraged for the automatic understanding of
visual data acquired from drones. However, detecting people at sea in aerial
imagery is challenging primarily due to the lack of specialized annotated
datasets for training and testing detectors for this task. To fill this gap, we
introduce and publicly release the MOBDrone benchmark, a collection of more
than 125K drone-view images in a marine environment under several conditions,
such as different altitudes, camera shooting angles, and illumination. We
manually annotated more than 180K objects, of which about 113K man overboard,
precisely localizing them with bounding boxes. Moreover, we conduct a thorough
performance analysis of several state-of-the-art object detectors on the
MOBDrone data, serving as baselines for further research.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:02:23 GMT""}]","2022-03-16"
"2203.07974","Jun Yang","Jun Yang","Plancherel Measures of Reductive Adelic Groups and Von Neumann
  Dimensions","18 pages",,,,"math.RT math.NT math.OA","http://creativecommons.org/licenses/by/4.0/","  Given a number field $F$ and a reductive group $G$ over $F$, the unitary dual
$\hat{G(\mathbb{A}_F)}$ of the adelic group $G(\mathbb{A}_F)$ and the Placherel
measure $\nu_{G(\mathbb{A}_F)}$ on it can be determined by the Plancherel
measure of its local groups $G(F_v)$. Given a subset $X\subset
\hat{G(\mathbb{A}_F)}$ of finite Plancherel measure, let $H_X$ be the direct
integral of the irreducible representations in $X$. Besides a
$G(\mathbb{A}_F)$-module and a $G(F)$-module, $H_X$ is also a module over the
group von Neumann algebra $\mathcal{L}(G(F))$, hence there is a canonical
dimension $\dim_{\mathcal{L}(G(F))}H_X\in [0,\infty)$. It is proved that the
Plancherel measure of $G(\mathbb{A}_F)$ coincides with the dimension over the
algebra $\mathcal{L}(G(F))$:
$\dim_{\mathcal{L}(G(F))}H_X=\nu_{G(\mathbb{A}_F)}(X)$, if $G$ is semisimple,
simply connected and $G(\mathbb{A}_F)$ is equipped with the Tamagawa measure.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:04:26 GMT""},{""version"":""v2"",""created"":""Mon, 1 Aug 2022 01:34:58 GMT""}]","2022-08-02"
"2203.07975","Artan Sheshmani","Artan Sheshmani and Yizhuang You and Wenbo Fu and Ahmadreza Azizi","Categorical Representation Learning and RG flow operators for
  algorithmic classifiers","31 pages, comments are very welcome","Machine Learning: Science and Technology, 2023","10.1088/2632-2153/acb488",,"cs.LG cond-mat.dis-nn cs.AI math.AG math.CT math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Following the earlier formalism of the categorical representation learning
(arXiv:2103.14770) by the first two authors, we discuss the construction of the
""RG-flow based categorifier"". Borrowing ideas from theory of renormalization
group flows (RG) in quantum field theory, holographic duality, and hyperbolic
geometry, and mixing them with neural ODE's, we construct a new algorithmic
natural language processing (NLP) architecture, called the RG-flow categorifier
or for short the RG categorifier, which is capable of data classification and
generation in all layers. We apply our algorithmic platform to biomedical data
sets and show its performance in the field of sequence-to-function mapping. In
particular we apply the RG categorifier to particular genomic sequences of flu
viruses and show how our technology is capable of extracting the information
from given genomic sequences, find their hidden symmetries and dominant
features, classify them and use the trained data to make stochastic prediction
of new plausible generated sequences associated with new set of viruses which
could avoid the human immune system. The content of the current article is part
of the recent US patent application submitted by first two authors (U.S. Patent
Application No.: 63/313.504).
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:04:51 GMT""}]","2023-01-25"
"2203.07976","Dominik Rivoir","Dominik Rivoir, Isabel Funke, Stefanie Speidel","On the Pitfalls of Batch Normalization for End-to-End Video Learning: A
  Study on Surgical Workflow Analysis",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Batch Normalization's (BN) unique property of depending on other samples in a
batch is known to cause problems in several tasks, including sequential
modeling. Yet, BN-related issues are hardly studied for long video
understanding, despite the ubiquitous use of BN in CNNs for feature extraction.
Especially in surgical workflow analysis, where the lack of pretrained feature
extractors has lead to complex, multi-stage training pipelines, limited
awareness of BN issues may have hidden the benefits of training CNNs and
temporal models end to end. In this paper, we %present and analyze known as
well as novel pitfalls of BN in video learning, including issues specific to
online tasks such as a 'cheating' effect in anticipation. We observe that BN's
properties create major obstacles for end-to-end learning. However, using
BN-free backbones, even simple CNN-LSTMs beat state of the art in two surgical
tasks by utilizing adequate end-to-end training strategies which maximize
temporal context. We conclude that awareness of BN's pitfalls is crucial for
effective end-to-end learning in surgical tasks. By reproducing results on
natural-video datasets, we hope our insights will benefit other areas of video
learning as well. Code: \url{https://gitlab.com/nct_tso_public/pitfalls_bn}.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:05:40 GMT""},{""version"":""v2"",""created"":""Thu, 16 Mar 2023 10:16:49 GMT""}]","2023-03-17"
"2203.07977","Wenbin Lin","Wenbin Lin, Chengwei Zheng, Jun-Hai Yong, Feng Xu","OcclusionFusion: Occlusion-aware Motion Estimation for Real-time Dynamic
  3D Reconstruction","Accepted by CVPR 2022. Project page:
  https://wenbin-lin.github.io/OcclusionFusion",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  RGBD-based real-time dynamic 3D reconstruction suffers from inaccurate
inter-frame motion estimation as errors may accumulate with online tracking.
This problem is even more severe for single-view-based systems due to strong
occlusions. Based on these observations, we propose OcclusionFusion, a novel
method to calculate occlusion-aware 3D motion to guide the reconstruction. In
our technique, the motion of visible regions is first estimated and combined
with temporal information to infer the motion of the occluded regions through
an LSTM-involved graph neural network. Furthermore, our method computes the
confidence of the estimated motion by modeling the network output with a
probabilistic model, which alleviates untrustworthy motions and enables robust
tracking. Experimental results on public datasets and our own recorded data
show that our technique outperforms existing single-view-based real-time
methods by a large margin. With the reduction of the motion errors, the
proposed technique can handle long and challenging motion sequences. Please
check out the project page for sequence results:
https://wenbin-lin.github.io/OcclusionFusion.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:09:01 GMT""}]","2022-03-16"
"2203.07978","Wei Xiao","Wei Xiao and Christos G. Cassandras and Calin A. Belta and Daniela Rus","Control Barrier Functions for Systems with Multiple Control Inputs","To appear in ACC2022",,,,"eess.SY cs.RO cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Control Barrier Functions (CBFs) are becoming popular tools in guaranteeing
safety for nonlinear systems and constraints, and they can reduce a constrained
optimal control problem into a sequence of Quadratic Programs (QPs) for affine
control systems. The recently proposed High Order Control Barrier Functions
(HOCBFs) work for arbitrary relative degree constraints. One of the challenges
in a HOCBF is to address the relative degree problem when a system has multiple
control inputs, i.e., the relative degree could be defined with respect to
different components of the control vector. This paper proposes two methods for
HOCBFs to deal with systems with multiple control inputs: a general integral
control method and a method which is simpler but limited to specific classes of
physical systems. When control bounds are involved, the feasibility of the
above mentioned QPs can also be significantly improved with the proposed
methods. We illustrate our approaches on a unicyle model with two control
inputs, and compare the two proposed methods to demonstrate their effectiveness
and performance.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:10:47 GMT""}]","2023-01-02"
"2203.07979","Rui Zhang","Rui Zhang, Li-Zheng Liu, Zheng-Da Li, Yue-Yang Fei, Xu-Fei Yin, Li Li,
  Nai-Le Liu, Yingqiu Mao, Yu-Ao Chen, and Jian-Wei Pan","Loss-tolerant all-photonic quantum repeater with generalized Shor code","8 pages, 5 figures","Optica 9, 152-158 (2022)","10.1364/OPTICA.439170",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The all-photonic quantum repeater (APQR) is a promising repeater scheme to
realize long-distance quantum communication. For a practical APQR, an
indispensable requirement is the robustness of the repeater graph state (RGS)
against photon loss. We propose a new loss-tolerant scheme by applying the
generalized Shor code to RGS, which can be experimentally demonstrated with
current technology. Experimentally, we first prepare and verify the nine-qubit
Shor code. Then, by applying the generalized Shor code to APQR and preparing a
simplified encoded RGS with the structure of $1\times2$ based on the Shor code
state, the effectiveness of our loss-tolerant scheme and the loss tolerance of
the encoded RGS are respectively verified. Our results make an essential step
toward a practical APQR and enrich the research of quantum error correction
code.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:12:15 GMT""}]","2022-03-16"
"2203.07980","Georg Hess","Georg Hess, Christoffer Petersson, Lennart Svensson","Object Detection as Probabilistic Set Prediction",,"European Conference on Computer Vision (ECCV). (2022) 550-566","10.1007/978-3-031-20080-9_32",,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Accurate uncertainty estimates are essential for deploying deep object
detectors in safety-critical systems. The development and evaluation of
probabilistic object detectors have been hindered by shortcomings in existing
performance measures, which tend to involve arbitrary thresholds or limit the
detector's choice of distributions. In this work, we propose to view object
detection as a set prediction task where detectors predict the distribution
over the set of objects. Using the negative log-likelihood for random finite
sets, we present a proper scoring rule for evaluating and training
probabilistic object detectors. The proposed method can be applied to existing
probabilistic detectors, is free from thresholds, and enables fair comparison
between architectures. Three different types of detectors are evaluated on the
COCO dataset. Our results indicate that the training of existing detectors is
optimized toward non-probabilistic metrics. We hope to encourage the
development of new object detectors that can accurately estimate their own
uncertainty. Code available at https://github.com/georghess/pmb-nll.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:13:52 GMT""},{""version"":""v2"",""created"":""Wed, 16 Mar 2022 15:54:13 GMT""},{""version"":""v3"",""created"":""Wed, 13 Jul 2022 17:10:35 GMT""}]","2022-12-09"
"2203.07981","Ketan Rikame","Ketan Rikame, Biswajit Paul, Pragati Pradhan, KT Paul","Discovery of Quasi Periodic Oscillations in the persistent X-ray
  emission of Accreting Binary X-ray Pulsar LMC X-4","6 pages, 4 figures, Accepted for publication in MNRAS",,"10.1093/mnras/stac729",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the discovery of quasi-periodic oscillations (QPOs) in the High
Mass X-ray Binary (HMXB) pulsar LMC X-4 in its non-flaring (persistent) state
using observations with XMM-Newton. In addition to the 74 mHz coherent
pulsations, the persistent emission light curve shows a QPO feature in the
frequency range of 20-30 mHz. Quasi-periodic flares have been previously
observed from LMC X-4 in observations made with Rossi X-ray Timing Explorer
(RXTE). However, this is the first time QPOs have been observed in the
persistent emission observations of LMC X-4. QPOs in X-ray binaries are
generally thought to be related to the rotation of the inhomogeneous matter
distribution in the inner accretion disk. In High Mass X-ray Binaries (HMXBs)
such as LMC X-4 where the compact object is a neutron star with a high magnetic
field, the radius of the inner accretion disk is determined by the mass
accretion rate and the magnetic moment of the neutron star. In such systems,
the QPO feature, along with the pulse period and X-ray luminosity measurement
helps us to constrain the magnetic field strength of the neutron star. We use
considerations of magnetospheric accretion to have an approximate value of the
magnetic field strength of the neutron star in LMC X-4.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:14:03 GMT""}]","2022-03-30"
"2203.07982","Sarah Winkler","Paolo Felli, Marco Montali, Sarah Winkler","Linear-Time Verification of Data-Aware Dynamic Systems with Arithmetic",,,,,"cs.LO cs.AI","http://creativecommons.org/licenses/by/4.0/","  Combined modeling and verification of dynamic systems and the data they
operate on has gained momentum in AI and in several application domains. We
investigate the expressive yet concise framework of data-aware dynamic systems
(DDS), extending it with linear arithmetic, and provide the following
contributions. First, we introduce a new, semantic property of ""finite
summary"", which guarantees the existence of a faithful finite-state
abstraction. We rely on this to show that checking whether a witness exists for
a linear-time, finite-trace property is decidable for DDSs with finite summary.
Second, we demonstrate that several decidability conditions studied in formal
methods and database theory can be seen as concrete, checkable instances of
this property. This also gives rise to new decidability results. Third, we show
how the abstract, uniform property of finite summary leads to modularity
results: a system enjoys finite summary if it can be partitioned appropriately
into smaller systems that possess the property. Our results allow us to analyze
systems that were out of reach in earlier approaches. Finally, we demonstrate
the feasibility of our approach in a prototype implementation.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:14:25 GMT""}]","2022-03-16"
"2203.07984","Thomas Y. Chen","Masha Baryakhtar, Regina Caputo, Djuna Croon, Kerstin Perez, Emanuele
  Berti, Joseph Bramante, Malte Buschmann, Richard Brito, Thomas Y. Chen,
  Philippa S. Cole, Adam Coogan, William E. East, Joshua W. Foster, Marios
  Galanis, Maurizio Giannotti, Bradley J. Kavanagh, Ranjan Laha, Rebecca K.
  Leane, Benjamin V. Lehmann, Gustavo Marques-Tavares, Jamie McDonald, Ken K.
  Y. Ng, Nirmal Raj, Laura Sagunski, Jeremy Sakstein, B.S. Sathyaprakash, Sarah
  Shandera, Nils Siemonsen, Olivier Simon, Kuver Sinha, Divya Singh, Rajeev
  Singh, Chen Sun, Ling Sun, Volodymyr Takhistov, Yu-Dai Tsai, Edoardo
  Vitagliano, Salvatore Vitale, Huan Yang, Jun Zhang","Dark Matter In Extreme Astrophysical Environments","Contribution to Snowmass 2021 -- CF3. Dark Matter: Cosmic Probes",,,,"hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Exploring dark matter via observations of extreme astrophysical environments
-- defined here as heavy compact objects such as white dwarfs, neutron stars,
and black holes, as well as supernovae and compact object merger events -- has
been a major field of growth since the last Snowmass process. Theoretical work
has highlighted the utility of current and near-future observatories to
constrain novel dark matter parameter space across the full mass range. This
includes gravitational wave instruments and observatories spanning the
electromagnetic spectrum, from radio to gamma-rays. While recent searches
already provide leading sensitivity to various dark matter models, this work
also highlights the need for theoretical astrophysics research to better
constrain the properties of these extreme astrophysical systems. The unique
potential of these search signatures to probe dark matter adds motivation to
proposed next-generation astronomical and gravitational wave instruments.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:15:02 GMT""},{""version"":""v2"",""created"":""Sun, 29 May 2022 20:23:34 GMT""},{""version"":""v3"",""created"":""Mon, 7 Nov 2022 05:48:05 GMT""}]","2022-11-08"
"2203.07985","Rui Vilela-Mendes","Tanya Ara\'ujo and R. Vilela Mendes","Long-range connections, real-world networks and rates of diffusion","25 pages Latex, 17 figures",,,,"nlin.AO","http://creativecommons.org/licenses/by/4.0/","  Long range connections play an essential role in dynamical processes on
networks, on the processing of information in biological networks, on the
structure of social and economical networks and in the propagation of opinions
and epidemics. Here we review the evidence for long range connections in real
world networks and discuss the nature of the nonlocal diffusion arising from
different distance-dependent laws. Particular attention is devoted to
exponential and power laws.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:17:58 GMT""}]","2022-03-16"
"2203.07986","Shiyong Zhu","Shiyong Zhu, Jianquan Lu, Liangjie Sun, Jinde Cao","Distributed Pinning Set Stabilization of Large-Scale Boolean Networks",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we design the distributed pinning controllers to globally
stabilize a Boolean network (BN), specially a sparsely connected large-scale
one, towards a preassigned subset of state space through the node-to-node
message exchange. Given an appointed state set, system nodes are partitioned
into two disjoint parts, which respectively gather the nodes whose states are
fixed or arbitrary with respect to the given state set. With such node
division, three parts of pinned nodes are selected and the state feedback
controllers are accordingly designed such that the resulting BN satisfies three
conditions: the states of the other nodes cannot affect the nodal dynamics of
fixed-state nodes, the subgraph of network structure induced by the fixed-state
nodes is acyclic, and the steady state of the subnetwork induced by the
fixed-state nodes lies in the state set given beforehand. If the BN after
control is acyclic, the stabilizing time is revealed to be no more than the
length of the longest path in the current network structure plus one. This
enables us to further design the pinning controllers with the constraint of
stabilizing time. Noting that the overall procedure runs in an exponentially
increasing time with respect to the largest number of functional variables in
the dynamics of pinned nodes, the sparsely-connected large-scale BNs can be
well addressed in a reasonable amount of time. Finally, we demonstrate the
applications of our theoretical results in a T-LGL survival signal network with
$29$ nodes and T-cell receptor signaling network with $90$ nodes.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:19:09 GMT""}]","2022-03-16"
"2203.07987","Jingyu Tang PhD","Jingyu Tang, Yuhong Zhang, Qingjin Xu, Jie Gao, Xinchou Lou, Yifang
  Wang","Study Overview for Super Proton-Proton Collider","contribution to Snowmass 2021",,,,"hep-ex physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  SPPC (Super Proton-Proton Collider) is a discovery machine that is designed
for energy frontier research in two decades from now, as the second stage of
the CEPC-SPPC project. The main objective is to carry out experiments at 125
TeV in center-of-mass energy in a two-ring collider of 100 km in circumference
and 20 T in dipole field. This white paper about SPPC describes the machine
related issues, including performance, design overview, design challenges, key
technologies and their maturity and required R&D, staged options and upgrades,
synergies with other facilities, and environmental impacts.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:20:08 GMT""},{""version"":""v2"",""created"":""Wed, 30 Mar 2022 09:10:24 GMT""}]","2022-03-31"
"2203.07988","Runfa Chen","Runfa Chen, Yu Rong, Shangmin Guo, Jiaqi Han, Fuchun Sun, Tingyang Xu,
  Wenbing Huang","Smoothing Matters: Momentum Transformer for Domain Adaptive Semantic
  Segmentation",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  After the great success of Vision Transformer variants (ViTs) in computer
vision, it has also demonstrated great potential in domain adaptive semantic
segmentation. Unfortunately, straightforwardly applying local ViTs in domain
adaptive semantic segmentation does not bring in expected improvement. We find
that the pitfall of local ViTs is due to the severe high-frequency components
generated during both the pseudo-label construction and features alignment for
target domains. These high-frequency components make the training of local ViTs
very unsmooth and hurt their transferability. In this paper, we introduce a
low-pass filtering mechanism, momentum network, to smooth the learning dynamics
of target domain features and pseudo labels. Furthermore, we propose a dynamic
of discrepancy measurement to align the distributions in the source and target
domains via dynamic weights to evaluate the importance of the samples. After
tackling the above issues, extensive experiments on sim2real benchmarks show
that the proposed method outperforms the state-of-the-art methods. Our codes
are available at https://github.com/alpc91/TransDA
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:20:30 GMT""}]","2022-03-16"
"2203.07989","Andrew J. Turner","Andrew J. Turner and Ata Kab\'an","Approximability and Generalisation","25 pages",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Approximate learning machines have become popular in the era of small
devices, including quantised, factorised, hashed, or otherwise compressed
predictors, and the quest to explain and guarantee good generalisation
abilities for such methods has just begun. In this paper we study the role of
approximability in learning, both in the full precision and the approximated
settings of the predictor that is learned from the data, through a notion of
sensitivity of predictors to the action of the approximation operator at hand.
We prove upper bounds on the generalisation of such predictors, yielding the
following main findings, for any PAC-learnable class and any given
approximation operator. 1) We show that under mild conditions, approximable
target concepts are learnable from a smaller labelled sample, provided
sufficient unlabelled data. 2) We give algorithms that guarantee a good
predictor whose approximation also enjoys the same generalisation guarantees.
3) We highlight natural examples of structure in the class of sensitivities,
which reduce, and possibly even eliminate the otherwise abundant requirement of
additional unlabelled data, and henceforth shed new light onto what makes one
problem instance easier to learn than another. These results embed the scope of
modern model compression approaches into the general goal of statistical
learning theory, which in return suggests appropriate algorithms through
minimising uniform bounds.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:21:48 GMT""}]","2022-03-16"
"2203.07991","Joel K\""ubler","Joel K\""ubler, Tobias Weth","Rotating waves in nonlinear media and critical degenerate Sobolev
  inequalities","45 pages, typos corrected",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the presence of rotating wave solutions of the nonlinear wave
equation $\partial_t^2 v - \Delta v +m v = |v|^{p-2} v$ in $\mathbb{R} \times
\mathbf{B}$, where $\mathbf{B} \subset \mathbb{R}^N$ is the unit ball,
complemented with Dirichlet boundary conditions on $\mathbb{R} \times
\partial\mathbf{B}$. Depending on the prescribed angular velocity $\alpha$ of
the rotation, this leads to a Dirichlet problem for a semilinear elliptic or
degenerate elliptic equation. We show that this problem is governed by an
associated critical degenerate Sobolev inequality in the half space. After
proving this inequality and the existence of associated extremal functions, we
then deduce necessary and sufficient conditions for the existence of ground
state solutions. Moreover, we analyze under which conditions on $\alpha$, $m$
and $p$ these ground states are nonradial and therefore give rise to truly
rotating waves. Our approach carries over to the corresponding Dirichlet
problems in an annulus and in more general Riemannian models with boundary,
including the hemisphere. We briefly discuss these problems and show that they
are related to a larger family of associated critical degenerate Sobolev
inequalities.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:24:25 GMT""},{""version"":""v2"",""created"":""Thu, 7 Apr 2022 18:11:03 GMT""}]","2022-04-11"
"2203.07992","Joseph Feneuil","Zanbing Dai, Joseph Feneuil, and Svitlana Mayboroda","Carleson Perturbations for the Regularity Problem","50 pages",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We prove that the solvability of the regularity problem in $L^q(\partial
\Omega)$ is stable under Carleson perturbations. If the perturbation is small,
then the solvability is preserved in the same $L^q$, and if the perturbation is
large, the regularity problem is solvable in $L^{r}$ for some other $r\in
(1,\infty)$. We extend an earlier result from Kenig and Pipher to very general
unbounded domains, possibly with lower dimensional boundaries as in the theory
developed by Guy David and the last two authors. To be precise, we only need
the domain to have non-tangential access to its Ahlfors regular boundary,
together with a notion of gradient on the boundary.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:27:14 GMT""},{""version"":""v2"",""created"":""Mon, 1 Aug 2022 05:00:31 GMT""}]","2022-08-02"
"2203.07993","Kai Chen","Kai Chen, Ye Wang, Yitong Li and Aiping Li","RotateQVS: Representing Temporal Information as Rotations in Quaternion
  Vector Space for Temporal Knowledge Graph Completion","To appear in ACL 2022 main conference",,,,"cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Temporal factors are tied to the growth of facts in realistic applications,
such as the progress of diseases and the development of political situation,
therefore, research on Temporal Knowledge Graph (TKG) attracks much attention.
In TKG, relation patterns inherent with temporality are required to be studied
for representation learning and reasoning across temporal facts. However,
existing methods can hardly model temporal relation patterns, nor can capture
the intrinsic connections between relations when evolving over time, lacking of
interpretability. In this paper, we propose a novel temporal modeling method
which represents temporal entities as Rotations in Quaternion Vector Space
(RotateQVS) and relations as complex vectors in Hamilton's quaternion space. We
demonstrate our method can model key patterns of relations in TKG, such as
symmetry, asymmetry, inverse, and can further capture time-evolved relations by
theory. Empirically, we show that our method can boost the performance of link
prediction tasks over four temporal knowledge graph benchmarks.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:27:23 GMT""},{""version"":""v2"",""created"":""Thu, 17 Mar 2022 03:31:46 GMT""}]","2022-03-18"
"2203.07994","Marc-Andr\'e Pleier","Aram Apyan, Chilufya Mwewa, Luka Nedic, Marc-Andr\'e Pleier, Karolos
  Potamianos","Sensitivity to longitudinal vector boson scattering in $\mathbf{W^\pm
  W^\pm jj}$ at future hadron colliders","11 pages, 3 figures, 3 tables. Submitted to the Proceedings of the US
  Community Study on the Future of Particle Physics (Snowmass 2021)",,,,"hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  We study the sensitivity to longitudinal vector boson scattering at a 27, 50
and 100 TeV $pp$ collider using events containing two leptonically-decaying
same-electric-charge $W$ bosons produced in association with two jets.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:27:33 GMT""},{""version"":""v2"",""created"":""Mon, 9 May 2022 16:03:53 GMT""}]","2022-05-10"
"2203.07995","Michael Headley","R. Zens, M. Headley, D. Wolf, A. Markovitz, F. Dukes, J. Tang, K.
  Bloom, V. Boisvert","Societal impacts of particle physics projects","contribution to Snowmass 2021",,,,"hep-ex physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large particle physics projects funded by the U.S. Government require an
evaluation and mitigation of each project's potential impacts on the local
communities. However, beyond meeting governmental requirements, particle
physics projects stand to play an essential role in local decision-making,
building relationships, and framing discussions about key projects by becoming
meaningfully engaged in their local communities. In this white paper for the
U.S. Particle Physics Community Planning Exercise (Snowmass), we examine
several local community engagement efforts made by three facilities: Lawrence
Berkeley National Laboratory (Berkeley Lab), Fermi National Accelerator
Laboratory (Fermilab), and the Sanford Underground Research Facility (SURF).
Although each facility focuses on a different endeavor in varying types of
communities, each study highlights the importance and benefits of employing
consistent outreach techniques, promoting diversity, establishing lasting
relationships, and creating environments for open and honest communication.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:28:03 GMT""}]","2022-03-16"
"2203.07997","Hanrong Ye","Hanrong Ye and Dan Xu","InvPT: Inverted Pyramid Multi-task Transformer for Dense Scene
  Understanding","Published in ECCV 2022 Conference. Code is available at
  https://github.com/prismformore/InvPT","ECCV 2022",,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Multi-task dense scene understanding is a thriving research domain that
requires simultaneous perception and reasoning on a series of correlated tasks
with pixel-wise prediction. Most existing works encounter a severe limitation
of modeling in the locality due to heavy utilization of convolution operations,
while learning interactions and inference in a global spatial-position and
multi-task context is critical for this problem. In this paper, we propose a
novel end-to-end Inverted Pyramid multi-task Transformer (InvPT) to perform
simultaneous modeling of spatial positions and multiple tasks in a unified
framework. To the best of our knowledge, this is the first work that explores
designing a transformer structure for multi-task dense prediction for scene
understanding. Besides, it is widely demonstrated that a higher spatial
resolution is remarkably beneficial for dense predictions, while it is very
challenging for existing transformers to go deeper with higher resolutions due
to huge complexity to large spatial size. InvPT presents an efficient
UP-Transformer block to learn multi-task feature interaction at gradually
increased resolutions, which also incorporates effective self-attention message
passing and multi-scale feature aggregation to produce task-specific prediction
at a high resolution. Our method achieves superior multi-task performance on
NYUD-v2 and PASCAL-Context datasets respectively, and significantly outperforms
previous state-of-the-arts. The code is available at
https://github.com/prismformore/InvPT
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:29:08 GMT""},{""version"":""v2"",""created"":""Mon, 18 Jul 2022 09:25:33 GMT""},{""version"":""v3"",""created"":""Mon, 7 Nov 2022 02:00:02 GMT""}]","2022-11-08"
"2203.08000","Gebhard Martin","Gebhard Martin, Giacomo Mezzedimi, Davide Cesare Veniani","Enriques surfaces of non-degeneracy 3","24 pages, v2: minor improvements and corrections",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We classify all non-extendable 3-sequences of half-fibers on Enriques
surfaces. If the characteristic is different from 2, we prove in particular
that every Enriques surface admits a 4-sequence, which implies that every
Enriques surface is the minimal desingularization of an Enriques sextic, and
that every Enriques surface is birational to a Castelnuovo quintic.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:32:03 GMT""},{""version"":""v2"",""created"":""Mon, 4 Jul 2022 14:37:27 GMT""}]","2022-07-05"
"2203.08001","Sergiy Vasylyev","Sergiy S. Vasylyev, Alexei V. Filippenko, Christian Vogl, Thomas G.
  Brink, Peter J. Brown, Thomas de Jaeger, Thomas Matheson, Avishay Gal-Yam,
  Paolo A. Mazzali, Maryam Modjaz, Kishore C. Patra, Micalyn Rowe, Nathan
  Smith, Schuyler D. Van Dyk, Marc Williamson, Yi Yang, WeiKang Zheng, Asia
  deGraw, Ori D. Fox, Elinor L. Gates, Connor Jennings, R. Michael Rich","Early-Time Ultraviolet Spectroscopy and Optical Follow-up Observations
  of the Type IIP Supernova 2021yja","Accepted to ApJ",,"10.3847/1538-4357/ac7220",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present three epochs of early-time ultraviolet (UV) and optical HST/STIS
spectroscopy of the young, nearby Type IIP supernova (SN) 2021yja. We
complement the HST data with two earlier epochs of Swift UVOT spectroscopy. The
HST and Swift UVOT spectra are consistent with those of other well-studied Type
IIP supernovae (SNe). The UV spectra exhibit rapid cooling at early times,
while less dramatic changes are seen in the optical. We also present Lick/KAIT
optical photometry up to the late-time-tail phase, showing a very long plateau
and shallow decline compared with other SNe IIP. Our modeling of the UV
spectrum with the TARDIS radiative-transfer code produces a good fit for a
high-velocity explosion, a low total extinction $E(B-V) = 0.07$ mag, and a
subsolar metallicity. We do not find a significant contribution to the UV flux
from an additional heating source, such as interaction with the circumstellar
medium, consistent with the observed flat plateau. Furthermore, the velocity
width of the Mg II $\lambda$2798 line is comparable to that of the hydrogen
Balmer lines, suggesting that the UV emission is confined to a region close to
the photosphere.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:32:56 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jul 2022 22:19:15 GMT""}]","2022-08-17"
"2203.08002","Ryan Mann","Michael J. Bremner, Zhengfeng Ji, Ryan L. Mann, Luke Mathieson, Mauro
  E.S. Morales, Alexis T.E. Shaw","Quantum Parameterized Complexity","23 pages, 1 figure",,,,"quant-ph cs.CC cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Parameterized complexity theory was developed in the 1990s to enrich the
complexity-theoretic analysis of problems that depend on a range of parameters.
In this paper we establish a quantum equivalent of classical parameterized
complexity theory, motivated by the need for new tools for the classifications
of the complexity of real-world problems. We introduce the quantum analogues of
a range of parameterized complexity classes and examine the relationship
between these classes, their classical counterparts, and well-studied problems.
This framework exposes a rich classification of the complexity of parameterized
versions of QMA-hard problems, demonstrating, for example, a clear separation
between the Quantum Circuit Satisfiability problem and the Local Hamiltonian
problem.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:34:38 GMT""}]","2022-03-16"
"2203.08003","Renata Ferrero","Renata Ferrero and Martin Reuter","The Spectral Geometry of de Sitter Space in Asymptotic Safety","64 pages, 13 figures",,"10.1007/JHEP08(2022)040","MITP-22-016","hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Within the functional renormalization group approach to Background
Independent quantum gravity, we explore the scale dependent effective geometry
of the de Sitter solution dS${}_4$. The investigation employs a novel approach
whose essential ingredient is a modified spectral flow of the metric dependent
d'Alembertian, or of similar hyperbolic kinetic operators. The corresponding
one-parameter family of spectra and eigenfunctions encodes information about
the nonperturbative backreaction of the dynamically gravitating vacuum
fluctuations on the mean field geometry of the quantum spacetime. Used as a
diagnostic tool, the power of the spectral flow method resides in its ability
to identify the scale dependent subsets of field modes that supply the degrees
of freedom which participate in the effective field theory description of the
respective scale. A central result is that the ultraviolet of Quantum Einstein
Gravity comprises far less effective degrees of freedom than predicted
(incorrectly) by background dependent reasoning. Exploring the quantum
spacetime's spatial geometry carried by physical fields, we find that
3-dimensional space disintegrates into a collection of coherent patches which
individually can, but in their entirety cannot be described by one of the
effective average actions occurring along the renormalization group trajectory.
A natural concept of an entropy is introduced in order to quantify this
fragmentation effect. Tentatively applied to the real Universe, surprising
analogies to properties of the observed cosmic microwave background are
uncovered. Furthermore, a set of distinguished field modes is found which, in
principle, has the ability to transport information about the asymptotic fixed
point regime from the ultraviolet, across almost the entire ""scale history"", to
cosmological distances in the observed Universe.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:35:31 GMT""},{""version"":""v2"",""created"":""Mon, 13 Jun 2022 13:11:00 GMT""}]","2022-08-24"
"2203.08004","Shu Chen","Yu Zhang, Bozhen Zhou, Haiping Hu, Shu Chen","Localization, multifractality, and many-body localization in
  periodically kicked quasiperiodic lattices","11 pages, 12 figures","Phys. Rev. B 106, 054312 (2022)","10.1103/PhysRevB.106.054312",,"cond-mat.dis-nn","http://creativecommons.org/licenses/by/4.0/","  We study the combined effect of quasiperiodic disorder, driven and
interaction in the periodically kicked Aubry-Andr\'{e} model. In the
non-interacting limit, by analyzing the quasienergy spectrum statistics, we
verify the existence of a dynamical localization transition in the
high-frequency region, whereas the spectrum statistics becomes intricate in the
low-frequency region due to the emergence of the
extended/localized-to-multifractal edges in the quasienergy spectrum, which
separate the multifractal states from the extended (localized) states. When the
interaction is introduced, we find the periodically kicked incommensurate
potential can lead to a transition from ergodic to many-body-localization phase
in the high-frequency region. However, the many-body localization phase
vanishes in the low-frequency region even for strong quasiperiodic disorder.
Our studies demonstrate that the periodically kicked Aubry-Andr\'{e} model
displays rich dynamical phenomena and the driving frequency plays an important
role in the formation of many-body localization in addition to the disorder
strength.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:38:47 GMT""},{""version"":""v2"",""created"":""Fri, 18 Mar 2022 14:43:55 GMT""},{""version"":""v3"",""created"":""Thu, 25 Aug 2022 14:50:57 GMT""}]","2022-08-26"
"2203.08005","Paul Schwahn","Paul Schwahn","Coindex and rigidity of Einstein metrics on homogeneous Gray manifolds","30 pages. v2: Shortened some elementary calculations. v3: Revised
  version",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Any $6$-dimensional strict nearly K\""ahler manifold is Einstein with positive
scalar curvature. We compute the coindex of the metric with respect to the
Einstein-Hilbert functional on each of the compact homogeneous examples.
Moreover, we show that the infinitesimal Einstein deformations on
$F_{1,2}=\mathrm{SU}(3)/T^2$ are not integrable into a curve of Einstein
metrics.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:42:10 GMT""},{""version"":""v2"",""created"":""Fri, 25 Mar 2022 15:57:58 GMT""},{""version"":""v3"",""created"":""Wed, 24 Aug 2022 13:30:48 GMT""}]","2022-08-25"
"2203.08006","Jad Hamdan","Luc Devroye and Jad Hamdan","Estimating monotone densities by cellular binary trees",,,,,"math.ST math.PR stat.TH","http://creativecommons.org/licenses/by/4.0/","  We propose a novel, simple density estimation algorithm for bounded monotone
densities with compact support under a cellular restriction. We show that its
expected error ($L_1$ distance) converges at a rate of $n^{-1/3}$, that its
expected runtime is sublinear and, in doing so, find a connection to the theory
of Galton--Watson processes.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:43:18 GMT""}]","2022-03-16"
"2203.08007","Arumoy Shome","Arumoy Shome and Luis Cruz and Arie van Deursen","Data Smells in Public Datasets",,,"10.1145/3522664.3528621",,"cs.SE cs.LG","http://creativecommons.org/licenses/by/4.0/","  The adoption of Artificial Intelligence (AI) in high-stakes domains such as
healthcare, wildlife preservation, autonomous driving and criminal justice
system calls for a data-centric approach to AI. Data scientists spend the
majority of their time studying and wrangling the data, yet tools to aid them
with data analysis are lacking. This study identifies the recurrent data
quality issues in public datasets. Analogous to code smells, we introduce a
novel catalogue of data smells that can be used to indicate early signs of
problems or technical debt in machine learning systems. To understand the
prevalence of data quality issues in datasets, we analyse 25 public datasets
and identify 14 data smells.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:44:20 GMT""},{""version"":""v2"",""created"":""Thu, 24 Mar 2022 09:42:27 GMT""},{""version"":""v3"",""created"":""Fri, 25 Mar 2022 10:15:38 GMT""}]","2022-03-28"
"2203.08008","Leander Weber","Leander Weber, Sebastian Lapuschkin, Alexander Binder, Wojciech Samek","Beyond Explaining: Opportunities and Challenges of XAI-Based Model
  Improvement",,,,,"cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Explainable Artificial Intelligence (XAI) is an emerging research field
bringing transparency to highly complex and opaque machine learning (ML)
models. Despite the development of a multitude of methods to explain the
decisions of black-box classifiers in recent years, these tools are seldomly
used beyond visualization purposes. Only recently, researchers have started to
employ explanations in practice to actually improve models. This paper offers a
comprehensive overview over techniques that apply XAI practically for improving
various properties of ML models, and systematically categorizes these
approaches, comparing their respective strengths and weaknesses. We provide a
theoretical perspective on these methods, and show empirically through
experiments on toy and realistic settings how explanations can help improve
properties such as model generalization ability or reasoning, among others. We
further discuss potential caveats and drawbacks of these methods. We conclude
that while model improvement based on XAI can have significant beneficial
effects even on complex and not easily quantifyable model properties, these
methods need to be applied carefully, since their success can vary depending on
a multitude of factors, such as the model and dataset used, or the employed
explanation method.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:44:28 GMT""}]","2022-03-16"
"2203.08009","Thomas Merritt","Thomas Merritt, Abdelhamid Ezzerg, Piotr Bili\'nski, Magdalena
  Proszewska, Kamil Pokora, Roberto Barra-Chicote, Daniel Korzekwa","Text-free non-parallel many-to-many voice conversion using normalising
  flows",,,,,"eess.AS cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Non-parallel voice conversion (VC) is typically achieved using lossy
representations of the source speech. However, ensuring only speaker identity
information is dropped whilst all other information from the source speech is
retained is a large challenge. This is particularly challenging in the scenario
where at inference-time we have no knowledge of the text being read, i.e.,
text-free VC. To mitigate this, we investigate information-preserving VC
approaches.
  Normalising flows have gained attention for text-to-speech synthesis, however
have been under-explored for VC. Flows utilize invertible functions to learn
the likelihood of the data, thus provide a lossless encoding of speech. We
investigate normalising flows for VC in both text-conditioned and text-free
scenarios. Furthermore, for text-free VC we compare pre-trained and
jointly-learnt priors. Flow-based VC evaluations show no degradation between
text-free and text-conditioned VC, resulting in improvements over the
state-of-the-art. Also, joint-training of the prior is found to negatively
impact text-free VC quality.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:45:54 GMT""}]","2022-03-16"
"2203.08010","Oksana Shadura","Doug Benjamin, Kenneth Bloom, Brian Bockelman, Lincoln Bryant, Kyle
  Cranmer, Rob Gardner, Chris Hollowell, Burt Holzman, Eric Lan\c{c}on, Ofer
  Rind, Oksana Shadura, Wei Yang","Analysis Facilities for HL-LHC","Contribution to Snowmass 2021",,,,"hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The HL-LHC presents significant challenges for the HEP analysis community.
The number of events in each analysis is expected to increase by an order of
magnitude and new techniques are expected to be required; both challenges
necessitate new services and approaches for analysis facilities. These services
are expected to provide new capabilities, a larger scale, and different access
modalities (complementing -- but distinct from -- traditional batch-oriented
approaches). To facilitate this transition, the US-LHC community is actively
investing in analysis facilities to provide a testbed for those developing new
analysis systems and to demonstrate new techniques for service delivery. This
whitepaper outlines the existing activities within the US LHC community in this
R&D area, the short- to medium-term goals, and the outline of common goals and
milestones.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:47:02 GMT""},{""version"":""v2"",""created"":""Wed, 16 Mar 2022 15:12:34 GMT""}]","2022-03-17"
"2203.08011","Konstantinos Balaskas","Konstantinos Balaskas, Georgios Zervakis, Kostas Siozios, Mehdi B.
  Tahoori, Joerg Henkel","Approximate Decision Trees For Machine Learning Classification on Tiny
  Printed Circuits","Accepted at the 23rd International Symposium on Quality Electronic
  Design (ISQED'22), April 6-7, 2022 (Virtual Conference)",,,,"cs.AR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Although Printed Electronics (PE) cannot compete with silicon-based systems
in conventional evaluation metrics, e.g., integration density, area and
performance, PE offers attractive properties such as on-demand ultra-low-cost
fabrication, flexibility and non-toxicity. As a result, it targets application
domains that are untouchable by lithography-based silicon electronics and thus
have not yet seen much proliferation of computing. However, despite the
attractive characteristics of PE, the large feature sizes in PE prohibit the
realization of complex printed circuits, such as Machine Learning (ML)
classifiers. In this work, we exploit the hardware-friendly nature of Decision
Trees for machine learning classification and leverage the hardware-efficiency
of the approximate design in order to generate approximate ML classifiers that
are suitable for tiny, ultra-resource constrained, and battery-powered printed
applications.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:47:59 GMT""}]","2022-03-16"
"2203.08012","Nelson Martins-Ferreira","J. P. Fatelo and N. Martins-Ferreira","A refinement of ternary Boolean algebras",,,,,"math.RA","http://creativecommons.org/licenses/by/4.0/","  An algebraic structure with two constants and one ternary operation, which is
not completely commutative, is put forward to accommodate ternary Boolean
algebras. When the ternary operation is interpreted as Church's conditioned
disjunction, Boolean algebras are characterized as a subvariety. Different
interpretations for the ternary operation lead to distinct subvarieties. Rings
and near-rings of characteristic 2 are used to illustrate the procedure.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:50:31 GMT""}]","2022-03-16"
"2203.08013","Mengze Li","Mengze Li, Tianbao Wang, Haoyu Zhang, Shengyu Zhang, Zhou Zhao, Jiaxu
  Miao, Wenqiao Zhang, Wenming Tan, Jin Wang, Peng Wang, Shiliang Pu and Fei Wu","End-to-End Modeling via Information Tree for One-Shot Natural Language
  Spatial Video Grounding",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Natural language spatial video grounding aims to detect the relevant objects
in video frames with descriptive sentences as the query. In spite of the great
advances, most existing methods rely on dense video frame annotations, which
require a tremendous amount of human effort. To achieve effective grounding
under a limited annotation budget, we investigate one-shot video grounding, and
learn to ground natural language in all video frames with solely one frame
labeled, in an end-to-end manner. One major challenge of end-to-end one-shot
video grounding is the existence of videos frames that are either irrelevant to
the language query or the labeled frames. Another challenge relates to the
limited supervision, which might result in ineffective representation learning.
To address these challenges, we designed an end-to-end model via Information
Tree for One-Shot video grounding (IT-OS). Its key module, the information
tree, can eliminate the interference of irrelevant frames based on branch
search and branch cropping techniques. In addition, several self-supervised
tasks are proposed based on the information tree to improve the representation
learning under insufficient labeling. Experiments on the benchmark dataset
demonstrate the effectiveness of our model.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:50:45 GMT""},{""version"":""v2"",""created"":""Mon, 23 May 2022 11:46:10 GMT""}]","2022-05-24"
"2203.08014","Yuya Sasaki","Silvia Sarpietro, Yuya Sasaki, Yulong Wang","Non-Existent Moments of Earnings Growth",,,,,"econ.EM","http://creativecommons.org/licenses/by/4.0/","  The literature often relies on moment-based measures of earnings risk, such
as the variance, skewness, and kurtosis (e.g., Guvenen, Karahan, Ozkan, and
Song, 2019, Econometrica). However, such moments may not exist in the
population under heavy-tailed distributions. We empirically show that the
population kurtosis, skewness, and even variance often fail to exist for the
conditional distribution of earnings growths. This evidence may invalidate the
moment-based analyses in the literature. In this light, we propose conditional
Pareto exponents as novel measures of earnings risk that are robust against
non-existence of moments, and develop estimation and inference methods.
  Using these measures with an administrative data set for the UK, the New
Earnings Survey Panel Dataset (NESPD), and the US Panel Study of Income
Dynamics (PSID), we quantify the tail heaviness of the conditional
distributions of earnings changes given age, gender, and past earnings. Our
main findings are that: 1) the aforementioned moments fail to exist; 2)
earnings risk is increasing over the life cycle; 3) job stayers are more
vulnerable to earnings risk, and 4) these patterns appear in both the period
2007-2008 of the great recession and the period 2015-2016 of positive growth
among others.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:50:49 GMT""},{""version"":""v2"",""created"":""Mon, 14 Nov 2022 23:13:34 GMT""}]","2022-11-16"
"2203.08017","Shay Zucker","Elad Dvash, Yam Peleg, Shay Zucker and Raja Giryes (Tel Aviv
  University, Tel Aviv, Israel)","Shallow Transits -- Deep Learning II: Identify Individual Exoplanetary
  Transits in Red Noise using Deep Learning","16 pages, 14 figures, accepted for publication in the Astronomical
  Journal",,"10.3847/1538-3881/ac5ea2",,"astro-ph.IM eess.IV","http://creativecommons.org/licenses/by/4.0/","  In a previous paper, we have introduced a deep learning neural network that
should be able to detect the existence of very shallow periodic planetary
transits in the presence of red noise. The network in that feasibility study
would not provide any further details about the detected transits. The current
paper completes this missing part. We present a neural network that tags
samples that were obtained during transits. This is essentially similar to the
task of identifying the semantic context of each pixel in an image -- an
important task in computer vision, called `semantic segmentation', which is
often performed by deep neural networks. The neural network we present makes
use of novel deep learning concepts such as U-Nets, Generative Adversarial
Networks (GAN), and adversarial loss. The resulting segmentation should allow
further studies of the light curves which are tagged as containing transits.
This approach towards the detection and study of very shallow transits is bound
to play a significant role in future space-based transit surveys such as PLATO,
which are specifically aimed to detect those extremely difficult cases of
long-period shallow transits. Our segmentation network also adds to the growing
toolbox of deep learning approaches which are being increasingly used in the
study of exoplanets, but so far mainly for vetting transits, rather than their
initial detection.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:53:32 GMT""}]","2022-05-11"
"2203.08018","Yuki Kato","Yuki Kato","Algebraic $K$-theory and algebraic cobordism of almost mathematics","Proposition 3.17 of the previous version was incorrect, and it was
  removed",,,,"math.KT math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Faltings; Gabber and Ramero introduced almost mathematics. In another way,
almost mathematics can be characterized bilocalization abelian category of
modules mentioned in Quillen's unpublished note. Applying the concept of
Quillen's bilocalization to Gabber and Ramero's work, this paper establishes
the almost version of algebraic $K$-theory and cobordism. As a result of almost
$K$-theory, we prove that in the case an almost algebra containing a field, the
almost $K$-theory of the almost algebra is a direct factor of the $K$-theory of
the field, implying that almost $K$-theory holds the Gersten property. We
clarify that an almost $K$-theory is a $K$-theory spectrum of non-unital firm
algebras in the sense of Quillen. Furthermore, we obtain that almost algebraic
cobordism holds tilting equivalence on the category of zero-section stable
integral perfectoid algebras with finite syntomic topology.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:53:55 GMT""},{""version"":""v2"",""created"":""Sun, 24 Apr 2022 15:22:20 GMT""},{""version"":""v3"",""created"":""Sat, 16 Jul 2022 15:30:15 GMT""},{""version"":""v4"",""created"":""Mon, 27 Feb 2023 14:32:12 GMT""}]","2023-02-28"
"2203.08023","Gelo Noel Tabia","Gelo Noel M. Tabia, Kai-Siang Chen, Chung-Yun Hsieh, Yu-Chun Yin,
  Yeong-Cherng Liang","Entanglement transitivity problems","8+10 pages, 9 figures, 2 tables. Virtually the same as the published
  version","npj Quantum Inf 8, 98 (2022)","10.1038/s41534-022-00616-1",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the goals of science is to understand the relation between a whole and
its parts, as exemplified by the problem of certifying the entanglement of a
system from the knowledge of its reduced states. Here, we focus on a different
but related question: can a collection of marginal information reveal new
marginal information? We answer this affirmatively and show that (non-)
entangled marginal states may exhibit (meta)transitivity of entanglement, i.e.,
implying that a different target marginal must be entangled. By showing that
the global $n$-qubit state compatible with certain two-qubit marginals in a
tree form is unique, we prove that transitivity exists for a system involving
an arbitrarily large number of qubits. We also completely characterize -- in
the sense of providing both the necessary and sufficient conditions -- when
(meta)transitivity can occur in a tripartite scenario when the two-qudit
marginals given are either the Werner states or the isotropic states. Our
numerical results suggest that in the tripartite scenario, entanglement
transitivity is generic among the marginals derived from pure states.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:57:33 GMT""},{""version"":""v2"",""created"":""Thu, 25 Aug 2022 14:32:36 GMT""}]","2022-08-26"
"2203.08024","John Carlstrom","Kevork Abazajian, Arwa Abdulghafour, Graeme E. Addison, Peter Adshead,
  Zeeshan Ahmed, Marco Ajello, Daniel Akerib, Steven W. Allen, David Alonso,
  Marcelo Alvarez, Mustafa A. Amin, Mandana Amiri, Adam Anderson, Behzad
  Ansarinejad, Melanie Archipley, Kam S. Arnold, Matt Ashby, Han Aung, Carlo
  Baccigalupi, Carina Baker, Abhishek Bakshi, Debbie Bard, Denis Barkats, Darcy
  Barron, Peter S. Barry, James G. Bartlett, Paul Barton, Ritoban Basu Thakur,
  Nicholas Battaglia, Jim Beall, Rachel Bean, Dominic Beck, Sebastian Belkner,
  Karim Benabed, Amy N. Bender, Bradford A. Benson, Bobby Besuner, Matthieu
  Bethermin, Sanah Bhimani, Federico Bianchini, Simon Biquard, Ian Birdwell,
  Colin A. Bischoff, Lindsey Bleem, Paulina Bocaz, James J. Bock, Sebastian
  Bocquet, Kimberly K. Boddy, J. Richard Bond, Julian Borrill, Francois R.
  Bouchet, Thejs Brinckmann, Michael L. Brown, Sean Bryan, Victor Buza, Karen
  Byrum, Erminia Calabrese, Victoria Calafut, Robert Caldwell, John E.
  Carlstrom, Julien Carron, Thomas Cecil, Anthony Challinor, Victor Chan,
  Clarence L. Chang, Scott Chapman, Eric Charles, Eric Chauvin, Cheng Cheng,
  Grace Chesmore, Kolen Cheung, Yuji Chinone, Jens Chluba, Hsiao-Mei Sherry
  Cho, Steve Choi, Justin Clancy, Susan Clark, Asantha Cooray, Gabriele Coppi,
  John Corlett, Will Coulton, Thomas M. Crawford, Abigail Crites, Ari
  Cukierman, Francis-Yan Cyr-Racine, Wei-Ming Dai, Cail Daley, Eli Dart,
  Gregorg Daues, Tijmen de Haan, Cosmin Deaconu, Jacques Delabrouille, Greg
  Derylo, Mark Devlin, Eleonora Di Valentino, Marion Dierickx, Brad Dober,
  Randy Doriese, Shannon Duff, Daniel Dutcher, Cora Dvorkin, Rolando D\""unner,
  Tarraneh Eftekhari, Joseph Eimer, Hamza El Bouhargani, Tucker Elleflot, Nick
  Emerson, Josquin Errard, Thomas Essinger-Hileman, Giulio Fabbian, Valentina
  Fanfani, Alessandro Fasano, Chang Feng, Simone Ferraro, Jeffrey P. Filippini,
  Raphael Flauger, Brenna Flaugher, Aurelien A. Fraisse, Josef Frisch, Andrei
  Frolov, Nicholas Galitzki, Patricio A. Gallardo, Silvia Galli, Ken Ganga,
  Martina Gerbino, Christos Giannakopoulos, Murdock Gilchriese, Vera Gluscevic,
  Neil Goeckner-Wald, David Goldfinger, Daniel Green, Paul Grimes, Daniel Grin,
  Evan Grohs, Riccardo Gualtieri, Vic Guarino, Jon E. Gudmundsson, Ian Gullett,
  Sam Guns, Salman Habib, Gunther Haller, Mark Halpern, Nils W. Halverson,
  Shaul Hanany, Emma Hand, Kathleen Harrington, Masaya Hasegawa, Matthew
  Hasselfield, Masashi Hazumi, Katrin Heitmann, Shawn Henderson, Brandon
  Hensley, Ryan Herbst, Carlos Hervias-Caimapo, J. Colin Hill, Richard Hills,
  Eric Hivon, Ren\'ee Hlozek, Anna Ho, Gil Holder, Matt Hollister, William
  Holzapfel, John Hood, Selim Hotinli, Alec Hryciuk, Johannes Hubmayr, Kevin M.
  Huffenberger, Howard Hui, Roberto Ib\'a nez, Ayodeji Ibitoye, Margaret Ikape,
  Kent Irwin, Cooper Jacobus, Oliver Jeong, Bradley R. Johnson, Doug Johnstone,
  William C. Jones, John Joseph, Baptiste Jost, Jae Hwan Kang, Ari Kaplan,
  Kirit S. Karkare, Nobuhiko Katayama, Reijo Keskitalo, Cesiley King, Theodore
  Kisner, Matthias Klein, Lloyd Knox, Brian J. Koopman, Arthur Kosowsky, John
  Kovac, Ely D. Kovetz, Alex Krolewski, Donna Kubik, Steve Kuhlmann, Chao-Lin
  Kuo, Akito Kusaka, Anne L\""ahteenm\""aki, Kenny Lau, Charles R. Lawrence,
  Adrian T. Lee, Louis Legrand, Matthaeus Leitner, Cl\'ement Leloup, Antony
  Lewis, Dale Li, Eric Linder, Ioannis Liodakis, Jia Liu, Kevin Long, Thibaut
  Louis, Marilena Loverde, Lindsay Lowry, Chunyu Lu, Phil Lubin, Yin-Zhe Ma,
  Thomas Maccarone, Mathew S. Madhavacheril, Felipe Maldonado, Adam Mantz,
  Gabriela Marques, Frederick Matsuda, Philip Mauskopf, Jared May, Heather
  McCarrick, Ken McCracken, Jeffrey McMahon, P. Daniel Meerburg, Jean-Baptiste
  Melin, Felipe Menanteau, Joel Meyers, Marius Millea, Vivian Miranda, Don
  Mitchell, Joseph Mohr, Lorenzo Moncelsi, Maria Elena Monzani, Magdy Moshed,
  Tony Mroczkowski, Suvodip Mukherjee, Moritz M\""unchmeyer, Daisuke Nagai,
  Chandan Nagarajappa, Johanna Nagy, Toshiya Namikawa, Federico Nati, Tyler
  Natoli, Simran Nerval, Laura Newburgh, Hogan Nguyen, Erik Nichols, Andrina
  Nicola, Michael D. Niemack, Brian Nord, Tim Norton, Valentine Novosad, Roger
  O'Brient, Yuuki Omori, Giorgio Orlando, Benjamin Osherson, Rachel Osten,
  Stephen Padin, Scott Paine, Bruce Partridge, Sanjaykumar Patil, Don
  Petravick, Matthew Petroff, Elena Pierpaoli, Mauricio Pilleux, Levon
  Pogosian, Karthik Prabhu, Clement Pryke, Giuseppe Puglisi, Benjamin Racine,
  Srinivasan Raghunathan, Alexandra Rahlin, Marco Raveri, Ben Reese, Christian
  L. Reichardt, Mathieu Remazeilles, Arianna Rizzieri, Graca Rocha, Natalie A.
  Roe, Kaja Rotermund, Anirban Roy, John E. Ruhl, Joe Saba, Noah Sailer, Maria
  Salatino, Benjamin Saliwanchik, Leonid Sapozhnikov, Mayuri Sathyanarayana
  Rao, Lauren Saunders, Emmanuel Schaan, Alessandro Schillaci, Benjamin
  Schmitt, Douglas Scott, Neelima Sehgal, Sarah Shandera, Blake D. Sherwin,
  Erik Shirokoff, Corwin Shiu, Sara M. Simon, Baibhav Singari, Anze Slosar,
  David Spergel, Tyler St. Germaine, Suzanne T. Staggs, Antony A. Stark, Glenn
  D. Starkman, Bryan Steinbach, Radek Stompor, Chris Stoughton, Aritoki Suzuki,
  Osamu Tajima, Chris Tandoi, Grant P. Teply, Gregg Thayer, Keith Thompson, Ben
  Thorne, Peter Timbie, Maurizio Tomasi, Cynthia Trendafilova, Matthieu
  Tristram, Carole Tucker, Gregory Tucker, Caterina Umilt\`a, Alexander van
  Engelen, Joshiwa van Marrewijk, Eve M. Vavagiakis, Clara Verg\`es, Joaquin D.
  Vieira, Abigail G. Vieregg, Kasey Wagoner, Benjamin Wallisch, Gensheng Wang,
  Guo-Jian Wang, Scott Watson, Duncan Watts, Chris Weaver, Lukas Wenzl, Ben
  Westbrook, Martin White, Nathan Whitehorn, Andrew Wiedlea, Paul Williams,
  Robert Wilson, Harrison Winch, Edward J. Wollack, W. L. Kimmy Wu, Zhilei Xu,
  Volodymyr G. Yefremenko, Cyndia Yu, David Zegeye, Jeff Zivick, Andrea Zonca","Snowmass 2021 CMB-S4 White Paper","Contribution to Snowmass 2021. arXiv admin note: substantial text
  overlap with arXiv:1908.01062, arXiv:1907.04473",,,,"astro-ph.CO astro-ph.IM gr-qc hep-ex hep-ph","http://creativecommons.org/licenses/by/4.0/","  This Snowmass 2021 White Paper describes the Cosmic Microwave Background
Stage 4 project CMB-S4, which is designed to cross critical thresholds in our
understanding of the origin and evolution of the Universe, from the highest
energies at the dawn of time through the growth of structure to the present
day. We provide an overview of the science case, the technical design, and
project plan.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:59:02 GMT""}]","2022-04-13"
"2203.08025","Soumitro Banerjee","Vaibhav Ganatra and Soumitro Banerjee","Sketching 1-D stable manifolds of 2-D maps without the inverse","9 pages, 7 figures",,"10.1142/S0218127422501115",,"nlin.CD","http://creativecommons.org/licenses/by/4.0/","  Saddle fixed points are the centerpieces of complicated dynamics in a system.
The one-dimensional stable and unstable manifolds of these saddle-points are
crucial to understanding the dynamics of such systems. While the problem of
sketching the unstable manifold is simple, plotting the stable manifold is not
as easy. Several algorithms exist to compute the stable manifold of
saddle-points, but they have their limitations, especially when the system is
not invertible. In this paper, we present a new algorithm to compute the stable
manifold of 2-dimensional systems which can also be used for non-invertible
systems. After outlining the logic of the algorithm, we demonstrate the output
of the algorithm on several examples.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:59:33 GMT""}]","2022-07-13"
"2203.08147","Antonio Emanuele Cin\`a","Antonio Emanuele Cin\`a, Ambra Demontis, Battista Biggio, Fabio Roli,
  Marcello Pelillo","Energy-Latency Attacks via Sponge Poisoning","Preprint;16 pages",,,,"cs.CR cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sponge examples are test-time inputs carefully optimized to increase energy
consumption and latency of neural networks when deployed on hardware
accelerators. In this work, we are the first to demonstrate that sponge
examples can also be injected at training time, via an attack that we call
sponge poisoning. This attack allows one to increase the energy consumption and
latency of machine-learning models indiscriminately on each test-time input. We
present a novel formalization for sponge poisoning, overcoming the limitations
related to the optimization of test-time sponge examples, and show that this
attack is possible even if the attacker only controls a few model updates; for
instance, if model training is outsourced to an untrusted third-party or
distributed via federated learning. Our extensive experimental analysis shows
that sponge poisoning can almost completely vanish the effect of hardware
accelerators. We also analyze the activations of poisoned models, identifying
which components are more vulnerable to this attack. Finally, we examine the
feasibility of countermeasures against sponge poisoning to decrease energy
consumption, showing that sanitization methods may be overly expensive for most
of the users.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:18:10 GMT""},{""version"":""v2"",""created"":""Mon, 11 Apr 2022 15:20:58 GMT""},{""version"":""v3"",""created"":""Thu, 9 Mar 2023 14:16:03 GMT""},{""version"":""v4"",""created"":""Tue, 28 Mar 2023 08:09:38 GMT""}]","2023-03-29"
"2203.08148","Onat Gungor","Onat Gungor, Tajana Rosing, Baris Aksanli","RES-HD: Resilient Intelligent Fault Diagnosis Against Adversarial
  Attacks Using Hyper-Dimensional Computing",,,,,"cs.CR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Industrial Internet of Things (I-IoT) enables fully automated production
systems by continuously monitoring devices and analyzing collected data.
Machine learning methods are commonly utilized for data analytics in such
systems. Cyber-attacks are a grave threat to I-IoT as they can manipulate
legitimate inputs, corrupting ML predictions and causing disruptions in the
production systems. Hyper-dimensional computing (HDC) is a brain-inspired
machine learning method that has been shown to be sufficiently accurate while
being extremely robust, fast, and energy-efficient. In this work, we use HDC
for intelligent fault diagnosis against different adversarial attacks. Our
black-box adversarial attacks first train a substitute model and create
perturbed test instances using this trained model. These examples are then
transferred to the target models. The change in the classification accuracy is
measured as the difference before and after the attacks. This change measures
the resiliency of a learning method. Our experiments show that HDC leads to a
more resilient and lightweight learning solution than the state-of-the-art deep
learning methods. HDC has up to 67.5% higher resiliency compared to the
state-of-the-art methods while being up to 25.1% faster to train.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:59:17 GMT""}]","2022-03-17"
"2203.08149","Arman Hasanzadeh","Arman Hasanzadeh, Ehsan Hajiramezanali, Nick Duffield, Xiaoning Qian","MoReL: Multi-omics Relational Learning",,,,,"q-bio.QM cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multi-omics data analysis has the potential to discover hidden molecular
interactions, revealing potential regulatory and/or signal transduction
pathways for cellular processes of interest when studying life and disease
systems. One of critical challenges when dealing with real-world multi-omics
data is that they may manifest heterogeneous structures and data quality as
often existing data may be collected from different subjects under different
conditions for each type of omics data. We propose a novel deep Bayesian
generative model to efficiently infer a multi-partite graph encoding molecular
interactions across such heterogeneous views, using a fused Gromov-Wasserstein
(FGW) regularization between latent representations of corresponding views for
integrative analysis. With such an optimal transport regularization in the deep
Bayesian generative model, it not only allows incorporating view-specific side
information, either with graph-structured or unstructured data in different
views, but also increases the model flexibility with the distribution-based
regularization. This allows efficient alignment of heterogeneous latent
variable distributions to derive reliable interaction predictions compared to
the existing point-based graph embedding methods. Our experiments on several
real-world datasets demonstrate enhanced performance of MoReL in inferring
meaningful interactions compared to existing baselines.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 02:50:07 GMT""}]","2022-03-18"
"2203.08150","Kairui Bao","Kairui Bao, Wen Yao, Xiaoya Zhang, Wei Peng, Yu Li","A physics and data co-driven surrogate modeling approach for temperature
  field prediction on irregular geometric domain",,,,,"cs.LG","http://creativecommons.org/publicdomain/zero/1.0/","  In the whole aircraft structural optimization loop, thermal analysis plays a
very important role. But it faces a severe computational burden when directly
applying traditional numerical analysis tools, especially when each
optimization involves repetitive parameter modification and thermal analysis
followed. Recently, with the fast development of deep learning, several
Convolutional Neural Network (CNN) surrogate models have been introduced to
overcome this obstacle. However, for temperature field prediction on irregular
geometric domains (TFP-IGD), CNN can hardly be competent since most of them
stem from processing for regular images. To alleviate this difficulty, we
propose a novel physics and data co-driven surrogate modeling method. First,
after adapting the Bezier curve in geometric parameterization, a body-fitted
coordinate mapping is introduced to generate coordinate transforms between the
irregular physical plane and regular computational plane. Second, a
physics-driven CNN surrogate with partial differential equation (PDE) residuals
as a loss function is utilized for fast meshing (meshing surrogate); then, we
present a data-driven surrogate model based on the multi-level reduced-order
method, aiming to learn solutions of temperature field in the above regular
computational plane (thermal surrogate). Finally, combining the grid position
information provided by the meshing surrogate with the scalar temperature field
information provided by the thermal surrogate (combined model), we reach an
end-to-end surrogate model from geometric parameters to temperature field
prediction on an irregular geometric domain. Numerical results demonstrate that
our method can significantly improve accuracy prediction on a smaller dataset
while reducing the training time when compared with other CNN methods.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 08:43:24 GMT""}]","2022-03-17"
"2203.08151","Shi Dai","S. Dai, Y. Feng, Y. P. Yang, Y. K. Zhang, D. Li, C. H. Niu, P. Wang,
  M. Y. Xue, B. Zhang, S. Burke-Spolaor, C. J. Law, R. S. Lynch, L. Connor, R.
  Anna-Thomas, L. Zhang, R. Duan, J. M. Yao, C. W. Tsai, W. W. Zhu, M. Cruces,
  G. Hobbs, C. C. Miao, J. R. Niu, M. D. Filipovic, S. Q. Zhu","Magnetic Field Reversal around an Active Fast Radio Burst","It was merged into arXiv:2202.11112. Science380,599-603(2023).
  DOI:10.1126/science.abo6526",,,,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The environment of actively repeating fast radio bursts (FRBs) has been shown
to be complex and varying. The recently localized FRB 20190520B is extremely
active, has the largest confirmed host dispersion measure, and is only the
second FRB source associated with a compact, persistent radio source (PRS). The
main tracer of the magneto-ionic environments is the rotation measure (RM), a
path-integral of the line-of-sight component of magnetic field strength (B) and
electron density, which does not allow a direct probe of the B-field
configuration. Here we report direct evidence for a B-field reversal based on
the observed sign change and extreme variation of FRB 20190520B's RM, which
changed from $\sim10000$ rad m$^{-2}$ to $\sim-16000$ rad m$^{-2}$ between June
2021 and January 2022. Such extreme RM reversal has never been observed before
in any FRB nor in any astronomical object. The implied short-term change of the
B-field configuration in or around the FRB could be due to the vicinity of
massive black holes, or a magnetized companion star in binary systems, or a
young supernova remnant along the line of sight.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:56:22 GMT""},{""version"":""v2"",""created"":""Thu, 11 May 2023 23:42:25 GMT""}]","2023-05-15"
"2203.08152","Louis Legrand","Louis Legrand and Julien Carron","CMB lensing power spectrum with next generation surveys","Contribution to the 2022 Cosmology session of the 56th Rencontres de
  Moriond, 2 pages, 2 figures",,,,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a new estimator of the CMB lensing power spectrum, together with
its likelihood, based on iterative lensing reconstruction. Despite the
increased complexity of the lensing maps, this estimator shares similarities
with the standard quadratic estimator. Most importantly, it is unbiased towards
the assumptions done on the noise and cosmology for the lensing reconstruction.
This new spectrum estimator can double the constraints on the lensing amplitude
compared to the quadratic estimator, while keeping numerical cost under control
and being robust to errors.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:43:24 GMT""}]","2022-03-17"
"2203.08609","Jingxu (Kent) Zheng","Jingxu Zheng, Yue Deng, Wenzao Li, Jiefu Yin, Patrick J. West, Tian
  Tang, Xiao Tong, David C. Bock, Shuo Jin, Qing Zhao, Regina Garcia-Mendez,
  Kenneth J. Takeuchi, Esther S. Takeuchi, Amy C. Marschilok, Lynden A. Archer","The Sabatier principle for Battery Anodes: Chemical Kinetics and
  Reversible Electrodeposition at Heterointerfaces","accepted at Science Advances, in press",,"10.1126/sciadv.abq6321",,"physics.chem-ph cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  How surface chemistry influences reactions occurring thereupon has been a
long-standing question of broad scientific and technological interest for
centuries. Recently, it has re-emerged as a critical question in a
subdiscipline of chemistry - electrochemistry at heterointerphases, where the
answers have implications for both how, and in what forms, humanity stores the
rising quantities of renewable electric power generated from solar and wind
installations world-wide. Here we consider the relation between the surface
chemistry at such interphases and the reversibility of electrochemical
transformations at a rechargeable battery electrode. Conventional wisdom holds
that stronger chemical interaction between the metal deposits and electrode
promotes reversibility. We report instead that a moderate strength of chemical
interaction between the deposit and the substrate, neither too weak nor too
strong, enables highest reversibility and stability of the plating/stripping
redox processes at a battery anode. Analogous to the empirical Sabatier
principle for chemical heterogeneous catalysis, our finding arises from the
confluence of competing processes - one driven by electrochemistry and the
other by chemical alloying. Based on experimental evaluation of metal
plating/stripping systems in battery anodes of contemporary interest, we show
that such knowledge provides a powerful tool for designing key materials in
highly reversible electrochemical energy storage technologies based on
earth-abundant, low-cost metals.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 20:47:47 GMT""},{""version"":""v2"",""created"":""Tue, 22 Mar 2022 17:09:16 GMT""},{""version"":""v3"",""created"":""Sun, 25 Sep 2022 22:47:24 GMT""}]","2022-09-27"
"2203.08613","Antonio Rodriguez","Antonio C. Rodriguez, Yuhan Yao, Kishalay De, S.R. Kulkarni","The Search for a Counterpart to NuSTAR J053449+2126.0","Accepted and Published in RNAAS","Res. Notes AAS 6 50 (2022)","10.3847/2515-5172/ac5c51",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Tumer et al. 2022, ATel #15171, have recently reported the discovery of an
X-ray source, NuSTAR J053449+2126.0, during a calibration observation which
took place on 25 April 2020. We scan the Zwicky Transient Facility (ZTF) alerts
and archival photometry to determine the nature of the source. Palomar
Gattini-IR is searched as well. We identify no obvious counterpart candidate.
Follow-up X-ray and optical studies are needed to determine the true
counterpart.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:00:02 GMT""}]","2022-03-17"
"2203.08800","Xiangyang Ju","Chun-Yi Wang, Xiangyang Ju, Shih-Chieh Hsu, Daniel Murnane, Paolo
  Calafiura, Steven Farrell, Maria Spiropulu, Jean-Roch Vlimant, Adam Aurisano,
  V Hewes, Giuseppe Cerati, Lindsey Gray, Thomas Klijnsma, Jim Kowalkowski,
  Markus Atkinson, Mark Neubauer, Gage DeZoort, Savannah Thais, Alexandra
  Ballow, Alina Lazar, Sylvain Caillou, Charline Rougier, Jan Stark, Alexis
  Vallier, Jad Sardain","Reconstruction of Large Radius Tracks with the Exa.TrkX pipeline","5 pages, 3 figures. Proceedings of 20th International Workshop on
  Advanced Computing and Analysis Techniques in Physics Research",,"10.1088/1742-6596/2438/1/012117",,"physics.ins-det hep-ex hep-ph physics.data-an","http://creativecommons.org/licenses/by/4.0/","  Particle tracking is a challenging pattern recognition task at the Large
Hadron Collider (LHC) and the High Luminosity-LHC. Conventional algorithms,
such as those based on the Kalman Filter, achieve excellent performance in
reconstructing the prompt tracks from the collision points. However, they
require dedicated configuration and additional computing time to efficiently
reconstruct the large radius tracks created away from the collision points. We
developed an end-to-end machine learning-based track finding algorithm for the
HL-LHC, the Exa.TrkX pipeline. The pipeline is designed so as to be agnostic
about global track positions. In this work, we study the performance of the
Exa.TrkX pipeline for finding large radius tracks. Trained with all tracks in
the event, the pipeline simultaneously reconstructs prompt tracks and large
radius tracks with high efficiencies. This new capability offered by the
Exa.TrkX pipeline may enable us to search for new physics in real time.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:32:06 GMT""}]","2023-03-01"
"2203.08801","Robert Erbacher","Robert F. Erbacher","Base-Rate Fallacy Redux and a Deep Dive Review in Cybersecurity",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper examines the current state of the science underlying cybersecurity
research with an emphasis on the non-signature-based intrusion detection
domain. First, the paper re-examines the base-rate fallacy originally published
by Axelsson, putting the impact of false positives into context. Given the
relative high numbers of false positives, the paper argues for deeper analysis
of false positives, akin to the analysis that true positives are treated to.
The second section of the paper examines the metrics being used to analyze
non-signature intrusion detection techniques, the current status quo of
employed metrics, and the impact of the status quo on scientific advancement.
Finally, the paper analyzes the use of online attack graphs and their
applicability, especially in scenarios of constrained environments, such as
Internet of Things devices. The use of offline attack graphs in such
constrained environments is also examined. In essence, a deep dive review
identified multiple areas throughout the field in which the effectiveness and
validity of the scientific method can be greatly improved, e.g., through
removal of logical fallacies.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:42:00 GMT""}]","2022-03-18"
"2203.08802","Ulisses Braga-Neto","E.J.R. Coutinho, M. Dall'Aqua, L. McClenny, M. Zhong, U. Braga-Neto,
  E. Gildin","Physics-Informed Neural Networks with Adaptive Localized Artificial
  Viscosity",,,,,"physics.flu-dyn cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Physics-informed Neural Network (PINN) is a promising tool that has been
applied in a variety of physical phenomena described by partial differential
equations (PDE). However, it has been observed that PINNs are difficult to
train in certain ""stiff"" problems, which include various nonlinear hyperbolic
PDEs that display shocks in their solutions. Recent studies added a diffusion
term to the PDE, and an artificial viscosity (AV) value was manually tuned to
allow PINNs to solve these problems. In this paper, we propose three approaches
to address this problem, none of which rely on an a priori definition of the
artificial viscosity value. The first method learns a global AV value, whereas
the other two learn localized AV values around the shocks, by means of a
parametrized AV map or a residual-based AV map. We applied the proposed methods
to the inviscid Burgers equation and the Buckley-Leverett equation, the latter
being a classical problem in Petroleum Engineering. The results show that the
proposed methods are able to learn both a small AV value and the accurate shock
location and improve the approximation error over a nonadaptive global AV
alternative method.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 05:43:27 GMT""}]","2022-03-18"
"2203.08803","Tamer Tolba Dr.","A. Alekou, E. Baussan, N. Blaskovic Kraljevic, M. Blennow, M.
  Bogomilov, E. Bouquerel, A. Burgman, C.J. Carlile, J. Cederkall, P.
  Christiansen, M. Collins, E. Cristaldo Morales, P. Cupial, L. D Alessi, H.
  Danared, J. P. A. M. de Andre, J.P. Delahaye, M. Dracos, I. Efthymiopoulos,
  T. Ekelof, M. Eshraqi, G. Fanourakis, E. Fernandez-Martinez, B. Folsom, N.
  Gazis, Th. Geralis, M. Ghosh, G. Gokbulut, L. Halic, A. Kayis Topaksu, B.
  Kildetoft, B. Klicek, M. Koziol, K. Krhac, L. Lacny, M. Lindroos, M.
  Mezzetto, M. Oglakci, T. Ohlsson, M. Olvegard, T. Ota, J. Park, D. Patrzalek,
  G. Petkov, P. Poussot, R. Johansson, S. Rosauro-Alcaraz, B. Szybinski, J.
  Snamina, G. Stavropoulos, M. Stipcevic, F. Terranova, J. Thomas, T. Tolba, E.
  Trachanas, R. Tsenov, G. Vankova-Kirilova, N. Vassilopoulos, E. Wildner, J.
  Wurtz, O. Zormpa, Y. Zou","The European Spallation Source neutrino Super Beam","contribution to Snowmass 2021",,,,"physics.acc-ph hep-ex","http://creativecommons.org/publicdomain/zero/1.0/","  In this Snowmass 2021 white paper, we summarise the Conceptual Design of the
European Spallation Source neutrino Super Beam (ESSvSB) experiment and its
synergies with the possible future muon based facilities, e.g. a Low Energy
nuSTORM and the Muon Collider. The ESSvSB will benefit from the high power, 5
MW, of the European Spallation Source (ESS) LINAC in Lund-Sweden to produce the
world most intense neutrino beam, enabling measurements to be made at the
second oscillation maximum. Assuming a ten-year exposure, physics simulations
show that the CP-invariance violation can be established with a significance of
5 sigma over more than 70% of all values of delta CP and with an error in the
measurement of the delta CP angle of less than 8 degree for all values of delta
CP.
  However, several technological and physics challenges must be further studied
before achieving a final Technical Design. Measuring at the 2nd oscillation
maximum necessitates a very intense neutrino beam with the appropriate energy.
For this, the ESS proton beam LINAC, which is designed to produce the world's
most intense neutron beam, will need to be upgraded to 10 MW power, 2.5 GeV
energy and 28 Hz beam pulse repetition rate. An accumulator ring will be
required for the compression of the ESS LINAC beam pulse from 2.86 ms to 1.3
mus. A high power target station facility will be needed to produce a
well-focused intense (super) mu-neutrino beam. The physics performance of that
neutrino Super Beam in conjunction with a megaton underground Water Cherenkov
neutrino far detector installed at a distance of either 360 km or 540 km from
the ESS, the baseline, has been evaluated.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 07:30:22 GMT""}]","2022-03-18"
"2203.08815","Christian Bauckhage","Christian Bauckhage, Thore Gerlach, Nico Piatkowski","QUBOs for Sorting Lists and Building Trees",,,,,"cs.DS cs.LG quant-ph","http://creativecommons.org/licenses/by/4.0/","  We show that the fundamental tasks of sorting lists and building search trees
or heaps can be modeled as quadratic unconstrained binary optimization problems
(QUBOs). The idea is to understand these tasks as permutation problems and to
devise QUBOs whose solutions represent appropriate permutation matrices. We
discuss how to construct such QUBOs and how to solve them using Hopfield nets
or adiabatic) quantum computing. In short, we show that neurocomputing methods
or quantum computers can solve problems usually associated with abstract data
structures.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 11:58:17 GMT""}]","2022-03-18"
"2203.08863","Pietro Vischia","Pietro Vischia","Electroweak Precision Measurements in Diboson Production at CMS","6 pages, 5 figures. Proceedings of 32nd Rencontres de Blois, Blois
  (France) 2021",,,"CMS-CR-2022-040","hep-ex hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this contribution, I have outlined recent precision measurements of the
standard model (SM) multiboson production at CMS. A study of diboson production
at 5 TeV constitutes an important probe of the SM at a new energy, and the data
favour NNLO predictions obtained by MATRIX. A study of WZ production at 13 TeV
constitutes the most comprehensive study of WZ production to date, containing
inclusive and differential cross section measurements, charge asymmetry
measurements, constraints on the LHC proton parton distribution functions, and
constraints on anomalous values of the WWZ trilinear gauge coupling. No
evidence for new physics is found, and all the results favour SM predictions
calculated at NNLO using MATRIX.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:47:22 GMT""}]","2022-04-12"
"2203.09451","Jie Gao","CEPC Accelerator Study Group","Snowmass2021 White Paper AF3-CEPC","48 pages,34 figures",,,,"physics.acc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The discovery of the Higgs boson at Large Hadron Collider (LHC) of CERN in
July 2012 raised new opportunities for large-scale accelerators. The Higgs
boson is the heart of the Standard Model (SM) and is at the center of many
biggest mysteries.In September 2012, Chinese scientists proposed a 240 GeV
Circular Electron Positron Collider (CEPC) as a Higgs Factory, having two large
detectors for Higgs studies and other topical researches. The 100 km tunnel of
CEPC could also host a Super proton proton Collider (SppC) to reach energies
well beyond the LHC. CEPC Conceptual Design Report (CDR) has been released in
Nov. 2018, and in this CEPC Accelerator White Paper to Snowmass21 AF3, CEPC
Technical Design Report (TDR) status with optimized design and key technology R
and D progresses have been reported. The energy range, luminosity, upgrade and
staging potentials, power consumption, cost, readiness assessment, timelines,
construction and operation plans, etc. are covered.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:24:34 GMT""}]","2022-03-18"
"2203.09478","Wen-Ge Wang","Wen-ge Wang","A framework for quantum theory of elementary physical entities","42 pages, no figure",,,,"physics.gen-ph","http://creativecommons.org/licenses/by/4.0/","  A unified framework, which is directly established on the quantum ground, is
proposed for elementary physical entities, called \emph{modes} in this paper.
The framework is mainly built upon five basic assumptions, which loosely
speaking have the following contents. (i) The state space of each mode is given
by the direct product of a momentum-state space and a spinor-state space, the
latter of which is certain representation space of the $SL(2,C)$ group (a
covering group of the Lorentz group); (ii) spinor states of modes have a
layer-type structure and modes are either fermionic or bosonic, depending on
their helicity properties; (iii) there are three fundamental processes -- free
evolution, vacuum fluctuation (emergence or vanishing of a pair of fermionic
modes that possess exactly opposite physical properties), and two fundamental
interaction processes (change of two fermionic modes into one bosonic mode and
the reverse); (iv) vacuum fluctuation happens instantly; and (v) the time
evolution operator is constructed from operators, which map state spaces of
incoming modes of fundamental processes to those of outgoing modes. The time
evolution operator turns out to be a function of quantum fields that are
constructed from creation and annihilation operators for free-mode states,
whose interaction part has a local feature. As an example, a simple model of
modes is studied and is compared with the first-generation part of the standard
model (SM). Concerning electroweak interactions, the studied model has a time
evolution operator, whose main body is formally similar to that of the SM.
Besides, it predicts $\frac 13$ and $\frac 23$ electronic changes for
quark-type modes, gives an interpretation to the color degree of freedom, and
contains certain modes that behave like dark matters.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 06:57:34 GMT""}]","2022-03-18"
"2203.09518","Pierre Champion","Pierre Champion (MULTISPEECH), Denis Jouvet (MULTISPEECH), Anthony
  Larcher (LIUM)","Privacy-Preserving Speech Representation Learning using Vector
  Quantization","Journ{\'e}es d'{\'E}tudes sur la Parole - JEP2022, Jun 2022, {\^I}le
  de Noirmoutier, France",,,,"eess.AS cs.AI cs.CL cs.CR cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the popularity of virtual assistants (e.g., Siri, Alexa), the use of
speech recognition is now becoming more and more widespread.However, speech
signals contain a lot of sensitive information, such as the speaker's identity,
which raises privacy concerns.The presented experiments show that the
representations extracted by the deep layers of speech recognition networks
contain speaker information.This paper aims to produce an anonymous
representation while preserving speech recognition performance.To this end, we
propose to use vector quantization to constrain the representation space and
induce the network to suppress the speaker identity.The choice of the
quantization dictionary size allows to configure the trade-off between utility
(speech recognition) and privacy (speaker identity concealment).
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:01:11 GMT""}]","2022-03-21"
"2203.09939","David Winn","David R Winn","Novel Low Workfunction Semiconductors for Calorimetry and Detection:
  High Energy, Dark Matter and Neutrino Phenomena","contribution to Snowmass",,,,"physics.ins-det hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This White Paper seeks to extend the applications of two weakly bound
semiconductor materials, Cs3Sb and Ag-O-Cs first developed decades ago for
vacuum photodetectors S1, S-11 photocathodes, respectively, proven to have low
electron-hole pair energies. Rather than thin film photocathodes, we propose
fabrication of these semiconductors in shapes and volumes which could be used
as diode or drifted ion detectors for low energy depositions via atom or
few-atomic layers. Ag-O-Cs has an e-hole pair threshold pair low as 0.5-0.7 eV
deposited energy, practical when cooled below 4 degrees K; Cs3Sb, with pair
energy as low as 1.6-2 eV - less than Si (3.6 eV), but with thermal noise at
room temperature similar to Si at -30 deg C. Exposure of photomultipliers to 10
MRad doses has shown that thin alkali photocathodes do not degrade more than 2%
of initial quantum efficiency.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 17:44:20 GMT""}]","2022-03-21"
"2203.09941","David Winn","David R Winn, Yasar Onel","Photomultipliers as High Rate Radiation-Resistant In-Situ Sensors in
  Future Experiments","Contribution to Snowmass",,,,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the Energy Frontier we suggest developing high rate (100 MHz) finely
segmented forward calorimetry preradiators with time resolution <50 ps which
will survive the first 1-2 Lint of incident high radiation doses, protecting
forward calorimeters 3<y<6; less than 5 degrees to the beam behind them from
radiation damage, with high granularity, high rate capability and 30ps time
resolution (4D calorimetry) providing lepton and photon ID and measurement. In
the Intensity Frontier beam particle selection, such as tagged neutrino and
kaon beams, and lepton violation experiments with muons require very high
rates. Cosmic Frontiers requiring low power, non-cooled calorimetry or optical
detection that can keep track of particles or photons arriving at 100 MHz, and
survivable for years in space radiation may also benefit. The basic research is
to use compact channelized PMTs with quartz or other radiation resistant
windows with metal envelopes as an in-situ sensor, directly coupled to Cerenkov
(or radiation-resistant scintillator) tiles, utilizing the dynode signals as a
potentially compensating 2nd signal, and with no active electronics. If
successful, directions include proposals for high SE yield mesh dynode
activator materials such as GaP or B doped diamond films with 25 SEe at 300 eV
electron energies, and possibly for compact low cost tile SE sensors with no
photocathode, far easier to fabricate than PMTs with all metal final assembly
in air, brazed seals; bakeout 900 C; pump out with tipoff - vacuum 100x higher
than PMTs. Such sensors have many applications beyond HEP, in research,
medicine, industry and defense.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 23:45:01 GMT""}]","2022-03-21"
"2203.09942","David Winn","David R Winn, Y. Onel, B. Bilki","High Rate and High Precision Timing and Calorimeter Detectors","contribution to Snowmass",,,,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High precision timing, high rate calorimeters, and radiation resistance are
becoming an important issue in particle physics especially in Energy and
Intensity Frontiers. We discuss doped Zinc Oxide (ZnO:Ga or GZO; ZnO:X where X
is Al, Cu or others) as a very fast scintillator and wavelength shifter (WLS),
Total internal reflection films, and PMT capable of counting at 300 MHz with 10
ps timing precision, with superior radiation resistance.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 02:48:04 GMT""}]","2022-03-21"
"2203.09943","Eugene Bagdasaryan","Eugene Bagdasaryan, Congzheng Song, Rogier van Dalen, Matt Seigel, and
  \'Aine Cahill","Training a Tokenizer for Free with Private Federated Learning",,,,,"cs.CR cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Federated learning with differential privacy, i.e. private federated learning
(PFL), makes it possible to train models on private data distributed across
users' devices without harming privacy. PFL is efficient for models, such as
neural networks, that have a fixed number of parameters, and thus a
fixed-dimensional gradient vector. Such models include neural-net language
models, but not tokenizers, the topic of this work. Training a tokenizer
requires frequencies of words from an unlimited vocabulary, and existing
methods for finding an unlimited vocabulary need a separate privacy budget.
  A workaround is to train the tokenizer on publicly available data. However,
in this paper we first show that a tokenizer trained on mismatched data results
in worse model performance compared to a privacy-violating ""oracle"" tokenizer
that accesses user data, with perplexity increasing by 20%. We also show that
sub-word tokenizers are better suited to the federated context than word-level
ones, since they can encode new words, though with more tokens per word.
  Second, we propose a novel method to obtain a tokenizer without using any
additional privacy budget. During private federated learning of the language
model, we sample from the model, train a new tokenizer on the sampled
sequences, and update the model embeddings. We then continue private federated
learning, and obtain performance within 1% of the ""oracle"" tokenizer. Since
this process trains the tokenizer only indirectly on private data, we can use
the ""postprocessing guarantee"" of differential privacy and thus use no
additional privacy budget.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:29:39 GMT""}]","2022-03-21"
"2203.09954","Yurong Qian","Yurong Qian, Jindan Xu, Shuhan Zhu, Wei Xu, Lisheng Fan, and George K.
  Karagiannidis","Learning to Optimize Resource Assignment for Task Offloading in Mobile
  Edge Computing",,,,,"eess.SP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider a multiuser mobile edge computing (MEC) system,
where a mixed-integer offloading strategy is used to assist the resource
assignment for task offloading. Although the conventional branch and bound
(BnB) approach can be applied to solve this problem, a huge burden of
computational complexity arises which limits the application of BnB. To address
this issue, we propose an intelligent BnB (IBnB) approach which applies deep
learning (DL) to learn the pruning strategy of the BnB approach. By using this
learning scheme, the structure of the BnB approach ensures near-optimal
performance and meanwhile DL-based pruning strategy significantly reduces the
complexity. Numerical results verify that the proposed IBnB approach achieves
optimal performance with complexity reduced by over 80%.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:17:29 GMT""}]","2022-03-21"
"2203.10114","Jussi Leinonen","Jussi Leinonen, Ulrich Hamann, Urs Germann","Seamless lightning nowcasting with recurrent-convolutional deep learning","21 pages, 9 figures. Accepted to Artificial Intelligence for the
  Earth Sciences. Changes after the previous version are in response to the
  comments received from one remaining anonymous reviewer","Artif. Intell. Earth Syst., 1, e220043 (2022)","10.1175/AIES-D-22-0043.1",,"physics.ao-ph cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  A deep learning model is presented to nowcast the occurrence of lightning at
a five-minute time resolution 60 minutes into the future. The model is based on
a recurrent-convolutional architecture that allows it to recognize and predict
the spatiotemporal development of convection, including the motion, growth and
decay of thunderstorm cells. The predictions are performed on a stationary
grid, without the use of storm object detection and tracking. The input data,
collected from an area in and surrounding Switzerland, comprise ground-based
radar data, visible/infrared satellite data and derived cloud products,
lightning detection, numerical weather prediction and digital elevation model
data. We analyze different alternative loss functions, class weighting
strategies and model features, providing guidelines for future studies to
select loss functions optimally and to properly calibrate the probabilistic
predictions of their model. Based on these analyses, we use focal loss in this
study, but conclude that it only provides a small benefit over cross entropy,
which is a viable option if recalibration of the model is not practical. The
model achieves a pixel-wise critical success index (CSI) of 0.45 to predict
lightning occurrence within 8 km over the 60-min nowcast period, ranging from a
CSI of 0.75 at a 5-min lead time to a CSI of 0.32 at a 60-min lead time.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 12:54:17 GMT""},{""version"":""v2"",""created"":""Mon, 11 Jul 2022 10:10:37 GMT""},{""version"":""v3"",""created"":""Tue, 27 Sep 2022 10:21:31 GMT""}]","2023-03-16"
"2203.10115","Xia Chen","Xia Chen, Jimmy Abualdenien, Manav Mahan Singh, Andr\'e Borrmann,
  Philipp Geyer","Introducing causal inference in the energy-efficient building design
  process","20 pages, 10 figures","Energy and Buildings, 2022","10.1016/j.enbuild.2022.112583",,"stat.ME cs.CE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  ""What-if"" questions are intuitively generated and commonly asked during the
design process. Engineers and architects need to inherently conduct design
decisions, progressing from one phase to another. They either use empirical
domain experience, simulations, or data-driven methods to acquire consequential
feedback. We take an example from an interdisciplinary domain of
energy-efficient building design to argue that the current methods for decision
support have limitations or deficiencies in four aspects: parametric
independency identification, gaps in integrating knowledge-based and
data-driven approaches, less explicit model interpretation, and ambiguous
decision support boundaries. In this study, we first clarify the nature of
dynamic experience in individuals and constant principal knowledge in design.
Subsequently, we introduce causal inference into the domain. A four-step
process is proposed to discover and analyze parametric dependencies in a
mathematically rigorous and computationally efficient manner by identifying the
causal diagram with interventions. The causal diagram provides a nexus for
integrating domain knowledge with data-driven methods, providing
interpretability and testability against the domain experience within the
design space. Extracting causal structures from the data is close to the nature
design reasoning process. As an illustration, we applied the properties of the
proposed estimators through simulations. The paper concludes with a feasibility
study demonstrating the proposed framework's realization.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 22:00:21 GMT""},{""version"":""v2"",""created"":""Thu, 23 Jun 2022 23:49:56 GMT""},{""version"":""v3"",""created"":""Mon, 24 Oct 2022 21:27:18 GMT""}]","2023-01-05"
"2203.10972","Ronald Mahler","Ronald Mahler","Mathematical Representation of Multitarget Systems","7 pages, 0 figures, preprint (not yet published)",,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  This paper systematically compares two mathematical foundations for
multitarget tracking: labeled random finite sets (LRFS's) and trajectory random
finite sets (TRFS's).
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 02:39:36 GMT""}]","2022-03-22"
"2203.11024","Akira Kinose","Akira Kinose, Masashi Okada, Ryo Okumura, Tadahiro Taniguchi","Multi-View Dreaming: Multi-View World Model with Contrastive Learning","7 pages, 8 figures",,,,"cs.AI cs.RO cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose Multi-View Dreaming, a novel reinforcement learning
agent for integrated recognition and control from multi-view observations by
extending Dreaming. Most current reinforcement learning method assumes a
single-view observation space, and this imposes limitations on the observed
data, such as lack of spatial information and occlusions. This makes obtaining
ideal observational information from the environment difficult and is a
bottleneck for real-world robotics applications. In this paper, we use
contrastive learning to train a shared latent space between different
viewpoints, and show how the Products of Experts approach can be used to
integrate and control the probability distributions of latent states for
multiple viewpoints. We also propose Multi-View DreamingV2, a variant of
Multi-View Dreaming that uses a categorical distribution to model the latent
state instead of the Gaussian distribution. Experiments show that the proposed
method outperforms simple extensions of existing methods in a realistic robot
control task.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 02:33:31 GMT""}]","2022-03-22"
"2203.11276","Jan Boelts","Jan Boelts","Model Comparison in Approximate Bayesian Computation","Master thesis supervised by Henning Sprekeler and Jakob H. Macke",,"10.13140/RG.2.2.20085.88807",,"stat.ML cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  A common problem in natural sciences is the comparison of competing models in
the light of observed data. Bayesian model comparison provides a statistically
sound framework for this comparison based on the evidence each model provides
for the data. However, this framework relies on the calculation of likelihood
functions which are intractable for most models used in practice. Previous
approaches in the field of Approximate Bayesian Computation (ABC) circumvent
the evaluation of the likelihood and estimate the model evidence based on
rejection sampling, but they are typically computationally intense. Here, I
propose a new efficient method to perform Bayesian model comparison in ABC.
Based on recent advances in posterior density estimation, the method
approximates the posterior over models in parametric form. In particular, I
train a mixture-density network to map features of the observed data to the
posterior probability of the models. The performance is assessed with two
examples. On a tractable model comparison problem, the underlying exact
posterior probabilities are predicted accurately. In a use-case scenario from
computational neuroscience -- the comparison between two ion channel models --
the underlying ground-truth model is reliably assigned a high posterior
probability. Overall, the method provides a new efficient way to perform
Bayesian model comparison on complex biophysical models independent of the
model architecture.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:24:16 GMT""}]","2022-03-23"
"2203.11733","Shengkun Wu","Shengkun Wu and Xingquan Li","GBEM: Galerkin Boundary Element Method for 3-D Capacitance Extraction",,,,,"math.NA cs.CE cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For modern IC design, electromagnetic coupling among interconnect wires plays
an increasingly important role in signoff analysis. The requirement of fast and
accurate capacitance extraction is becoming more and more urgent.The critical
step of extracting capacitance among interconnect wires is solving electric
field. However, due to the high computational complexity, solving electric
field is extreme timing-consuming. To improve computational efficiency, we
propose a Galerkin boundary element method (GBEM) to extract capacitance. The
advantage of this method is that it can greatly reduce the number of boundary
elements on the premise of ensuring that the error is small enough. As a
consequence, the matrix order of the discretization equation will also
decrease. The experiments in this paper have proved this advantage of our
algorithm. Moreover, we have took advantage of some mathematical theorems in
this paper. Our attempt shows that there will be more connections between the
capacitance extraction and some mathematical conception so that we can use more
mathematical tools to solve the problems of capacitance extraction.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 08:23:38 GMT""}]","2022-03-23"
"2203.12456","Jun Lu","Jun Lu, Shao Yi","Reducing overestimating and underestimating volatility via the augmented
  blending-ARCH model",,"Applied Economics and Finance 9 (2), 48-59, 2022","10.11114/aef.v9i2.5507",,"q-fin.ST cs.LG","http://creativecommons.org/licenses/by/4.0/","  SVR-GARCH model tends to ""backward eavesdrop"" when forecasting the financial
time series volatility in which case it tends to simply produce the prediction
by deviating the previous volatility. Though the SVR-GARCH model has achieved
good performance in terms of various performance measurements, trading
opportunities, peak or trough behaviors in the time series are all hampered by
underestimating or overestimating the volatility. We propose a blending ARCH
(BARCH) and an augmented BARCH (aBARCH) model to overcome this kind of problem
and make the prediction towards better peak or trough behaviors. The method is
illustrated using real data sets including SH300 and S&P500. The empirical
results obtained suggest that the augmented and blending models improve the
volatility forecasting ability.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 08:52:01 GMT""}]","2022-06-23"
"2203.12461","Dibakar Ghosh Dr.","Md Sayeed Anwar and Dibakar Ghosh","Intralayer and interlayer synchronization in multiplex network with
  higher-order interactions","10 pages, 7 figures; Accepted for publication in Chaos","Chaos: An Interdisciplinary Journal of Nonlinear Science 32 (3),
  033125 (2022)","10.1063/5.0074641",,"nlin.AO nlin.CD physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  Recent developments in complex systems have witnessed that many real-world
scenarios, successfully represented as networks are not always restricted to
binary interactions but often include higher-order interactions among the
nodes. These beyond pairwise interactions are preferably modeled by
hypergraphs, where hyperedges represent higher-order interactions between a set
of nodes. In this work, we consider a multiplex network where the intralayer
connections are represented by hypergraphs, called multiplex hypergraph. The
hypergraph is constructed by mapping the maximal cliques of a scale-free
network to hyperedges of suitable sizes. We investigate the intralayer and
interlayer synchronization of such multiplex structures. Our study unveils that
the intralayer synchronization appreciably enhances when the higher-order
structure is taken into consideration inspite of only pairwise connections. We
derive the necessary condition for stable synchronization states by the master
stability function approach, which perfectly agrees with the numerical results.
We also explore the robustness of interlayer synchronization and find that for
the multiplex structures with many-body interaction, the interlayer
synchronization is more persistent than multiplex networks with pairwise
interaction.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 08:22:36 GMT""}]","2022-04-22"
"2203.12675","Xiaoyu He Dr.","Xiaoyu He and Zibin Zheng and Yuren Zhou","MMES: Mixture Model based Evolution Strategy for Large-Scale
  Optimization",,"IEEE Transactions on Evolutionary Computation, 2021, 25(2):
  320-333","10.1109/TEVC.2020.3034769",,"cs.NE cs.AI","http://creativecommons.org/licenses/by/4.0/","  This work provides an efficient sampling method for the covariance matrix
adaptation evolution strategy (CMA-ES) in large-scale settings. In contract to
the Gaussian sampling in CMA-ES, the proposed method generates mutation vectors
from a mixture model, which facilitates exploiting the rich variable
correlations of the problem landscape within a limited time budget. We analyze
the probability distribution of this mixture model and show that it
approximates the Gaussian distribution of CMA-ES with a controllable accuracy.
We use this sampling method, coupled with a novel method for mutation strength
adaptation, to formulate the mixture model based evolution strategy (MMES) -- a
CMA-ES variant for large-scale optimization. The numerical simulations show
that, while significantly reducing the time complexity of CMA-ES, MMES
preserves the rotational invariance, is scalable to high dimensional problems,
and is competitive against the state-of-the-arts in performing global
optimization.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 14:33:37 GMT""}]","2022-03-25"
"2203.14717","Armin Salimi-Badr PhD","Athena Abdi, Armin Salimi-Badr","A novel evolutionary-based neuro-fuzzy task scheduling approach to
  jointly optimize the main design challenges of heterogeneous MPSoCs",,,,,"cs.DC cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, an online task scheduling and mapping method based on a fuzzy
neural network (FNN) learned by an evolutionary multi-objective algorithm
(NSGA-II) to jointly optimize the main design challenges of heterogeneous
MPSoCs is proposed. In this approach, first, the FNN parameters are trained
using an NSGA-II-based optimization engine by considering the main design
challenges of MPSoCs including temperature, power consumption, failure rate,
and execution time on a training dataset consisting of different application
graphs of various sizes. Next, the trained FNN is employed as an online task
scheduler to jointly optimize the main design challenges in heterogeneous
MPSoCs. Due to the uncertainty in sensor measurements and the difference
between computational models and reality, applying the fuzzy neural network is
advantageous in online scheduling procedures. The performance of the method is
compared with some previous heuristic, meta-heuristic, and rule-based
approaches in several experiments. Based on these experiments our proposed
method outperforms the related studies in optimizing all design criteria. Its
improvement over related heuristic and meta-heuristic approaches are estimated
10.58% in temperature, 9.22% in power consumption, 39.14% in failure rate, and
12.06% in execution time, averagely. Moreover, considering the interpretable
nature of the FNN, the frequently fired extracted fuzzy rules of the proposed
approach are demonstrated.
","[{""version"":""v1"",""created"":""Mon, 14 Mar 2022 18:50:15 GMT""}]","2022-03-29"
"2203.15786","Serge Kernbach","Serge Kernbach","Electric-field-coupled oscillators for collective electrochemical
  perception in underwater robotics",,"Bioinspiration & Biomimetics, 2022","10.1088/1748-3190/ac93d8",,"cs.RO physics.ins-det","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This work explores the application of nonlinear oscillators coupled by
electric field in water for collective tasks in underwater robotics. Such
coupled oscillators operate in clear and colloidal (mud, bottom silt) water and
represent a collective electrochemical sensor that is sensitive to global
environmental parameters, geometry of common electric field and spatial
dynamics of autonomous underwater vehicles (AUVs). Implemented in hardware and
software, this approach can be used to create global awareness in the group of
robots, which possess limited sensing and communication capabilities. Using
oscillators from different AUVs enables extending the range limitations related
to electric dipole of a single AUV. Applications of this technique are
demonstrated for detecting the number of AUVs, distances between them,
perception of dielectric objects, synchronization of behavior and
discrimination between 'collective self' and 'collective non-self' through an
'electrical mirror'. These approaches have been implemented in several research
projects with AUVs in fresh and salt water.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 10:44:30 GMT""}]","2022-09-23"
"2203.16443","Spiros Cotsakis","Spiros Cotsakis and Alexander P. Yefremov","100 years of mathematical cosmology: Models, theories, and problems","91 pages","Phil. Trans. R. Soc. A.380 (2022) 20210191","10.1098/rsta.2021.0191",,"physics.hist-ph astro-ph.CO gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An elementary survey of mathematical cosmology is presented. We cover certain
key ideas and developments in a qualitative way, from the time of the Einstein
static universe in 1917 until today. We divide our presentation into four main
parts, the first part containing important cosmologies discovered until 1960.
The second period (1960-80) contains discussions of geometric extensions of the
standard cosmology, singularities, chaotic behaviour, and the initial input of
particle physics ideas into cosmology. Our survey for the third period
(1980-2000) continues with brief descriptions of the main ideas of inflation,
the multiverse, quantum, Kaluza-Klein, and string cosmologies, wormholes and
baby universes, cosmological stability, and modified gravity. The last period
which ends today includes various more advanced topics such as M-theoretic
cosmology, braneworlds, the landscape, topological issues, the measure problem,
genericity, dynamical singularities, and dark energy. We emphasize certain
threads that run throughout the whole period of development of theoretical
cosmology and underline their importance in the overall structure of the field.
We end this outline with an inclusion of the abstracts of all papers
contributed to the Philosophical Transactions of the Royal Society A, Theme
Issue `The Future of Mathematical Cosmology'.
","[{""version"":""v1"",""created"":""Tue, 15 Mar 2022 15:21:37 GMT""}]","2022-03-31"
