"2202.05724","Alexander Andronov Dr","A. Andronov and V. Pozdniakova","On RT CW THz Cyclotron Resonance lasing in graphene in crossed E, H
  fields",,,,,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In framework of classical consideration of electron trajectories in crossed
electric and magnetic fields and conductivity of electron system on cyclotron
resonance in single layer graphene possibility to achieve cyclotron lasing in
hexagonal boron nitride single layer graphene sandwiches is discussed. By
simplified consideration with known data on scattering rate in the sandwiches
it is demonstrated that the continuing wave laser action can be achieved in
high quality sandwiches at room temperature at frequencies above one tera hertz
in magnetic field above one Tesla.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:01:59 GMT""}]","2022-02-14"
"2202.05725","Zesheng Chen","Zesheng Chen","On the Detection of Adaptive Adversarial Attacks in Speaker Verification
  Systems",,"IEEE Internet of Things Journal, 2023","10.1109/JIOT.2023.3267619",,"cs.CR cs.LG cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Speaker verification systems have been widely used in smart phones and
Internet of things devices to identify legitimate users. In recent work, it has
been shown that adversarial attacks, such as FAKEBOB, can work effectively
against speaker verification systems. The goal of this paper is to design a
detector that can distinguish an original audio from an audio contaminated by
adversarial attacks. Specifically, our designed detector, called MEH-FEST,
calculates the minimum energy in high frequencies from the short-time Fourier
transform of an audio and uses it as a detection metric. Through both analysis
and experiments, we show that our proposed detector is easy to implement, fast
to process an input audio, and effective in determining whether an audio is
corrupted by FAKEBOB attacks. The experimental results indicate that the
detector is extremely effective: with near zero false positive and false
negative rates for detecting FAKEBOB attacks in Gaussian mixture model (GMM)
and i-vector speaker verification systems. Moreover, adaptive adversarial
attacks against our proposed detector and their countermeasures are discussed
and studied, showing the game between attackers and defenders.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:02:06 GMT""},{""version"":""v2"",""created"":""Mon, 1 Aug 2022 13:17:25 GMT""}]","2023-04-19"
"2202.05726","Mikhail Zubkov Dr","J. Miller, G.E.Volovik, M.A.Zubkov","Fundamental scalar field with zero dimension from anomaly cancelations","Latex, 12 pages, 3 figures","Phys. Rev. D 106 (2022), 015021","10.1103/PhysRevD.106.015021",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article a novel mechanism for dynamical electroweak symmetry breaking
and the ensuing appearance of fermion mass terms in the action is proposed. The
action contains massless fermions of the SM coupled to gravity through a new
type of non-minimal coupling to the vielbein field. The corresponding coupling
constants in our approach become zero-dimension scalar fields. Such scalar
fields provide the cancellation of the Weyl anomaly \cite{Boyle:2021jaz}.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:02:54 GMT""},{""version"":""v2"",""created"":""Sat, 25 Jun 2022 22:03:44 GMT""}]","2022-09-14"
"2202.05727","Alexander Urech","Alexander Urech, Ivo H. A. Knottnerus, Robert J. C. Spreeuw, and
  Florian Schreck","Narrow-line imaging of single strontium atoms in shallow optical
  tweezers","11 pages, 6 figures","Phys. Rev. Research 4, 023245 (2022)","10.1103/PhysRevResearch.4.023245",,"physics.atom-ph cond-mat.quant-gas","http://creativecommons.org/licenses/by/4.0/","  Single strontium atoms held in optical tweezers have so far only been imaged
using the broad $^{1\hspace{-0.3ex}}S_0$-$^{1\hspace{-0.3ex}}P_1$ transition.
For Yb, use of the narrow (183 kHz-wide)
$^{1\hspace{-0.3ex}}S_0$-$^{3\hspace{-0.3ex}}P_1$ transition for simultaneous
imaging and cooling has been demonstrated in tweezers with a magic wavelength
for the imaging transition. We demonstrate high-fidelity imaging of single Sr
atoms using its even narrower (7.4 kHz-wide) $^{1\hspace{-0.3ex}}S_0$ -
$^{3\hspace{-0.3ex}}P_1$ transition. The atoms are trapped in
\textit{non}-magic-wavelength tweezers. We detect the photons scattered during
Sisyphus cooling, thus keeping the atoms near the motional ground state of the
tweezer throughout imaging. The fidelity of detection is 0.9991(4) with a
survival probability of 0.97(2). An atom in a tweezer can be held under imaging
conditions for 79(3) seconds allowing for hundreds of images to be taken,
limited mainly by background gas collisions. We detect atoms in an arrary of 36
tweezers with 813.4-nm light and trap depths of 135(20) $\mu$K. This trap depth
is three times shallower than typically used for imaging on the broad
$^{1\hspace{-0.3ex}}S_0$ - $^{1\hspace{-0.3ex}}P_1$ transition. Narrow-line
imaging opens the possibility to even further reduce this trap depth, as long
as all trap frequencies are kept larger than the imaging transition linewidth.
Imaging using a narrow-linewidth transition in a non-magic-wavelength tweezer
also allows for selective imaging of a given tweezer. As a demonstration, we
selectively image (hide) a single tweezer from the array. This provides a
useful tool for quantum error correction protocols.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:03:52 GMT""}]","2022-06-28"
"2202.05728","Ahmad Hammoudeh","Ahmad Hammoudeh, Bastien Vanderplaetse, St\'ephane Dupont","Deep soccer captioning with transformer: dataset, semantics-related
  losses, and multi-level evaluation",,,"10.1016/j.procs.2022.10.125",,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  This work aims at generating captions for soccer videos using deep learning.
In this context, this paper introduces a dataset, model, and triple-level
evaluation. The dataset consists of 22k caption-clip pairs and three visual
features (images, optical flow, inpainting) for ~500 hours of \emph{SoccerNet}
videos. The model is divided into three parts: a transformer learns language,
ConvNets learn vision, and a fusion of linguistic and visual features generates
captions. The paper suggests evaluating generated captions at three levels:
syntax (the commonly used evaluation metrics such as BLEU-score and CIDEr),
meaning (the quality of descriptions for a domain expert), and corpus (the
diversity of generated captions). The paper shows that the diversity of
generated captions has improved (from 0.07 reaching 0.18) with
semantics-related losses that prioritize selected words. Semantics-related
losses and the utilization of more visual features (optical flow, inpainting)
improved the normalized captioning score by 28\%. The web page of this work:
https://sites.google.com/view/soccercaptioning}{https://sites.google.com/view/soccercaptioning
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:04:03 GMT""},{""version"":""v2"",""created"":""Wed, 30 Nov 2022 12:26:31 GMT""}]","2022-12-01"
"2202.05729","Rituraj Borah","Rituraj Borah and Sammy W. Verbruggen","Effect of size distribution, skewness and roughness on the optical
  properties of colloidal plasmonic nanoparticles",,"Colloids and Surfaces A: Physicochemical and Engineering Aspects,
  Volume 640, 5 May 2022, 128521","10.1016/j.colsurfa.2022.128521",,"physics.optics cond-mat.mes-hall cond-mat.mtrl-sci physics.app-ph physics.atm-clus","http://creativecommons.org/publicdomain/zero/1.0/","  It is a generally accepted idea that the particle size distribution strongly
affects the optical spectra of colloidal plasmonic nanoparticles. It is often
quoted as one of the main reasons while explaining the mismatch between the
theoretical and experimental optical spectra of such nanoparticles. In this
work, these aspects are critically analyzed by means of a bottom up statistical
approach that considers variables such as mean, standard deviation and skewness
of the nanoparticle size distribution independently from one another. By
assuming normal and log-normal distributions of the particle size, the effect
of the statistical parameters on the Mie analytical optical spectra of
colloidal nanoparticles was studied. The effect of morphology was also studied
numerically in order to understand to what extent it can play a role. It is our
finding that the particle polydispersity, skewness and surface morphology in
fact only weakly impact the optical spectra. While, the selection of suitable
optical constants with regard to the crystallinity of the nanoparticles is a
far more influential factor for correctly predicting both the plasmon band
position and the plasmon bandwidth in theoretical simulations of the optical
spectra. It is shown that the mean particle size can be correctly estimated
directly from the plasmon band position, as it is the mean that determines the
resonance wavelength. The standard deviation can on the other hand be estimated
from the intensity distribution data obtained from dynamic light scattering
experiments. The results reported herein clear the ambiguity around particle
size distribution and optical response of colloidal plasmonic nanoparticles.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:04:48 GMT""}]","2022-02-14"
"2202.05730","Tiankuan Liu","Tiankuan Liu (on behalf of the ATLAS Liquid Argon Calorimeter Group)","A 4.9-GHz Low Power, Low Jitter, LC Phase Locked Loop","8 pages, 8 figures","JINST 5 C12045 (2011)","10.1088/1748-0221/5/12/C12045",,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a low power, low jitter LC phase locked loop (PLL) which
has been designed and fabricated in a commercial 0.25-um Silicon-on-Sapphire
CMOS technology. Random jitter and deterministic jitter of the PLL are 1.3 ps
and 7.5 ps, respectively. The measured tuning range, from 4.6 to 5.0 GHz, is
narrower than the expected one, from 3.8 to 5.0 GHz. The narrow tuning range
issue has been investigated and traced to the first stage of the divider chain.
The power consumption at the central frequency is 111 mW.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:05:11 GMT""}]","2022-02-14"
"2202.05731","Sitabhra Sinha","Chandrashekar Kuyyamudi, Shakti N. Menon, Sitabhra Sinha","Flags, Landscapes and Signaling: Contact-mediated inter-cellular
  interactions enable plasticity in fate determination driven by positional
  information","10 pages, 6 figures",,"10.1007/s12648-022-02348-6",,"q-bio.TO nlin.PS physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multicellular organisms exhibit a high degree of structural organization with
specific cell types always occurring in characteristic locations. The
conventional framework for describing the emergence of such consistent spatial
patterns is provided by Wolpert's ""French flag"" paradigm. According to this
view, intra-cellular genetic regulatory mechanisms use positional information
provided by morphogen concentration gradients to differentially express
distinct fates, resulting in a characteristic pattern of differentiated cells.
However, recent experiments have shown that suppression of inter-cellular
interactions can alter these spatial patterns, suggesting that cell fates are
not exclusively determined by the regulation of gene expression by local
morphogen concentration. Using an explicit model where adjacent cells
communicate by Notch signaling, we provide a mechanistic description of how
contact-mediated interactions allow information from the cellular environment
to be incorporated into cell fate decisions. Viewing cellular differentiation
in terms of trajectories along an epigenetic landscape (as first enunciated by
Waddington), our results suggest that the contours of the landscape are moulded
differently in a cell position-dependent manner, not only by the global signal
provided by the morphogen but also by the local environment via cell-cell
interactions. We show that our results are robust with respect to different
choices of coupling between the inter-cellular signaling apparatus and the
intra-cellular gene regulatory dynamics. Indeed, we show that the broad
features can be observed even in abstract spin models. Our work reconciles
interaction-mediated self-organized pattern formation with boundary-organized
mechanisms involving signals that break symmetry.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:07:59 GMT""}]","2022-05-11"
"2202.05732","Vasily Sartakov A.","Vasily A. Sartakov, Llu\'is Vilanova, David Eyers, Takahiro Shinagawa,
  Peter Pietzuch","CAP-VMs: Capability-Based Isolation and Sharing for Microservices",,,,,"cs.OS","http://creativecommons.org/licenses/by/4.0/","  Cloud stacks must isolate application components, while permitting efficient
data sharing between components deployed on the same physical host.
Traditionally, the MMU enforces isolation and permits sharing at page
granularity. MMU approaches, however, lead to cloud stacks with large TCBs in
kernel space, and page granularity requires inefficient OS interfaces for data
sharing. Forthcoming CPUs with hardware support for memory capabilities offer
new opportunities to implement isolation and sharing at a finer granularity.
  We describe cVMs, a new VM-like abstraction that uses memory capabilities to
isolate application components while supporting efficient data sharing, all
without mandating application code to be capability-aware. cVMs share a single
virtual address space safely, each having only capabilities to access its own
memory. A cVM may include a library OS, thus minimizing its dependency on the
cloud environment. cVMs efficiently exchange data through two capability-based
primitives assisted by a small trusted monitor: (i) an asynchronous read-write
interface to buffers shared between cVMs; and (ii) a call interface to transfer
control between cVMs. Using these two primitives, we build more expressive
mechanisms for efficient cross-cVM communication. Our prototype implementation
using CHERI RISC-V capabilities shows that cVMs isolate services (Redis and
Python) with low overhead while improving data sharing.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:08:43 GMT""},{""version"":""v2"",""created"":""Fri, 24 Jun 2022 09:55:17 GMT""}]","2022-06-27"
"2202.05733","Tiankuan Liu","Tiankuan Liu (for the ATLAS Liquid Argon Calorimeter Group)","Optical Links for ATLAS Liquid Argon Calorimeter Front-end Electronics
  Readout","8 pages, 6 figures","JINST 6 C01013 (2011)","10.1088/1748-0221/6/01/C01013",,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the optical data links for the ATLAS liquid argon calorimeter. The
current status of the vertical cavity surface emitting laser failures, the
up-to-date results in searching for the failure cause, experiences gained in
the searching process, possible backup plans for the optical transmitters and
the lessons learned are also discussed.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:10:37 GMT""}]","2022-02-14"
"2202.05734","Thomas Gastine","V. Gopinath, A. Fournier, T. Gastine","An assessment of implicit-explicit time integrators for the
  pseudo-spectral approximation of Boussinesq thermal convection in an annulus","39 pages, 15 figures, 5 tables, accepted for publication in JCP",,"10.1016/j.jcp.2022.110965",,"physics.flu-dyn physics.comp-ph physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze the behaviour of an ensemble of time integrators applied to the
semi-discrete problem resulting from the spectral discretization of the
equations describing Boussinesq convection in a cylindrical annulus. The
equations are cast in a vorticity-streamfunction formulation that yields a
differential algebraic equation (DAE). The ensemble comprises 28 members: 4
implicit-explicit multistep schemes, 22 implicit-explicit Runge-Kutta (IMEX-RK)
schemes, and 2 fully explicit schemes used for reference. The schemes are
assessed for 11 different physical setups that cover laminar and turbulent
regimes. Multistep and order 2 IMEX-RK methods exhibit their expected order of
convergence under all circumstances. IMEX-RK methods of higher-order show
occasional order reduction that impacts both algebraic and differential field
variables. We ascribe the order reduction to the stiffness of the problem and,
to a larger extent, the presence of the DAE. Using the popular Crank-Nicolson
Adams-Bashforth of order 2 (CNAB2) integrator as reference, performance is
defined by the ratio of maximum admissible time step to the cost of performing
one iteration; the maximum admissible time step is determined by inspection of
the time series of viscous dissipation within the system, which guarantees a
physically acceptable solution. Relative performance is bounded between 0.5 and
1.5 across all studied configurations. Considering accuracy jointly with
performance, we find that 6 schemes consistently outperform CNAB2, meaning that
in addition to allowing for a more efficient calculation, the accuracy that
they achieve at their operational limit of stability yields a lower error. In
our most turbulent setup, where the behaviour of the methods is almost entirely
dictated by their explicit component, 13 IMEX-RK integrators outperform CNAB2
in terms of accuracy and efficiency.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:17:40 GMT""}]","2022-02-14"
"2202.05735","Kevin Kotzen","Kevin Kotzen, Peter H. Charlton, Sharon Salabi, Lea Amar, Amir
  Landesberg and Joachim A. Behar","SleepPPG-Net: a deep learning algorithm for robust sleep staging from
  continuous photoplethysmography","11 pages, 10 figures",,,,"cs.LG eess.SP","http://creativecommons.org/licenses/by/4.0/","  Introduction: Sleep staging is an essential component in the diagnosis of
sleep disorders and management of sleep health. It is traditionally measured in
a clinical setting and requires a labor-intensive labeling process. We
hypothesize that it is possible to perform robust 4-class sleep staging using
the raw photoplethysmography (PPG) time series and modern advances in deep
learning (DL). Methods: We used two publicly available sleep databases that
included raw PPG recordings, totalling 2,374 patients and 23,055 hours. We
developed SleepPPG-Net, a DL model for 4-class sleep staging from the raw PPG
time series. SleepPPG-Net was trained end-to-end and consists of a residual
convolutional network for automatic feature extraction and a temporal
convolutional network to capture long-range contextual information. We
benchmarked the performance of SleepPPG-Net against models based on the
best-reported state-of-the-art (SOTA) algorithms. Results: When benchmarked on
a held-out test set, SleepPPG-Net obtained a median Cohen's Kappa ($\kappa$)
score of 0.75 against 0.69 for the best SOTA approach. SleepPPG-Net showed good
generalization performance to an external database, obtaining a $\kappa$ score
of 0.74 after transfer learning. Perspective: Overall, SleepPPG-Net provides
new SOTA performance. In addition, performance is high enough to open the path
to the development of wearables that meet the requirements for usage in
clinical applications such as the diagnosis and monitoring of obstructive sleep
apnea.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:17:42 GMT""},{""version"":""v2"",""created"":""Fri, 18 Feb 2022 19:13:21 GMT""},{""version"":""v3"",""created"":""Tue, 15 Mar 2022 16:55:41 GMT""},{""version"":""v4"",""created"":""Fri, 29 Apr 2022 15:00:18 GMT""}]","2022-05-02"
"2202.05736","Kamil David Sommer","Kamil David Sommer, Lucas Reineking, Yogesh Parry Ravichandran,
  Romuald Skoda, Martin M\""onnigmann","Estimating flow fields with Reduced Order Models of Centrifugal Pumps","14 pages, 12 figures",,,,"physics.flu-dyn cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  The estimation of fluid flows inside a centrifugal pump in realtime is a
challenging task that cannot be achieved with long-established methods like CFD
due to their computational demands. We use a projection-based reduced order
model (ROM) instead. Based on this ROM, a realtime observer can be devised that
estimates the temporally and spatially resolved velocity and pressure fields
inside the pump. The entire fluid-solid domain is treated as a fluid in order
to be able to consider moving rigid bodies in the reduction method. A greedy
algorithm is introduced for finding suitable and as few measurement locations
as possible. Robust observability is ensured with an extended Kalman filter,
which is based on a time-variant observability matrix obtained from the
nonlinear velocity ROM. We present the results of the velocity and pressure
ROMs based on a unsteady Reynolds-averaged Navier-Stokes CFD simulation of a 2D
centrifugal model pump, as well as the results for the extended Kalman filter.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:20:13 GMT""}]","2022-02-14"
"2202.05737","Matteo Pagliardini","Matteo Pagliardini, Gilberto Manunza, Martin Jaggi, Michael I. Jordan,
  Tatjana Chavdarova","Improving Generalization via Uncertainty Driven Perturbations",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Recently Shah et al., 2020 pointed out the pitfalls of the simplicity bias -
the tendency of gradient-based algorithms to learn simple models - which
include the model's high sensitivity to small input perturbations, as well as
sub-optimal margins. In particular, while Stochastic Gradient Descent yields
max-margin boundary on linear models, such guarantee does not extend to
non-linear models. To mitigate the simplicity bias, we consider
uncertainty-driven perturbations (UDP) of the training data points, obtained
iteratively by following the direction that maximizes the model's estimated
uncertainty. The uncertainty estimate does not rely on the input's label and it
is highest at the decision boundary, and - unlike loss-driven perturbations -
it allows for using a larger range of values for the perturbation magnitude.
Furthermore, as real-world datasets have non-isotropic distances between data
points of different classes, the above property is particularly appealing for
increasing the margin of the decision boundary, which in turn improves the
model's generalization. We show that UDP is guaranteed to achieve the maximum
margin decision boundary on linear models and that it notably increases it on
challenging simulated datasets. For nonlinear models, we show empirically that
UDP reduces the simplicity bias and learns more exhaustive features.
Interestingly, it also achieves competitive loss-based robustness and
generalization trade-off on several datasets.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:22:08 GMT""},{""version"":""v2"",""created"":""Mon, 28 Feb 2022 21:20:50 GMT""}]","2022-03-02"
"2202.05738","Yingfeng Cai","Yingfeng Cai, Junqiao Zhao, Jiafeng Cui, Fenglin Zhang, Chen Ye,
  Tiantian Feng","Patch-NetVLAD+: Learned patch descriptor and weighted matching strategy
  for place recognition",,,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Visual Place Recognition (VPR) in areas with similar scenes such as urban or
indoor scenarios is a major challenge. Existing VPR methods using global
descriptors have difficulty capturing local specific regions (LSR) in the scene
and are therefore prone to localization confusion in such scenarios. As a
result, finding the LSR that are critical for location recognition becomes key.
To address this challenge, we introduced Patch-NetVLAD+, which was inspired by
patch-based VPR researches. Our method proposed a fine-tuning strategy with
triplet loss to make NetVLAD suitable for extracting patch-level descriptors.
Moreover, unlike existing methods that treat all patches in an image equally,
our method extracts patches of LSR, which present less frequently throughout
the dataset, and makes them play an important role in VPR by assigning proper
weights to them. Experiments on Pittsburgh30k and Tokyo247 datasets show that
our approach achieved up to 6.35\% performance improvement than existing
patch-based methods.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:22:27 GMT""}]","2022-02-14"
"2202.05739","Faranak Farshadifar <","Faranak Farshadifar","The duals of annihilator conditions for modules",,,,,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let R be a commutative ring with identity and let M be an R-module. The
purpose of this paper is to introduce and investigate the submodules of an
R-module M which satisfy the dual of Property A, the dual of strong Property A,
and the dual of proper strong Property A. Moreover, a submodule N of M which
satisfy Property SJ (N) and Property IM J (N) will be introduced and
investigated.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:24:13 GMT""}]","2022-02-14"
"2202.05740","Lorenzo Monacelli","Lorenzo Monacelli, Michele Casula, Kosuke Nakano, Sandro Sorella,
  Francesco Mauri","Quantum phase diagram of high-pressure hydrogen",,,,,"cond-mat.mtrl-sci cond-mat.supr-con physics.comp-ph quant-ph","http://creativecommons.org/licenses/by/4.0/","  The interplay between electron correlation and nuclear quantum effects makes
our understanding of elemental hydrogen a formidable challenge. Here, we
present the phase diagram of hydrogen and deuterium at low temperatures and
high-pressure ($P > 300$ GPa by accounting for highly accurate electronic and
nuclear enthalpies. We evaluated internal electronic energies by diffusion
quantum Monte Carlo, while nuclear quantum motion and anharmonicity have been
included by the stochastic self-consistent harmonic approximation. Our results
show that the long-sought atomic metallic hydrogen, predicted to host
room-temperature superconductivity, forms at $577\pm 10$ GPa ($640\pm 14$ GPa
in deuterium). Indeed, anharmonicity pushes the stability of this phase towards
pressures much larger than previous theoretical estimates or attained
experimental values. Before atomization, molecular hydrogen transforms from a
conductive phase III to another metallic structure that is still molecular
(phase VI) at $422\pm 40$ GPa ($442\pm30$ GPa in deuterium). We predict
clear-cut signatures in optical spectroscopy and DC conductivity that can be
used experimentally to distinguish between the two structural transitions.
According to our findings, the experimental evidence of metallic hydrogen has
so far been limited to molecular phases.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:25:26 GMT""},{""version"":""v2"",""created"":""Mon, 14 Feb 2022 13:18:43 GMT""}]","2022-02-15"
"2202.05741","Ramon Overwater","Ramon Overwater, Masoud Babaie, Fabio Sebastiano","Neural-Network Decoders for Quantum Error Correction using Surface
  Codes:A Space Exploration of the Hardware Cost-Performance Trade-Offs","19 pages, 21 figures, 5 papers",,"10.1109/TQE.2022.3174017","IEEE TQE 3 (2022)","quant-ph","http://creativecommons.org/licenses/by/4.0/","  Quantum Error Correction (QEC) is required in quantum computers to mitigate
the effect of errors on physical qubits. When adopting a QEC scheme based on
surface codes, error decoding is the most computationally expensive task in the
classical electronic back-end. Decoders employing neural networks (NN) are
well-suited for this task but their hardware implementation has not been
presented yet. This work presents a space exploration of fully-connected
feed-forward NN decoders for small distance surface codes. The goal is to
optimize the neural network for high decoding performance, while keeping a
minimalistic hardware implementation. This is needed to meet the tight delay
constraints of real-time surface code decoding. We demonstrate that hardware
based NN-decoders can achieve high decoding performance comparable to other
state-of-the-art decoding algorithms whilst being well below the tight delay
requirements $(\approx 440\ \mathrm{ns})$ of current solid-state qubit
technologies for both ASIC designs $(<30\ \mathrm{ns})$ and FPGA
implementations $(<90\ \mathrm{ns})$. These results designates NN-decoders as
fitting candidates for an integrated hardware implementation in future
large-scale quantum computers.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:27:14 GMT""}]","2022-06-14"
"2202.05742","Thibaut Verron","Thibaut Verron","On the computation of Gr\""obner bases for matrix-weighted homogeneous
  systems","23 pages",,,,"cs.SC","http://creativecommons.org/licenses/by-sa/4.0/","  In this paper, we examine the structure of systems that are weighted
homogeneous for several systems of weights, and how it impacts the computation
of Gr\""obner bases. We present several linear algebra algorithms for computing
Gr\""obner bases for systems with this structure, either directly or by reducing
to existing structures. We also present suitable optimization techniques.
  As an opening towards complexity studies, we discuss potential definitions of
regularity and prove that they are generic if non-empty. Finally, we present
experimental data from a prototype implementation of the algorithms in
SageMath.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:32:11 GMT""},{""version"":""v2"",""created"":""Wed, 28 Sep 2022 12:41:25 GMT""}]","2022-09-29"
"2202.05743","Ram Sewak Dubey","Edmond Berisha, Ram Sewak Dubey, Orkideh Gharehgozli","Inflation and income inequality: Does the level of income inequality
  matter?",,,,,"econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the recent times of global Covid pandemic, the Federal Reserve has raised
the concerns of upsurges in prices. Given the complexity of interaction between
inflation and inequality, we examine whether the impact of inflation on
inequality differs among distinct levels of income inequality across the US
states. Results reveal that there is a negative contemporaneous effect of
inflation on the inequality which becomes stronger with higher levels of income
inequality. However, over a one year period, we find higher inflation rate to
further increase income inequality only when income inequality is initially
relatively low.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:32:22 GMT""}]","2022-02-14"
"2202.05744","Jie Wang","Jie Wang, Yuji Liu, Binling Wang, Yiming Zhi, Song Li1, Shipeng Xia,
  Jiayang Zhang, Lin Li1, Qingyang Hong, Feng Tong","The xmuspeech system for multi-channel multi-party meeting transcription
  challenge",,,,,"eess.AS cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper describes the system developed by the XMUSPEECH team for the
Multi-channel Multi-party Meeting Transcription Challenge (M2MeT). For the
speaker diarization task, we propose a multi-channel speaker diarization system
that obtains spatial information of speaker by Difference of Arrival (DOA)
technology. Speaker-spatial embedding is generated by x-vector and s-vector
derived from Filter-and-Sum Beamforming (FSB) which makes the embedding more
robust. Specifically, we propose a novel multi-channel sequence-to-sequence
neural network architecture named Discriminative Multi-stream Neural Network
(DMSNet) which consists of Attention Filter-and-Sum block (AFSB) and Conformer
encoder. We explore DMSNet to address overlapped speech problem on
multi-channel audio. Compared with LSTM based OSD module, we achieve a
decreases of 10.1% in Detection Error Rate(DetER). By performing DMSNet based
OSD module, the DER of cluster-based diarization system decrease significantly
form 13.44% to 7.63%. Our best fusion system achieves 7.09% and 9.80% of the
diarization error rate (DER) on evaluation set and test set.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:32:52 GMT""}]","2022-02-14"
"2202.05745","Tiankuan Liu","Michael P. King, Datao Gong, Chonghan Liu, Tiankuan Liu, Annie C.
  Xiang, Jinbo Ye, Ronald D. Schrimpf, Robert A. Reed, Michael L. Alles, and
  Daniel M. Fleetwood","Response of a Commercial 0.25 um Thin-Film Silicon-on-Sapphire CMOS
  Technology to Total Ionizing Dose","5 pages, 5 figures","JINST 5 C11021 (2010)","10.1088/1748-0221/5/11/C11021",,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The radiation response of a 0.25 um silicon-on-sapphire CMOS technology is
characterized at the transistor and circuit levels utilizing both standard and
enclosed layout devices. Device-level characterization showed threshold voltage
change of less than 170 mV and leakage current change of less than 1 nA for
individual nMOSFET and pMOSFET devices at a total dose of 100 krad(SiO2). The
increase in power supply current at the circuit level was less than 5%,
consistent with the small change in off-state transistor leakage current. The
technology exhibits good characteristics for use in the electronics of the
ATLAS experiment at the Large Hadron Collider.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:34:23 GMT""}]","2022-02-14"
"2202.05746","Tom Scruby","Thomas R. Scruby, Michael Vasmer, Dan E. Browne","Non-Pauli Errors in the Three-Dimensional Surface Code","15 pages (+ 8 page appendices), 11 figures; v2 added additional
  simulation results for the case of depolarising errors occuring immediately
  before the application of the CCZ gate. Added additional references","Phys. Rev. Research 4, 043052 (2022)","10.1103/PhysRevResearch.4.043052",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  A powerful feature of stabiliser error correcting codes is the fact that
stabiliser measurement projects arbitrary errors to Pauli errors, greatly
simplifying the physical error correction process as well as classical
simulations of code performance. However, logical non-Clifford operations can
map Pauli errors to non-Pauli (Clifford) errors, and while subsequent
stabiliser measurements will project the Clifford errors back to Pauli errors
the resulting distributions will possess additional correlations that depend on
both the nature of the logical operation and the structure of the code.
Previous work has studied these effects when applying a transversal $T$ gate to
the three-dimensional colour code and shown the existence of a non-local
""linking charge"" phenomenon between membranes of intersecting errors. In this
work we generalise these results to the case of a $CCZ$ gate in the
three-dimensional surface code and find that many aspects of the problem are
much more easily understood in this setting. In particular, the emergence of
linking charge is a local effect rather than a non-local one. We use the
relative simplicity of Clifford errors in this setting to simulate their effect
on the performance of a single-shot magic state preparation process (the first
such simulation to account for the full effect of these errors) and find that
their effect on the threshold is largely determined by probability of $X$
errors occurring immediately prior to the application of the gate, after the
most recent stabiliser measurement.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:34:57 GMT""},{""version"":""v2"",""created"":""Wed, 8 Jun 2022 05:56:51 GMT""}]","2022-10-25"
"2202.05747","Isaac Grosof","Isaac Grosof and Michael Mitzenmacher","Incentive Compatible Queues Without Money","20 pages",,,,"cs.GT cs.PF","http://creativecommons.org/licenses/by-nc-sa/4.0/","  For job scheduling systems, where jobs require some amount of processing and
then leave the system, it is natural for each user to provide an estimate of
their job's time requirement in order to aid the scheduler. However, if there
is no incentive mechanism for truthfulness, each user will be motivated to
provide estimates that give their job precedence in the schedule, so that the
job completes as early as possible.
  We examine how to make such scheduling systems incentive compatible, without
using monetary charges, under a natural queueing theory framework. In our
setup, each user has an estimate of their job's running time, but it is
possible for this estimate to be incorrect. We examine scheduling policies
where if a job exceeds its estimate, it is with some probability ""punished"" and
re-scheduled after other jobs, to disincentivize underestimates of job times.
However, because user estimates may be incorrect (without any malicious
intent), excessive punishment may incentivize users to overestimate their job
times, which leads to less efficient scheduling. We describe two natural
scheduling policies, BlindTrust and MeasuredTrust. We show that, for both of
these policies, given the parameters of the system, we can efficiently
determine the set of punishment probabilities that are incentive compatible, in
that users are incentivized to provide their actual estimate of the job time.
Moreover, we prove for MeasuredTrust that in the limit as estimates converge to
perfect accuracy, the range of punishment probabilities that are incentive
compatible converges to $[0,1]$. Our formalism establishes a framework for
studying further queue-based scheduling problems where job time estimates from
users are utilized, and the system needs to incentivize truthful reporting of
estimates.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:37:42 GMT""}]","2022-02-14"
"2202.05748","Evann Courdier","Evann Courdier and Fran\c{c}ois Fleuret","Borrowing from yourself: Faster future video segmentation with partial
  channel update",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Semantic segmentation is a well-addressed topic in the computer vision
literature, but the design of fast and accurate video processing networks
remains challenging. In addition, to run on embedded hardware, computer vision
models often have to make compromises on accuracy to run at the required speed,
so that a latency/accuracy trade-off is usually at the heart of these real-time
systems' design. For the specific case of videos, models have the additional
possibility to make use of computations made for previous frames to mitigate
the accuracy loss while being real-time.
  In this work, we propose to tackle the task of fast future video segmentation
prediction through the use of convolutional layers with time-dependent channel
masking. This technique only updates a chosen subset of the feature maps at
each time-step, bringing simultaneously less computation and latency, and
allowing the network to leverage previously computed features. We apply this
technique to several fast architectures and experimentally confirm its benefits
for the future prediction subtask.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:37:53 GMT""},{""version"":""v2"",""created"":""Fri, 17 Jun 2022 09:45:27 GMT""}]","2022-06-20"
"2202.05749","Guangyu Shen","Guangyu Shen, Yingqi Liu, Guanhong Tao, Qiuling Xu, Zhuo Zhang,
  Shengwei An, Shiqing Ma, Xiangyu Zhang","Constrained Optimization with Dynamic Bound-scaling for Effective
  NLPBackdoor Defense",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  We develop a novel optimization method for NLPbackdoor inversion. We leverage
a dynamically reducing temperature coefficient in the softmax function to
provide changing loss landscapes to the optimizer such that the process
gradually focuses on the ground truth trigger, which is denoted as a one-hot
value in a convex hull. Our method also features a temperature rollback
mechanism to step away from local optimals, exploiting the observation that
local optimals can be easily deter-mined in NLP trigger inversion (while not in
general optimization). We evaluate the technique on over 1600 models (with
roughly half of them having injected backdoors) on 3 prevailing NLP tasks, with
4 different backdoor attacks and 7 architectures. Our results show that the
technique is able to effectively and efficiently detect and remove backdoors,
outperforming 4 baseline methods.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:40:25 GMT""}]","2022-02-14"
"2202.05750","Said Ouala","Said Ouala, Steven L. Brunton, Ananda Pascual, Bertrand Chapron,
  Fabrice Collard, Lucile Gaultier, Ronan Fablet","Bounded nonlinear forecasts of partially observed geophysical systems
  with physics-constrained deep learning",,,"10.1016/j.physd.2022.133630",,"stat.ML cs.LG math.DS","http://creativecommons.org/licenses/by/4.0/","  The complexity of real-world geophysical systems is often compounded by the
fact that the observed measurements depend on hidden variables. These latent
variables include unresolved small scales and/or rapidly evolving processes,
partially observed couplings, or forcings in coupled systems. This is the case
in ocean-atmosphere dynamics, for which unknown interior dynamics can affect
surface observations. The identification of computationally-relevant
representations of such partially-observed and highly nonlinear systems is thus
challenging and often limited to short-term forecast applications. Here, we
investigate the physics-constrained learning of implicit dynamical embeddings,
leveraging neural ordinary differential equation (NODE) representations. A key
objective is to constrain their boundedness, which promotes the generalization
of the learned dynamics to arbitrary initial condition. The proposed
architecture is implemented within a deep learning framework, and its relevance
is demonstrated with respect to state-of-the-art schemes for different
case-studies representative of geophysical dynamics.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:40:46 GMT""},{""version"":""v2"",""created"":""Wed, 2 Mar 2022 15:41:17 GMT""}]","2023-02-01"
"2202.05751","Hideaki Hata","Naomichi Shimada, Tao Xiao, Hideaki Hata, Christoph Treude, Kenichi
  Matsumoto","GitHub Sponsors: Exploring a New Way to Contribute to Open Source","12 pages, ICSE 2022",,"10.1145/3510003.3510116",,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  GitHub Sponsors, launched in 2019, enables donations to individual open
source software (OSS) developers. Financial support for OSS maintainers and
developers is a major issue in terms of sustaining OSS projects, and the
ability to donate to individuals is expected to support the sustainability of
developers, projects, and community. In this work, we conducted a mixed-methods
study of GitHub Sponsors, including quantitative and qualitative analyses, to
understand the characteristics of developers who are likely to receive
donations and what developers think about donations to individuals. We found
that: (1) sponsored developers are more active than non-sponsored developers,
(2) the possibility to receive donations is related to whether there is someone
in their community who is donating, and (3) developers are sponsoring as a new
way to contribute to OSS. Our findings are the first step towards data-informed
guidance for using GitHub Sponsors, opening up avenues for future work on this
new way of financially sustaining the OSS community.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:44:24 GMT""}]","2022-02-14"
"2202.05752","Julia Dyck","Julia Dyck and Odile Sauzet","Parameter uncertainty estimation for exponential semi-variogram models:
  Two generalized bootstrap methods with check- and quantile-based filtering","25 pages, 4 figures",,,,"stat.ME stat.CO","http://creativecommons.org/licenses/by/4.0/","  The estimation of parameter standard errors for semi-variogram models is
challenging, given the two-step process required to fit a parametric model to
spatially correlated data. Motivated by an application in the
social-epidemiology, we focus on exponential semi-variogram models fitted to
data between 500 to 2000 observations and little control over the sampling
design. Previously proposed methods for the estimation of standard errors
cannot be applied in this context. Approximate closed form solutions are too
costly using generalized least squares in terms of memory capacities. The
generalized bootstrap proposed by Olea and Pardo-Ig\'uzquiza is nonetheless
applicable with weighted instead of generalized least squares. However, the
standard error estimates are hugely biased and imprecise. Therefore, we propose
a filtering method added to the generalized bootstrap. The new development is
presented and evaluated with a simulation study which shows that the
generalized bootstrap with check-based filtering leads to massively improved
results compared to the quantile-based filter method and previously developed
approaches. We provide a case study using birthweight data.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:46:23 GMT""}]","2022-02-14"
"2202.05753","Carolina Andonie","Carolina Andonie, Claudio Ricci, St\'ephane Paltani, Patricia
  Ar\'evalo, Ezequiel Treister, Franz Bauer, and Marko Stalevski","A multiwavelength-motivated X-ray model for the Circinus Galaxy","Accepted for publication in MNRAS. 15 pages, 10 figures, 8 tables",,"10.1093/mnras/stac403",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Reprocessed X-ray emission in Active Galactic Nuclei (AGN) can provide
fundamental information about the circumnuclear environments of supermassive
black holes. Recent mid-infrared studies have shown evidence of an extended
dusty structure perpendicular to the torus plane. In this work, we build a
self-consistent X-ray model for the Circinus Galaxy including the different
physical components observed at different wavelengths and needed to reproduce
both the morphological and spectral properties of this object in the
mid-infrared. The model consists of four components: the accretion disk, the
broad line region (BLR), a flared disk in the equatorial plane and a hollow
cone in the polar direction. Our final model reproduces well the 3--70 keV
Chandra and NuSTAR spectra of Circinus, including the complex Fe K$\alpha$ zone
and the spectral curvature, although several additional Gaussian lines,
associated to either ionized iron or to broadened Fe K$\alpha$/K$\beta$ lines,
are needed. We find that the flared disk is Compton thick ($ N_{\rm H,d}= \rm
1.01^{+0.03}_{-0.24}\times 10^{25}\: cm^{-2}$) and geometrically thick
($CF=0.55^{+0.01}_{-0.05}$), and that the hollow cone has a Compton-thin column
density ($ N_{\rm H,c}= \rm 2.18^{+0.47}_{-0.43}\times 10^{23}\: cm^{-2}$),
which is consistent with the values inferred by mid-infrared studies. Including
also the BLR, the effective line of sight column density is $ N_{\rm H}= \rm
1.47^{+0.03}_{-0.24}\times 10^{25}\: cm^{-2}$. This approach to X-ray
modelling, i.e. including all the different reprocessing structures, will be
very important to fully exploit data from future X-ray missions.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:46:39 GMT""},{""version"":""v2"",""created"":""Thu, 10 Mar 2022 09:05:15 GMT""},{""version"":""v3"",""created"":""Sun, 13 Mar 2022 13:18:54 GMT""}]","2022-03-15"
"2202.05754","Milica Vasiljevic","Milica Vasiljevic, Marton Kollar, David Spirito, Lukas Riemer, Laszlo
  Forro, Endre Horvath, Semen Gorfman, Dragan Damjanovic","""Forbidden"" polarisation and extraordinary piezoelectric effect in
  organometallic lead halide perovskites",,"Adv. Funct. Mater.2022, 2204898","10.1002/adfm.202204898",,"cond-mat.mtrl-sci physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Organometallic lead halide perovskites are highly efficient materials for
solar cells and other optoelectronic applications due to their high quantum
efficiency and exceptional semiconducting properties. A peculiarity of these
perovskites is the substantial ionic motion under external forces. Here, we
reveal that electric field-and light-induced ionic motion in MAPbX3 crystals
(X=Cl, Br, I and MA=CH3NH3) leads to unexpected piezoelectric-like response, an
order of magnitude larger than in ferroelectric perovskite oxides. The nominal
macroscopic symmetry of the crystals is broken by redistribution of ionic
species, which can be controlled deterministically by light and electric field.
The revealed piezoelectric response is possibly present in other materials with
significant ionic activity but the unique feature of organometallic perovskites
is the strong effect on the piezoelectric response of interplay of ionic motion
(MA+ and X-1) and photoelectrons generated with illumination.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:47:20 GMT""}]","2022-09-01"
"2202.05755","Daniel Zhu","Daniel G. Zhu","Sub-Fibonacci behavior in numerical semigroup enumeration","18 pages",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In 2013, Zhai proved that most numerical semigroups of a given genus have
depth at most $3$ and that the number $n_g$ of numerical semigroups of a genus
$g$ is asymptotic to $S\varphi^g$, where $S$ is some positive constant and
$\varphi \approx 1.61803$ is the golden ratio. In this paper, we prove
exponential upper and lower bounds on the factors that cause $n_g$ to deviate
from a perfect exponential, including the number of semigroups with depth at
least $4$. Among other applications, these results imply the sharpest known
asymptotic bounds on $n_g$ and shed light on a conjecture by Bras-Amor\'os
(2008) that $n_g \geq n_{g-1} + n_{g-2}$. Our main tools are the use of Kunz
coordinates, introduced by Kunz (1987), and a result by Zhao (2011) bounding
weighted graph homomorphisms.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:48:41 GMT""}]","2022-02-14"
"2202.05756","Kia Dashtipour","Tassadaq Hussain, Muhammad Diyan, Mandar Gogate, Kia Dashtipour, Ahsan
  Adeel, Yu Tsao, Amir Hussain","A Novel Speech Intelligibility Enhancement Model based on
  CanonicalCorrelation and Deep Learning","arXiv admin note: substantial text overlap with arXiv:2202.04172",,,,"cs.SD cs.LG eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Current deep learning (DL) based approaches to speech intelligibility
enhancement in noisy environments are often trained to minimise the feature
distance between noise-free speech and enhanced speech signals. Despite
improving the speech quality, such approaches do not deliver required levels of
speech intelligibility in everyday noisy environments .
Intelligibility-oriented (I-O) loss functions have recently been developed to
train DL approaches for robust speech enhancement. Here, we formulate, for the
first time, a novel canonical correlation based I-O loss function to more
effectively train DL algorithms. Specifically, we present a
canonical-correlation based short-time objective intelligibility (CC-STOI) cost
function to train a fully convolutional neural network (FCN) model. We carry
out comparative simulation experiments to show that our CC-STOI based speech
enhancement framework outperforms state-of-the-art DL models trained with
conventional distance-based and STOI-based loss functions, using objective and
subjective evaluation measures for case of both unseen speakers and noises.
Ongoing future work is evaluating the proposed approach for design of robust
hearing-assistive technology.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:48:41 GMT""}]","2022-02-14"
"2202.05757","Justine Falque","Nicolas Borie and Justine Falque","Product-Coproduct Prographs and Triangulations of the Sphere",,,,,"math.CO cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we explain how the classical Catalan families of objects
involving paths, tableaux, triangulations, parentheses configurations and more
generalize canonically to a three-dimensional version. In particular, we
present product-coproduct prographs as central objects explaining the
combinatorics of the triangulations of the sphere. Then we expose a natural way
to extend the Tamari lattice to the product-coproduct prographs.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:49:11 GMT""}]","2022-02-14"
"2202.05758","Abigail Swenor","Abigail Swenor and Jugal Kalita","Using Random Perturbations to Mitigate Adversarial Attacks on Sentiment
  Analysis Models","To be published in the proceedings for the 18th International
  Conference on Natural Language Processing (ICON 2021)",,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Attacks on deep learning models are often difficult to identify and therefore
are difficult to protect against. This problem is exacerbated by the use of
public datasets that typically are not manually inspected before use. In this
paper, we offer a solution to this vulnerability by using, during testing,
random perturbations such as spelling correction if necessary, substitution by
random synonym, or simply dropping the word. These perturbations are applied to
random words in random sentences to defend NLP models against adversarial
attacks. Our Random Perturbations Defense and Increased Randomness Defense
methods are successful in returning attacked models to similar accuracy of
models before attacks. The original accuracy of the model used in this work is
80% for sentiment classification. After undergoing attacks, the accuracy drops
to accuracy between 0% and 44%. After applying our defense methods, the
accuracy of the model is returned to the original accuracy within statistical
significance.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:50:17 GMT""}]","2022-02-14"
"2202.05759","Amy Ray","Amy E. Ray, Peter M. Frinchaboy, John Donor, S. D. Chojnowski, Matthew
  Melendez","The Open Cluster Chemical Abundances and Mapping Survey: V. Chemical
  Abundances of CTIO/Hydra Clusters using The Cannon","10 pages, 4 figures, astronomical journal accepted",,"10.3847/1538-3881/ac5835",,"astro-ph.GA astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Open clusters are key chemical and age tracers of Milky Way evolution. While
open clusters provide significant constraints on galaxy evolution, their use
has been limited due to discrepancies in measuring abundances from different
studies. We analyze medium resolution (R~19,000) CTIO/Hydra spectra of giant
stars in 58 open clusters using The Cannon to determine [Fe/H], [Mg/Fe],
[Si/Fe], [Al/Fe], and [O/Fe]. This work adds an additional 55 primarily
southern hemisphere open clusters calibrated to the SDSS/APOGEE DR16
metallicity system. This uniform analysis is compared to previous studies
[Fe/H] measurements for 23 clusters and we present spectroscopic metallicities
for the first time for 35 open clusters.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:51:03 GMT""}]","2022-04-13"
"2202.05760","Francesca Falzon","Emily Wenger, Francesca Falzon, Josephine Passananti, Haitao Zheng,
  Ben Y. Zhao","Assessing Privacy Risks from Feature Vector Reconstruction Attacks","7 pages",,,,"cs.CR cs.CV","http://creativecommons.org/licenses/by/4.0/","  In deep neural networks for facial recognition, feature vectors are numerical
representations that capture the unique features of a given face. While it is
known that a version of the original face can be recovered via ""feature
reconstruction,"" we lack an understanding of the end-to-end privacy risks
produced by these attacks. In this work, we address this shortcoming by
developing metrics that meaningfully capture the threat of reconstructed face
images. Using end-to-end experiments and user studies, we show that
reconstructed face images enable re-identification by both commercial facial
recognition systems and humans, at a rate that is at worst, a factor of four
times higher than randomized baselines. Our results confirm that feature
vectors should be recognized as Personal Identifiable Information (PII) in
order to protect user privacy.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:52:02 GMT""}]","2022-02-14"
"2202.05761","Zachary Kilpatrick PhD","Subekshya Bidari, Ahmed El Hady, Jacob Davidson, and Zachary P
  Kilpatrick","Stochastic dynamics of social patch foraging decisions","24 pages, 7 figures",,,,"q-bio.PE q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Animals typically forage in groups. Social foraging can help animals avoid
predation and decrease their uncertainty about the richness of food resources.
Despite this, theoretical mechanistic models of patch foraging have
overwhelmingly focused on the behavior of single foragers. In this study, we
develop a mechanistic model describing the behavior of individuals foraging
together and departing food patches following an evidence accumulation process.
Each individual's belief about patch quality is represented by a stochastically
accumulating variable coupled to others' belief, representing the transfer of
information. We consider a cohesive group, and model information sharing as
either intermittent pulsatile coupling (communicate decision to leave) or
continuous diffusive coupling (communicate online belief). Foraging efficiency
under pulsatile coupling has a stronger dependence on the coupling strength
parameter compared to diffusive. Despite employing minimal information
transfer, pulsatile coupling can still provide similar or higher foraging
efficiency compared to diffusive coupling. Conversely, diffusive coupling is
more robust to parameter detuning and performs better when individuals have
heterogeneous departure criteria and social information weighting. Efficiency
is measured by a reward rate function that balances the amount of energy
accumulated against the time spent in a patch, computed by solving an ordered
first passage time problem for the patch departures of each individual. Using
synthetic data we show that we can distinguish between the two modes of
communication and identify the model parameters. Our model establishes a social
patch foraging framework to parse and identify deliberative decision
strategies, to distinguish different forms of social communication, and to
allow model fitting to real world animal behavior data.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:52:13 GMT""}]","2022-02-14"
"2202.05762","Andrea Ardenghi Mr.","A. Ardenghi, O. Bierwagen, A. Falkenstein, G. Hoffmann, J.
  L\""ahnemann, M. Martin, P. Mazzolini","Towards controllable Si-doping in oxide molecular beam epitaxy using a
  solid SiO source: Application to $\beta$-Ga2O3",,"A. Ardenghi et al., Appl. Phys. Lett. 121, 042109 (2022)","10.1063/5.0087987","Volume 121, Issue 4","cond-mat.mtrl-sci physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  The oxidation-related issues in controlling Si doping from the Si source
material in oxide molecular beam epitaxy (MBE) is addressed by using solid SiO
as an alternative source material in a conventional effusion cell.
Line-of-sight quadrupole mass spectrometry of the direct SiO-flux
($\Phi_{SiO}$) from the source at different temperatures ($T_{SiO}$) confirmed
SiO molecules to sublime with an activation energy of 3.3eV. The
$T_{SiO}$-dependent $\Phi_{SiO}$ was measured in vacuum before and after
subjecting the source material to an O$_{2}$-background of $10^{-5}$ mbar
(typical oxide MBE regime). The absence of a significant $\Phi_{SiO}$
difference indicates negligible source oxidation in molecular O$_{2}$. Mounted
in an oxygen plasma-assisted MBE, Si-doped $\beta$-Ga2O3 layers were grown
using this source. The $\Phi_{SiO}$ at the substrate was evaluated [from
2.9x10$^{9}$ cm$^{-2}$s$^{-1}$ ($T_{SiO}$=700{\deg}C) to 5.5x10$^{13}$
cm$^{-2}$s$^{-1}$ (T$_{SiO}$=1000{\deg}C)] and Si-concentration in the
$\beta$-Ga2O3 layers measured by secondary ion mass spectrometry highlighting
unprecedented control of continuous Si-doping for oxide MBE, i.e., $N_{Si}$
from 4x10$^{17}$ cm$^{-3}$ ($T_{SiO}$=700{\deg}C) up to 1.7x10$^{20}$ cm$^{-3}$
($T_{SiO}$=900{\deg}C). For a homoepitaxial $\beta$-Ga2O3 layer an Hall charge
carrier concentration of 3x10$^{19}$ cm$^{-3}$ in line with the provided
$\Phi_{SiO}$ ($T_{SiO}$=800{\deg}C) is demonstrated. No SiO-incorporation
difference was found between $\beta$-Ga2O3(010) layers homoepitaxially grown at
750{\deg}C and $\beta$-Ga2O3(-201) layers heteroepitaxially grown at
550{\deg}C. The presence of activated oxygen (plasma) resulted in partial
source oxidation and related decrease of doping concentration (particularly at
$T_{SiO}$<800{\deg}C) which has been tentatively explained with a simple model.
Degassing the source at 1100{\deg}C reverted the oxidation.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:55:57 GMT""}]","2022-09-08"
"2202.05763","Tobias A{\ss}mann","Tobias A{\ss}mann, Fabio Di Pumpo, Enno Giese","Light-pulse atom interferometry with entangled atom-optical elements","10 pages, 4 figures, 1 table","Phys. Rev. Research 4, 013115 (2022)","10.1103/PhysRevResearch.4.013115",,"quant-ph physics.atom-ph","http://creativecommons.org/licenses/by/4.0/","  The analogs of optical elements in light-pulse atom interferometers are
generated from the interaction of matter waves with light fields. As such,
these fields possess quantum properties, which fundamentally lead to a reduced
visibility in the observed interference. This loss is a consequence of the
encoded information about the atom's path. However, the quantum nature of the
atom-optical elements also gives an additional degree of freedom to reduce such
effects: We demonstrate that entanglement between all light fields can be used
to erase information about the atom's path and by that to partially recover the
visibility. Thus, our work highlights the role of complementarity on
atom-interferometric experiments.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:58:06 GMT""}]","2022-02-14"
"2202.05764","Quentin Glorieux","Tangui Aladjidi, Murad Abuzarli, Guillaume Brochier, Tom Bienaim\'e,
  Thomas Picot, Alberto Bramati, Quentin Glorieux","Transit effects for non-linear index measurement in hot atomic vapors","13 pages, 5 figures, 2 pages supplementary material. Submitted to PRA",,,,"quant-ph physics.optics","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Hot atomic vapors are widely used in non-linear and quantum optics due to
their large Kerr non-linearity. While the linear refractive index and the
transmission are precisely measured and well modeled theoretically, similar
characterization remains partial for the $\chi^{(3)}$ non-linear part of the
susceptibility. In this work, we present a set of tools to measure and estimate
numerically the non-linear index of hot atomic vapors both in the steady state
and during the transient response of the medium. We apply these techniques for
the characterization of a hot vapor of rubidium and we evidence the critical
role played by transit effects, due to finite beam sizes, in the measurement of
the non-linear index.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:58:52 GMT""},{""version"":""v2"",""created"":""Tue, 31 May 2022 11:19:54 GMT""}]","2022-06-01"
"2202.05765","Pietro Speziali","H. Borges, G. Korchm\'aros and P. Speziali","Plane curves with a large linear automorphism group in characteristic
  $p$","35 pages",,,,"math.AG","http://creativecommons.org/licenses/by/4.0/","  Let $G$ be a subgroup of the three dimensional projective group
$\mathrm{PGL}(3,q)$ defined over a finite field $\mathbb{F}_q$ of order $q$,
viewed as a subgroup of $\mathrm{PGL}(3,K)$ where $K$ is an algebraic closure
of $\mathbb{F}_q$. For the seven nonsporadic, maximal subgroups $G$ of
$\mathrm{PGL}(3,q)$, we investigate the (projective, irreducible) plane curves
defined over $K$ that are left invariant by $G$. For each, we compute the
minimum degree $d(G)$ of $G$-invariant curves, provide a classification of all
$G$-invariant curves of degree $d(G)$, and determine the first gap
$\varepsilon(G)$ in the spectrum of the degrees of all $G$-invariant curves. We
show that the curves of degree $d(G)$ belong to a pencil depending on $G$,
unless they are uniquely determined by $G$. We also point out that
$G$-invariant curves of degree $d(G)$ have particular geometric features such
as Frobenius nonclassicality and an unusual variation of the number of
$\mathbb{F}_{q^i}$-rational points. For most examples of plane curves left
invariant by a large subgroup of $\mathrm{PGL}(3,q)$, the whole automorphism
group of the curve is linear, i.e., a subgroup of $\mathrm{PGL}(3,K)$. Although
this appears to be a general behavior, we show that the opposite case can also
occur for some irreducible plane curves, that is, the curve has a large group
of linear automorphisms, but its full automorphism group is nonlinear.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 16:59:40 GMT""}]","2022-02-14"
"2202.05766","Luk\'a\v{s} Mal\'y","George Baravdish, Gabriel Eilertsen, Rym Jaroudi, B. Tomas Johansson,
  Luk\'a\v{s} Mal\'y and Jonas Unger","Learning via nonlinear conjugate gradients and depth-varying neural ODEs","26 pages, 3 figures",,,,"cs.LG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The inverse problem of supervised reconstruction of depth-variable
(time-dependent) parameters in a neural ordinary differential equation (NODE)
is considered, that means finding the weights of a residual network with time
continuous layers. The NODE is treated as an isolated entity describing the
full network as opposed to earlier research, which embedded it between pre- and
post-appended layers trained by conventional methods. The proposed parameter
reconstruction is done for a general first order differential equation by
minimizing a cost functional covering a variety of loss functions and penalty
terms. A nonlinear conjugate gradient method (NCG) is derived for the
minimization. Mathematical properties are stated for the differential equation
and the cost functional. The adjoint problem needed is derived together with a
sensitivity problem. The sensitivity problem can estimate changes in the
network output under perturbation of the trained parameters. To preserve
smoothness during the iterations the Sobolev gradient is calculated and
incorporated. As a proof-of-concept, numerical results are included for a NODE
and two synthetic datasets, and compared with standard gradient approaches (not
based on NODEs). The results show that the proposed method works well for deep
learning with infinite numbers of layers, and has built-in stability and
smoothness.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:00:48 GMT""}]","2022-02-14"
"2202.05767","Vladimir Kobzar","Vladimir A. Kobzar, Robert V. Kohn","A PDE-Based Analysis of the Symmetric Two-Armed Bernoulli Bandit","Improved presentation",,,,"cs.LG math.AP stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work addresses a version of the two-armed Bernoulli bandit problem where
the sum of the means of the arms is one (the symmetric two-armed Bernoulli
bandit). In a regime where the gap between these means goes to zero and the
number of prediction periods approaches infinity, we obtain the leading order
terms of the minmax optimal regret and pseudoregret for this problem by
associating each of them with a solution of a linear parabolic partial
differential equation. Our results improve upon the previously known results;
specifically, we explicitly compute these leading order terms in three
different scaling regimes for the gap. Additionally, we obtain new
non-asymptotic bounds for any given time horizon.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:03:18 GMT""},{""version"":""v2"",""created"":""Fri, 9 Sep 2022 15:01:51 GMT""},{""version"":""v3"",""created"":""Sat, 12 Nov 2022 08:09:09 GMT""}]","2022-11-15"
"2202.05768","Christopher Leonard","Alina Chertock, Christopher Leonard, and Semyon Tsynkov","Finding the Shape of Lacunae of the Wave Equation Using Artificial
  Neural Networks","12 pages",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We apply a fully connected neural network to determine the shape of the
lacunae in the solutions of the wave equation. Lacunae are the regions of
quietness behind the trailing fronts of the propagating waves. The network is
trained using a computer simulated data set containing a sufficiently large
number of samples. The network is then shown to correctly reconstruct the shape
of lacunae including the configurations when it is fully enclosed.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:03:25 GMT""}]","2022-02-14"
"2202.05769","Jonathan Mace","Lei Zhang, Vaastav Anand, Zhiqiang Xie, Ymir Vigfusson, Jonathan Mace","The Benefit of Hindsight: Tracing Edge-Cases in Distributed Systems",,,,,"cs.DC","http://creativecommons.org/licenses/by/4.0/","  Today's distributed tracing frameworks are ill-equipped to troubleshoot rare
edge-case requests. The crux of the problem is a trade-off between specificity
and overhead. On the one hand, frameworks can indiscriminately select requests
to trace when they enter the system (head sampling), but this is unlikely to
capture a relevant edge-case trace because the framework cannot know which
requests will be problematic until after-the-fact. On the other hand,
frameworks can trace everything and later keep only the interesting edge-case
traces (tail sampling), but this has high overheads on the traced application
and enormous data ingestion costs.
  In this paper we circumvent this trade-off for any edge-case with symptoms
that can be programmatically detected, such as high tail latency, errors, and
bottlenecked queues. We propose a lightweight and always-on distributed tracing
system, Hindsight, which implements a retroactive sampling abstraction: instead
of eagerly ingesting and processing traces, Hindsight lazily retrieves trace
data only after symptoms of a problem are detected. Hindsight is analogous to a
car dash-cam that, upon detecting a sudden jolt in momentum, persists the last
hour of footage. Developers using Hindsight receive the exact edge-case traces
they desire without undue overhead or dependence on luck. Our evaluation shows
that Hindsight scales to millions of requests per second, adds nanosecond-level
overhead to generate trace data, handles GB/s of data per node, transparently
integrates with existing distributed tracing systems, and successfully persists
full, detailed traces in real-world use cases when edge-case problems are
detected.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:05:03 GMT""},{""version"":""v2"",""created"":""Tue, 26 Apr 2022 18:14:21 GMT""}]","2022-04-28"
"2202.05770","Nian Guo","Nian Guo and Victoria Kostina","Reliability function for streaming over a DMC with feedback",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conventionally, posterior matching is investigated in channel coding and
block encoding contexts -- the source symbols are equiprobably distributed and
are entirely known by the encoder before the transmission. In this paper, we
consider a streaming source, whose symbols arrive at the encoder at a sequence
of deterministic times. We derive the joint source-channel coding (JSCC)
reliability function for streaming over a discrete memoryless channel (DMC)
with feedback. We propose a novel instantaneous encoding phase that operates
during the symbol arriving period and achieves the JSCC reliability function
for streaming when followed by a block encoding scheme that achieves the JSCC
reliability function for a classical source whose symbols are fully accessible
before the transmission. During the instantaneous encoding phase, the evolving
message alphabet is partitioned into groups, and the encoder determines the
index of the group that contains the symbols arrived so far and applies
randomization to match the distribution of the transmitted index to the
capacity-achieving one. Surprisingly, the JSCC reliability function for
streaming is equal to that for a fully accessible source, implying that the
knowledge of the entire symbol sequence before the transmission offers no
advantage regarding the reliability function. For streaming over a symmetric
2-input DMC, we propose an instantaneous small-enough difference (SED) code
that not only achieves the JSCC reliability function but also can be used to
stabilize an unstable linear system over a noisy channel. We design low
complexity algorithms to implement both the instantaneous encoding phase and
the instantaneous SED code. While the reliability function is derived for
non-degenerate DMCs, for degenerate DMCs we design a code with instantaneous
encoding that achieves zero error for all rates below Shannon's JSCC limit.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:05:20 GMT""},{""version"":""v2"",""created"":""Sat, 2 Apr 2022 22:32:11 GMT""},{""version"":""v3"",""created"":""Sat, 25 Jun 2022 21:08:18 GMT""},{""version"":""v4"",""created"":""Wed, 30 Nov 2022 07:58:17 GMT""}]","2022-12-01"
"2202.05771","Melina Merkel","Melina Merkel, Bernard Kapidani, Sebastian Sch\""ops, and Rafael
  V\'azquez","Torque Computation with the Isogeometric Mortar Method for the
  Simulation of Electric Machines",,"IEEE Transactions on Magnetics, vol. 58, no. 9, Sept. 2022, Art
  no. 8107604","10.1109/TMAG.2022.3186247",,"cs.CE cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work isogeometric mortaring is used for the simulation of a six pole
permanent magnet synchronous machine. Isogeometric mortaring is especially well
suited for the efficient computation of rotating electric machines as it allows
for an exact geometry representation for arbitrary rotation angles without the
need of remeshing. The appropriate B-spline spaces needed for the solution of
Maxwell's equations and the corresponding mortar spaces are introduced. Unlike
in classical finite element methods their construction is straightforward in
the isogeometric case. The torque in the machine is computed using two
different methods, i.e., Arkkio's method and by using the Lagrange multipliers
from the mortaring.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:07:08 GMT""}]","2023-05-03"
"2202.05773","James Goodman","James Goodman, Diego Perez-Liebana, Simon Lucas","Visualising Multiplayer Game Spaces","13 pages, 7 figures, Accepted for IEEE Transactions on Games","IEEE Transactions on Games 2021","10.1109/TG.2021.3138561",,"cs.AI cs.MA","http://creativecommons.org/licenses/by/4.0/","  We compare four different `game-spaces' in terms of their usefulness in
characterising multi-player tabletop games, with a particular interest in any
underlying change to a game's characteristics as the number of players changes.
In each case we take a 16-dimensional feature space, and reduce it to a
2-dimensional visualizable landscape.
  We find that a space obtained from optimization of parameters in Monte Carlo
Tree Search (MCTS) is the most directly interpretable to characterise our set
of games in terms of the relative importance of imperfect information,
adversarial opponents and reward sparsity. These results do not correlate with
a space defined using attributes of the game-tree.
  This dimensionality reduction does not show any general effect as the number
of players. We therefore consider the question using the original features to
classify the games into two sets; those for which the characteristics of the
game changes significantly as the number of players changes, and those for
which there is no such effect.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:09:32 GMT""}]","2022-02-14"
"2202.05774","Alexander Turbiner","D.J.Nader, J.C. del Valle, J.C. Lopez Vieyra, A.V. Turbiner","Ultra-Compact accurate wave functions for He-like and Li-like
  iso-electronic sequences and variational calculus. III. Spin-quartet state of
  the Lithium sequence","29 pages, 5 figures, 2 tables","Int Journal of Quantum Chemistry 123 (8) (2022) qua.26952","10.1002/qua.26952",,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As a continuation of Part I, dedicated to the ground state of He-like and
Li-like isoelectronic sequences for nuclear charges $Z \leq 20$, and Part II,
dedicated to two excited states of He-like sequence, two ultra-compact wave
functions in the form of generalized Guevara-Harris-Turbiner functions are
constructed for Li-like sequence. They describe accurately the domain of
applicability of the Quantum Mechanics of Coulomb Charges (QMCC) for energies
(2-3 significant digits (s.d.)) of the spin-quartet state $1^40^+$ of Li-like
ions (in static approximation with point-like, infinitely heavy nuclei).
Variational parameters are fitted in $Z$ by 2nd degree polynomials. The most
accurate ultra-compact function leads to the absolute accuracy $\sim
10^{-3}$\,a.u. for energy, and $\sim 10^{-4}$ for the normalized
electron-nuclear cusp parameter for $Z \leq 20$. Critical charge $Z=Z_B$, where
the ultra-compact trial function for the $1^40^+$ state looses its
square-integrability, is estimated, $Z_B(1^4\,0^+) \sim 1.26 - 1.30$. As a
complement to Part I, square integrability for the compact functions
constructed for the {\it ground, spin-doublet state} $1^2\,0^+$ of the Li-like
sequence is discussed. The critical charge, for which these functions stop to
be normalizable, is estimated as $Z_B( 1^2\,0^+) = 1.62 - 1.65$. It implies
that at $Z=2$ - the negative helium ion He${}^-$ - both states $1^2\,0^+$ and
$1^4\,0^+$ exist as states embedded to continuum.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:10:33 GMT""}]","2022-07-14"
"2202.05775","Do Edmond Sanou","Do Edmond Sanou, Christophe Ambroise and Genevi\`eve Robin","Inference of Multiscale Gaussian Graphical Model",,,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  Gaussian Graphical Models (GGMs) are widely used for exploratory data
analysis in various fields such as genomics, ecology, psychometry. In a
high-dimensional setting, when the number of variables exceeds the number of
observations by several orders of magnitude, the estimation of GGM is a
difficult and unstable optimization problem. Clustering of variables or
variable selection is often performed prior to GGM estimation. We propose a new
method allowing to simultaneously infer a hierarchical clustering structure and
the graphs describing the structure of independence at each level of the
hierarchy. This method is based on solving a convex optimization problem
combining a graphical lasso penalty with a fused type lasso penalty. Results on
real and synthetic data are presented.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:11:20 GMT""},{""version"":""v2"",""created"":""Wed, 22 Jun 2022 13:14:00 GMT""}]","2022-06-23"
"2202.05776","Tamalika Mukherjee","Jeremiah Blocki, Elena Grigorescu, Tamalika Mukherjee","Privately Estimating Graph Parameters in Sublinear time",,,,,"cs.DS cs.CR","http://creativecommons.org/licenses/by/4.0/","  We initiate a systematic study of algorithms that are both differentially
private and run in sublinear time for several problems in which the goal is to
estimate natural graph parameters. Our main result is a differentially-private
$(1+\rho)$-approximation algorithm for the problem of computing the average
degree of a graph, for every $\rho>0$. The running time of the algorithm is
roughly the same as its non-private version proposed by Goldreich and Ron
(Sublinear Algorithms, 2005). We also obtain the first differentially-private
sublinear-time approximation algorithms for the maximum matching size and the
minimum vertex cover size of a graph.
  An overarching technique we employ is the notion of coupled global
sensitivity of randomized algorithms. Related variants of this notion of
sensitivity have been used in the literature in ad-hoc ways. Here we formalize
the notion and develop it as a unifying framework for privacy analysis of
randomized approximation algorithms.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:17:01 GMT""},{""version"":""v2"",""created"":""Mon, 14 Mar 2022 15:29:21 GMT""}]","2022-03-15"
"2202.05777","Andreas Galanis","Amin Coja-Oghlan, Andreas Galanis, Leslie Ann Goldberg, Jean Bernoulli
  Ravelomanana, Daniel Stefankovic, Eric Vigoda","Metastability of the Potts ferromagnet on random regular graphs","Abstract shortened for arXiv. To appear in Communications in
  Mathematical Physics (CIMP)",,"10.1007/s00220-023-04644-6",,"math.PR cs.DM","http://creativecommons.org/licenses/by/4.0/","  We study the performance of Markov chains for the $q$-state ferromagnetic
Potts model on random regular graphs. It is conjectured that their performance
is dictated by metastability phenomena, i.e., the presence of ""phases""
(clusters) in the sample space where Markov chains with local update rules,
such as the Glauber dynamics, are bound to take exponential time to escape. The
phases that are believed to drive these metastability phenomena in the case of
the Potts model emerge as local, rather than global, maxima of the so-called
Bethe functional, and previous approaches of analysing these phases based on
optimisation arguments fall short of the task.
  Our first contribution is to detail the emergence of the metastable phases
for the $q$-state Potts model on the $d$-regular random graph for all integers
$q,d\geq 3$, and establish that for an interval of temperatures, which is
delineated by the uniqueness and a broadcasting threshold on the $d$-regular
tree, the two phases coexist. The proofs are based on a conceptual connection
between spatial properties and the structure of the Potts distribution on the
random regular graph, rather than complicated moment calculations.
  Based on this new structural understanding of the model, we obtain various
algorithmic consequences. We first complement recent fast mixing results for
Glauber dynamics by Blanca and Gheissari below the uniqueness threshold,
showing an exponential lower bound on the mixing time above the uniqueness
threshold. Then, we obtain tight results even for the non-local Swendsen-Wang
chain, where we establish slow mixing/metastability for the whole interval of
temperatures where the chain is conjectured to mix slowly on the random regular
graph. The key is to bound the conductance of the chains using a random graph
""planting"" argument combined with delicate bounds on random-graph percolation.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:20:39 GMT""},{""version"":""v2"",""created"":""Wed, 14 Sep 2022 10:58:28 GMT""},{""version"":""v3"",""created"":""Tue, 10 Jan 2023 11:43:10 GMT""}]","2023-03-01"
"2202.05778","Shahrukh Khan","Shahrukh Khan, Mahnoor Shahid, Navdeeppal Singh","White-Box Attacks on Hate-speech BERT Classifiers in German with
  Explicit and Implicit Character Level Defense",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  In this work, we evaluate the adversarial robustness of BERT models trained
on German Hate Speech datasets. We also complement our evaluation with two
novel white-box character and word level attacks thereby contributing to the
range of attacks available. Furthermore, we also perform a comparison of two
novel character-level defense strategies and evaluate their robustness with one
another.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:20:50 GMT""},{""version"":""v2"",""created"":""Mon, 14 Feb 2022 10:32:29 GMT""}]","2022-02-15"
"2202.05779","Ruizhe Jia","Agostino Capponi, Ruizhe Jia, Ye Wang","The Evolution of Blockchain: from Lit to Dark",,,,,"q-fin.GN","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Transactions submitted through the blockchain peer-to-peer (P2P) network may
leak out exploitable information. We study the economic incentives behind the
adoption of blockchain dark venues, where users' transactions are observable
only by miners on these venues. We show that miners may not fully adopt dark
venues to preserve rents extracted from arbitrageurs, hence creating execution
risk for users. The dark venue neither eliminates frontrunning risk nor reduces
transaction costs. It strictly increases the payoff of miners, weakly increases
the payoff of users, and weakly reduces arbitrageurs' profits. We provide
empirical support for our main implications, and show that they are
economically significant. A 1% increase in the probability of being frontrun
raises users' adoption rate of the dark venue by 0.6%. Arbitrageurs'
cost-to-revenue ratio increases by a third with a dark venue.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:22:50 GMT""}]","2022-02-14"
"2202.05780","Kazuki Irie","Kazuki Irie, Imanol Schlag, R\'obert Csord\'as, J\""urgen Schmidhuber","A Modern Self-Referential Weight Matrix That Learns to Modify Itself","Accepted to ICML 2022",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  The weight matrix (WM) of a neural network (NN) is its program. The programs
of many traditional NNs are learned through gradient descent in some error
function, then remain fixed. The WM of a self-referential NN, however, can keep
rapidly modifying all of itself during runtime. In principle, such NNs can
meta-learn to learn, and meta-meta-learn to meta-learn to learn, and so on, in
the sense of recursive self-improvement. While NN architectures potentially
capable of implementing such behaviour have been proposed since the '90s, there
have been few if any practical studies. Here we revisit such NNs, building upon
recent successes of fast weight programmers and closely related linear
Transformers. We propose a scalable self-referential WM (SRWM) that learns to
use outer products and the delta update rule to modify itself. We evaluate our
SRWM in supervised few-shot learning and in multi-task reinforcement learning
with procedurally generated game environments. Our experiments demonstrate both
practical applicability and competitive performance of the proposed SRWM. Our
code is public.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:24:31 GMT""},{""version"":""v2"",""created"":""Fri, 17 Jun 2022 12:54:20 GMT""}]","2022-06-20"
"2202.05781","Nicol\'as Grandi","Jos\'e D. Edelstein, Nicol\'as Grandi, Alberto Rivadulla S\'anchez","Holographic superconductivity in Einsteinian Cubic Gravity","19 pages, 8 figures, replaced by revised version with minor
  correeections","J. High Energ. Phys. 2022, 188 (2022)","10.1007/JHEP05(2022)188",,"hep-th cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the condensation of a charged scalar field in a $(3+1)$-dimensional
asymptotically AdS background in the context of Einsteinian cubic gravity,
featuring a holographic superconductor with higher curvature corrections
corresponding to a CFT with a non-vanishing value of the stress tensor
three-point function $t_4$. As it was previously noticed for higher dimensional
Gauss-Bonnet theory, we observe that the critical temperature of the
superconducting phase transition is lowered as the higher curvature coupling
grows.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:24:33 GMT""},{""version"":""v2"",""created"":""Wed, 23 Feb 2022 16:10:32 GMT""}]","2022-06-14"
"2202.05782","Swayamtrupta Panda","Swayamtrupta Panda ((1) Center for Theoretical Physics, Polish Academy
  of Sciences, Warsaw, Poland, (2) Laborat\'orio Nacional de Astrof\'isica -
  MCTIC, Itajub\'a, Brazil, (3) Nicolaus Copernicus Astronomical Center, Polish
  Academy of Sciences, Warsaw, Poland)","Parameterizing the AGN radius -- luminosity relation from the
  Eigenvector 1 viewpoint","33 pages, 12 figures, 4 tables, accepted for publication in
  `Frontiers in Astronomy and Space Sciences: Rising Stars' Issue",,,,"astro-ph.GA astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The study of the broad-line region (BLR) using reverberation mapping has
allowed us to establish an empirical relation between the size of this line
emitting region and the continuum luminosity that drives the line emission
(i.e. the R$_{\rm BLR}$-L$_{\rm 5100}$ relation). To realize its full
potential, the intrinsic scatter in the R$_{\rm BLR}$-L$_{\rm 5100}$ relation
needs to be understood better. The Eddington ratio plays a key role in
addressing this problem. On the other hand, the Eigenvector 1 schema has helped
to reveal an almost clear connection between the Eddington ratio and the
strength of the optical FeII emission which has its origin from the BLR. This
paper aims to reveal the connection between theoretical entities, like, the
ionization parameter (U) and cloud mean density (n$_{\rm H}$) of the BLR, with
physical observables obtained directly from the spectra, such as optical FeII
strength (R$_{\rm FeII}$) that has immense potential to trace the accretion
rate. We utilize the photoionization code CLOUDY and perform a suite of models
to reveal the BLR in the U-n parameter space and estimate RFeII. We compare the
SEDs for a prototypical Population A and Population B source, I Zw 1 and NGC
5548, respectively, in this study. The results from the photoionization
modelling are combined with existing reverberation mapped sources with observed
R$_{\rm FeII}$ estimates, allowing us to provide an analytical formulation to
tie together the aforementioned quantities. We utilize the comparison of the
modelled equivalent widths for the low-ionization emission lines to their
observed values to identify the optimal (U,n$_{\rm H}$). The recovery of the
correct physical conditions in the BLR suggests that the BLR `sees' a
different, filtered ionizing continuum with only a very small fraction (~1-10%)
that leads to the line emission in the dustless, low-ionization BLR.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:27:09 GMT""}]","2022-02-14"
"2202.05783","Jaime Pedregal Pastor","Jaime Pedregal Pastor","From Symplectic to Poisson. A Study of Reduction and a Proposal Towards
  Implosion",,,,,"math.SG math.DG","http://creativecommons.org/licenses/by/4.0/","  The imploded cross-section of a symplectic manifold is a stratified space
allowing for an abelianization of its symplectic reduction. After recalling
symplectic and Poisson reduction and reviewing the basics of symplectic
implosion, we prove a cross-section theorem for Poisson manifolds, generalizing
the Guillemin-Sternberg theorem for symplectic manifolds, which constitutes a
first step towards Poisson implosion. On our way, we find and fix a mistake in
the proof of Guillemin-Sternberg's theorem, and we identify Poisson
transversals as the right analogue to symplectic submanifolds in this context.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:27:44 GMT""}]","2022-02-14"
"2202.05784","Daniele Dorigoni Dr","Daniele Dorigoni, Michael B. Green, Congkao Wen","Exact results for duality-covariant integrated correlators in
  $\mathcal{N}=4$ SYM with general classical gauge groups","38 pages, v2: minor changes, version accepted for publication in
  SciPost",,,"QMUL-PH-22-04","hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present exact expressions for certain integrated correlators of four
superconformal primary operators in the stress tensor multiplet of
$\mathcal{N}=4$ supersymmetric Yang--Mills (SYM) theory with classical gauge
group, $G_N$ $= SO(2N)$, $SO(2N+1)$, $USp(2N)$. These integrated correlators
are expressed as two-dimensional lattice sums by considering derivatives of the
localised partition functions, generalising the expression obtained for $SU(N)$
in our previous works. These expressions are manifestly covariant under
Goddard-Nuyts-Olive duality. The integrated correlators can also be formally
written as infinite sums of non-holomorphic Eisenstein series with integer
indices and rational coefficients. Furthermore, the action of the hyperbolic
Laplace operator with respect to the complex coupling $\tau=\theta/(2\pi) +
4\pi i /g^2_{_{YM}}$ on any integrated correlator for gauge group $G_N$ relates
it to a linear combination of correlators with gauge groups $G_{N+1}$, $G_N$
and $G_{N-1}$. These ""Laplace-difference equation"" determine the expressions of
integrated correlators for all classical gauge groups for any value of $N$ in
terms of the correlator for the gauge group $SU(2)$. The perturbation
expansions of these integrated correlators for any finite value of $N$ agree
with properties obtained from perturbative Yang--Mills quantum field theory,
together with various multi-instanton calculations which are also shown to
agree with those determined by supersymmetric localisation. The coefficients of
terms in the large-$N$ expansion are sums of non-holomorphic Eisenstein series
with half-integer indices, which extend recent results and make contact with
low order terms in the low energy expansion of type IIB superstring theory in
an $AdS_5\times S^5/\mathbb{Z}_2$ background.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:28:52 GMT""},{""version"":""v2"",""created"":""Tue, 11 Oct 2022 15:23:21 GMT""}]","2022-10-12"
"2202.05785","Cheuk Yu Mak","Eduardo Gonz\'alez, Cheuk Yu Mak and Dan Pomerleano","Affine nil-Hecke algebras and Quantum cohomology","39 pages, comments welcome, added toric and flag varieties examples",,,,"math.SG math.AG math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $G$ be a compact, connected Lie group and $T \subset G$ a maximal torus.
Let $(M,\omega)$ be a monotone closed symplectic manifold equipped with a
Hamiltonian action of $G$. We construct a module action of the affine nil-Hecke
algebra $\hat{H}_*^{S^1 \times T}(LG/T)$ on the $S^1 \times T$-equivariant
quantum cohomology of $M$, $QH^*_{S^1 \times T}(M).$ Our construction
generalizes the theory of shift operators for Hamiltonian torus actions
[OP,LJ]. We show that, as in the abelian case, this action behaves well with
respect to the quantum connection. As an application of our construction, we
show that when $G$ is semi-simple, the $G$-equivariant quantum cohomology
$QH_G^*(M)$ defines a canonical holomorphic Lagrangian subvariety
$\mathbb{L}_G(M) \hookrightarrow BFM(G_{\mathbb{C}}^{\vee})$ in the BFM-space
of the Langlands dual group, confirming an expectation of Teleman from [T1].
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:29:05 GMT""},{""version"":""v2"",""created"":""Fri, 29 Apr 2022 16:41:03 GMT""}]","2022-05-02"
"2202.05786","Xiangru Zhu","Xiangru Zhu, Zhixu Li, Xiaodan Wang, Xueyao Jiang, Penglei Sun, Xuwu
  Wang, Yanghua Xiao, Nicholas Jing Yuan","Multi-Modal Knowledge Graph Construction and Application: A Survey","20 pages, 8 figures, 6 tables. Accepted by TKDE 2022",,"10.1109/TKDE.2022.3224228",,"cs.AI cs.CL cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent years have witnessed the resurgence of knowledge engineering which is
featured by the fast growth of knowledge graphs. However, most of existing
knowledge graphs are represented with pure symbols, which hurts the machine's
capability to understand the real world. The multi-modalization of knowledge
graphs is an inevitable key step towards the realization of human-level machine
intelligence. The results of this endeavor are Multi-modal Knowledge Graphs
(MMKGs). In this survey on MMKGs constructed by texts and images, we first give
definitions of MMKGs, followed with the preliminaries on multi-modal tasks and
techniques. We then systematically review the challenges, progresses and
opportunities on the construction and application of MMKGs respectively, with
detailed analyses of the strength and weakness of different solutions. We
finalize this survey with open research problems relevant to MMKGs.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:31:12 GMT""},{""version"":""v2"",""created"":""Sun, 18 Dec 2022 14:52:44 GMT""}]","2022-12-20"
"2202.05788","Tom Dove","Tom Dove, Thomas Schick, Mario Vel\'asquez","A Fixed Point Decomposition of Twisted Equivariant K-Theory","16 pages",,,,"math.KT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a decomposition of rational twisted $G$-equivariant K-theory, $G$
a finite group, into cyclic group equivariant K-theory groups of fixed point
spaces. This generalises the untwisted decomposition by Atiyah and Segal as
well as the decomposition by Adem and Ruan for twists coming from group
cocycles.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:34:37 GMT""}]","2022-02-14"
"2202.05789","Valerio Astuti","Valerio Astuti","A constraint on the dynamics of wealth concentration","New sections added",,,,"econ.TH cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the context of a large class of stochastic processes used to describe the
dynamics of wealth growth, we prove a set of inequalities establishing
necessary and sufficient conditions in order to avoid infinite wealth
concentration. These inequalities generalize results previously found only in
the context of particular models, or with more restrictive sets of hypotheses.
In particular, we emphasize the role of the additive component of growth -
usually representing labor incomes - in limiting the growth of inequality. Our
main result is a proof that in an economy with random wealth growth, with
returns non-negatively correlated with wealth, an average labor income growing
at least proportionally to the average wealth is necessary to avoid a runaway
concentration. One of the main advantages of this result with respect to the
standard economics literature is the independence from the concept of an
equilibrium wealth distribution, which does not always exist in random growth
models. We analyze in this light three toy models, widely studied in the
economics and econophysics literature.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:35:09 GMT""},{""version"":""v2"",""created"":""Mon, 28 Feb 2022 12:15:09 GMT""},{""version"":""v3"",""created"":""Fri, 8 Apr 2022 16:23:39 GMT""},{""version"":""v4"",""created"":""Tue, 19 Apr 2022 14:54:15 GMT""},{""version"":""v5"",""created"":""Wed, 1 Mar 2023 14:33:59 GMT""}]","2023-03-02"
"2202.05790","Veselin Kostov B","Veselin B. Kostov, Brian P. Powell, Saul A. Rappaport, Tamas
  Borkovits, Robert Gagliano, Thomas L. Jacobs, Martti H. Kristiansen, Daryll
  M. LaCourse, Mark Omohundro, Jerome Orosz, Allan R. Schmitt, Hans M.
  Schwengeler, Ivan A. Terentev, Guillermo Torres, Thomas Barclay, Adam H.
  Friedman, Ethan Kruse, Greg Olmschenk, Andrew Vanderburg, William Welsh","97 Eclipsing Quadruple Star Candidates Discovered in TESS Full Frame
  Images","56 pages, 27 figures, 4 tables",,"10.3847/1538-4365/ac5458",,"astro-ph.SR astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a catalog of 97 uniformly-vetted candidates for quadruple star
systems. The candidates were identified in TESS Full Frame Image data from
Sectors 1 through 42 through a combination of machine learning techniques and
visual examination, with major contributions from a dedicated group of citizen
scientists. All targets exhibit two sets of eclipses with two different
periods, both of which pass photocenter tests confirming that the eclipses are
on-target. This catalog outlines the statistical properties of the sample,
nearly doubles the number of known multiply-eclipsing quadruple systems, and
provides the basis for detailed future studies of individual systems. Several
important discoveries have already resulted from this effort, including the
first sextuply-eclipsing sextuple stellar system and the first transiting
circumbinary planet detected from one sector of TESS data.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:35:32 GMT""}]","2022-04-20"
"2202.05791","Matthew Faw","Matthew Faw, Isidoros Tziotis, Constantine Caramanis, Aryan Mokhtari,
  Sanjay Shakkottai, Rachel Ward","The Power of Adaptivity in SGD: Self-Tuning Step Sizes with Unbounded
  Gradients and Affine Variance","Accepted to COLT 2022",,,,"stat.ML cs.LG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study convergence rates of AdaGrad-Norm as an exemplar of adaptive
stochastic gradient methods (SGD), where the step sizes change based on
observed stochastic gradients, for minimizing non-convex, smooth objectives.
Despite their popularity, the analysis of adaptive SGD lags behind that of non
adaptive methods in this setting. Specifically, all prior works rely on some
subset of the following assumptions: (i) uniformly-bounded gradient norms, (ii)
uniformly-bounded stochastic gradient variance (or even noise support), (iii)
conditional independence between the step size and stochastic gradient. In this
work, we show that AdaGrad-Norm exhibits an order optimal convergence rate of
$\mathcal{O}\left(\frac{\mathrm{poly}\log(T)}{\sqrt{T}}\right)$ after $T$
iterations under the same assumptions as optimally-tuned non adaptive SGD
(unbounded gradient norms and affine noise variance scaling), and crucially,
without needing any tuning parameters. We thus establish that adaptive gradient
methods exhibit order-optimal convergence in much broader regimes than
previously understood.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:37:54 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jul 2022 17:44:55 GMT""}]","2022-07-26"
"2202.05792","Manuel G. Algaba","Manuel G. Algaba, Mario Ponce-Martinez, Carlos Munuera-Javaloy,
  Vicente Pina-Canelles, Manish Thapa, Bruno G. Taketani, Martin Leib, In\'es
  de Vega, Jorge Casanova, Hermanni Heimonen","Co-Design quantum simulation of nanoscale NMR",,"Phys. Rev. Research 4, 043089 (2022)",,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum computers have the potential to efficiently simulate the dynamics of
nanoscale NMR systems. In this work we demonstrate that a noisy
intermediate-scale quantum computer can be used to simulate and predict
nanoscale NMR resonances. In order to minimize the required gate fidelities, we
propose a superconducting application-specific Co-Design quantum processor that
reduces the number of SWAP gates by over 90 % for chips with more than 20
qubits. The processor consists of transmon qubits capacitively coupled via
tunable couplers to a central co-planar waveguide resonator with a quantum
circuit refrigerator (QCR) for fast resonator reset. The QCR implements the
non-unitary quantum operations required to simulate nuclear hyperpolarization
scenarios.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:38:59 GMT""},{""version"":""v2"",""created"":""Mon, 14 Mar 2022 17:30:43 GMT""},{""version"":""v3"",""created"":""Thu, 24 Nov 2022 17:22:42 GMT""}]","2022-11-28"
"2202.05793","Tran Cao Son","Tran Cao Son and Enrico Pontelli and Marcello Balduccini and Torsten
  Schaub","Answer Set Planning: A Survey","68 pages, 6 figures",,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  Answer Set Planning refers to the use of Answer Set Programming (ASP) to
compute plans, i.e., solutions to planning problems, that transform a given
state of the world to another state. The development of efficient and scalable
answer set solvers has provided a significant boost to the development of
ASP-based planning systems. This paper surveys the progress made during the
last two and a half decades in the area of answer set planning, from its
foundations to its use in challenging planning domains. The survey explores the
advantages and disadvantages of answer set planning. It also discusses typical
applications of answer set planning and presents a set of challenges for future
research.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:42:47 GMT""}]","2022-02-14"
"2202.05794","Peter Shternin","Peter Shternin and Dmitry Ofengeim","Transport coefficients of magnetized neutron star cores","53 pages, 12 figures; accepted for publication in European Physical
  Journal A",,"10.1140/epja/s10050-022-00687-w",,"nucl-th astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We review the calculations of the kinetic coefficients (thermal conductivity,
shear viscosity, momentum transfer rates) of the neutron star core matter
within the framework of the Landau Fermi-liquid theory. We restrict ourselves
to the case of normal (i.e. non-superfluid) matter. As an example we consider
simplest $npe\mu$ composition of neutron star core matter. Utilizing the
CompOSE database of dense matter equations of state and several microscopic
interactions we analyze the uncertainties in calculations of the kinetic
coefficients that result from the insufficient knowledge of the properties of
the dense nuclear matter and suggest possible approximate treatment. In our
study we also take into account non-quantizing magnetic field. The presence of
magnetic field makes transport anisotropic leading to the tensor structure of
kinetic coefficients. We find that the moderate ($B\lesssim 10^{12}$ G)
magnetic field do not affect considerably thermal conductivity of neutron star
core matter, since the latter is mainly governed by the electrically neutral
neutrons. In contrast, shear viscosity is affected even by the moderate $B\sim
10^8 - 10^{10}$ G. Based on the in-vacuum nucleon interactions we provide
practical expressions for calculation of transport coefficients for any
equation of state of dense matter.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:43:43 GMT""}]","2022-03-23"
"2202.05795","Guan Wang","Haoyang Cao, Xin Guo, Guan Wang","Meta-learning with GANs for anomaly detection, with deployment in
  high-speed rail inspection system",,,,,"cs.LG cs.AI cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Anomaly detection has been an active research area with a wide range of
potential applications. Key challenges for anomaly detection in the AI era with
big data include lack of prior knowledge of potential anomaly types, highly
complex and noisy background in input data, scarce abnormal samples, and
imbalanced training dataset. In this work, we propose a meta-learning framework
for anomaly detection to deal with these issues. Within this framework, we
incorporate the idea of generative adversarial networks (GANs) with appropriate
choices of loss functions including structural similarity index measure (SSIM).
Experiments with limited labeled data for high-speed rail inspection
demonstrate that our meta-learning framework is sharp and robust in identifying
anomalies. Our framework has been deployed in five high-speed railways of China
since 2021: it has reduced more than 99.7% workload and saved 96.7% inspection
time.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:43:49 GMT""}]","2022-02-14"
"2202.05796","Michael Farber","Michael Farber and Shmuel Weinberger","Parametrized topological complexity of sphere bundles",,,,,"math.AT","http://creativecommons.org/licenses/by/4.0/","  Parametrized motion planning algorithms have high degree of flexibility and
universality, they can work under a variety of external conditions, which are
viewed as parameters and form part of the input of the algorithm. In this paper
we analyse the parameterized motion planning problem in the case of sphere
bundles. Our main results provide upper and lower bounds for the parametrized
topological complexity; the upper bounds typically involve sectional categories
of the associated fibrations and the lower bounds are given in terms of
characteristic classes and their properties. We explicitly compute the
parametrized topological complexity in many examples and show that it may
assume arbitrarily large values.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:45:22 GMT""},{""version"":""v2"",""created"":""Thu, 12 May 2022 14:22:04 GMT""}]","2022-05-13"
"2202.05797","Christopher Jung","Pranjal Awasthi, Christopher Jung, Jamie Morgenstern","Distributionally Robust Data Join",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Suppose we are given two datasets: a labeled dataset and unlabeled dataset
which also has additional auxiliary features not present in the first dataset.
What is the most principled way to use these datasets together to construct a
predictor?
  The answer should depend upon whether these datasets are generated by the
same or different distributions over their mutual feature sets, and how similar
the test distribution will be to either of those distributions. In many
applications, the two datasets will likely follow different distributions, but
both may be close to the test distribution. We introduce the problem of
building a predictor which minimizes the maximum loss over all probability
distributions over the original features, auxiliary features, and binary
labels, whose Wasserstein distance is $r_1$ away from the empirical
distribution over the labeled dataset and $r_2$ away from that of the unlabeled
dataset. This can be thought of as a generalization of distributionally robust
optimization (DRO), which allows for two data sources, one of which is
unlabeled and may contain auxiliary features.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:46:24 GMT""}]","2022-02-14"
"2202.05798","Kazuki Irie","Kazuki Irie, R\'obert Csord\'as, J\""urgen Schmidhuber","The Dual Form of Neural Networks Revisited: Connecting Test Time
  Predictions to Training Patterns via Spotlights of Attention","Two first authors. Accepted to ICML 2022",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Linear layers in neural networks (NNs) trained by gradient descent can be
expressed as a key-value memory system which stores all training datapoints and
the initial weights, and produces outputs using unnormalised dot attention over
the entire training experience. While this has been technically known since the
1960s, no prior work has effectively studied the operations of NNs in such a
form, presumably due to prohibitive time and space complexities and impractical
model sizes, all of them growing linearly with the number of training patterns
which may get very large. However, this dual formulation offers a possibility
of directly visualising how an NN makes use of training patterns at test time,
by examining the corresponding attention weights. We conduct experiments on
small scale supervised image classification tasks in single-task, multi-task,
and continual learning settings, as well as language modelling, and discuss
potentials and limits of this view for better understanding and interpreting
how NNs exploit training patterns. Our code is public.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:49:22 GMT""},{""version"":""v2"",""created"":""Fri, 17 Jun 2022 13:22:42 GMT""}]","2022-06-20"
"2202.05799","Feicheng Wang","Feicheng Wang and Lucas Janson","Rate-matching the regret lower-bound in the linear quadratic regulator
  with unknown dynamics",,,,,"cs.LG cs.SY eess.SY math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The theory of reinforcement learning currently suffers from a mismatch
between its empirical performance and the theoretical characterization of its
performance, with consequences for, e.g., the understanding of sample
efficiency, safety, and robustness. The linear quadratic regulator with unknown
dynamics is a fundamental reinforcement learning setting with significant
structure in its dynamics and cost function, yet even in this setting there is
a gap between the best known regret lower-bound of $\Omega_p(\sqrt{T})$ and the
best known upper-bound of $O_p(\sqrt{T}\,\text{polylog}(T))$. The contribution
of this paper is to close that gap by establishing a novel regret upper-bound
of $O_p(\sqrt{T})$. Our proof is constructive in that it analyzes the regret of
a concrete algorithm, and simultaneously establishes an estimation error bound
on the dynamics of $O_p(T^{-1/4})$ which is also the first to match the rate of
a known lower-bound. The two keys to our improved proof technique are (1) a
more precise upper- and lower-bound on the system Gram matrix and (2) a
self-bounding argument for the expected estimation error of the optimal
controller.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:50:14 GMT""}]","2022-02-14"
"2202.05800","Nicol\`o Dal Fabbro","Nicol\`o Dal Fabbro, Subhrakanti Dey, Michele Rossi, Luca Schenato","SHED: A Newton-type algorithm for federated learning based on
  incremental Hessian eigenvector sharing","The name of the algorithm has been changed to SHED (Sharing Hessian
  Eigenvectors for Distributed learning). Section 3 has been enriched with an
  example Figure. In Sec. 5, the main theorems have been updated and improved,
  explicit sufficient conditions for the beginning of the linear convergence
  phase have been provided and conditions for super linear convergence have
  been made more general",,,,"cs.LG cs.AI math.OC","http://creativecommons.org/licenses/by/4.0/","  There is a growing interest in the distributed optimization framework that
goes under the name of Federated Learning (FL). In particular, much attention
is being turned to FL scenarios where the network is strongly heterogeneous in
terms of communication resources (e.g., bandwidth) and data distribution. In
these cases, communication between local machines (agents) and the central
server (Master) is a main consideration. In this work, we present SHED, an
original communication-constrained Newton-type (NT) algorithm designed to
accelerate FL in such heterogeneous scenarios. SHED is by design robust to non
i.i.d. data distributions, handles heterogeneity of agents' communication
resources (CRs), only requires sporadic Hessian computations, and achieves
super-linear convergence. This is possible thanks to an incremental strategy,
based on eigendecomposition of the local Hessian matrices, which exploits
(possibly) outdated second-order information. The proposed solution is
thoroughly validated on real datasets by assessing (i) the number of
communication rounds required for convergence, (ii) the overall amount of data
transmitted and (iii) the number of local Hessian computations. For all these
metrics, the proposed approach shows superior performance against state-of-the
art techniques like GIANT and FedNL.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:52:56 GMT""},{""version"":""v2"",""created"":""Mon, 12 Sep 2022 21:38:08 GMT""}]","2022-09-14"
"2202.05801","Michael Farber","Michael Farber and Shmuel Weinberger","Parametrized motion planning and topological complexity",,,,,"cs.RO math.AT","http://creativecommons.org/licenses/by/4.0/","  In this paper we study paramertized motion planning algorithms which provide
universal and flexible solutions to diverse motion planning problems. Such
algorithms are intended to function under a variety of external conditions
which are viewed as parameters and serve as part of the input of the algorithm.
Continuing a recent paper, we study further the concept of parametrized
topological complexity. We analyse in full detail the problem of controlling a
swarm of robots in the presence of multiple obstacles in Euclidean space which
served for us a natural motivating example. We present an explicit parametrized
motion planning algorithm solving the motion planning problem for any number of
robots and obstacles.. This algorithm is optimal, it has minimal possible
topological complexity for any d odd. Besides, we describe a modification of
this algorithm which is optimal for d even. We also analyse the parametrized
topological complexity of sphere bundles using the Stiefel - Whitney
characteristic classes.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:55:55 GMT""},{""version"":""v2"",""created"":""Wed, 23 Feb 2022 10:53:08 GMT""}]","2022-02-24"
"2202.05802","Mukesh Kumar Singh","Mukesh Kumar Singh, Divyajyoti, Shasvath J. Kapadia, Md Arif Shaikh,
  Parameswaran Ajith","Improved early-warning estimates of luminosity distance and orbital
  inclination of compact binary mergers using higher modes of gravitational
  radiation","12 pages, 7 figures",,"10.1093/mnras/stac852",,"astro-ph.HE gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The pre-merger (early-warning) gravitational-wave (GW) detection and
localization of a compact binary merger would enable astronomers to capture
potential electromagnetic (EM) emissions around the time of the merger, thus
shedding light on the complex physics of the merger. While early detection and
sky localization are of primary importance to the multimessenger follow-up of
the event, improved estimates of luminosity distance and orbital inclination
could also provide insights on the observability of the EM emission. In this
work, we demonstrate that the inclusion of higher modes of gravitational
radiation, which vibrate at higher multiples of the orbital frequency than the
dominant mode, would significantly improve the earlywarning estimates of the
luminosity distance and orbital inclination of the binary. This will help
astronomers to better determine their follow-up strategy. Focusing on future
observing runs of the ground-based GW detector network [O5 run of
LIGOVirgo-KAGRA, Voyager, and third-generation (3G) detectors], we show that
for a range of masses spanning the neutron-star black-hole binaries that are
potentially EM-bright, the inclusion of higher modes improve the luminosity
distance estimates by a factor of ~ 1 - 1.5 (1.1 - 2) [1.1 - 5] for the O5
(Voyager) [3G] observing scenario, 45 (45) [300] seconds before the merger for
the sources located at 100 Mpc. There are significant improvements in orbital
inclination estimates as well. We also investigate these improvements with
varying sky-location and polarization angle. Combining the luminosity distance
uncertainties with localization skyarea estimates, we find that the number of
galaxies within localization volume is reduced by a factor of ~ 1 - 2.5 (1.2 -
4) [1.2 - 10] with the inclusion of higher modes at early-warning time of 45
(45) [300] seconds in O5 (Voyager) [3G].
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:56:31 GMT""}]","2022-04-06"
"2202.05803","Ido Kaminer","Sergey Hazanov, Alexey Gorlach, Ron Ruimy, Dmitry Yakushevskiy,
  Marcelo F. Ciappina, and Ido Kaminer","High Harmonic Generation from Isolated Bound States: Tunable Emission
  Spectra and Mollow Triplets","13 pages, 4 figures",,,,"quant-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High harmonic generation (HHG) is a highly nonlinear emission process in
which systems driven by intense laser pulses emit integer multiples (harmonics)
of the driving field. This feature is considered universal to all occurrences
of HHG. Here we show that a strong nonlinear response of certain systems can
split the HHG spectrum into non-harmonic Mollow-type triplets, imprinting the
internal electronic characteristics and confining potential on the HHG
spectrum. The spectral lines become tunable by the driver field. These
phenomena are universal to any material system with isolated bound states. We
identify the conditions under which our predictions become accessible and
propose experimental systems to observe them.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:57:09 GMT""}]","2022-02-14"
"2202.05804","Trevor Wooley","Trevor D. Wooley","Subconvexity in the inhomogeneous cubic Vinogradov system","18 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When $\mathbf h\in \mathbb Z^3$, denote by $B(X;\mathbf h)$ the number of
integral solutions to the system \[ \sum_{i=1}^6(x_i^j-y_i^j)=h_j\quad (1\le
j\le 3), \] with $1\le x_i,y_i\le X$ $(1\le i\le 6)$. When $h_1\ne 0$ and
appropriate local solubility conditions on $\mathbf h$ are met, we obtain an
asymptotic formula for $B(X;\mathbf h)$, thereby establishing a subconvex
local-global principle in the inhomogeneous cubic Vinogradov system. We obtain
similar conclusions also when $h_1=0$, $h_2\ne 0$ and $X$ is sufficiently large
in terms of $h_2$. Our arguments involve minor arc estimates going beyond
square-root cancellation.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:57:15 GMT""}]","2022-02-14"
"2202.05805","Nicolas Loayza Romero","Daniel G. Figueroa, Adrien Florio, Nicolas Loayza, Mauro Pieroni","""Stairway to Heaven"" -- Spectroscopy of Particle Couplings with
  Gravitational Waves","4 pages, 3 figures and supplemental material",,"10.1103/PhysRevD.106.063522",,"astro-ph.CO hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss the possibility to measure particle couplings with stochastic
gravitational wave backgrounds (SGWBs). Under certain circumstances a sequence
of peaks of different amplitude and frequency -- a $stairway$ -- emerges in a
SGWB spectrum, with each peak probing a different coupling. The detection of
such signature opens the possibility to reconstruct couplings (spectroscopy) of
particle species involved in high energy phenomena generating SGWBs.
Stairway-like signatures may arise in causally produced backgrounds in the
early Universe, e.g. from preheating or first order phase transitions. As a
proof of principle we study a preheating scenario with an inflaton $\phi$
coupled to multiple $daughter$ fields $\lbrace \chi_j \rbrace$ with different
coupling strengths. As a clear stairway signature is imprinted in the SGWB
spectrum, we reconstruct the relevant couplings with various detectors.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:03:58 GMT""}]","2022-10-05"
"2202.05806","Rajeev Sangal Dr","Rajeev Sangal","Evaluating MT Systems: A Theoretical Framework","18 pages",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper outlines a theoretical framework using which different automatic
metrics can be designed for evaluation of Machine Translation systems. It
introduces the concept of {\em cognitive ease} which depends on {\em adequacy}
and {\em lack of fluency}. Thus, cognitive ease becomes the main parameter to
be measured rather than comprehensibility. The framework allows the components
of cognitive ease to be broken up and computed based on different linguistic
levels etc. Independence of dimensions and linearly combining them provides for
a highly modular approach.
  The paper places the existing automatic methods in an overall framework, to
understand them better and to improve upon them in future. It can also be used
to evaluate the newer types of MT systems, such as speech to speech translation
and discourse translation.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:05:17 GMT""}]","2022-02-14"
"2202.05807","Letizia Parato","L. Parato, Sz. Borsanyi, Z. Fodor, J. N. Guenther, C. Hoelbling, S. D.
  Katz, L. Lellouch, T. Lippert, K. Miura, K. K. Szabo, F. Stokes, B. C. Toth,
  Cs. Torok, L. Varnhorst (BMW Collaboration)","QED and strong isospin corrections in the hadronic vacuum polarization
  contribution to the anomalous magnetic moment of the muon","talk presented at the 38th International Symposium on Lattice Field
  Theory, LATTICE2021 26th-30th July, 2021 Zoom/Gather@Massachusetts Institute
  of Technology",,,,"hep-lat hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, the Budapest-Marseille-Wuppertal collaboration achieved sub-percent
precision in the evaluation of the lowest-order hadronic vacuum polarization
contribution to the muon $g_\mu-2$ (arXiv:hep-lat/2002.12347v3). At this level
of precision, isospin-symmetric QCD is not sufficient. In this contribution we
review how QED and strong-isospin-breaking effects have been included in our
work. Isospin breaking is implemented by expanding the relevant correlation
functions to second order in the electric charge $e$ and to first order in
$m_u-m_d$. The correction terms are then computed using isospin-symmetric
configurations. The choice of this approach allows us to better distribute the
available computing resources among the various contributions.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:07:07 GMT""},{""version"":""v2"",""created"":""Mon, 14 Feb 2022 09:25:23 GMT""}]","2022-02-15"
"2202.05808","Arna Ghosh","Arna Ghosh, Arnab Kumar Mondal, Kumar Krishna Agrawal, Blake Richards","Investigating Power laws in Deep Representation Learning",,,,,"cs.LG cs.AI q-bio.NC","http://creativecommons.org/licenses/by/4.0/","  Representation learning that leverages large-scale labelled datasets, is
central to recent progress in machine learning. Access to task relevant labels
at scale is often scarce or expensive, motivating the need to learn from
unlabelled datasets with self-supervised learning (SSL). Such large unlabelled
datasets (with data augmentations) often provide a good coverage of the
underlying input distribution. However evaluating the representations learned
by SSL algorithms still requires task-specific labelled samples in the training
pipeline. Additionally, the generalization of task-specific encoding is often
sensitive to potential distribution shift. Inspired by recent advances in
theoretical machine learning and vision neuroscience, we observe that the
eigenspectrum of the empirical feature covariance matrix often follows a power
law. For visual representations, we estimate the coefficient of the power law,
$\alpha$, across three key attributes which influence representation learning:
learning objective (supervised, SimCLR, Barlow Twins and BYOL), network
architecture (VGG, ResNet and Vision Transformer), and tasks (object and scene
recognition). We observe that under mild conditions, proximity of $\alpha$ to
1, is strongly correlated to the downstream generalization performance.
Furthermore, $\alpha \approx 1$ is a strong indicator of robustness to label
noise during fine-tuning. Notably, $\alpha$ is computable from the
representations without knowledge of any labels, thereby offering a framework
to evaluate the quality of representations in unlabelled datasets.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:11:32 GMT""}]","2022-02-14"
"2202.05809","Valery Suleimanov","Valery F. Suleimanov, Victor Doroshenko, and Klaus Werner (IAAT)","Hard X-ray luminosity functions of cataclysmic variables: Joint
  Swift/BAT and Gaia data","10 pages, 4 figures, 4 tables. Accepted for publication in MNRAS",,"10.1093/mnras/stac417",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cataclysmic variables (CVs) are the most numerous population among the
Galactic objects emitting in hard X-rays. Most probably, they are responsible
for the extended hard X-ray emission of the Galactic ridge and the central
Galactic regions. Here we consider the sample of CVs detected in the all-sky
hard X-ray Swift/BAT survey which were also detected by Gaia and thus have
reliable distance estimates. Using these data, we derive accurate estimates for
local number density per solar mass (\rho_M = 1.37^{+0.3}_{-0.16} x 10^{-5}
M_sun^{-1}) and luminosity density per solar mass (\rho_L = 8.95^{+0.15}_{-0.1}
x 10^{26} erg s^{-1} M_sun^{-1}) for objects in the sample. These values appear
to be in good agreement with the integrated Galactic ridge X-ray emission and
Nuclear Stellar Cluster luminosities. Analysis of the differential luminosity
functions d\rho_M/d(\log_{10} L_x) and d\rho_L/d(\log_{10} L_x) confirms that
there are two populations of hard X-ray emitting CVs. Intermediate polars
dominate at luminosities L > 10^{33} erg s^{-1}, whereas non-magnetic CVs and
polars are much more numerous but have lower luminosities on average. As a
consequence, the contribution of these populations to the observed hard X-ray
luminosity is almost equivalent.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:12:57 GMT""}]","2022-02-23"
"2202.05810","Rapha\""el Bulle","Rapha\""el Bulle, Olga Barrera, St\'ephane P. A. Bordas, Franz Chouly,
  Jack S. Hale","An a posteriori error estimator for the spectral fractional power of the
  Laplacian",,"Computer Methods in Applied Mechanics and Engineering, Volume 407,
  2023, 115943, ISSN 0045-7825","10.1016/j.cma.2023.115943",,"math.NA cs.NA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We develop a novel a posteriori error estimator for the $L^2$ error committed
by the finite element discretization of the solution of the fractional
Laplacian. Our a posteriori error estimator takes advantage of the
semi-discretization scheme using rational approximations which allow to
reformulate the fractional problem into a family of non-fractional parametric
problems. The estimator involves applying the implicit Bank-Weiser error
estimation strategy to each parametric non-fractional problem and
reconstructing the fractional error through the same rational approximation
used to compute the solution to the original fractional problem. In addition we
propose an algorithm to adapt both the finite element mesh and the rational
scheme in order to balance the discretization errors. We provide several
numerical examples in both two and three-dimensions demonstrating the
effectivity of our estimator for varying fractional powers and its ability to
drive an adaptive mesh refinement strategy.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:16:42 GMT""},{""version"":""v2"",""created"":""Fri, 10 Mar 2023 21:33:56 GMT""}]","2023-03-14"
"2202.05811","John McConnell","John McConnell, Fanfei Chen, and Brendan Englot","Overhead Image Factors for Underwater Sonar-based SLAM","To appear in RA-L 2022 and presented at ICRA 2022",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Simultaneous localization and mapping (SLAM) is a critical capability for any
autonomous underwater vehicle (AUV). However, robust, accurate state estimation
is still a work in progress when using low-cost sensors. We propose enhancing a
typical low-cost sensor package using widely available and often free prior
information; overhead imagery. Given an AUV's sonar image and a partially
overlapping, globally-referenced overhead image, we propose using a
convolutional neural network (CNN) to generate a synthetic overhead image
predicting the above-surface appearance of the sonar image contents. We then
use this synthetic overhead image to register our observations to the provided
global overhead image. Once registered, the transformation is introduced as a
factor into a pose SLAM factor graph. We use a state-of-the-art simulation
environment to perform validation over a series of benchmark trajectories and
quantitatively show the improved accuracy of robot state estimation using the
proposed approach. We also show qualitative outcomes from a real AUV field
deployment. Video attachment: https://youtu.be/_uWljtp58ks
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:21:18 GMT""}]","2022-02-14"
"2202.05812","Usman Khan","Muhammad I. Qureshi and Usman A. Khan","Distributed saddle point problems for strongly concave-convex functions",,,,,"math.OC cs.LG cs.MA stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose GT-GDA, a distributed optimization method to solve
saddle point problems of the form: $\min_{\mathbf{x}} \max_{\mathbf{y}}
\{F(\mathbf{x},\mathbf{y}) :=G(\mathbf{x}) + \langle \mathbf{y}, \overline{P}
\mathbf{x} \rangle - H(\mathbf{y})\}$, where the functions $G(\cdot)$,
$H(\cdot)$, and the the coupling matrix $\overline{P}$ are distributed over a
strongly connected network of nodes. GT-GDA is a first-order method that uses
gradient tracking to eliminate the dissimilarity caused by heterogeneous data
distribution among the nodes. In the most general form, GT-GDA includes a
consensus over the local coupling matrices to achieve the optimal (unique)
saddle point, however, at the expense of increased communication. To avoid
this, we propose a more efficient variant GT-GDA-Lite that does not incur the
additional communication and analyze its convergence in various scenarios. We
show that GT-GDA converges linearly to the unique saddle point solution when
$G(\cdot)$ is smooth and convex, $H(\cdot)$ is smooth and strongly convex, and
the global coupling matrix $\overline{P}$ has full column rank. We further
characterize the regime under which GT-GDA exhibits a network
topology-independent convergence behavior. We next show the linear convergence
of GT-GDA to an error around the unique saddle point, which goes to zero when
the coupling cost ${\langle \mathbf y, \overline{P} \mathbf x \rangle}$ is
common to all nodes, or when $G(\cdot)$ and $H(\cdot)$ are quadratic. Numerical
experiments illustrate the convergence properties and importance of GT-GDA and
GT-GDA-Lite for several applications.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:21:23 GMT""},{""version"":""v2"",""created"":""Fri, 1 Jul 2022 04:54:30 GMT""}]","2022-07-04"
"2202.05813","Justin Wittrock","Justin M. Wittrock, Stefan Dreizler, Michael A. Reefe, Brett M.
  Morris, Peter P. Plavchan, Patrick J. Lowrance, Brice-Olivier Demory, James
  G. Ingalls, Emily A. Gilbert, Thomas Barclay, Bryson L. Cale, Karen A.
  Collins, Kevin I. Collins, Ian J. M. Crossfield, Diana Dragomir, Jason D.
  Eastman, Mohammed El Mufti, Dax Feliz, Jonathan Gagne, Eric Gaidos, Peter
  Gao, Claire S. Geneser, Leslie Hebb, Christopher E. Henze, Keith D. Horne,
  Jon M. Jenkins, Eric L. N. Jensen, Stephen R. Kane, Laurel Kaye, Eder
  Martioli, Teresa A. Monsue, Enric Palle, Elisa V. Quintana, Don J. Radford,
  Veronica Roccatagliata, Joshua E. Schlieder, Richard P. Schwarz, Avi Shporer,
  Keivan G. Stassun, Christopher Stockdale, Thiam-Guan Tan, Angelle M. Tanner,
  Andrew Vanderburg, Laura D. Vega, and Songhu Wang","Transit Timing Variations for AU Microscopii b & c","Corrected typos; revised Section 3, 4, and 5 to reflect reanalysis,
  results unchanged. Submitted to AAS Journals Nov 11th, 2020; favorable
  referee report received Jan 3rd; final draft accepted for publication in the
  AJ Apr 19th",,"10.3847/1538-3881/ac68e5",,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  We explore the transit timing variations (TTVs) of the young (22 Myr) nearby
AU Mic planetary system. For AU Mic b, we introduce three Spitzer (4.5 $\mu$m)
transits, five TESS transits, 11 LCO transits, one PEST transit, one Brierfield
transit, and two transit timing measurements from Rossiter-McLaughlin
observations; for AU Mic c, we introduce three TESS transits. We present two
independent TTV analyses. First, we use EXOFASTv2 to jointly model the Spitzer
and ground-based transits and to obtain the midpoint transit times. We then
construct an O--C diagram and model the TTVs with Exo-Striker. Second, we
reproduce our results with an independent photodynamical analysis. We recover a
TTV mass for AU Mic c of 10.8$^{+2.3}_{-2.2}$ M$_{E}$. We compare the
TTV-derived constraints to a recent radial-velocity (RV) mass determination. We
also observe excess TTVs that do not appear to be consistent with the dynamical
interactions of b and c alone, and do not appear to be due to spots or flares.
Thus, we present a hypothetical non-transiting ""middle-d"" candidate exoplanet
that is consistent with the observed TTVs, the candidate RV signal, and would
establish the AU Mic system as a compact resonant multi-planet chain in a 4:6:9
period commensurability. These results demonstrate that the AU Mic planetary
system is dynamically interacting producing detectable TTVs, and the implied
orbital dynamics may inform the formation mechanisms for this young system. We
recommend future RV and TTV observations of AU Mic b and c to further constrain
the masses and to confirm the existence of possible additional planet(s).
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:21:27 GMT""},{""version"":""v2"",""created"":""Wed, 20 Apr 2022 21:12:39 GMT""}]","2022-07-06"
"2202.05814","Benedikt Schroer","Benedikt Schroer, Oreste Pezzi, Damiano Caprioli, Colby Haggerty,
  Pasquale Blasi","Cosmic-ray generated bubbles around their sources","12 pages, accepted for publication in MNRAS",,"10.1093/mnras/stac466",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cosmic rays are thought to escape their sources streaming along the local
magnetic field lines. We show that this phenomenon generally leads to the
excitation of both resonant and non-resonant streaming instabilities. The
self-generated magnetic fluctuations induce particle diffusion in extended
regions around the source, so that cosmic rays build up a large pressure
gradient. By means of two-dimensional (2D) and three-dimensional (3D) hybrid
particle-in-cell simulations, we show that such a pressure gradient excavates a
cavity around the source and leads to the formation of a cosmic-ray dominated
bubble, inside which diffusivity is strongly suppressed. Based on the trends
extracted from self-consistent simulations, we estimate that, in the absence of
severe damping of the self-generated magnetic fields, the bubble should keep
expanding until pressure balance with the surrounding medium is reached,
corresponding to a radius of $\sim 10-50$ pc. The implications of the formation
of these regions of low diffusivity for sources of Galactic cosmic rays are
discussed. Special care is devoted to estimating the self-generated diffusion
coefficient and the grammage that cosmic rays might accumulate in the bubbles
before moving into the interstellar medium. Based on the results of 3D
simulations, general considerations on the morphology of the $\gamma$-ray and
synchrotron emission from these extended regions also are outlined.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:22:48 GMT""}]","2022-03-02"
"2202.05815","Marcello Malagutti","Marcello Malagutti","Semialgebraic and Continuous Solution of Linear Equations with
  Semialgebraic Coefficients","12 pages. arXiv admin note: text overlap with arXiv:2005.00067",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Starting from the results of Charles Fefferman and Janos Koll\'ar in
\texit{Continuous Solutions of Linear Equations} [1], we adopt a new approach
based on Fefferman's techniques of Glaeser refinement to show a more general
result than the one proved by Koll\'ar by using techniques from algebraic
geometry. Considering a system of linear equations with semialgebraic (not only
polynomial as in [1]) coefficients on $\mathbb{R}^{n}$, we get a necessary and
sufficient condition for the existence of a continuous and semialgebraic
solution on $\mathbb{R}^{n}$. This is different from what Fefferman and Luli
obtained in \textit{Semialgebraic Sections Over the Plane} since they stated
their result for solutions of regularity $C^m$ on the plane $\mathbb{R}^2$.
More in depth, we prove that a continuous and semialgebraic solution on
$\mathbb{R}^{n}$ exists if and only if there is a continuous solution i.e., if
the Glaeser-stable bundle associated to the system has no empty fiber.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:24:09 GMT""},{""version"":""v2"",""created"":""Tue, 18 Apr 2023 21:33:03 GMT""}]","2023-04-20"
"2202.05816","Matt Luckcuck","Matt Luckcuck, Marie Farrell, Ois\'in Sheridan","Why just FRET when you can Refactor? Retuning FRETISH Requirements",,,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Formal verification of a software system relies on formalising the
requirements to which it should adhere, which can be challenging. While
formalising requirements from natural-language, we have dependencies that lead
to duplication of information across many requirements, meaning that a change
to one requirement causes updates in several places. We propose to adapt code
refactorings for NASA's Formal Requirements Elicitation Tool (FRET), our
tool-of-choice. Refactoring is the process of reorganising software to improve
its internal structure without altering its external behaviour; it can also be
applied to requirements, to make them more manageable by reducing repetition.
FRET automatically translates requirements (written in its input language
Fretish) into Temporal Logic, which enables us to formally verify that
refactoring has preserved the requirements' underlying meaning. In this paper,
we present four refactorings for Fretish requirements and explain their
utility. We describe the application of one of these refactorings to the
requirements of a civilian aircraft engine software controller, to decouple the
dependencies from the duplication, and analyse how this changes the number of
requirements and the number of repetitions. We evaluate our approach using
Spot, a tool for checking equivalence of Temporal Logic specifications.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:25:28 GMT""}]","2022-02-14"
"2202.05817","Andrea Poltronieri","Andrea Poltronieri and Aldo Gangemi","The HaMSE Ontology: Using Semantic Technologies to support Music
  Representation Interoperability and Musicological Analysis",,,"10.5281/zenodo.6047780",,"cs.SD cs.AI cs.DL cs.MM eess.AS","http://creativecommons.org/licenses/by-sa/4.0/","  The use of Semantic Technologies - in particular the Semantic Web - has
revealed to be a great tool for describing the cultural heritage domain and
artistic practices. However, the panorama of ontologies for musicological
applications seems to be limited and restricted to specific applications. In
this research, we propose HaMSE, an ontology capable of describing musical
features that can assist musicological research. More specifically, HaMSE
proposes to address sues that have been affecting musicological research for
decades: the representation of music and the relationship between quantitative
and qualitative data. To do this, HaMSE allows the alignment between different
music representation systems and describes a set of musicological features that
can allow the music analysis at different granularity levels.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:26:24 GMT""}]","2023-03-31"
"2202.05818","Toby Gee","Toby Gee","Modularity lifting theorems","Accepted version, to appear in Essential Number Theory","Ess. Number Th. 1 (2022) 73-126","10.2140/ent.2022.1.73",,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Updated version of 2013 Arizona WInter School notes on modularity lifting
theorems for for two-dimensional p-adic representations, using wherever
possible arguments that go over to the n-dimensional (self-dual) case.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:26:58 GMT""},{""version"":""v2"",""created"":""Mon, 17 Oct 2022 13:47:14 GMT""}]","2022-10-26"
"2202.05819","Aakash Khandelwal","Aakash Khandelwal, Nilay Kant, Ranjan Mukherjee","Nonprehensile Manipulation of a Stick Using Impulsive Forces","This work has been submitted for possible publication. This version
  submitted to Nonlinear Dynamics on 28 Jun 2022",,,,"eess.SY cs.RO cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The problem of nonprehensile manipulation of a stick in three-dimensional
space using intermittent impulsive forces is considered. The objective is to
juggle the stick between a sequence of configurations that are rotationally
symmetric about the vertical axis. The dynamics of the stick is described by
five generalized coordinates and three control inputs. Between two consecutive
configurations where impulsive inputs are applied, the dynamics is conveniently
represented by a Poincar\'e map in the reference frame of the juggler.
Stabilization of the orbit associated with a desired juggling motion is
accomplished by stabilizing a fixed point on the Poincar\'e map. The Impulse
Controlled Poincar\'e Map approach is used to stabilize the orbit, and
numerical simulations are used to demonstrate convergence to the desired
juggling motion from an arbitrary initial configuration. In the limiting case,
where consecutive rotationally symmetric configurations are chosen arbitrarily
close, it is shown that the dynamics reduces to that of steady precession of
the stick on a hoop.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:28:46 GMT""},{""version"":""v2"",""created"":""Wed, 6 Jul 2022 14:21:34 GMT""}]","2022-07-07"
"2202.05820","Philip Schniter","Saurav K Shastri, Rizwan Ahmad, Christopher A Metzler, Philip Schniter","Expectation Consistent Plug-and-Play for MRI",,,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  For image recovery problems, plug-and-play (PnP) methods have been developed
that replace the proximal step in an optimization algorithm with a call to an
application-specific denoiser, often implemented using a deep neural network.
Although such methods have been successful, they can be improved. For example,
the denoiser is often trained using white Gaussian noise, while PnP's denoiser
input error is often far from white and Gaussian, with statistics that are
difficult to predict from iteration to iteration. PnP methods based on
approximate message passing (AMP) are an exception, but only when the forward
operator behaves like a large random matrix. In this work, we design a PnP
method using the expectation consistent (EC) approximation algorithm, a
generalization of AMP, that offers predictable error statistics at each
iteration, from which a deep-net denoiser can be effectively trained.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:32:15 GMT""}]","2022-02-14"
"2202.05821","Arnaud Huaulm\'e","Arnaud Huaulm\'e, Kanako Harada, Quang-Minh Nguyen, Bogyu Park,
  Seungbum Hong, Min-Kook Choi, Michael Peven, Yunshuang Li, Yonghao Long, Qi
  Dou, Satyadwyoom Kumar, Seenivasan Lalithkumar, Ren Hongliang, Hiroki
  Matsuzaki, Yuto Ishikawa, Yuriko Harai, Satoshi Kondo, Mamoru Mitsuishi,
  Pierre Jannin","PEg TRAnsfer Workflow recognition challenge report: Does multi-modal
  data improve recognition?","Challenge report doi.org/10.1016/j.cmpb.2023.107561","Computer Methods and Programs in Biomedicine, Volume 236, 2023",,,"cs.LG cs.AI cs.DB","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper presents the design and results of the ""PEg TRAnsfert Workflow
recognition"" (PETRAW) challenge whose objective was to develop surgical
workflow recognition methods based on one or several modalities, among video,
kinematic, and segmentation data, in order to study their added value. The
PETRAW challenge provided a data set of 150 peg transfer sequences performed on
a virtual simulator. This data set was composed of videos, kinematics, semantic
segmentation, and workflow annotations which described the sequences at three
different granularity levels: phase, step, and activity. Five tasks were
proposed to the participants: three of them were related to the recognition of
all granularities with one of the available modalities, while the others
addressed the recognition with a combination of modalities. Average
application-dependent balanced accuracy (AD-Accuracy) was used as evaluation
metric to take unbalanced classes into account and because it is more
clinically relevant than a frame-by-frame score. Seven teams participated in at
least one task and four of them in all tasks. Best results are obtained with
the use of the video and the kinematics data with an AD-Accuracy between 93%
and 90% for the four teams who participated in all tasks. The improvement
between video/kinematic-based methods and the uni-modality ones was significant
for all of the teams. However, the difference in testing execution time between
the video/kinematic-based and the kinematic-based methods has to be taken into
consideration. Is it relevant to spend 20 to 200 times more computing time for
less than 3% of improvement? The PETRAW data set is publicly available at
www.synapse.org/PETRAW to encourage further research in surgical workflow
recognition.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:33:11 GMT""},{""version"":""v2"",""created"":""Thu, 14 Apr 2022 15:07:56 GMT""},{""version"":""v3"",""created"":""Thu, 27 Apr 2023 13:27:49 GMT""}]","2023-04-28"
"2202.05822","Yael Vinker","Yael Vinker, Ehsan Pajouheshgar, Jessica Y. Bo, Roman Christian
  Bachmann, Amit Haim Bermano, Daniel Cohen-Or, Amir Zamir, Ariel Shamir","CLIPasso: Semantically-Aware Object Sketching","https://clipasso.github.io/clipasso/",,,,"cs.GR cs.AI cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Abstraction is at the heart of sketching due to the simple and minimal nature
of line drawings. Abstraction entails identifying the essential visual
properties of an object or scene, which requires semantic understanding and
prior knowledge of high-level concepts. Abstract depictions are therefore
challenging for artists, and even more so for machines. We present CLIPasso, an
object sketching method that can achieve different levels of abstraction,
guided by geometric and semantic simplifications. While sketch generation
methods often rely on explicit sketch datasets for training, we utilize the
remarkable ability of CLIP (Contrastive-Language-Image-Pretraining) to distill
semantic concepts from sketches and images alike. We define a sketch as a set
of B\'ezier curves and use a differentiable rasterizer to optimize the
parameters of the curves directly with respect to a CLIP-based perceptual loss.
The abstraction degree is controlled by varying the number of strokes. The
generated sketches demonstrate multiple levels of abstraction while maintaining
recognizability, underlying structure, and essential visual components of the
subject drawn.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:35:25 GMT""},{""version"":""v2"",""created"":""Mon, 16 May 2022 07:04:54 GMT""}]","2022-05-17"
"2202.05823","Kalle Alaluusua","Kalle Alaluusua and Lasse Leskel\""a","Consistent Bayesian community recovery in multilayer networks","13 pages, 1 table",,,,"math.ST math.PR stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Revealing underlying relations between nodes in a network is one of the most
important tasks in network analysis. Using tools and techniques from a variety
of disciplines, many community recovery methods have been developed for
different scenarios. Despite the recent interest on community recovery in
multilayer networks, theoretical results on the accuracy of the estimates are
few and far between. Given a multilayer, e.g. temporal, network and a
multilayer stochastic block model, we derive bounds for sufficient separation
between intra- and inter-block connectivity parameters to achieve posterior
exact and almost exact community recovery. These conditions are comparable to a
well known threshold for community detection by a single-layer stochastic block
model. A simulation study shows that the derived bounds translate to
classification accuracy that improves as the number of observed layers
increases.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:35:58 GMT""}]","2022-02-14"
"2202.05824","Riddhi Chatterjee","Riddhi Chatterjee, A. S. Majumdar","Bell's inequality violation by dynamical Casimir photons in a
  superconducting microwave circuit",,,"10.1103/PhysRevA.106.042224",,"quant-ph cond-mat.mes-hall cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the Bell's inequality violation by dynamical Casimir radiation with
pseudospin measurement. We consider a circuit quantum electrodynamical set-up
where a relativistically moving mirror is simulated by variable external
magnetic flux in a SQUID terminating a superconducting-microwave waveguide. We
analytically obtain expectation values of the Bell operator optimized with
respect to channel orientations, in terms of the system parameters. We consider
the effects of local noise in the microwave field modes, asymmetry between the
field modes resulting from nonzero detuning, and signal loss. Our analysis
provides ranges of the above experimental parameters for which Bell violation
can be observed. We show that Bell violation can be observed in this set-up up
to 40 mK temperature as well as up to 65 % signal loss.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:37:02 GMT""},{""version"":""v2"",""created"":""Sun, 23 Oct 2022 17:28:43 GMT""}]","2022-11-09"
"2202.05825","Gy\""orgy Frank","Gerg\H{o} Pint\'er, Gy\""orgy Frank, D\'aniel Varjas and Andr\'as
  P\'alyi","Birth Quota of Non-Generic Degeneracy Points","6 pages, 2 figures",,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Weyl points are generic and stable features in the energy spectrum of
Hamiltonians that depend on a three-dimensional parameter space. Non-generic
isolated two-fold degeneracy points, such as multi-Weyl points, split into Weyl
points upon a generic perturbation that removes the fine-tuning or protecting
symmetry. The number of the resulting Weyl points is at least $|Q|$, where $Q$
is the topological charge associated to the non-generic degeneracy point. Here,
we show that such a non-generic degeneracy point also has a birth quota, i.e.,
a maximum number of Weyl points that can be born from it upon any perturbation.
The birth quota is a local multiplicity associated to the non-generic
degeneracy point, an invariant of map germs known from singularity theory. This
holds not only for the case of a three-dimensional parameter space with a
Hermitian Hamiltonian, but also for the case of a two-dimensional parameter
space with a chiral-symmetric Hamiltonian. We illustrate the power of this
result for electronic band structures of two- and three-dimensional crystals.
Our work establishes a strong connection between singularity theory and
topological band structures, and more broadly, parameter-dependent quantum
systems.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:37:24 GMT""}]","2022-02-14"
"2202.05826","Arpit Bansal","Arpit Bansal, Avi Schwarzschild, Eitan Borgnia, Zeyad Emam, Furong
  Huang, Micah Goldblum, Tom Goldstein","End-to-end Algorithm Synthesis with Recurrent Networks: Logical
  Extrapolation Without Overthinking",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine learning systems perform well on pattern matching tasks, but their
ability to perform algorithmic or logical reasoning is not well understood. One
important reasoning capability is algorithmic extrapolation, in which models
trained only on small/simple reasoning problems can synthesize complex
strategies for large/complex problems at test time. Algorithmic extrapolation
can be achieved through recurrent systems, which can be iterated many times to
solve difficult reasoning problems. We observe that this approach fails to
scale to highly complex problems because behavior degenerates when many
iterations are applied -- an issue we refer to as ""overthinking."" We propose a
recall architecture that keeps an explicit copy of the problem instance in
memory so that it cannot be forgotten. We also employ a progressive training
routine that prevents the model from learning behaviors that are specific to
iteration number and instead pushes it to learn behaviors that can be repeated
indefinitely. These innovations prevent the overthinking problem, and enable
recurrent systems to solve extremely hard extrapolation tasks.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:43:28 GMT""},{""version"":""v2"",""created"":""Tue, 15 Feb 2022 14:38:12 GMT""},{""version"":""v3"",""created"":""Fri, 14 Oct 2022 20:06:54 GMT""}]","2022-10-18"
"2202.05827","Junhuan Yang","Junhuan Yang, Yi Sheng, Sizhe Zhang, Ruixuan Wang, Kenneth Foreman,
  Mikell Paige, Xun Jiao, Weiwen Jiang, Lei Yang","Automated Architecture Search for Brain-inspired Hyperdimensional
  Computing",,,,,"cs.LG","http://creativecommons.org/publicdomain/zero/1.0/","  This paper represents the first effort to explore an automated architecture
search for hyperdimensional computing (HDC), a type of brain-inspired neural
network. Currently, HDC design is largely carried out in an
application-specific ad-hoc manner, which significantly limits its application.
Furthermore, the approach leads to inferior accuracy and efficiency, which
suggests that HDC cannot perform competitively against deep neural networks.
Herein, we present a thorough study to formulate an HDC architecture search
space. On top of the search space, we apply reinforcement-learning to
automatically explore the HDC architectures. The searched HDC architectures
show competitive performance on case studies involving a drug discovery dataset
and a language recognition task. On the Clintox dataset, which tries to learn
features from developed drugs that passed/failed clinical trials for toxicity
reasons, the searched HDC architecture obtains the state-of-the-art ROC-AUC
scores, which are 0.80% higher than the manually designed HDC and 9.75% higher
than conventional neural networks. Similar results are achieved on the language
recognition task, with 1.27% higher performance than conventional methods.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:43:36 GMT""}]","2022-02-14"
"2202.05828","Andr\'as S\'andor","Gerg\H{o} Pint\'er and Andr\'as S\'andor","Cross-caps, triple points and a linking invariant for finitely
  determined germs","13 page, 2 figures",,,,"math.AT math.AG math.CV","http://creativecommons.org/licenses/by/4.0/","  It was recently proved that for finitely determined germs $ \Phi: (
\mathbb{C}^2, 0) \to ( \mathbb{C}^3, 0) $ the number $C(\Phi)$ of Whitney
umbrella points and the number $T(\Phi)$ of triple values of a stable
deformation are topological invariants. The proof uses the fact that the
combination $C(\Phi)-3T(\Phi)$ is topological since it equals the linking
invariant of the associated immersion $S^3 \looparrowright S^5$ introduced by
Ekholm and Sz\H{u}cs. We provide a new, direct proof for this equality. We also
clarify the relation between various definitions of the latter invariant.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:49:09 GMT""},{""version"":""v2"",""created"":""Fri, 27 Jan 2023 18:23:57 GMT""}]","2023-01-30"
"2202.05829","Praveen Sriram","Connie L. Hsueh, Praveen Sriram, Tiantian Wang, Candice Thomas,
  Geoffrey Gardner, Marc A. Kastner, Michael J. Manfra, David Goldhaber-Gordon","Clean quantum point contacts in an InAs quantum well grown on a
  lattice-mismatched InP substrate","Main text (8 pages, 5 figures), Supplemental Material (10 pages, 10
  figures)","Phys. Rev. B 105, 195303 (2022)","10.1103/PhysRevB.105.195303",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Strong spin-orbit coupling, the resulting large $g$ factor, and small
effective mass make InAs an attractive material platform for inducing
topological superconductivity. The surface Fermi level pinning in the
conduction band enables highly transparent ohmic contact without excessive
doping. We investigate electrostatically defined quantum point contacts (QPCs)
in a deep-well InAs two-dimensional electron gas. Despite the 3.3% lattice
mismatch between the InAs quantum well and the InP substrate, we report clean
QPCs with up to eight pronounced quantized conductance plateaus at zero
magnetic field. Source-drain dc bias spectroscopy reveals a harmonic
confinement potential with a nearly $5$ meV subband spacing. We find a
many-body exchange interaction enhancement for the out-of-plane $g$ factor
$|g_{\perp}^*| = 27 \pm 1$, whereas the in-plane $g$ factor is isotropic
$|g^*_{x}| = |g^*_{y}| = 12 \pm 2$, close to the bulk value for InAs.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:49:46 GMT""},{""version"":""v2"",""created"":""Sat, 14 May 2022 22:26:18 GMT""}]","2022-05-17"
"2202.05830","Daniel Watson","Daniel Watson, William Chan, Jonathan Ho, Mohammad Norouzi","Learning Fast Samplers for Diffusion Models by Differentiating Through
  Sample Quality","Published as a conference paper at ICLR 2022",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Diffusion models have emerged as an expressive family of generative models
rivaling GANs in sample quality and autoregressive models in likelihood scores.
Standard diffusion models typically require hundreds of forward passes through
the model to generate a single high-fidelity sample. We introduce
Differentiable Diffusion Sampler Search (DDSS): a method that optimizes fast
samplers for any pre-trained diffusion model by differentiating through sample
quality scores. We also present Generalized Gaussian Diffusion Models (GGDM), a
family of flexible non-Markovian samplers for diffusion models. We show that
optimizing the degrees of freedom of GGDM samplers by maximizing sample quality
scores via gradient descent leads to improved sample quality. Our optimization
procedure backpropagates through the sampling process using the
reparametrization trick and gradient rematerialization. DDSS achieves strong
results on unconditional image generation across various datasets (e.g., FID
scores on LSUN church 128x128 of 11.6 with only 10 inference steps, and 4.82
with 20 steps, compared to 51.1 and 14.9 with strongest DDPM/DDIM baselines).
Our method is compatible with any pre-trained diffusion model without
fine-tuning or re-training required.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:53:18 GMT""}]","2022-02-14"
"2202.05831","Ting Xue","Ting Xue","Character sheaves for classical graded Lie algebras","16 pages",,,,"math.RT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note we study character sheaves for graded Lie algebras arising from
inner automorphisms of special linear groups and Vinberg's type II classical
graded Lie algebras.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:54:05 GMT""}]","2022-02-14"
"2202.05832","Kentaro Wada","Kentaro Wada, Stephen James, Andrew J. Davison","SafePicking: Learning Safe Object Extraction via Object-Level Mapping","7 pages, 6 figures, IEEE International Conference on Robotics and
  Automation (ICRA) 2022",,,,"cs.RO cs.AI cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Robots need object-level scene understanding to manipulate objects while
reasoning about contact, support, and occlusion among objects. Given a pile of
objects, object recognition and reconstruction can identify the boundary of
object instances, giving important cues as to how the objects form and support
the pile. In this work, we present a system, SafePicking, that integrates
object-level mapping and learning-based motion planning to generate a motion
that safely extracts occluded target objects from a pile. Planning is done by
learning a deep Q-network that receives observations of predicted poses and a
depth-based heightmap to output a motion trajectory, trained to maximize a
safety metric reward. Our results show that the observation fusion of poses and
depth-sensing gives both better performance and robustness to the model. We
evaluate our methods using the YCB objects in both simulation and the real
world, achieving safe object extraction from piles.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:55:10 GMT""},{""version"":""v2"",""created"":""Tue, 1 Mar 2022 09:14:01 GMT""}]","2022-03-02"
"2202.05833","Ecenaz Erdemir","Ecenaz Erdemir, Pier Luigi Dragotti, and Deniz Gunduz","Active Privacy-Utility Trade-off Against Inference in Time-Series Data
  Sharing","12 pages, 12 figures",,,,"cs.IT cs.CR cs.LG math.IT stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Internet of things (IoT) devices, such as smart meters, smart speakers and
activity monitors, have become highly popular thanks to the services they
offer. However, in addition to their many benefits, they raise privacy concerns
since they share fine-grained time-series user data with untrusted third
parties. In this work, we consider a user releasing her data containing
personal information in return of a service from an honest-but-curious service
provider (SP). We model user's personal information as two correlated random
variables (r.v.'s), one of them, called the secret variable, is to be kept
private, while the other, called the useful variable, is to be disclosed for
utility. We consider active sequential data release, where at each time step
the user chooses from among a finite set of release mechanisms, each revealing
some information about the user's personal information, i.e., the true values
of the r.v.'s, albeit with different statistics. The user manages data release
in an online fashion such that the maximum amount of information is revealed
about the latent useful variable as quickly as possible, while the confidence
for the sensitive variable is kept below a predefined level. For privacy
measure, we consider both the probability of correctly detecting the true value
of the secret and the mutual information (MI) between the secret and the
released data. We formulate both problems as partially observable Markov
decision processes (POMDPs), and numerically solve them by advantage
actor-critic (A2C) deep reinforcement learning (DRL). We evaluate the
privacy-utility trade-off (PUT) of the proposed policies on both the synthetic
data and smoking activity dataset, and show their validity by testing the
activity detection accuracy of the SP modeled by a long short-term memory
(LSTM) neural network.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:57:31 GMT""}]","2022-02-14"
"2202.05834","Yaodong Yu","Yaodong Yu, Zitong Yang, Alexander Wei, Yi Ma, Jacob Steinhardt","Predicting Out-of-Distribution Error with the Projection Norm",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a metric -- Projection Norm -- to predict a model's performance on
out-of-distribution (OOD) data without access to ground truth labels.
Projection Norm first uses model predictions to pseudo-label test samples and
then trains a new model on the pseudo-labels. The more the new model's
parameters differ from an in-distribution model, the greater the predicted OOD
error. Empirically, our approach outperforms existing methods on both image and
text classification tasks and across different network architectures.
Theoretically, we connect our approach to a bound on the test error for
overparameterized linear models. Furthermore, we find that Projection Norm is
the only approach that achieves non-trivial detection performance on
adversarial examples. Our code is available at
https://github.com/yaodongyu/ProjNorm.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:58:21 GMT""}]","2022-02-14"
"2202.05835","Christian Seifert","Dennis Gallaun, Jan Meichsner, Christian Seifert","Final State Observability in Banach spaces with applications to
  Subordination and Semigroups induced by L{\'e}vy processes",,,,,"math.FA math.OC math.PR","http://creativecommons.org/licenses/by/4.0/","  This paper generalizes the abstract method of proving an observability
estimate by combining an uncertainty principle and a dissipation estimate. In
these estimates we allow for a large class of growth/decay rates satisfying an
integrability condition. In contrast to previous results, we use an iterative
argument which enables us to give an asymptotically sharp estimate for the
observation constant and which is explicit in the model parameters. We give two
types of applications where the extension of the growth/decay rates naturally
appear. By exploiting subordination techniques we show how the dissipation
estimate of a semigroup transfers to subordinated semigroups. Furthermore, we
apply our results to semigroups related to L{\'e}vy processes.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:59:39 GMT""},{""version"":""v2"",""created"":""Tue, 3 Jan 2023 17:35:10 GMT""}]","2023-01-04"
"2202.05836","Jorge Moreno","Jorge Moreno, Shany Danieli, James S. Bullock, Robert Feldmann, Philip
  F. Hopkins, Onur Catmabacak, Alexander Gurvich, Alexandres Lazar, Courtney
  Klein, Cameron B. Hummels, Zachary Hafen, Francisco J. Mercado, Sijie Yu,
  Fangzhou Jiang, Coral Wheeler, Andrew Wetzel, Daniel Angles-Alcazar, Michael
  Boylan-Kolchin, Eliot Quataert, Claude-Andre Faucher-Giguere and Dusan Keres","Galaxies lacking dark matter produced by close encounters in a
  cosmological simulation","55 pages, 4 figures, 13 supplementary figures. 29 pages, 4 figures.
  Accepted for publication in Nature Astronomy. To appear on 14-February-2022.
  Published version: https://www.nature.com/articles/s41550-021-01598-4",,"10.1038/s41550-021-01598-4",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  The standard cold dark matter plus cosmological constant model predicts that
galaxies form within dark-matter haloes, and that low-mass galaxies are more
dark-matter dominated than massive ones. The unexpected discovery of two
low-mass galaxies lacking dark matter immediately provoked concerns about the
standard cosmology and ignited explorations of alternatives, including
self-interacting dark matter and modified gravity. Apprehension grew after
several cosmological simulations using the conventional model failed to form
adequate numerical analogues with comparable internal characteristics (stellar
masses, sizes, velocity dispersions and morphologies). Here we show that the
standard paradigm naturally produces galaxies lacking dark matter with internal
characteristics in agreement with observations. Using a state-of-the-art
cosmological simulation and a meticulous galaxy-identification technique, we
find that extreme close encounters with massive neighbours can be responsible
for this. We predict that approximately 30 percent of massive central galaxies
(with at least 1e11 solar masses in stars) harbour at least one
dark-matter-deficient satellite (with 1e8 - 1e9 solar masses in stars). This
distinctive class of galaxies provides an additional layer in our understanding
of the role of interactions in shaping galactic properties. Future observations
surveying galaxies in the aforementioned regime will provide a crucial test of
this scenario.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:59:59 GMT""}]","2022-02-14"
"2202.05842","Jorge Berger","Jorge Berger","Thermodynamic failure in the Ginzburg--Landau approach to fluctuation
  superconductivity","Additional issues have been worked out",,,,"cond-mat.stat-mech cond-mat.mes-hall cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  The Ginzburg--Landau approach postulates an energy density, together with an
interpretation for the supercurrent, and invokes Ohm's law. We consider
quasi-one-dimensional nonuniform superconducting loops, either smooth or
piecewise uniform, that enclose a magnetic flux, above the critical
temperature. We evaluate the averages of the current and of the power released
per unit length, due to thermal fluctuations. We consider three averages:
canonical ensemble average, time-average using a time-dependent model, and
canonical ensemble in the reciprocal space. All the evaluations imply that heat
is absorbed in part of the loop and released in other part, despite the
assumption that the loop is at uniform temperature.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 06:41:27 GMT""},{""version"":""v2"",""created"":""Sat, 15 Oct 2022 05:52:35 GMT""},{""version"":""v3"",""created"":""Sun, 29 Jan 2023 08:22:57 GMT""}]","2023-02-01"
"2202.05843","Buddhika Semage","Buddhika Laknath Semage, Thommen George Karimpanal, Santu Rana and
  Svetha Venkatesh","Fast Model-based Policy Search for Universal Policy Networks",,,,,"cs.LG cs.AI cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Adapting an agent's behaviour to new environments has been one of the primary
focus areas of physics based reinforcement learning. Although recent approaches
such as universal policy networks partially address this issue by enabling the
storage of multiple policies trained in simulation on a wide range of
dynamic/latent factors, efficiently identifying the most appropriate policy for
a given environment remains a challenge. In this work, we propose a Gaussian
Process-based prior learned in simulation, that captures the likely performance
of a policy when transferred to a previously unseen environment. We integrate
this prior with a Bayesian Optimisation-based policy search process to improve
the efficiency of identifying the most appropriate policy from the universal
policy network. We empirically evaluate our approach in a range of continuous
and discrete control environments, and show that it outperforms other competing
baselines.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:08:02 GMT""}]","2022-02-15"
"2202.05844","Buddhika Semage","Buddhika Laknath Semage, Thommen George Karimpanal, Santu Rana and
  Svetha Venkatesh","Uncertainty Aware System Identification with Universal Policies",,,,,"cs.LG cs.AI cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sim2real transfer is primarily concerned with transferring policies trained
in simulation to potentially noisy real world environments. A common problem
associated with sim2real transfer is estimating the real-world environmental
parameters to ground the simulated environment to. Although existing methods
such as Domain Randomisation (DR) can produce robust policies by sampling from
a distribution of parameters during training, there is no established method
for identifying the parameters of the corresponding distribution for a given
real-world setting. In this work, we propose Uncertainty-aware policy search
(UncAPS), where we use Universal Policy Network (UPN) to store
simulation-trained task-specific policies across the full range of
environmental parameters and then subsequently employ robust Bayesian
optimisation to craft robust policies for the given environment by combining
relevant UPN policies in a DR like fashion. Such policy-driven grounding is
expected to be more efficient as it estimates only task-relevant sets of
parameters. Further, we also account for the estimation uncertainties in the
search process to produce policies that are robust against both aleatoric and
epistemic uncertainties. We empirically evaluate our approach in a range of
noisy, continuous control environments, and show its improved performance
compared to competing baselines.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:27:23 GMT""}]","2022-02-15"
"2202.05845","Elli Heyes Ms","Guillermo Arias-Tamargo, Yang-Hui He, Elli Heyes, Edward Hirst, Diego
  Rodriguez-Gomez","Brain Webs for Brane Webs","12 pages, 12 figures","Phys. Lett. B 833 (2022) 137376","10.1016/j.physletb.2022.137376","LIMS-2022-08","hep-th","http://creativecommons.org/publicdomain/zero/1.0/","  We propose a new technique for classifying 5d Superconformal Field Theories
arising from brane webs in Type IIB String Theory, using technology from
Machine Learning to identify different webs giving rise to the same theory. We
concentrate on webs with three external legs, for which the problem is
analogous to that of classifying sets of 7-branes. Training a Siamese Neural
Network to determine equivalence between any two brane webs shows an improved
performance when webs are considered equivalent under a weaker set of
conditions. Thus, Machine Learning teaches us that the conjectured
classification of 7-brane sets is not complete, which we confirm with explicit
examples.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:00:00 GMT""},{""version"":""v2"",""created"":""Tue, 20 Sep 2022 09:04:25 GMT""}]","2022-09-21"
"2202.05846","Simon Holz","Simon Holz, Christoph Hanhart, Martin Hoferichter, Bastian Kubis","A dispersive analysis of $\eta'\to\pi^+\pi^-\gamma$ and $\eta'\to
  \ell^+\ell^-\gamma$","18 pages, 2 figures, tension in $\epsilon_{\rho\omega}$ resolved by
  including higher orders in $e^2$","Eur. Phys. J. C 82, 434 (2022)","10.1140/epjc/s10052-022-11094-2","INT-PUB-22-004","hep-ph hep-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a dispersive representation of the $\eta'$ transition form factor
that allows one to account, in a consistent way, for the effects of
$\rho$-$\omega$ mixing in both the isoscalar and the isovector contributions.
Using this formalism, we analyze recent data on $\eta'\to \pi^+\pi^-\gamma$ to
constrain the isovector part of the form factor, individually and in
combination with data for the pion vector form factor. As a first application,
we use our results, in combination with the most recent input for the isoscalar
part of the form factor, to predict the corresponding spectrum of
$\eta'\to\ell^+\ell^-\gamma$, in particular we find the slope parameter
$b_{\eta'}=1.431(23)\, \text{GeV}^{-2}$. With forthcoming data on the latter
process, our results establish the necessary framework to improve the
evaluation of the $\eta'$-pole contribution to the anomalous magnetic moment of
the muon using experimental input from both $\eta'$ decay channels.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:00:00 GMT""},{""version"":""v2"",""created"":""Fri, 13 May 2022 12:30:55 GMT""},{""version"":""v3"",""created"":""Wed, 30 Nov 2022 16:00:01 GMT""}]","2023-01-04"
"2202.05847","Andrew King","Andrew D. King, Sei Suzuki, Jack Raymond, Alex Zucca, Trevor Lanting,
  Fabio Altomare, Andrew J. Berkley, Sara Ejtemaee, Emile Hoskinson, Shuiyuan
  Huang, Eric Ladizinsky, Allison MacDonald, Gaelen Marsden, Travis Oh, Gabriel
  Poulin-Lamarre, Mauricio Reis, Chris Rich, Yuki Sato, Jed D. Whittaker, Jason
  Yao, Richard Harris, Daniel A. Lidar, Hidetoshi Nishimori and Mohammad H.
  Amin","Coherent quantum annealing in a programmable 2000-qubit Ising chain",,"Nature Physics Vol. 18, 1324-1328 (2022)","10.1038/s41567-022-01741-6",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum simulation has emerged as a valuable arena for demonstrating and
understanding the capabilities of near-term quantum computers. Quantum
annealing has been used successfully in simulating a range of open quantum
systems, both at equilibrium and out of equilibrium. However, in all previous
experiments, annealing has been too slow to simulate a closed quantum system
coherently, due to the onset of thermal effects from the environment. Here we
demonstrate coherent evolution through a quantum phase transition in the
paradigmatic setting of the 1D transverse-field Ising chain, using up to 2000
superconducting flux qubits in a programmable quantum annealer. In large
systems we observe the quantum Kibble-Zurek mechanism with theoretically
predicted kink statistics, as well as characteristic positive kink-kink
correlations, independent of system temperature. In small chains, excitation
statistics validate the picture of a Landau-Zener transition at a minimum gap.
In both cases, results are in quantitative agreement with analytical solutions
to the closed-system quantum model. For slower anneals we observe
anti-Kibble-Zurek scaling in a crossover to the open quantum regime. These
experiments demonstrate that large-scale quantum annealers can be operated
coherently, paving the way to exploiting coherent dynamics in quantum
optimization, machine learning, and simulation tasks.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:00:00 GMT""},{""version"":""v2"",""created"":""Thu, 10 Mar 2022 18:49:44 GMT""}]","2022-11-28"
"2202.05848","Antonino Marasco","N. Lehner, J. C. Howk, A. Marasco and F. Fraternali","Intermediate- and high-velocity clouds in the Milky Way I: covering
  factors and vertical heights","Paper I. 14 pages, 9 figures, submitted to MNRAS. Comments are
  welcome",,"10.1093/mnras/stac987",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Intermediate- and high-velocity clouds (IVCs, HVCs) are a potential source of
fuel for star formation in the Milky Way (MW), but their origins and fates
depend sensitively on their distances. We search for IVC and HVC in HST
high-resolution ultraviolet spectra of 55 halo stars at vertical heights $|z|
\gtrsim 1$ kpc. We show that IVCs ($40 \leq |v_{\rm LSR}| <90$ km/s) have a
high detection rate - the covering factor, $f_c$ - that is about constant ($f_c
=0.90\pm 0.04$) from $z=1.5$ to $14$ kpc, implying IVCs are essentially
confined to $|z|\lesssim 1.5$ kpc. For the HVCs ($90 \leq |v_{\rm LSR}|
\lesssim 170$ km/s), we find $f_c$ increases from $f_c \simeq 0.14\pm 0.10$ at
$|z|\lesssim 2-3$ kpc to $f_c =0.60\pm 0.15$ at $5\lesssim |z|\lesssim 14$ kpc,
the latter value being similar to that found towards QSOs. In contrast, the
covering factor of very high-velocity clouds (VHVCs, $|v_{\rm LSR}|\gtrsim 170$
km/s) is $f_c<4\%$ in the stellar sample compared to 20\% in a QSO sample,
implying these clouds must be at $d\gtrsim 10-15$ kpc ($|z|\gtrsim 10$ kpc).
Gas clouds with $|v_{\rm LSR}|>40$ km/s at $|b|\gtrsim 15^\circ$ have therefore
$|v_{\rm LSR}|$ decreasing with decreasing $|z|$. Assuming each feature
originates from a single cloud, we derive scale-heights of $1.0 \pm 0.3$ and
$2.8 \pm 0.3$ kpc for the IVCs and HVCs, respectively. Our findings provide
support to the ""rain"" and galactic fountain models. In the latter scenario,
VHVCs may mostly serve as fuel for the MW halo. In view of their locations and
high covering factors, IVCs and HVCs are good candidates to sustain star
formation in the MW.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:00:01 GMT""}]","2022-04-20"
"2202.05849","Kyoungchul Kong","Haider Alhazmi, Zhongtian Dong, Li Huang, Jeong Han Kim, Kyoungchul
  Kong, David Shih","Resolving Combinatorial Ambiguities in Dilepton $t \bar t$ Event
  Topologies with Neural Networks","22 pages, 15 figures, 1 table, matches the published version","Phys.Rev.D 105 (2022) 11, 115011","10.1103/PhysRevD.105.115011",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We study the potential of deep learning to resolve the combinatorial problem
in SUSY-like events with two invisible particles at the LHC. As a concrete
example, we focus on dileptonic $t \bar t$ events, where the combinatorial
problem becomes an issue of binary classification: pairing the correct lepton
with each $b$ quark coming from the decays of the tops. We investigate the
performance of a number of machine learning algorithms, including
attention-based networks, which have been used for a similar problem in the
fully-hadronic channel of $t\bar t$ production; and the Lorentz Boost Network,
which is motivated by physics principles. We then consider the general case
when the underlying mass spectrum is unknown, and hence no kinematic endpoint
information is available. Compared against existing methods based on kinematic
variables, we demonstrate that the efficiency for selecting the correct pairing
is greatly improved by utilizing deep learning techniques.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 27 Jun 2022 04:40:27 GMT""}]","2022-06-28"
"2202.05850","Alexander Wietek Ph.D.","Alexander Wietek","Fragmented Cooper pair condensation in striped superconductors","5 pages, 6 figures","Phys. Rev. Lett. 129, 177001 (2022)","10.1103/PhysRevLett.129.177001",,"cond-mat.str-el cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Condensation of bosons in Bose-Einstein condensates or Cooper pairs in
superconductors refers to a macroscopic occupation of a few single- or
two-particle states. A condensate is called ""fragmented"" if not a single, but
multiple states are macroscopically occupied. While fragmentation is known to
occur in particular Bose-Einstein condensates, we propose that fragmentation
naturally takes place in striped superconductors. To this end, we investigate
the nature of the superconducting ground state realized in the two-dimensional
$t$-$t^\prime$-$J$ model. In the presence of charge density modulations, the
condensate is shown to be fragmented and composed of partial condensates
located on the stripes. The fragments of the condensates hybridize to form an
extended macroscopic wave function across the system. The results are obtained
from evaluating the singlet-pairing two-particle density matrix of the ground
state on finite cylinders computed via the density matrix renormalization group
(DMRG) method. Our results shed light on the intricate relation between stripe
order and superconductivity in systems of strongly correlated electrons.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:00:01 GMT""},{""version"":""v2"",""created"":""Tue, 18 Oct 2022 14:21:35 GMT""}]","2022-10-19"
"2202.05851","Shane P. Kelly","Shane P. Kelly, James K. Thompson, Ana Maria Rey, and Jamir Marino","Resonant light enhances phase coherence in a cavity QED simulator of
  fermionic superfluidity","5 pages, 3 figures, Supplemental Material","Phys. Rev. Research 4, L042032 (2022)","10.1103/PhysRevResearch.4.L042032",,"cond-mat.quant-gas cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cavity QED experiments are natural hosts for non-equilibrium phases of matter
supported by photon-mediated interactions. In this work, we consider a cavity
QED simulation of the BCS model of superfluidity, by studying regimes where the
cavity photons act as dynamical degrees of freedom instead of mere mediators of
the interaction via virtual processes. We find an enhancement of long time
coherence following a quench whenever the cavity frequency is tuned into
resonance with the atoms. We discuss how this is equivalent to enhancement of
non-equilibrium superfluidity and highlight similarities to an analogous
phenomena recently studied in solid state quantum optics. We also discuss the
conditions for observing this enhanced resonant pairing in experiments by
including the effect of photon losses and inhomogeneous coupling in our
analysis.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:00:01 GMT""}]","2022-12-02"
"2202.05852","Antonino Marasco","A. Marasco, F. Fraternali, N. Lehner and J. C. Howk","Intermediate- and high-velocity clouds in the Milky Way II: evidence for
  a Galactic fountain with collimated outflows and diffuse inflows","Paper II. 13 pages, 4 figures, submitted to MNRAS. Comments are
  welcome",,"10.1093/mnras/stac1172",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We model the kinematics of the high- and intermediate- velocity clouds (HVCs
and IVCs) observed in absorption towards a sample of 55 Galactic halo stars
with accurate distance measurements. We employ a simple model of a thick disc
whose main free parameters are the gas azimuthal, radial and vertical
velocities ($v_\phi$, $v_{\rm R}$ and $v_{\rm z}$), and apply it to the data by
fully accounting for the distribution of the observed features in the
distance-velocity space. We find that at least two separate components are
required to reproduce the data. A scenario where the HVCs and the IVCs are
treated as distinct populations provides only a partial description of the
data, which suggests that a pure velocity-based separation may give a biased
vision of the gas physics at the Milky Way's disc-halo interface. Instead, the
data are best described by a combination of an inflow and an outflow
components, both characterised by rotation with $v_\phi$ comparable to that of
the disc and $v_{\rm z}$ of 50-100 km/s. Features associated with the inflow
appear to be diffused across the sky, while those associated with the outflow
are mostly confined within a bi-cone pointing towards ($l\!=\!220^{\circ}$,
$b\!=\!+40^{\circ}$) and ($l\!=\!40^{\circ}$, $b\!=\!-40^{\circ}$). Our
findings indicate that the lower ($|z|\!\lesssim\!10$ kpc) Galactic halo is
populated by a mixture of diffuse inflowing gas and collimated outflowing
material, which are likely manifestations of a galaxy-wide gas cycle triggered
by stellar feedback, that is, the galactic fountain.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:00:02 GMT""}]","2022-05-25"
"2202.05853","Mart\'in de los Rios","Mart\'in Emilio de los Rios","Cosmic Kite: Auto-encoding the Cosmic Microwave Background","Accepted for its publication in MNRAS",,"10.1093/mnras/stac393",,"astro-ph.CO physics.data-an","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we present the results of the study of the cosmic microwave
background TT power spectrum through auto-encoders in which the latent
variables are the cosmological parameters. This method was trained and
calibrated using a data-set composed by 80000 power spectra from random
cosmologies computed numerically with the CAMB code. Due to the specific
architecture of the auto-encoder, the encoder part is a model that estimates
the maximum-likelihood parameters from a given power spectrum. On the other
hand, the decoder part is a model that computes the power spectrum from the
cosmological parameters and can be used as a forward model in a fully Bayesian
analysis. We show that the encoder is able to estimate the true cosmological
parameters with a precision varying from $\approx 0.004\% $ to $\approx 0.2\% $
(depending on the cosmological parameter), while the decoder computes the power
spectra with a mean percentage error of $\approx 0.0018\% $ for all the
multipole range. We also demonstrate that the decoder recovers the expected
trends when varying the cosmological parameters one by one, and that it does
not introduce any significant bias on the estimation of cosmological parameters
through a Bayesian analysis. These studies gave place to the Cosmic Kite python
software that is publicly available and can be downloaded and installed from
https://github.com/Martindelosrios/cosmic-kite. Although this algorithm does
not improve the precision of the measurements compared with the traditional
methods, it reduces significantly the computation time and represents the first
attempt towards forcing the latent variables to have a physical interpretation.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:00:02 GMT""}]","2022-02-23"
"2202.05854","Nisarga Paul","Nisarga Paul, Philip J.D. Crowley, Trithep Devakul, Liang Fu","Moir\'e Landau fans and magic zeros","5+4 pages; version to appear in PRL",,"10.1103/PhysRevLett.129.116804",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  We study the energy spectrum of moir\'e systems under a uniform magnetic
field. The superlattice potential generally broadens Landau levels into Chern
bands with finite bandwidth. However, we find that these Chern bands become
flat at a discrete set of magnetic fields which we dub ""magic zeros"". The flat
band subspace is generally different from the Landau level subspace in the
absence of the moir\'e superlattice. By developing a semiclassical quantization
method and taking account of superlattice induced Bragg reflection, we prove
that magic zeros arise from the simultaneous quantization of two distinct
$k$-space orbits. The flat bands at magic zeros provide a new setting for
exploring crystalline fractional quantum Hall physics.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:00:03 GMT""},{""version"":""v2"",""created"":""Tue, 30 Aug 2022 16:35:59 GMT""}]","2022-09-13"
"2202.05855","Shuai Chen","Shuai A. Chen, Qianqian Chen, Zheng Zhu","Proposal for asymmetric photoemission and tunneling spectroscopies in
  quantum simulators of the triangular-lattice Fermi-Hubbard model","Published version","Phys. Rev. B 106, 085138(2022)","10.1103/PhysRevB.106.085138",,"cond-mat.quant-gas cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  Recent realization of well-controlled quantum simulators of the
triangular-lattice Fermi-Hubbard model, including the triangular optical
lattices loaded with ultracold Fermions and the heterostructures of the
transition-metal dichalcogenides, as well as the more advanced techniques to
probe them, pave the way for studying frustrated Fermi-Hubbard physics. Here,
we theoretically predict asymmetric photoemission and tunneling spectroscopies
for a lightly hole-doped and electron-doped triangular Mott antiferromagnet,
and reveal two distinct types of magnetic polarons: a \emph{lightly}
renormalized quasiparticle with the same momentum as the spin background and a
\emph{heavily} renormalized quasiparticle with a shifted momentum and a nearly
flat band, using both analytical and unbiased numerical methods. We propose
these theoretical findings to be verified in frustrated optical lattices and
Moir\'e superlattices by probing various observables including the spectral
function, the density of states, the energy dispersion and the quasiparticle
weight. Moreover, we reveal the asymmetric response of the spin background
against charge doping, demonstrating that the interplay between the local spin
and charge degrees of freedom plays a vital role in doped triangular Mott
antiferromagnets.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:00:04 GMT""},{""version"":""v2"",""created"":""Wed, 14 Sep 2022 03:10:31 GMT""}]","2022-09-15"
"2202.05856","Abhijith Gandrakota","Abhijith Gandrakota, Amitabh Lath, Alexandre V. Morozov, Sindhu Murthy","Model selection and signal extraction using Gaussian Process regression",,,"10.1007/JHEP02(2023)230","FERMILAB-PUB-22-073-CMS","hep-ex hep-ph physics.data-an","http://creativecommons.org/licenses/by/4.0/","  We present a novel computational approach for extracting weak signals, whose
exact location and width may be unknown, from complex background distributions
with an arbitrary functional form. We focus on datasets that can be naturally
presented as binned integer counts, demonstrating our approach on the CERN open
dataset from the ATLAS collaboration at the Large Hadron Collider, which
contains the Higgs boson signature. Our approach is based on Gaussian Process
(GP) regression - a powerful and flexible machine learning technique that
allowed us to model the background without specifying its functional form
explicitly, and to separate the background and signal contributions in a robust
and reproducible manner. Unlike functional fits, our GP-regression-based
approach does not need to be constantly updated as more data becomes available.
We discuss how to select the GP kernel type, considering trade-offs between
kernel complexity and its ability to capture the features of the background
distribution. We show that our GP framework can be used to detect the Higgs
boson resonance in the data with more statistical significance than a
polynomial fit specifically tailored to the dataset. Finally, we use Markov
Chain Monte Carlo (MCMC) sampling to confirm the statistical significance of
the extracted Higgs signature.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:00:08 GMT""}]","2023-03-22"
"2202.05857","Duccio Macconi","Duccio Macconi, Paola Grandi, Myriam Gitti, Cristian Vignali, Eleonora
  Torresi, Fabrizio Brighenti","Detection of a radio-filled X-ray cavity within the interstellar medium
  of NGC 5141","9 pages, 6 figures, accepted for publication in A&A on 28 January
  2022","A&A 660, A32 (2022)","10.1051/0004-6361/202143024",,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present the first Chandra detection of a single X-ray cavity within the
interstellar medium of the small Fanaroff-Riley type I (FRI) radio galaxy NGC
5141. The X-ray surface brightness depression, located $\approx 4$ kpc away
from the galaxy center, is projected on the northern radio lobe, which is
completely contained within the galaxy. The thermal gas surrounding the cavity,
which extends to $\approx$ 20 kpc, has a bolometric X-ray luminosity (0.1 - 100
keV) of L${_X}\approx2\times10^{40}$ erg s$^{-1}$ and a temperature of
$kT\approx0.8$ keV. We calculated the total energy (E$_{cav} = 4PV \approx
10^{55}$ erg) required to inflate the cavity and its age ($t_{cav}\approx 9$
Myrs), assuming that it is filled with relativistic particles and rises
buoyantly. The inferred total cavity power is as low as
P$_{cav}=E_{cav}/t_{cav}\approx6\times10^{40}$ erg s$^{-1}$, which is the
lowest one among the radio-filled systems. Comparing $P_{cav}$ to the
bolometric X-ray luminosity (i.e., the cooling luminosity), we conclude that
NGC 5141's central active galactic nucleus can heat the interstellar medium and
balance its cooling luminosity, confirming that the $P_{cav}-L_{cool}$
relation, mainly tested on groups and clusters, also works for such a low-power
system.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:00:31 GMT""}]","2022-04-20"
"2202.05858","Jacob Haqq-Misra","Jacob Haqq-Misra, Ravi Kopparapu, Thomas J. Fauchez, Adam Frank, Jason
  T. Wright, Manasvi Lingam1","Detectability of Chlorofluorocarbons in the Atmospheres of Habitable
  M-dwarf Planets","Accepted by the Planetary Science Journal, 13 pages, 5 figures","Planet. Sci. J. (2022) 3: 60","10.3847/PSJ/ac5404",,"astro-ph.EP astro-ph.IM physics.pop-ph","http://creativecommons.org/licenses/by/4.0/","  The presence of chlorofluorocarbons (CFCs) in Earth's atmosphere is a direct
result of technology. Ozone-depleting CFCs have been banned by most countries,
but some CFCs have persistent in elevated concentrations due to their long
stratospheric lifetimes. CFCs are effective greenhouse gases and could serve as
a remotely detectable spectral signature of technology. Here we use a
three-dimensional climate model and a synthetic spectrum generator to assess
the detectability of CFC-11 and CFC-12 as a technosignature on exoplanets. We
consider the case of TRAPPIST-1e as well as a habitable Earth-like planet
around a 3300 K M-dwarf star, with CFC abundances ranging from one to five
times present-day levels. Assuming an optimistic James Webb Space Telescope
(JWST) Mid Infrared Instrument (MIRI) low resolution spectrometer (LRS) noise
floor level of 10 ppm to multiple co-added observations, we find that spectral
features potentially attributable to present or historic Earth-level CFC
features could be detected with a SNR $\ge 3-5$ on TRAPPIST-1e, if present, in
$\sim 100$ hours of in-transit time. However, applying a very conservative 50
ppm noise floor to co-added observations, even a 5x Earth-level CFC would not
be detectable no matter the observation time. Such observations could be
carried out simultaneously and at no additional cost with searches for
biosignature gases. Non-detection would place upper limits on the CFC
concentration. We find that with the launch of JWST, humanity may be
approaching the cusp of being able to detect passive atmospheric
technosignatures equal in strength to its own around the nearest stars.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:01:17 GMT""}]","2022-03-11"
"2202.05859","Matja\v{z} Gomil\v{s}ek","M. Gomil\v{s}ek, F. L. Pratt, S. P. Cottrell, S. J. Clark, T.
  Lancaster","Many-Body Quantum Muon Effects and Quadrupolar Coupling in Solid
  Nitrogen","Main text: 6 pages, 3 figures. Supplemental Material: 4 pages, 4
  figures",,,,"cond-mat.str-el cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Quantum zero-point motion (ZPM) of light particles in materials has only
recently begun to be explored from an ab initio perspective, through several
competing approximations. Here we develop a unified description of muon (or
light nucleus) ZPM and establish the regimes of anharmonicity and positional
quantum entanglement where different approximation schemes apply. Via density
functional theory and path-integral molecular dynamics simulations we
demonstrate that in solid nitrogen, $\alpha$--N$_2$, muon ZPM is both strongly
anharmonic and many-body in character, with the muon forming an extended
electric-dipole polaron around a central, quantum-entangled
[N$_2$--$\mu$--N$_2$]$^+$ complex. By combining this quantitative description
of quantum muon ZPM with precision muon quadrupolar level-crossing resonance
experiments, we independently determine the static $^{14}$N nuclear quadrupolar
coupling constant of pristine $\alpha$--N$_2$ to be $-5.36(2)$ MHz, a
significant improvement in accuracy over the previously-accepted value of
$-5.39(5)$ MHz.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:01:29 GMT""}]","2022-02-16"
"2202.05860","Maciej Hendzel","M. Hendzel, M. Fidrysiak, J. Spa{\l}ek","Many-particle covalency, ionicity, and atomicity revisited for a few
  simple example molecules",,"J. Phys. B: At. Mol. Opt. Phys. 55 185101 (2022)","10.1088/1361-6455/ac8298",,"cond-mat.str-el physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  We analyze two-particle binding factors of H2, LiH, and HeH+ molecules/ions
with the help of our original exact diagonalization ab intio (EDABI) approach.
The interelectronic correlations are taken into account rigorously within the
second quantization scheme for restricted basis of renormalized single-particle
wave functions, i.e., with their size readjusted in the correlated state. This
allows us to determine the many-particle covalency and ionicity factors in a
natural and intuitive manner in terms of the microscopic single-particle and
interaction parameters, also determined within our method. We discuss the
limitations of those basic characteristics and introduce the concept of
atomicity, corresponding to the Mott and Hubbard criterion concerning
localization threshold in many-particle systems. This addition introduces an
atomic ingredient into the electron states and thus removes a spurious behavior
of covalency with the increasing interatomic distance, as well as provides a
more complete physical interpretation of bonding.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:02:29 GMT""},{""version"":""v2"",""created"":""Fri, 1 Jul 2022 15:41:41 GMT""}]","2022-08-24"
"2202.05861","Jose M. Diego Rodriguez","T. Broadhurst, J.M. Diego, G.F. Smoot","A uniform stellar origin for binary black holes revealed by lensing","7 pages, 5 figures",,,,"astro-ph.GA astro-ph.CO astro-ph.HE gr-qc","http://creativecommons.org/licenses/by/4.0/","  Although most gravitational wave events are claimed to be mergers of
unusually massive, $25-65M_\odot$, black holes, it is now clear that 20\% of
all reported events comprise modest mass black holes, $5-15M_\odot$, like the
stellar black holes in the Milky Way. We show that such stellar mass black hole
binaries (BBH) if magnified by lensing galaxies can be detected at high
redshift, 1$< $z$ <$5, with chirp masses increased by $1+z$, accounting for the
majority of apparently high mass BBH events. This simple lensing explanation is
manifested by the evident bimodality of BBH chirp masses now visible, with 80\%
of BBH events in a broad peak centered on $m_{chirp} \simeq 35M_\odot$, and
20\% of BBH events in a narrow, low mass peak at $m_{chirp} \simeq 8.5M_\odot$,
matching well our prediction for lensed and unlensed events respectively. This
lensing interpretation is reinforced by the ""graveyard plot"" when ranked by
chirp mass, revealing a jump in chirp mass at $m_{chirp} \simeq 10M_\odot$ that
we show is caused by the large redshift difference between unlensed events with
$z<0.3$ and lensed events above $z>1$. Furthermore, nearly all BBH events are
seen to share a component mass ratio of $m_1/m_2=1.45\pm0.03$, indicating a
common stellar origin for BBH events across all chirp masses. This observed
component mass uniformity implies most binary black holes seldom pair up by
random capture, instead we may conclude that massive progenitor stars of BBH
black holes typically formed in-situ, in a well defined way over the full span
of cosmic time accessed through gravitational lensing.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:03:52 GMT""}]","2022-02-15"
"2202.05862","Suvedha Naik","Suvedha Suresh Naik, Kazuyuki Furuuchi, Pravabati Chingangbam","Particle production during inflation: A Bayesian analysis with CMB data
  from Planck 2018","Revised to match the published version, results unchanged",,"10.1088/1475-7516/2022/07/016",,"astro-ph.CO hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A class of inflationary models that involve rapid bursts of particle
productions predict observational signatures, such as bump-like features in the
primordial scalar power spectrum. In this work, we analyze such models by
comparing their predictions with the latest CMB data from Planck 2018. We
consider two scenarios of particle production. The first one is a simple
scenario consisting of a single burst of particle production during observable
inflation. The second one consists of multiple bursts of particle production
that lead to a series of bump-like features in the primordial power spectrum.
We find that the second scenario of the multi-bump model gives better fit to
the CMB data compared to the concordance $\Lambda$CDM model. We carried out
model comparisons using Bayesian evidences. From the observational constraints
on the amplitude of primordial features of the multi-bump model, we find that
the coupling parameter $g$ responsible for particle production is bound to be
$g< 0.05$.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:06:25 GMT""},{""version"":""v2"",""created"":""Tue, 6 Jun 2023 04:55:57 GMT""}]","2023-06-07"
"2202.05863","Daniel Sobotka","Daniel Sobotka, Michael Ebner, Ernst Schwartz, Karl-Heinz Nenning,
  Athena Taymourtash, Tom Vercauteren, Sebastien Ourselin, Gregor Kasprian,
  Daniela Prayer, Georg Langs, Roxane Licandro","Motion Correction and Volumetric Reconstruction for Fetal Functional
  Magnetic Resonance Imaging Data","Preprint submitted to NeuroImage",,"10.1016/j.neuroimage.2022.119213",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motion correction is an essential preprocessing step in functional Magnetic
Resonance Imaging (fMRI) of the fetal brain with the aim to remove artifacts
caused by fetal movement and maternal breathing and consequently to suppress
erroneous signal correlations. Current motion correction approaches for fetal
fMRI choose a single 3D volume from a specific acquisition timepoint with least
motion artefacts as reference volume, and perform interpolation for the
reconstruction of the motion corrected time series. The results can suffer, if
no low-motion frame is available, and if reconstruction does not exploit any
assumptions about the continuity of the fMRI signal. Here, we propose a novel
framework, which estimates a high-resolution reference volume by using
outlier-robust motion correction, and by utilizing Huber L2 regularization for
intra-stack volumetric reconstruction of the motion-corrected fetal brain fMRI.
We performed an extensive parameter study to investigate the effectiveness of
motion estimation and present in this work benchmark metrics to quantify the
effect of motion correction and regularised volumetric reconstruction
approaches on functional connectivity computations. We demonstrate the proposed
framework's ability to improve functional connectivity estimates,
reproducibility and signal interpretability, which is clinically highly
desirable for the establishment of prognostic noninvasive imaging biomarkers.
The motion correction and volumetric reconstruction framework is made available
as an open-source package of NiftyMIC.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:11:16 GMT""}]","2022-05-06"
"2202.05864","Hans Hon Sang Chan","Hans Hon Sang Chan, Richard Meister, Tyson Jones, David P. Tew, Simon
  C. Benjamin","Grid-based methods for chemistry simulations on a quantum computer","Update to reflect published version. 37 pages, 12 figures",,"10.1126/sciadv.abo7484",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  First quantized, grid-based methods for chemistry modelling are a natural and
elegant fit for quantum computers. However, it is infeasible to use today's
quantum prototypes to explore the power of this approach, because it requires a
significant number of near-perfect qubits. Here we employ exactly-emulated
quantum computers with up to 36 qubits, to execute deep yet resource-frugal
algorithms that model 2D and 3D atoms with single and paired particles. A range
of tasks is explored, from ground state preparation and energy estimation to
the dynamics of scattering and ionisation; we evaluate various methods within
the split-operator QFT (SO-QFT) Hamiltonian simulation paradigm, including
protocols previously-described in theoretical papers as well as our own novel
techniques. While we identify certain restrictions and caveats, generally the
grid-based method is found to perform very well; our results are consistent
with the view that first quantized paradigms will be dominant from the early
fault-tolerant quantum computing era onward.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:11:47 GMT""},{""version"":""v2"",""created"":""Mon, 30 May 2022 20:16:46 GMT""},{""version"":""v3"",""created"":""Mon, 17 Oct 2022 11:16:59 GMT""},{""version"":""v4"",""created"":""Mon, 16 Jan 2023 15:41:44 GMT""},{""version"":""v5"",""created"":""Wed, 8 Mar 2023 15:11:39 GMT""}]","2023-03-09"
"2202.05865","Karunava Sil","Sandip Mahish and Karunava Sil","Quantum information scrambling and quantum chaos in little string theory","38 pages, 15 figures, new comments added, References added, Accepted
  for publication in JHEP",,"10.1007/JHEP08(2022)041",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  In the current manuscript we perform a systematic investigation about the
effects of nonlocal interaction to the spread of quantum information in many
body system. In particular, we have studied how nonlocality influence the
existing bound on the growth rate of the commutator involving two local
operators, the butterfly velocity. For this purpose, we consider the nonlocal
theory on the worldvolume of $N\gg 1$, NS$5$ branes arising in the limit of
vanishing string coupling, the `little string theory'. A direct evidence of
nonlocality can be realized from the `volume law' behavior for the most
dominant part of holographic entanglement entropy. We obtain the butterfly
velocity by studying the dynamics of the near horizon geometry backreacted by a
high energy quanta in the form of a shockwave resulting from an early
perturbation on the corresponding thermofield double state. We observe that the
butterfly velocity increases with the nonlocal scale of little string theory,
the inverse Hagedorn temperature $\beta_{h}$, indicating a faster rate of
information spread due to the nonlocal interaction. The same conclusion follows
as the disruption of two sided mutual information is observed to occur at a
faster rate for higher values of $\beta_{h}$. Finally, we realize a direct
connection between the parameters of quantum chaos and the quasinormal modes
for collective excitations through the phenomenon of `pole skipping'.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:11:57 GMT""},{""version"":""v2"",""created"":""Tue, 28 Jun 2022 06:14:09 GMT""}]","2022-08-24"
"2202.05866","Clay C\'ordova","Clay Cordova, Kantaro Ohmori, Tom Rudelius","Generalized Symmetry Breaking Scales and Weak Gravity Conjectures","44 pages, 1 figure",,"10.1007/JHEP11(2022)154",,"hep-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore the notion of approximate global symmetries in quantum field
theory and quantum gravity. We show that a variety of conjectures about quantum
gravity, including the weak gravity conjecture, the distance conjecture, and
the magnetic and axion versions of the weak gravity conjecture can be motivated
by the assumption that generalized global symmetries should be strongly broken
within the context of low-energy effective field theory, i.e. at a
characteristic scale less than the Planck scale where quantum gravity effects
become important. For example, the assumption that the electric one-form
symmetry of Maxwell theory should be strongly broken below the Planck scale
implies the weak gravity conjecture. Similarly, the violation of generalized
non-invertible symmetries is closely tied to analogs of this conjecture for
non-abelian gauge theory. This reasoning enables us to unify these conjectures
with the absence of global symmetries in quantum gravity.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:13:57 GMT""}]","2022-12-14"
"2202.05867","Mark Wolfire","Mark G. Wolfire, Livia Vallini, and M\'elanie Chevance","Photodissociation and X-Ray Dominated Regions","Submitted to Annual Reviews of Astronomy and Astrophysics, Volume 60,
  2022",,"10.1146/annurev-astro-052920-010254",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  The radiation from stars and active galactic nuclei (AGN) creates
photodissociation regions (PDRs) and X-ray dominated regions (XDRs), where the
chemistry or heating are dominated by far-ultraviolet (FUV) radiation or X-ray
radiation, respectively. PDRs include a wide range of environments from the
diffuse interstellar medium to dense star-forming regions. XDRs are found in
the center of galaxies hosting AGN, in protostellar disks, and in the vicinity
of X-ray binaries. In this review, we describe the dominant thermal, chemical,
and radiation transfer processes in PDRs and XDRs, as well as a brief
description of models and their use to analyze observations. We then present
recent results from Milky Way, nearby extragalactic, and high-redshift
observations. Several important results are:
  $\bullet$ Velocity resolved PDR lines reveal the kinematics of the neutral
atomic gas and provide constraints on the stellar feedback process. Their
interpretation is, however, in dispute as observations suggest a prominent role
for stellar winds while they are much less important in theoretical models.
  $\bullet$ A significant fraction of molecular mass resides in CO-dark gas
especially in low-metallicity/highly irradiated environments.
  $\bullet$ The CO ladder and CI/CII ratios can determine if FUV or X-rays
dominate the ISM heating of extragalactic sources.
  $\bullet$ With ALMA, PDR and XDR tracers are now routinely detected on
galactic scales over cosmic time. This makes it possible to link the star
formation history of the Universe to the evolution of the physical and chemical
properties of the gas.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:18:45 GMT""},{""version"":""v2"",""created"":""Tue, 15 Feb 2022 10:39:25 GMT""}]","2022-09-28"
"2202.05868","Paolo Sylos Labini","Paolo Sylos Labini, Massimo Bernaschi, Francesco Silvestri, Flavio
  Vella","Blocking Techniques for Sparse Matrix Multiplication on Tensor
  Accelerators","12 pages, 14 images",,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tensor accelerators have gained popularity because they provide a cheap and
efficient solution for speeding up computational-expensive tasks in Deep
Learning and, more recently, in other Scientific Computing applications.
However, since their features are specifically designed for tensor algebra
(typically dense matrix-product), it is commonly assumed that they are not
suitable for applications with sparse data. To challenge this viewpoint, we
discuss methods and present solutions for accelerating sparse matrix
multiplication on such architectures. In particular, we present a 1-dimensional
blocking algorithm with theoretical guarantees on the density, which builds
dense blocks from arbitrary sparse matrices. Experimental results show that,
even for unstructured and highly-sparse matrices, our block-based solution
which exploits Nvidia Tensor Cores is faster than its sparse counterpart. We
observed significant speed-ups of up to two orders of magnitude on real-world
sparse matrices.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:19:51 GMT""}]","2022-02-15"
"2202.05869","Joseph Lewis","Joseph S. W. Lewis, Pierre Ocvirk, Jenny G. Sorce, Yohan Dubois,
  Dominique Aubert, Luke Conaboy, Paul R. Shapiro, Taha Dawoodbhoy, Romain
  Teyssier, Gustavo Yepes, Stefan Gottl\""ober, Yann Rasera, Kyungjin Ahn, Ilian
  T. Iliev, Hyunbae Park, \'Emilie Th\'elie","The short ionizing photon mean free path at z=6 in Cosmic Dawn III, a
  new fully-coupled radiation-hydrodynamical simulation of the Epoch of
  Reionization","Submitted to MNRAS Accepted 2022 August 08. Received 2022 August 05;
  in original form 2022 February 11",,"10.1093/mnras/stac2383",,"astro-ph.CO","http://creativecommons.org/licenses/by-sa/4.0/","  Recent determinations of the mean free path of ionising photons (mfp) in the
intergalactic medium (IGM) at $\rm z=6$ are lower than many theoretical
predictions. To gain insight into this issue, we investigate the evolution of
the mfp in our new massive fully coupled radiation hydrodynamics cosmological
simulation of reionization: Cosmic Dawn III (CoDaIII). CoDaIII's scale ($\rm
94^3 \, cMpc^3$) and resolution ($\rm 8192^3$ grid) make it particularly
suitable to study the evolution of the IGM during Reionization. The simulation
was performed with RAMSES-CUDATON on Summit, and used 131072 processors coupled
to 24576 GPUs, making it the largest Reionization simulation, and largest
RAMSES simulation ever performed. A superior agreement with global constraints
on Reionization is obtained in CoDaIII over CoDaII especially for the evolution
of the neutral hydrogen fraction and the cosmic photo-ionization rate, thanks
to an improved calibration, later end of reionization ($\rm z=5.6$), and higher
spatial resolution. Analyzing the mfp, we find that CoDaIII reproduces the most
recent observations very well, from $\rm z=6$ to $\rm z=4.6$. We show that the
distribution of the mfp in CoDaIII is bimodal, with short (neutral) and long
(ionized) mfp modes, respectively, due to the patchiness of reionization and
the co-existence of neutral versus ionized regions during Reionization. The
neutral mode peaks at sub-kpc to kpc scales of mfp, while the ionized mode peak
evolves from $\rm 0.1 Mpc/h$ at $\rm z=7$ to $\sim 10$ Mpc/h at $\rm z=5.2$.
Computing the mfp as the average of the ionized mode provides the best match to
the recent observational determinations. The distribution reduces to a single
neutral (ionized) mode at $\rm z>13$ ($\rm z<5$).
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:27:12 GMT""},{""version"":""v2"",""created"":""Mon, 21 Feb 2022 17:24:43 GMT""},{""version"":""v3"",""created"":""Mon, 22 Aug 2022 10:02:18 GMT""}]","2022-08-30"
"2202.05870","Rudolf Haussmann","Rudolf Haussmann","Microscopic density-functional approach to nonlinear elasticity theory","74 pages, 0 figures","Journal of Statistical Mechanics: Theory and Experiment, 053210
  (2022)","10.1088/1742-5468/ac6d61",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Starting from a general classical model of many interacting particles we
present a well defined step by step procedure to derive the continuum-mechanics
equations of nonlinear elasticity theory with fluctuations which describe the
macroscopic phenomena of a solid crystal. As the relevant variables we specify
the coarse-grained densities of the conserved quantities and a properly defined
displacement field which describes the local translations, rotations, and
deformations. In order to stay within the framework of the conventional
density-functional theory we first and mainly consider the isothermal case and
omit the effects of heat transport and warming by friction where later we
extend our theory to the general case and include these effects. We proceed in
two steps. First, we apply the concept of local thermodynamic equilibrium and
minimize the free energy functional under the constraints that the macroscopic
relevant variables are fixed. As results we obtain the local free energy
density and we derive explicit formulas for the elastic constants which are
exact within the framework of density-functional theory. Second, we apply the
methods of nonequilibrium statistical mechanics with projection-operator
techniques. We extend the projection operators in order to include the effects
of coarse-graining and the displacement field. As a result we obtain the
time-evolution equations for the relevant variables with three kinds of terms
on the right-hand sides: reversible, dissipative, and fluctuating terms. We
find explicit formulas for the transport coefficients which are exact in the
limit of continuum mechanics if the projection operators are properly defined.
By construction the theory allows the diffusion of particles in terms of point
defects where, however, in a normal crystal this diffusion is suppressed.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:29:59 GMT""},{""version"":""v2"",""created"":""Wed, 1 Jun 2022 10:29:52 GMT""}]","2022-06-02"
"2202.05871","Philippe Arnault","Philippe Arnault and S\'ebastien Guisset","Chapman-Enskog derivation of multicomponent Navier-Stokes equations",,,"10.1063/5.0088013",,"physics.flu-dyn physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There are several reasons to extend the presentation of Navier-Stokes
equations to multicomponent systems. Many technological applications are based
on physical phenomena that are present neither in pure elements nor in binary
mixtures. Whereas Fourier's law must already be generalized in binaries, it is
only with more than two components that Fick's law breaks down in its simple
form. The emergence of dissipative phenomena affects also the inertial
confinement fusion configurations, designed as prototypes for the future fusion
nuclear plants hopefully replacing the fission ones.
  This important topic can be described in much simpler terms than in many
textbooks since the publication of the formalism put forward recently by Snider
in \textit{Phys. Rev. E} \textbf{82}, 051201 (2010). In a very natural way, it
replaces the linearly dependent atomic fractions by the independent set of
partial densities. Then, the Chapman-Enskog procedure is hardly more
complicated for multicomponent mixtures than for pure elements. Moreover, the
recent proposal of a convergent kinetic equation by Baalrud and Daligault in
\textit{Phys. Plasmas} \textbf{26}, 082106 (2019) demonstrates that Boltzmann
equation with the potential of mean force is a far better choice in situations
close to equilibrium, as described by the Navier-Stokes equations, than Landau
or Lenard-Balescu equations.
  In our comprehensive presentation, we emphasize the physical arguments behind
Chapman-Enskog derivation and keep the mathematics as simple as possible. This
excludes as a technical non-essential aspect the solution of the linearized
Boltzmann equation through an expansion in Hermite polynomials. We discuss the
link with the second principle of Thermodynamics of entropy increase, and what
can be learned from this exposition.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:31:29 GMT""}]","2022-09-14"
"2202.05872","Zachary Grannan","Zachary Grannan, Niki Vazou, Eva Darulova, Alexander J. Summers","REST: Integrating Term Rewriting with Program Verification (Extended
  Version)",,,,,"cs.PL","http://creativecommons.org/licenses/by/4.0/","  We introduce REST, a novel term rewriting technique for theorem proving that
uses online termination checking and can be integrated with existing program
verifiers. REST enables flexible but terminating term rewriting for theorem
proving by: (1) exploiting newly-introduced term orderings that are more
permissive than standard rewrite simplification orderings; (2) dynamically and
iteratively selecting orderings based on the path of rewrites taken so far; and
(3) integrating external oracles that allow steps that cannot be justified with
rewrite rules. Our REST approach is designed around an easily implementable
core algorithm, parameterizable by choices of term orderings and their
implementations; in this way our approach can be easily integrated into
existing tools. We implemented REST as a Haskell library and incorporated it
into Liquid Haskell's evaluation strategy, extending Liquid Haskell with
rewriting rules. We evaluated our REST implementation by comparing it against
both existing rewriting techniques and E-matching and by showing that it can be
used to supplant manual lemma application in many existing Liquid Haskell
proofs.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:32:43 GMT""},{""version"":""v2"",""created"":""Thu, 17 Feb 2022 04:54:06 GMT""}]","2022-02-18"
"2202.05873","Anjali Shriwastawa","Michael Ruzhansky, Anjali Shriwastawa, Bankteshwar Tiwari","A note on best constants for Weighted Integral Hardy inequalities on
  homogeneous groups","11 pages",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  The main aim of this note is to prove sharp weighted integral Hardy
inequality and conjugate integral Hardy inequality on homogeneous Lie groups
with any quasi-norm for the range $1<p\leq q<\infty.$ We also calculate the
precise value of sharp constants in respective inequalities, improving the
result of $[19]$ in the case of homogeneous groups.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:37:05 GMT""}]","2022-02-15"
"2202.05874","Filiberto Ares","Filiberto Ares, Sara Murciano, Pasquale Calabrese","Symmetry-resolved entanglement in a long-range free-fermion chain","25 pages, 8 figures. Minor clarifications, new figure, references
  added. Final version published in JSTAT","J. Stat. Mech. (2022) 063104","10.1088/1742-5468/ac7644",,"cond-mat.stat-mech hep-th quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the symmetry resolution of entanglement in the presence of
long-range couplings. To this end, we study the symmetry-resolved entanglement
entropy in the ground state of a fermionic chain that has dimerised long-range
hoppings with power-like decaying amplitude -- a long-range generalisation of
the Su-Schrieffer-Heeger model. This is a system that preserves the number of
particles. The entropy of each symmetry sector is calculated via the charged
moments of the reduced density matrix. We exploit some recent results on block
Toeplitz determinants generated by a discontinuous symbol to obtain
analytically the asymptotic behaviour of the charged moments and of the
symmetry-resolved entropies for a large subsystem. At leading order we find
entanglement equipartition, but comparing with the short-range counterpart its
breaking occurs at a different order and it does depend on the hopping
amplitudes.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:38:38 GMT""},{""version"":""v2"",""created"":""Tue, 21 Jun 2022 14:44:42 GMT""}]","2022-06-22"
"2202.05875","Noah Olander","Aise Johan de Jong and Noah Olander","On weakly \'etale morphisms","7 pages, comments welcome",,,,"math.AG math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the weakly \'etale morphisms, used to define the pro-\'etale
site of a scheme, are characterized by a lifting property similar to the one
which characterizes formally \'etale morphisms. In order to prove this, we
prove a theorem called Henselian descent which is a ""Henselized version"" of the
fact that a scheme defines a sheaf for the fpqc topology. Finally, we show that
weakly \'etale algebras over regular rings arising in geometry are ind-\'etale
and that weakly \'etale algebras do not always lift along surjective ring
homomorphisms.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:42:03 GMT""}]","2022-02-15"
"2202.05879","Lars Tiemann","Vincent Strenzke, Jana M. Meyer, Isabell Grandt-Ionita, Marta Prada,
  Hyun-Seok Kim, Martin Heilmann, Joao Marcelo J. Lopes, Lars Tiemann, and
  Robert H. Blick","Nuclear-induced dephasing and signatures of hyperfine effects in
  isotopically purified $^{13}$C graphene","5 figures, 21 pages",,"10.1103/PhysRevB.105.144303",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The hyperfine interaction between the spins of electrons and nuclei is both a
blessing and a curse. It can provide a wealth of information when used as an
experimental probing technique but it can also be destructive when it acts as a
dephasive perturbation on the electronic system. In this work, we fabricated
large scale single and multilayer isotopically-purified $^{13}$C graphene Hall
bars to search for interaction effects between the nuclear magnetic moments and
the electronic system. We find signatures of nuclei with a spin in the analysis
of the weak localization phenomenon that shows a significant dichotomy in the
scattering times of monolayer $^{12}$C and $^{13}$C graphene close the Dirac
point. Microwave-induced electron spin flips were exploited to transfer
momentum to the nuclei and build-up a nuclear field. The presence of a very
weak nuclear field is encoded in a modulation of the electron Zeeman energy
which shifts the energy for resonant absorption and reduces the $g$-factor.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:47:51 GMT""}]","2022-04-20"
"2202.05880","George Mertzios","Nina Klobas and George B. Mertzios and Hendrik Molter and Paul G.
  Spirakis","The complexity of computing optimum labelings for temporal connectivity","45 pages, 36 figures",,,,"cs.DS cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A graph is temporally connected if there exists a strict temporal path, i.e.
a path whose edges have strictly increasing labels, from every vertex $u$ to
every other vertex $v$. In this paper we study temporal design problems for
undirected temporally connected graphs. The basic setting of these optimization
problems is as follows: given a connected undirected graph $G$, what is the
smallest number $|\lambda|$ of time-labels that we need to add to the edges of
$G$ such that the resulting temporal graph $(G,\lambda)$ is temporally
connected? As it turns out, this basic problem, called MINIMUM LABELING (ML),
can be optimally solved in polynomial time. However, exploiting the temporal
dimension, the problem becomes more interesting and meaningful in its following
variations, which we investigate in this paper. First we consider the problem
MIN. AGED LABELING (MAL) of temporally connecting the graph when we are given
an upper-bound on the allowed age (i.e. maximum label) of the obtained temporal
graph $(G,\lambda)$. Second we consider the problem MIN. STEINER LABELING
(MSL), where the aim is now to have a temporal path between any pair of
""terminals"" vertices which lie in a subset $R\subseteq V$. This relaxed problem
resembles STEINER TREE in static graphs. However, due to the requirement of
strictly increasing labels in a temporal path, STEINER TREE is not a special
case of MSL. Finally we consider the age-restricted version of MSL, namely MIN.
AGED STEINER LABELING (MASL). Our main results are threefold: we prove that (i)
MAL becomes NP-complete on undirected graphs, while (ii) MASL becomes W[1]-hard
with respect to the number $|R|$ of terminals. On the other hand we prove that
(iii) although the age-unrestricted problem MSL is NP-hard, it is in FPT with
respect to the number $|R|$ of terminals. That is, adding the age restriction,
makes the above problems strictly harder.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:50:01 GMT""},{""version"":""v2"",""created"":""Sun, 1 May 2022 22:10:34 GMT""}]","2022-05-03"
"2202.05882","Juan Rocamonde","Juan Rocamonde, Louie Corpe, Gustavs Zilgalvis, Maria Avramidou and
  Jon Butterworth","Picking the low-hanging fruit: testing new physics at scale with active
  learning",,"SciPost Phys. 13, 002 (2022)","10.21468/SciPostPhys.13.1.002","MCnet-21","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Since the discovery of the Higgs boson, testing the many possible extensions
to the Standard Model has become a key challenge in particle physics. This
paper discusses a new method for predicting the compatibility of new physics
theories with existing experimental data from particle colliders. Using machine
learning, the technique obtained comparable results to previous methods (>90%
precision and recall) with only a fraction of their computing resources (<10%).
This makes it possible to test models that were impossible to probe before, and
allows for large-scale testing of new physics theories.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:52:00 GMT""},{""version"":""v2"",""created"":""Tue, 12 Apr 2022 14:32:24 GMT""}]","2022-07-20"
"2202.05883","Nathan Odendahl","Nathan L. Odendahl and Phillip L. Geissler","Local ice-like structure at the liquid water surface","34 pages, 12 figures, 2 tables","J.Am.Chem.Soc. (2022) 144, 25, 11178-11188","10.1021/jacs.2c01827",,"cond-mat.soft cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Experiments and computer simulations have established that liquid water's
surfaces can deviate in important ways from familiar bulk behavior. Even in the
simplest case of an air-water interface, distinctive layering, orientational
biases, and hydrogen bond arrangements have been reported, but an overarching
picture of their origins and relationships has been incomplete. Here we show
that a broad set of such observations can be understood through an analogy with
the basal face of crystalline ice. Using simulations, we specifically
demonstrate that water and ice surfaces share a set of structural features
suggesting the presence of nanometer-scale ice-like domains at the air-water
interface. Most prominent is a shared characteristic layering of molecular
density and orientation perpendicular to the interface. Similarities in
two-point correlations of hydrogen bond network geometry point to shared
ice-like intermolecular structure in the parallel direction as well. Our
results bolster and significantly extend previous conceptions of ice-like
structure at the liquid's boundary, and suggest that the much-discussed
quasi-liquid layer on ice evolves subtly above the melting point into a
quasi-ice layer at the surface of liquid water.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:53:37 GMT""}]","2022-07-15"
"2202.05884","Joanna Blawat","Joanna Blawat, Madalynn Marshall, John Singleton, Erxi Feng, Huibo
  Cao, Weiwei Xie, Rongying Jin","Unusual electrical and magnetic properties in layered EuZn2As2","17 pages, 4 figures",,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Eu-based compounds often exhibit unusual magnetism, which is critical for
nontrivial topological properties seen in materials such as EuCd2As2. We
investigate the structure and physical properties of EuZn2As2 through
measurements of the electrical resistivity, Hall effect, magnetization, and
neutron diffraction. Our data show that EuZn2As2 orders antiferromagnetically
with an A-type spin configuration below TN = 19 K. Surprisingly, there is
strong evidence for dominant ferromagnetic fluctuations above TN, as reflected
by positive Curie-Weiss temperature and extremely large negative
magnetoresistance (MR) between TN and Tfl {\guillemotright} 200 K. Furthermore,
the angle dependence of the MRab indicates field-induced spin reorientation
from the ab-plane to a direction approximately 45{\deg} from the ab plane.
Compared to EuCd2As2, the doubled TN and Tfl make EuZn2As2 a better platform
for exploring topological properties in both magnetic fluctuation (TN < T <
Tfl) and ordered (T < TN) regimes.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:55:52 GMT""}]","2022-02-15"
"2202.05885","Murray Frank","Hong Chen and Murray Zed Frank","Equilibrium Defaultable Corporate Debt and Investment",,,,,"q-fin.GN econ.TH","http://creativecommons.org/licenses/by/4.0/","  In dynamic capital structure models with an investor break-even condition,
the firm's Bellman equation may not generate a contraction mapping, so the
standard existence and uniqueness conditions do not apply. First, we provide an
example showing the problem in a classical trade-off model. The firm can issue
one-period defaultable debt, invest in capital and pay a dividend. If the firm
cannot meet the required debt payment, it is liquidated. Second, we show how to
use a dual to the original problem and a change of measure, such that existence
and uniqueness can be proved. In the unique Markov-perfect equilibrium, firm
decisions reflect state-dependent capital and debt targets. Our approach may be
useful for other dynamic firm models that have an investor break-even
condition.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 19:56:54 GMT""}]","2022-02-15"
"2202.05886","Simon Chiche","Simon Chiche, Olivier Martineau-Huynh, Kumiko Kotera, Matias Tueros,
  Krijn D. de Vries","Radio-Morphing: a fast, efficient and accurate tool to compute the radio
  signals from air-showers","8 pages, 4 figures. ICRC proceeding",,,,"astro-ph.IM astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Radio detection of air-showers is a mature technique that has gained momentum
over the past decades. With increasingly large-scale experiments, massive
air-shower simulations are needed to evaluate the radio signal at each antenna
position. Radio Morphing was developed for this purpose. It is a
semi-analytical tool that enables a fast computation of the radio signal
emitted by any air-shower at any location, from the simulation data of one
single reference shower at given positions. It relies on simple electromagnetic
scaling laws of the radio emission (i.e., electric field) at the antenna level
and then an interpolation of the radio pulse at the desired positions. We
present here major improvements on the Radio Morphing method that have been
implemented recently. The upgraded version is based on revised and refined
scaling laws, derived from physical principles. It also includes
shower-to-shower fluctuations and a new spatial interpolation technique, thanks
to which an excellent signal timing accuracy of a fraction of nanosecond can be
reached. This new implementation, provides simulated signals with relative
differences on the peak-to-peak amplitude of ZHAireS simulations below 10\%
(respectively 25\%) for 91\% (99\%) of antennas while the computation time was
reduced by more than 2 orders of magnitude compared to standard simulations.
This makes Radio Morphing an efficient tool that allows for a fast and accurate
computation of air-shower radio signals. Further implementation of Askaryan
emission or enabling to use an input value of the geomagnetic field should
reduce relative differences with ZHAireS by few percents and make the method
more universal.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 20:00:14 GMT""}]","2022-02-15"
"2202.05887","Sunho Jang","Sunho Jang, Necmiye Ozay, Johanna L. Mathieu","An Invariant Set Construction Method, Applied to Safe Coordination of
  Thermostatic Loads","13 pages, 8 figures, submitted to IEEE Transactions on Control of
  Network Systems",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of coordinating a collection of switched subsystems
under both local and global constraints for safe operation of the system.
Although an invariant set can be leveraged to construct a safety-guaranteed
controller for this kind of problem, computing an invariant set is not scalable
to high-dimensional systems. In this paper, we introduce a strategy to obtain
an implicit representation of a controlled invariant set for a collection of
switched subsystems, and construct a safety-guaranteed controller to coordinate
the subsystems using the representation. Specifically, we incorporate the
invariant set into a model predictive controller to guarantee safety and
recursive feasibility. Since the amount of computations is independent of the
number of subsystems, this approach scales to large collections of switched
subsystems. We use our approach to safely control a collection of
thermostatically controlled loads to provide grid balancing services. The
problem includes constraints on each load's temperature and duration it must
remain in a mode after a switch, and also on aggregate power consumption to
ensure network safety. Numerical simulations show that the proposed approach
outperforms benchmark strategies in terms of safety and recursive feasibility.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 20:05:01 GMT""}]","2022-02-15"
"2202.05888","Mingao Yuan","Mingao Yuan, Zuofeng Shang","Statistical Limits for Testing Correlation of Hypergraphs","20pages",,,,"math.ST stat.ML stat.TH","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this paper, we consider the hypothesis testing of correlation between two
$m$-uniform hypergraphs on $n$ unlabelled nodes. Under the null hypothesis, the
hypergraphs are independent, while under the alternative hypothesis, the
hyperdges have the same marginal distributions as in the null hypothesis but
are correlated after some unknown node permutation. We focus on two scenarios:
the hypergraphs are generated from the Gaussian-Wigner model and the dense
Erd\""{o}s-R\'{e}nyi model. We derive the sharp information-theoretic testing
threshold. Above the threshold, there exists a powerful test to distinguish the
alternative hypothesis from the null hypothesis. Below the threshold, the
alternative hypothesis and the null hypothesis are not distinguishable. The
threshold involves $m$ and decreases as $m$ gets larger. This indicates testing
correlation of hypergraphs ($m\geq3$) becomes easier than testing correlation
of graphs ($m=2$)
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 20:11:21 GMT""}]","2022-02-15"
"2202.05889","Muhammad Ardiyansyah","Muhammad Ardiyansyah, Dimitra Kosta, Jordi Roca-Lacostena","Embeddability of centrosymmetric matrices capturing the double-helix
  structure in natural and synthetic DNA","34 pages, 9 tables",,,,"q-bio.PE math.PR","http://creativecommons.org/licenses/by/4.0/","  In this paper, we discuss the embedding problem for centrosymmetric matrices,
which are higher order generalizations of the matrices occurring in Strand
Symmetric Models. These models capture the substitution symmetries arising from
the double helix structure of the DNA. Deciding whether a transition matrix is
embeddable or not enables us to know if the observed substitution probabilities
are consistent with a homogeneous continuous time substitution model, such as
the Kimura models, the Jukes-Cantor model or the general time-reversible model.
On the other hand, the generalization to higher order matrices is motivated by
the setting of synthetic biology, which works with different sizes of genetic
alphabets.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 20:13:16 GMT""},{""version"":""v2"",""created"":""Tue, 8 Nov 2022 08:43:13 GMT""}]","2022-11-09"
"2202.05890","Yuansheng Cao","Yuansheng Cao, Tairan Li, Yuhai Tu","Modeling bacterial flagellar motor with new structure information:
  Rotational dynamics of two interacting protein nano-rings",,,,,"cond-mat.soft q-bio.BM q-bio.SC","http://creativecommons.org/licenses/by-sa/4.0/","  In this article, we develop a mathematical model for the rotary bacterial
flagellar motor (BFM) based on the recently discovered structure of the stator
complex (MotA$_5$MotB$_2$). The structure suggested that the stator also
rotates. The BFM is modeled as two rotating nano-rings that interact with each
other. Specifically, translocation of protons through the stator complex drives
rotation of the MotA pentamer ring, which in turn drives rotation of the FliG
ring in the rotor via interactions between the MotA ring of the stator and the
FliG ring of the rotor. Preliminary results from the structure-informed model
are consistent with the observed torque-speed relation. More importantly, the
model predicts distinctive rotor and stator dynamics and their load dependence,
which may be tested by future experiments. Possible approaches to verify and
improve the model to further understanding of the molecular mechanism for
torque generation in BFM are also discussed.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 20:15:38 GMT""}]","2022-02-15"
"2202.05891","Shrisha Rao","Karishma, Shrisha Rao","Cooperative Solutions to Exploration Tasks Under Speed and Budget
  Constraints",,"Journal of Simulation, 2023","10.1080/17477778.2022.2043792",,"cs.MA cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a multi-agent system where agents can cooperate to solve a system
of dependent tasks, with agents having the capability to explore a solution
space, make inferences, as well as query for information under a limited
budget. Re-exploration of the solution space takes place by an agent when an
older solution expires and is thus able to adapt to dynamic changes in the
environment. We investigate the effects of task dependencies, with
highly-dependent graph $G_{40}$ (a well-known program graph that contains $40$
highly interlinked nodes, each representing a task) and less-dependent graphs
$G_{18}$ (a program graph that contains $18$ tasks with fewer links),
increasing the speed of the agents and the complexity of the problem space and
the query budgets available to agents. Specifically, we evaluate trade-offs
between the agent's speed and query budget. During the experiments, we observed
that increasing the speed of a single agent improves the system performance to
a certain point only, and increasing the number of faster agents may not
improve the system performance due to task dependencies. Favoring faster agents
during budget allocation enhances the system performance, in line with the
""Matthew effect."" We also observe that allocating more budget to a faster agent
gives better performance for a less-dependent system, but increasing the number
of faster agents gives a better performance for a highly-dependent system.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 20:17:15 GMT""}]","2023-01-18"
"2202.05892","Tassos Fragos","Tassos Fragos, Jeff J. Andrews, Simone S. Bavera, Christopher P. L.
  Berry, Scott Coughlin, Aaron Dotter, Prabin Giri, Vicky Kalogera, Aggelos
  Katsaggelos, Konstantinos Kovlakas, Shamal Lalvani, Devina Misra, Philipp M.
  Srivastava, Ying Qin, Kyle A. Rocha, Jaime Roman-Garza, Juan Gabriel Serra,
  Petter Stahle, Meng Sun, Xu Teng, Goce Trajcevski, Nam Hai Tran, Zepei Xing,
  Emmanouil Zapartas and Michael Zevin","POSYDON: A General-Purpose Population Synthesis Code with Detailed
  Binary-Evolution Simulations","60 pages, 33 figures, 8 tables, referee's comments addressed. The
  code and the accompanying documentations and data products are available at
  https:\\posydon.org",,"10.3847/1538-4365/ac90c1",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Most massive stars are members of a binary or a higher-order stellar systems,
where the presence of a binary companion can decisively alter their evolution
via binary interactions. Interacting binaries are also important astrophysical
laboratories for the study of compact objects. Binary population synthesis
studies have been used extensively over the last two decades to interpret
observations of compact-object binaries and to decipher the physical processes
that lead to their formation. Here, we present POSYDON, a novel, binary
population synthesis code that incorporates full stellar-structure and
binary-evolution modeling, using the MESA code, throughout the whole evolution
of the binaries. The use of POSYDON enables the self-consistent treatment of
physical processes in stellar and binary evolution, including: realistic
mass-transfer calculations and assessment of stability, internal
angular-momentum transport and tides, stellar core sizes, mass-transfer rates
and orbital periods. This paper describes the detailed methodology and
implementation of POSYDON, including the assumed physics of stellar- and
binary-evolution, the extensive grids of detailed single- and binary-star
models, the post-processing, classification and interpolation methods we
developed for use with the grids, and the treatment of evolutionary phases that
are not based on pre-calculated grids. The first version of POSYDON targets
binaries with massive primary stars (potential progenitors of neutron stars or
black holes) at solar metallicity.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 20:24:04 GMT""},{""version"":""v2"",""created"":""Sun, 7 Aug 2022 07:47:37 GMT""}]","2023-02-15"
"2202.05893","Sayan Banerjee","Sayan Banerjee, Amarjit Budhiraja, Benjamin Estevez","The Inert Drift Atlas Model","55 pages, to appear in Communications in Mathematical Physics",,"10.1007/s00220-022-04589-2",,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consider a massive (inert) particle impinged from above by N Brownian
particles that are instantaneously reflected upon collision with the inert
particle.
  The velocity of the inert particle increases due to the influence of an
external Newtonian potential (e.g. gravitation) and decreases in proportion to
the total local time of collisions with the Brownian particles.
  This system models a semi-permeable membrane in a fluid having microscopic
impurities (Knight (2001)).
  We study the long-time behavior of the process $(V,\mathbf{Z})$, where $V$ is
the velocity of the inert particle and $\mathbf{Z}$ is the vector of gaps
between successive particles ordered by their relative positions. The system is
not hypoelliptic, not reversible, and has singular form interactions. Thus the
study of stability behavior of the system requires new ideas. We show that this
process has a unique stationary distribution that takes an explicit product
form which is Gaussian in the velocity component and Exponential in the other
components. We also show that convergence in total variation distance to the
stationary distribution happens at an exponential rate. We further obtain
certain law of large numbers results for the particle locations and
intersection local times.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 20:24:13 GMT""},{""version"":""v2"",""created"":""Wed, 23 Nov 2022 14:42:25 GMT""}]","2022-12-28"
"2202.05894","Alec Farid","Alec Farid and David Snyder and Allen Z. Ren and Anirudha Majumdar","Failure Prediction with Statistical Guarantees for Vision-Based Robot
  Control",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We are motivated by the problem of performing failure prediction for
safety-critical robotic systems with high-dimensional sensor observations
(e.g., vision). Given access to a black-box control policy (e.g., in the form
of a neural network) and a dataset of training environments, we present an
approach for synthesizing a failure predictor with guaranteed bounds on
false-positive and false-negative errors. In order to achieve this, we utilize
techniques from Probably Approximately Correct (PAC)-Bayes generalization
theory. In addition, we present novel class-conditional bounds that allow us to
trade-off the relative rates of false-positive vs. false-negative errors. We
propose algorithms that train failure predictors (that take as input the
history of sensor observations) by minimizing our theoretical error bounds. We
demonstrate the resulting approach using extensive simulation and hardware
experiments for vision-based navigation with a drone and grasping objects with
a robotic manipulator equipped with a wrist-mounted RGB-D camera. These
experiments illustrate the ability of our approach to (1) provide strong bounds
on failure prediction error rates (that closely match empirical error rates),
and (2) improve safety by predicting failures.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 20:24:27 GMT""},{""version"":""v2"",""created"":""Fri, 6 May 2022 00:50:56 GMT""}]","2022-05-09"
"2202.05895","Farhad Shirani Chaharsooghi","M. Shariatnasab, F. Shirani and Z. Anwar","Privacy Limits in Power-Law Bipartite Networks under Active
  Fingerprinting Attacks",,,,,"cs.SI cs.DB cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work considers the fundamental privacy limits under active
fingerprinting attacks in power-law bipartite networks. The scenario arises
naturally in social network analysis, tracking user mobility in wireless
networks, and forensics applications, among others. A stochastic growing
network generation model -- called the popularity-based model -- is
investigated, where the bipartite network is generated iteratively, and in each
iteration vertices attract new edges based on their assigned popularity values.
It is shown that using the appropriate choice of initial popularity values, the
node degree distribution follows a power-law distribution with arbitrary
parameter $\alpha>2$, i.e. fraction of nodes with degree $d$ is proportional to
$d^{-\alpha}$. An active fingerprinting deanonymization attack strategy called
the augmented information threshold attack strategy (A-ITS) is proposed which
uses the attacker's knowledge of the node degree distribution along with the
concept of information values for deanonymization. Sufficient conditions for
the success of the A-ITS, based on network parameters, are derived. It is shown
through simulations that the proposed attack significantly outperforms the
state-of-the-art attack strategies.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 20:31:09 GMT""}]","2022-02-15"
"2202.05896","Anthony Ashmore","Anthony Ashmore","Calabi-Yau metrics, CFTs and random matrices","6 pages + references, 2 figures. Contribution to Proceedings of the
  2021 Nankai Symposium on Mathematical Dialogues",,,,"hep-th math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Calabi-Yau manifolds have played a key role in both mathematics and physics,
and are particularly important for deriving realistic models of particle
physics from string theory. Unfortunately, very little is known about the
explicit metrics on these spaces, leaving us unable, for example, to compute
particle masses or couplings in these models. We review recent progress in this
direction on using numerical approximations to compute the spectrum of the
Laplacian on these spaces. We give an example of what one can do with this new
""data"", giving a surprising link between Calabi-Yau metrics and random matrix
theory.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 20:38:39 GMT""}]","2022-02-15"
"2202.05897","Chris-Daniel Tarnu","Daniel Tarnu","On maximal autocorrelations of Rudin-Shapiro sequences","16 pages, 2 figures",,,,"math.CO cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  In this paper, we present an alternative proof showing that the maximal
aperiodic autocorrelation of the $m$-th Rudin-Shapiro sequence is of the same
order as $\lambda^{m}$, where $\lambda$ is the real root of $x^{3} + x^{2} - 2x
- 4$. This result was originally proven by Allouche, Choi, Denise, Erd\'elyi,
and Saffari (2019) and Choi (2020) using a translation of the problem into
linear algebra. Our approach simplifies this linear algebraic translation and
provides another method of dealing with the computations given by Choi.
Additionally, we prove an analogous result for the maximal periodic
autocorrelation of the $m$-th Rudin-Shapiro sequence. We conclude with a
discussion on the connection between the proofs given and joint spectral radius
theory, as well as a couple of conjectures on which autocorrelations are
maximal.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 20:39:39 GMT""},{""version"":""v2"",""created"":""Thu, 20 Oct 2022 07:54:26 GMT""}]","2022-10-21"
"2202.05898","Simon Gr\""utzner","Simon Gr\""utzner, Adrian Muntean","Identifying Processes Governing Damage Evolution in Quasi-Static
  Elasticity. Part 2 -- Numerical Simulations","19 pages, 43 figures",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  We investigate numerically a quasi-static elasticity system of Kachanov-type.
To do so we propose an Euler time discretization combined with a suitable
finite elements scheme (FEM) to handle the discretization is space. We use
ODE-type arguments to prove the consistency of the scheme as well as its
convergence rate. We rely on the computational platform FEniCS to perform the
FEM discretizations in space needed to compute the model output. The simulation
results show a good agreement with both the physics of the problem and with our
previous qualitative mathematical analysis results obtained for precisely the
same problem setting. Furthermore, our implementation recovers nicely the
theoretically expected convergence rate. This is a preliminary study preparing
the framework for the rigorous numerical identification of the damage process
in Kachanov-type models.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 20:47:00 GMT""}]","2022-02-15"
"2202.05899","Joshua Faber","Joshua L. Faber","Sheaves over complexes of groups and developability","16 pages",,,,"math.GR","http://creativecommons.org/licenses/by/4.0/","  We define the notion of a sheaf over a complex of groups. As an application,
we give a criterion for the developability of a complex of groups. When the
developability is witnessed by a morphism to $\mathrm{GL}(V)$ for some $V$, our
criterion is a characterization of developability.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 20:52:02 GMT""}]","2022-02-15"
"2202.05900","Keegan Marr","Keegan C. Marr, Carol E. Jones, Chris Tycner, Alex C. Carciofi, Ariane
  C. Fonseca Silva","The Role of Disk Tearing and Precession in the Observed Variability of
  Pleione","19 pages, 15 figures",,"10.3847/1538-4357/ac551b",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We acquired H$\alpha$ spectroscopic observations from 2005 to 2019 showing
Pleione has transitioned from a Be phase to a Be-shell phase during this
period. Using the radiative transfer code \hdust\ we created a grid of
$\sim100,000$ disk models for Pleione. We successfully reproduced the observed
transition with a disk model that varies in inclination while maintaining an
equatorial density of $\rho_0(r) = 3\times 10^{-11}
(r/R_{eq})^{-2.7}~\rm{g~cm^{-3}}$, and an H$\alpha$ emitting region extending
to $15~\rm{R_{eq}}$. We use a precessing disk model to extrapolate the changing
disk inclination over $120$ years and follow the variability in archival
observations. The best-fit disk model precesses over a line of sight
inclination between $\sim25\rm{^{\circ}}$ and $\sim144\rm{^{\circ}}$ with a
precessional period of $\sim80.5$ years. Our precessing models match some of
the observed variability but fail to reproduce all of the historical data
available. Therefore, we propose an ad-hoc model based on our precessing disk
model inspired by recent SPH simulations of similar systems, where the disk
tears due to the tidal influence of a companion star. In this model, a single
disk is slowly tilted to an angle of $30^{\circ}$ from the stellar equator over
$34$ years. Then, the disk is torn by the companion's tidal torque, with the
outer region separating from the innermost disk. The small inner disk returns
to the stellar equator as mass injection remains constant. The outer disk
precesses for $\sim15$ years before gradually dissipating. The process repeats
every $34$ years and reproduces all trends in Pleione's variability.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 20:59:09 GMT""}]","2022-04-13"
"2202.05901","Tom Narock","Thomas Narock, Ayris Narock, Luiz F. G. Dos Santos, Teresa
  Nieves-Chinchilla","Identification of Flux Rope Orientation via Neural Networks",,"https://www.frontiersin.org/articles/10.3389/fspas.2022.838442/abstract",,,"physics.space-ph cs.LG","http://creativecommons.org/licenses/by/4.0/","  Geomagnetic disturbance forecasting is based on the identification of solar
wind structures and accurate determination of their magnetic field orientation.
For nowcasting activities, this is currently a tedious and manual process.
Focusing on the main driver of geomagnetic disturbances, the twisted internal
magnetic field of interplanetary coronal mass ejections (ICMEs), we explore a
convolutional neural network's (CNN) ability to predict the embedded magnetic
flux rope's orientation once it has been identified from in situ solar wind
observations. Our work uses CNNs trained with magnetic field vectors from
analytical flux rope data. The simulated flux ropes span many possible
spacecraft trajectories and flux rope orientations. We train CNNs first with
full duration flux ropes and then again with partial duration flux ropes. The
former provides us with a baseline of how well CNNs can predict flux rope
orientation while the latter provides insights into real-time forecasting by
exploring how accuracy is affected by percentage of flux rope observed. The
process of casting the physics problem as a machine learning problem is
discussed as well as the impacts of different factors on prediction accuracy
such as flux rope fluctuations and different neural network topologies.
Finally, results from evaluating the trained network against observed ICMEs
from Wind during 1995-2015 are presented.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 20:59:26 GMT""},{""version"":""v2"",""created"":""Mon, 21 Feb 2022 12:01:47 GMT""}]","2022-02-22"
"2202.05902","Michael Cretignier","M. Cretignier, X. Dumusque, F. Pepe","Stellar activity correction using PCA decomposition of shells",,"A&A 659, A68 (2022)","10.1051/0004-6361/202142435",,"astro-ph.IM astro-ph.EP astro-ph.SR","http://creativecommons.org/publicdomain/zero/1.0/","  Context. Stellar activity and instrumental signals are the main limitations
to the detection of Earth-like planets using the radial velocity (RV)
technique. Recent studies show that the key to mitigating those perturbing
effects might reside in analysing the spectra themselves, rather than the RV
time series and a few activity proxies. Aims. The goal of this paper is to
demonstrate that we can reach further improvement in RV precision by performing
a principal component analysis (PCA) decomposition of the shell time series,
with the shell as the projection of a spectrum onto the spacenormalised flux
versus flux gradient. Methods. By performing a PCA decomposition of shell time
series, it is possible to obtain a basis of first-order spectral variations
that are not related to Keplerian motion. The time coeffcients associated with
this basis can then be used to correct for non-Dopplerian signatures in RVs.
Results. We applied this new method on the YARARA post-processed spectra time
series of HD10700 and HD128621. On HD10700, we demonstrate, thanks to planetary
signal injections, that this new approach can successfully disentangle real
Dopplerian signals from instrumental systematics. The application of this new
methodology on HD128621 shows that the strong stellar activity signal seen at
the stellar rotational period and one-year aliases becomes insignificant in a
periodogram analysis. The RV root mean square on the five-year data is reduced
from 2.44 m/s down to 1.73 m/s. This new approach allows us to strongly
mitigate stellar activity, however, noise injections tests indicate that rather
high signal-to-noise ratio (S/N>250) is required to correct for the observed
activity signal on HD128621.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 21:02:34 GMT""}]","2022-03-14"
"2202.05903","Travis Whetsell","Leisha DeHart-Davis, Nicole Humphrey, Travis A. Whetsell","Can We Talk? An Exploratory Study of Gender and Network Ties in a Local
  Government Setting",,,,,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore the influence of gender and formal organizational status on the
formation of discussion ties. Network data, gathered through surveying
employees from a municipal organization in the United States, garnered a 92%
response rate (n=143). Results of exponential random graph modeling indicate
women supervisors are more likely to send discussion ties, while women in
general are more likely to receive discussion ties. These exploratory results
suggest women may be perceived as more approachable for work discussions, but
not as supervisors. Finally, the results identified a consistent homophily
effect of gender in the discussion network.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 21:03:13 GMT""},{""version"":""v2"",""created"":""Thu, 20 Oct 2022 14:41:32 GMT""}]","2022-10-21"
"2202.05904","Stephan Stolz","Stephan Stolz","Positive scalar curvature -- constructions and obstructions","34 pages, to appear in volume ""Perspectives in Scalar Curvature""
  edited by Misha Gromov and Blaine Lawson",,,,"math.DG math.AT","http://creativecommons.org/licenses/by/4.0/","  This is a survey of the current state of the question ""Which closed connected
manifolds of dimension $n\ge 5$ admit Riemannian metrics whose scalar curvature
function is everywhere positive?"" The introduction gives a brief overview of
these results, while the body of the paper discusses the methods used in the
proofs of these results. We mention the two flavors of topological obstructions
to the existence of \pscm s: one is a consequence of the Weizenb\""ock formula
for the Dirac operator, the other is obtained by considering stable minimal
hypersurfaces. We talk about geometric constructions of \pscm s (the
surgery/bordism theorem), which shows that the answer to the question above
depends only the bordism class of the manifold in a suitable bordism group. Via
the Pontryagin-Thom construction this can be translated into stable homotopy
theory, and solved completely in some cases, in particular for simply connected
manifolds, or manifolds with very special fundamental groups. The last section
discusses some open questions.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 21:06:42 GMT""}]","2022-02-15"
"2202.05905","Yifeng Mao","Yifeng Mao, Mark A. Hoefer","Experimental investigations of linear and nonlinear periodic traveling
  waves in a viscous fluid conduit",,,"10.1017/jfm.2022.993",,"physics.flu-dyn nlin.PS","http://creativecommons.org/licenses/by/4.0/","  Conduits generated by the buoyant dynamics between two miscible, Stokes
fluids with high viscosity contrast exhibit rich nonlinear wave dynamics.
However, little is known about the fundamental wave dispersion properties of
the medium. In the present work, a pump is used to inject a time-periodic flow
that results in the excitation of propagating small and large amplitude
periodic traveling waves along the conduit interface. This wavemaker problem is
used as a means to measure the linear and nonlinear dispersion relations and
corresponding periodic traveling wave profiles. Measurements are favorably
compared with predictions from a fully nonlinear, long-wave model (the conduit
equation) and the analytically computed linear dispersion relation for
two-Stokes flow. A critical frequency is observed, marking the threshold
between propagating and non-propagating (spatially decaying) waves.
Measurements of wave profiles and the wavenumber-frequency dispersion relation
quantitatively agree with wave solutions of the conduit equation. An upshift
from the conduit equation's predicted critical frequency is observed and is
hypothesized to be explained by incorporating a weak recirculating flow into
the full two-Stokes flow model which we observe to be operable in the
experiment. When the boundary condition corresponds to the temporal profile of
a nonlinear periodic traveling wave solution of the conduit equation, weakly
nonlinear and strongly nonlinear, cnoidal-type waves are observed that
quantitatively agree with the conduit nonlinear dispersion relation and wave
profiles. This wavemaker problem is an important precursor to the experimental
investigation of more general boundary value problems in viscous fluid conduit
nonlinear wave dynamics.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 21:09:18 GMT""}]","2023-01-18"
"2202.05906","Boyuan Chen","Jiawen Xiong, Yong Shi, Boyuan Chen, Filipe R. Cogo, Zhen Ming (Jack)
  Jiang","Towards Build Verifiability for Java-based Systems",,,"10.1145/3510457.3513050",,"cs.SE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Build verifiability refers to the property that the build of a software
system can be verified by independent third parties and it is crucial for the
trustworthiness of a software system. Various efforts towards build
verifiability have been made to C/C++-based systems, yet the techniques for
Java-based systems are not systematic and are often specific to a particular
build tool (e.g., Maven). In this study, we present a systematic approach
towards build verifiability on Java-based systems. Our approach consists of
three parts: a unified build process, a tool that dynamically controls
non-determinism during the build process, and another tool that eliminates
non-equivalences by post-processing the build artifacts. We apply our approach
on 46 unverified open source projects from Reproducible Central and 13 open
source projects that are widely used by Huawei commercial products. As a
result, 91% of the unverified Reproducible Central projects and 100% of the
commercially adopted OSS projects are successfully verified with our approach.
In addition, based on our experience in analyzing thousands of builds for both
commercial and open source Java-based systems, we present 14 patterns that
introduce non-equivalences in generated build artifacts and their respective
mitigation strategies. Among these patterns, 11 (78%) are unique for Java-based
system, whereas the remaining 3 (22%) are common with C/C++-based systems. The
approach and the findings of this paper are useful for both practitioners and
researchers who are interested in build verifiability.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 21:13:08 GMT""}]","2022-02-15"
"2202.05907","Antonio Blanca","Antonio Blanca and Sarah Cannon and Will Perkins","Fast and perfect sampling of subgraphs and polymer systems",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give an efficient perfect sampling algorithm for weighted, connected
induced subgraphs (or graphlets) of rooted, bounded degree graphs. Our
algorithm utilizes a vertex-percolation process with a carefully chosen
rejection filter and works under a percolation subcriticality condition. We
show that this condition is optimal in the sense that the task of
(approximately) sampling weighted rooted graphlets becomes impossible in finite
expected time for infinite graphs and intractable for finite graphs when the
condition does not hold. We apply our sampling algorithm as a subroutine to
give near linear-time perfect sampling algorithms for polymer models and
weighted non-rooted graphlets in finite graphs, two widely studied yet very
different problems. This new perfect sampling algorithm for polymer models
gives improved sampling algorithms for spin systems at low temperatures on
expander graphs and unbalanced bipartite graphs, among other applications.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 21:13:40 GMT""},{""version"":""v2"",""created"":""Wed, 1 Jun 2022 01:37:41 GMT""}]","2022-06-02"
"2202.05908","Qiang Hu","Qiang Hu, Yuchen Liu, Yan Yan, Miao Liu, Jun Zheng, and Douglas M.
  Blough","Towards the Maximum Traffic Demand and Throughput Supported by
  Relay-Assisted mmWave Backhaul Networks",,,,,"cs.NI cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper investigates the throughput performance issue of the
relay-assisted mmWave backhaul network. The maximum traffic demand of
small-cell base stations (BSs) and the maximum throughput at the macro-cell BS
have been found in a tree-style backhaul network through linear programming
under different network settings, which concern both the number of radio chains
available on BSs and the interference relationship between logical links in the
backhaul network. A novel interference model for the relay-assisted mmWave
backhaul network in the dense urban environment is proposed, which demonstrates
the limited interference footprint of mmWave directional communications.
Moreover, a scheduling algorithm is developed to find the optimal scheduling
for tree-style mmWave backhaul networks. Extensive numerical analysis and
simulations are conducted to show and validate the network throughput
performance and the scheduling algorithm.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 21:22:49 GMT""},{""version"":""v2"",""created"":""Tue, 22 Feb 2022 16:54:50 GMT""}]","2022-02-23"
"2202.05909","Matthew Clement","Matthew S. Clement, Elisa V. Quintana, Billy L. Quarles","Habitable planet formation around low-mass stars: Rapid accretion, rapid
  debris removal and the essential contribution of external giants","19 pages, 9 figures, 3 tables, accepted for publication in ApJ",,"10.3847/1538-4357/ac549e",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years a paradigm shift has occurred in exoplanet science, wherein
low-mass stars are increasingly viewed as a foundational pillar of the search
for potentially habitable worlds in the solar neighborhood. However, the
formation processes of this rapidly accumulating sample of planet systems are
still poorly understood. Moreover, it is unclear whether tenuous primordial
atmospheres around these Earth-analogs could have survived the intense epoch of
heightened stellar activity that is typical for low-mass stars. We present new
simulations of in-situ planet formation across the M-dwarf mass spectrum, and
derive leftover debris populations of small bodies that might source delayed
volatile delivery. We then follow the evolution of this debris with
high-resolution models of real systems of habitable zone planets around
low-mass stars such as TRAPPIST-1, Proxima Centauri and TOI-700. While debris
in the radial vicinity of the habitable zone planets is removed rapidly, thus
making delayed volatile delivery highly unlikely, we find that material
ubiquitously scattered into an exo-asteroid belt region during the planet
formation process represents a potentially lucrative reservoir of icy small
bodies. Thus, the presence of external ~Neptune-Saturn mass planets capable of
dynamically perturbing these asteroids would be a sign that habitable zone
worlds around low-mass stars might have avoided complete desiccation. However,
we also find that such giant planets significantly limit the efficiency of
asteroidal implantation during the planet formation process. In the coming
decade, long-baseline radial velocity studies and Roman Space Telescope
microlensing observations will undoubtedly further constrain this process.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 21:23:46 GMT""}]","2022-04-06"
"2202.05910","Oren Katzir","Oren Katzir, Vicky Perepelook, Dani Lischinski and Daniel Cohen-Or","Multi-level Latent Space Structuring for Generative Control",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Truncation is widely used in generative models for improving the quality of
the generated samples, at the expense of reducing their diversity. We propose
to leverage the StyleGAN generative architecture to devise a new truncation
technique, based on a decomposition of the latent space into clusters, enabling
customized truncation to be performed at multiple semantic levels. We do so by
learning to re-generate W-space, the extended intermediate latent space of
StyleGAN, using a learnable mixture of Gaussians, while simultaneously training
a classifier to identify, for each latent vector, the cluster that it belongs
to. The resulting truncation scheme is more faithful to the original
untruncated samples and allows a better trade-off between quality and
diversity. We compare our method to other truncation approaches for StyleGAN,
both qualitatively and quantitatively.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 21:26:17 GMT""}]","2022-02-15"
"2202.05911","Anil Yesilkaya","Anil Yesilkaya and Harald Haas","Channel Modelling and Error Performance Investigation for Reading Lights
  Based In-flight LiFi",,,"10.1109/TVT.2022.3148796",,"cs.IT eess.SP math.IT","http://creativecommons.org/licenses/by/4.0/","  The new generation of communication technologies are constantly being pushed
to meet a diverse range of user requirements such as high data rate, low power
consumption, very low latency, very high reliability and broad availability. To
address all these demands, 5G radio access technologies have been extended into
a wide range of new services. However, there are still only a limited number of
applications for RF based wireless communications inside aircraft cabins that
comply with the 5G vision. Potential interference and safety issues in on-board
wireless communications pose significant deployment challenges. By transforming
each reading light into an optical wireless AP, LiFi, could provide seamless
on-board connectivity in dense cabin environments without RF interference.
Furthermore, the utilization of available reading lights allows for a
relatively simple, cost-effective deployment with the high energy and spectral
efficiency. To successfully implement the aeronautical cabin LiFi applications,
comprehensive optical channel characterization is required. In this paper, we
propose a novel MCRT channel modelling technique to capture the details of
in-flight LiFi links. Accordingly, a realistic channel simulator, which takes
the cabin models, interior elements and measurement based optical source,
receiver, surface material characteristics into account is developed. The
effect of the operation wavelength, cabin model accuracy and user terminal
mobility on the optical channel conditions is also investigated. As a final
step, the on-board DCO-OFDM performance is evaluated by using obtained
in-flight LiFi channels. Numerical results show that the location of a mobile
terminal and accurate aircraft cabin modelling yield as much as 12 and 2 dB
performance difference, respectively.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 21:35:53 GMT""}]","2022-02-15"
"2202.05912","Vijay Ravi","Vijay Ravi, Jinhan Wang, Jonathan Flint, Abeer Alwan","FrAUG: A Frame Rate Based Data Augmentation Method for Depression
  Detection from Speech Signals","Accepted to ICASSP 2022. copyright 2022 IEEE. Personal use of this
  material is permitted",,,,"eess.AS eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, a data augmentation method is proposed for depression
detection from speech signals. Samples for data augmentation were created by
changing the frame-width and the frame-shift parameters during the feature
extraction process. Unlike other data augmentation methods (such as VTLP, pitch
perturbation, or speed perturbation), the proposed method does not explicitly
change acoustic parameters but rather the time-frequency resolution of
frame-level features. The proposed method was evaluated using two different
datasets, models, and input acoustic features. For the DAIC-WOZ (English)
dataset when using the DepAudioNet model and mel-Spectrograms as input, the
proposed method resulted in an improvement of 5.97% (validation) and 25.13%
(test) when compared to the baseline. The improvements for the CONVERGE
(Mandarin) dataset when using the x-vector embeddings with CNN as the backend
and MFCCs as input features were 9.32% (validation) and 12.99% (test). Baseline
systems do not incorporate any data augmentation. Further, the proposed method
outperformed commonly used data-augmentation methods such as noise
augmentation, VTLP, Speed, and Pitch Perturbation. All improvements were
statistically significant.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 21:37:22 GMT""}]","2022-02-15"
"2202.05913","Yuhao Li","Xi Chen, Yuhao Li","Improved Upper Bounds for Finding Tarski Fixed Points","To appear in EC 2022",,,,"cs.GT cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the query complexity of finding a Tarski fixed point over the
$k$-dimensional grid $\{1,\ldots,n\}^k$. Improving on the previous best upper
bound of $\smash{O(\log^{\lceil 2k/3\rceil} n)}$ [FPS20], we give a new
algorithm with query complexity $\smash{O(\log^{\lceil (k+1)/2\rceil} n)}$.
This is based on a novel decomposition theorem about a weaker variant of the
Tarski fixed point problem, where the input consists of a monotone function
$f:[n]^k\rightarrow [n]^k$ and a monotone sign function $b:[n]^k\rightarrow
\{-1,0,1\}$ and the goal is to find an $x\in [n]^k$ that satisfies $either$
$f(x)\preceq x$ and $b(x)\le 0$ $or$ $f(x)\succeq x$ and $b(x)\ge 0$.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 21:42:35 GMT""},{""version"":""v2"",""created"":""Mon, 23 May 2022 03:53:18 GMT""}]","2022-05-24"
"2202.05914","Li Guo","Huhu Zhang, Xing Gao and Li Guo","Operator identities on Lie algebras, rewriting systems and
  Gr\""obner-Shirshov bases","29 pages. arXiv admin note: substantial text overlap with
  arXiv:2108.11823; text overlap with arXiv:2103.13046 by other authors",,,,"math.QA math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the pivotal role played by linear operators, many years ago Rota
proposed to determine algebraic operator identities satisfied by linear
operators on associative algebras, later called Rota's program on algebraic
operators. Recent progresses on this program have been achieved in the contexts
of operated algebra, rewriting systems and Groebner-Shirshov bases. These
developments also suggest that Rota's insight can be applied to determine
operator identities on Lie algebras, and thus to put the various linear
operators on Lie algebras in a uniform perspective.
  This paper carries out this approach, utilizing operated polynomial Lie
algebras spanned by non-associative Lyndon-Shirshov bracketed words. The Lie
algebra analog of Rota's program was formulated in terms convergent rewriting
systems and equivalently in terms of Groebner-Shirshov bases. This Lie algebra
analog is shown to be compatible with Rota's program for associative algebras.
As applications, a classification of differential type operators and
Rota-Baxter operators are presented.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 21:48:01 GMT""}]","2022-02-17"
"2202.05915","Joshua Thompson","Josh Thompson, Davin Hemmila","Collapsing Maps and Quasi-Isometries",,,,,"math.MG math.GT","http://creativecommons.org/licenses/by/4.0/","  We introduce a generalization of the b-metric we call a (b,c)-metric. We show
that if $X$ is a $(b,c)$-metric space and $\psi: X \longrightarrow Y$ is a
quasi-isometry then $Y$ is $(b,c)$-metrizable. We also define a particular kind
of collapsing map that can be applied to an arbitrary $(b,c)$-metric space. We
define a distance function on the image of this collapsing map and with this
prove that the collapsing map is a quasi-isometry.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 21:52:03 GMT""}]","2022-02-15"
"2202.05916","Lenny Fukshansky","Maxwell Forst and Lenny Fukshansky","On zeros of multilinear polynomials","15 pages; to appear in Journal of Number Theory",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider multivariable polynomials over a fixed number field, linear in
some of the variables. For a system of such polynomials satisfying certain
technical conditions we prove the existence of search bounds for simultaneous
zeros with respect to height. For a single such polynomial, we prove the
existence of search bounds with respect to height for zeros lying outside of a
prescribed algebraic set. We also obtain search bounds in the case of
homogeneous multilinear polynomials, which are related to a so-called ""sparse""
version of Siegel's lemma. Among the tools we develop are height inequalities
that are of some independent interest.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 21:57:27 GMT""},{""version"":""v2"",""created"":""Tue, 9 Aug 2022 21:51:56 GMT""},{""version"":""v3"",""created"":""Fri, 11 Nov 2022 17:25:20 GMT""}]","2022-11-14"
"2202.05917","Delaram Kahrobaei","Delaram Kahrobaei, Ram\'on Flores, Marialaura Noce","Group-based Cryptography in the Quantum Era","To appear in the Notices of the American Mathematical Society",,,,"cs.CR math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this expository article we present an overview of the current
state-of-the-art in post-quantum group-based cryptography. We describe several
families of groups that have been proposed as platforms, with special emphasis
in polycyclic groups and graph groups, dealing in particular with their
algorithmic properties and cryptographic applications. We then, describe some
applications of combinatorial algebra in fully homomorphic encryption. In the
end we discussing several open problems in this direction.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 22:01:45 GMT""},{""version"":""v2"",""created"":""Sat, 19 Feb 2022 17:22:40 GMT""},{""version"":""v3"",""created"":""Thu, 24 Feb 2022 15:01:28 GMT""},{""version"":""v4"",""created"":""Tue, 17 Jan 2023 11:52:12 GMT""}]","2023-01-18"
"2202.05918","Stefano Burrello","S. Burrello, S. Calabrese, F. Cappuzzello, D. Carbone, M. Cavallaro,
  M. Colonna, J. A. Lay, H. Lenske, C. Agodi, J. L. Ferreira, S. Firat, A.
  Hacisalihoglu, L. La Fauci, A. Spatafora, L. Acosta, J. I. Bellone, T.
  Borello-Lewin, I. Boztosun, G. A. Brischetto, D. Calvo, E. R.
  Ch\'avez-Lomel\'i, I. Ciraldo, M. Cutuli, F. Delaunay, P. Finocchiaro, M.
  Fisichella, A. Foti, F. Iazzi, G. Lanzalone, R. Linares, J. Lubian, M.
  Moralles, J. R. B. Oliveira, A. Pakou, L. Pandola, H. Petrascu, F. Pinna, G.
  Russo, O. Sgouros, S. O. Solakci, V. Soukeras, G. Souliotis, D. Torresi, S.
  Tudisco, A. Yildirin and V. A. B. Zagatto","Multi-channel experimental and theoretical constraints for the
  $^{116}$Cd($^{20}$Ne,$^{20}$F)$^{116}$In charge exchange reaction at 306 MeV","21 pages, 11 figures",,"10.1103/PhysRevC.105.024616",,"nucl-th nucl-ex","http://creativecommons.org/licenses/by/4.0/","  Charge exchange (CE) reactions offer a major opportunity to excite nuclear
isovector modes, providing clues about the nuclear interaction in the medium.
Moreover, double charge exchange (DCE) reactions are proving to be a tempting
tool to access nuclear transition matrix elements (NME) related to double
beta-decay processes. Through a multi-channel experimental analysis and a
consistent theoretical approach of the $^{116}$Cd($^{20}$Ne,$^{20}$F)$^{116}$In
single charge exchange (SCE) reaction at 306 MeV, we aim at disentangling from
the experimental cross section the contribution of the competing mechanisms,
associated with second or higher order sequential transfer and inelastic
processes. We measured excitation energy spectra and absolute cross sections
for elastic + inelastic, one-proton transfer and SCE channels, using the MAGNEX
large acceptance magnetic spectrometer to detect the ejectiles. For the first
two channels, we also extracted the experimental cross section angular
distributions. The experimental data are compared with theoretical predictions
obtained by performing two-step distorted wave Born approximation and coupled
reaction channel calculations. We employ spectroscopic amplitudes for
single-particle transitions derived within a large-scale shell model approach
and different optical potentials for modeling the initial and the final state
interactions. The present study significantly mitigates the possible model
dependence existing in the description of these complex reaction mechanisms,
thanks to the reproduction of several channels at once. In particular, our work
demonstrates that the two-step transfer mechanisms produce a non negligible
contribution to the total cross section of the
$^{116}$Cd($^{20}$Ne,$^{20}$F)$^{116}$In reaction channel, although a relevant
fraction is still missing, being ascribable to the direct SCE mechanism, which
is not addressed here.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 22:05:26 GMT""}]","2022-02-25"
"2202.05919","Christian Fonseca-Mora","C. A. Fonseca-Mora","Almost Sure Uniform Convergence of Stochastic Processes in the Dual of a
  Nuclear Space",,"J Theor Probab 36, 1-26 (2023)","10.1007/s10959-023-01243-y",,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\Phi$ be a nuclear space and let $\Phi'$ denote its strong dual. In this
paper we introduce sufficient conditions for the almost surely uniform
convergence on bounded intervals of time for a sequence of $\Phi'$-valued
processes having continuous (respectively c\`{a}dl\`{a}g) paths. The main
result is formulated first in the general setting of cylindrical processes but
later specialized to other situations of interest. In particular, we establish
conditions for the convergence to occur in a Hilbert space continuously
embedded in $\Phi'$. Furthermore, in the context of the dual of an
ultrabornological nuclear space (like spaces of smooth functions and
distributions) we also include applications to the convergence of a series of
independent c\`{a}dl\`{a}g process and to the convergence of solutions to
linear evolution equations driven by L\'{e}vy noise.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 22:06:36 GMT""}]","2023-03-31"
"2202.05920","Omar Montasser","Avrim Blum, Omar Montasser, Greg Shakhnarovich, Hongyang Zhang","Boosting Barely Robust Learners: A New Perspective on Adversarial
  Robustness",,,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  We present an oracle-efficient algorithm for boosting the adversarial
robustness of barely robust learners. Barely robust learning algorithms learn
predictors that are adversarially robust only on a small fraction $\beta \ll 1$
of the data distribution. Our proposed notion of barely robust learning
requires robustness with respect to a ""larger"" perturbation set; which we show
is necessary for strongly robust learning, and that weaker relaxations are not
sufficient for strongly robust learning. Our results reveal a qualitative and
quantitative equivalence between two seemingly unrelated problems: strongly
robust learning and barely robust learning.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 22:07:36 GMT""}]","2022-02-15"
"2202.05921","Tian An Wong","A. Suki Dasher, A. Hermida, and Tian An Wong","The Three Gap Theorem and Periodic Functions",,"Integers 22 (2022), Paper No. A21, 9 pp",,,"math.CO math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Three Gap Theorem, also known as the Steinhaus Conjecture, is a classical
result on the combinatorics of the fractional part function, and has since been
generalized in many ways. In this paper, we pose a new problem related to these
results: for which other periodic functions does an analogue of the Three Gap
Theorem hold? We prove analogous results for certain classes of
piecewise-linear periodic functions and demonstrate the existence of functions
for which no bound exists on the number of gap lengths.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 22:32:42 GMT""}]","2022-02-15"
"2202.05922","Roy Velich","Roy Velich, Ron Kimmel","Deep Signatures -- Learning Invariants of Planar Curves",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  We propose a learning paradigm for numerical approximation of differential
invariants of planar curves. Deep neural-networks' (DNNs) universal
approximation properties are utilized to estimate geometric measures. The
proposed framework is shown to be a preferable alternative to axiomatic
constructions. Specifically, we show that DNNs can learn to overcome
instabilities and sampling artifacts and produce numerically-stable signatures
for curves subject to a given group of transformations in the plane. We compare
the proposed schemes to alternative state-of-the-art axiomatic constructions of
group invariant arc-lengths and curvatures.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 22:34:15 GMT""}]","2022-02-15"
"2202.05923","Robert Zellem","Robert T. Zellem, Bijan Nemati, Guillermo Gonzalez, Marie Ygouf,
  Vanessa P. Bailey, Eric J. Cady, M. Mark Colavita, Sergi R. Hildebrandt, Erin
  R. Maier, Bertrand Mennesson, Lindsey Payne, Neil Zimmerman, Ruslan Belikov,
  Robert J. De Rosa, John Debes, Ewan S. Douglas, Julien Girard, Tyler Groff,
  Jeremy Kasdin, Patrick J. Lowrance, Bruce Macintosh, Daniel Ryan, Carey
  Weisberg","Nancy Grace Roman Space Telescope Coronagraph Instrument Observation
  Calibration Plan","Posting for public information on the current status of the Roman
  Coronagraph Observation Calibration Plan; latest updates as of July 29, 2022",,,,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  NASA's next flagship mission, the Nancy Grace Roman Space Telescope, is a
2.4-meter observatory set to launch no later than May 2027. Roman features two
instruments: the Wide Field Imager and the Coronagraph Instrument. Roman's
Coronagraph is a Technology Demonstration that will push the current
capabilities of direct imaging to smaller contrast ratios ($\sim$10$^{-9}$) and
inner-working angles (3~$\lambda$/D). In order to achieve this high precision,
Roman Coronagraph data must be calibrated to remove as many potential sources
of error as possible. Here we present a detailed overview of the Nancy Grace
Roman Space Telescope Coronagraph Instrument Observation Calibration Plan
including identifying potential sources of error and how they will be mitigated
via on-sky calibrations.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 22:38:03 GMT""},{""version"":""v2"",""created"":""Thu, 17 Feb 2022 17:23:41 GMT""},{""version"":""v3"",""created"":""Fri, 29 Jul 2022 20:48:54 GMT""}]","2022-08-02"
"2202.05924","Jaime Sevilla","Jaime Sevilla, Lennart Heim, Anson Ho, Tamay Besiroglu, Marius
  Hobbhahn and Pablo Villalobos","Compute Trends Across Three Eras of Machine Learning",,,,,"cs.LG cs.AI cs.CY","http://creativecommons.org/licenses/by/4.0/","  Compute, data, and algorithmic advances are the three fundamental factors
that guide the progress of modern Machine Learning (ML). In this paper we study
trends in the most readily quantified factor - compute. We show that before
2010 training compute grew in line with Moore's law, doubling roughly every 20
months. Since the advent of Deep Learning in the early 2010s, the scaling of
training compute has accelerated, doubling approximately every 6 months. In
late 2015, a new trend emerged as firms developed large-scale ML models with 10
to 100-fold larger requirements in training compute. Based on these
observations we split the history of compute in ML into three eras: the Pre
Deep Learning Era, the Deep Learning Era and the Large-Scale Era. Overall, our
work highlights the fast-growing compute requirements for training advanced ML
systems.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 22:42:47 GMT""},{""version"":""v2"",""created"":""Wed, 9 Mar 2022 19:30:21 GMT""}]","2022-03-11"
"2202.05925","Julien Gaboriaud","Isma\""el Bussi\`ere, Julien Gaboriaud, Luc Vinet and Alexei Zhedanov","Bispectrality and biorthogonality of the rational functions of $q$-Hahn
  type","19 pages, updated version to match the one accepted for publication",,,,"math.CA math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  We introduce families of rational functions that are biorthogonal with
respect to the $q$-hypergeometric distribution. A triplet of $q$-difference
operators $X$, $Y$, $Z$ is shown to play a role analogous to the pair of
bispectral operators of orthogonal polynomials. The recurrence relation and
difference equation take the form of generalized eigenvalue problems involving
the three operators. The algebra generated by $X$, $Y$, $Z$ is akin to the
algebras of Askey--Wilson type in the case of orthogonal polynomials. The
actions of these operators in three different basis are presented. Connections
with Wilson's ${}_{10}\phi_9$ biorthogonal rational functions are also
discussed.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 22:45:00 GMT""},{""version"":""v2"",""created"":""Mon, 30 May 2022 05:52:46 GMT""}]","2022-05-31"
"2202.05926","Theo Torres","Theo Torres, Max Lloyd, Sam R. Dolan and Silke Weinfurtner","Wave focusing by submerged islands and gravitational analogues","33 pages, 11 figures",,,,"physics.flu-dyn gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study water waves propagating over a smooth obstacle in a fluid of varying
depth, motivated by the observation that submerged islands in the ocean act as
effective lenses that increase the amplitude and destructive power of tsunami
waves near focal points. We show that islands of substantial height (compared
to the water depth) lead to strong focusing in their immediate vicinity, and
generate caustics of either cusp or butterfly type. We highlight similarities
and differences with focusing of (high-frequency) gravitational waves by a
neutron star. In the linear regime, the comparison is made precise through an
effective-spacetime description of the island-fluid system. This description is
then put to practical use: we identify caustics by solving the Raychaudhuri
equation (a transport equation) along rays of the effective metric. Next, the
island-fluid scattering processes are examined in detail (i.e.~deflection
angle, phase shifts, scattering amplitudes) using numerical simulations and
analytical techniques, including the eikonal approximation and its
generalisation in the form of the Gaussian beam approximation. We show that the
techniques capture the key features of the simulations. Finally, we extend the
eikonal approximation to the dispersive regime, demonstrating that the
essential features are robust in dispersive settings. This paves the way for
future exploration in a controlled laboratory set-up.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 22:50:42 GMT""}]","2022-02-24"
"2202.05927","Toru Fujii Dr","Toru Fujii, Koshi Komuro, Yosuke Okudaira, Ryo Narita and Masayasu
  Sawada","Energy landscape transformation of Ising problem with invariant
  eigenvalues for quantum annealing",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum annealing tends to be more difficult as the energy landscape of the
problem becomes complicated with many local minima. We have found a
transformation for changing the energy landscape that swaps the eigenvalues and
paired states without changing the eigenvalues of the instance at all. The
transformation is basically a partial recombination of the two-spin interaction
coefficient Jij and the longitudinal magnetic field interaction coefficient hi.
The Hamming distance corresponding to a barrier between the states changes by
the transformation, which in turn affects the ground state convergence. In the
quantum annealing simulation results of a small number of spin instances, the
annealing time was shortened by several orders of magnitude by applying the
transformation. In addition, we also obtained a result using a D-Wave quantum
annealer, which also showed a big improvement in the ground state convergence.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 22:57:56 GMT""}]","2022-02-15"
"2202.05928","Spencer Frei","Spencer Frei, Niladri S. Chatterji, Peter L. Bartlett","Benign Overfitting without Linearity: Neural Network Classifiers Trained
  by Gradient Descent for Noisy Linear Data","39 pages; updated proof of loss ratio bound",,,,"cs.LG math.ST stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Benign overfitting, the phenomenon where interpolating models generalize well
in the presence of noisy data, was first observed in neural network models
trained with gradient descent. To better understand this empirical observation,
we consider the generalization error of two-layer neural networks trained to
interpolation by gradient descent on the logistic loss following random
initialization. We assume the data comes from well-separated class-conditional
log-concave distributions and allow for a constant fraction of the training
labels to be corrupted by an adversary. We show that in this setting, neural
networks exhibit benign overfitting: they can be driven to zero training error,
perfectly fitting any noisy training labels, and simultaneously achieve minimax
optimal test error. In contrast to previous work on benign overfitting that
require linear or kernel-based predictors, our analysis holds in a setting
where both the model and learning dynamics are fundamentally nonlinear.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 23:04:00 GMT""},{""version"":""v2"",""created"":""Tue, 22 Mar 2022 15:52:05 GMT""},{""version"":""v3"",""created"":""Tue, 20 Sep 2022 11:06:01 GMT""}]","2022-09-21"
"2202.05929","Guilherme Bergman De Souza","Guilherme B. Souza, Roberto G. Pacheco, Rodrigo S. Couto","Improving Image-recognition Edge Caches with a Generative Adversarial
  Network","to appear in Proc. IEEE International Conference on Communications
  (ICC) 2022",,,,"cs.NI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Image recognition is an essential task in several mobile applications. For
instance, a smartphone can process a landmark photo to gather more information
about its location. If the device does not have enough computational resources
available, it offloads the processing task to a cloud infrastructure. Although
this approach solves resource shortages, it introduces a communication delay.
Image-recognition caches on the Internet's edge can mitigate this problem.
These caches run on servers close to mobile devices and stores information
about previously recognized images. If the server receives a request with a
photo stored in its cache, it replies to the device, avoiding cloud offloading.
The main challenge for this cache is to verify if the received image matches a
stored one. Furthermore, for outdoor photos, it is difficult to compare them if
one was taken in the daytime and the other at nighttime. In that case, the
cache might wrongly infer that they refer to different places, offloading the
processing to the cloud. This work shows that a well-known generative
adversarial network, called ToDayGAN, can solve this problem by generating
daytime images using nighttime ones. We can thus use this translation to
populate a cache with synthetic photos that can help image matching. We show
that our solution reduces cloud offloading and, therefore, the application's
latency.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 23:12:05 GMT""}]","2022-02-15"
"2202.05930","Manoj Acharya","Manoj Acharya, Anirban Roy, Kaushik Koneripalli, Susmit Jha,
  Christopher Kanan, Ajay Divakaran","Detecting out-of-context objects using contextual cues",,"IJCAI-ECAI 2022",,,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  This paper presents an approach to detect out-of-context (OOC) objects in an
image. Given an image with a set of objects, our goal is to determine if an
object is inconsistent with the scene context and detect the OOC object with a
bounding box. In this work, we consider commonly explored contextual relations
such as co-occurrence relations, the relative size of an object with respect to
other objects, and the position of the object in the scene. We posit that
contextual cues are useful to determine object labels for in-context objects
and inconsistent context cues are detrimental to determining object labels for
out-of-context objects. To realize this hypothesis, we propose a graph
contextual reasoning network (GCRN) to detect OOC objects. GCRN consists of two
separate graphs to predict object labels based on the contextual cues in the
image: 1) a representation graph to learn object features based on the
neighboring objects and 2) a context graph to explicitly capture contextual
cues from the neighboring objects. GCRN explicitly captures the contextual cues
to improve the detection of in-context objects and identify objects that
violate contextual relations. In order to evaluate our approach, we create a
large-scale dataset by adding OOC object instances to the COCO images. We also
evaluate on recent OCD benchmark. Our results show that GCRN outperforms
competitive baselines in detecting OOC objects and correctly detecting
in-context objects.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 23:15:01 GMT""}]","2022-05-09"
"2202.05931","Ruiheng Song","Ruiheng Song, Thomas M. Henderson, Gustavo E. Scuseria","A Power Series Approximation in Symmetry Projected Coupled Cluster
  Theory",,,"10.1063/5.0080165",,"cond-mat.str-el physics.chem-ph","http://creativecommons.org/publicdomain/zero/1.0/","  Projected Hartree-Fock theory provides an accurate description of many kinds
of strong correlations but does not properly describe weakly-correlated
systems. On the other hand, single-reference methods such as configuration
interaction or coupled cluster theory can handle weakly-correlated problems but
cannot properly account for strong correlations. Ideally, we would like to
combine these approaches in a symmetry-projected coupled cluster approach, but
this is far from straightforward. In this work, we provide an alternative
formulation to identify the so-called disentangled cluster operators which
arise when we combine these two methodological strands. Our formulation shows
promising results for model systems and small molecules.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 23:19:12 GMT""}]","2022-04-06"
"2202.05932","Yu Zhang","Yu Zhang, Zhihong Shen, Chieh-Han Wu, Boya Xie, Junheng Hao, Ye-Yi
  Wang, Kuansan Wang, Jiawei Han","Metadata-Induced Contrastive Learning for Zero-Shot Multi-Label Text
  Classification","12 pages; Accepted to WWW 2022",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large-scale multi-label text classification (LMTC) aims to associate a
document with its relevant labels from a large candidate set. Most existing
LMTC approaches rely on massive human-annotated training data, which are often
costly to obtain and suffer from a long-tailed label distribution (i.e., many
labels occur only a few times in the training set). In this paper, we study
LMTC under the zero-shot setting, which does not require any annotated
documents with labels and only relies on label surface names and descriptions.
To train a classifier that calculates the similarity score between a document
and a label, we propose a novel metadata-induced contrastive learning (MICoL)
method. Different from previous text-based contrastive learning techniques,
MICoL exploits document metadata (e.g., authors, venues, and references of
research papers), which are widely available on the Web, to derive similar
document-document pairs. Experimental results on two large-scale datasets show
that: (1) MICoL significantly outperforms strong zero-shot text classification
and contrastive learning baselines; (2) MICoL is on par with the
state-of-the-art supervised metadata-aware LMTC method trained on 10K-200K
labeled documents; and (3) MICoL tends to predict more infrequent labels than
supervised methods, thus alleviates the deteriorated performance on long-tailed
labels.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 23:22:17 GMT""},{""version"":""v2"",""created"":""Thu, 24 Mar 2022 22:34:41 GMT""}]","2022-03-28"
"2202.05933","Corentin Ferry","Corentin Ferry and Tomofumi Yuki and Steven Derrien and Sanjay
  Rajopadhye","Increasing FPGA Accelerators Memory Bandwidth with a Burst-Friendly
  Memory Layout","16 pages; 17 figures",,,,"cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Offloading compute-intensive kernels to hardware accelerators relies on the
large degree of parallelism offered by these platforms. However, the effective
bandwidth of the memory interface often causes a bottleneck, hindering the
accelerator's effective performance. Techniques enabling data reuse, such as
tiling, lower the pressure on memory traffic but still often leave the
accelerators I/O-bound. A further increase in effective bandwidth is possible
by using burst rather than element-wise accesses, provided the data is
contiguous in memory.
  In this paper, we propose a memory allocation technique, and provide a
proof-of-concept source-to-source compiler pass, that enables such burst
transfers by modifying the data layout in external memory. We assess how this
technique pushes up the memory throughput, leaving room for exploiting
additional parallelism, for a minimal logic overhead.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 23:25:07 GMT""},{""version"":""v2"",""created"":""Wed, 23 Feb 2022 23:00:45 GMT""}]","2022-02-25"
"2202.05934","Danila Milanov","Danila V. Milanov","Representation of the gravitational potential of a level ellipsoid by a
  simple layer","12 pages, 4 figures",,"10.1007/s10569-022-10086-4",,"physics.class-ph astro-ph.EP astro-ph.SR gr-qc physics.geo-ph","http://creativecommons.org/licenses/by/4.0/","  A closed-form expression is obtained for the density of a simple layer,
equipotential to an oblate level ellipsoid of revolution in an outer space. The
potential of any level spheroid of positive mass with the inward direction of
attracting force on its surface can be represented in this way. A family of
density functions defined on the whole volume of a level ellipsoid of
revolution is found. Several density examples are considered.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 23:29:23 GMT""}]","2022-06-06"
"2202.05935","Nan Zou","Nan Zou","POT-flavored estimator of Pickands dependence function",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work proposes an estimator with both Peak-Over-Threshold and
Block-Maxima flavors, uses it to estimate the Pickands dependence function of
bivariate time series, and illustrates how it brings down the asymptotic bias
and the overall mean squared error.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 23:30:49 GMT""}]","2022-02-15"
"2202.05936","Elena Accomando","E. Accomando, J. Brannigan, J. Gunn, Y. Huyan and S. Mulligan","Constrained Vector-like quark model with perturbative unitarity","18 pages, 4 figures",,,,"hep-ph","http://creativecommons.org/publicdomain/zero/1.0/","  We propose a Vector-like quark (VLQ) model constrained by the requirement of
perturbative unitarity. In this scenario, the neutral and charged couplings of
the new heavy VLQs to SM quarks and bosons are strictly related. We derive the
corresponding sum rules and display the definite structure of the couplings. We
analyse, qualitatively, the phenomenological consequences of this model in
terms of expected width, production mechanism and decay channels. We show that
the upcoming LHC run 3 could have sensitivity to such particles but the search
strategy should be adapted to cover wide resonances decaying mainly in the
charged channel T(B) -> Wq.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 23:31:37 GMT""}]","2022-02-15"
"2202.05937","Romain Tirole","Romain Tirole, Emanuele Galiffi, Jakub Dranczewski, Taran Attavar,
  Benjamin Tilmann, Yao-Ting Wang, Paloma A. Huidobro, Andrea Al\'u, John B.
  Pendry, Stefan A. Maier, Stefano Vezzoli, Riccardo Sapienza","Saturable time-varying mirror based on an ENZ material","6 pages, 4 figures Supplemental: 7 pages, 5 figures update:
  resubmitted version following referee feedback - removed red-colored
  sentences",,,,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  We report a switchable time-varying mirror, composed of an ITO-Au stack,
which can be efficiently modulated in time with over a ten-fold increase in
reflectivity, with a change of 0.6. Upon interacting with the time-varying
mirror, the frequency content of a reflected pulse is extended to 31 THz. This
originates from the shortening of the response time of the mirror beyond
saturation, as confirmed by a time-varying model and by further four-wave
mixing experiments. A temporal response unbounded by the pump bandwidth opens
new avenues for spectral manipulation from time-varying systems with impact for
communication networks, optical switching and computing.
  We report a switchable time-varying mirror, composed of an ITO-Au bilayer,
displaying a ten-fold modulation of reflectivity ($\Delta R \approx 0.6$),
which saturates for a driving pump intensity $I_{\mathrm{pump}}\approx
100$~GW/cm$^2$. Upon interacting with the saturated time-varying mirror, the
frequency content of a reflected pulse is extended up to 31 THz, well beyond
the pump spectral content (2.8 THz). We interpret the spectral broadening as a
progressive shortening of the mirror rise time from 110 fs to sub 30 fs with
increasing pump power, which is confirmed by four-wave mixing experiments and
partially captured by a linear time-varying model of the mirror. A temporal
response unbounded by the pump bandwidth opens new avenues for spectral
manipulation from time-varying systems with impact for communication networks,
optical switching and computing.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 23:42:59 GMT""},{""version"":""v2"",""created"":""Wed, 16 Feb 2022 12:56:34 GMT""},{""version"":""v3"",""created"":""Mon, 6 Jun 2022 16:39:09 GMT""},{""version"":""v4"",""created"":""Wed, 22 Jun 2022 11:12:34 GMT""}]","2022-06-23"
"2202.05938","Cl\'ement Quinton","Pierre Bourhis (1), Laurence Duchien (1), J\'er\'emie Dusart (1),
  Emmanuel Lonca (2), Pierre Marquis (2 and 3), Cl\'ement Quinton (1) ((1)
  University of Lille, CNRS, Inria, Centrale Lille, UMR 9189 CRIStAL, (2) Univ.
  Artois, CNRS, UMR 8188 CRIL, (3) Institut Universitaire de France)","Pseudo Polynomial-Time Top-k Algorithms for d-DNNF Circuits",,,,,"cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We are interested in computing $k$ most preferred models of a given d-DNNF
circuit $C$, where the preference relation is based on an algebraic structure
called a monotone, totally ordered, semigroup $(K, \otimes, <)$. In our
setting, every literal in $C$ has a value in $K$ and the value of an assignment
is an element of $K$ obtained by aggregating using $\otimes$ the values of the
corresponding literals. We present an algorithm that computes $k$ models of $C$
among those having the largest values w.r.t. $<$, and show that this algorithm
runs in time polynomial in $k$ and in the size of $C$. We also present a pseudo
polynomial-time algorithm for deriving the top-$k$ values that can be reached,
provided that an additional (but not very demanding) requirement on the
semigroup is satisfied. Under the same assumption, we present a pseudo
polynomial-time algorithm that transforms $C$ into a d-DNNF circuit $C'$
satisfied exactly by the models of $C$ having a value among the top-$k$ ones.
Finally, focusing on the semigroup $(\mathbb{N}, +, <)$, we compare on a large
number of instances the performances of our compilation-based algorithm for
computing $k$ top solutions with those of an algorithm tackling the same
problem, but based on a partial weighted MaxSAT solver.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 23:53:43 GMT""},{""version"":""v2"",""created"":""Thu, 5 May 2022 21:51:53 GMT""}]","2022-05-09"
"2202.05939","Rocio Jauregui","J. E. Alba-Arroyo, S. F. Caballero-Benitez, R. Jauregui","Weber number and the outcome of binary collisions between quantum
  droplets","26pages,13 figures",,,,"physics.atom-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A theoretical analysis of binary collisions of quantum droplets under
feasible experimental conditions is reported. Droplets formed from degenerate
dilute Bose gases made up from binary mixtures of ultra cold atoms are
considered. Reliable expressions for the surface tension of the droplets are
introduced based on a study of low energy excitations of their ground state
within the random phase approximation. Their relevance is evaluated considering
an estimation of the expected excitation energy having in mind the Thouless
variational theorem. The surface tension expressions allow calculating the
Weber number of the droplets involved in the collisions. Several regimes on the
outcomes of the binary frontal collisions that range from the coalescence of
the quantum droplets to their disintegration into smaller droplets are
identified. Atoms losses of the droplets derived from self-evaporation and
three-body scattering are quantified for both homo- and hetero-nuclear
mixtures. Their control is mandatory for the observation of some interesting
effects arising from droplets collisions.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 00:14:04 GMT""}]","2022-02-15"
"2202.05940","Zhengxu Xia","Zhengxu Xia (1), Yajie Zhou (2), Francis Y. Yan (3), Junchen Jiang (1)
  ((1) University of Chicago, (2) Boston University, (3) Microsoft Research)","Automatic Curriculum Generation for Learning Adaptation in Networking","Accepted by SIGCOMM'22",,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As deep reinforcement learning (RL) showcases its strengths in networking and
systems, its pitfalls also come to the public's attention--when trained to
handle a wide range of network workloads and previously unseen deployment
environments, RL policies often manifest suboptimal performance and poor
generalizability.
  To tackle these problems, we present Genet, a new training framework for
learning better RL-based network adaptation algorithms. Genet is built on the
concept of curriculum learning, which has proved effective against similar
issues in other domains where RL is extensively employed. At a high level,
curriculum learning gradually presents more difficult environments to the
training, rather than choosing them randomly, so that the current RL model can
make meaningful progress in training. However, applying curriculum learning in
networking is challenging because it remains unknown how to measure the
""difficulty"" of a network environment.
  Instead of relying on handcrafted heuristics to determine the environment's
difficulty level, our insight is to utilize traditional rule-based (non-RL)
baselines: If the current RL model performs significantly worse in a network
environment than the baselines, then the model's potential to improve when
further trained in this environment is substantial. Therefore, Genet
automatically searches for the environments where the current model falls
significantly behind a traditional baseline scheme and iteratively promotes
these environments as the training progresses. Through evaluating Genet on
three use cases--adaptive video streaming, congestion control, and load
balancing, we show that Genet produces RL policies which outperform both
regularly trained RL policies and traditional baselines in each context, not
only under synthetic workloads but also in real environments.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 00:18:13 GMT""},{""version"":""v2"",""created"":""Thu, 8 Sep 2022 09:31:38 GMT""}]","2022-09-09"
"2202.05941","Zhize Wu","Zhize Wu, Xiaofeng Wang, Tong Xu, Xuebin Yang, Le Zou, Lixiang Xu and
  Thomas Weise","Domain-Invariant Proposals based on a Balanced Domain Classifier for
  Object Detection",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Object recognition from images means to automatically find object(s) of
interest and to return their category and location information. Benefiting from
research on deep learning, like convolutional neural networks~(CNNs) and
generative adversarial networks, the performance in this field has been
improved significantly, especially when training and test data are drawn from
similar distributions. However, mismatching distributions, i.e., domain shifts,
lead to a significant performance drop. In this paper, we build
domain-invariant detectors by learning domain classifiers via adversarial
training. Based on the previous works that align image and instance level
features, we mitigate the domain shift further by introducing a domain
adaptation component at the region level within Faster \mbox{R-CNN}. We embed a
domain classification network in the region proposal network~(RPN) using
adversarial learning. The RPN can now generate accurate region proposals in
different domains by effectively aligning the features between them. To
mitigate the unstable convergence during the adversarial learning, we introduce
a balanced domain classifier as well as a network learning rate adjustment
strategy. We conduct comprehensive experiments using four standard datasets.
The results demonstrate the effectiveness and robustness of our object
detection approach in domain shift scenarios.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 00:21:27 GMT""}]","2022-02-15"
"2202.05942","Dileep V. Reddy","Dileep V. Reddy, Negar Otrooshi, Sae Woo Nam, Richard P. Mirin, and
  Varun B. Verma","Broadband polarization insensitivity and high detection efficiency in
  high-fill-factor superconducting microwire single-photon detectors","18 pages, 13 figures (including supplementary document) Added
  citations in replacement version","APL Photonics 7, 051302 (2022)","10.1063/5.0088007",,"quant-ph physics.ins-det physics.optics","http://creativecommons.org/licenses/by/4.0/","  Single-photon detection via absorption in current-biased nanoscale
superconducting structures has become a preferred technology in quantum optics
and related fields. Single-mode fiber packaged devices have seen new records
set in detection efficiency, timing jitter, recovery times, and largest
sustainable count rates. The popular approaches to decreasing polarization
sensitivity have thus far been limited to introduction of geometrically
symmetric nanowire meanders, such as spirals and fractals, in the active area.
The constraints on bending radii, and by extension, fill factors, in such
designs limits their maximum efficiency. The discovery of single-photon
sensitivity in micrometer-scale superconducting wires enables novel meander
patterns with no effective upper limit on fill factor. This work demonstrates
simultaneous low-polarization sensitivity ($1.02\pm 0.008$) and high detection
efficiency ($> 91.8\%$ with $67\%$ confidence at $2\times10^5$ counts per
second) across a $40$ nm bandwidth centered at 1550 nm in 0.51 $\mu\text{m}$
wide microwire devices made of silicon-rich tungsten silicide, with a $0.91$
fill factor in the active area. These devices boasted efficiencies of
$96.5-96.9\% \pm 0.5\%$ at $1\times10^5$ counts per second for 1550 nm light.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 00:28:58 GMT""},{""version"":""v2"",""created"":""Wed, 2 Mar 2022 23:35:43 GMT""}]","2022-05-17"
"2202.05943","Carl Edwards","Carl Edwards and Heng Ji","Semi-supervised New Event Type Induction and Description via Contrastive
  Loss-Enforced Batch Attention",,,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most event extraction methods have traditionally relied on an annotated set
of event types. However, creating event ontologies and annotating supervised
training data are expensive and time-consuming. Previous work has proposed
semi-supervised approaches which leverage seen (annotated) types to learn how
to automatically discover new event types. State-of-the-art methods, both
semi-supervised or fully unsupervised, use a form of reconstruction loss on
specific tokens in a context. In contrast, we present a novel approach to
semi-supervised new event type induction using a masked contrastive loss, which
learns similarities between event mentions by enforcing an attention mechanism
over the data minibatch. We further disentangle the discovered clusters by
approximating the underlying manifolds in the data, which allows us to increase
normalized mutual information and Fowlkes-Mallows scores by over 20% absolute.
Building on these clustering results, we extend our approach to two new tasks:
predicting the type name of the discovered clusters and linking them to
FrameNet frames.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 00:32:22 GMT""}]","2022-02-15"
"2202.05944","Josephine C. Meyer","Josephine C. Meyer, Gina Passante, Steven J. Pollock, Bethany R.
  Wilcox","The interdisciplinary quantum information classroom: Themes from a
  survey of quantum information science instructors","15 pages, 5 figures. Submitted to Physical Review Physics Education
  Research","Phys Rev Phys Educ Res 18, 010150 (published 30 June 2022)","10.1103/PhysRevPhysEducRes.18.010150",,"physics.ed-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Interdisciplinary introduction to quantum information science (QIS) courses
are proliferating at universities across the US, but the experiences of
instructors in these courses have remained largely unexplored in the
discipline-based education research (DBER) communities. Here, we address this
gap by reporting on the findings of a survey of instructors teaching
introduction to QIS courses at institutions across the US, primarily at the
undergraduate or hybrid undergraduate/graduate level, as well as follow-up
focus interviews with six individual instructors. Key themes from this analysis
include challenges and opportunities associated with the diversity of
instructor and student backgrounds, student difficulties with the mathematical
formalism (especially though not exclusively with linear algebra), and the need
for better textbooks and curricular materials. We also find that while course
topics are ostensibly similar, each course is crafted by its instructor to tell
a different story about QIS and to uniquely balance goals such as accessibility
and academic rigor, such that no canonical introduction to QIS course emerges
from our dataset. We discuss the implications of this finding with regard to
the benefits and risks associated with standardization of curricula as QIS
coursework matures.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 00:37:58 GMT""},{""version"":""v2"",""created"":""Thu, 5 May 2022 22:40:46 GMT""}]","2022-07-04"
"2202.05945","Binglin Zeng","Binglin Zeng, Yuliang Wang, Christian Diddens, Harold J. W. Zandvliet,
  and Detlef Lohse","Droplet dissolution driven by emerging thermal gradients and Marangoni
  flow","15 pages, 6 figures",,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The lifetime $\tau$ of an isothermal and purely diffusively dissolving
droplet in a host liquid scales as $\tau \sim R_0^2$ with its initial radius
$R_0$ [Langmuir, Phys. Rev. 12, 368 (1919)]. For a droplet dissolving due to
natural convection driven by density differences, its lifetime scales as
$\tau\sim R_0^{5/4}$ [Dietrich et al., J. Fluid Mech. 794, 45 (2016)]. In this
paper we experimentally find and theoretically derive yet another droplet
dissolution behavior, resulting in $\tau \sim R_0^4$. It occurs when the
dissolution dynamics is controlled by local heating of the liquid, leading to a
modified solubility and a thermal Marangoni flow around the droplet. The
thermal gradient is achieved by plasmonic heating of a gold nanoparticle
decorated sample surface, on which a sessile water droplet immersed in
water-saturated 1-butanol solution is sitting. The resulting off-wall thermal
Marangoni flow and the temperature dependence of the solubility determine the
droplet dissolution rate, resulting in a shrinkage $R(t) \sim (\tau -t )^{1/4}$
of the droplet radius and thus in $\tau \sim R_0^{4}$.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 00:50:02 GMT""}]","2022-02-15"
"2202.05946","Martino Banchio","Martino Banchio, Giacomo Mantegazza","Adaptive Algorithms and Collusion via Coupling","57 pages, 13 figures",,,,"econ.TH cs.AI cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a theoretical model to study strategic interactions between
adaptive learning algorithms. Applying continuous-time techniques, we uncover
the mechanism responsible for collusion between Artificial Intelligence
algorithms documented by recent experimental evidence. We show that spontaneous
coupling between the algorithms' estimates leads to periodic coordination on
actions that are more profitable than static Nash equilibria. We provide a
sufficient condition under which this coupling is guaranteed to disappear, and
algorithms learn to play undominated strategies. We apply our results to
interpret and complement experimental findings in the literature and to the
design of learning-robust strategy-proof mechanisms. We show that ex-post
feedback provision guarantees robustness to the presence of learning agents. We
fully characterize the optimal learning-robust mechanisms: they are menu
mechanisms.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 00:50:15 GMT""},{""version"":""v2"",""created"":""Sun, 10 Jul 2022 22:34:42 GMT""},{""version"":""v3"",""created"":""Mon, 7 Nov 2022 01:11:57 GMT""}]","2022-11-08"
"2202.05947","Martino Banchio","Martino Banchio, Andrzej Skrzypacz","Artificial Intelligence and Auction Design","30 pages, 11 figures",,,,"econ.TH cs.AI cs.GT","http://creativecommons.org/licenses/by/4.0/","  Motivated by online advertising auctions, we study auction design in repeated
auctions played by simple Artificial Intelligence algorithms (Q-learning). We
find that first-price auctions with no additional feedback lead to
tacit-collusive outcomes (bids lower than values), while second-price auctions
do not. We show that the difference is driven by the incentive in first-price
auctions to outbid opponents by just one bid increment. This facilitates
re-coordination on low bids after a phase of experimentation. We also show that
providing information about lowest bid to win, as introduced by Google at the
time of switch to first-price auctions, increases competitiveness of auctions.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 00:54:40 GMT""}]","2022-02-15"
"2202.05948","Lin He","Ya-Ning Ren, Yu-Chen Zhuang, Qing-Feng Sun, and Lin He","Magnetic field-tunable valley-contrasting pseudomagnetic confinement in
  graphene",,,"10.1103/PhysRevLett.129.076802",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Introducing quantum confinement has uncovered a rich set of interesting
quantum phenomena and allows one to directly probe the physics of confined
(quasi-)particles. In most experiments, however, electrostatic potential is the
only available method to generate the quantum confinement in a continuous
system. Here, we demonstrated experimentally that inhomogeneous pseudomagnetic
fields in strained graphene can introduce exotic quantum confinement of
massless Dirac fermions. The pseudomagnetic fields have opposite directions in
the two distinct valleys of graphene. By tuning real magnetic field, the total
effective magnetic fields in the two valleys are imbalanced. Then, we realized
valley-contrasting spatial confinement, which lifts the valley degeneracy and
results in field-tunable valley-polarized confined states in graphene. Our
results provide a new avenue to manipulate the valley degree of freedom.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 01:22:50 GMT""}]","2022-08-31"
"2202.05949","Dominic Beck","Dominic Beck, Ari Cukierman, W. L. Kimmy Wu","Bias on Tensor-to-Scalar Ratio Inference With Estimated Covariance
  Matrices","9 pages, 10 figures, accepted for publication in MNRAS",,"10.1093/mnras/stac1775",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  We investigate simulation-based bandpower covariance matrices commonly used
in cosmological parameter inferences such as the estimation of the
tensor-to-scalar ratio $r$. We find that upper limits on $r$ can be biased low
by tens of percent. The underestimation of the upper limit is most severe when
the number of simulation realizations is similar to the number of observables.
Convergence of the covariance-matrix estimation can require a number of
simulations an order of magnitude larger than the number of observables, which
could mean $\mathcal{O}(10\ 000)$ simulations. This is found to be caused by an
additional scatter in the posterior probability of $r$ due to Monte Carlo noise
in the estimated bandpower covariance matrix, in particular, by spurious
non-zero off-diagonal elements. We show that matrix conditioning can be a
viable mitigation strategy in the case that legitimate covariance assumptions
can be made.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 01:26:55 GMT""},{""version"":""v2"",""created"":""Thu, 23 Jun 2022 17:31:00 GMT""}]","2022-07-06"
"2202.05950","Mahdis Ghodrati","Mahdis Ghodrati","Chaos, Phase Transitions and Curvature Invariants of (rotating, warped,
  massive) BTZ Black Holes","Contribution to the proceedings of 17th Italy-Korea Symposium on
  Relativistic Astrophysics",,,,"hep-th gr-qc","http://creativecommons.org/licenses/by/4.0/","  Combining several results from the previous works of the author, three main
subtleties will be clarified here. First, similar to the rotating BTZ black
holes, we show how for the warped BTZ black holes, the consideration of the
effective temperatures could solve the seemingly unsaturation issue of the
chaos bound. Second, comparing the Hawking-Page phase diagrams of BTZ and
warped BTZ black holes in the topologically massive gravity and new massive
gravity theories, we show how the characteristics of the action would specify
the behaviors of the chaos modes, and there we emphasize the importance of
using the local and ""physical"" thermodynamical ensembles for studying the
boundary chaos modes in warped CFTs and also the connections with the bulk
reconstruction. Third, we propose that the boundary modular scrambling modes
which saturate the modular chaos bound are related to the curvature invariants
in the geometrical side.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 01:40:32 GMT""},{""version"":""v2"",""created"":""Mon, 17 Apr 2023 09:57:50 GMT""}]","2023-04-18"
"2202.05951","Albert Rigosi","Albert F. Rigosi","Historical Context and Outlook of Quantum Hall Research for the
  Redefined SI",,,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by-nc-nd/4.0/","  To fully appreciate the impacts that the discovery of the quantum Hall effect
had on electrical metrology, it may benefit the reader to cultivate a general
understanding of the phenomenon. Two-dimensional electron systems can exhibit
many interesting quantum phenomena. The QHE may be exhibited by a 2D electron
system when placed under a strong magnetic field perpendicular to the plane of
the system. These conditions allow for Landau quantization, or the
discretization of available energies of the electrons affected by the magnetic
field. These energy values, determined by solving the Schr\""odinger equation,
are known as Landau levels. During the course of a QHE measurement, one defines
the Hall resistance Rxy as the measured voltage, perpendicular to the direction
of the applied current, divided by that same current. The characteristic
longitudinal resistivity \r{ho}xx goes to zero as Rxy approaches a quantized
value (nominally called a plateau).
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 02:10:12 GMT""}]","2022-02-15"
"2202.05952","Albert Rigosi","Albert F. Rigosi","Marking the Graphene Era in Disseminating the Redefined SI",,,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The history of quantum Hall standards stretches several decades and mostly
begins with the use of GaAs given that 2D electron systems exhibit interesting
quantum phenomena. At the end 2000s, research in 2D materials like graphene
became prevalent. The QHE was observed and quickly became accessible to
metrologists. QHR devices were becoming graphene-based, with fabrications
performed by chemical vapor deposition (CVD), epitaxial growth, and the
exfoliation of graphite. Given the many methods of available graphene
synthesis, efforts to find an optimal synthesis method for metrological
purposes were underway. Exfoliated graphene was widely known to exhibit the
highest mobilities due to its pristine crystallinity. It was a primary initial
candidate as far as metrological testing was concerned.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 02:13:25 GMT""}]","2022-02-15"
"2202.05953","Rui Shao","Rui Shao, Pramuditha Perera, Pong C. Yuen, Vishal M. Patel","Open-set Adversarial Defense with Clean-Adversarial Mutual Learning","Accepted by International Journal of Computer Vision (IJCV) 2022.
  Code will be available at https://github.com/rshaojimmy/ECCV2020-OSAD. arXiv
  admin note: text overlap with arXiv:2009.00814",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Open-set recognition and adversarial defense study two key aspects of deep
learning that are vital for real-world deployment. The objective of open-set
recognition is to identify samples from open-set classes during testing, while
adversarial defense aims to robustify the network against images perturbed by
imperceptible adversarial noise. This paper demonstrates that open-set
recognition systems are vulnerable to adversarial samples. Furthermore, this
paper shows that adversarial defense mechanisms trained on known classes are
unable to generalize well to open-set samples. Motivated by these observations,
we emphasize the necessity of an Open-Set Adversarial Defense (OSAD) mechanism.
This paper proposes an Open-Set Defense Network with Clean-Adversarial Mutual
Learning (OSDN-CAML) as a solution to the OSAD problem. The proposed network
designs an encoder with dual-attentive feature-denoising layers coupled with a
classifier to learn a noise-free latent feature representation, which
adaptively removes adversarial noise guided by channel and spatial-wise
attentive filters. Several techniques are exploited to learn a noise-free and
informative latent feature space with the aim of improving the performance of
adversarial defense and open-set recognition. First, we incorporate a decoder
to ensure that clean images can be well reconstructed from the obtained latent
features. Then, self-supervision is used to ensure that the latent features are
informative enough to carry out an auxiliary task. Finally, to exploit more
complementary knowledge from clean image classification to facilitate feature
denoising and search for a more generalized local minimum for open-set
recognition, we further propose clean-adversarial mutual learning, where a peer
network (classifying clean images) is further introduced to mutually learn with
the classifier (classifying adversarial images).
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 02:13:55 GMT""}]","2022-02-15"
"2202.05954","Albert Rigosi","Albert F. Rigosi","Expansion of Graphene-Based Device Technology for Resistance Metrology",,,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The field of Quantum Hall metrology had a strong start with the implemntation
of GaAs-based devices, given that 2D materials systems provided access to
interesting quantum phenomena, including the infrastructure associated with
making relevant measurements. With the technology laid out, further
improvements in both infrastructure and standards were achieved in the previous
two decades as EG-based quantized Hall resistance (QHR) devices became
established as national standards. Since the metrology community has reached
some understanding that a comparison against GaAs-based QHR devices had been
accomplished, the next steps became clearer as far as how the EG-based QHR with
a single Hall bar could be further developed. Since the early 90s, it has been
of modest interest that QHR devices have a means of interconnecting several
single Hall bar elements and has since been a subject of research. NMIs are now
presently at a juncture where consideration must be granted beyond just
simplicity of operation. A natural direction for resistance standards would be
to increase the total accessible parameter space. This means using EG-based QHR
devices to output more than the single value at the $\nu = 2$ plateau (about
12.9 k$\Omega$). A first natural question is whether one may use the $\nu = 6$
plateau or $\nu = 10$ plateau, and though some work has been done with these
Landau levels in graphene, they simply do not offer the same level of precision
as the $\nu = 2$ plateau.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 02:19:14 GMT""}]","2022-02-15"
"2202.05955","Bruno Grenet","Pascal Giorgi, Bruno Grenet, Armelle Perret du Cray, Daniel S. Roche","Random primes in arithmetic progressions",,,,,"cs.CC cs.SC math.NT","http://creativecommons.org/licenses/by/4.0/","  We describe a straightforward method to generate a random prime q such that
the multiplicative group GF(q)* also has a random large prime-order subgroup.
The described algorithm also yields this order p as well as a p'th primitive
root of unity. The methods here are efficient asymptotically, but due to large
constants may not be very useful in practical settings.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 02:19:27 GMT""},{""version"":""v2"",""created"":""Fri, 29 Apr 2022 15:46:15 GMT""}]","2022-05-02"
"2202.05956","Choiti Bandyopadhyay","Choiti Bandyopadhyay","Fixed Points and Continuity of Semihypergroup Actions","21 Pages, comments are welcome",,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  In a couple of previous papers, we initiated a systematic study of
semihypergroups and had a thorough discussion on certain analytic and algebraic
aspects associated to this class of objects. In this article, we introduce and
examine (separately) continuous actions on the category of semihypergroups. In
particular, we discuss the continuity properties of such actions and explore
the equivalence relations between different fixed-point properties of certain
actions and the existence of left-invariant mean(s) on the space of almost
periodic functions on a semihypergroup.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 02:21:33 GMT""},{""version"":""v2"",""created"":""Fri, 8 Apr 2022 13:55:52 GMT""}]","2022-04-11"
"2202.05957","James Davis","Jim Davis","Confident AI",,,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose ""Confident AI"" as a means to designing Artificial
Intelligence (AI) and Machine Learning (ML) systems with both algorithm and
user confidence in model predictions and reported results. The 4 basic tenets
of Confident AI are Repeatability, Believability, Sufficiency, and
Adaptability. Each of the tenets is used to explore fundamental issues in
current AI/ML systems and together provide an overall approach to Confident AI.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 02:26:46 GMT""}]","2022-02-15"
"2202.05958","Tao Zhou","Junfang Zhu, Xuezao Ren, Peijie Ma, Kun Gao, Bing-Hong Wang and Tao
  Zhou","Detecting network communities via greedy expanding based on local
  superiority index",,"Physica A 603 (2022) 127722","10.1016/j.physa.2022.127722",,"physics.soc-ph cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Community detection is a significant and challenging task in network science.
Nowadays, plenty of attention has been paid on local methods for community
detection. Greedy expanding is a popular and efficient class of local
algorithms, which typically starts from some selected central nodes and expands
those nodes to obtain provisional communities by optimizing a certain quality
function. In this paper, we propose a novel index, called local superiority
index (LSI), to identify central nodes. In the process of expansion, we apply
the fitness function to estimate the quality of provisional communities and
ensure that all provisional communities must be weak communities. Evaluation
based on the normalized mutual information suggests: (1) LSI is superior to the
global maximal degree index and the local maximal degree index on most
considered networks; (2) The greedy algorithm based on LSI is better than the
classical fast algorithm on most considered networks.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 02:28:45 GMT""}]","2022-07-13"
"2202.05959","Koundinya Vajjha","Koundinya Vajjha, Barry Trager, Avraham Shinnar, Vasily Pestun","Formalization of a Stochastic Approximation Theorem","17 pages",,"10.4230/LIPIcs.ITP.2022.31",,"cs.LO cs.LG cs.PL math.PR","http://creativecommons.org/licenses/by/4.0/","  Stochastic approximation algorithms are iterative procedures which are used
to approximate a target value in an environment where the target is unknown and
direct observations are corrupted by noise. These algorithms are useful, for
instance, for root-finding and function minimization when the target function
or model is not directly known. Originally introduced in a 1951 paper by
Robbins and Monro, the field of Stochastic approximation has grown enormously
and has come to influence application domains from adaptive signal processing
to artificial intelligence. As an example, the Stochastic Gradient Descent
algorithm which is ubiquitous in various subdomains of Machine Learning is
based on stochastic approximation theory. In this paper, we give a formal proof
(in the Coq proof assistant) of a general convergence theorem due to Aryeh
Dvoretzky, which implies the convergence of important classical methods such as
the Robbins-Monro and the Kiefer-Wolfowitz algorithms. In the process, we build
a comprehensive Coq library of measure-theoretic probability theory and
stochastic processes.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 02:31:14 GMT""},{""version"":""v2"",""created"":""Mon, 8 Aug 2022 21:09:24 GMT""}]","2022-08-10"
"2202.05960","Haotian Li","Haotian Li, Yong Wang, Aoyu Wu, Huan Wei, Huamin Qu","Structure-aware Visualization Retrieval","Accepted to the 2022 CHI Conference on Human Factors in Computing
  Systems (CHI 22)",,"10.1145/3491102.3502048",,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the wide usage of data visualizations, a huge number of Scalable Vector
Graphic (SVG)-based visualizations have been created and shared online.
Accordingly, there has been an increasing interest in exploring how to retrieve
perceptually similar visualizations from a large corpus, since it can benefit
various downstream applications such as visualization recommendation. Existing
methods mainly focus on the visual appearance of visualizations by regarding
them as bitmap images. However, the structural information intrinsically
existing in SVG-based visualizations is ignored. Such structural information
can delineate the spatial and hierarchical relationship among visual elements,
and characterize visualizations thoroughly from a new perspective. This paper
presents a structure-aware method to advance the performance of visualization
retrieval by collectively considering both the visual and structural
information. We extensively evaluated our approach through quantitative
comparisons, a user study and case studies. The results demonstrate the
effectiveness of our approach and its advantages over existing methods.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 02:35:46 GMT""}]","2022-02-15"
"2202.05961","Arda Senocak","Arda Senocak, Junsik Kim, Tae-Hyun Oh, Hyeonggon Ryu, Dingzeyu Li, In
  So Kweon","Audio-Visual Fusion Layers for Event Type Aware Video Recognition",,,,,"cs.CV eess.IV","http://creativecommons.org/licenses/by/4.0/","  Human brain is continuously inundated with the multisensory information and
their complex interactions coming from the outside world at any given moment.
Such information is automatically analyzed by binding or segregating in our
brain. While this task might seem effortless for human brains, it is extremely
challenging to build a machine that can perform similar tasks since complex
interactions cannot be dealt with single type of integration but requires more
sophisticated approaches. In this paper, we propose a new model to address the
multisensory integration problem with individual event-specific layers in a
multi-task learning scheme. Unlike previous works where single type of fusion
is used, we design event-specific layers to deal with different audio-visual
relationship tasks, enabling different ways of audio-visual formation.
Experimental results show that our event-specific layers can discover unique
properties of the audio-visual relationships in the videos. Moreover, although
our network is formulated with single labels, it can output additional true
multi-labels to represent the given videos. We demonstrate that our proposed
framework also exposes the modality bias of the video data category-wise and
dataset-wise manner in popular benchmark datasets.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 02:56:22 GMT""}]","2022-02-15"
"2202.05962","Fanyang Mo","Hao Xu, Jinglong Lin, Qianyi Liu, Yuntian Chen, Jianning Zhang, Yang
  Yang, Michael C. Young, Yan Xu, Dongxiao Zhang, Fanyang Mo","High-throughput discovery of chemical structure-polarity relationships
  combining automation and machine learning techniques",,"Chem 2022","10.1016/j.chempr.2022.08.008",,"physics.chem-ph cond-mat.mtrl-sci cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  As an essential attribute of organic compounds, polarity has a profound
influence on many molecular properties such as solubility and phase transition
temperature. Thin layer chromatography (TLC) represents a commonly used
technique for polarity measurement. However, current TLC analysis presents
several problems, including the need for a large number of attempts to obtain
suitable conditions, as well as irreproducibility due to non-standardization.
Herein, we describe an automated experiment system for TLC analysis. This
system is designed to conduct TLC analysis automatically, facilitating
high-throughput experimentation by collecting large experimental data under
standardized conditions. Using these datasets, machine learning (ML) methods
are employed to construct surrogate models correlating organic compounds'
structures and their polarity using retardation factor (Rf). The trained ML
models are able to predict the Rf value curve of organic compounds with high
accuracy. Furthermore, the constitutive relationship between the compound and
its polarity can also be discovered through these modeling methods, and the
underlying mechanism is rationalized through adsorption theories. The trained
ML models not only reduce the need for empirical optimization currently
required for TLC analysis, but also provide general guidelines for the
selection of conditions, making TLC an easily accessible tool for the broad
scientific community.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 03:00:36 GMT""}]","2022-11-22"
"2202.05963","Tian Li","Tian Li, Manzil Zaheer, Sashank J. Reddi, Virginia Smith","Private Adaptive Optimization with Side Information","ICML 2022",,,,"cs.LG cs.CR stat.ML","http://creativecommons.org/licenses/by/4.0/","  Adaptive optimization methods have become the default solvers for many
machine learning tasks. Unfortunately, the benefits of adaptivity may degrade
when training with differential privacy, as the noise added to ensure privacy
reduces the effectiveness of the adaptive preconditioner. To this end, we
propose AdaDPS, a general framework that uses non-sensitive side information to
precondition the gradients, allowing the effective use of adaptive methods in
private settings. We formally show AdaDPS reduces the amount of noise needed to
achieve similar privacy guarantees, thereby improving optimization performance.
Empirically, we leverage simple and readily available side information to
explore the performance of AdaDPS in practice, comparing to strong baselines in
both centralized and federated settings. Our results show that AdaDPS improves
accuracy by 7.7% (absolute) on average -- yielding state-of-the-art
privacy-utility trade-offs on large-scale text and image benchmarks.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 03:02:06 GMT""},{""version"":""v2"",""created"":""Sat, 25 Jun 2022 01:19:01 GMT""}]","2022-06-28"
"2202.05964","Jie Cai","Christine L. Cook, Jie Cai, Donghee Yvette Wohn","Awe Versus Aww: The Effectiveness of Two Kinds of Positive Emotional
  Stimulation on Stress Reduction for Online Content Moderators","Accepted by CSCW 2022",,"10.1145/3555168",,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When people have the freedom to create and post content on the internet,
particularly anonymously, they do not always respect the rules and regulations
of the websites on which they post, leaving other unsuspecting users vulnerable
to sexism, racism, threats, and other unacceptable content in their daily
cyberspace diet. However, content moderators witness the worst of humanity on a
daily basis in place of the average netizen. This takes its toll on moderators,
causing stress, fatigue, and emotional distress akin to the symptomology of
post-traumatic stress disorder (PTSD). The goal of the present study was to
explore whether adding positive stimuli to breaktimes-images of baby animals or
beautiful, aweinspiring landscapes-could help reduce the negative side-effects
of being a content moderator. To test this, we had over 300 experienced content
moderators read and decide whether 200 fake text-based social media posts were
acceptable or not for public consumption. Although we set out to test positive
emotional stimulation, however, we actually found that it is the cumulative
nature of the negative emotions that likely negates most of the effects of the
intervention: the longer the person had practiced content moderation, the
stronger their negative experience. Connections to compassion fatigue and how
best to spend work breaks as a content moderator are discussed.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 03:23:03 GMT""}]","2023-05-17"
"2202.05965","Haonan Wang","Haonan Wang, Ang Li, Ya-Feng Liu, Qibo Qin, Lingyang Song, and Yonghui
  Li","Achievable Rate Maximization Pattern Design for Reconfigurable MIMO
  Antenna Array","This work has been accepted by IEEE Transactions on Wireless
  Communications","IEEE Transactions on Wireless Communications, 2023, (Early Access)","10.1109/TWC.2023.3238069",,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reconfigurable multiple-input multiple-output can provide performance gains
over traditional MIMO by reshaping the channels, i.e., introducing more channel
realizations. In this paper, we focus on the achievable rate maximization
pattern design for reconfigurable MIMO systems. Firstly, we introduce the
matrix representation of pattern reconfigurable MIMO (PR-MIMO), based on which
a pattern design problem is formulated. To further reveal the effect of the
radiation pattern on the wireless channel, we consider pattern design for both
the single-pattern case where the optimized radiation pattern is the same for
all the antenna elements, and the multi-pattern case where different antenna
elements can adopt different radiation patterns. For the single-pattern case,
we show that the pattern design is equivalent to a redistribution of gains
among all scattering paths, and an eigenvalue optimization based solution is
obtained. For the multi-pattern case, we propose a sequential optimization
framework with manifold optimization and eigenvalue decomposition to obtain
near-optimal solutions. Numerical results validate the superiority of PR-MIMO
systems over traditional MIMO in terms of achievable rate, and also show the
effectiveness of the proposed solutions.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 03:27:56 GMT""},{""version"":""v2"",""created"":""Mon, 13 Feb 2023 11:27:58 GMT""}]","2023-02-14"
"2202.05966","Norio Konno","Takashi Komatsu, Norio Konno, Iwao Sato, Shunya Tamura","Mahler/Zeta Correspondence","27 pages. arXiv admin note: text overlap with arXiv:2109.07664,
  arXiv:2104.10287",,,,"quant-ph math-ph math.CO math.MP math.NT math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Mahler measure was introduced by Mahler in the study of number theory. It
is known that the Mahler measure appears in different areas of mathematics and
physics. On the other hand, we have been investigated a new class of zeta
functions for various kinds of walks including quantum walks by a series of our
previous work on ""Zeta Correspondence"". The quantum walk is a quantum
counterpart of the random walk. In this paper, we present a new relation
between the Mahler measure and our zeta function for quantum walks. Firstly we
consider this relation in the case of one-dimensional quantum walks. Afterwards
we deal with higher-dimensional quantum walks. For comparison with the case of
the quantum walk, we also treat the case of higher-dimensional random walks.
Our results bridge between the Mahler measure and the zeta function via quantum
walks for the first time.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 03:32:49 GMT""}]","2022-02-15"
"2202.05967","Jian-Qin Lu","Jian-Qin Lu","Development of Beams Optics Code LEADS-v5","number of pages: 12, number of figures: 14",,,,"physics.acc-ph","http://creativecommons.org/publicdomain/zero/1.0/","  To calculate nonlinear transport of space charge dominated beam in 6D phase
spaces, a computer code package LEADS-v5 (Linear and Electrostatic Accelerator
Dynamics Simulations) has been developed. The codes calculate particle motions
in the beam transport systems consisting of electrostatic and magnetic focusing
lenses, ion analyzers, multipoles and RF accelerating structures. The nonlinear
forces of external electric/magnetic fields are analyzed by the Lie algebraic
method, and the space charge forces are obtained by the particle in cell (PIC)
scheme. In the codes, Uniform and Gaussian particle distributions can be chosen
to generate randomly the particle initial coordinates. The optimization
procedures are provided to make the beam optics designs reasonable and fast.
Graphically displays of calculated results are provided.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 03:34:19 GMT""}]","2022-02-15"
"2202.05968","Mingqiang Ren","Ming-Qiang Ren, Shu-Ze Wang, Sha Han, Can-Li Song, Xu-Cun Ma and
  Qi-Kun Xue","Tuning the electronic states and superconductivity in alkali fulleride
  films","20 pages, 19 figures","AAPPS Bulletin 32,1(2022)","10.1007/s43673-021-00031-2",,"cond-mat.supr-con cond-mat.mtrl-sci cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The successful preparation of superconducting alkali fulleride
(A$_x$C$_{60}$, A = K, Rb, Cs) films using state-of-the-art molecular beam
epitaxy overcomes the disadvantages of the air-sensitivity and phase separation
in bulk A$_x$C$_{60}$, enabling for the first time a direct investigation of
the superconductivity in alkali fullerides on the molecular scale. In this
paper, we briefly review recent cryogenic scanning tunneling microscopy results
of the structural, electronic, and superconducting properties of the fcc
A$_x$C$_{60}$ films grown on graphitized SiC substrates. Robust $s$-wave
superconductivity is revealed against the pseudogap, electronic correlation,
non-magnetic impurities, and merohedral disorder. By controlling the alkali
metal species, film thickness, and electron doping, we systematically tune the
C$_{60}^{x-}$ orientational orderings and superconductivity in A$_x$C$_{60}$
films and then complete a unified phase diagram of superconducting gap size vs
electronic correlation and doping. These investigations are conclusive and
elucidated that the $s$-wave superconductivity retains in alkali fullerides
despite of the electronic correlation and presence of pseudogap.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 03:34:28 GMT""}]","2022-02-15"
"2202.05969","Xinghong Pan","Xinghong Pan and Chao-Jiang Xu","Global tangentially analytical solutions of the 3D axially symmetric
  Prandtl equations",,"Chinese Annals of Mathematics, Series B, 2023",,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we will prove the global existence of solutions to the three
dimensional axially symmetric Prandtl boundary layer equations with small
initial data, which lies in $H^1$ Sobolev space with respect to the normal
variable and is analytical with respect to the tangential variables. Proof of
the main result relies on the construction of a tangentially weighted analytic
energy functional, which acts on a specially designed good unknown. The
constructed energy functional can find its two dimensional parallel in
Ignatova-Vicol [2016ARMA] where no tangential weight is introduced and the
specially good unknown is set to control the lower bound of the analytical
radius, whose two dimensional similarity can be traced to Paicu-Zhang
[2021ARMA]. Our result is an improvement of that in Ignatova-Vicol [2016ARMA]
from the almost global existence to the global existence and an extension of
that in Paicu-Zhang [2021ARMA] from the two dimensional case to the three
dimensional axially symmetric case.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 03:35:54 GMT""}]","2023-03-20"
"2202.05970","Charles Marcus","H. Q. Nguyen, D. Sabonis, D. Razmadze, E. T. Mannila, V. F. Maisi, D.
  M. T. van Zanten, E. C. T. O'Farrell, P. Krogstrup, F. Kuemmeth, J. P.
  Pekola, C. M. Marcus","Electrostatic control of quasiparticle poisoning in a hybrid
  semiconductor-superconductor island",,,,"NBI QDev 2022","cond-mat.mes-hall cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  The performance of superconducting devices is often degraded by the
uncontrolled appearance and disappearance of quasiparticles, a process known as
poisoning. We demonstrate electrostatic control of quasiparticle poisoning in
the form of single-charge tunneling across a fixed barrier onto a Coulomb
island in an InAs/Al hybrid nanowire. High-bandwidth charge sensing was used to
monitor charge occupancy of the island across Coulomb blockade peaks, where
tunneling rates were maximal, and Coulomb valleys, where tunneling was absent.
Electrostatic gates changed on-peak tunneling rates by two orders of magnitude
for a barrier with fixed normal-state resistance, which we attribute to gate
dependence of the size and softness of the induced superconducting gap on the
island, corroborated by separate density-of-states measurements. Temperature
and magnetic field dependence of tunneling rates are also investigated.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 03:40:49 GMT""}]","2022-02-15"
"2202.05971","Jing Yang Lee","Jing Yang Lee, Kong Aik Lee and Woon Seng Gan","Improving Contextual Coherence in Variational Personalized and
  Empathetic Dialogue Agents","Accepted at ICASSP 2022",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  In recent years, latent variable models, such as the Conditional Variational
Auto Encoder (CVAE), have been applied to both personalized and empathetic
dialogue generation. Prior work have largely focused on generating diverse
dialogue responses that exhibit persona consistency and empathy. However, when
it comes to the contextual coherence of the generated responses, there is still
room for improvement. Hence, to improve the contextual coherence, we propose a
novel Uncertainty Aware CVAE (UA-CVAE) framework. The UA-CVAE framework
involves approximating and incorporating the aleatoric uncertainty during
response generation. We apply our framework to both personalized and empathetic
dialogue generation. Empirical results show that our framework significantly
improves the contextual coherence of the generated response. Additionally, we
introduce a novel automatic metric for measuring contextual coherence, which
was found to correlate positively with human judgement.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 03:57:14 GMT""}]","2022-02-15"
"2202.05972","Qian Zhao","Xinyi Liu and Qi Xie and Qian Zhao and Hong Wang and Deyu Meng","Low-light Image Enhancement by Retinex Based Algorithm Unrolling and
  Adjustment",,,,,"cs.CV eess.IV","http://creativecommons.org/licenses/by/4.0/","  Motivated by their recent advances, deep learning techniques have been widely
applied to low-light image enhancement (LIE) problem. Among which, Retinex
theory based ones, mostly following a decomposition-adjustment pipeline, have
taken an important place due to its physical interpretation and promising
performance. However, current investigations on Retinex based deep learning are
still not sufficient, ignoring many useful experiences from traditional
methods. Besides, the adjustment step is either performed with simple image
processing techniques, or by complicated networks, both of which are
unsatisfactory in practice. To address these issues, we propose a new deep
learning framework for the LIE problem. The proposed framework contains a
decomposition network inspired by algorithm unrolling, and adjustment networks
considering both global brightness and local brightness sensitivity. By virtue
of algorithm unrolling, both implicit priors learned from data and explicit
priors borrowed from traditional methods can be embedded in the network,
facilitate to better decomposition. Meanwhile, the consideration of global and
local brightness can guide designing simple yet effective network modules for
adjustment. Besides, to avoid manually parameter tuning, we also propose a
self-supervised fine-tuning strategy, which can always guarantee a promising
performance. Experiments on a series of typical LIE datasets demonstrated the
effectiveness of the proposed method, both quantitatively and visually, as
compared with existing methods.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 03:59:38 GMT""},{""version"":""v2"",""created"":""Tue, 15 Feb 2022 08:25:36 GMT""}]","2022-02-16"
"2202.05973","Tong-Jie Zhang Dr.","Jian-Chen Zhang, Jing Zheng, Tong-Jie Zhang","Model-independent reconstruction of the cosmological scale factor as a
  function of lookback time","9 pages, 8 figures, 3 tables. Accepted for publication in ApJ",,"10.3847/1538-4357/ac549c",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a model-independent method of reconstructing scale factor against
lookback time from the Observational Hubble parameter Data (OHD). The
reconstruction method is independent of dynamical models and is only based on
the Friedmann-Robertson-Walker metric. We also calculate the propagation of
error in the reconstruction process. The reconstruction data errors mainly come
from trapezoidal rule approximation and the uncertainty from OHD. Furthermore,
the model discrimination ability of original OHD and reconstructed a-t data is
discussed under a dimensionless standard method. a-t data can present the
differences between cosmology models more clearly than H-z data by comparing
their coefficients of variations. Finally, we add fifty simulated H(z) data to
estimate the influence of future observation. More Hubble measurements in the
future will help constrain cosmological parameters more accurately.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 04:02:13 GMT""}]","2022-03-30"
"2202.05974","Charles Marcus","O. Erlandsson, D. Sabonis, A. Kringh{\o}j, T.W. Larsen, P. Krogstrup,
  K. D. Petersson, C. M. Marcus","Parity switching in a full-shell superconductor-semiconductor nanowire
  qubit",,,,"NBI QDev 2022","cond-mat.mes-hall cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  The rate of charge-parity switching in a full-shell
superconductor-semiconductor nanowire qubit is measured by directly monitoring
the dispersive shift of a readout resonator. At zero magnetic field, the
measured switching time scale $T_P$ is on the order of 100 ms. Two-tone
spectroscopy data post-selected on charge-parity is demonstrated. With
increasing temperature or magnetic field, TP is at first constant, then
exponentially suppressed, consistent with a model that includes both
non-equilibrium and thermally activated quasiparticles. As TP is suppressed,
qubit lifetime T1 also decreases. The long $T_P\sim 0.1$ s at zero field is
promising for future development of qubits based on hybrid nanowires.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 04:04:25 GMT""}]","2022-02-15"
"2202.05975","Lan-Zhe Guo","Lan-Zhe Guo and Zhi Zhou and Yu-Feng Li","Robust Deep Semi-Supervised Learning: A Brief Introduction","We will rewrite this paper",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Semi-supervised learning (SSL) is the branch of machine learning that aims to
improve learning performance by leveraging unlabeled data when labels are
insufficient. Recently, SSL with deep models has proven to be successful on
standard benchmark tasks. However, they are still vulnerable to various
robustness threats in real-world applications as these benchmarks provide
perfect unlabeled data, while in realistic scenarios, unlabeled data could be
corrupted. Many researchers have pointed out that after exploiting corrupted
unlabeled data, SSL suffers severe performance degradation problems. Thus,
there is an urgent need to develop SSL algorithms that could work robustly with
corrupted unlabeled data. To fully understand robust SSL, we conduct a survey
study. We first clarify a formal definition of robust SSL from the perspective
of machine learning. Then, we classify the robustness threats into three
categories: i) distribution corruption, i.e., unlabeled data distribution is
mismatched with labeled data; ii) feature corruption, i.e., the features of
unlabeled examples are adversarially attacked; and iii) label corruption, i.e.,
the label distribution of unlabeled data is imbalanced. Under this unified
taxonomy, we provide a thorough review and discussion of recent works that
focus on these issues. Finally, we propose possible promising directions within
robust SSL to provide insights for future research.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 04:16:41 GMT""},{""version"":""v2"",""created"":""Mon, 14 Nov 2022 04:13:26 GMT""}]","2022-11-15"
"2202.05976","Chao Mi","Chao Mi, Ming Guan, Xun Zhang, Liu Yang, Sitong Wu, Zhichao Yang,
  Zhiyong Guo, Jiayan Liao, Jiajia Zhou, Dayong Jin, Xiaocong Yuan","High Spatial and Temporal Resolution NIR-IIb Gastrointestinal Imaging in
  Mice",,,"10.1021/acs.nanolett.1c04909",,"physics.med-ph physics.optics","http://creativecommons.org/licenses/by/4.0/","  Conventional biomedical imaging modalities, including endoscopy, X-rays, and
magnetic resonance, are invasive and cannot provide sufficient spatial and
temporal resolutions for regular imaging of gastrointestinal (GI) tract to
guide prognosis and therapy of GI diseases. Here we report a non-invasive
method for optical imaging of GI tract. It is based on a new type of
lanthanide-doped nanocrystal with near-infrared (NIR) excitation at 980 nm and
second NIR window (NIR-IIb) (1500~1700 nm) fluorescence emission at around 1530
nm. The rational design and controlled synthesis of nanocrystals with high
brightness have led to an absolute quantum yield (QY) up to 48.6%. Further
benefitting from the minimized scattering through the NIR-IIb window, we
enhanced the spatial resolution by 3 times compared with the other NIR-IIa
(1000~1500 nm) contract agents for GI tract imaging. The approach also led to a
high temporal resolution of 8 frames per second, so that the moment of mice
intestinal peristalsis happened in one minute can be captured. Furthermore,
with a light-sheet imaging system, we demonstrated a three-dimensional (3D)
imaging of the stereoscopic structure of the GI tract. Moreover, we
successfully translate these advances to diagnose inflammatory bowel disease
(IBD) in a pre-clinical model of mice colitis.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 04:20:45 GMT""}]","2022-04-27"
"2202.05977","Yc Huo","Hangming Fan, Rui Wang, Yuchi Huo, Hujun Bao","Real-time Monte Carlo Denoising with Weight Sharing Kernel Prediction
  Network",,"Computer Graphics Forum. 2021, 40(4): 15-27","10.1111/cgf.14338",,"cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Real-time Monte Carlo denoising aims at removing severe noise under low
samples per pixel (spp) in a strict time budget. Recently, kernel-prediction
methods use a neural network to predict each pixel's filtering kernel and have
shown a great potential to remove Monte Carlo noise. However, the heavy
computation overhead blocks these methods from real-time applications. This
paper expands the kernel-prediction method and proposes a novel approach to
denoise very low spp (e.g., 1-spp) Monte Carlo path traced images at real-time
frame rates. Instead of using the neural network to directly predict the kernel
map, i.e., the complete weights of each per-pixel filtering kernel, we predict
an encoding of the kernel map, followed by a high-efficiency decoder with
unfolding operations for a high-quality reconstruction of the filtering
kernels. The kernel map encoding yields a compact single-channel representation
of the kernel map, which can significantly reduce the kernel-prediction
network's throughput. In addition, we adopt a scalable kernel fusion module to
improve denoising quality. The proposed approach preserves kernel prediction
methods' denoising quality while roughly halving its denoising time for 1-spp
noisy inputs. In addition, compared with the recent neural bilateral grid-based
real-time denoiser, our approach benefits from the high parallelism of
kernel-based reconstruction and produces better denoising results at equal
time.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 04:21:37 GMT""},{""version"":""v2"",""created"":""Fri, 25 Feb 2022 09:16:14 GMT""}]","2022-02-28"
"2202.05978","Woongbae Park","Woongbae Park","A new conformal heat flow of harmonic maps",,,,,"math.DG math.AP","http://creativecommons.org/licenses/by/4.0/","  We introduce and study a conformal heat flow of harmonic maps defined by an
evolution equation for a pair consisting of a map and a conformal factor of
metric on the two-dimensional domain. This flow is designed to postpone finite
time singularity but does not get rid of possibility of bubble forming. We show
that Struwe type global weak solution exists, which is smooth except at most
finitely many points.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 04:23:30 GMT""},{""version"":""v2"",""created"":""Mon, 3 Apr 2023 18:53:06 GMT""}]","2023-04-05"
"2202.05979","Long Kong","Long Kong and Steven Kisseleff and Symeon Chatzinotas and Bj\""orn
  Ottersten and Melike Erol-Kantarci","On the Impacts of Phase Shifting Design and Eavesdropping Uncertainty on
  Secrecy Metrics of RIS-aided Systems","6 pages, 7 figures, conference",,,,"cs.IT eess.SP math.IT","http://creativecommons.org/licenses/by/4.0/","  This paper investigates the secrecy outage probability (SOP), the lower bound
of SOP, and the probability of non-zero secrecy capacity (PNZ) of
reconfigurable intelligent surface (RIS)-assisted systems from an
information-theoretic perspective. In particular, we consider the impacts of
eavesdroppers' location uncertainty and the phase adjustment uncertainty,
namely imperfect coherent phase shifting and discrete phase shifting on RIS.
More specifically, analytical and simulation results are presented to show that
(i) the SOP gain due to the increase of the RIS reflecting elements number
gradually decreases; and (ii) both phase shifting designs demonstrate the same
PNZ secrecy performance, in other words, the random discrete phase shifting
outperforms the imperfect coherent phase shifting design with reduced
complexity.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 04:25:36 GMT""},{""version"":""v2"",""created"":""Mon, 4 Apr 2022 16:10:44 GMT""}]","2022-04-05"
"2202.05980","Fulin Zhang","Gang-Gang He and Xing-Yan Fan and Fu-Lin Zhang","Robust violation of a multipartite Bell inequality from the perspective
  of a single-system game","9 pages, 2 figures","Mod. Phys. Lett.A 37,(2022) 2250082","10.1142/S0217732322500821",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, Fan \textit{et al.} [Mod. Phys. Lett. A 36, 2150223 (2021)],
presented a generalized Clauser-Horne-Shimony-Holt (CHSH) inequality, to
identify $N$-qubit Greenberger-Horne-Zeilinger (GHZ) states. They showed an
interesting phenomenon that the maximal violation of the generalized CHSH
inequality is robust under some specific noises. In this work, we map the
inequality to the CHSH game, and consequently to the CHSH* game in a
single-qubit system. This mapping provides an explanation for the robust
violations in $N$-qubit systems. Namely, the robust violations, resulting from
the degeneracy of the generalized CHSH operators correspond to the symmetry of
the maximally entangled two-qubit states and the identity transformation in the
single-qubit game. This explanation enables us to exactly demonstrate that the
degeneracy is $2^{N-2}$.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 04:30:18 GMT""},{""version"":""v2"",""created"":""Wed, 8 Jun 2022 04:29:53 GMT""}]","2022-06-09"
"2202.05981","Vladimir Khachatryan","Gregory Matousek, Vladimir Khachatryan and Jinlong Zhang","Scaling properties of exclusive vector meson production cross section
  from gluon saturation","26 pages and 18 figures","Eur. Phys. J. Plus (2023) 138:113","10.48550/arXiv.2202.05981, 10.1140/epjp/s13360-023-03729-4",,"nucl-th hep-ph nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is already known from phenomenological studies that in exclusive
deep-inelastic scattering off nuclei there appears to be a scaling behavior of
vector meson production cross section in both nuclear mass number, $A$, and
photon virtuality, $Q^{2}$, which is strongly modified due to gluon saturation
effects. In this work we continue those studies in a realistic setup based upon
using the Monte Carlo event generator Sar{\em t}re. We make quantitative
predictions for the kinematics of the Electron-Ion Collider, focusing on this
$A$ and $Q^{2}$ scaling picture, along with establishing a small region of
squared momentum transfer, $t$, where there are signs of this scaling that may
potentially be observed at the EIC. Our results are represented as pseudo-data
of vector meson production diffractive cross section and/or their ratios, which
are obtained by parsing data collected by the event generator through smearing
functions, emulating the proposed detector resolutions for the future EIC.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 04:31:23 GMT""},{""version"":""v2"",""created"":""Thu, 2 Feb 2023 21:10:03 GMT""}]","2023-02-06"
"2202.05982","Hong Jin Kang","Hong Jin Kang, Khai Loong Aw, David Lo","Detecting False Alarms from Automatic Static Analysis Tools: How Far are
  We?","Accepted to the Technical Track of ICSE 2022",,"10.1145/3510003.3510214",,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Automatic static analysis tools (ASATs), such as Findbugs, have a high false
alarm rate. The large number of false alarms produced poses a barrier to
adoption. Researchers have proposed the use of machine learning to prune false
alarms and present only actionable warnings to developers. The state-of-the-art
study has identified a set of ""Golden Features"" based on metrics computed over
the characteristics and history of the file, code, and warning. Recent studies
show that machine learning using these features is extremely effective and that
they achieve almost perfect performance.
  We perform a detailed analysis to better understand the strong performance of
the ""Golden Features"". We found that several studies used an experimental
procedure that results in data leakage and data duplication, which are subtle
issues with significant implications. Firstly, the ground-truth labels have
leaked into features that measure the proportion of actionable warnings in a
given context. Secondly, many warnings in the testing dataset appear in the
training dataset. Next, we demonstrate limitations in the warning oracle that
determines the ground-truth labels, a heuristic comparing warnings in a given
revision to a reference revision in the future. We show the choice of reference
revision influences the warning distribution. Moreover, the heuristic produces
labels that do not agree with human oracles. Hence, the strong performance of
these techniques previously seen is overoptimistic of their true performance if
adopted in practice. Our results convey several lessons and provide guidelines
for evaluating false alarm detectors.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 04:36:14 GMT""}]","2022-02-15"
"2202.05983","Kailas Vodrahalli","Kailas Vodrahalli, Tobias Gerstenberg, and James Zou","Uncalibrated Models Can Improve Human-AI Collaboration","21 pages, 12 figures, NeurIPS 2022",,,,"cs.AI cs.CV cs.HC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In many practical applications of AI, an AI model is used as a decision aid
for human users. The AI provides advice that a human (sometimes) incorporates
into their decision-making process. The AI advice is often presented with some
measure of ""confidence"" that the human can use to calibrate how much they
depend on or trust the advice. In this paper, we present an initial exploration
that suggests showing AI models as more confident than they actually are, even
when the original AI is well-calibrated, can improve human-AI performance
(measured as the accuracy and confidence of the human's final prediction after
seeing the AI advice). We first train a model to predict human incorporation of
AI advice using data from thousands of human-AI interactions. This enables us
to explicitly estimate how to transform the AI's prediction confidence, making
the AI uncalibrated, in order to improve the final human prediction. We
empirically validate our results across four different tasks--dealing with
images, text and tabular data--involving hundreds of human participants. We
further support our findings with simulation analysis. Our findings suggest the
importance of jointly optimizing the human-AI system as opposed to the standard
paradigm of optimizing the AI model alone.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 04:51:00 GMT""},{""version"":""v2"",""created"":""Wed, 1 Jun 2022 22:25:53 GMT""},{""version"":""v3"",""created"":""Fri, 28 Oct 2022 01:43:51 GMT""}]","2022-10-31"
"2202.05984","Matias Cattaneo","Matias D. Cattaneo and Yingjie Feng and Filippo Palomba and Rocio
  Titiunik","scpi: Uncertainty Quantification for Synthetic Control Methods",,,,,"stat.ME econ.EM stat.AP stat.CO","http://creativecommons.org/licenses/by/4.0/","  The synthetic control method offers a way to quantify the effect of an
intervention using weighted averages of untreated units to approximate the
counterfactual outcome that the treated unit(s) would have experienced in the
absence of the intervention. This method is useful for program evaluation and
causal inference in observational studies. We introduce the software package
scpi for prediction and inference using synthetic controls, implemented in
Python, R, and Stata. For point estimation or prediction of treatment effects,
the package offers an array of (possibly penalized) approaches leveraging the
latest optimization methods. For uncertainty quantification, the package offers
the prediction interval methods introduced by Cattaneo, Feng and Titiunik
(2021) and Cattaneo, Feng, Palomba and Titiunik (2022). The paper includes
numerical illustrations and a comparison with other synthetic control software.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 04:54:39 GMT""},{""version"":""v2"",""created"":""Wed, 7 Sep 2022 20:28:46 GMT""},{""version"":""v3"",""created"":""Tue, 11 Oct 2022 12:14:24 GMT""}]","2022-10-12"
"2202.05985","Roberto Ramirez","Freiman Triana-Arango, Gabriel Ramos-Ortiz and Roberto
  Ram\'irez-Alarc\'on","Entangled two-photon absorption detection through a Hong-Ou-Mandel
  interferometer","11 pages, 6 figures",,,,"quant-ph physics.optics","http://creativecommons.org/licenses/by/4.0/","  Recently, different experimental methods to investigate the entangled
two-photon absorption (ETPA) process in a variety of materials have been
reported. The present work reports on a different approach on which the ETPA
process is detected based on the changes induced on the Hong-Ou-Mandel (HOM)
interferogram of two photons produced by a spontaneous parametric down
conversion (SPDC) Type-II process. Using an organic solution of the laser dye
Rhodamine B as a model, it is demonstrated that ETPA at 800nm can be monitored
by the changes in the temporal-width and visibility of the HOM interferogram
produced by the photons at a beam splitter after interacting with the sample.
Additionally, we present a detail model in which the sample is modeled as a
filtering function which fullfills the energy conservation conditions required
by ETPA, allowing to explain the experimental observations with excellent
agreement. We believe that this work represents a new perspective to study the
ETPA process, by using an ultra-sensitive quantum interference technique and a
detailed mathematical model of the process.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 05:00:11 GMT""}]","2022-02-15"
"2202.05986","Anderson Chaves","Anderson S. Chaves, Daniel T. Larson, Efthimios Kaxiras and Alex
  Antonelli","Outstanding thermoelectric performance predicted for out-of-plane
  p-doped GeSe","13 pages, 7 figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The record-breaking thermoelectric performance of tin selenide (SnSe) has
motivated the investigation of analogue compounds with the same structure. A
promising candidate that emerged recently is germanium selenide (GeSe). Here,
using extensive first-principles calculations of the hole-phonon and
hole-impurity scattering, we investigate the thermoelectric transport
properties of the orthorhombic phase of p-doped GeSe. We predict outstanding
thermoelectric performance for GeSe over a broad range of temperatures due to
its high Seebeck coefficients, extremely low Lorenz numbers, ultralow total
thermal conductivity, and relatively large band gap. In particular, the
out-of-plane direction in GeSe presents equivalent or even higher performance
than SnSe for temperatures above 500 K. By extending the analysis to 900 K, we
obtained an ultrahigh value for the thermoelectric figure of merit (zT = 3.2)
at the optimal hole density of 4x10^19 cm^-3. Our work provides strong
motivation for continued experimental work focusing on improving the GeSe
doping efficiency in order to achieve this optimal hole density.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 05:10:23 GMT""}]","2022-02-15"
"2202.05987","Shariefuddin Pirzada","S. Pirzada, Saleem Khan","Distance Laplacian eigenvalues of graphs and chromatic and independence
  number","17 pages",,,,"math.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  For a connected graph $G$ of order $n$, let $Diag(Tr)$ be the diagonal matrix
of vertex transmissions and $D(G)$ be the distance matrix of $G$. The distance
Laplacian matrix of $G$ is defined as $D^L(G)=Diag(Tr)-D(G)$ and the
eigenvalues of $D^{L}(G)$ are called the distance Laplacian eigenvalues of $G$.
Let $\partial_{1}^{L}(G)\geq \partial_{2}^{L}(G)\geq \dots \geq
\partial_{n}^{L}(G)$ be the distance Laplacian eigenvalues of $G$. Given an
interval $I$, let $m_{D^{L} (G)} I$ (or simply $m_{D^{L} } I$) be the number of
distance Laplacian eigenvalues of $G$ which lie in the interval $I$. For a
prescribed interval $I$, we determine $m_{D^{L} }I$ in terms of independence
number $\alpha(G)$, chromatic number $\chi$, number of pendant vertices and
diameter $d$ of the graph $G$. In particular, we prove that $m_{D^{L}(G)
}[n,n+2)\leq \chi-1$, ~$m_{D^{L}(G) }[n,n+\alpha(G))\leq n-\alpha(G)$ and we
show that the inequalities are sharp. We also show that $m_{D^{L} (G )}\bigg(
n,n+\left\lceil\frac{n}{\chi}\right\rceil\bigg)\leq n-
\left\lceil\frac{n}{\chi}\right\rceil-C_{\overline{G}}+1 $, where
$C_{\overline{G}}$ is the number of components in $\overline{G}$, and discuss
some cases where the bound is best possible. In addition, we prove that
$m_{D^{L} (G )}[n,n+p)\leq n-p$, where $p\geq 1$ is the number of pendant
vertices. Also, we characterize graphs of diameter $d\leq 2$ which satisfy
$m_{D^{L}(G) } (2n-1,2n )= \alpha(G)-1=\frac{n}{2}-1$. At the end, we propose
some problems of interest.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 05:19:21 GMT""}]","2022-02-15"
"2202.05988","Advait Kumar","Advait Kumar, Dipesh Tamboli, Shivam Pande, Biplab Banerjee","RSINet: Inpainting Remotely Sensed Images Using Triple GAN Framework",,,,,"cs.CV cs.LG eess.IV","http://creativecommons.org/licenses/by/4.0/","  We tackle the problem of image inpainting in the remote sensing domain.
Remote sensing images possess high resolution and geographical variations, that
render the conventional inpainting methods less effective. This further entails
the requirement of models with high complexity to sufficiently capture the
spectral, spatial and textural nuances within an image, emerging from its high
spatial variability. To this end, we propose a novel inpainting method that
individually focuses on each aspect of an image such as edges, colour and
texture using a task specific GAN. Moreover, each individual GAN also
incorporates the attention mechanism that explicitly extracts the spectral and
spatial features. To ensure consistent gradient flow, the model uses residual
learning paradigm, thus simultaneously working with high and low level
features. We evaluate our model, alongwith previous state of the art models, on
the two well known remote sensing datasets, Open Cities AI and Earth on Canvas,
and achieve competitive performance.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 05:19:37 GMT""}]","2022-02-15"
"2202.05989","Aditya Lonkar","Arindam Khan, Aditya Lonkar, Arnab Maiti, Amatya Sharma, Andreas Wiese","Tight Approximation Algorithms for Two Dimensional Guillotine Strip
  Packing","32 pages, 9 figures",,,,"cs.DS cs.CG","http://creativecommons.org/licenses/by/4.0/","  In the Strip Packing problem (SP), we are given a vertical half-strip
$[0,W]\times[0,\infty)$ and a set of $n$ axis-aligned rectangles of width at
most $W$. The goal is to find a non-overlapping packing of all rectangles into
the strip such that the height of the packing is minimized. A well-studied and
frequently used practical constraint is to allow only those packings that are
guillotine separable, i.e., every rectangle in the packing can be obtained by
recursively applying a sequence of edge-to-edge axis-parallel cuts (guillotine
cuts) that do not intersect any item of the solution. In this paper, we study
approximation algorithms for the Guillotine Strip Packing problem (GSP), i.e.,
the Strip Packing problem where we require additionally that the packing needs
to be guillotine separable. This problem generalizes the classical Bin Packing
problem and also makespan minimization on identical machines, and thus it is
already strongly NP-hard. Moreover, due to a reduction from the Partition
problem, it is NP-hard to obtain a polynomial-time
$(3/2-\varepsilon)$-approximation algorithm for GSP for any $\varepsilon>0$
(exactly as Strip Packing). We provide a matching polynomial time
$(3/2+\varepsilon)$-approximation algorithm for GSP. Furthermore, we present a
pseudo-polynomial time $(1+\varepsilon)$-approximation algorithm for GSP. This
is surprising as it is NP-hard to obtain a $(5/4-\varepsilon)$-approximation
algorithm for (general) Strip Packing in pseudo-polynomial time. Thus, our
results essentially settle the approximability of GSP for both the polynomial
and the pseudo-polynomial settings.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 05:21:38 GMT""},{""version"":""v2"",""created"":""Sun, 20 Feb 2022 12:50:22 GMT""},{""version"":""v3"",""created"":""Fri, 6 May 2022 08:14:21 GMT""}]","2022-05-09"
"2202.05990","Xuankun Liao","Xuankun Liao, Qing Liu, Jiaxin Jiang, Xin Huang, Jianliang Xu, Byron
  Choi","Distributed D-core Decomposition over Large Directed Graphs",,,,,"cs.DB","http://creativecommons.org/licenses/by/4.0/","  Given a directed graph $G$ and integers $k$ and $l$, a D-core is the maximal
subgraph $H \subseteq G$ such that for every vertex of $H$, its in-degree and
out-degree are no smaller than $k$ and $l$, respectively. For a directed graph
$G$, the problem of D-core decomposition aims to compute the non-empty D-cores
for all possible values of $k$ and $l$. In the literature, several
\emph{peeling-based} algorithms have been proposed to handle D-core
decomposition. However, the peeling-based algorithms that work in a sequential
fashion and require global graph information during processing are mainly
designed for \emph{centralized} settings, which cannot handle large-scale
graphs efficiently in distributed settings. Motivated by this, we study the
\emph{distributed} D-core decomposition problem in this paper. We start by
defining a concept called \emph{anchored coreness}, based on which we propose a
new H-index-based algorithm for distributed D-core decomposition. Furthermore,
we devise a novel concept, namely \emph{skyline coreness}, and show that the
D-core decomposition problem is equivalent to the computation of skyline
corenesses for all vertices. We design an efficient D-index to compute the
skyline corenesses distributedly. We implement the proposed algorithms under
both vertex-centric and block-centric distributed graph processing frameworks.
Moreover, we theoretically analyze the algorithm and message complexities.
Extensive experiments on large real-world graphs with billions of edges
demonstrate the efficiency of the proposed algorithms in terms of both the
running time and communication overhead.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 05:26:25 GMT""}]","2022-02-15"
"2202.05991","Joshua Isaacson","Joshua Isaacson","Generators and the (Accelerated) Future","11 pages, 8 figures, 5 tables, plenary proceedings for the 20th
  International Workshop on Advanced Computing and Analysis Techniques in
  Physics Research",,"10.1088/1742-6596/2438/1/012001","FERMILAB-CONF-22-071-T","hep-ph","http://creativecommons.org/licenses/by/4.0/","  With the High Luminosity LHC coming online in the near future, event
generators will need to provide very large event samples to match the
experimental precision. Currently, the estimated cost to generate these events
exceeds the computing budget of the LHC experiments. To address these issues,
the computing efficiency of event generators need to be improved. Many
different approaches are being taken to achieve this goal. I will cover the
ongoing work on implementing event generators on the GPUs, machine learning the
matrix element, machine learning the phase space, and minimizing the number of
negative weight events.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 05:31:13 GMT""}]","2023-03-01"
"2202.05992","Di Xia","Di Xia, Zelin Yang, Pingyang Zeng, Bin Zhang, Jiayue Wu, Zifu Wang,
  Jiaxin Zhao, Mingqi Gao, Yufei Huang, Jianteng Huang, Liyang Luo, Dong Liu,
  Shuixian Yang, Hairun Guo and Zhaohui Li","Soliton Microcombs in Integrated Chalcogenide Microresonators","22 pages, 5 figures","Laser & Photonics Reviews 16 202200219 (2022)","10.1002/lpor.202200219",,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Photonic integrated microcombs have enabled advanced applications in optical
communication, microwave synthesis, and optical metrology, which in nature
unveil an optical dissipative soliton pattern under cavity-enhanced nonlinear
processes. The most decisive factor of microcombs lies in the photonic material
platforms, where materials with high nonlinearity and in capacity of
high-quality chip integration are highly demanded. In this work, we present a
home-developed chalcogenide glasses-Ge25Sb10S65 (GeSbS) for the nonlinear
photonic integration and for the dissipative soliton microcomb generation.
Compared with the current integrated nonlinear platforms, the GeSbS features
wider transparency from the visible to 11 um region, stronger nonlinearity, and
lower thermo-refractive coefficient, and is CMOS compatible in fabrication. In
this platform, we achieve chip-integrated optical microresonators with a
quality (Q) factor above 2 x 10^6, and carry out lithographically controlled
dispersion engineering. In particular, we demonstrate that both a bright
soliton-based microcomb and a dark-pulsed comb are generated in a single
microresonator, in its separated fundamental polarized mode families under
different dispersion regimes. The overall pumping power is on the ten-milliwatt
level, determined by both the high Q-factor and the high material nonlinearity
of the microresonator. Our results may contribute to the field of nonlinear
photonics with an alternative material platform for highly compact and
high-intensity nonlinear interactions, while on the application aspect,
contribute to the development of soliton microcombs at low operation power,
which is potentially required for monolithically integrated optical frequency
combs.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 05:41:50 GMT""}]","2023-03-10"
"2202.05993","Santosh Gondi","Santosh Gondi","Wav2Vec2.0 on the Edge: Performance Evaluation","9 pages",,,,"cs.SD cs.HC eess.AS","http://creativecommons.org/licenses/by/4.0/","  Wav2Vec2.0 is a state-of-the-art model which learns speech representations
through unlabeled speech data, aka, self supervised learning. The pretrained
model is then fine tuned on small amounts of labeled data to use it for
speech-to-text and machine translation tasks. Wav2Vec 2.0 is a transformative
solution for low resource languages as it is mainly developed using unlabeled
audio data. Getting large amounts of labeled data is resource intensive and
especially challenging to do for low resource languages such as Swahilli,
Tatar, etc. Furthermore, Wav2Vec2.0 word-error-rate(WER) matches or surpasses
the very recent supervised learning algorithms while using 100x less labeled
data. Given its importance and enormous potential in enabling speech based
tasks on world's 7000 languages, it is key to evaluate the accuracy, latency
and efficiency of this model on low resource and low power edge devices and
investigate the feasibility of using it in such devices for private, secure and
reliable speech based tasks. On-device speech tasks preclude sending audio data
to the server hence inherently providing privacy, reduced latency and enhanced
reliability. In this paper, Wav2Vec2.0 model's accuracy and latency has been
evaluated on Raspberry Pi along with the KenLM language model for speech
recognition tasks. How to tune certain parameters to achieve desired level of
WER rate and latency while meeting the CPU, memory and energy budgets of the
product has been discussed.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 05:49:49 GMT""}]","2022-02-15"
"2202.05994","Sangeeta Srivastava","Sangeeta Srivastava, Samuel Olin, Viktor Podolskiy, Anuj Karpatne,
  Wei-Cheng Lee, Anish Arora","Physics-Guided Problem Decomposition for Scaling Deep Learning of
  High-dimensional Eigen-Solvers: The Case of Schr\""{o}dinger's Equation","9 pages, Submitted to SIGKDD in Feb 2022",,,,"cs.LG cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given their ability to effectively learn non-linear mappings and perform fast
inference, deep neural networks (NNs) have been proposed as a viable
alternative to traditional simulation-driven approaches for solving
high-dimensional eigenvalue equations (HDEs), which are the foundation for many
scientific applications. Unfortunately, for the learned models in these
scientific applications to achieve generalization, a large, diverse, and
preferably annotated dataset is typically needed and is computationally
expensive to obtain. Furthermore, the learned models tend to be memory- and
compute-intensive primarily due to the size of the output layer. While
generalization, especially extrapolation, with scarce data has been attempted
by imposing physical constraints in the form of physics loss, the problem of
model scalability has remained.
  In this paper, we alleviate the compute bottleneck in the output layer by
using physics knowledge to decompose the complex regression task of predicting
the high-dimensional eigenvectors into multiple simpler sub-tasks, each of
which are learned by a simple ""expert"" network. We call the resulting
architecture of specialized experts Physics-Guided Mixture-of-Experts (PG-MoE).
We demonstrate the efficacy of such physics-guided problem decomposition for
the case of the Schr\""{o}dinger's Equation in Quantum Mechanics. Our proposed
PG-MoE model predicts the ground-state solution, i.e., the eigenvector that
corresponds to the smallest possible eigenvalue. The model is 150x smaller than
the network trained to learn the complex task while being competitive in
generalization. To improve the generalization of the PG-MoE, we also employ a
physics-guided loss function based on variational energy, which by quantum
mechanics principles is minimized iff the output is the ground-state solution.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 05:59:08 GMT""},{""version"":""v2"",""created"":""Tue, 15 Feb 2022 15:49:21 GMT""}]","2022-02-16"
"2202.05995","Reza Abdi","Reza Abdi, Terri S. Hogue","Wildfires and Climate Change: What does social media tell us on linkages
  and public understanding? (Preliminary White Paper, February 11, 2022)","17 pages, 4 figures in the main text, 7 figures and 2 tables in the
  supplementary materials",,,,"cs.SI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Wildfires are increasing in frequency and size across the western U.S., with
some of the deadliest fires in recorded history occurring in the last few
years. The public, as well as elected officials, use social media to convey
opinions and knowledge on topics that are impacting their communities. We
utilize the platform Twitter to assess connections of wildfire to climate
change during recent events and evaluate the differences in knowledge between
the public and their government officials. Results show some linkages of
wildfire cause and effect, although this relationship was not large (only 5%)
and was even lower at the governmental level (2%), suggesting that a broader
number of the public and government did not relate climate change to recent
extreme wildfires.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 06:01:00 GMT""}]","2022-02-15"
"2202.05996","Zhilin Zhao","Zhilin Zhao and Longbing Cao and Yuanyu Wan","Coupling Online-Offline Learning for Multi-distributional Data Streams",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The distributions of real-life data streams are usually nonstationary, where
one exciting setting is that a stream can be decomposed into several offline
intervals with a fixed time horizon but different distributions and an
out-of-distribution online interval. We call such data multi-distributional
data streams, on which learning an on-the-fly expert for unseen samples with a
desirable generalization is demanding yet highly challenging owing to the
multi-distributional streaming nature, particularly when initially limited data
is available for the online interval. To address these challenges, this work
introduces a novel optimization method named coupling online-offline learning
(CO$_2$) with theoretical guarantees about the knowledge transfer, the regret,
and the generalization error. CO$_2$ extracts knowledge by training an offline
expert for each offline interval and update an online expert by an
off-the-shelf online optimization method in the online interval. CO$_2$ outputs
a hypothesis for each sample by adaptively coupling both the offline experts
and the underlying online expert through an expert-tracking strategy to adapt
to the dynamic environment. To study the generalization performance of the
output hypothesis, we propose a general theory to analyze its excess risk bound
related to the loss function properties, the hypothesis class, the data
distribution, and the regret.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 06:04:13 GMT""}]","2022-02-15"
"2202.05997","Ming Lei","Ming Lei, Sinisa Coh","Spin-orbit driven terahertz optical response in ferromagnetic Fe-Co-Al
  alloys",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/publicdomain/zero/1.0/","  We study the magneto-optical properties of Fe-Co-Al ordered alloys in the
terahertz range of frequencies. We find that magnetism can modify the
reflection of light from these magnets and that this modification strongly
depends on the frequency of incoming light in the terahertz range. For example,
we find that below 10~THz Co$_3$Al has nearly constant $\sigma_{xy}$ and that
above 10~THz it is reduced by about 50 times. Furthermore, we find a strong
dependence of $\sigma_{xy}$ on chemical composition. For example, we find that
the addition of Al to Fe changes the sign of $\sigma_{xy}$, while the addition
of Co to Fe leads to non-monotonic dependence of $\sigma_{xy}$ on
Co-concentration.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 06:05:36 GMT""}]","2022-02-15"
"2202.05998","Hangwei Qian","Hangwei Qian, Tian Tian, Chunyan Miao","What Makes Good Contrastive Learning on Small-Scale Wearable-based
  Tasks?","Preprint",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Self-supervised learning establishes a new paradigm of learning
representations with much fewer or even no label annotations. Recently there
has been remarkable progress on large-scale contrastive learning models which
require substantial computing resources, yet such models are not practically
optimal for small-scale tasks. To fill the gap, we aim to study contrastive
learning on the wearable-based activity recognition task. Specifically, we
conduct an in-depth study of contrastive learning from both algorithmic-level
and task-level perspectives. For algorithmic-level analysis, we decompose
contrastive models into several key components and conduct rigorous
experimental evaluations to better understand the efficacy and rationale behind
contrastive learning. More importantly, for task-level analysis, we show that
the wearable-based signals bring unique challenges and opportunities to
existing contrastive models, which cannot be readily solved by existing
algorithms. Our thorough empirical studies suggest important practices and shed
light on future research challenges. In the meantime, this paper presents an
open-source PyTorch library \texttt{CL-HAR}, which can serve as a practical
tool for researchers. The library is highly modularized and easy to use, which
opens up avenues for exploring novel contrastive models quickly in the future.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 06:10:15 GMT""}]","2022-02-15"
"2202.05999","Xiao-Ming Xu","Li-Yuan Li, Xiao-Ming Xu, H. J. Weber","Production of $\psi (4040)$, $\psi (4160)$, and $\psi (4415)$ mesons in
  hadronic matter","50 pages, 21 figures, 5 tables; discussions added","Phys. Rev. D 105, 114025 (2022)","10.1103/PhysRevD.105.114025",,"hep-ph hep-ex nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the first study of production of $\psi (4040)$, $\psi (4160)$, and
$\psi (4415)$ mesons in hadronic matter. Quark interchange between two
colliding charmed mesons leads to the production of the three mesons. We
calculate unpolarized cross sections for the reactions, $D\bar{D} \to \rho R$,
$D\bar{D}^* \to \pi R$, $D\bar{D}^* \to \rho R$, $D^*\bar{D} \to \pi R$,
$D^*\bar{D} \to \rho R$, $D^*\bar{D}^* \to \pi R$, and $D^*\bar{D}^* \to \rho
R$, where $R$ stands for $\psi (4040)$, $\psi (4160)$, and $\psi (4415)$. In
the temperature region covering hadronic matter the peak cross sections of
producing $\psi (4040)$ are similar to or larger than the ones of producing
$\psi (4415)$, and the latter are generally larger than those of producing
$\psi (4160)$. With the cross sections we establish new master rate equations
for $\psi (4040)$, $\psi (4160)$, and $\psi (4415)$. The equations are solved
for central Pb-Pb collisions at $\sqrt{s_{NN}}=5.02$ TeV at the Large Hadron
Collider. Solutions of the equations show that the $\psi (4040)$ number density
at kinetic freeze-out of hadronic matter is larger than the $\psi (4415)$
number density which is larger than the $\psi (4160)$ number density.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 06:25:59 GMT""},{""version"":""v2"",""created"":""Wed, 22 Jun 2022 05:54:21 GMT""}]","2022-06-23"
"2202.06000","Mingming Fan","Xuan Zhao, Mingming Fan, Teng Han","""I Don't Want People to Look At Me Differently"": Designing User-Defined
  Above-the-Neck Gestures for People with Upper Body Motor Impairments","CHI Conference on Human Factors in Computing Systems (CHI '22)",,,,"cs.HC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Recent research proposed eyelid gestures for people with upper-body motor
impairments (UMI) to interact with smartphones without finger touch. However,
such eyelid gestures were designed by researchers. It remains unknown what
eyelid gestures people with UMI would want and be able to perform. Moreover,
other above-the-neck body parts (e.g., mouth, head) could be used to form more
gestures. We conducted a user study in which 17 people with UMI designed
above-the-neck gestures for 26 common commands on smartphones. We collected a
total of 442 user-defined gestures involving the eyes, the mouth, and the head.
Participants were more likely to make gestures with their eyes and preferred
gestures that were simple, easy-to-remember, and less likely to draw attention
from others. We further conducted a survey (N=24) to validate the usability and
acceptance of these user-defined gestures. Results show that user-defined
gestures were acceptable to both people with and without motor impairments.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 06:36:43 GMT""}]","2022-02-15"
"2202.06001","Ayaka Ishikawa","Ayaka Ishikawa, Hideaki Morita, Iwao Sato","The Ihara expression for generalized weighted zeta functions of
  Bartholdi type on finite digraphs",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Ihara expression of a weighted zeta function for a general finite digraph
is given. It unifies all the Ihara expressions obtained for known zeta
functions for finite digraphs. Any digraph in this paper permits multi-edges
and multi-loops.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 06:52:54 GMT""}]","2022-02-15"
"2202.06002","Li Chen","Guozhong Zheng, Jiqiang Zhang, Rizhou Liang, Lin Ma, and Li Chen","Probabilistic fair behaviors spark its boost in the Ultimatum Game: the
  strength of good Samaritans","8 pages, 6 figures","J. Phys. Complex. 3 035004(2022)","10.1088/2632-072X/ac86b3",,"q-bio.PE cond-mat.dis-nn cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Behavioral experiments on the Ultimatum Game have shown that we human beings
have remarkable preference in fair play, contradicting the predictions by the
game theory. Most of the existing models seeking for explanations, however,
strictly follow the assumption of \emph{Homo economicus} in orthodox Economics
that people are self-interested and fully rational to maximize their earnings.
Here we relax this assumption by allowing that people probabilistically choose
to be ""good Samaritans"", acting as fair players from time to time. For
well-mixed and homogeneously structured populations, we numerically show that
as this probability increases the level of fairness undergoes from the low
scenario abruptly to the full fairness state, where occasional fair behaviors
($\sim5\%$) are sufficient to drive the whole population to behave in the
half-half split manner. We also develop a mean-field theory, which correctly
reproduces the first-order phase transition and points out that the bistability
is an intrinsic property of this game and small fair acts lead to dramatical
change due to its bifurcation structure. Heterogeneously structured
populations, however, display continuous fairness transition; surprisingly,
very few hub nodes acting as fair players are able to entrain the whole
population to the full fairness state. Our results thus reveal the unexpected
strength of ""good Samaritans"", which may constitute a new explanation for the
emergence of fairness in our society.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 06:56:23 GMT""}]","2022-12-07"
"2202.06003","Parameswaran Kamalaruban Dr.","Luca Viano, Yu-Ting Huang, Parameswaran Kamalaruban, Craig Innes,
  Subramanian Ramamoorthy, Adrian Weller","Robust Learning from Observation with Model Misspecification","accepted to AAMAS 2022 (camera-ready version)",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Imitation learning (IL) is a popular paradigm for training policies in
robotic systems when specifying the reward function is difficult. However,
despite the success of IL algorithms, they impose the somewhat unrealistic
requirement that the expert demonstrations must come from the same domain in
which a new imitator policy is to be learned. We consider a practical setting,
where (i) state-only expert demonstrations from the real (deployment)
environment are given to the learner, (ii) the imitation learner policy is
trained in a simulation (training) environment whose transition dynamics is
slightly different from the real environment, and (iii) the learner does not
have any access to the real environment during the training phase beyond the
batch of demonstrations given. Most of the current IL methods, such as
generative adversarial imitation learning and its state-only variants, fail to
imitate the optimal expert behavior under the above setting. By leveraging
insights from the Robust reinforcement learning (RL) literature and building on
recent adversarial imitation approaches, we propose a robust IL algorithm to
learn policies that can effectively transfer to the real environment without
fine-tuning. Furthermore, we empirically demonstrate on continuous-control
benchmarks that our method outperforms the state-of-the-art state-only IL
method in terms of the zero-shot transfer performance in the real environment
and robust performance under different testing conditions.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 07:04:06 GMT""},{""version"":""v2"",""created"":""Tue, 15 Feb 2022 10:35:34 GMT""}]","2022-02-16"
"2202.06004","Travis Scrimshaw","Ajeeth Gunna and Travis Scrimshaw","Integrable systems and crystals for edge labeled tableaux","29 pages, 2 figures",,,,"math.CO math.QA math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the edge Schur functions $E^{\lambda}$ that are defined as a
generating series over edge labeled tableaux. We formulate $E^{\lambda}$ as the
partition function for a solvable lattice model, which we use to show they are
symmetric polynomials and derive a Cauchy-type identity with factorial Schur
polynomials. Finally, we give a crystal structure on edge labeled tableau to
give a positive Schur polynomial expansion of $E^{\lambda}$ and show it
intertwines with an uncrowding algorithm.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 07:08:10 GMT""}]","2022-02-15"
"2202.06005","Jongha Jon Ryu","J. Jon Ryu and Young-Han Kim","An Information-Theoretic Proof of the Kac--Bernstein Theorem","4 pages",,,,"cs.IT math.IT math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A short, information-theoretic proof of the Kac--Bernstein theorem, which is
stated as follows, is presented: For any independent random variables $X$ and
$Y$, if $X+Y$ and $X-Y$ are independent, then $X$ and $Y$ are normally
distributed.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 07:10:03 GMT""},{""version"":""v2"",""created"":""Mon, 21 Feb 2022 06:17:09 GMT""}]","2022-02-22"
"2202.06006","Wenjing Chen","Wenjing Chen and Xiaomeng Huang","Sign-changing bubble tower solutions for a Paneitz-type problem","arXiv admin note: text overlap with arXiv:1710.01880 by other authors",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  This paper is concerned with the following biharmonic problem
\begin{equation}\label{ineq} \begin{cases} \Delta^2 u=|u|^{\frac{8}{N-4}}u
&\text{ in } \ \Omega\backslash \overline{{B(\xi_0,\varepsilon)}},
  u=\Delta u=0 &\text{ on } \ \partial (\Omega \backslash
\overline{{B(\xi_0,\varepsilon)}}), \end{cases} \end{equation} where $\Omega$
is an open bounded domain in $\mathbb{R}^N$, $N\geq 5$, and
$B(\xi_0,\varepsilon)$ is a ball centered at $\xi_0$ with radius $\varepsilon$,
$\varepsilon$ is a small positive parameter. We obtain the existence of
solutions for problem (\ref{ineq}), which is an arbitrary large number of
sign-changing solutions whose profile is a superposition of bubbles with
alternate sign which concentrate at the center of the hole.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 07:20:10 GMT""}]","2022-02-17"
"2202.06007","Pravin Kumar Natwariya Mr.","Pravin Kumar Natwariya and Alekha C. Nayak","Bounds on sterile neutrino lifetime and mixing angle with active
  neutrinos by global 21 cm signal","Published in Physics Letters B","Physics Letters B 827, 136955 (2022)","10.1016/j.physletb.2022.136955",,"hep-ph astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Sterile neutrinos can be a possible candidate for dark matter. Sterile
neutrinos are radiatively unstable and can inject photon energy into the
intergalactic medium (IGM). The injection of photon energy into IGM can modify
the temperature and ionization history of IGM gas during cosmic dawn.
Theoretical models based on the {\Lambda}CDM framework predict an absorption
profile in the 21 cm line during the cosmic dawn era. Recently, the Experiment
to Detect the Global Epoch of Reionization Signature (EDGES) collaboration
confirmed such an adsorption signal. Injection of energy into IGM can modify
the absorption amplitude in the 21 cm signal. Considering the 21 cm absorption
signal at cosmic dawn, we constrain the lifetime of sterile neutrinos and the
mixing angle of sterile neutrinos with active neutrinos. We also compare these
bounds with other astrophysical observational bounds.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 07:45:36 GMT""}]","2022-04-01"
"2202.06008","Khosro Pakmanesh","Khosro Pakmanesh, Mehdi Mojaradi","Applying multi product lines to equity market software ecosystem",,,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Context: In recent decades, many financial markets and their participants
have changed their working method from a completely manual and traditional one
to an automatic one, benefiting from complex software systems. There are
different approaches to the development of such software systems. Objective: In
this paper, we study the application of the Multi Product Line (MPL) approach
in the software ecosystem (SECO) of the equity market. By profiting from the
concepts and practices of the MPL approach, we want to design a SECO that makes
the real-time and automated flow of financial transaction data between market
participants' software pieces possible. Method: We first provide some
background information about the equity market, its participants and their
relations, and two primary order life-cycles in which these players cooperate.
After that, we analyze the variability in each market participant's software.
Next, we describe the employed architecture and the implementation approach.
Finally, we discuss three scenarios by which the whole proposed SECO is tested
and validated. Results: To implement the mentioned working method, named
Straight-through Processing (STP), different technical and non-technical
elements' contribution is essential. Attaining success in developing the equity
market's SECO addresses the technical aspect and prepares the technical
infrastructure for the rest of the work. Conclusion: The successful validation
of the equity market's SECO indicates that the adoption of the MPL approach is
a viable strategy for the development of equity market SECOs. It also suggests
that this approach is worthy of more attention and investment.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 07:48:39 GMT""}]","2022-02-15"
"2202.06009","Yucheng Lu","Yucheng Lu, Conglong Li, Minjia Zhang, Christopher De Sa, Yuxiong He","Maximizing Communication Efficiency for Large-scale Training via 0/1
  Adam",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  1-bit gradient compression and local steps are two representative techniques
that enable drastic communication reduction in distributed SGD. Their benefits,
however, remain an open question on Adam-based large model pre-training (e.g.
BERT and GPT). In this paper, we demonstrate the non-linearity in Adam causes
slow convergence even when 1-bit compression or local steps are individually
applied. To alleviate this limitation, we propose 0/1 Adam that linearizes each
Adam step via approximating its optimizer states using their stale estimates
and linear correlation. 0/1 Adam performs an Adam-like step to preserve the
adaptivity, while its linearity allows utilizing 1-bit compression and local
steps simultaneously for wall-clock time speed up. We provide convergence
guarantee for 0/1 Adam on smooth non-convex objectives. On various large-scale
benchmarks such as BERT-Base, BERT-Large, GPT-2 pre-training and ImageNet, we
demonstrate on up to 128 GPUs that 0/1 Adam is able to reduce up to 87% of data
volume, 54% of communication rounds, and achieve up to 2$\times$ higher
training throughput and end-to-end training time reduction compared to the
state-of-the-art baseline 1-bit Adam; while enjoying the same statistical
convergence speed and end task model accuracy on GLUE dataset and ImageNet
validation set.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 08:02:23 GMT""},{""version"":""v2"",""created"":""Sun, 13 Mar 2022 15:35:20 GMT""},{""version"":""v3"",""created"":""Sun, 22 May 2022 04:50:43 GMT""}]","2022-05-24"
"2202.06010","Lu Zhao","Lu Zhao (1), Lijuan Zhang (1), Houfu Song (1), Hongda Du (2), Renshaw
  X. Wang (3), Junqiao Wu (4,5), Feiyu Kang (1,2) and Bo Sun (1,2) ((1)
  Tsinghua-Berkeley Shenzhen Institute, Tsinghua University, Shenzhen,
  Guangdong 518055, China (2) Institute of Materials Research, Tsinghua
  Shenzhen International Graduate School, Guangdong Provincial Key Laboratory
  of Thermal Management Engineering and Materials Shenzhen, Guangdong 518055,
  China (3) School of Physical and Mathematical Sciences, Nanyang Technological
  University, Singapore 637371, Singapore (4) Department of Materials Science
  and Engineering, University of California, Berkeley, Berkeley, CA 94720, USA
  (5) Materials Sciences, Lawrence Berkeley National Laboratory, Berkeley, CA
  94720, USA)","Incoherent phonon transport dominates heat conduction across van der
  Waals superlattices","31 pages, 7 figures",,"10.1063/5.0096861",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Heat conduction mechanisms in superlattices could be different across
different types of interfaces. Van der Waals superlattices are structures
physically assembled through weak van der Waals interactions by design, and may
host properties beyond the traditional limits of lattice matching and
processing compatibility, offering new types of interfaces. In this work,
natural van der Waals (SnS)1.17(NbS2)n superlattices are synthesized, and their
thermal conductivities are measured by time-domain thermoreflectance as a
function of interface density. Our results show that heat conduction of
(SnS)1.17(NbS2)n superlattices is dominated by interface scattering when the
coherent length of phonons is larger than the superlattice period, indicating
incoherent phonon transport dominates cross-plane heat conduction in van der
Waals superlattices even when the period is atomically thin and abrupt.
Moreover, our result suggests that the widely accepted heat conduction
mechanism for conventional superlattices that coherent phonons dominate when
the period is short, is not applicable due to symmetry breaking in most van der
Waals superlattices. Our findings provide new insight for understanding the
thermal behavior of van der Waals superlattices, and devise approaches for
effective thermal management of superlattices depending on the distinct types
of interfaces.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 08:07:37 GMT""}]","2022-07-27"
"2202.06011","Nicolas Chamel","Aur\'elien Sourie, Nicolas Chamel","Generalization of the Kutta-Joukowski theorem for the hydrodynamic
  forces acting on a quantized vortex","17 pages, 2 figures","Int. J. Mod. Phys. B 34, No. 10, 2050099 (2020)","10.1142/S021797922050099X",,"cond-mat.quant-gas cond-mat.supr-con physics.flu-dyn quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The hydrodynamic forces acting on a quantized vortex in a superfluid have
long been a highly controversial issue. A new approach, originally developed in
the astrophysical context of compact stars, is presented to determine these
forces by considering small perturbations of the asymptotically uniform flows
in the region far from the vortex in the framework of Landau-Khalatnikov
two-fluid model. Focusing on the irrotational part of the flows in the
Helmholtz decomposition, the classical Kutta-Joukowski theorem from ordinary
hydrodynamics is thus generalized to superfluid systems. The same method is
applied to predict the hydrodynamic forces acting on vortices in cold atomic
condensates and superfluid mixtures.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 08:09:58 GMT""}]","2022-02-15"
"2202.06012","Yaling Ma","Yaling Ma, Runze Gao, Li Dai, Jinxian Wu and Yuanqing Xia","Cloud-based computational model predictive control using a parallel
  multi-block ADMM approach","Statements and experiments are flawed",,,,"math.OC cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Heavy computational load for solving nonconvex problems for large-scale
systems or systems with real-time demands at each sample step has been
recognized as one of the reasons for preventing a wider application of
nonlinear model predictive control (NMPC). To improve the real-time feasibility
of NMPC with input nonlinearity, we devise an innovative scheme called
cloud-based computational model predictive control (MPC) by using an
elaborately designed parallel multi-block alternating direction method of
multipliers (ADMM) algorithm. This novel parallel multi-block ADMM algorithm is
tailored to tackle the computational issue of solving a nonconvex problem with
nonlinear constraints.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 08:15:38 GMT""},{""version"":""v2"",""created"":""Sat, 16 Apr 2022 01:48:07 GMT""}]","2022-04-19"
"2202.06013","Kamen Kozarev","Kamen Kozarev, Mohamed Nedal, Rositsa Miteva, Momchil Dechev, and
  Pietro Zucca","A Multi-Event Study of Early-Stage SEP Acceleration by CME-Driven Shocks
  -- Sun to 1 AU","23 pages, 15 figures. Accepted for publication in Frontiers in
  Astronomy and Space Sciences",,,,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  The solar corona below 10 solar radii is an important region for early
acceleration and transport of solar energetic particles (SEPs) by coronal mass
ejection-driven shock waves. There, these waves propagate into a highly
variable dynamic medium with steep gradients and rapidly expanding coronal
magnetic fields, which modulates the particle acceleration near the shock or
wave surfaces, and the way SEPs spread into the heliosphere. We present a study
modelling the acceleration of SEPs in global coronal shock events in the
corona, as well as their transport to 1 au, based on telescopic observations
coupled with dynamic physical models.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 08:15:42 GMT""}]","2022-02-15"
"2202.06014","Xianghao Zang","Xianghao Zang, Ge Li, Wei Gao","Multi-direction and Multi-scale Pyramid in Transformer for Video-based
  Pedestrian Retrieval","10 pages, 6 figures, Accepted for publication in IEEE Transactions on
  Industrial Informatics","IEEE Transactions on Industrial Informatics 2022","10.1109/TII.2022.3151766",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In video surveillance, pedestrian retrieval (also called person
re-identification) is a critical task. This task aims to retrieve the
pedestrian of interest from non-overlapping cameras. Recently,
transformer-based models have achieved significant progress for this task.
However, these models still suffer from ignoring fine-grained, part-informed
information. This paper proposes a multi-direction and multi-scale Pyramid in
Transformer (PiT) to solve this problem. In transformer-based architecture,
each pedestrian image is split into many patches. Then, these patches are fed
to transformer layers to obtain the feature representation of this image. To
explore the fine-grained information, this paper proposes to apply vertical
division and horizontal division on these patches to generate
different-direction human parts. These parts provide more fine-grained
information. To fuse multi-scale feature representation, this paper presents a
pyramid structure containing global-level information and many pieces of
local-level information from different scales. The feature pyramids of all the
pedestrian images from the same video are fused to form the final
multi-direction and multi-scale feature representation. Experimental results on
two challenging video-based benchmarks, MARS and iLIDS-VID, show the proposed
PiT achieves state-of-the-art performance. Extensive ablation studies
demonstrate the superiority of the proposed pyramid structure. The code is
available at https://git.openi.org.cn/zangxh/PiT.git.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 08:22:47 GMT""},{""version"":""v2"",""created"":""Wed, 6 Apr 2022 03:00:43 GMT""}]","2022-04-07"
"2202.06015","Mieczys{\l}aw K{\l}opotek","Mieczyslaw A. Klopotek and Robert A. Klopotek","Towards Continuous Consistency Axiom","42 pages, 6 tables, 9 figures","Applied Intelligence 2022","10.1007/s10489-022-03710-1",,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Development of new algorithms in the area of machine learning, especially
clustering, comparative studies of such algorithms as well as testing according
to software engineering principles requires availability of labeled data sets.
While standard benchmarks are made available, a broader range of such data sets
is necessary in order to avoid the problem of overfitting. In this context,
theoretical works on axiomatization of clustering algorithms, especially axioms
on clustering preserving transformations are quite a cheap way to produce
labeled data sets from existing ones. However, the frequently cited axiomatic
system of Kleinberg:2002, as we show in this paper, is not applicable for
finite dimensional Euclidean spaces, in which many algorithms like $k$-means,
operate. In particular, the so-called outer-consistency axiom fails upon making
small changes in datapoint positions and inner-consistency axiom is valid only
for identity transformation in general settings.
  Hence we propose an alternative axiomatic system, in which Kleinberg's inner
consistency axiom is replaced by a centric consistency axiom and outer
consistency axiom is replaced by motion consistency axiom. We demonstrate that
the new system is satisfiable for a hierarchical version of $k$-means with
auto-adjusted $k$, hence it is not contradictory. Additionally, as $k$-means
creates convex clusters only, we demonstrate that it is possible to create a
version detecting concave clusters and still the axiomatic system can be
satisfied. The practical application area of such an axiomatic system may be
the generation of new labeled test data from existent ones for clustering
algorithm testing. %We propose the gravitational consistency as a replacement
which does not have this deficiency.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 08:25:01 GMT""}]","2022-07-25"
"2202.06016","Yanfeng Guo","Zhenhai Yu1, Xuejiao Chen, Wei Xia, Ningning Wang, Xiaodong Lv,
  Xiaolei Liu, Hao Su, Zhongyang Li, Desheng Wu, Wei Wu, Ziyi Liu, Jinggeng
  Zhao, Mingtao Li, Shujia Li, Xin Li, Zhaohui Dong, Chunyin Zhou, Lili Zhang,
  Xia Wang, Na Yu, Zhiqiang Zou, Jianlin Luo, Jinguang Cheng, Lin Wang,
  Zhicheng Zhong, and Yanfeng Guo","Pressure-induced ideal Weyl semimetal state in the layered
  antiferromagnet EuCd2As2","main text 16 pages,4 figures and SI 8 pages, 4 figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The rich nontrivial topological phases rooted in the interplay between
magnetism and topology in the layered antiferromagnet EuCd2As2 have captured
vast attention, especially the ideal Weyl semimetal state realized in the
spin-polarized ferromagnetic (FM) structure driven by a moderate external
magnetic field. In this work, combining high-pressure magnetotransport
measurements, structure chracterizations and first principles calculations, we
find that application of pressure can also realize the ideal Weyl state in
EuCd2As2 through driving the in-plane antiferromagnetic state across an
intermediate in-plane FM state then into the out-of-plane FM state. Our
high-pressure angle dispersive X-ray diffraction and X-ray absorption near-edge
spectroscopy measurements excluded structure transition and/or change of Eu2+
valence state as the sources for the magnetic phase transitions. Alternatively,
the apparently reduced axial ratio (c/a) and compressed Eu-layer space distance
should play important roles. Our result provides an alternative way to realize
the ideal Weyl semimetal state in EuCd2As2 and would be instructive for the
exploration of exotic topological properties in such layered magnetic
topological phase with strongly competing magnetic exchanges by using high
pressure.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 08:33:03 GMT""}]","2022-02-15"
"2202.06017","Berk Ozturk","Dimitris Bertsimas and Berk \""Ozt\""urk","Global Optimization via Optimal Decision Trees","52 pages, 9 figures, 10 tables. Submitted to Operations Research",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The global optimization literature places large emphasis on reducing
intractable optimization problems into more tractable structured optimization
forms. In order to achieve this goal, many existing methods are restricted to
optimization over explicit constraints and objectives that use a subset of
possible mathematical primitives. These are limiting in real-world contexts
where more general explicit and black box constraints appear. Leveraging the
dramatic speed improvements in mixed-integer optimization (MIO) and recent
research in machine learning, we propose a new method to learn MIO-compatible
approximations of global optimization problems using optimal decision trees
with hyperplanes (OCT-Hs). This constraint learning approach only requires a
bounded variable domain, and can address both explicit and inexplicit
constraints. We solve the MIO approximation efficiently to find a near-optimal,
near-feasible solution to the global optimization problem. We further improve
the solution using a series of projected gradient descent iterations. We test
the method on a number of numerical benchmarks from the literature as well as
real-world design problems, demonstrating its promise in finding global optima
efficiently.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 08:35:03 GMT""}]","2022-02-15"
"2202.06018","Abasi-Amefon Affia","Abasi-amefon Obot Affia, Alexander Nolte, Raimundas Matulevi\v{c}ius","Integrating Hackathons into an Online Cybersecurity Course",,,"10.1145/3510456.3514151",,"cs.HC","http://creativecommons.org/licenses/by/4.0/","  Cybersecurity educators have widely introduced hackathons to facilitate
practical knowledge gaining in cybersecurity education. Introducing such events
into cybersecurity courses can provide valuable learning experiences for
students. The nature of the hackathon format encourages a learning-by-doing
approach, and the hackathon outcomes can serve as evidence for students
knowledge, capability and learning gains. Prior work on hackathons in education
mainly focused on collocated hackathon events in the traditional classroom
setting. These hackathon events often took place as a one-off event at the end
of the course. However, one-off hackathon events at the end of a course might
not be sufficient to improve learning. Instead, we focus on analyzing the
integration of a series of online hackathon events into an online cybersecurity
course and explore how this integration can address online education issues by
encouraging collaboration and developing a practical understanding of the
delivered course by solving real-world challenges. We evaluate interventions to
foster learning and analyze its effect on collaboration and learning gains for
students in the course. Our findings indicate that students attribute learning
benefits to the introduced interventions that supported teamwork and
collaboration, maintained student participation and interest in the course, and
encouraged learning-by-doing.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 08:57:02 GMT""}]","2022-02-15"
"2202.06019","Xian-Yu Wang","Xian-Yu Wang, Zhen-Yu Wu, Jing Liu, T. Hidayat","New analysis of the fraction of observable nights at astronomical sites
  based on FengYun-2 satellite data","9 pages, 5 figures; accepted for publication in MNRAS (Acceptation
  date: 2022 February 10)",,"10.1093/mnras/stac408",,"astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  The fraction of observable nights is an essential parameter for selecting
astronomical sites. In recent years, meteorological satellite data have played
an essential role in recognising and providing statistics of observable nights.
We present a method to estimate the fraction of observable nights based on the
FengYun-2 series of geostationary meteorological satellites and weather records
of multiple astronomical sites. We have calculated the fraction of observable
nights at 27 sites in Indonesia and two astronomical sites in China to validate
the method. The results derived from our method show good agreement with
previous works. Furthermore, we have derived the yearly distribution of the
fraction of observable nights above China, which indicates the area near
40$^{\circ}$N has more observable nights than other areas in China.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 08:58:06 GMT""}]","2022-03-14"
"2202.06020","Andrew Gitlin","Sylvie Corteel, Andrew Gitlin, David Keating","Colored vertex models and $k$-tilings of the Aztec diamond","41 pages",,,,"math.CO math.PR","http://creativecommons.org/licenses/by/4.0/","  We study $k$-tilings ($k$-tuples of domino tilings) of the Aztec diamond of
rank $m$. We assign a weight to each $k$-tiling, depending on the number of
dominos of certain types and the number of ""interactions"" between the tilings.
Employing the colored vertex models introduced in earlier work to study
supersymmetric LLT polynomials, we compute the generating polynomials of the
$k$-tilings. We then prove some combinatorial results about $k$-tilings,
including a bijection between $k$-tilings with no interactions and $1$-tilings,
and we compute the arctic curves of the tilings for $t=0$ and
$t\rightarrow\infty$. We also present some lozenge $k$-tilings of the hexagon
and compute the arctic curves of the tilings for $t=0$.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 09:08:40 GMT""},{""version"":""v2"",""created"":""Sat, 19 Mar 2022 00:04:28 GMT""}]","2022-03-22"
"2202.06021","Atul Sandur","Atul Sandur, ChanHo Park, Stavros Volos, Gul Agha, Myeongjae Jeon","Jarvis: Large-scale Server Monitoring with Adaptive Near-data Processing","[Best Paper Award] Published in Proceedings of the 38th IEEE
  International Conference on Data Engineering (ICDE) 2022",,,,"cs.DB cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Rapid detection and mitigation of issues that impact performance and
reliability is paramount for large-scale online services. For real-time
detection of such issues, datacenter operators use a stream processor and
analyze streams of monitoring data collected from servers (referred to as data
source nodes) and their hosted services. The timely processing of incoming
streams requires the network to transfer massive amounts of data, and
significant compute resources to process it. These factors often create
bottlenecks for stream analytics. To help overcome these bottlenecks, current
monitoring systems employ near-data processing by either computing an optimal
query partition based on a cost model or using model-agnostic heuristics.
Optimal partitioning is computationally expensive, while model-agnostic
heuristics are iterative and search over a large solution space. We combine
these approaches by using model-agnostic heuristics to improve the partitioning
solution from a model-based heuristic. Moreover, current systems use
operator-level partitioning: if a data source does not have sufficient
resources to execute an operator on all records, the operator is executed only
on the stream processor. Instead, we perform data-level partitioning, i.e., we
allow an operator to be executed both on a stream processor and data sources.
We implement our algorithm in a system called Jarvis, which enables quick
adaptation to dynamic resource conditions. Our evaluation on a diverse set of
monitoring workloads suggests that Jarvis converges to a stable query partition
within seconds of a change in node resource conditions. Compared to current
partitioning strategies, Jarvis handles up to 75% more data sources while
improving throughput in resource-constrained scenarios by 1.2-4.4x.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 09:09:09 GMT""},{""version"":""v2"",""created"":""Sun, 29 Jan 2023 10:28:39 GMT""}]","2023-01-31"
"2202.06022","Cristian Botezatu","Cristian Botezatu, Mathias Ibsen, Christian Rathgeb, Christoph Busch","Fun Selfie Filters in Face Recognition: Impact Assessment and Removal",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work investigates the impact of fun selfie filters, which are frequently
used to modify selfies, on face recognition systems. Based on a qualitative
assessment and classification of freely available mobile applications, ten
relevant fun selfie filters are selected to create a database. To this end, the
selected filters are automatically applied to face images of public face image
databases. Different state-of-the-art methods are used to evaluate the
influence of fun selfie filters on the performance of face detection using
dlib, RetinaFace, and a COTS method, sample quality estimated by FaceQNet and
MagFace, and recognition accuracy employing ArcFace and a COTS algorithm. The
obtained results indicate that selfie filters negatively affect face
recognition modules, especially if fun selfie filters cover a large region of
the face, where the mouth, nose, and eyes are covered. To mitigate such
unwanted effects, a GAN-based selfie filter removal algorithm is proposed which
consists of a segmentation module, a perceptual network, and a generation
module. In a cross-database experiment the application of the presented selfie
filter removal technique has shown to significantly improve the biometric
performance of the underlying face recognition systems.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 09:12:31 GMT""}]","2022-02-15"
"2202.06023","Quoc Van Tran Dr.","Quoc Van Tran and Jinwhan Kim","Bearing-constrained Formation Tracking Control of Nonholonomic Agents
  without Inter-agent Communication","8 pages, Manuscript submitted to the IEEE Control Systems Letters
  (L-CSS)",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This letter presents two bearing-constrained formation tracking control
protocols for multiple nonholonomic agents based respectively on the bearing
vectors and displacements between the agents. The desired formation pattern of
the system is specified by the desired inter-agent bearing vectors. In the
proposed control schemes, there are two or more leaders moving with the same
constant velocity; the other follower agents do not have the information of the
leaders' velocity nor communicate variables with their neighbors. Under both
the proposed control laws, the system achieves the moving target formation
asymptotically. Simulation results are provided to support the theoretical
development.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 09:22:43 GMT""}]","2022-02-15"
"2202.06024","Anastasiia Hraivoronska","Anastasiia Hraivoronska and Oliver Tse","Diffusive limit of random walks on tessellations via generalized
  gradient flows",,,,,"math.AP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study asymptotic limits of reversible random walks on tessellations via a
variational approach, which relies on a specific generalized-gradient-flow
formulation of the corresponding forward Kolmogorov equation. We establish
sufficient conditions on sequences of tessellations and jump intensities under
which a sequence of random walks converges to a diffusion process with a
possibly spatially-dependent diffusion tensor.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 09:33:03 GMT""}]","2022-02-15"
"2202.06025","Chuanming Zong","Miao Fu, Fei Xue and Chuanming Zong","Lower Bounds on Lattice Covering Densities of Simplices","16 pages, 4 figures",,,,"math.MG math.CO","http://creativecommons.org/licenses/by/4.0/","  This paper presents new lower bounds for the lattice covering densities of
simplices by studying the Degree-Diameter Problem for abelian Cayley digraphs.
In particular, it proves that the density of any lattice covering of a
tetrahedron is at least $25/18$ and the density of any lattice covering of a
four-dimensional simplex is at least $343/264$.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 09:35:47 GMT""}]","2022-02-15"
"2202.06026","Gian Piero Puccioni","G.L. Lippi, T. Wang, G.P. Puccioni","""Phase Transitions"" in small systems: why standard threshold definitions
  fail for nanolasers","Main article: 29 pages, 24 figures Supplementary material: 16 pages,
  25 figures",,"10.1016/j.chaos.2022.111850",,"physics.optics","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Since the development of micro- and nanolasers, the question of laser
threshold has been subject to debate. Different definitions have been used to
try and establish its occurrence, often encountering major obstacles. We
examine a set of common physical definitions which we apply to measurements
taken in a micro-VCSEL. Their predictions not only clearly disagree, pointing
to different pump values at which the laser should cross threshold, but they
also correspond to autocorrelation values which demonstrate very low field
coherence. A topological analysis of the rate equations, with average
spontaneous emission added to the lasing mode, clearly identifies the
contradictions and explains the origin of the discrepancies. Additional
considerations help understanding the failure of the approach and highlight the
path towards a unique and general definition of threshold in all lasers,
irrespective of their sizes. A critical scrutiny of the assumptions made in the
rate equations with spontaneous emission illustrates their strength and
weaknesses and better defines the bounds within which their predictions hold.
We remark in the conclusions how the main results of this paper could hold for
other small systems.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 09:45:24 GMT""}]","2022-03-14"
"2202.06027","Wei Jing","Tianying Wang, En Yen Puang, Marcus Lee, Yan Wu, Wei Jing","End-to-end Reinforcement Learning of Robotic Manipulation with Robust
  Keypoints Representation","8 pages",,,,"cs.RO cs.CV","http://creativecommons.org/licenses/by/4.0/","  We present an end-to-end Reinforcement Learning(RL) framework for robotic
manipulation tasks, using a robust and efficient keypoints representation. The
proposed method learns keypoints from camera images as the state
representation, through a self-supervised autoencoder architecture. The
keypoints encode the geometric information, as well as the relationship of the
tool and target in a compact representation to ensure efficient and robust
learning. After keypoints learning, the RL step then learns the robot motion
from the extracted keypoints state representation. The keypoints and RL
learning processes are entirely done in the simulated environment. We
demonstrate the effectiveness of the proposed method on robotic manipulation
tasks including grasping and pushing, in different scenarios. We also
investigate the generalization capability of the trained model. In addition to
the robust keypoints representation, we further apply domain randomization and
adversarial training examples to achieve zero-shot sim-to-real transfer in
real-world robotic manipulation tasks.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 09:58:09 GMT""}]","2022-02-15"
"2202.06028","Chunyang Fu","Chunyang Fu, Ge Li, Rui Song, Wei Gao, Shan Liu","OctAttention: Octree-Based Large-Scale Contexts Model for Point Cloud
  Compression","Accepted by AAAI 2022","Proceedings of the AAAI Conference on Artificial Intelligence
  36(1):625-633, June 2022","10.1609/aaai.v36i1.19942",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In point cloud compression, sufficient contexts are significant for modeling
the point cloud distribution. However, the contexts gathered by the previous
voxel-based methods decrease when handling sparse point clouds. To address this
problem, we propose a multiple-contexts deep learning framework called
OctAttention employing the octree structure, a memory-efficient representation
for point clouds. Our approach encodes octree symbol sequences in a lossless
way by gathering the information of sibling and ancestor nodes. Expressly, we
first represent point clouds with octree to reduce spatial redundancy, which is
robust for point clouds with different resolutions. We then design a
conditional entropy model with a large receptive field that models the sibling
and ancestor contexts to exploit the strong dependency among the neighboring
nodes and employ an attention mechanism to emphasize the correlated nodes in
the context. Furthermore, we introduce a mask operation during training and
testing to make a trade-off between encoding time and performance. Compared to
the previous state-of-the-art works, our approach obtains a 10%-35% BD-Rate
gain on the LiDAR benchmark (e.g. SemanticKITTI) and object point cloud dataset
(e.g. MPEG 8i, MVUB), and saves 95% coding time compared to the voxel-based
baseline. The code is available at https://github.com/zb12138/OctAttention.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 10:06:12 GMT""},{""version"":""v2"",""created"":""Sun, 8 May 2022 02:40:28 GMT""}]","2022-08-30"
"2202.06029","Boby Joseph","Govindaraj Lingannan, Boby Joseph, Muthukumaran Sundaramoorthy, Chia
  Nung Kuo, Chin Shan Lue, Sonachalam Arumugam","Pressure-enhanced superconductivity in cage-type quasiskutterudite
  Sc5Rh6Sn18 single crystal",,"Journal of Physics: Condensed Matter (2022)","10.1088/1361-648X/ac61b6",,"cond-mat.supr-con cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sc5Rh6Sn18 with a cage-type quasiskutterudite crystal lattice and type II
superconductivity, with superconducting transition temperature Tc = 4.99 K, was
investigated under hydrostatic high-pressure (HP) using electrical transport,
synchrotron X-ray diffraction (XRD) and Raman spectroscopy. Our data show that
HP enhance the metallic nature and Tc of the system. Tc is found to show a
continuous increase reaching to 5.24 K at 2.5 GPa. Athough the system is
metallic in nature, Raman spectroscopy investigations at ambient pressure
revealed the presence of three weak modes at 165.97, 219.86 and 230.35 cm-1,
mostly related to the rattling atom Sc. The HP-XRD data revealed that the cage
structure was stable without any structural phase transition up to ~7 GPa. The
lattice parameters and volume exhibited a smooth decrease without any anomalies
as a function of pressure in this pressure range. In particular, a second order
Birch-Murnaghan equation of state can describe the pressure dependence of the
unit cell volume well, yielding a bulk modulus of ~ 97 GPa. HP Raman
investigations revealed a linear shift of all the three Raman modes to higher
wavenumbers with increasing pressure up to ~8 GPa. As the pressure enhances the
bond overlap, thus inducing more electronic charges into the system, HP-XRD and
Raman results may indciate the possibility of obtaining higher Tc with
increasing pressures in this pressure range.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 10:08:28 GMT""},{""version"":""v2"",""created"":""Tue, 29 Mar 2022 09:56:45 GMT""}]","2022-03-30"
"2202.06030","Sankar Davuluri","Sankar Davuluri, Yong Li","Light as quantum back-action nullifying meter","6 pages, 1 figure",,"10.1364/JOSAB.462699",,"physics.optics quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new method to overcome quantum back-action in a measurement
process using oscillators. An optical oscillator is used as a meter to measure
the parameters of another open oscillator. The optical oscillator is
synthesized such that the optical restoring force counters any perturbations
induced by the quantum back-action phenomena. As a result, it is shown that the
quantum back-action in continuous measurement is suppressed in the low
frequency regime i.e., for frequencies much smaller than the resonance
frequency of the open oscillator. As the meter plays the role of measuring
parameters as well as suppressing the quantum back-action, we call it as
quantum back-action nullifying meter. As an application of this method,
synthesis of quantum back-action nullifying optical oscillator for suppressing
radiation pressure force noise in linear and non-linear optomechanics is
described.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 10:09:12 GMT""}]","2022-11-23"
"2202.06031","Bruno Klingler","Bruno Klingler and Leonardo A. Lerer","Abelian differentials and their periods: the bi-algebraic point of view",,,,,"math.NT math.AG math.GT","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We study the transcendence of periods of abelian differentials, both at the
arithmetic and functional level, from the point of view of the natural
bi-algebraic structure on strata of abelian differentials. We characterise
geometrically the arithmetic points, study their distribution, and prove that
in many cases the bi-algebraic curves are the linear ones.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 10:12:05 GMT""}]","2022-02-15"
"2202.06032","Hiroshi Oike","Hiroshi Oike, Kazuya Miyagawa, Hiromi Taniguchi, Hiroyuki Okamoto,
  Kazushi Kanoda","Metal-insulator transition via control of spin liquidity in a doped Mott
  insulator",,,,,"cond-mat.str-el cond-mat.mtrl-sci cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum spin liquid states, in which spins are quantum-mechanically
delocalized in direction, have been so far studied for charge-localized Mott
insulators arising from strong repulsive interaction. Recently, however, it was
found that the doped Mott insulator with a triangular lattice,
$\kappa$-(ET)$_4$Hg$_{2.89}$Br$_8$, exhibits both spin-liquid-like magnetism
and metallic electrical conduction. Thus, it is now possible to experimentally
explore how the spin liquidity affects the electrical conduction, an issue that
has received a great deal of theoretical attention. Here, with a newly
developed method to combine uniaxial and hydrostatic pressures, we investigate
the electrical conduction in the doped Mott insulator with controlling the
triangular lattice geometry and the repulsion strength which determines the
spin-liquidity and Mottness, respectively. We found that, in a strongly
interacting regime, the electronic state drastically changes from an insulator
to a Fermi liquid via a non-Fermi liquid with varying geometrical frustration,
which suggests that spin liquidity promotes delocalization of charges. This
result indicates that frustration in spin degrees of freedom has a decisive
impact on the transport of charges through the entanglement of spin and charge
in a doped Mott insulator.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 10:24:44 GMT""}]","2022-02-15"
"2202.06033","Anastasiia Birillo","Anastasiia Birillo, Elena Lyulina, Maria Malysheva, Vladislav Tankov,
  Timofey Bryksin","Reflekt: a Library for Compile-Time Reflection in Kotlin","10 pages, 10 figures",,"10.1145/3510457.3513053",,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Reflection in Kotlin is a powerful mechanism to introspect program behavior
during its execution at run-time. However, among the variety of practical tasks
involving reflection, there are scenarios when the poor performance of run-time
approaches becomes a significant disadvantage. This problem manifests itself in
Kotless, a popular framework for developing serverless applications, because
the faster the applications launch, the less their cloud infrastructure costs.
In this paper, we present Reflekt - a compile-time reflection library which
allows to perform the search among classes, object expressions (which in Kotlin
are implemented as singleton classes), and functions in Kotlin code based on
the given search query. It comes with a convenient DSL and better performance
comparing to the existing run-time reflection approaches. Our experiments show
that replacing run-time reflection calls with Reflekt in serverless
applications created with Kotless resulted in a significant performance boost
in start-up time of these applications.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 10:32:13 GMT""},{""version"":""v2"",""created"":""Tue, 15 Feb 2022 18:18:34 GMT""}]","2022-02-16"
"2202.06034","Hao-Wen Dong","Hao-Wen Dong, Cong Zhou, Taylor Berg-Kirkpatrick, Julian McAuley","Deep Performer: Score-to-Audio Music Performance Synthesis","ICASSP 2022 final version with appendix",,,,"cs.SD cs.LG cs.MM eess.AS eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Music performance synthesis aims to synthesize a musical score into a natural
performance. In this paper, we borrow recent advances in text-to-speech
synthesis and present the Deep Performer -- a novel system for score-to-audio
music performance synthesis. Unlike speech, music often contains polyphony and
long notes. Hence, we propose two new techniques for handling polyphonic inputs
and providing a fine-grained conditioning in a transformer encoder-decoder
model. To train our proposed system, we present a new violin dataset consisting
of paired recordings and scores along with estimated alignments between them.
We show that our proposed model can synthesize music with clear polyphony and
harmonic structures. In a listening test, we achieve competitive quality
against the baseline model, a conditional generative audio model, in terms of
pitch accuracy, timbre and noise level. Moreover, our proposed model
significantly outperforms the baseline on an existing piano dataset in overall
quality.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 10:36:52 GMT""},{""version"":""v2"",""created"":""Mon, 21 Feb 2022 03:29:43 GMT""}]","2022-02-22"
"2202.06035","David Walter","David Walter","Measurement of top-quark electroweak couplings in associated top quark
  production with vector bosons at the ATLAS and CMS experiments","Contribution to the he European Physical Society Conference on High
  Energy Physics (EPS-HEP2021)",,,,"hep-ex","http://creativecommons.org/licenses/by/4.0/","  Recent analyses of top quark production in association with vector bosons are
summarized, representing the most precise inclusive and differential cross
section measurements of these processes to date. Proton-proton collision data
at a center-of-mass energy of $\sqrt{s}=13$ TeV, recorded by the ATLAS and CMS
detectors at the LHC are analyzed, corresponding to an integrated luminosity of
up to 139 fb$^{-1}$ for each experiment. Comparisons with theory calculations
are performed and overall good agreement with standard model predictions are
obtained.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 10:44:29 GMT""}]","2022-02-15"
"2202.06036","Luca Viano","Luca Viano and Johanni Brea","Neural NID Rules","Physical Reasoning and Inductive Biases for the Real World at NeurIPS
  2021",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Abstract object properties and their relations are deeply rooted in human
common sense, allowing people to predict the dynamics of the world even in
situations that are novel but governed by familiar laws of physics. Standard
machine learning models in model-based reinforcement learning are inadequate to
generalize in this way. Inspired by the classic framework of noisy
indeterministic deictic (NID) rules, we introduce here Neural NID, a method
that learns abstract object properties and relations between objects with a
suitably regularized graph neural network. We validate the greater
generalization capability of Neural NID on simple benchmarks specifically
designed to assess the transition dynamics learned by the model.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 10:47:06 GMT""}]","2022-02-15"
"2202.06037","Valentyna Sheminova","V. A. Sheminova","Macro-microturbulence in the solar photosphere","5 pages, 4 figures, published by Kinematics Phys. Celest. Bodies,
  1985, Vol. 1, p. 50-52. In Russian","Kinematics and Physics of Celestial Bodies, 1. (1985), p. 50-52",,,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The velocity distribution of the large and small-scale motion in solar
photosphere has been obtained by crossing method based on fitting the observed
and calculated equivalent widths as well as the central depths of the spectral
lines at the center of the and the limb of the solar disk. We used about 200 Fe
I lines. According to our results the motions in photosphere are anisotropic.
The radial component of microturbulent velocity decreases from 1.0 to 0.3 km/s
and the tangential one from 1.7 to 1.3 km/c at the photosphere heights from 200
to 500 km (log tau_5 = -1.4 and -3.5). At the same heights the radial component
of the macroturbulent velocity decreases from 1.8 to 1.2 km/s and the
tangential one from 2.3 to 0.8 km/s.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 10:51:41 GMT""}]","2022-02-15"
"2202.06038","David Walter","David Walter","Rare top quark production in CMS","Contribution to the Blois 2021 Conference: 32nd Rencontres de Blois
  on ""Particle Physics and Cosmology"" 17-22 Oct 2021",,,,"hep-ex","http://creativecommons.org/licenses/by/4.0/","  Latest results from the CMS experiment at the LHC on top quark production in
association with a Z boson or a photon, and the production of four top quarks,
are summarized. Proton-proton collision data corresponding to an integrated
luminosity of up to 138 fb$^{-1}$, collected at 13 TeV center-of-mass energy
are used. Among the measured results, most precise inclusive cross sections,
most stringent limits on models beyond the standard model and first
differential measurements are presented. Overall, good agreement with standard
model predictions is observed.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 10:54:46 GMT""}]","2022-02-15"
"2202.06039","Zaid Saeed Khan","Zaid Saeed Khan, Weili He, Monica Menendez","Application of Modular Vehicle Technology to Mitigate Bus Bunching","25 pages, 10 figures, 3 tables",,"10.1016/j.trc.2022.103953",,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The stochastic nature of public transport systems leads to headway
variability and bus bunching, causing both operator and passenger cost to
increase significantly. Traditional strategies to counter bus bunching,
including bus-holding, stop-skipping, and bus substitution/insertion, suffer
from trade-offs and shortcomings. Autonomous modular vehicle (AMV) technology
provides an additional level of flexibility in bus dispatching and operations,
which can offer significant benefits in mitigating bus bunching compared to
strategies available with conventional buses. This paper introduces a novel
alternative to stop-skipping by leveraging the new capabilities offered by AMVs
(in particular, en-route coupling and decoupling of modular units). We develop
a simple bus-splitting strategy that directs a modular bus to decouple into
individual units when it experiences a headway longer than a given threshold.
We then use a macroscopic simulation to present a proof-of-concept evaluation
of the proposed modular strategy compared to a benchmark traditional
stop-skipping strategy and the base (no control) case. We find that the
proposed strategy outperforms the benchmark in decreasing each of the three
travel time components: waiting time, in-vehicle time, and walking time (which
it eliminates completely). It therefore reduces the overhead of bus bunching
and thus the travel cost by more than twice as much as the benchmark for busy
bus lines. Simultaneously, it also reduces headway variability to a comparable
degree. Furthermore, we analyze different control thresholds for applying the
proposed strategy, and show that it is most effective when applied proactively,
i.e. with the control action being triggered even by small headway deviations.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 10:55:21 GMT""}]","2023-01-26"
"2202.06040","Gowtham Raghunath Kurri","Gowtham R. Kurri, Oliver Kosut, Lalitha Sankar","A Variational Formula for Infinity-R\'{e}nyi Divergence with
  Applications to Information Leakage","Accepted to ISIT 2022, 6 pages",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a variational characterization for the R\'{e}nyi divergence of
order infinity. Our characterization is related to guessing: the objective
functional is a ratio of maximal expected values of a gain function applied to
the probability of correctly guessing an unknown random variable. An important
aspect of our variational characterization is that it remains agnostic to the
particular gain function considered, as long as it satisfies some regularity
conditions. Also, we define two variants of a tunable measure of information
leakage, the maximal $\alpha$-leakage, and obtain closed-form expressions for
these information measures by leveraging our variational characterization.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 10:59:36 GMT""},{""version"":""v2"",""created"":""Mon, 2 May 2022 11:57:33 GMT""}]","2022-05-03"
"2202.06041","Oriol Domingo","Oriol Domingo, Marta R. Costa-juss\`a and Carlos Escolano","A multi-task semi-supervised framework for Text2Graph & Graph2Text","5 pages, 2 figures, 3 tables and 8 equations",,,,"cs.CL cs.IR","http://creativecommons.org/licenses/by/4.0/","  The Artificial Intelligence industry regularly develops applications that
mostly rely on Knowledge Bases, a data repository about specific, or general,
domains, usually represented in a graph shape. Similar to other databases, they
face two main challenges: information ingestion and information retrieval. We
approach these challenges by jointly learning graph extraction from text and
text generation from graphs. The proposed solution, a T5 architecture, is
trained in a multi-task semi-supervised environment, with our collected
non-parallel data, following a cycle training regime. Experiments on WebNLG
dataset show that our approach surpasses unsupervised state-of-the-art results
in text-to-graph and graph-to-text. More relevantly, our framework is more
consistent across seen and unseen domains than supervised models. The resulting
model can be easily trained in any new domain with non-parallel data, by simply
adding text and graphs about it, in our cycle framework.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 11:02:17 GMT""},{""version"":""v2"",""created"":""Fri, 18 Feb 2022 19:31:34 GMT""}]","2022-02-22"
"2202.06042","Fan Yang","Fan Yang, Xu-zhi Zhou, Jing-huan Li, Qiu-Gang Zong, Shu-Tao Yao,
  Quan-Qi Shi, Anton V. Artemyev","Kinetic-scale flux ropes: Observations and applications of kinetic
  equilibrium models","Accepted by Astrophysical Journal (ApJ), 15 pages, 5 figures","ApJ 926 208 (2022)","10.3847/1538-4357/ac47f9",,"physics.space-ph physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  Magnetic flux ropes with helical field lines and strong core field are
ubiquitous structures in space plasmas. Recently, kinetic-scale flux ropes have
been identified by high-resolution observations from Magnetospheric Multiscale
(MMS) spacecraft in the magnetosheath, which have drawn a lot of attention
because of their non-ideal behavior and internal structures. Detailed
investigation of flux rope structure and dynamics requires development of
realistic kinetic models. In this paper, we generalize an equilibrium model to
reconstruct a kinetic-scale flux rope previously reported via MMS observations.
The key features in the magnetic field and electron pitch-angle distribution
measurements of all four satellites are simultaneously reproduced in this
reconstruction. Besides validating the model, our results also indicate that
the anisotropic features previously attributed to asymmetric magnetic
topologies in the magnetosheath can be alternatively explained by the
spacecraft motion in the flux rope rest frame.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 11:19:20 GMT""}]","2022-03-01"
"2202.06043","Zhen Li","Zhen Li, Guenevere (Qian) Chen, Chen Chen, Yayi Zou, Shouhuai Xu","RoPGen: Towards Robust Code Authorship Attribution via Automatic Coding
  Style Transformation","ICSE 2022",,"10.1145/3510003.3510181",,"cs.CR cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Source code authorship attribution is an important problem often encountered
in applications such as software forensics, bug fixing, and software quality
analysis. Recent studies show that current source code authorship attribution
methods can be compromised by attackers exploiting adversarial examples and
coding style manipulation. This calls for robust solutions to the problem of
code authorship attribution. In this paper, we initiate the study on making
Deep Learning (DL)-based code authorship attribution robust. We propose an
innovative framework called Robust coding style Patterns Generation (RoPGen),
which essentially learns authors' unique coding style patterns that are hard
for attackers to manipulate or imitate. The key idea is to combine data
augmentation and gradient augmentation at the adversarial training phase. This
effectively increases the diversity of training examples, generates meaningful
perturbations to gradients of deep neural networks, and learns diversified
representations of coding styles. We evaluate the effectiveness of RoPGen using
four datasets of programs written in C, C++, and Java. Experimental results
show that RoPGen can significantly improve the robustness of DL-based code
authorship attribution, by respectively reducing 22.8% and 41.0% of the success
rate of targeted and untargeted attacks on average.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 11:27:32 GMT""}]","2022-02-15"
"2202.06044","Haokun Li","Haokun Li, Bican Xia and Tianqi Zhao","Square-free Strong Triangular Decomposition of Zero-dimensional
  Polynomial Systems",,,,,"cs.SC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Triangular decomposition with different properties has been used for various
types of problem solving, e.g. geometry theorem proving, real solution
isolation of zero-dimensional polynomial systems, etc. In this paper, the
concepts of strong chain and square-free strong triangular decomposition
(SFSTD) of zero-dimensional polynomial systems are defined. Because of its good
properties, SFSTD may be a key way to many problems related to zero-dimensional
polynomial systems, such as real solution isolation and computing radicals of
zero-dimensional ideals. Inspired by the work of Wang and of Dong and Mou, we
propose an algorithm for computing SFSTD based on Gr\""obner bases computation.
The novelty of the algorithm is that we make use of saturated ideals and
separant to ensure that the zero sets of any two strong chains have no
intersection and every strong chain is square-free, respectively. On one hand,
we prove that the arithmetic complexity of the new algorithm can be single
exponential in the square of the number of variables, which seems to be among
the rare complexity analysis results for triangular-decomposition methods. On
the other hand, we show experimentally that, on a large number of examples in
the literature, the new algorithm is far more efficient than a popular
triangular-decomposition method based on pseudo-division. Furthermore, it is
also shown that, on those examples, the methods based on SFSTD for real
solution isolation and for computing radicals of zero-dimensional ideals are
very efficient.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 11:33:04 GMT""}]","2022-02-15"
"2202.06045","Bolaji Yusuf","Bolaji Yusuf, Ankur Gandhe and Alex Sokolov","USTED: Improving ASR with a Unified Speech and Text Encoder-Decoder","2022 IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP 2022)",,,,"cs.CL cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Improving end-to-end speech recognition by incorporating external text data
has been a longstanding research topic. There has been a recent focus on
training E2E ASR models that get the performance benefits of external text data
without incurring the extra cost of evaluating an external language model at
inference time. In this work, we propose training ASR model jointly with a set
of text-to-text auxiliary tasks with which it shares a decoder and parts of the
encoder. When we jointly train ASR and masked language model with the 960-hour
Librispeech and Opensubtitles data respectively, we observe WER reductions of
16% and 20% on test-other and test-clean respectively over an ASR-only baseline
without any extra cost at inference time, and reductions of 6% and 8% compared
to a stronger MUTE-L baseline which trains the decoder with the same text data
as our model. We achieve further improvements when we train masked language
model on Librispeech data or when we use machine translation as the auxiliary
task, without significantly sacrificing performance on the task itself.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 11:35:59 GMT""}]","2022-02-15"
"2202.06046","Ziye Jia","Ziye Jia, Qihui Wu, Chao Dong, Chau Yuen, and Zhu Han","Hierarchical Aerial Computing for Internet of Things via Cooperation of
  HAPs and UAVs",,,,,"cs.NI eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the explosive increment of computation requirements, the multi-access
edge computing (MEC) paradigm appears as an effective mechanism. Besides, as
for the Internet of Things (IoT) in disasters or remote areas requiring MEC
services, unmanned aerial vehicles (UAVs) and high altitude platforms (HAPs)
are available to provide aerial computing services for these IoT devices. In
this paper, we develop the hierarchical aerial computing framework composed of
HAPs and UAVs, to provide MEC services for various IoT applications. In
particular, the problem is formulated to maximize the total IoT data computed
by the aerial MEC platforms, restricted by the delay requirement of IoT and
multiple resource constraints of UAVs and HAPs, which is an integer programming
problem and intractable to solve. Due to the prohibitive complexity of
exhaustive search, we handle the problem by presenting the matching game theory
based algorithm to deal with the offloading decisions from IoT devices to UAVs,
as well as a heuristic algorithm for the offloading decisions between UAVs and
HAPs. The external effect affected by interplay of different IoT devices in the
matching is tackled by the externality elimination mechanism. Besides, an
adjustment algorithm is also proposed to make the best of aerial resources. The
complexity of proposed algorithms is analyzed and extensive simulation results
verify the efficiency of the proposed algorithms, and the system performances
are also analyzed by the numerical results.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 11:39:42 GMT""}]","2022-02-15"
"2202.06047","Bin Liu","Bin Liu, Frederik Geth, Nariman Mahdavi, Jiangxia Zhong","Load Balancing in Low-Voltage Distribution Networks via Optimizing
  Residential Phase Connections","The paper has been submitted to and accepted by IEEE PES Innovative
  Smart Grid Technologies Conference Asia (ISGT Asia 2021)","proceedings of IEEE Innovative Smart Grid Technologies Conference
  Asia (ISGT Asia 2021)",,,"math.OC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Unbalance issues in low-voltage distribution networks (LVDN) can be worsened
by increasing penetration of residential PV generation if unevenly distributed
among three phases. To address this issue, the phase-switching device (PSD)
provides a viable and efficient method by dynamically switching customers to
other phases. This paper further investigates how to optimize residential phase
connections by controlling PSDs efficiently. The optimization problem is
formulated as a mixed-integer non-convex programming (MINCP) problem
considering relevant operational requirements of an LVDN based on the exact
formulation of unbalanced three-phase optimal power flow (UTOPF). Unlike most
heuristic algorithms and the linearization techniques in our previous work,
this paper proposes to solve the MINCP problem via an iteration-based algorithm
after exact reformulations and reasonable approximations of some constraints.
The proposed method is tested in a real LVDN and compared with the approach of
Zhao et al. based on the well-known linear UTOPF formulation. Case studies
based on the European low-voltage test feeder demonstrate the proposed method's
efficiency in mitigating the network unbalance while ensuring network security
and flexibility to deal with more controllable resources.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 11:43:21 GMT""}]","2022-02-15"
"2202.06048","Thomas Bracht","Thomas K. Bracht, Tim Seidelmann, Tilmann Kuhn, V. Martin Axt, Doris
  E. Reiter","Phonon wave packet emission during state preparation of a semiconductor
  quantum dot using different schemes",,,"10.1002/pssb.202100649",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The carrier-phonon interaction in semiconductor quantum dots can greatly
affect the optical preparation of the excited state. For resonant excitation
used in the Rabi preparation scheme, the polaron is formed accompanied by the
emission of a phonon wave packet, leading to a degradation of preparation
fidelity. In this paper, phonon wave packets for different coherent excitation
schemes are analyzed. One example is the adiabatic rapid passage scheme relying
on a chirped excitation. Here, also a phonon wave packet is emitted, but the
preparation fidelity can still be approximately unity. A focus is on the phonon
impact on a recently proposed swing-up scheme, induced by two detuned pulses.
Similar to the Rabi scheme, a degradation and a phonon wave packet emission is
found, despite the detuning. If the swing-up frequency coincides with the
maximum of the phonon spectral density, a series of wave packets is emitted
yielding an even stronger degradation. The insight gained from our results will
further help in designing an optimal preparation scheme for quantum dots.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 11:48:15 GMT""},{""version"":""v2"",""created"":""Tue, 15 Feb 2022 10:09:17 GMT""}]","2022-06-29"
"2202.06049","A. Nihat Berker","Egemen Tunca and A. Nihat Berker","Renormalization-Group Theory of the Heisenberg Model in d Dimensions","5 pages, 5 figures",,"10.1016/j.physa.2022.128300",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The classical Heisenberg model has been solved in spatial d dimensins,
exactly in d=1 and by the Migdal-Kadanoff approximation in d>1, by using a
Fourier-Legendre expansion. The phase transition temperatures, the energy
densities, and the specific heats are calculated in arbitrary dimension d.
Fisher's exact result is recovered in d=1. The absence of an ordered phase,
conventional or algebraic (in contrast to the XY model yielding an
algebraically ordered phase), is recovered in d=2. A conventionally ordered
phase occurs at d>2. This method opens the way to complex-system calculations
with Heisenberg local degrees of freedom.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 12:07:43 GMT""}]","2022-12-14"
"2202.06050","Marcus Scheele","Korath Shivan Sugi, Andre Maier, and Marcus Scheele","Emergent properties in supercrystals of atomically precise nanocluster
  and colloidal nanocrystals","19 pages, 15 Figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We provide a comprehensive account of the optical, electrical and mechanical
properties that emerge from the self-assembly of colloidal nanocrystals or
atomically precise nanoclusters into crystalline arrays with long-range order.
We compare the correlation between the supercrystalline structure and these
emergent properties with similar correlations in crystals of atoms to address
the hypothesis that nanocrystals and nanoclusters exhibit quasi-atomic
behaviour. We come to the conclusion that, effectively, this analogy is indeed
justified, although the chemical origin for the same emergent properties are
substantially different in crystals of atoms vs. supercrystals. We provide an
outlook onto the most promising applications of supercrystals of nanocrystals
and nanoclusters and discuss the challenges to be overcome before their
commercialization.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 12:35:47 GMT""}]","2022-02-15"
"2202.06051","Alexandre Deur","S. J. Brodsky, A. Deur, C. D. Roberts","Artificial Dynamical Effects in Quantum Field Theory","21 page, 4 Figure. A version of this document, amended during the
  peer consultation process, has been accepted for publication in Nature
  Reviews Physics","Nature Reviews Physics vol. 4 489-495 (2022)","10.1038/s42254-022-00453-3","SLAC-PUB-17618; JLAB-PHY-21-3526; NJU-INP 048/21","hep-ph hep-lat hep-th nucl-th","http://creativecommons.org/licenses/by/4.0/","  In Newtonian mechanics, inertial pseudoforces - or fictitious forces - appear
in systems studied in non-Galilean reference frames; e.g., a centrifugal force
seems to arise if the dynamics is analyzed in a rotating reference frame. The
equivalent of Galilean invariance for relativistic kinematics is Poincar\'e
invariance; analogous artificial effects may arise in relativistic quantum
field theory (QFT) if a system is studied in a framework violating Poincar\'e
invariance. We highlight how such issues complicate the traditional canonical
quantization of QFTs and can lead to a subjective description of natural
phenomena. In fact, if the system involves the strong interaction, obtaining
objective results can become an intractable problem using canonical
quantization because the pseudoforces are essentially nonperturbative. In
contrast, the treatment of the same problem using light-front (LF) quantization
is free of spurious pseudoeffects because Poincar\'e invariance is manifest;
thus the treatment of strong interaction problems becomes simpler. These
statements are illustrated using several examples: the Gerasimov-Drell-Hearn
(GDH) relation, a fundamental feature of QFT; the absence of any measurable
impact of Lorentz contraction in high-energy collisions; and the fictitious
character of vacuum fluctuation contributions to the cosmological constant.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 12:36:17 GMT""}]","2022-11-14"
"2202.06052","Sebastian Weichwald","Sebastian Weichwald, S{\o}ren Wengel Mogensen, Tabitha Edith Lee,
  Dominik Baumann, Oliver Kroemer, Isabelle Guyon, Sebastian Trimpe, Jonas
  Peters, Niklas Pfister","Learning by Doing: Controlling a Dynamical System using Causality,
  Control, and Reinforcement Learning","https://learningbydoingcompetition.github.io/",,,,"cs.LG cs.RO cs.SY eess.SY stat.ME stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Questions in causality, control, and reinforcement learning go beyond the
classical machine learning task of prediction under i.i.d. observations.
Instead, these fields consider the problem of learning how to actively perturb
a system to achieve a certain effect on a response variable. Arguably, they
have complementary views on the problem: In control, one usually aims to first
identify the system by excitation strategies to then apply model-based design
techniques to control the system. In (non-model-based) reinforcement learning,
one directly optimizes a reward. In causality, one focus is on identifiability
of causal structure. We believe that combining the different views might create
synergies and this competition is meant as a first step toward such synergies.
The participants had access to observational and (offline) interventional data
generated by dynamical systems. Track CHEM considers an open-loop problem in
which a single impulse at the beginning of the dynamics can be set, while Track
ROBO considers a closed-loop problem in which control variables can be set at
each time step. The goal in both tracks is to infer controls that drive the
system to a desired state. Code is open-sourced (
https://github.com/LearningByDoingCompetition/learningbydoing-comp ) to
reproduce the winning solutions of the competition and to facilitate trying out
new methods on the competition tasks.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 12:37:29 GMT""}]","2022-02-15"
"2202.06053","Mahawaga Arachchige Pathum Chamikara","M.A.P. Chamikara, Dongxi Liu, Seyit Camtepe, Surya Nepal, Marthie
  Grobler, Peter Bertok, Ibrahim Khalil","Local Differential Privacy for Federated Learning","17 pages",,,,"cs.CR cs.DB","http://creativecommons.org/licenses/by/4.0/","  Advanced adversarial attacks such as membership inference and model
memorization can make federated learning (FL) vulnerable and potentially leak
sensitive private data. Local differentially private (LDP) approaches are
gaining more popularity due to stronger privacy notions and native support for
data distribution compared to other differentially private (DP) solutions.
However, DP approaches assume that the FL server (that aggregates the models)
is honest (run the FL protocol honestly) or semi-honest (run the FL protocol
honestly while also trying to learn as much information as possible). These
assumptions make such approaches unrealistic and unreliable for real-world
settings. Besides, in real-world industrial environments (e.g., healthcare),
the distributed entities (e.g., hospitals) are already composed of locally
running machine learning models (this setting is also referred to as the
cross-silo setting). Existing approaches do not provide a scalable mechanism
for privacy-preserving FL to be utilized under such settings, potentially with
untrusted parties. This paper proposes a new local differentially private FL
(named LDPFL) protocol for industrial settings. LDPFL can run in industrial
settings with untrusted entities while enforcing stronger privacy guarantees
than existing approaches. LDPFL shows high FL model performance (up to 98%)
under small privacy budgets (e.g., epsilon = 0.5) in comparison to existing
methods.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 12:40:47 GMT""},{""version"":""v2"",""created"":""Wed, 3 Aug 2022 14:54:01 GMT""}]","2022-08-04"
"2202.06054","Jing Xu","Jing Xu, Jiaye Teng, Yang Yuan, Andrew Chi-Chih Yao","When do Models Generalize? A Perspective from Data-Algorithm
  Compatibility",,,,,"cs.LG math.ST stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the major open problems in machine learning is to characterize
generalization in the overparameterized regime, where most traditional
generalization bounds become inconsistent (Nagarajan and Kolter, 2019). In many
scenarios, their failure can be attributed to obscuring the crucial interplay
between the training algorithm and the underlying data distribution. To address
this issue, we propose a concept named compatibility, which quantitatively
characterizes generalization in a both data-relevant and algorithm-relevant
manner. By considering the entire training trajectory and focusing on
early-stopping iterates, compatibility exploits the data and the algorithm
information and is therefore a more suitable notion for generalization. We
validate this by theoretically studying compatibility under the setting of
solving overparameterized linear regression with gradient descent.
Specifically, we perform a data-dependent trajectory analysis and derive a
sufficient condition for compatibility in such a setting. Our theoretical
results demonstrate that in the sense of compatibility, generalization holds
with significantly weaker restrictions on the problem instance than the
previous last iterate analysis.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 12:42:36 GMT""},{""version"":""v2"",""created"":""Mon, 15 Aug 2022 08:14:48 GMT""},{""version"":""v3"",""created"":""Sat, 1 Oct 2022 02:48:52 GMT""}]","2022-10-04"
"2202.06055","Yuri A. Kordyukov","Yuri A. Kordyukov and Iskander A. Taimanov","Trace formula for the magnetic Laplacian on a compact hyperbolic surface","20 pages, v3. Final version","Regular and Chaotic Dynamics, 2022, vol. 27, no. 4, pp. 460-476","10.1134/S1560354722040050",,"math.DG math-ph math.DS math.MP math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We compute the trace formula for the magnetic Laplacian on a compact
hyperbolic surface of constant curvature with constant magnetic field for
energies above the Mane critical level of the corresponding magnetic geodesic
flow. We discuss the asymptotic behavior of the coefficients of the trace
formula when the energy approaches the Mane critical level.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 12:44:04 GMT""},{""version"":""v2"",""created"":""Tue, 12 Apr 2022 18:23:14 GMT""},{""version"":""v3"",""created"":""Sun, 24 Jul 2022 09:24:57 GMT""}]","2022-08-30"
"2202.06056","Geesara Prathap Kulathunga","Geesara Kulathunga, Hany Hamed, Dmitry Devitt, Alexandr Klimchik","Optimization-based Trajectory Tracking Approach for Multi-rotor Aerial
  Vehicles in Unknown Environments",,,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  The goal of this paper is to develop a continuous optimization-based
refinement of the reference trajectory to 'push it out' of the
obstacle-occupied space in the global phase for Multi-rotor Aerial Vehicles in
unknown environments. Our proposed approach comprises two planners: a global
planner and a local planner. The global planner refines the initial reference
trajectory when the trajectory goes either through an obstacle or near an
obstacle and lets the local planner calculate a near-optimal control policy.
The global planner comprises two convex programming approaches: the first one
helps to refine the reference trajectory, and the second one helps to recover
the reference trajectory if the first approach fails to refine. The global
planner mainly focuses on real-time performance and obstacles avoidance,
whereas the proposed formulation of the constrained nonlinear model predictive
control-based local planner ensures safety, dynamic feasibility, and the
reference trajectory tracking accuracy for low-speed maneuvers, provided that
local and global planners have mean computation times 0.06s (15Hz) and 0.05s
(20Hz), respectively, on an NVIDIA Jetson Xavier NX computer. The results of
our experiment confirmed that, in cluttered environments, the proposed approach
outperformed three other approaches: sampling-based pathfinding followed by
trajectory generation, a local planner, and graph-based pathfinding followed by
trajectory generation.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 12:50:35 GMT""}]","2022-02-15"
"2202.06057","Mayu Tsukamoto","Takahide Adachi, Mayu Tsukamoto","Mixed standardization and Ringel duality","29 pages",,,,"math.RT math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dlab--Ringel's standardization method gives a realization of a standardly
stratified algebra. In this paper, we construct mixed stratified algebras,
which are a generalization of standardly stratified algebras, following
Dlab--Ringel's standardization method. Moreover, we study a Ringel duality of
mixed stratified algebras from the viewpoint of stratifying systems.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 12:52:40 GMT""},{""version"":""v2"",""created"":""Fri, 25 Mar 2022 15:49:28 GMT""},{""version"":""v3"",""created"":""Mon, 17 Oct 2022 13:13:41 GMT""}]","2022-10-18"
"2202.06058","Zhi-Gang Wang","Zhi-Gang Wang","Comment on ""$Z_c$-like spectra from QCD Laplace sum rules at NLO""","6 pages, 3 figures",,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  In Phys. Rev. {\bf D103} (2021) 074015 (arXiv:2101.07281), huge (or largest)
mass gaps between the ground states and first radial excited states for the
tetraquark molecular states are obtained, $\Delta=1.70\sim 2.35\,\rm{GeV}$. We
explore the problems in the operator product expansion, Borel windows, etc, in
details.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 13:02:28 GMT""}]","2022-02-15"
"2202.06059","Meraj Alam","M. Alam, A. Muntean and G. P. Raja Sekhar","Nonlinear biphasic mixture model: existence and uniqueness results","17 pages, 1 figure",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  This paper is concerned with the development and analysis of a mathematical
model that is motivated by the interstitial hydrodynamics and tissue
deformation mechanics (poro-elasto-hydrodynamics) within an in-vitro solid
tumor. The classical mixture theory is adopted to mass and momentum balance
equations for a two phase system. The main contribution of this study: we treat
the physiological transport parameter (i.e., hydraulic resistivity) as
anisotropic and heterogeneous, thus the governing system is strongly coupled
and non-linear. We establish the existence and uniqueness results to this
non-linear system in a weak sense. We show further that the solution depends
continuously on the given data.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 13:02:58 GMT""}]","2022-02-15"
"2202.06060","Yukang Lu","Yukang Lu, Dingyao Min, Keren Fu, Qijun Zhao","Depth-Cooperated Trimodal Network for Video Salient Object Detection","5 pages, 3 figures, Accepted at ICIP-2022",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Depth can provide useful geographical cues for salient object detection
(SOD), and has been proven helpful in recent RGB-D SOD methods. However,
existing video salient object detection (VSOD) methods only utilize
spatiotemporal information and seldom exploit depth information for detection.
In this paper, we propose a depth-cooperated trimodal network, called DCTNet
for VSOD, which is a pioneering work to incorporate depth information to assist
VSOD. To this end, we first generate depth from RGB frames, and then propose an
approach to treat the three modalities unequally. Specifically, a multi-modal
attention module (MAM) is designed to model multi-modal long-range dependencies
between the main modality (RGB) and the two auxiliary modalities (depth,
optical flow). We also introduce a refinement fusion module (RFM) to suppress
noises in each modality and select useful information dynamically for further
feature refinement. Lastly, a progressive fusion strategy is adopted after the
refined features to achieve final cross-modal fusion. Experiments on five
benchmark datasets demonstrate the superiority of our depth-cooperated model
against 12 state-of-the-art methods, and the necessity of depth is also
validated.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 13:04:16 GMT""},{""version"":""v2"",""created"":""Mon, 11 Jul 2022 11:52:49 GMT""}]","2022-07-12"
"2202.06061","Ashutosh Wadge","Ashutosh S Wadge (1), Bogdan J Kowalski (2), Carmine Autieri (1),
  Przemys{\l}aw Iwanowski (1 and 2), Andrzej Hruban (2), Natalia Olszowska (3),
  Marcin Rosmus (3), Jacek Ko{\l}odziej (3) and Andrzej Wi\'sniewski (1 and 2)","Topological Lifshitz transition in Weyl semimetal NbP decorated with
  heavy elements","9 Pages, 8 Figures",,"10.1103/PhysRevB.105.235304",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Studies of the Fermi surface modification after in-situ covering NbP
semimetal with heavy elements Pb and Nb ultrathin layers were performed by
means of angle-resolved photoemission spectroscopy (ARPES). First, the
electronic structure was investigated for pristine single crystals with two
possible terminations (P and Nb) of the (0 0 1) surface. The nature of the
electronic states of these two cleaving planes is different: P-terminated
surface shows spoon and bow tie shaped fingerprints, whereas these shapes are
not present in Nb-terminated surfaces. ARPES studies show that even 1 monolayer
(ML) of Pb causes topological quantum Lifshitz transition (TQLT) in P- and
Nb-terminated surfaces. Deposited Pb 5d electrons have wide extended atomic
orbitals which leads to strong hybridization with Pb-terminated surface and a
corresponding shift in the Fermi energy. Nb has less capability to perturb the
system than Pb because Nb has weaker spin-orbit coupling than Pb. Nb-terminated
surface subjected to surface decoration with approximately 1.3 ML of Nb shows
no dramatic modification in the Fermi surface. In the case of Nb decorated
P-terminated surface, deposition of approximately 1 ML modifies the electronic
structure of NbP and it is on the verge of TQLT. Despite the strong spin-orbit
and strong hybridization of the heavy elements on the surface, it is possible
to observe the TQLT of the surface states thanks to the robustness of the bulk
topology.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 13:04:34 GMT""},{""version"":""v2"",""created"":""Fri, 15 Apr 2022 07:52:31 GMT""},{""version"":""v3"",""created"":""Mon, 4 Jul 2022 08:15:17 GMT""}]","2022-07-05"
"2202.06062","Huangwei Zhang","Shan Jin and Chao Xu and Hongtao Zheng and Huangwei Zhang","Detailed chemistry modelling of rotating detonations with dilute
  n-heptane sprays and preheated air",,,,,"physics.flu-dyn physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  Utilization of liquid fuels is crucial to enabling commercialization of
rotating detonation engines in the near future. In this study,
Eulerian-Lagrangian simulations are conducted for rotating detonative
combustion with dilute n-heptane sprays and preheated air. Two-dimensional
flattened configuration is used and a skeletal chemical mechanism with 44
species and 112 elementary reactions for n-heptane combustion is adopted. The
flow structure, droplet distribution, and thermochemical parameters in the
refill zone are first analyzed. It is shown that the mixture in the refill zone
is heterogeneous, including evaporating droplets, vapor, and air. When the
total temperature is below 950 K, the average equivalence ratio increases with
the total temperature. When it is higher than 950 K, the average equivalence
ratio is almost constant. Subsequently, the chemical explosive mode analysis is
applied to identify the controlling reactions and dominant combustion modes in
the fuel refill zone and reaction fronts. Results demonstrate that the
initiation reaction and low-temperature reaction are dominant in the upstream
and downstream of the refill zone, respectively. The intermediate species from
low-temperature chemistry is found to be important for the chemical explosive
mode in the undetonated mixture. The influence of species diffusion and
dispersed droplets is further analyzed. Results show that vapor autoignition
facilitated by droplet evaporation occurs in the refill zone. Finally, the
effects of the air total temperature on the detonation propagation speed and
RDE propulsion performance are investigated. It is found that the detonation
propagation speed and specific impulse increase with air total temperature.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 13:26:32 GMT""}]","2022-02-15"
"2202.06063","Jayson Victoriano Mr.","Jayson M. Victoriano, Jaime P. Pulumbarit, Luisito Lolong Lacatan,
  Richard Albert S. Salivio, Rica Louise A. Barawid","Data Analysis of Bulacan State University Faculty Scientific Publication
  Based on Google Scholar using Web Data Scraping Technique",,"International Journal of Computing Sciences Research (ISSN print:
  2546-0552; ISSN online: 2546-115X), Vol. 6, pp. 976-987, January 19, 2022","10.25147/ijcsr.2017.001.1.85",,"cs.DL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper aims to analyze and monitor the research publication productivity
of the faculty members of Bulacan State University. This paper compiles all the
scientific publications from Bulacan State University (BulSU) and its external
campuses as an index in Google Scholar. This study was intended to track and
monitor the scientific productivity of the faculty members of Bulacan State
University and each college and campus.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 13:34:39 GMT""}]","2022-02-15"
"2202.06064","Wenjian Liu","Linfeng Ye, Hao Wang, Yong Zhang, and Wenjian Liu","Self-Adaptive Real-Time Time-Dependent Density Functional Theory for
  X-ray Absorptions","40 pages, 10 figures, 3 tables",,,,"physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  Real-time time-dependent density functional theory (RT-TDDFT) can in
principle access the whole absorption spectrum of a many-electron system
exposed to a narrow pulse. However, this requires an accurate and efficient
propagator for the numerical integration of the time-dependent Kohn-Sham
equation. While a low-order time propagator is already sufficient for the
low-lying valence absorption spectra, it is no longer the case for the X-ray
absorption spectra (XAS) of systems composed even only of light elements, for
which the use of a high-order propagator is indispensable. It is then crucial
to choose a largest possible time step and a shortest possible simulation time,
so as to minimize the computational cost. To this end, we propose here a robust
AutoPST approach to determine automatically (Auto) the propagator (P), step
(S), and time (T) for relativistic RT-TDDFT simulations of XAS.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 13:38:30 GMT""},{""version"":""v2"",""created"":""Wed, 4 May 2022 05:16:02 GMT""},{""version"":""v3"",""created"":""Tue, 28 Jun 2022 02:59:37 GMT""}]","2022-06-29"
"2202.06065","Laurent Feuilloley","Nicolas Bousquet and Laurent Feuilloley and Th\'eo Pierron","What can be certified compactly?","A preliminary version of this paper appeared on the arxiv under the
  name ""Local certification of MSO properties for bounded treedepth graphs"".
  See arxiv:2110.01936. arXiv admin note: substantial text overlap with
  arXiv:2110.01936",,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Local certification consists in assigning labels (called \emph{certificates})
to the nodes of a network to certify a property of the network or the
correctness of a data structure distributed on the network. The verification of
this certification must be local: a node typically sees only its neighbors in
the network. The main measure of performance of a certification is the size of
its certificates.
  In 2011, G\""o\""os and Suomela identified $\Theta(\log n)$ as a special
certificate size: below this threshold little is possible, and several key
properties do have certifications of this type. A certification with such small
certificates is now called a \emph{compact local certification}, and it has
become the gold standard of the area, similarly to polynomial time for
centralized computing. A major question is then to understand which properties
have $O(\log n)$ certificates, or in other words: what is the power of compact
local certification?
  Recently, a series of papers have proved that several well-known network
properties have compact local certifications: planarity, bounded-genus, etc.
But one would like to have more general results, \emph{i.e.} meta-theorems. In
the analogue setting of polynomial-time centralized algorithms, a very fruitful
approach has been to prove that restricted types of problems can be solved in
polynomial time in graphs with restricted structures. These problems are
typically those that can be expressed in some logic, and the graph structures
are whose with bounded width or depth parameters. We take a similar approach
and prove the first meta-theorems for local certification. (See the abstract of
the pdf for more details.)
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 13:39:32 GMT""}]","2022-02-15"
"2202.06066","Jayson Victoriano Mr.","Jayson M. Victoriano, Manuel Luis C. Delos Santos, Albert A. Vinluan
  and Jennifer T. Carpio","Predicting Pollution Level Using Random Forest: A Case Study of Marilao
  River in Bulacan Province, Philippines",,"International Journal of Computing Sciences Research (ISSN print:
  2546-0552; ISSN online: 2546-115X) Vol. 3, No. 1, pp. 151-162, March 11, 2019","10.25147/ijcsr.2017.001.1.30",,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study aims to predict the pollution level that threatens the Marilao
River, located in the province of Bulacan, Philippines. The inhabitants of this
area are now being exposed to pollution. Contamination of this waterway comes
from both formal and informal industries, such as a used lead-acid battery,
open dumpsites metal refining, and other toxic metals. Using various water
quality parameters like Dissolved Oxygen (DO), Potential of Hydrogen (pH),
Biochemical Oxygen Demand (BOD) and Total Suspended Solids (TSS) were the basis
for predicting the pollution level. This study used the Data Mining technique
based on the sample data collected from January of 2013 to November of 2017.
These were used as a training data and test results to predict the river
condition with its corresponding pollution level classification indicated with
the used of colors such as Green for Normal, Yellow for Average, Orange for
Polluted and Red for Highly Polluted. The model got an accuracy of 91.75% with
a Kappa value of 0.8115, interpreted as Strong in terms of the level of
agreement.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 13:47:21 GMT""}]","2022-02-15"
"2202.06067","Tomoya Ono","Mukai Tsunasaki, Tomoya Ono, and Mitsuharu Uemoto","Theoretical investigation of vacancy related defects at
  4H-SiC(000$\bar{1}$)/SiO$_2$ interface after wet oxidation","12 pages",,"10.35848/1347-4065/ac5a97","PRESAT-9501","cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The stability and formation mechanism of the defects relevant to silicon and
carbon vacancies at the 4H-SiC(000$\bar{1}$)/SiO$_2$ interface after wet
oxidation are investigated by first-principles calculation based on the density
functional theory. The difference in the total energy of the defects agrees
with the experimental results concerning the dencity of defects. We found that
the characteristic behaviors of the generation of defects are explained by the
positions of vacancies and antisites in the SiC(000$\bar{1}$) substrate and
that the formation of silicon and carbon vacancies is relevant to the
generation mechanism of defects. The generation of silicon and carbon vacancies
is attributed to the termination of dangling bonds by H atoms introduced by wet
oxidation, resulting in generation of carbon-antisite--carbon-vacancy and
divacancies defects in wet oxidation.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 13:48:21 GMT""}]","2022-04-13"
"2202.06068","Andrei A. Shiryaev","Andrei A. Shiryaev, Anton D. Pavlushin, Alexei V. Pakhnevich,
  Ekaterina S. Kovalenko, Alexei A. Avein, Anna G. Ivanova","Structural peculiarities, mineral inclusions and point defects in
  yakutites -- a variety of impact-related diamond","PUBLISHED IN: METEORITICS & PLANETARY SCIENCE (2022)","METEORITICS & PLANETARY SCIENCE (2022), Vol. 57(3), 730-744","10.1111/maps.13791",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An unusual variety of impact-related diamond from the Popigai impact
structure - yakutites - is characterized by complementary methods including
optical microscopy, X-ray diffraction, radiography and tomography, infra-red,
Raman and luminescence spectroscopy providing structural information at widely
different scales. It is shown that relatively large graphite aggregates may be
transformed to diamond with preservation of many morphological features.
Spectroscopic and X-ray diffraction data indicate that the yakutite matrix
represents bulk nanocrystalline diamond. For the first time, features of
two-phonon infra-red absorption spectra of bulk nanocrystalline diamond are
interpreted in the framework of phonon dispersion curves. Luminescence spectra
of yakutite are dominated by dislocation-related defects. Optical microscopy
supported by X-ray diffraction reveals the presence of single crystal diamonds
with sizes of up to several tens of microns embedded into nanodiamond matrix.
The presence of single crystal grains in impact diamond may be explained by
CVD-like growth in a transient cavity and/or a seconds-long compression stage
of the impact process due to slow pressure release in a volatile-rich target.
For the first time, protogenetic mineral inclusions in yakutites represented by
mixed monoclinic and tetragonal ZrO2 are observed. This implies the presence of
baddeleyite in target rocks responsible for yakutite formation.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 13:53:03 GMT""}]","2022-03-14"
"2202.06069","Jayson Victoriano Mr.","Harold R. Lucero, Jayson M. Victoriano, Jennifer T. Carpio and Paquito
  G. Fernando Jr","Assessment of E-Learning Readiness of Faculty Members and Students in
  the Government and Private Higher Education Institutions in the Philippines",,"International Journal of Computing Sciences Research (ISSN print:
  2546-0552; ISSN online: 2546-115X) Vol. 5, No. 1, pp. 398-406 August 1, 2020","10.25147/ijcsr.2017.001.1.48",,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study seeks to determine the level of readiness of selected private and
government-managed colleges and universities in the Philippines. The study also
aims to determine if there's a significant difference in the level of readiness
between the private and government HEI's. In line with this, a
descriptive-comparative method was employed. A questionnaire from the works of
Aklaslan and Merca was utilized to determine the faculty members' and students'
status of their e-learning readiness, acceptance, training, technological
infrastructure, and tool awareness on the implementation of an e-learning
program. Weighted mean was used to determine the level of readiness while a
t-test was employed to determine if there is a significant difference between
results.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 13:55:17 GMT""}]","2022-02-15"
"2202.06070","Yulong Gao","Yulong Gao, Qiusheng Gu, Yong Shi, Luwenjia Zhou, Min Bao, Xiaoling
  Yu, Zhiyu Zhang, Tao Wang, Suzanne C. Madden, Matthew Hayes, Shiying Lu, and
  Ke Xu","The molecular gas resolved by ALMA in the low-metallicity dwarf merging
  galaxy Haro 11","14 pages, 10 figures; accepted for publication in A&A","A&A 661, A136 (2022)","10.1051/0004-6361/202142309",,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The physical mechanisms for starburst or quenching in less massive ($M_* <
10^{10} M_{\odot}$) galaxies are unclear. The merger is one of the inescapable
processes referred to as both starburst and quenching in massive galaxies.
However, the effects of the merger on star formation in dwarf galaxies and
their evolution results are still uncertain. We aim to explore how to trigger
and quench star formation in dwarf galaxies by studying the metal-poor gas-rich
dwarf mergers based on the multi-band observations at a spatial resolution of
$\sim$ 460 pc. We use the archival data of ALMA (band 3, 8) and VLT/MUSE to map
CO($J=$1-0), [CI]($^3$P$_1 - ^3$P$_0$), and H$\alpha$ emission in one of the
most extreme starburst merging dwarf galaxies, Haro 11. We find the molecular
gas is assembled around the central two star-forming regions. The
molecular/ionized gas and stellar components show complex kinematics,
indicating that the gas is probably at a combined stage of collision of clouds
and feedback from star formation. The peak location and distribution of
[CI](1-0) strongly resemble the CO(1-0) emission, meaning that it might trace
the same molecular gas as CO in such a dwarf merger starburst galaxy. The
enhancement of line ratios ($\sim 0.5$) of [CI]/CO around knot C is probably
generated by the dissociation of CO molecules by cosmic rays and
far-ultraviolet photons. Globally, Haro 11 and its star-forming regions share
similar SFEs as the high-$z$ starburst galaxies or the clumps in nearby
(U)LIRGs. Given the high SFE, sSFR, small stellar mass, low metallicity, and
deficient HI gas, Haro 11 could be an analog of high-$z$ dwarf starburst and
the potential progenitor of the nearby less massive elliptical galaxies. The
significantly smaller turbulent pressure and viral parameter will probably
trigger the intense starbursts. We also predict that it will quench at $M_* <
8.5 \times 10^9 M_{\odot}$.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 14:04:06 GMT""}]","2022-05-25"
"2202.06071","Yuda Chen","Yuda Chen, Meng Guo and Zhongkui Li","Deadlock Resolution and Feasibility Guarantee in MPC-based Multi-robot
  Trajectory Generation","15 pages, 15 figures",,,,"cs.RO cs.MA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Online collision-free trajectory generation within a shared workspace is
fundamental for most multi-robot applications. However, many widely-used
methods based on model predictive control (MPC) lack theoretical guarantees on
the feasibility of underlying optimization. Furthermore, when applied in a
distributed manner without a central coordinator, deadlocks often occur where
several robots block each other indefinitely. Whereas heuristic methods such as
introducing random perturbations exist, no profound analyses are given to
validate these measures. Towards this end, we propose a systematic method
called infinite-horizon model predictive control with deadlock resolution. The
MPC is formulated as a convex optimization over the proposed modified buffered
Voronoi with warning band. Based on this formulation, the condition of
deadlocks is formally analyzed and proven to be analogous to a force
equilibrium. A detection-resolution scheme is proposed, which can effectively
detect deadlocks online before they even happen. Once detected, it utilizes an
adaptive resolution scheme to resolve deadlocks, under which no stable
deadlocks can exist under minor conditions. In addition, the proposed planning
algorithm ensures recursive feasibility of the underlying optimization at each
time step under both input and model constraints, is concurrent for all robots
and requires only local communication. Comprehensive simulation and experiment
studies are conducted over large-scale multi-robot systems. Significant
improvements on success rate are reported, in comparison with other
state-of-the-art methods and especially in crowded and high-speed scenarios.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 14:04:44 GMT""},{""version"":""v2"",""created"":""Tue, 16 Aug 2022 06:32:39 GMT""},{""version"":""v3"",""created"":""Tue, 7 Mar 2023 03:43:48 GMT""}]","2023-03-08"
"2202.06072","Rawat Kanishka Dr.","R. Kanishka and V. Bhatnagar","Characterization and Comparison of Glass Electrodes","12 pages, 13 figures","2022_JINST_17_P02039","10.1088/1748-0221/17/02/P02039",,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents the study on the characterization of glass electrodes,
which are one of the main components of detectors like Resistive Plate Chambers
(RPCs). The RPCs are being used in various ongoing High Energy Physics
experiments, e.g., BELLE at KEK, CMS at LHC, and would be used in the near
future experiments e.g., INO-ICAL in India. The characterization of glass
electrodes has been done to understand the factors like quality of glass that
can help in improving the detector's performance. The glass samples chosen were
procured locally Asahi (A), Saint Gobain (S), Modi (M) that are easily
available in Indian industry. The characterization includes the tests to study
the optical, surface, physical, electrical properties, the composition of glass
samples, and leakage currents. This paper adds new information to the existing
body of research on the subject. Based on the techniques discussed in the paper
a comparison of the measurements among the three different types of glass
electrodes has been done. This study helps us to determine the best quality of
glass that can be chosen for better operation of the detectors.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 14:07:42 GMT""}]","2022-03-01"
"2202.06073","Aravind Ravi","Aravind Ravi","Classification of Microscopy Images of Breast Tissue: Region Duplication
  based Self-Supervision vs. Off-the Shelf Deep Representations",,,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Breast cancer is one of the leading causes of female mortality in the world.
This can be reduced when diagnoses are performed at the early stages of
progression. Further, the efficiency of the process can be significantly
improved with computer aided diagnosis. Deep learning based approaches have
been successfully applied to achieve this. One of the limiting factors for
training deep networks in a supervised manner is the dependency on large
amounts of expert annotated data. In reality, large amounts of unlabelled data
and only small amounts of expert annotated data are available. In such
scenarios, transfer learning approaches and self-supervised learning (SSL)
based approaches can be leveraged. In this study, we propose a novel
self-supervision pretext task to train a convolutional neural network (CNN) and
extract domain specific features. This method was compared with deep features
extracted using pre-trained CNNs such as DenseNet-121 and ResNet-50 trained on
ImageNet. Additionally, two types of patch-combination methods were introduced
and compared with majority voting. The methods were validated on the BACH
microscopy images dataset. Results indicated that the best performance of 99%
sensitivity was achieved for the deep features extracted using ResNet50 with
concatenation of patch-level embedding. Preliminary results of SSL to extract
domain specific features indicated that with just 15% of unlabelled data a high
sensitivity of 94% can be achieved for a four class classification of
microscopy images.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 14:12:13 GMT""}]","2022-02-15"
"2202.06074","Zhejie Ding","Zhejie Ding, Chia-Hsun Chuang, Yu Yu, Lehman H. Garrison, Adrian E.
  Bayer, Yu Feng, Chirag Modi, Daniel J. Eisenstein, Martin White, Andrei
  Variu, Cheng Zhao, Hanyu Zhang, Jennifer Meneses Rizo, David Brooks, Kyle
  Dawson, Peter Doel, Enrique Gaztanaga, Robert Kehoe, Alex Krolewski, Martin
  Landriau, Nathalie Palanque-Delabrouille, Claire Poppett","The DESI $N$-body Simulation Project -- II. Suppressing sample variance
  with fast simulations","Matched version accepted by MNRAS, should be clearer",,"10.1093/mnras/stac1501",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dark Energy Spectroscopic Instrument (DESI) will construct a large and
precise three-dimensional map of our Universe. The survey effective volume
reaches $\sim20\Gpchcube$. It is a great challenge to prepare high-resolution
simulations with a much larger volume for validating the DESI analysis
pipelines. \textsc{AbacusSummit} is a suite of high-resolution dark-matter-only
simulations designed for this purpose, with $200\Gpchcube$ (10 times DESI
volume) for the base cosmology. However, further efforts need to be done to
provide a more precise analysis of the data and to cover also other
cosmologies. Recently, the CARPool method was proposed to use paired accurate
and approximate simulations to achieve high statistical precision with a
limited number of high-resolution simulations. Relying on this technique, we
propose to use fast quasi-$N$-body solvers combined with accurate simulations
to produce accurate summary statistics. This enables us to obtain 100 times
smaller variance than the expected DESI statistical variance at the scales we
are interested in, e.g. $k < 0.3\hMpc$ for the halo power spectrum. In
addition, it can significantly suppress the sample variance of the halo
bispectrum. We further generalize the method for other cosmologies with only
one realization in \textsc{AbacusSummit} suite to extend the effective volume
$\sim 20$ times. In summary, our proposed strategy of combining high-fidelity
simulations with fast approximate gravity solvers and a series of variance
suppression techniques sets the path for a robust cosmological analysis of
galaxy survey data.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 14:13:10 GMT""},{""version"":""v2"",""created"":""Sat, 18 Jun 2022 14:06:41 GMT""}]","2022-06-22"
"2202.06075","The CMS Collaboration","CMS Collaboration","Search for new physics in the lepton plus missing transverse momentum
  final state in proton-proton collisions at $\sqrt{s} =$ 13 TeV","Replaced with the published version. Added the journal reference and
  the DOI. All the figures and tables can be found at
  http://cms-results.web.cern.ch/cms-results/public-results/publications/EXO-19-017
  (CMS Public Pages)","JHEP 07 (2022) 067","10.1007/JHEP07(2022)067","CMS-EXO-19-017, CERN-EP-2021-142","hep-ex","http://creativecommons.org/licenses/by/4.0/","  A search for physics beyond the standard model (SM) in final states with an
electron or muon and missing transverse momentum is presented. The analysis
uses data from proton-proton collisions at a centre-of-mass energy of 13 TeV,
collected with the CMS detector at the LHC in 2016-2018 and corresponding to an
integrated luminosity of 138 fb$^{-1}$. No significant deviation from the SM
prediction is observed. Model-independent limits are set on the production
cross section of W' bosons decaying into lepton-plus-neutrino final states.
Within the framework of the sequential standard model, with the combined
results from the electron and muon decay channels a W' boson with mass less
than 5.7 TeV is excluded at 95% confidence level. Results on a SM precision
test, the determination of the oblique electroweak $W$ parameter, are presented
using LHC data for the first time. These results together with those from the
direct W' resonance search are used to extend existing constraints on composite
Higgs scenarios. This is the first experimental exclusion on compositeness
parameters using results from LHC data other than Higgs boson measurements.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 14:17:48 GMT""},{""version"":""v2"",""created"":""Fri, 15 Jul 2022 13:16:01 GMT""}]","2022-07-18"
"2202.06076","Grzegorz Jacenk\'ow","Grzegorz Jacenk\'ow, Alison Q. O'Neil, Sotirios A. Tsaftaris","Indication as Prior Knowledge for Multimodal Disease Classification in
  Chest Radiographs with Transformers","Accepted at the IEEE International Symposium on Biomedical Imaging
  (ISBI) 2022 as an oral presentation",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  When a clinician refers a patient for an imaging exam, they include the
reason (e.g. relevant patient history, suspected disease) in the scan request;
this appears as the indication field in the radiology report. The
interpretation and reporting of the image are substantially influenced by this
request text, steering the radiologist to focus on particular aspects of the
image. We use the indication field to drive better image classification, by
taking a transformer network which is unimodally pre-trained on text (BERT) and
fine-tuning it for multimodal classification of a dual image-text input. We
evaluate the method on the MIMIC-CXR dataset, and present ablation studies to
investigate the effect of the indication field on the classification
performance. The experimental results show our approach achieves 87.8 average
micro AUROC, outperforming the state-of-the-art methods for unimodal (84.4) and
multimodal (86.0) classification. Our code is available at
https://github.com/jacenkow/mmbt.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 14:23:30 GMT""}]","2022-02-15"
"2202.06077","Yang Liu","Rui-Cheng Liu, Lishuai Jin, Zongxi Cai, Yang Liu","An experimental study of morphological formation in bilayered tubular
  structures driven by swelling/growth","27 pages, 15 figures",,,,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  This paper presents an experimental investigation on pattern formation and
evolution in bilayered tubular organs using swelling deformation of
polydimethylsiloxane (PDMS) and aims at supplying a thorough comparison with
theoretical and finite element results. To create a twin model in modelling and
simulation, the shear modulus in the incompressible neo-Hookean material is
estimated via uni-axial tensile and pure shear tests. Five bilayered tubes with
different material or geometrical parameters are fabricated. Swelling
experiments are carried out for these samples in an individual experimental
setup where a plane-strain deformation is guaranteed, and several surface
patterns and the associated mode transformations are observed, namely, creases,
wrinkles, period-doubling profiles, wrinkle-to-crease transition, and
wrinkle-to-period-doubling transition. In particular, an interfacial wrinkling
pattern is also observed. To make comparisons, a buckling analysis is conducted
within the framework of finite elasticity by means of the Stroh formulation. In
addition, a finite element analysis is performed to trace the evolution of
surface instabilities. It turns out that the experimental findings agree well
with the theoretical predictions as well as the finite element results. From
our experiments, it is found that creasing mode may appear instead of wrinkling
mode when both layers share a similar mechanical property. It is expected that
the current work could provide novel experimental insight into pattern
formation in tubular structures, and the good agreement among experimental,
theoretical, and simulation consequences supplies strong evidence that a
phenomenological growth model is satisfactory to reveal mechanisms behind
intricate surface morphology in tubular tissues.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 14:30:19 GMT""}]","2022-02-15"
"2202.06078","Wim Veldman","Wim Veldman","On some of Brouwer's axioms",,,,,"math.LO","http://creativecommons.org/licenses/by/4.0/","  We discuss the position of intuitionistic mathematics within the field of
constructive mathematics. We discuss some principles defended and used by
Brouwer but rejected by Bishop, like the Coninuity Principle, the Fan Theorem
and the Bar Theorem. We explain some of their consequences in the development
of constructive mathematics, like the Borel Hierarchy Theorem and the
Intuitionistic Ramsey Theorem. We go into the theory of measure and integration
as Bishop followed in this field a path different from Brouwer's.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 14:37:13 GMT""},{""version"":""v2"",""created"":""Fri, 11 Nov 2022 10:53:23 GMT""}]","2022-11-14"
"2202.06079","M. Furkan Atasoy","Zehranaz Canfes, M. Furkan Atasoy, Alara Dirik, Pinar Yanardag","Text and Image Guided 3D Avatar Generation and Manipulation",,,,,"cs.CV cs.GR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The manipulation of latent space has recently become an interesting topic in
the field of generative models. Recent research shows that latent directions
can be used to manipulate images towards certain attributes. However,
controlling the generation process of 3D generative models remains a challenge.
In this work, we propose a novel 3D manipulation method that can manipulate
both the shape and texture of the model using text or image-based prompts such
as 'a young face' or 'a surprised face'. We leverage the power of Contrastive
Language-Image Pre-training (CLIP) model and a pre-trained 3D GAN model
designed to generate face avatars, and create a fully differentiable rendering
pipeline to manipulate meshes. More specifically, our method takes an input
latent code and modifies it such that the target attribute specified by a text
or image prompt is present or enhanced, while leaving other attributes largely
unaffected. Our method requires only 5 minutes per manipulation, and we
demonstrate the effectiveness of our approach with extensive results and
comparisons.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 14:37:29 GMT""}]","2022-02-15"
"2202.06080","Oliver T\""uselmann","Oliver T\""uselmann, Friedrich M\""uller, Fabian Wolf and Gernot A. Fink","Recognition-free Question Answering on Handwritten Document Collections",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, considerable progress has been made in the research area of
Question Answering (QA) on document images. Current QA approaches from the
Document Image Analysis community are mainly focusing on machine-printed
documents and perform rather limited on handwriting. This is mainly due to the
reduced recognition performance on handwritten documents. To tackle this
problem, we propose a recognition-free QA approach, especially designed for
handwritten document image collections. We present a robust document retrieval
method, as well as two QA models. Our approaches outperform the
state-of-the-art recognition-free models on the challenging BenthamQA and
HW-SQuAD datasets.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 14:47:44 GMT""}]","2022-02-15"
"2202.06081","Lu Fan","Fan Lu, Qimai Li, Bo Liu, Xiao-Ming Wu, Xiaotong Zhang, Fuyu Lv, Guli
  Lin, Sen Li, Taiwei Jin and Keping Yang","Modeling User Behavior with Graph Convolution for Personalized Product
  Search",,,,,"cs.IR","http://creativecommons.org/licenses/by/4.0/","  User preference modeling is a vital yet challenging problem in personalized
product search. In recent years, latent space based methods have achieved
state-of-the-art performance by jointly learning semantic representations of
products, users, and text tokens. However, existing methods are limited in
their ability to model user preferences. They typically represent users by the
products they visited in a short span of time using attentive models and lack
the ability to exploit relational information such as user-product interactions
or item co-occurrence relations. In this work, we propose to address the
limitations of prior arts by exploring local and global user behavior patterns
on a user successive behavior graph, which is constructed by utilizing
short-term actions of all users. To capture implicit user preference signals
and collaborative patterns, we use an efficient jumping graph convolution to
explore high-order relations to enrich product representations for user
preference modeling. Our approach can be seamlessly integrated with existing
latent space based methods and be potentially applied in any product retrieval
method that uses purchase history to model user preferences. Extensive
experiments on eight Amazon benchmarks demonstrate the effectiveness and
potential of our approach. The source code is available at
\url{https://github.com/floatSDSDS/SBG}.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 14:58:08 GMT""}]","2022-02-15"
"2202.06082","Alvanh Alem Pido","Alvanh Alem G. Pido and Bryan P. Pagcaliwagan","First principles calculations of the electronic properties of O- and
  O2-NbSe2 complexes","14 pages, 13 figures","International Journal of Computing Sciences Research, 6, 962-975
  (2022)","10.25147/ijcsr.2017.001.1.87",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Purpose: We investigated the interaction of O and O2 on monolayer Niobium
Diselenide (NbSe2) to provide theoretical predictions about the electronic
properties of the complexes using First principles calculations in Quantum
Espresso 6.7. As known, considering impurities in pristine nanomaterials like
NbSe2 is very important as it can alter some of its properties.
  Method: In this paper, we performed some topological analyses on the
electronic densities and electronic structures calculations to O- and O2-NbSe2
complexes. Charge Density Difference (CDD) and Bader charge analysis reveal
that O and O2 acted as oxidizing agents and accumulated electronic charges from
the NbSe2.
  Results: The electronic properties calculations of the complexes showed that
the metallic behavior of NbSe2 is preserved after O and O2 adsorption.
Calculations of the net charge transfer revealed that the atomic and molecular
oxygen has accumulated electronic charges while the NbSe2 has depleted
electronic charges. These results showed the possibility of tailoring the
electronic properties of NbSe2.
  Conclusion: The interaction of O and O2 with the monolayer NbSe2 caused
charge redistributions while maintaining the metallicity of the NbSe2. In all
circumstances, the results are consistent with the established works which show
the possibility of modifying the electronic properties of NbSe2 that could open
some potential applications in nanotechnology and other nanoelectronics-related
devices.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 15:01:50 GMT""}]","2022-02-15"
"2202.06083","Tomoya Murata","Tomoya Murata and Taiji Suzuki","Escaping Saddle Points with Bias-Variance Reduced Local Perturbed SGD
  for Communication Efficient Nonconvex Distributed Learning","50 pages",,,,"cs.LG cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent centralized nonconvex distributed learning and federated learning,
local methods are one of the promising approaches to reduce communication time.
However, existing work has mainly focused on studying first-order optimality
guarantees. On the other side, second-order optimality guaranteed algorithms,
i.e., algorithms escaping saddle points, have been extensively studied in the
non-distributed optimization literature. In this paper, we study a new local
algorithm called Bias-Variance Reduced Local Perturbed SGD (BVR-L-PSGD), that
combines the existing bias-variance reduced gradient estimator with parameter
perturbation to find second-order optimal points in centralized nonconvex
distributed optimization. BVR-L-PSGD enjoys second-order optimality with nearly
the same communication complexity as the best known one of BVR-L-SGD to find
first-order optimality. Particularly, the communication complexity is better
than non-local methods when the local datasets heterogeneity is smaller than
the smoothness of the local loss. In an extreme case, the communication
complexity approaches to $\widetilde \Theta(1)$ when the local datasets
heterogeneity goes to zero. Numerical results validate our theoretical
findings.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 15:12:17 GMT""},{""version"":""v2"",""created"":""Tue, 31 May 2022 08:49:31 GMT""},{""version"":""v3"",""created"":""Wed, 12 Oct 2022 11:21:56 GMT""}]","2022-10-13"
"2202.06084","Mirazul Haque","Mirazul Haque, Yaswanth Yadlapalli, Wei Yang, and Cong Liu","EREBA: Black-box Energy Testing of Adaptive Neural Networks",,,"10.1145/3510003.3510088",,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Recently, various Deep Neural Network (DNN) models have been proposed for
environments like embedded systems with stringent energy constraints. The
fundamental problem of determining the robustness of a DNN with respect to its
energy consumption (energy robustness) is relatively unexplored compared to
accuracy-based robustness. This work investigates the energy robustness of
Adaptive Neural Networks (AdNNs), a type of energy-saving DNNs proposed for
many energy-sensitive domains and have recently gained traction. We propose
EREBA, the first black-box testing method for determining the energy robustness
of an AdNN. EREBA explores and infers the relationship between inputs and the
energy consumption of AdNNs to generate energy surging samples. Extensive
implementation and evaluation using three state-of-the-art AdNNs demonstrate
that test inputs generated by EREBA could degrade the performance of the system
substantially. The test inputs generated by EREBA can increase the energy
consumption of AdNNs by 2,000% compared to the original inputs. Our results
also show that test inputs generated via EREBA are valuable in detecting energy
surging inputs.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 15:16:04 GMT""}]","2022-02-15"
"2202.06085","Yukuan Jia","Yukuan Jia, Ruiqing Mao, Yuxuan Sun, Sheng Zhou, Zhisheng Niu","Online V2X Scheduling for Raw-Level Cooperative Perception","7 pages, 5 figures, accepted by 2022 IEEE International Conference on
  Communications (ICC)",,"10.1109/ICC45855.2022.9838439",,"cs.IT cs.LG math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cooperative perception of connected vehicles comes to the rescue when the
field of view restricts stand-alone intelligence. While raw-level cooperative
perception preserves most information to guarantee accuracy, it is demanding in
communication bandwidth and computation power. Therefore, it is important to
schedule the most beneficial vehicle to share its sensor in terms of
supplementary view and stable network connection. In this paper, we present a
model of raw-level cooperative perception and formulate the energy minimization
problem of sensor sharing scheduling as a variant of the Multi-Armed Bandit
(MAB) problem. Specifically, volatility of the neighboring vehicles,
heterogeneity of V2X channels, and the time-varying traffic context are taken
into consideration. Then we propose an online learning-based algorithm with
logarithmic performance loss, achieving a decent trade-off between exploration
and exploitation. Simulation results under different scenarios indicate that
the proposed algorithm quickly learns to schedule the optimal cooperative
vehicle and saves more energy as compared to baseline algorithms.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 15:16:45 GMT""}]","2023-02-28"
"2202.06086","Yang-Hui He","Yang-Hui He","From the String Landscape to the Mathematical Landscape: a
  Machine-Learning Outlook","10 pages, 2 figures. Based on various talks in 2021-22, this is an
  invited contribution to the Proceedings of ""The 14th International Workshop
  on Lie theory and its applications in physics"", to be published by
  Springer-Nature",,,"LIMS-2022-009","hep-th cs.LG math.HO","http://creativecommons.org/licenses/by/4.0/","  We review the recent programme of using machine-learning to explore the
landscape of mathematical problems. With this paradigm as a model for human
intuition - complementary to and in contrast with the more formalistic approach
of automated theorem proving - we highlight some experiments on how AI helps
with conjecture formulation, pattern recognition and computation.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 15:18:59 GMT""}]","2022-02-15"
"2202.06087","Joshua Erde Dr","Tuan Anh Do, Joshua Erde, Mihyun Kang","A note on the width of sparse random graphs","18 pages",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  In this note, we consider the width of a supercritical random graph according
to some commonly studied width measures. We give short, direct proofs of
results of Lee, Lee and Oum, and of Perarnau and Serra, on the rank- and
tree-width of the random graph $G(n,p)$ when $p= \frac{1+\epsilon}{n}$ for
$\epsilon > 0$ constant. Our proofs avoid the use, as a black box, of a result
of Benjamini, Kozma and Wormald on the expansion properties of the giant
component in this regime, and so as a further benefit we obtain explicit bounds
on the dependence of these results on $\epsilon$. Finally, we also consider the
width of the random graph in the weakly supercritical regime, where $\epsilon =
o(1)$ and $\epsilon^3n \to \infty$. In this regime, we determine, up to a
constant multiplicative factor, the rank- and tree-width of $G(n,p)$ as a
function of $n$ and $\epsilon$.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 15:20:49 GMT""}]","2022-02-15"
"2202.06088","Jiakai Zhang","Jiakai Zhang, Liao Wang, Xinhang Liu, Fuqiang Zhao, Minzhang Li,
  Haizhao Dai, Boyuan Zhang, Wei Yang, Lan Xu and Jingyi Yu","NeuVV: Neural Volumetric Videos with Immersive Rendering and Editing",,,,,"cs.CV cs.GR","http://creativecommons.org/licenses/by/4.0/","  Some of the most exciting experiences that Metaverse promises to offer, for
instance, live interactions with virtual characters in virtual environments,
require real-time photo-realistic rendering. 3D reconstruction approaches to
rendering, active or passive, still require extensive cleanup work to fix the
meshes or point clouds. In this paper, we present a neural volumography
technique called neural volumetric video or NeuVV to support immersive,
interactive, and spatial-temporal rendering of volumetric video contents with
photo-realism and in real-time. The core of NeuVV is to efficiently encode a
dynamic neural radiance field (NeRF) into renderable and editable primitives.
We introduce two types of factorization schemes: a hyper-spherical harmonics
(HH) decomposition for modeling smooth color variations over space and time and
a learnable basis representation for modeling abrupt density and color changes
caused by motion. NeuVV factorization can be integrated into a Video Octree
(VOctree) analogous to PlenOctree to significantly accelerate training while
reducing memory overhead. Real-time NeuVV rendering further enables a class of
immersive content editing tools. Specifically, NeuVV treats each VOctree as a
primitive and implements volume-based depth ordering and alpha blending to
realize spatial-temporal compositions for content re-purposing. For example, we
demonstrate positioning varied manifestations of the same performance at
different 3D locations with different timing, adjusting color/texture of the
performer's clothing, casting spotlight shadows and synthesizing distance
falloff lighting, etc, all at an interactive speed. We further develop a hybrid
neural-rasterization rendering framework to support consumer-level VR headsets
so that the aforementioned volumetric video viewing and editing, for the first
time, can be conducted immersively in virtual 3D space.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 15:23:16 GMT""}]","2022-02-15"
"2202.06948","Jian Cui","Jian Cui, Liqiang Yuan, Zhaoxiang Wang, Ruilin Li, Tianzi Jiang","Towards Best Practice of Interpreting Deep Learning Models for EEG-based
  Brain Computer Interfaces",,,,,"cs.NE cs.HC cs.LG eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  As deep learning has achieved state-of-the-art performance for many tasks of
EEG-based BCI, many efforts have been made in recent years trying to understand
what have been learned by the models. This is commonly done by generating a
heatmap indicating to which extent each pixel of the input contributes to the
final classification for a trained model. Despite the wide use, it is not yet
understood to which extent the obtained interpretation results can be trusted
and how accurate they can reflect the model decisions. In order to fill this
research gap, we conduct a study to evaluate different deep interpretation
techniques quantitatively on EEG datasets. The results reveal the importance of
selecting a proper interpretation technique as the initial step. In addition,
we also find that the quality of the interpretation results is inconsistent for
individual samples despite when a method with an overall good performance is
used. Many factors, including model structure and dataset types, could
potentially affect the quality of the interpretation results. Based on the
observations, we propose a set of procedures that allow the interpretation
results to be presented in an understandable and trusted way. We illustrate the
usefulness of our method for EEG-based BCI with instances selected from
different scenarios.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 07:54:12 GMT""},{""version"":""v2"",""created"":""Fri, 18 Feb 2022 03:37:17 GMT""},{""version"":""v3"",""created"":""Tue, 18 Apr 2023 03:29:58 GMT""}]","2023-04-19"
"2202.07072","Jiri Krticka","J. Krticka, J. Kubat, I. Krtickova","X-ray irradiation of the stellar wind in HMXBs with B supergiants:
  Implications for ULXs","11 pages, accepted for publication in Astronomy & Astrophysics","A&A 659, A117 (2022)","10.1051/0004-6361/202142502",,"astro-ph.HE astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Wind-fed high-mass X-ray binaries are powered by accretion of the radiatively
driven wind on the compact star. Accretion-generated X-rays alter the
ionization state of the wind. Because higher ionization states drive the wind
less effectively, X-ray ionization may brake acceleration of the wind. This
causes a decrease in the wind terminal velocity and mass flux in the direction
toward the X-ray source. We study the effect of X-ray ionization on the stellar
wind of B supergiants. We determine the binary parameters for which the X-ray
irradiation significantly influences the stellar wind. This can be studied in
diagrams that plot the optical depth parameter versus the X-ray luminosity. For
low optical depths or for high X-ray luminosities, X-ray ionization leads to a
disruption in the wind aimed toward the X-ray source. Observational parameters
of high-mass X-ray binaries with B-supergiant components appear outside the
wind disruption zone. The X-ray feedback determines the resulting X-ray
luminosity. For low X-ray luminosities, ionization is weak, and the wind is not
disrupted by X-rays and flows at large velocities, consequently the accretion
rate is relatively low. On the other hand, for high X-ray luminosities, the
X-ray ionization disrupts the flow braking the acceleration, the wind velocity
is low, and the accretion rate becomes high. These effects determine the X-ray
luminosity of individual binaries. Accounting for the X-ray feedback, estimated
X-ray luminosities reasonably agree with observational values. We study the
effect of small-scale wind inhomogeneities, showing that they weaken the effect
of X-ray ionization by increasing recombination and the mass-loss. This effect
is particularly important in the region of the bistability jump. We show that
ultraluminous X-ray binaries with $L_x<10^{40}$ erg/s may be powered by
accretion of a B-supergiant wind on a massive black hole.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:02:16 GMT""}]","2022-03-16"
"2202.07389","Nicholas Horton","Nicholas J. Horton and Jie Chao and William Finzer and Phebe Palmer","Spam four ways: Making sense of text data","in press, CHANCE",,"10.1080/09332480.2022.2066414",,"stat.OT stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The world is full of text data, yet text analytics has not traditionally
played a large part in statistics education. We consider four different ways to
provide students with opportunities to explore whether email messages are
unwanted correspondence (spam). Text from subject lines are used to identify
features that can be used in classification. The approaches include use of a
Model Eliciting Activity, exploration with CODAP, modeling with a specially
designed Shiny app, and coding more sophisticated analyses using R. The
approaches vary in their use of technology and code but all share the common
goal of using data to make better decisions and assessment of the accuracy of
those decisions.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 21:29:32 GMT""}]","2022-10-11"
"2202.07421","Mete Ozay","Jiwei Tian and Buhong Wang and Jing Li and Zhen Wang and Mete Ozay","Adversarial Attacks and Defense Methods for Power Quality Recognition","Technical report",,,,"cs.CR cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Vulnerability of various machine learning methods to adversarial examples has
been recently explored in the literature. Power systems which use these
vulnerable methods face a huge threat against adversarial examples. To this
end, we first propose a signal-specific method and a universal signal-agnostic
method to attack power systems using generated adversarial examples. Black-box
attacks based on transferable characteristics and the above two methods are
also proposed and evaluated. We then adopt adversarial training to defend
systems against adversarial attacks. Experimental analyses demonstrate that our
signal-specific attack method provides less perturbation compared to the FGSM
(Fast Gradient Sign Method), and our signal-agnostic attack method can generate
perturbations fooling most natural signals with high probability. What's more,
the attack method based on the universal signal-agnostic algorithm has a higher
transfer rate of black-box attacks than the attack method based on the
signal-specific algorithm. In addition, the results show that the proposed
adversarial training improves robustness of power systems to adversarial
examples.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 21:18:37 GMT""}]","2022-02-16"
"2202.07422","Guang Yang","Ming Li, Yingying Fang, Zeyu Tang, Chibudom Onuorah, Jun Xia, Javier
  Del Ser, Simon Walsh, Guang Yang","Explainable COVID-19 Infections Identification and Delineation Using
  Calibrated Pseudo Labels","10 pages, 6 figures, IEEE TETCI Accepted",,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The upheaval brought by the arrival of the COVID-19 pandemic has continued to
bring fresh challenges over the past two years. During this COVID-19 pandemic,
there has been a need for rapid identification of infected patients and
specific delineation of infection areas in computed tomography (CT) images.
Although deep supervised learning methods have been established quickly, the
scarcity of both image-level and pixel-level labels as well as the lack of
explainable transparency still hinder the applicability of AI. Can we identify
infected patients and delineate the infections with extreme minimal
supervision? Semi-supervised learning has demonstrated promising performance
under limited labelled data and sufficient unlabelled data. Inspired by
semi-supervised learning, we propose a model-agnostic calibrated
pseudo-labelling strategy and apply it under a consistency regularization
framework to generate explainable identification and delineation results. We
demonstrate the effectiveness of our model with the combination of limited
labelled data and sufficient unlabelled data or weakly-labelled data. Extensive
experiments have shown that our model can efficiently utilize limited labelled
data and provide explainable classification and segmentation results for
decision-making in clinical routine. The code is available at
https://github.com/ayanglab/XAI COVID-19.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:32:46 GMT""},{""version"":""v2"",""created"":""Sun, 3 Jul 2022 21:29:06 GMT""}]","2022-07-05"
"2202.07423","Philipp Kopper","Philipp Kopper, Simon Wiegrebe, Bernd Bischl, Andreas Bender, David
  R\""ugamer","DeepPAMM: Deep Piecewise Exponential Additive Mixed Models for Complex
  Hazard Structures in Survival Analysis","13 pages, 2 figures, This work has been accepted by the 26th
  Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD2022)",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Survival analysis (SA) is an active field of research that is concerned with
time-to-event outcomes and is prevalent in many domains, particularly
biomedical applications. Despite its importance, SA remains challenging due to
small-scale data sets and complex outcome distributions, concealed by
truncation and censoring processes. The piecewise exponential additive mixed
model (PAMM) is a model class addressing many of these challenges, yet PAMMs
are not applicable in high-dimensional feature settings or in the case of
unstructured or multimodal data. We unify existing approaches by proposing
DeepPAMM, a versatile deep learning framework that is well-founded from a
statistical point of view, yet with enough flexibility for modeling complex
hazard structures. We illustrate that DeepPAMM is competitive with other
machine learning approaches with respect to predictive performance while
maintaining interpretability through benchmark experiments and an extended case
study.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 11:38:57 GMT""}]","2022-02-16"
"2202.07425","George Anastassiou Prof","George A Anastassiou","Algebraic function based Banach space valued ordinary and fractional
  neural network approximations","arXiv admin note: substantial text overlap with arXiv:1404.6449",,,,"stat.ML cs.LG math.CA","http://creativecommons.org/licenses/by/4.0/","  Here we research the univariate quantitative approximation, ordinary and
fractional, of Banach space valued continuous functions on a compact interval
or all the real line by quasi-interpolation Banach space valued neural network
operators. These approximations are derived by establishing Jackson type
inequalities involving the modulus of continuity of the engaged function or its
Banach space valued high order derivative of fractional derivatives. Our
operators are defined by using a density function generated by an algebraic
sigmoid function. The approximations are pointwise and of the uniform norm. The
related Banach space valued feed-forward neural networks are with one hidden
layer.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 20:08:52 GMT""}]","2022-02-16"
"2202.07435","Abhishek Gupta","Abhishek Gupta (1, 2, 3), Connor Wright (1, 4), Marianna Bergamaschi
  Ganapini (1, 5), Masa Sweidan (1), Renjie Butalid (1) ((1) Montreal AI Ethics
  Institute, (2) Microsoft, (3) Green Software Foundation, (4) University of
  Exeter, (5) Union College)","State of AI Ethics Report (Volume 6, February 2022)","295 pages",,,,"cs.CY cs.AI","http://creativecommons.org/licenses/by/4.0/","  This report from the Montreal AI Ethics Institute (MAIEI) covers the most
salient progress in research and reporting over the second half of 2021 in the
field of AI ethics. Particular emphasis is placed on an ""Analysis of the AI
Ecosystem"", ""Privacy"", ""Bias"", ""Social Media and Problematic Information"", ""AI
Design and Governance"", ""Laws and Regulations"", ""Trends"", and other areas
covered in the ""Outside the Boxes"" section. The two AI spotlights feature
application pieces on ""Constructing and Deconstructing Gender with AI-Generated
Art"" as well as ""Will an Artificial Intellichef be Cooking Your Next Meal at a
Michelin Star Restaurant?"". Given MAIEI's mission to democratize AI,
submissions from external collaborators have featured, such as pieces on the
""Challenges of AI Development in Vietnam: Funding, Talent and Ethics"" and using
""Representation and Imagination for Preventing AI Harms"". The report is a
comprehensive overview of what the key issues in the field of AI ethics were in
2021, what trends are emergent, what gaps exist, and a peek into what to expect
from the field of AI ethics in 2022. It is a resource for researchers and
practitioners alike in the field to set their research and development agendas
to make contributions to the field of AI ethics.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 14:14:32 GMT""}]","2022-02-16"
"2202.07438","Christoph Glasmacher","Christoph Glasmacher, Robert Krajewski, Lutz Eckstein","An Automated Analysis Framework for Trajectory Datasets","13 pages, 13 figures",,"10.48550/arXiv.2202.07438",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Trajectory datasets of road users have become more important in the last
years for safety validation of highly automated vehicles. Several naturalistic
trajectory datasets with each more than 10.000 tracks were released and others
will follow. Considering this amount of data, it is necessary to be able to
compare these datasets in-depth with ease to get an overview. By now, the
datasets' own provided information is mainly limited to meta-data and
qualitative descriptions which are mostly not consistent with other datasets.
This is insufficient for users to differentiate the emerging datasets for
application-specific selection. Therefore, an automated analysis framework is
proposed in this work. Starting with analyzing individual tracks, fourteen
elementary characteristics, so-called detection types, are derived and used as
the base of this framework. To describe each traffic scenario precisely, the
detections are subdivided into common metrics, clustering methods and anomaly
detection. Those are combined using a modular approach. The detections are
composed into new scores to describe three defined attributes of each track
data quantitatively: interaction, anomaly and relevance. These three scores are
calculated hierarchically for different abstract layers to provide an overview
not just between datasets but also for tracks, spatial regions and individual
situations. So, an objective comparison between datasets can be realized.
Furthermore, it can help to get a deeper understanding of the recorded
infrastructure and its effect on road user behavior. To test the validity of
the framework, a study is conducted to compare the scores with human
perception. Additionally, several datasets are compared.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 10:55:53 GMT""}]","2022-04-12"
"2202.07439","Sumer Kohli","Sumer Kohli, Neelesh Ramachandran, Ana Tudor, Gloria Tumushabe, Olivia
  Hsu, Gireeja Ranade","Inclusive Study Group Formation At Scale",,,"10.1145/3545945.3569885",,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Underrepresented students face many significant challenges in their
education. In particular, they often have a harder time than their peers from
majority groups in building long-term high-quality study groups. This challenge
is exacerbated in remote-learning scenarios, where students are unable to meet
face-to-face and must rely on pre-existing networks for social support.
  We present a scalable system that removes structural obstacles faced by
underrepresented students and supports all students in building inclusive and
flexible study groups. One of our main goals is to make the traditionally
informal and unstructured process of finding study groups for homework more
equitable by providing a uniform but lightweight structure. We aim to provide
students from underrepresented groups an experience that is similar in quality
to that of students from majority groups. Our process is unique in that it
allows students the opportunity to request group reassignments during the
semester if they wish. Unlike other collaboration tools our system is not
mandatory and does not use peer-evaluation.
  We trialed our approach in a 1000+ student introductory Engineering and
Computer Science course that was conducted entirely online during the COVID-19
pandemic. We find that students from underrepresented backgrounds were more
likely to ask for group-matching support compared to students from majority
groups. At the same time, underrepresented students that we matched into study
groups had group experiences that were comparable to students we matched from
majority groups. B-range students in high-comfort and high-quality groups had
improved learning outcomes.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 06:38:55 GMT""},{""version"":""v2"",""created"":""Wed, 16 Feb 2022 06:54:30 GMT""},{""version"":""v3"",""created"":""Thu, 16 Feb 2023 09:25:22 GMT""}]","2023-02-17"
"2202.07466","Gabriel Ramos","Bruno Grisci, Gabriela Kuhn, Felipe Colombelli, V\'itor Matter, Leomar
  Lima, Karine Heinen, Mauricio Pegoraro, Marcio Borges, Sandro Rigo, Jorge
  Barbosa, Rodrigo da Rosa Righi, Cristiano Andr\'e da Costa, Gabriel de
  Oliveira Ramos","Perspectives on risk prioritization of data center vulnerabilities using
  rank aggregation and multi-objective optimization",,,,,"cs.CR cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nowadays, data has become an invaluable asset to entities and companies, and
keeping it secure represents a major challenge. Data centers are responsible
for storing data provided by software applications. Nevertheless, the number of
vulnerabilities has been increasing every day. Managing such vulnerabilities is
essential for building a reliable and secure network environment. Releasing
patches to fix security flaws in software is a common practice to handle these
vulnerabilities. However, prioritization becomes crucial for organizations with
an increasing number of vulnerabilities since time and resources to fix them
are usually limited. This review intends to present a survey of vulnerability
ranking techniques and promote a discussion on how multi-objective optimization
could benefit the management of vulnerabilities risk prioritization. The
state-of-the-art approaches for risk prioritization were reviewed, intending to
develop an effective model for ranking vulnerabilities in data centers. The
main contribution of this work is to point out multi-objective optimization as
a not commonly explored but promising strategy to prioritize vulnerabilities,
enabling better time management and increasing security.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 11:10:22 GMT""}]","2022-04-20"
"2202.07651","Tony Albers","Tony Albers, David M\""uller-Bender and G\""unter Radons","Anti-persistent random walks in time-delayed systems","10 pages, 6 figures",,"10.1103/PhysRevE.105.064212",,"cond-mat.stat-mech nlin.CD","http://creativecommons.org/licenses/by/4.0/","  We show that the occurrence of chaotic diffusion in a typical class of
time-delayed systems with linear instantaneous and nonlinear delayed term can
be well described by an anti-persistent random walk. We numerically investigate
the dependence of all relevant quantities characterizing the random walk on the
strength of the nonlinearity and on the delay. With the help of analytical
considerations, we show that for a decreasing nonlinearity parameter the
resulting dependence of the diffusion coefficient is well described by Markov
processes of increasing order.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:11:11 GMT""}]","2022-07-13"
"2202.07730","Alejandro Saavedra-Nieves","Encarnaci\'on Algaba, Andrea Prieto, Alejandro Saavedra-Nieves","Rankings in the Zerkani network by a game theoretical approach",,,,,"cs.SI math.ST stat.TH","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper introduces the Banzhaf and Banzhaf-Owen values as novel centrality
measures for ranking terrorists in a network. This new approach let integrate
the complete topology (i.e. nodes and edges) of the network and a coalitional
structure on the nodes of the network. More precisely, the characteristics of
the nodes (e.g., terrorists) of the network and their possible relationships
(e.g., types of communication links), as well as coalitional information (e.g.
level of hierarchies) independent of the network. First, for both centrality
measures, we provide approximation algorithms and the corresponding R-codes.
Second, as illustration, we rank the members of the Zerkani network,
responsible for the attacks in Paris (2015) and Brussels (2016). Finally, we
give a comparison between the rankings established by Banzhaf and Banzhaf-Owen
and the rankings obtained when using the Shapley value (cf. Hamers et al.,
2019) and the Owen value as centrality measures
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:04:52 GMT""}]","2022-02-17"
"2202.08100","Hussain Nyeem","Md. Abdul Wahed and Hussain Nyeem","Reversible data hiding with dual pixel-value-ordering and1minimum
  prediction error expansion","Submitted to Plos One [PONE-D-21-21353R1]",,,,"cs.CV cs.MM","http://creativecommons.org/licenses/by/4.0/","  Pixel Value Ordering (PVO) holds an impressive property for high fidelity
Reversible Data Hiding (RDH). In this paper, we introduce a dual-PVO (dPVO) for
Prediction Error Expansion(PEE), and thereby develop a new RDH scheme to offer
a better rate-distortion performance. Particularly, we propose to embed in two
phases: forward and backward. In the forward phase, PVO with classic PEE is
applied to every non-overlapping image block of size 1x3. In the backward
phase,minimum-set and maximum-set of pixels are determined from the pixels
predicted in the forward phase. The minimum set only contains the lowest
predicted pixels and the maximum set contains the largest predicted pixels of
each image block. Proposed dPVO withPEE is then applied to both sets, so that
the pixel values of the minimum set are increased and that of the maximum set
are decreased by a unit value. Thereby, the pixels predicted in the forward
embedding can partially be restored to their original values resulting in both
better-embedded image quality and a higher embedding rate. Experimental results
have recorded a promising rate-distortion performance of our scheme with a
significant improvement of embedded image quality at higher embedding rates
compared to the popular and state-of-the-art PVO-based RDHschemes.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 09:35:56 GMT""}]","2022-02-17"
"2202.08101","Anjan K. Gupta","Arjit Kant Gupta and Anjan K. Gupta","Acoustic analog to multiple avoided-crossings in two coupled acoustic
  cavities","7 pages, 6 figures, suppl info available on request",,,,"physics.ed-ph","http://creativecommons.org/licenses/by/4.0/","  A cylindrical pipe with closed ends and with a partition in-between exhibits
acoustic modes in the two, thus formed, one-dimensional cavities at certain
frequencies. A partial transmission through the partition leads to interaction
between the two cavities' modes and to multiple avoided crossings between
modes' frequencies as a function of the partition position. This is analogous
to a quantum system that has two multi-level and interacting sub-systems and
thus exhibits multiple avoided crossings. Such an acoustic analog is realized
and studied by measuring the sound transmission as a function of frequency
through a pipe with a partially transmitting and movable partition. An
excellent agreement is obtained between the experimental results and a simple
model based on sound wave transmission and reflection at different interfaces.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 03:42:39 GMT""}]","2022-02-17"
"2202.08205","Zhangyang Gao","Zhangyang Gao, Cheng Tan, Lirong Wu, Stan Z. Li","SemiRetro: Semi-template framework boosts deep retrosynthesis prediction",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, template-based (TB) and template-free (TF) molecule graph learning
methods have shown promising results to retrosynthesis. TB methods are more
accurate using pre-encoded reaction templates, and TF methods are more scalable
by decomposing retrosynthesis into subproblems, i.e., center identification and
synthon completion. To combine both advantages of TB and TF, we suggest
breaking a full-template into several semi-templates and embedding them into
the two-step TF framework. Since many semi-templates are reduplicative, the
template redundancy can be reduced while the essential chemical knowledge is
still preserved to facilitate synthon completion. We call our method SemiRetro,
introduce a new GNN layer (DRGAT) to enhance center identification, and propose
a novel self-correcting module to improve semi-template classification.
Experimental results show that SemiRetro significantly outperforms both
existing TB and TF methods. In scalability, SemiRetro covers 98.9\% data using
150 semi-templates, while previous template-based GLN requires 11,647 templates
to cover 93.3\% data. In top-1 accuracy, SemiRetro exceeds template-free G2G
4.8\% (class known) and 6.0\% (class unknown). Besides, SemiRetro has better
training efficiency than existing methods.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 00:38:11 GMT""}]","2022-02-17"
"2202.08372","Dimitris Iakovidis","Dimitrios E. Diamantis and Dimitris K. Iakovidis","Fuzzy Pooling","The final version of the paper has been published in
  https://ieeexplore.ieee.org/document/9197689","IEEE Transactions on Fuzzy Systems, vol. 29, no. 11, pp. 3481 -
  3488, Nov. 2020","10.1109/TFUZZ.2020.3024023",,"cs.LG cs.AI cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Convolutional Neural Networks (CNNs) are artificial learning systems
typically based on two operations: convolution, which implements feature
extraction through filtering, and pooling, which implements dimensionality
reduction. The impact of pooling in the classification performance of the CNNs
has been highlighted in several previous works, and a variety of alternative
pooling operators have been proposed. However, only a few of them tackle with
the uncertainty that is naturally propagated from the input layer to the
feature maps of the hidden layers through convolutions. In this paper we
present a novel pooling operation based on (type-1) fuzzy sets to cope with the
local imprecision of the feature maps, and we investigate its performance in
the context of image classification. Fuzzy pooling is performed by
fuzzification, aggregation and defuzzification of feature map neighborhoods. It
is used for the construction of a fuzzy pooling layer that can be applied as a
drop-in replacement of the current, crisp, pooling layers of CNN architectures.
Several experiments using publicly available datasets show that the proposed
approach can enhance the classification performance of a CNN. A comparative
evaluation shows that it outperforms state-of-the-art pooling approaches.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 11:18:32 GMT""}]","2022-02-18"
"2202.09362","Maryam Kelkinnama","Maryam Kelkinnama and Majid Asadi","Optimal Redundancy Allocation in Coherent Systems with Heterogeneous
  Dependent Components","To appear in J. Applied Probability",,,,"math.OC stat.ME","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper is concerned with the optimal number of redundant allocation to
$n$-component coherent systems consist of heterogeneous dependent components.
We assume that the system is built of $L$ groups of different components,
$L\geq 1$, where there are $n_i$ components in group $i$, and
$\sum_{i=1}^{L}n_i=n$. The problem of interest is to allocate $v_i$ active
redundant components to each component of type $i$, $i=1,\dots, L$. To get the
optimal values of $v_i$, we propose two cost-based criteria. One of them is
introduced based on the costs of renewing the failed components and the costs
of refreshing the alive ones at the system failure time. The other criterion is
proposed based on the costs of replacing the system at its failure time or at a
predetermined time $\tau$, whichever occurs first. The expressions for the
proposed functions are derived using the mixture representation of the system
reliability function based on the notion of survival signature. We assume that
a given copula function models the dependency structure between the components.
In the particular case that the system is a series-parallel structure, we
provide the formulas for the proposed cost-based functions. The results are
discussed numerically for some specific coherent systems.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 13:20:24 GMT""}]","2022-02-22"
"2202.10221","Fl\'avio Ca\c{c}\~ao","Fl\'avio Nakasato Ca\c{c}\~ao, Anna Helena Reali Costa, Natalie
  Unterstell, Liuca Yonaha, Taciana Stec and F\'abio Ishisaki","Tracking environmental policy changes in the Brazilian Federal Official
  Gazette","Accepted at the 15th International Conference on the Computational
  Processing of Portuguese (PROPOR 2022)",,,,"cs.IR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Even though most of its energy generation comes from renewable sources,
Brazil is one of the largest emitters of greenhouse gases in the world, due to
intense farming and deforestation of biomes such as the Amazon Rainforest,
whose preservation is essential for compliance with the Paris Agreement. Still,
regardless of lobbies or prevailing political orientation, all government legal
actions are published daily in the Brazilian Federal Official Gazette (BFOG, or
""Di\'ario Oficial da Uni\~ao"" in Portuguese). However, with hundreds of decrees
issued every day by the authorities, it is absolutely burdensome to manually
analyze all these processes and find out which ones can pose serious
environmental hazards. In this paper, we present a strategy to compose
automated techniques and domain expert knowledge to process all the data from
the BFOG. We also provide the Government Actions Tracker, a highly curated
dataset, in Portuguese, annotated by domain experts, on federal government acts
about the Brazilian environmental policies. Finally, we build and compared four
different NLP models on the classfication task in this dataset. Our best model
achieved a F1-score of $0.714 \pm 0.031$. In the future, this system should
serve to scale up the high-quality tracking of all oficial documents with a
minimum of human supervision and contribute to increasing society's awareness
of government actions.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 21:06:13 GMT""}]","2022-02-22"
"2202.10223","Fabian Denner","Christian Gorges, Fabien Evrard, Berend van Wachem, Fabian Denner","Reducing volume and shape errors in front tracking by
  divergence-preserving velocity interpolation and parabolic fit vertex
  positioning",,,"10.1016/j.jcp.2022.111072",,"physics.flu-dyn physics.comp-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Volume conservation and shape preservation are two well-known issues related
to the advection and remeshing in front tracking. To address these issues, this
paper proposes a divergence-preserving velocity interpolation method and a
parabolic fit vertex positioning method for remeshing operations for
three-dimensional front tracking. Errors in preserving the divergence of the
velocity field when interpolating the velocity from the fluid mesh to the
vertices of the triangles of the front are a primary reason for volume
conservation errors when advecting the front. The proposed interpolation method
preserves the discrete divergence of the fluid velocity by construction and is
compared in this work with other known interpolation methods in divergence-free
and non-divergence-free test cases, with respect to volume conservation and
shape preservation of the front. The presented interpolation method conserves
the volume and shape up to an order of magnitude better than the conventionally
used interpolation methods and is within the range of higher order
interpolation methods at lower computational cost. Additionally, the parabolic
fit vertex positioning method for remeshing operations locally approximates the
front with a smooth polynomial surface, improving volume conservation and shape
preservation by an order of magnitude compared to conventional remeshing
algorithms.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 20:53:23 GMT""}]","2022-02-23"
"2202.10225","Alejandro Frery","Avik Bhattacharya, Subhadip Dey, Alejandro C. Frery","Dual Approaches to Express the Generalized Degree of Polarimetric Purity",,,,,"physics.class-ph physics.optics","http://creativecommons.org/licenses/by-sa/4.0/","  The degree of polarimetric purity is an invariant dimensionless quantity that
characterizes the closeness of a polarization state of a wave to a pure state
and is related to the Von Neumann entropy. The polarimetric purity of a plane
wave characterized by the second-order statistics (i.e., the covariance matrix)
is uniquely described by the degree of polarization. However, the 2D formalism
is only applicable when the wave propagation direction is fixed. This
assumption is typical in optical and radar polarimetric measurements.
Therefore, one must consider all the components to describe the general state
of wave polarization. Starting from Samson and Barakat, several different
concepts have been proposed in the literature to describe the 3D degree of
polarization. We discuss two new ways of achieving such description: by the
Coefficient of Variation and by a Direct Sum Decomposition.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 15:58:49 GMT""}]","2022-02-22"
"2202.12711","Mansoor Haider","Mansoor A. Haider, Katherine J. Pearce, Naomi C. Chesler, Nicholas A.
  Hill and Mette S. Olufsen","Application and reduction of a nonlinear hyperelastic wall model
  capturing ex vivo relationships between fluid pressure, area and wall
  thickness in normal and hypertensive murine left pulmonary arteries",,,,,"q-bio.TO","http://creativecommons.org/licenses/by/4.0/","  Pulmonary hypertension is a cardiovascular disorder manifested by elevated
arterial blood pressure together with vessel wall stiffening and thickening due
to alterations in collagen, elastin and smooth muscle cells. Hypoxia-induced
(type 3) pulmonary hypertension can be studied in animals exposed to a low
oxygen environment for prolonged time periods leading to biomechanical
alterations in vessel wall structure. This study formulates and systematically
reduces a nonlinear elastic structural wall model for a large pulmonary artery,
generating a novel pressure-area relation capturing remodeling in type 3
pulmonary hypertension. The model is calibrated using {\em ex vivo}
measurements of vessel diameter and wall thickness changes, under controlled
flow conditions, in left pulmonary arteries isolated from control and
hypertensive mice. A two-layer, hyperelastic, anisotropic model incorporating
residual stresses is formulated using the Holzapfel-Gasser-Ogden model. Complex
relations predicting vessel area and wall thickness with increasing blood
pressure are derived and calibrated using the data. Sensitivity analysis,
parameter estimation and subset selection are used to systematically reduce the
16-parameter model to one in which a much smaller subset of identifiable
parameters is estimated via solution of an inverse problem. Our final reduced
model includes a single set of three elastic moduli. Estimated ranges of these
parameters demonstrate that nonlinear stiffening is dominated by elastin in the
control animals and by collagen in the hypertensive group. The novel
pressure-area relation developed in this study has potential impact on
one-dimensional fluids network models of vessel wall remodeling in the presence
of cardiovascular disease.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 17:35:28 GMT""}]","2022-02-28"
"2202.12715","Nicha Dvornek","Xueqi Guo, Sule Tinaz, Nicha C. Dvornek","Early Disease Stage Characterization in Parkinson's Disease from
  Resting-state fMRI Data Using a Long Short-term Memory Network","Submitted to IEEE Journal of Biomedical and Health Informatics",,"10.3389/fnimg.2022.952084",,"q-bio.NC cs.LG eess.SP q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Parkinson's disease (PD) is a common and complex neurodegenerative disorder
with 5 stages in the Hoehn and Yahr scaling. Given the heterogeneity of PD, it
is challenging to classify early stages 1 and 2 and detect brain function
alterations. Functional magnetic resonance imaging (fMRI) is a promising tool
in revealing functional connectivity (FC) differences and developing biomarkers
in PD. Some machine learning approaches like support vector machine and
logistic regression have been successfully applied in the early diagnosis of PD
using fMRI data, which outperform classifiers based on manually selected
morphological features. However, the early-stage characterization in FC changes
has not been fully investigated. Given the complexity and non-linearity of fMRI
data, we propose the use of a long short-term memory (LSTM) network to
characterize the early stages of PD. The study included 84 subjects (56 in
stage 2 and 28 in stage 1) from the Parkinson's Progression Markers Initiative
(PPMI), the largest available public PD dataset. Under a repeated 10-fold
stratified cross-validation, the LSTM model reached an accuracy of 71.63%,
13.52% higher than the best traditional machine learning method, indicating
significantly better robustness and accuracy compared with other machine
learning classifiers. We used the learned LSTM model weights to select the top
brain regions that contributed to model prediction and performed FC analyses to
characterize functional changes with disease stage and motor impairment to gain
better insight into the brain mechanisms of PD.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 18:34:11 GMT""}]","2022-07-22"
"2202.12831","Izzat Alsmadi","Gongbo Liang and Izzat Alsmadi","Benchmark Assessment for DeepSpeed Optimization Library",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Deep Learning (DL) models are widely used in machine learning due to their
performance and ability to deal with large datasets while producing high
accuracy and performance metrics. The size of such datasets and the complexity
of DL models cause such models to be complex, consuming large amount of
resources and time to train. Many recent libraries and applications are
introduced to deal with DL complexity and efficiency issues. In this paper, we
evaluated one example, Microsoft DeepSpeed library through classification
tasks. DeepSpeed public sources reported classification performance metrics on
the LeNet architecture. We extended this through evaluating the library on
several modern neural network architectures, including convolutional neural
networks (CNNs) and Vision Transformer (ViT). Results indicated that DeepSpeed,
while can make improvements in some of those cases, it has no or negative
impact on others.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 04:52:28 GMT""}]","2022-02-28"
"2203.02272","Vivek Baruah Thapa","Vivek Baruah Thapa, Monika Sinha","Direct URCA process in light of PREX-2","8 pages, 7 figures, 3 tables",,,,"nucl-th astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We study the implications of the recent development in nuclear symmetry
energy constraints from PREX-2 data on dense matter equation of state and its
impact on dURCA threshold density. In this work, we construct the equation of
state within the framework of covariant density functional theory implementing
coupling schemes of non-linear and density-dependent models and exploring the
coupling parameter space of isovector-vector meson to baryons constrained by
the isospin asymmetry parameter values deduced from recent PREX-2 data. The
modified parameter sets are applied to evaluate the dense matter properties. We
find that the updated data suggests the occurrence of dURCA process within
neutron star even with mass as low as one solar mass.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 15:29:52 GMT""}]","2022-03-07"
"2203.03545","Peng Jiang","Peng Jiang, Krishna Sumanth Muppalla, Qing Wei, Chidambara Natarajan
  Gopal, Chun Wang","Double-Barreled Question Detection at Momentive",,,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Momentive offers solutions in market research, customer experience, and
enterprise feedback. The technology is gleaned from the billions of real
responses to questions asked on the platform. However, people may create biased
questions. A double-barreled question (DBQ) is a common type of biased question
that asks two aspects in one question. For example, ""Do you agree with the
statement: The food is yummy, and the service is great."". This DBQ confuses
survey respondents because there are two parts in a question. DBQs impact both
the survey respondents and the survey owners. Momentive aims to detect DBQs and
recommend survey creators to make a change towards gathering high quality
unbiased survey data. Previous research work has suggested detecting DBQs by
checking the existence of grammatical conjunction. While this is a simple
rule-based approach, this method is error-prone because conjunctions can also
exist in properly constructed questions. We present an end-to-end machine
learning approach for DBQ classification in this work. We handled this
imbalanced data using active learning, and compared state-of-the-art embedding
algorithms to transform text data into vectors. Furthermore, we proposed a
model interpretation technique propagating the vector-level SHAP values to a
SHAP value for each word in the questions. We concluded that the word2vec
subword embedding with maximum pooling is the optimal word embedding
representation in terms of precision and running time in the offline
experiments using the survey data at Momentive. The A/B test and production
metrics indicate that this model brings a positive change to the business. To
the best of our knowledge, this is the first machine learning framework for DBQ
detection, and it successfully differentiates Momentive from the competitors.
We hope our work sheds light on machine learning approaches for bias question
detection.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 00:04:24 GMT""}]","2022-03-08"
"2203.04286","Xiangyong Cao","Xiangyong Cao, Yang Chen, Wenfei Cao","Proximal PanNet: A Model-Based Deep Network for Pansharpening","9 pages, 6 figures",,,,"cs.CV eess.IV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Recently, deep learning techniques have been extensively studied for
pansharpening, which aims to generate a high resolution multispectral (HRMS)
image by fusing a low resolution multispectral (LRMS) image with a high
resolution panchromatic (PAN) image. However, existing deep learning-based
pansharpening methods directly learn the mapping from LRMS and PAN to HRMS.
These network architectures always lack sufficient interpretability, which
limits further performance improvements. To alleviate this issue, we propose a
novel deep network for pansharpening by combining the model-based methodology
with the deep learning method. Firstly, we build an observation model for
pansharpening using the convolutional sparse coding (CSC) technique and design
a proximal gradient algorithm to solve this model. Secondly, we unfold the
iterative algorithm into a deep network, dubbed as Proximal PanNet, by learning
the proximal operators using convolutional neural networks. Finally, all the
learnable modules can be automatically learned in an end-to-end manner.
Experimental results on some benchmark datasets show that our network performs
better than other advanced methods both quantitatively and qualitatively.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 15:49:13 GMT""}]","2022-04-12"
"2203.04960","Xiangyong Cao Mr.","Man Zhou, Keyu Yan, Jinshan Pan, Wenqi Ren, Qi Xie, Xiangyong Cao","Memory-augmented Deep Unfolding Network for Guided Image
  Super-resolution","24 pages, 16 figures",,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Guided image super-resolution (GISR) aims to obtain a high-resolution (HR)
target image by enhancing the spatial resolution of a low-resolution (LR)
target image under the guidance of a HR image. However, previous model-based
methods mainly takes the entire image as a whole, and assume the prior
distribution between the HR target image and the HR guidance image, simply
ignoring many non-local common characteristics between them. To alleviate this
issue, we firstly propose a maximal a posterior (MAP) estimation model for GISR
with two types of prior on the HR target image, i.e., local implicit prior and
global implicit prior. The local implicit prior aims to model the complex
relationship between the HR target image and the HR guidance image from a local
perspective, and the global implicit prior considers the non-local
auto-regression property between the two images from a global perspective.
Secondly, we design a novel alternating optimization algorithm to solve this
model for GISR. The algorithm is in a concise framework that facilitates to be
replicated into commonly used deep network structures. Thirdly, to reduce the
information loss across iterative stages, the persistent memory mechanism is
introduced to augment the information representation by exploiting the Long
short-term memory unit (LSTM) in the image and feature spaces. In this way, a
deep network with certain interpretation and high representation ability is
built. Extensive experimental results validate the superiority of our method on
a variety of GISR tasks, including Pan-sharpening, depth image
super-resolution, and MR image super-resolution.
","[{""version"":""v1"",""created"":""Sat, 12 Feb 2022 15:37:13 GMT""}]","2022-03-11"
"2203.11315","Zbyn\v{e}k Pitra","Zbyn\v{e}k Pitra, Jan Koza, Ji\v{r}\'i Tumpach, Martin Hole\v{n}a","Landscape Analysis for Surrogate Models in the Evolutionary Black-Box
  Context","25 pages main article, 28 pages supplementary material, 3 figures,
  currently under review at Evolutionary Computation journal",,,,"cs.NE cs.LG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Surrogate modeling has become a valuable technique for black-box optimization
tasks with expensive evaluation of the objective function. In this paper, we
investigate the relationship between the predictive accuracy of surrogate
models and features of the black-box function landscape. We also study
properties of features for landscape analysis in the context of different
transformations and ways of selecting the input data. We perform the landscape
analysis of a large set of data generated using runs of a surrogate-assisted
version of the Covariance Matrix Adaptation Evolution Strategy on the noiseless
part of the Comparing Continuous Optimisers benchmark function testbed.
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 21:06:56 GMT""},{""version"":""v2"",""created"":""Sun, 2 Oct 2022 18:46:49 GMT""}]","2022-10-04"
"2205.01090","David Leiser","David Leiser (1), Stefan Loehle (1), Stefanos Fasoulas (2) ((1) High
  Enthalpy Flow Diagnostics Group, Institute of Space Systems, University of
  Stuttgart, Germany, (2) Institute of Space Systems, University of Stuttgart,
  Germany)","Spectral Features for Re-entry Break-up Event Identification","submitted to Journal of Spacecraft and Rockets",,,,"astro-ph.IM physics.plasm-ph physics.space-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The fragmentation of two aerospace aluminum alloys is investigated in a
ground testing facility including mechanical loads as occurring due to
aerodynamic forces in a real atmospheric entry event at three trajectory
points. The emission spectroscopic analysis shows that these materials fail
after distinct alkali metal features are observed in the spectra. The two
alloys feature characteristic emissions of the different alkali metals. The
presence of lithium lines that have previously been exclusively attributed to
battery failure in observation campaigns may be considered as a marker for
aluminum breakup. This is particularly interesting for future entry
observations because it allows a new insight into the structural failure
processes of the demising spacecraft. The lack of emission of alloying elements
points to these spectra being a candidate for the determination of spacecraft
demise. The identification of such features in ground testing will allow a more
certain identification of specific break-up events
","[{""version"":""v1"",""created"":""Fri, 11 Feb 2022 21:24:37 GMT""}]","2022-05-04"
