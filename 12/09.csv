"2212.04364","Ignacio Araya","Giorgos Anastasiou, Ignacio J. Araya, Mairym Busnego-Barrientos,
  Cristobal Corral and Nelson Merino","Conformal renormalization of scalar-tensor theories","28 pages, accepted in PRD","Phys. Rev. D 107, (2023) 104049","10.1103/PhysRevD.107.104049",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a conformally coupled scalar-tensor theory with a quartic potential
possessing local conformal symmetry up to a boundary term. We show that
requiring the restoration of the full local conformal symmetry fixes the
counterterms that render the on-shell action finite. The building block of the
resulting action is a conformally covariant tensor which is constructed out of
the metric and the scalar field and it has the same conformal weight as the
Weyl tensor. This allows us to obtain the counterterms for the scalar-tensor
sector in a closed form. The finiteness of the conformally complete version of
the action is suggestive on the validity of the Conformal Renormalization
prescription. We extend this theory by adding the Conformal Gravity action and
also the Einstein-AdS action written in McDowell-Mansouri form. Even though the
latter breaks the conformal symmetry, we find that the action is still
renormalized provided a suitable falloff of the scalar field when considering
asymptotically locally anti-de Sitter solutions. Black hole solutions in these
theories are studied, for which the Hawking temperature and the partition
function to first order in the saddle-point approximation are calculated,
providing a concrete example of this renormalization scheme.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:03:22 GMT""},{""version"":""v2"",""created"":""Thu, 11 May 2023 20:18:55 GMT""}]","2023-05-25"
"2212.04365","Haifeng Li","Jiawei Zhu, Mei Hong, Ronghua Du, Haifeng Li","Alleviating neighbor bias: augmenting graph self-supervise learning with
  structural equivalent positive samples","8 pages, 5 figures, 8 tables",,,,"cs.LG cs.AI cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, using a self-supervised learning framework to learn the
general characteristics of graphs has been considered a promising paradigm for
graph representation learning. The core of self-supervised learning strategies
for graph neural networks lies in constructing suitable positive sample
selection strategies. However, existing GNNs typically aggregate information
from neighboring nodes to update node representations, leading to an
over-reliance on neighboring positive samples, i.e., homophilous samples; while
ignoring long-range positive samples, i.e., positive samples that are far apart
on the graph but structurally equivalent samples, a problem we call ""neighbor
bias."" This neighbor bias can reduce the generalization performance of GNNs. In
this paper, we argue that the generalization properties of GNNs should be
determined by combining homogeneous samples and structurally equivalent
samples, which we call the ""GC combination hypothesis."" Therefore, we propose a
topological signal-driven self-supervised method. It uses a topological
information-guided structural equivalence sampling strategy. First, we extract
multiscale topological features using persistent homology. Then we compute the
structural equivalence of node pairs based on their topological features. In
particular, we design a topological loss function to pull in non-neighboring
node pairs with high structural equivalence in the representation space to
alleviate neighbor bias. Finally, we use the joint training mechanism to adjust
the effect of structural equivalence on the model to fit datasets with
different characteristics. We conducted experiments on the node classification
task across seven graph datasets. The results show that the model performance
can be effectively improved using a strategy of topological signal enhancement.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:04:06 GMT""}]","2022-12-09"
"2212.04366","Glenn Van Wallendael","Yentl Vermeulen, Sam Van Damme, Glenn Van Wallendael, Filip De Turck,
  Maria Torres Vega","Haptic Interactions for Extended Reality",,,,,"cs.HC cs.MM","http://creativecommons.org/licenses/by/4.0/","  This research investigates whether the interaction methods of XR headsets can
be improved by using haptic feedback. As a first and most common technique,
indirect interactions are considered. Indirect interactions correspond to
manipulations of virtual objects from a virtual distance using pre-defined hand
gestures. As a second interaction technique, direct interaction (namely DIM)
has been implemented where the user manipulates objects by virtually touching
these with their hands. A third interaction method extends the previous one
with haptic feedback (namely HEDIM). These 3 methods are compared with each
other based on objective and subjective user tests, also taking into account
financial considerations. This research concludes that the DIM improves upon
the standard indirect method. Additionally, it has been observed that haptic
feedback could enhance the DIM in specific situations. Nevertheless, when
considering the current financial cost, our subjects were not convinced of the
small improvements haptic feedback brings.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:06:33 GMT""}]","2022-12-09"
"2212.04368","Diego Paiva Pires","Guilherme Fiusa, Diogo O. Soares-Pinto, Diego Paiva Pires","Fidelity-based distance bounds for $N$-qubit approximate quantum error
  correction","12 pages, 6 figures. Close to published version","Phys. Rev. A 107, 032422 (2023)","10.1103/PhysRevA.107.032422",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Eastin-Knill theorem is a central result of quantum error correction
theory and states that a quantum code cannot correct errors exactly, possess
continuous symmetries, and implement a universal set of gates transversely. As
a way to circumvent this result, there are several approaches in which one
gives up on either exact error correction or continuous symmetries. In this
context, it is common to employ a complementary measure of fidelity as a way to
quantify quantum state distinguishability and benchmark approximations in error
correction. Despite having useful properties, evaluating fidelity measures
stands as a challenging task for quantum states with a large number of
entangled qubits. With that in mind, we address two distance measures based on
the sub- and superfidelities as a way to bound error approximations, which in
turn require a lower computational cost. We model the lack of exact error
correction to be equivalent to the action of a single dephasing channel,
evaluate the proposed fidelity-based distances both analytically and
numerically, and obtain a closed-form expression for a general $N$-qubit
quantum state. We illustrate our bounds with two paradigmatic examples, an
$N$-qubit mixed GHZ state and an $N$-qubit mixed $W$ state.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:10:58 GMT""},{""version"":""v2"",""created"":""Sat, 25 Mar 2023 19:35:27 GMT""}]","2023-03-28"
"2212.04369","Meng Huang","Meng Huang and Francesco A. Evangelista","A benchmark study of core-excited states of organic molecules computed
  with the generalized active space driven similarity renormalization group",,,"10.1063/5.0137096",,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work examines the accuracy and precision of X-ray absorption spectra
computed with a multireference approach that combines generalized active space
(GAS) references with the driven similarity renormalization group (DSRG). We
employ the X-ray absorption benchmark of organic molecules (XABOOM) set,
consisting of 116 transitions from mostly organic molecules [T. Fransson et
al., J. Chem. Theory Comput. 17, 1618 (2021)]. Several approximations to a
full-valence active space are examined and benchmarked. Absolute excitation
energies and intensities computed with the GAS-DSRG truncated to second-order
in perturbation theory are found to systematically underestimate experimental
and reference theoretical values. Third-order perturbative corrections
significantly improve the accuracy of GAS-DSRG absolute excitation energies,
bringing the mean absolute deviation from experimental values down to 0.32 eV.
The ozone molecule and glyoxylic acid are particularly challenging for
second-order perturbation theory and are examined in detail to assess the
importance of active space truncation and intruder states.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:13:01 GMT""},{""version"":""v2"",""created"":""Mon, 19 Dec 2022 03:59:39 GMT""}]","2023-04-05"
"2212.04370","Nathan Satchell","N. Satchell, S. Gupta, M. Maheshwari, P. M. Shepley, M. Rogers, O.
  Cespedes, G. Burnell","Thin film epitaxial [111] Co$_{50}$Pt$_{50}$: Structure, magnetisation,
  and spin polarisation","17 pages main text, 7 figures main text. 12 pages SI, 10 figures SI",,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Ferromagnetic films with perpendicular magnetic anisotropy are of interest in
spintronics and superconducting spintronics. Perpendicular magnetic anisotropy
can be achieved in thin ferromagnetic multilayer structures, when the
anisotropy is driven by carefully engineered interfaces. Devices with multiple
interfaces are disadvantageous for our application in superconducting
spintronics, where the current perpendicular to plane is affected by the
interfaces. Robust intrinsic PMA can be achieved in certain Co$_x$Pt$_{100-x}$
alloys and compounds at any thickness, without increasing the number of
interfaces. Here, we grow equiatomic Co$_{50}$Pt$_{50}$ and report a
comprehensive study on the structural, magnetic, and spin-polarisation
properties in the $L1_1$ and $L1_0$ ordered compounds. Primarily, interest in
Co$_{50}$Pt$_{50}$ has been in the $L1_0$ crystal structure, where layers of Pt
and Co are stacked alternately in the [100] direction. There has been less work
on $L1_1$ crystal structure, where the stacking is in the [111] direction. For
the latter $L1_1$ crystal structure, we find magnetic anisotropy perpendicular
to the film plane. For the former $L1_0$ crystal structure, the magnetic
anisotropy is perpendicular to the [100] plane, which is neither in-plane or
out-of-plane in our samples. We obtain a value for the ballistic spin
polarisation of the $L1_1$ and $L1_0$ Co$_{50}$Pt$_{50}$ to be $47\pm3\%$.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:13:34 GMT""},{""version"":""v2"",""created"":""Wed, 31 May 2023 09:44:40 GMT""}]","2023-06-01"
"2212.04371","Ergute Bao","Ergute Bao, Yizheng Zhu, Xiaokui Xiao, Yin Yang, Beng Chin Ooi,
  Benjamin Hong Meng Tan, Khin Mi Mi Aung","Skellam Mixture Mechanism: a Novel Approach to Federated Learning with
  Differential Privacy",,,,,"cs.LG cs.CR","http://creativecommons.org/licenses/by/4.0/","  Deep neural networks have strong capabilities of memorizing the underlying
training data, which can be a serious privacy concern. An effective solution to
this problem is to train models with differential privacy, which provides
rigorous privacy guarantees by injecting random noise to the gradients. This
paper focuses on the scenario where sensitive data are distributed among
multiple participants, who jointly train a model through federated learning
(FL), using both secure multiparty computation (MPC) to ensure the
confidentiality of each gradient update, and differential privacy to avoid data
leakage in the resulting model. A major challenge in this setting is that
common mechanisms for enforcing DP in deep learning, which inject real-valued
noise, are fundamentally incompatible with MPC, which exchanges finite-field
integers among the participants. Consequently, most existing DP mechanisms
require rather high noise levels, leading to poor model utility. Motivated by
this, we propose Skellam mixture mechanism (SMM), an approach to enforce DP on
models built via FL. Compared to existing methods, SMM eliminates the
assumption that the input gradients must be integer-valued, and, thus, reduces
the amount of noise injected to preserve DP. Further, SMM allows tight privacy
accounting due to the nice composition and sub-sampling properties of the
Skellam distribution, which are key to accurate deep learning with DP. The
theoretical analysis of SMM is highly non-trivial, especially considering (i)
the complicated math of differentially private deep learning in general and
(ii) the fact that the mixture of two Skellam distributions is rather complex,
and to our knowledge, has not been studied in the DP literature. Extensive
experiments on various practical settings demonstrate that SMM consistently and
significantly outperforms existing solutions in terms of the utility of the
resulting model.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:13:35 GMT""}]","2022-12-09"
"2212.04372","Michael Short","Purusothmn Nair S. Bhasker Nair, Raymond R. Tan, Dominic C. Y. Foo,
  Disni Gamaralalage, Michael Short","DECO2 An Open-source Energy System Decarbonisation Planning Software
  Including Negative Emissions Technologies",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The deployment of CO2 capture and storage (CCS) and negative emissions
technologies (NETs) are crucial to meet the net-zero target by year 2050, as
emphasised by the Glasgow Climate Pact. Over the years, several energy planning
models have been developed to address the temporal aspects of carbon
management. However, limited works have incorporated CCS and NETs for bottom-up
energy planning at the individual plant scale, which is considered in this
work. The novel formulation is implemented in an open-source energy system
software that has been developed in this work for optimal decarbonisation
planning. The DECarbonation Options Optimisation (DECO2) software considers
multiperiod energy planning with a superstructural model and was developed in
Python with an integrated user interface in Microsoft Excel. The software
application is demonstrated with two scenarios that differ in terms of the
availabilities of mitigation technologies. Results demonstrated the potential
of fuel substitutions for low-carbon alternatives in existing coal and natural
gas power plants. Additionally, once NETs are mature and are available for
commercial deployment, their deployment is crucial in aiding CO2 removal in
minimal investment costs scenarios. Overall, the newly developed open-source
software demonstrates the importance of determining the optimal deployment of
mitigation technologies in meeting climate change targets for each period.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:13:36 GMT""}]","2022-12-19"
"2212.04373","Alberto Quattrini Li","Pengzhi Yang, Haowen Liu, Monika Roznere, Alberto Quattrini Li","Monocular Camera and Single-Beam Sonar-Based Underwater Collision-Free
  Navigation with Domain Randomization","Accepted at the International Symposium on Robotics Research (ISRR),
  2022",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Underwater navigation presents several challenges, including unstructured
unknown environments, lack of reliable localization systems (e.g., GPS), and
poor visibility. Furthermore, good-quality obstacle detection sensors for
underwater robots are scant and costly; and many sensors like RGB-D cameras and
LiDAR only work in-air. To enable reliable mapless underwater navigation
despite these challenges, we propose a low-cost end-to-end navigation system,
based on a monocular camera and a fixed single-beam echo-sounder, that
efficiently navigates an underwater robot to waypoints while avoiding nearby
obstacles. Our proposed method is based on Proximal Policy Optimization (PPO),
which takes as input current relative goal information, estimated depth images,
echo-sounder readings, and previous executed actions, and outputs 3D robot
actions in a normalized scale. End-to-end training was done in simulation,
where we adopted domain randomization (varying underwater conditions and
visibility) to learn a robust policy against noise and changes in visibility
conditions. The experiments in simulation and real-world demonstrated that our
proposed method is successful and resilient in navigating a low-cost underwater
robot in unknown underwater environments. The implementation is made publicly
available at https://github.com/dartmouthrobotics/deeprl-uw-robot-navigation.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:15:04 GMT""}]","2022-12-09"
"2212.04374","Natalia Cherezova","Natalia Cherezova, Dmitri Mihhailov, Sergei Devadze, Artur Jutman","HLS-based Optimization of Tau Triggering Algorithm for LHC: a case study","6 pages, 5 figures, 2022 18th Biennial Baltic Electronics Conference
  (BEC)",,"10.1109/BEC56180.2022.9935599",,"cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the current increase in the data produced by the Large Hadron Collider
(LHC) at CERN, it becomes important to process this data in a corresponding
manner. To begin with, to efficiently select events that contain relevant
information from a massive flow of data. This is the task of the tau lepton
decay triggering algorithm. The implementation is based on the High-Level
Synthesis (HLS) approach that allows generating a hardware description of the
design from the algorithm written in a high-level programming language like
C++. HLS tools are intended to decrease the time and complexity of hardware
design development, however, their capabilities are limited. The development of
an efficient application requires substantial knowledge of the hardware design
and HLS specifics. This paper presents the optimizations introduced to the
algorithm that improved latency and area and more importantly solved the
problems with the routing, making it possible to implement the algorithm on the
FPGA fabric.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:16:41 GMT""}]","2022-12-09"
"2212.04375","Adam Fleisher","Adam J. Fleisher, Zeeshan Ahmed, Tobias Herman, Matthew R. Hartings","Dual electro-optic frequency comb photonic thermometry","4 pages, 3 figures, 33 references",,"10.1364/OL.482838",,"physics.optics physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report a precision realization of photonic thermometry using dual-comb
spectroscopy to interrogate a $\pi$-phase-shifted fiber Bragg grating. We
achieve read-out stability of 7.5 mK at 1 s and resolve temperature changes of
similar magnitude--sufficient for most industrial applications. Our dual-comb
approach enables rapid sensing of dynamic temperature, and our scalable and
reconfigurable electro-optic generation scheme enables a broad sensing range
without laser tuning. Reproducibility on the International Temperature Scale of
1990 is tested, and ultimately limited by the frequency reference and
check-thermometer stability. Our demonstration opens the door for a universal
interrogator deployable to multiple photonic devices in parallel. Applications
include on-chip measurements to simultaneously evaluate quantities like
temperature, pressure, humidity, magnetic field and radiation dose.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:17:12 GMT""}]","2023-04-26"
"2212.04376","Flavien L\'eger","Flavien L\'eger, Fran\c{c}ois-Xavier Vialard","A geometric Laplace method",,,,,"math.DG math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A classical tool for approximating integrals is the Laplace method. The
first-order, as well as the higher-order Laplace formula is most often written
in coordinates without any geometrical interpretation. In this article,
motivated by a situation arising, among others, in optimal transport, we give a
geometric formulation of the first-order term of the Laplace method. The
central tool is the Kim-McCann Riemannian metric which was introduced in the
field of optimal transportation. Our main result expresses the first-order term
with standard geometric objects such as volume forms, Laplacians, covariant
derivatives and scalar curvatures of two different metrics arising naturally in
the Kim-McCann framework. Passing by, we give an explicitly quantified version
of the Laplace formula, as well as examples of applications.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:17:33 GMT""}]","2022-12-09"
"2212.04377","Shahriar Rezghi Shirsavar","Shahriar Rezghi Shirsavar, Abdol-Hossein Vahabie, Mohammad-Reza A.
  Dehaqani","Models Developed for Spiking Neural Networks","9 pages, 4 figures, 2 tables",,,,"cs.NE cs.CV q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Emergence of deep neural networks (DNNs) has raised enormous attention
towards artificial neural networks (ANNs) once again. They have become the
state-of-the-art models and have won different machine learning challenges.
Although these networks are inspired by the brain, they lack biological
plausibility, and they have structural differences compared to the brain.
Spiking neural networks (SNNs) have been around for a long time, and they have
been investigated to understand the dynamics of the brain. However, their
application in real-world and complicated machine learning tasks were limited.
Recently, they have shown great potential in solving such tasks. Due to their
energy efficiency and temporal dynamics there are many promises in their future
development. In this work, we reviewed the structures and performances of SNNs
on image classification tasks. The comparisons illustrate that these networks
show great capabilities for more complicated problems. Furthermore, the simple
learning rules developed for SNNs, such as STDP and R-STDP, can be a potential
alternative to replace the backpropagation algorithm used in DNNs.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:18:53 GMT""}]","2022-12-09"
"2212.04378","Dmitry Mylnikov Dr","Dmitry Mylnikov, Elena I. Titova, Mikhail A. Kashchenko, Ilya V.
  Safonov, Sergey S. Zhukov, Valentin A. Semkin, Kostya S. Novoselov, Denis A.
  Bandurin, and Dmitry A. Svintsov","Terahertz photoconductivity in bilayer graphene transistors: evidence
  for tunneling at gate-induced junctions",,,"10.1021/acs.nanolett.2c04119",,"cond-mat.mes-hall physics.optics","http://creativecommons.org/licenses/by/4.0/","  Photoconductivity of novel materials is the key property of interest for
design of photodetectors, optical modulators, and switches. Despite the
photoconductivity of most novel 2d materials has been studied both
theoretically and experimentally, the same is not true for 2d p-n junctions
that are necessary blocks of most electronic devices. Here, we study the
sub-terahertz photocoductivity of gapped bilayer graphene with
electrically-induced p-n junctions. We find a strong positive contribution from
junctions to resistance, temperature resistance coefficient and
photo-resistivity at cryogenic temperatures T ~ 20 K. The contribution to these
quantities from junctions exceeds strongly the bulk values at uniform channel
doping even at small band gaps ~ 10 meV. We further show that positive junction
photoresistance is a hallmark of interband tunneling, and not of intra-band
thermionic conduction. Our results point to the possibility of creating various
interband tunneling devices based on bilayer graphene, including
steep-switching transistors and selective sensors.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:21:45 GMT""}]","2022-12-23"
"2212.04379","H\'elder Larragu\'ivel","Jakub Jankowski, Piotr Kucharski, H\'elder Larragu\'ivel, Dmitry
  Noshchenko, Piotr Su{\l}kowski","Quiver diagonalization and open BPS states","37 pages",,,,"hep-th math-ph math.MP math.QA math.RT","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We show that motivic Donaldson-Thomas invariants of a~symmetric quiver $Q$,
captured by the generating function $P_Q$, can be encoded in another quiver
$Q^{(\infty)}$ of (almost always) infinite size, whose only arrows are loops,
and whose generating function $P_{Q^{(\infty)}}$ is equal to $P_Q$ upon
appropriate identification of generating parameters. Consequences of this
statement include a generalization of the proof of integrality of
Donaldson-Thomas and Labastida-Mari\~{n}o-Ooguri-Vafa invariants that count
open BPS states, as well as expressing motivic Donaldson-Thomas invariants of
an arbitrary symmetric quiver in terms of invariants of $m$-loop quivers. In
particular, this means that the already known combinatorial interpretation of
invariants of $m$-loop quivers extends to arbitrary symmetric quivers.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:22:59 GMT""}]","2022-12-09"
"2212.04380","Yoshiaki Yasuno","Yoshiaki Yasuno","Optical coherence tomography -- principles, implementation, and
  applications in ophthalmology",,,,,"physics.med-ph physics.ins-det physics.optics","http://creativecommons.org/licenses/by-sa/4.0/","  This short textbook was written for someone who newly start studying, doing
research, or development about optical coherence tomography (OCT) or using OCT.
The first chapter summarizes the concept and the history of OCT. In the second
chapter, the technologies of OCT are summarized, which includes the
mathematical principle, hardware implementation, the instructions for designs
such as interferometer and wavelength selections, and theories of resolutions
and sensitivity. In the third chapter, some examples of ophthalmic applications
of OCT are described. In the last chapter, instructions for next learning steps
are given.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:23:01 GMT""}]","2022-12-09"
"2212.04381","Lukas J. Furtak","Lukas J. Furtak (1), Adi Zitrin (1), John R. Weaver (2), Hakim Atek
  (3), Rachel Bezanson (4), Ivo Labbe (5), Katherine E. Whitaker (2), Joel Leja
  (6), Sedona H. Price (4), Gabriel B. Brammer (7), Bingjie Wang (6), Danilo
  Marchesini (8), Richard Pan (8), Pratika Dayal (9), Pieter van Dokkum (10),
  Robert Feldmann (11), Seiji Fujimoto (12), Marijn Franx (13), Gourav Khullar
  (4), Erica J. Nelson (14) and Lamiya A. Mowla (15) ((1) Ben-Gurion University
  of the Negev, (2) University of Massachusetts, (3) Institut d'Astrophysique
  de Paris, (4) University of Pittsburgh, (5) Swinburne University of
  Technology, (6) The Pennsylvania State University, (7) Cosmic Dawn Center,
  (8) Tufts University, (9) Kapteyn Astronomical Institute, (10) Yale
  University, (11) University of Zurich, (12) University of Texas at Austin,
  (13) Leiden Observatory, (14) University of Colorado, (15) Dunlap Institute
  for Astronomy and Astrophysics)","UNCOVERing the extended strong lensing structures of Abell 2744 with the
  deepest JWST imaging","Accepted for publication in MNRAS. Updated to match the published
  version",,"10.1093/mnras/stad1627",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new parametric lens model for the massive galaxy cluster
Abell~2744 based on the new ultra-deep JWST imaging taken in the framework of
the UNCOVER program. These observations constitute the deepest JWST images of a
lensing cluster to date, adding to the existing deep Hubble Space Telescope
(HST) images and the recent JWST ERS and DDT data taken for this field. The
wide field-of-view of UNCOVER ($\sim45$ arcmin$^2$) extends beyond the
cluster's well-studied central core and reveals a spectacular wealth of
prominent lensed features around two massive cluster sub-structures in the
north and north-west, where no multiple images were previously known. The 75
newly uncovered multiple images and candidates of 16 sources allow us, for the
first time, to constrain the lensing properties and total mass distribution
around these extended cluster structures using strong lensing (SL). Our model
yields an effective Einstein radius of $\theta_{E,\mathrm{main}}\simeq23''$ for
the main cluster core (for $z_{\mathrm{s}}=2$), enclosing a mass of
$M(\theta<\theta_{E,\mathrm{main}})\simeq7.7\times10^{13}$ M$_{\odot}$, and
$\theta_{E,\mathrm{NW}}\simeq13''$ for the newly discovered north-western SL
structure enclosing $M(\theta<\theta_{E,\mathrm{NW}})\simeq2.2\times10^{13}$
M$_{\odot}$. The northern clump is somewhat less massive with
$\theta_{E,\mathrm{N}}\simeq7''$ enclosing
$M(\theta<\theta_{E,\mathrm{N}})\simeq8\times10^{12}$ M$_{\odot}$. We find the
northern sub-structures of Abell~2744 to broadly agree with the findings from
weak lensing (WL) and align with the filamentary structure found by these
previous studies. Our model in particular reveals a large area of high
magnifications between the various cluster structures, which will be paramount
for lensed galaxy studies in the UNCOVER field. The model is made publicly
available to accompany the first UNCOVER data release.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:23:14 GMT""},{""version"":""v2"",""created"":""Thu, 15 Dec 2022 20:46:38 GMT""},{""version"":""v3"",""created"":""Sun, 28 May 2023 08:59:51 GMT""}]","2023-06-07"
"2212.04382","Alan Karr","Alan F. Karr, Zac Bowen, Adam A. Porter","Structure of Classifier Boundaries: Case Study for a Naive Bayes
  Classifier",,,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  Whether based on models, training data or a combination, classifiers place
(possibly complex) input data into one of a relatively small number of output
categories. In this paper, we study the structure of the boundary--those points
for which a neighbor is classified differently--in the context of an input
space that is a graph, so that there is a concept of neighboring inputs, The
scientific setting is a model-based naive Bayes classifier for DNA reads
produced by Next Generation Sequencers. We show that the boundary is both large
and complicated in structure. We create a new measure of uncertainty, called
Neighbor Similarity, that compares the result for a point to the distribution
of results for its neighbors. This measure not only tracks two inherent
uncertainty measures for the Bayes classifier, but also can be implemented, at
a computational cost, for classifiers without inherent measures of uncertainty.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:23:42 GMT""}]","2022-12-09"
"2212.04383","Lahcen Lamgouni","Lahcen Lamgouni","C-polynomials and LC-functions: towards a generalization of the Hurwitz
  zeta function","30 pages, 6 figures",,,,"math.NT math.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Let $f(t)=\sum_{n=0}^{+\infty}\frac{C_{f,n}}{n!}t^n$ be an analytic function
at $0$, and let $C_{f, n}(x)=\sum_{k=0}^{n}\binom{n}{k}C_{f,k} x^{n-k}$ be the
sequence of Appell polynomials, referred to as $\textit{C-polynomials
associated to f}$, constructed from the sequence of coefficients $C_{f,n}$. We
also define $P_{f,n}(x)$ as the sequence of C-polynomials associated to the
function $p_{f}(t)=f(t)(e^t-1)/t$, called $\textit{P-polynomials associated to
f}$. This work investigates three main topics. Firstly, we examine the
properties of C-polynomials and P-polynomials and the underlying features that
connect them. Secondly, drawing inspiration from the definition of
P-polynomials and subject to an additional condition on $f$, we introduce and
study the complex-variable function
$P_{f}(s,z)=\sum_{k=0}^{+\infty}\binom{z}{k}P_{f,k}s^{z-k}$, which generalizes
the $s^z$ function and is denoted by $s^{(z,f)}$. Thirdly, the paper's
significant contribution is the generalization of the Hurwitz zeta function and
its fundamental properties, most notably Hurwitz's formula, by constructing a
novel class of functions defined by
$L(z,f)=\sum_{n=n_{f}}^{+\infty}n^{(-z,f)}$, which are intrinsically linked to
C-polynomials and referred to as $\textit{LC-functions associated to f}$ (the
constant $n_{f}$ is a positive integer dependent on the choice of $f$). This
research offers a detailed analysis of C-polynomials, P-polynomials, and
LC-functions associated to a given analytic function $f$, thoroughly examining
their interrelations and introducing unexplored research directions for a novel
and expansive class of LC-functions possessing a functional equation equivalent
to that of the Riemann zeta function, thereby highlighting the potential
applications and implications of the findings.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:25:42 GMT""},{""version"":""v2"",""created"":""Mon, 12 Dec 2022 18:51:15 GMT""},{""version"":""v3"",""created"":""Fri, 5 May 2023 21:03:35 GMT""}]","2023-05-09"
"2212.04384","Lewis Riley Dr.","L. A. Riley, I.C.S. Hay, L. T. Baby, A. L. Conley, P. D. Cottle, J.
  Esparza, K. Hanselman, B. Kelly, K. W. Kemper, K. T. Macon, G. W. McCann, M.
  W. Quirin, R. Renom, R. L. Saunders, M. Spieker, and I. Wiedenh\""over","$^{54}$Fe($d$,$p$)$^{55}$Fe and the evolution of single neutron energies
  in the $N=29$ isotones","16 pages, 6 figures. arXiv admin note: text overlap with
  arXiv:2106.05781","Phys. Rev. C 106, 064308 (2022)","10.1103/PhysRevC.106.064308",,"nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A measurement of the $^{54}$Fe($d$,$p$)$^{55}$Fe reaction at 16 MeV was
performed using the Florida State University Super-Enge Split-Pole Spectrograph
to determine single-neutron energies for the $2p_{3/2}$, $2p_{1/2}$,
$1f_{5/2}$, $1g_{9/2}$ and $2d_{5/2}$ orbits. Two states were observed that had
not been observed in previous (d, p) measurements. In addition, we made angular
momentum transfer, \textit{L}, assignments to four states and changed
\textit{L} assignments from previous ($d$, $p$) measurements for nine more
states. The spin-orbit splitting between the $2p_{3/2}$ and $2p_{1/2}$ orbits
is similar to that in the other $N=29$ isotones and not close to zero as a
previous measurement suggested. While the $1f_{5/2}$ single neutron energy is
significantly lower in $^{55}$Fe than in $^{51}$Ti, as predicted by a covariant
density functional theory calculation, the single-neutron energy for this orbit
in $^{55}$Fe is more than 1 MeV higher than the calculation suggests, although
it is only 400 keV above the $2p_{1/2}$ orbit. The summed spectroscopic
strength we observed for the $1g_{9/2}$ orbit up to the single-neutron
separation energy of 9.3 MeV is only 0.3. This is surprising because the
$1g_{9/2}$ orbit is predicted by Togashi \textit{et al.} to be located only 5.5
MeV above the $2p_{3/2}$ orbit.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:26:01 GMT""}]","2022-12-09"
"2212.04385","Dong An","Dong An, Yuankai Qi, Yangguang Li, Yan Huang, Liang Wang, Tieniu Tan,
  Jing Shao","BEVBert: Topo-Metric Map Pre-training for Language-guided Navigation",,,,,"cs.CV cs.AI cs.CL cs.RO","http://creativecommons.org/licenses/by/4.0/","  Existing approaches for vision-and-language navigation (VLN) are mainly based
on cross-modal reasoning over discrete views. However, this scheme may hamper
an agent's spatial and numerical reasoning because of incomplete objects within
a single view and duplicate observations across views. A potential solution is
mapping discrete views into a unified birds's-eye view, which can aggregate
partial and duplicate observations. Existing metric maps could achieve this
goal, but they suffer from less expressive semantics (e.g. usually predefined
labels) and limited map size, which weakens an agent's language grounding and
long-term planning ability. Inspired by the robotics community, we introduce
hybrid topo-metric maps into VLN, where a topological map is used for long-term
planning and a metric map for short-term reasoning. Beyond mapping with more
expressive deep features, we further design a pre-training framework via the
hybrid map to learn language-informed map representations, which enhances
cross-modal grounding and facilitates the final language-guided navigation
goal. Extensive experiments demonstrate the effectiveness of the map-based
route for VLN, and the proposed method sets the new state-of-the-art on three
VLN benchmarks.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:27:54 GMT""}]","2022-12-09"
"2212.04386","Markus Worchel","Markus Worchel, Rodrigo Diaz, Weiwen Hu, Oliver Schreer, Ingo
  Feldmann, Peter Eisert","Multi-View Mesh Reconstruction with Neural Deferred Shading","CVPR 2022, project page:
  https://fraunhoferhhi.github.io/neural-deferred-shading/",,,,"cs.CV cs.GR cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We propose an analysis-by-synthesis method for fast multi-view 3D
reconstruction of opaque objects with arbitrary materials and illumination.
State-of-the-art methods use both neural surface representations and neural
rendering. While flexible, neural surface representations are a significant
bottleneck in optimization runtime. Instead, we represent surfaces as triangle
meshes and build a differentiable rendering pipeline around triangle
rasterization and neural shading. The renderer is used in a gradient descent
optimization where both a triangle mesh and a neural shader are jointly
optimized to reproduce the multi-view images. We evaluate our method on a
public 3D reconstruction dataset and show that it can match the reconstruction
accuracy of traditional baselines and neural approaches while surpassing them
in optimization runtime. Additionally, we investigate the shader and find that
it learns an interpretable representation of appearance, enabling applications
such as 3D material editing.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:29:46 GMT""}]","2022-12-09"
"2212.04387","Charles Fancher","C. T. Fancher, K. Nicolich, K. Backes, N. Malvania, K. Cox, D. H.
  Meyer, P. D. Kunz, J. C. Hill, W. Holland, and B. L. Schmittberger Marlow","A self-locking Rydberg atom electric field sensor","6 pages, 5 figures",,"10.1063/5.0137127",,"physics.atom-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  A crucial step towards enabling real-world applications for quantum sensing
devices such as Rydberg atom electric field sensors is reducing their size,
weight, power, and cost (SWaP-C) requirements without significantly reducing
performance. Laser frequency stabilization is a key part of many quantum
sensing devices and, when used for exciting non-ground state atomic
transitions, is currently limited to techniques that require either large
SWaP-C optical cavities and electronics or use significant optical power solely
for frequency stabilization. Here we describe a laser frequency stabilization
technique for exciting non-ground state atomic transitions that solves these
challenges and requires only a small amount of additional electronics. We
describe the operation, capabilities, and limitations of this frequency
stabilization technique and quantitatively characterize measure its
performance. We show experimentally that Rydberg electric field sensors using
this technique are capable of data collection while sacrificing only 0.1% of
available bandwidth for frequency stabilization of noise up to 900 Hz.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:30:54 GMT""}]","2023-03-08"
"2212.04388","Yuhui Su","Yuhui Su, Chunyang Chen, Junjie Wang, Zhe Liu, Dandan Wang, Shoubin Li
  and Qing Wang","The Metamorphosis: Automatic Detection of Scaling Issues for Mobile Apps",,,"10.1145/3551349.3556935",,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As the bridge between users and software, Graphical User Interface (GUI) is
critical to the app accessibility. Scaling up the font or display size of GUI
can help improve the visual impact, readability, and usability of an app, and
is frequently used by the elderly and people with vision impairment. Yet this
can easily lead to scaling issues such as text truncation, component overlap,
which negatively influence the acquirement of the right information and the
fluent usage of the app. Previous techniques for UI display issue detection and
cross-platform inconsistency detection cannot work well for these scaling
issues. In this paper, we propose an automated method, dVermin, for scaling
issue detection, through detecting the inconsistency of a view under the
default and a larger display scale. The evaluation result shows that dVermin
achieves 97% precision and 97% recall in issue page detection, and 84%
precision and 91% recall for issue view detection, outperforming two
state-of-the-art baselines by a large margin. We also evaluate dVermin with
popular Android apps on F-droid, and successfully uncover 21
previously-undetected scaling issues with 20 of them being confirmed/fixed.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:31:30 GMT""}]","2022-12-09"
"2212.04389","Boris Zelener","B. B. Zelener (1), E. V. Vilshanskaya (1), N. V. Morozov (1), S. A.
  Saakyan (1), A. A. Bobrov (1), B. V. Zelener (1) ((1) Joint Institute for
  High Temperatures Russian Academy of Sciences, Moscow, Russia)","Steady-State Ultracold Plasma",,,,,"physics.plasm-ph physics.optics","http://creativecommons.org/licenses/by/4.0/","  A strongly coupled ultracold plasma can be used as an excellent test platform
for studying many-body interactions associated with various plasma phenomena.
In this paper we discuss an approach that makes possible creation of the
steady-state ultracold plasma having various densities and temperatures by
means of continuous two-step optical excitation of calcium atoms in the MOT.
The parameters of the plasma are studied using laser-induced fluorescence of
calcium ions. The experimental results are well described by a simple
theoretical model involving equilibration of the continuous source of charged
particles by the hydrodynamical ion outflux and three-body recombination. The
strongly coupled plasma with the peak ion density of $6\cdot10^5$ cm$^{-3}$ and
the minimum electron temperature near 2 K has been prepared. Our steady-state
approach in combination with the strong magnetic confinement of the plasma will
make it possible to reach extremely strong coupling in such system.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:36:42 GMT""}]","2022-12-09"
"2212.04390","Martin Jutzi","Martin Jutzi, Sabina D. Raducan, Yun Zhang, Patrick Michel, Masahiko
  Arakawa","Constraining surface properties of asteroid (162173) Ryugu from
  numerical simulations of Hayabusa2 mission impact experiment",,"Nature Communications, Volume 13, Article number: 7134 (2022)","10.1038/s41467-022-34540-x",,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  The Hayabusa2 mission impact experiment on asteroid Ryugu created an
unexpectedly large crater. The associated regime of low-gravity, low-strength
cratering remained largely unexplored so far, because these impact conditions
cannot be re-created in laboratory experiments on Earth. Here we show that the
target cohesion may be very low and the impact probably occurred in the
transitional cratering regime, between strength and gravity. For such
conditions, our numerical simulations are able to reproduce the outcome of the
impact on Ryugu, including the effects of boulders originally located near the
impact point. Consistent with most recent analysis of Ryugu and Bennu,
cratering scaling-laws derived from our results suggest that surfaces of small
asteroids must be very young. However, our results also show that the cratering
efficiency can be strongly affected by the presence of a very small amount of
cohesion. Consequently, the varying ages of different geological surface units
on Ryugu may be due to the influence of cohesion.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:38:10 GMT""}]","2022-12-09"
"2212.04391","Pieter Pas","Pieter Pas, Andreas Themelis, Panagiotis Patrinos","Gauss-Newton meets PANOC: A fast and globally convergent algorithm for
  nonlinear optimal control","Submitted to the 2023 IFAC World Congress, Yokohama",,,,"math.OC cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  PANOC is an algorithm for nonconvex optimization that has recently gained
popularity in real-time control applications due to its fast, global
convergence. The present work proposes a variant of PANOC that makes use of
Gauss-Newton directions to accelerate the method. Furthermore, we show that
when applied to optimal control problems, the computation of this Gauss-Newton
step can be cast as a linear quadratic regulator (LQR) problem, allowing for an
efficient solution through the Riccati recursion. Finally, we demonstrate that
the proposed algorithm is more than twice as fast as the traditional L-BFGS
variant of PANOC when applied to an optimal control benchmark problem, and that
the performance scales favorably with increasing horizon length.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:41:34 GMT""}]","2022-12-09"
"2212.04392","Corentin Le Bihan","Corentin Le Bihan","Long time validity of the linearized Boltzmann equation for hard
  spheres: a proof without billiard theory","55 pages",,,,"math.AP math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  We study space-time fluctuations of a hard sphere system at thermal
equilibrium, and prove that the covariance converges to the solution of a
linearized Boltzmann equation in the low density limit, globally in time. This
result has been obtained previously in [7], by using uniform bounds on the
number of recollisions of dispersing systems of hard spheres (as provided for
instance in [9]). We present a self-contained proof with substantial
differences, which does not use this geometric result. This can be regarded as
the first step of a program aiming to derive the fluctuation theory of the
rarefied gas, for interaction potentials different from hard spheres.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:42:32 GMT""}]","2022-12-09"
"2212.04393","Pia Mareen Bredt","Pia Mareen Bredt","Automated NLO Electroweak Corrections to Processes at Hadron and Lepton
  Colliders","205 pages, 44 figures",,"10.3204/PUBDB-2022-07422","DESY-THESIS-2022-026","hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  The aim of this thesis is the completion of the NLO automated framework of
the MC program WHIZARD, accounting for NLO corrections in the full SM for cross
sections and distributions of processes at hadron and lepton colliders.
Specifically, it builds on the implemented FKS subtraction scheme for NLO QCD
calculations, and extends it to automated NLO EW and QCD-EW mixed corrections.
To that end, the implemented FKS scheme is generalised to systematically
subtract QED and QCD infrared (IR) divergences in mixed coupling expansions.
The automated computation of NLO contributions is validated for a set of
benchmark processes at the LHC, including e.~g. $t\bar{t}~(+H/W/Z)$ production.
Cross-checks for $e^+e^-$ processes likewise show that WHIZARD can be used for
predictions at lepton colliders including fixed $\mathcal{O}(\alpha)$
corrections. This framework is applied to the study of NLO EW cross sections
and differential distributions for multi-boson processes at a future multi-TeV
muon collider. For some high-energy lepton-collider setups, tiny initial-state
masses jeopardise the reliability of fixed-order expansions of observables in
QED perturbation theory. In order to recover meaningful predictions for NLO EW
observables, QED parton-distribution functions (PDFs) must be applied
guaranteeing a universal treatment of collinear ISR effects. This however
causes computational challenges for MC integration measures. Methods to cope
with these difficulties are presented in this thesis. With the automation of
NLO EW corrections for hadron and lepton collision processes, WHIZARD offers a
powerful tool for EW precision studies at current and future colliders and
provides the desired accuracy level of predictions for new physics searches.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:48:43 GMT""}]","2023-01-05"
"2212.04394","Nicole B\""auerle","Nicole B\""auerle and An Chen","Optimal investment under partial observations and robust VaR-type
  constraint",,,,,"q-fin.RM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The present paper extends the literature on utility maximization by combining
the framework of partial information and (robust) regulatory constraints.
Partial information is characterized by the fact that the stock price itself is
observable to the optimizing financial institution, but the outcome of the
market price of risk $\theta$ is unknown to the institution. The regulator
builds the same or a different belief about the market price of risk as the
financial institution. The solution to our optimization problem takes the same
form as in the full information case: the optimal wealth can be expressed as a
decreasing function of the state price density, and the regulatory threshold is
ensured in the intermediate economic states. The main difference lies in the
terminal state price density depending on the entire evolution of the estimated
market price of risk $\hat{\theta}(s)$. The subjective evaluation of the
regulatory constraint influences the width of the ensured region.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:52:59 GMT""}]","2022-12-09"
"2212.04395","Rudi Rahn","Simon Cal\`o, Coenraad Marinissen, Rudi Rahn","Discrete symmetries and Efficient Counting of Operators","19 pages, no figures",,,"Nikhef 2022-018","hep-ph hep-th","http://creativecommons.org/licenses/by/4.0/","  We present DECO (""Discrete and Efficient Counting of Operators""), an
implementation of the Hilbert Series to enumerate subleading operator bases for
SMEFT-like EFTs with symmetry groups as typically found in flavour and BSM
physics. DECO can accommodate EFTs with arbitrary numbers and combinations of
the SM gauge groups, as well as the discrete groups S4, A4, and Zn, and U(1)
groups with residual global charge (and these groups' most important
representations). The program is highly modular and can easily be extended to
additional groups and/or representations. We demonstrate the design cases for
DECO by using it to cross-check subleading operator bases of EFTs in the
literature, which allows us to identify a missing operator in a widely used
model for the neutrino masses and discuss said operator's impact.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:53:21 GMT""}]","2022-12-09"
"2212.04396","Dawei Sun","Dawei Sun and Minhyun Cho and Inseok Hwang","On Attack Detection and Identification for the Cyber-Physical System
  using Lifted System Model","It is the preprint of a paper submitted to Automatica",,,,"eess.SY cs.SY math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the safety and security issues related to cyber-physical systems
with potentially multi-rate, delayed, and nonuniformly sampled measurements, we
investigate the attack detection and identification using the lifted system
model in this paper. Attack detectability and identifiability based on the
lifted system model are formally defined and rigorously characterized in a
novel approach. The method of checking detectability is discussed, and a
residual design problem for attack detection is formulated in a general way.
For attack identification, we define and characterize it by generalizing the
concept of mode discernibility for switched systems, and a method for
identifying the attack is discussed based on the theoretical analysis. An
illustrative example of an unmanned aircraft system (UAS) is provided to
validate the main results.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:54:32 GMT""}]","2022-12-09"
"2212.04397","Peter Keevash","Peter Keevash","The optimal edge-colouring threshold","21 pages",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consider any dense r-regular quasirandom bipartite graph H with parts of size
n and fix a set of r colours. Let L be a random list assignment where each
colour is available for each edge of H with probability p. We show that the
threshold probability for H to have a proper L-edge-colouring is p of order
(log n)/n. This answers a question of Kang, Kelly, K\""uhn, Methuku and Osthus.
We thus obtain the same threshold for Steiner Triple Systems and Latin squares;
the latter answers a question of Johanssen from 2006.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:55:01 GMT""}]","2022-12-09"
"2212.04398","Ahmad Fahim Habib","A. F. Habib, G.G. Manahan, P. Scherkl, T. Heinemann, A. Sutherland, R.
  Altuiri, B. M. Alotaibi, M. Litos, J. Cary, T. Raubenheimer, E. Hemsing, M.
  Hogan, J.B. Rosenzweig, P. H. Williams, B. W. J. McNeil and B. Hidding","Attosecond-Angstrom free-electron-laser towards the cold beam limit","17 pages, 4 figures",,"10.1038/s41467-023-36592-z",,"physics.acc-ph physics.optics physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  Electron beam quality is paramount for X-ray pulse production in
free-electron-lasers (FELs). State-of-the-art linear accelerators (linacs) can
deliver multi-GeV electron beams with sufficient quality for hard X-ray-FELs,
albeit requiring km-scale setups, whereas plasma-based accelerators can produce
multi-GeV electron beams on metre-scale distances, and begin to reach beam
qualities sufficient for EUV FELs. We show, that electron beams from plasma
photocathodes many orders of magnitude brighter than state-of-the-art can be
generated in plasma wakefield accelerators (PWFA), and then extracted,
captured, transported and injected into undulators without quality loss. These
ultrabright, sub-femtosecond electron beams can drive hard X-FELs near the cold
beam limit to generate coherent X-ray pulses of attosecond-Angstrom class,
reaching saturation after only 10 metres of undulator. This plasma-X-FEL opens
pathways for novel photon science capabilities, such as unperturbed observation
of electronic motion inside atoms at their natural time and length scale, and
towards higher photon energies.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:56:08 GMT""}]","2023-03-22"
"2212.04399","R\'egine Marchand","R\'egine Marchand, Ir\`ene Marcovici, Pierrick Siest","Corner percolation with preferential directions","12 pages, 7 figures",,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  Corner percolation is a dependent bond percolation model on Z^2 introduced by
B\'alint T\'oth, in which each vertex has exactly two incident edges,
perpendicular to each other. G\'abor Pete has proven in 2008 that under the
maximal entropy probability measure, all connected components are finite cycles
almost surely. We consider here a regime where West and North directions are
preferred with probability p and q respectively, with (p,q) different from
(1/2,1/2). We prove that there exists almost surely an infinite number of
infinite connected components, which are in fact infinite paths. Furthermore,
they all have the same asymptotic slope (2q-1)/(1-2p).
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:56:26 GMT""}]","2022-12-09"
"2212.04400","Alice Corbella Dr","Alice Corbella, Trevelyan J. McKinley, Paul J. Birrell, Anne M.
  Presanis, Simon E. F. Spencer, Gareth O. Roberts, Daniela De Angelis","The Lifebelt Particle Filter for robust estimation from low-valued count
  data",,,,,"stat.CO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Particle filtering methods are well developed for continuous state-space
models. When dealing with discrete spaces on bounded domains, particle
filtering methods can still be applied to sample from and marginalise over the
unknown hidden states. Nevertheless, problems such as particle degradation can
arise in this context and be even more severe than they are within the
continuous-state domain: proposed particles can easily be incompatible with the
data and the discrete system could often result in all particles having weights
of zero. However, if the boundaries of the discrete hidden space are known,
then these could be used to prevent particle collapse. In this paper we
introduce the Lifebelt Particle Filter (LBPF), a novel method for robust
likelihood estimation when low-valued count data arise. The LBPF combines a
standard particle filter with one (or more) \textit{lifebelt particles} which,
by construction, will tend not to be incompatible with the data. A mixture of
resampled and non-resampled particles allows for the preservation of the
lifebelt particle, which, together with the remaining particle swarm, provides
samples from the filtering distribution, and can be used to generate estimates
of the likelihood. The LBPF can be used within a pseudo-marginal scheme to draw
inference on static parameters, $ \boldsymbol{\theta} $, governing a discrete
state-space model with low-valued counts. We present here the applied case
estimating a parameter governing probabilities and timings of deaths and
recoveries of hospitalised patients during an epidemic.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:57:52 GMT""}]","2022-12-09"
"2212.04401","Ida Momennejad","Ida Momennejad","A Rubric for Human-like Agents and NeuroAI",,,,,"cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Researchers across cognitive, neuro-, and computer sciences increasingly
reference human-like artificial intelligence and neuroAI. However, the scope
and use of the terms are often inconsistent. Contributed research ranges widely
from mimicking behaviour, to testing machine learning methods as neurally
plausible hypotheses at the cellular or functional levels, or solving
engineering problems. However, it cannot be assumed nor expected that progress
on one of these three goals will automatically translate to progress in others.
Here a simple rubric is proposed to clarify the scope of individual
contributions, grounded in their commitments to human-like behaviour, neural
plausibility, or benchmark/engineering goals. This is clarified using examples
of weak and strong neuroAI and human-like agents, and discussing the
generative, corroborate, and corrective ways in which the three dimensions
interact with one another. The author maintains that future progress in
artificial intelligence will need strong interactions across the disciplines,
with iterative feedback loops and meticulous validity tests, leading to both
known and yet-unknown advances that may span decades to come.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:59:40 GMT""}]","2022-12-09"
"2212.04402","Victor Helson","Victor Helson, Timo Zwettler, Farokh Mivehvar, Elvia Colella, Kevin
  Roux, Hideki Konishi, Helmut Ritsch and Jean-Philippe Brantut","Density-wave ordering in a unitary Fermi gas with photon-mediated
  interactions","11 pages, 7 figures",,,,"cond-mat.quant-gas physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A density wave (DW) is a fundamental type of long-range order in quantum
matter tied to self-organization into a crystalline structure. The interplay of
DW order with superfluidity can lead to complex scenarios that pose a great
challenge to theoretical analysis. In the last decades, tunable quantum Fermi
gases have served as model systems for exploring the physics of strongly
interacting fermions, including most notably magnetic ordering, pairing and
superfluidity, and the crossover from a Bardeen-Cooper-Schrieffer (BCS)
superfluid to a Bose-Einstein condensate (BEC). Here, we realize a Fermi gas
featuring both strong, tunable contact interactions and photon-mediated,
spatially structured long-range interactions in a transversely driven
high-finesse optical cavity. Above a critical long-range interaction strength
DW order is stabilized in the system, which we identify via its superradiant
light scattering properties. We quantitatively measure the variation of the
onset of DW order as the contact interaction is varied across the BCS-BEC
crossover, in qualitative agreement with a mean-field theory. The atomic DW
susceptibility varies over an order of magnitude upon tuning the strength and
the sign of the long-range interactions below the self-ordering threshold,
demonstrating independent and simultaneous control over the contact and
long-range interactions. Therefore, our experimental setup provides a fully
tunable and microscopically controllable platform for the experimental study of
the interplay of superfluidity and DW order.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:02:06 GMT""}]","2022-12-09"
"2212.04403","Lorenzo Loconte","Lorenzo Loconte and Gennaro Gala","DeeProb-kit: a Python Library for Deep Probabilistic Modelling",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  DeeProb-kit is a unified library written in Python consisting of a collection
of deep probabilistic models (DPMs) that are tractable and exact
representations for the modelled probability distributions. The availability of
a representative selection of DPMs in a single library makes it possible to
combine them in a straightforward manner, a common practice in deep learning
research nowadays. In addition, it includes efficiently implemented learning
techniques, inference routines, statistical algorithms, and provides
high-quality fully-documented APIs. The development of DeeProb-kit will help
the community to accelerate research on DPMs as well as to standardise their
evaluation and better understand how they are related based on their
expressivity.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:02:16 GMT""}]","2022-12-09"
"2212.04404","Nikolay Chtchelkatchev","Elizaveta A. Batalova, Larisa V. Kamaeva and Nikolay M. Chtchelkatchev","The Effect of short-range order on the viscosity and crystallization of
  Al-Mg melts","8 pages, 4 figures",,,,"cond-mat.mtrl-sci physics.chem-ph physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, using the methods of viscosimetry and thermal analysis, the
concentration changes in the values of the supercooling viscosity of Al-Mg
melts with Mg content from 2.5 to 95 at.% are studied. It is shown that the
temperature dependences of viscosity are well described by an exponential
dependence. The concentration dependence of viscosity is not monotonous and
reflects a change in the chemical short-range order in the liquid phase. The
concentration dependence of supercooling of Al-Mg melts is determined by the
type of solid phase formed during solidification, and also reflects the most
significant changes in the chemical short-range order in the liquid phase at 20
and 80 at.% Mg. Al-Mg alloys in the concentration ranges: 0-10, 40-50 and
90-100 at.% Mg are prone to non-equilibrium crystallization, the formation of
quasi-eutectics and solidification without intermediate intermetallic phases.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:02:55 GMT""}]","2022-12-09"
"2212.04405","Antonio Stanziola","Antonio Stanziola, Jos\'e A. Pineda-Pardo and Bradley Treeby","Transcranial ultrasound simulation with uncertainty estimation","6 pages, 5 figures",,,,"physics.med-ph physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transcranial ultrasound simulations are increasingly used to predict in situ
exposure parameters for ultrasound therapies in the brain. However, there can
be considerable uncertainty in estimating the acoustic medium properties of the
skull and brain from computed tomography (CT) images. Here, we show how the
resulting uncertainty in the simulated acoustic field can be predicted in a
computationally efficient way using linear uncertainty propagation. Results for
a representative transcranial simulation using a focused bowl transducer at 500
kHz show good agreement with unbiased uncertainty estimates obtained using
Monte Carlo.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:03:12 GMT""}]","2022-12-09"
"2212.04408","Xuancheng Ren","Jinze Bai, Rui Men, Hao Yang, Xuancheng Ren, Kai Dang, Yichang Zhang,
  Xiaohuan Zhou, Peng Wang, Sinan Tan, An Yang, Zeyu Cui, Yu Han, Shuai Bai,
  Wenbin Ge, Jianxin Ma, Junyang Lin, Jingren Zhou, Chang Zhou","OFASys: A Multi-Modal Multi-Task Learning System for Building Generalist
  Models",,,,,"cs.CV cs.AI cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generalist models, which are capable of performing diverse multi-modal tasks
in a task-agnostic way within a single model, have been explored recently.
Being, hopefully, an alternative to approaching general-purpose AI, existing
generalist models are still at an early stage, where modality and task coverage
is limited. To empower multi-modal task-scaling and speed up this line of
research, we release a generalist model learning system, OFASys, built on top
of a declarative task interface named multi-modal instruction. At the core of
OFASys is the idea of decoupling multi-modal task representations from the
underlying model implementations. In OFASys, a task involving multiple
modalities can be defined declaratively even with just a single line of code.
The system automatically generates task plans from such instructions for
training and inference. It also facilitates multi-task training for diverse
multi-modal workloads. As a starting point, we provide presets of 7 different
modalities and 23 highly-diverse example tasks in OFASys, with which we also
develop a first-in-kind, single model, OFA+, that can handle text, image,
speech, video, and motion data. The single OFA+ model achieves 95% performance
in average with only 16% parameters of 15 task-finetuned models, showcasing the
performance reliability of multi-modal task-scaling provided by OFASys.
Available at https://github.com/OFA-Sys/OFASys
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:07:09 GMT""}]","2022-12-09"
"2212.04411","Ronan Hix","Ronan Hix, Chong-Chong He, Massimo Ricotti (University of Maryland)","Bimodal Star Formation in Simulations of Strongly Magnetized Giant
  Molecular Clouds","14 Pages, 10 Figures, Submitted to MNRAS",,"10.1093/mnras/stad1346",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the results of a set of radiation magnetohydrodynamic simulations
of turbulent molecular clouds in which we vary the initial strength of the
magnetic field within a range ($1 \lesssim \mu \lesssim 5$) consistent with
observations of local giant molecular clouds (GMCs). We find that as we
increase the strength of the magnetic field, star formation transitions from
unimodal (the baseline case, $\mu=5$, with a single burst of star formation and
Salpeter IMF) to bimodal. This effect is clearest in the most strongly
magnetized GMCs ($\mu=1$): a first burst of star formation with duration,
intensity and IMF comparable to the baseline case, is followed by a second star
formation episode in which only low-mass stars are formed. Overall, due to the
second burst of star formation, the strongly magnetized case results in a
longer star formation period and a higher efficiency of star formation. The
second burst is produced by gas that is not expelled by radiative feedback,
instead remaining trapped in the GMC by the large-scale B-field, producing a
nearly one-dimensional flow of gas along the field lines. The trapped gas has a
turbulent and magnetic topology that differs from that of the first phase and
strongly suppresses gas accretion onto protostellar cores, reducing their
masses. We speculate that this star formation bimodality may be an important
ingredient to understand the origin of multiple stellar populations observed in
massive globular clusters.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:10:15 GMT""}]","2023-05-17"
"2212.04412","Sachit Menon","Sachit Menon, Ishaan Preetam Chandratreya, Carl Vondrick","Task Bias in Vision-Language Models","First two authors contributed equally",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Incidental supervision from language has become a popular approach for
learning generic visual representations that can be prompted to perform many
recognition tasks in computer vision. We conduct an in-depth exploration of the
CLIP model and show that its visual representation is often strongly biased
towards solving some tasks more than others. Moreover, which task the
representation will be biased towards is unpredictable, with little consistency
across images. To resolve this task bias, we show how to learn a visual prompt
that guides the representation towards features relevant to their task of
interest. Our results show that these visual prompts can be independent of the
input image and still effectively provide a conditioning mechanism to steer
visual representations towards the desired task.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:10:31 GMT""}]","2022-12-09"
"2212.04413","Xue Zhang","Xue Zhang, Abhishek Banerjee, Mahapan Leyser, Gilad Perez, Stephan
  Schiller, Dmitry Budker, Dionysios Antypas","Search for ultralight dark matter with spectroscopy of radio-frequency
  atomic transitions",,,,,"physics.atom-ph hep-ph","http://creativecommons.org/licenses/by/4.0/","  The effects of scalar and pseudoscalar ultralight bosonic dark matter (UBDM)
were searched for by comparing the frequency of a quartz oscillator to that of
a hyperfine-structure transition in $^{87}$Rb, and an electronic transition in
$^{164}$Dy. We constrain linear interactions between a scalar UBDM field and
Standard-Model (SM) fields for an underlying UBDM particle mass in the range
$1\times10^{-17}-8.3\times10^{-13} $ eV and quadratic interactions between a
pseudoscalar UBDM field and SM fields in the range $5\times10^{-18}-
4.1\times10^{-13} $ eV. Within regions of the respective ranges, our
constraints on linear interactions significantly improve on results from
previous, direct searches for oscillations in atomic parameters, while
constraints on quadratic interactions surpass limits imposed by such direct
searches as well as by astrophysical observations.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:10:39 GMT""}]","2022-12-12"
"2212.04414","Marius Adrian Oancea","Marius A. Oancea, Achal Kumar","Semiclassical analysis of Dirac fields on curved spacetime",,"Phys. Rev. D 107, 044029 (2023)","10.1103/PhysRevD.107.044029",,"gr-qc hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a semiclassical analysis for Dirac fields on an arbitrary
spacetime background and in the presence of a fixed electromagnetic field. Our
approach is based on a Wentzel-Kramers-Brillouin approximation, and the results
are analyzed at leading and next-to-leading order in the small expansion
parameter $\hbar$. Taking into account the spin-orbit coupling between the
internal and external degrees of freedom of wave packets, we derive effective
ray equations with spin-dependent terms. These equations describe the
gravitational spin Hall effect of localized Dirac wave packets. We treat both
massive and massless Dirac fields and show how a covariantly defined Berry
connection and the associated Berry curvature govern the semiclassical
dynamics. The gravitational spin Hall equations are shown to be particular
cases of the Mathisson-Papapetrou equations for spinning objects.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:12:00 GMT""},{""version"":""v2"",""created"":""Tue, 14 Feb 2023 19:26:26 GMT""}]","2023-02-16"
"2212.04415","Mark Hobbs","Mark Hobbs, Hussein Rappel, Tim Dodwell","A probabilistic peridynamic framework with an application to the study
  of the statistical size effect",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mathematical models are essential for understanding and making predictions
about systems arising in nature and engineering. Yet, mathematical models are a
simplification of true phenomena, thus making predictions subject to
uncertainty. Hence, the ability to quantify uncertainties is essential to any
modelling framework, enabling the user to assess the importance of certain
parameters on quantities of interest and have control over the quality of the
model output by providing a rigorous understanding of uncertainty. Peridynamic
models are a particular class of mathematical models that have proven to be
remarkably accurate and robust for a large class of material failure problems.
However, the high computational expense of peridynamic models remains a major
limitation, hindering outer-loop applications that require a large number of
simulations, for example, uncertainty quantification. This contribution
provides a framework to make such computations feasible. By employing a
Multilevel Monte Carlo (MLMC) framework, where the majority of simulations are
performed using a coarse mesh, and performing relatively few simulations using
a fine mesh, a significant reduction in computational cost can be realised, and
statistics of structural failure can be estimated. The results show a speed-up
factor of 16x over a standard Monte Carlo estimator, enabling the forward
propagation of uncertain parameters in a computationally expensive peridynamic
model. Furthermore, the multilevel method provides an estimate of both the
discretisation error and sampling error, thus improving the confidence in
numerical predictions. The performance of the approach is demonstrated through
an examination of the statistical size effect in quasi-brittle materials.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:15:04 GMT""},{""version"":""v2"",""created"":""Thu, 2 Mar 2023 15:18:49 GMT""}]","2023-03-03"
"2212.04416","Mohammad Abbasi Eskandari","M. Abbasi Eskandari, S. Ghotb and P. Fournier","Impact of a ferromagnetic insulating barrier in magnetic tunnel
  junctions",,,,,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate spin-dependent conductance across a magnetic tunnel junction
(MTJ) including a ferromagnetic insulating barrier. The MTJ consists of two
half-metallic ferromagnetic La2/3Sr1/3MnO3 (LSMO) manganites as electrodes and
La2NiMnO6 (LNMO) double perovskite as a ferromagnetic insulating barrier. The
resistance of the junction is strongly dependent not only on the orientation of
the magnetic moments in LSMO electrodes, but also on the direction of the
magnetization of the LNMO barrier with respect to that of LSMO. The ratio of
tunnel magnetoresistance reaches a maximum value of 24% at 10 K, and it
decreases with temperature until it completely disappears above the critical
temperature of LNMO at 280 K. The tunneling process is described using a
mechanism which involves both empty and filled eg states of the LNMO barrier
acting as a spin-filter. A magnetic insulating barrier is an interesting path
for achieving room temperature magnetoresistance in oxide-based
heterostructures.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:15:14 GMT""}]","2022-12-09"
"2212.04417","Christoph Konrad","Christoph Konrad, Owe Philipsen, Jonas Scheunert","Mean field approximation for effective theories of lattice QCD","9 pages, 3 figures, contribution to the 39th International Symposium
  on Lattice Field Theory (LATTICE2022)",,,,"hep-lat hep-th","http://creativecommons.org/licenses/by-nc-nd/4.0/","  For the exploration of the phase diagram of QCD, effective Polyakov loop
theories derived from lattice QCD provide a valuable tool in the heavy quark
mass regime. In practice, the evaluation of these theories is complicated by
the appearance of long-range and multipoint interaction terms. On the other
hand, it is well known that for theories with such kind of interactions mean
field approximations can be expected to yield reliable results. Here, we apply
this framework to the critical endpoint of the deconfinement transition and
results are compared to the literature. This treatment can also be used to
investigate the phase diagram at non-zero baryon and isospin chemical
potential.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:17:14 GMT""}]","2022-12-09"
"2212.04418","Shengli Chen","Xu Wang, Sheng-Li Chen, Yan-Hui Han, and Younane Abousleiman","A Complete Graphical Solution for Undrained Cylindrical Cavity Expansion
  in K_0-Consolidated Mohr-Coulomb Soil","37 pages with 7 figures and 1 table",,,,"physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper develops a general and complete solution for the undrained
cylindrical cavity expansion problem in non-associated Mohr-Coulomb soil under
non-hydrostatic initial stress field (i.e., arbitrary K_0 values of the earth
pressure coefficient), by expanding a unique and efficient graphical solution
procedure recently proposed by Chen & Wang in 2022 for the special in situ
stress case with K_0 = 1. The new generalized, graph-based theoretical
framework contains two essential components: the geometrical analysis to track
the stress path trajectory/evolution in different sectors of the deviatoric
plane; and a full Lagrangian formulation of both the constitutive relationship
and radial equilibrium equation to analytically determine the representative
soil particle responses at the cavity surface. It is interesting to find that
the cavity expansion deviatoric stress path is always composed of a series of
piecewise straight lines, for all different case scenarios of K_0 being
involved. The salient advantage/feature of the present general graphical
approach lies in that it can deduce the cavity expansion responses in full
closed form, nevertheless being free of the limitation of the intermediacy
assumption for the vertical stress and of the difficulty existing in the
traditional zoning method that involves cumbersome, sequential determination of
distinct Mohr-Coulomb plastic regions. The analytical closed-form solutions
developed herein can be regarded as a definitive one for the undrained cavity
expansion problem in classical Mohr-Coulomb materials without the
approximations and simplifications in previous solutions, and will be of great
value for the interpretation of pressuremeter tests in cohesive-frictional
soils.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:18:22 GMT""}]","2022-12-09"
"2212.04419","Conor Muldoon","Conor Muldoon, Levent G\""org\""u, John J. O'Sullivan, Wim G. Meijer,
  Gregory M. P. O'Hare","Mining Explainable Predictive Features for Water Quality Management",,,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  With water quality management processes, identifying and interpreting
relationships between features, such as location and weather variable tuples,
and water quality variables, such as levels of bacteria, is key to gaining
insights and identifying areas where interventions should be made. There is a
need for a search process to identify the locations and types of phenomena that
are influencing water quality and a need to explain how the quality is being
affected and which factors are most relevant. This paper addresses both of
these issues. A process is developed for collecting data for features that
represent a variety of variables over a spatial region and which are used for
training models and inference. An analysis of the performance of the features
is undertaken using the models and Shapley values. Shapley values originated in
cooperative game theory and can be used to aid in the interpretation of machine
learning results. Evaluations are performed using several machine learning
algorithms and water quality data from the Dublin Grand Canal basin.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:18:50 GMT""},{""version"":""v2"",""created"":""Fri, 9 Dec 2022 15:47:59 GMT""}]","2022-12-12"
"2212.04420","Hongwei Yi","Hongwei Yi, Hualin Liang, Yifei Liu, Qiong Cao, Yandong Wen, Timo
  Bolkart, Dacheng Tao, Michael J. Black","Generating Holistic 3D Human Motion from Speech","Project Webpage: https://talkshow.is.tue.mpg.de",,,,"cs.CV cs.GR","http://creativecommons.org/licenses/by/4.0/","  This work addresses the problem of generating 3D holistic body motions from
human speech. Given a speech recording, we synthesize sequences of 3D body
poses, hand gestures, and facial expressions that are realistic and diverse. To
achieve this, we first build a high-quality dataset of 3D holistic body meshes
with synchronous speech. We then define a novel speech-to-motion generation
framework in which the face, body, and hands are modeled separately. The
separated modeling stems from the fact that face articulation strongly
correlates with human speech, while body poses and hand gestures are less
correlated. Specifically, we employ an autoencoder for face motions, and a
compositional vector-quantized variational autoencoder (VQ-VAE) for the body
and hand motions. The compositional VQ-VAE is key to generating diverse
results. Additionally, we propose a cross-conditional autoregressive model that
generates body poses and hand gestures, leading to coherent and realistic
motions. Extensive experiments and user studies demonstrate that our proposed
approach achieves state-of-the-art performance both qualitatively and
quantitatively. Our novel dataset and code will be released for research
purposes at https://talkshow.is.tue.mpg.de.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:25:19 GMT""}]","2022-12-09"
"2212.04421","Kevin Smith","Kevin Smith","Implications of subconvexity bounds for the moments of zeta","17 pages",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  It is well-known that upper bounds for moments of the Riemann zeta function
$\zeta(s)$ have implications for subconvexity bounds. In this paper we explore
some implications in the opposite direction using functional analysis in the
right-half of the critical strip. The main results characterise potential
transitions in the behaviour of the moments.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:27:40 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 12:53:08 GMT""}]","2023-02-07"
"2212.04423","Gregory Fuchs","Qin Xu, Hil Fung Harry Cheung, Donley S. Cormode, Tharnier O. Puel,
  Huma Yusuf, Michael Chilcote, Michael E. Flatt\'e, Ezekiel Johnston-Halperin,
  and Gregory D. Fuchs","Strong photon-magnon coupling using a lithographically defined organic
  ferrimagnet","31 pages preprint format with supplementary materials",,,,"quant-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate a hybrid quantum system composed of superconducting resonator
photons and magnons hosted by the organic-based ferrimagnet vanadium
tetracyanoethylene (V[TCNE]$_x$). Our work is motivated by the challenge of
scalably integrating an arbitrarily-shaped, low-damping magnetic system with
planar superconducting circuits, thus enabling a host of quantum magnonic
circuit designs that were previously inaccessible. For example, by leveraging
the inherent properties of magnons, one can enable nonreciprocal
magnon-mediated quantum devices that use magnon propagation rather than
electrical current. We take advantage of the properties of V[TCNE]$_x$, which
has ultra-low intrinsic damping, can be grown at low processing temperatures on
arbitrary substrates, and can be patterned via electron beam lithography. We
demonstrate the scalable, lithographically integrated fabrication of hybrid
quantum magnonic devices consisting of a thin-film superconducting resonator
coupled to a low-damping, thin-film V[TCNE]$_x$ microstructure. Our devices
operate in the strong coupling regime, with a cooperativity as high as 1181(44)
at T$\sim$0.4 K, suitable for scalable quantum circuit integration. This work
paves the way for the exploration of high-cooperativity hybrid magnonic quantum
devices in which magnonic circuits can be designed and fabricated as easily as
electrical wires.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:31:47 GMT""}]","2022-12-09"
"2212.04424","Albert Bruch","Albert Bruch","TESS light curves of cataclysmic variables -- II: Superhumps in old
  novae and novalike variables",,,"10.1093/mnras/stac3493",,"astro-ph.SR astro-ph.HE","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Superhumps are among the abundant variable phenomena observed in the light
curves of cataclysmic variables (CVs). They come in two flavours as positive
and negative superhumps, distinguished by periods slightly longer or shorter,
respectively, than the orbital periods of these interacting binary systems.
Positive superhumps are ubiquitous in superoutbursting short period dwarf novae
of the SU~UMa type but are less common in longer period systems with accretion
disks in a permanent bright state such as novalike variables and most old
novae. Negative superhumps do not seem not to have a preference for a
particular type of CV. Here, I take advantage of the long high cadence light
curves provided by TESS for huge number of stars, selecting all old novae and
novalike variables with past reported superhumps for which TESS light curves
are available and have not yet been analysed in previous publications in order
to study their superhump behaviour. In combination with information taken from
the literature the results enable to compile the most complete census of
superhumps in these stars so far. As a corollary, for the eclipsing systems in
the present sample of objects eclipse epochs derived from the TESS light curves
and in some cases from archival light curves are listed and used to update
orbital ephemeris and to discuss period changes.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:33:02 GMT""}]","2022-12-28"
"2212.04425","Matthew Lorig","Matthew Lorig, Natchanon Suaysom","Explicit Caplet Implied Volatilities for Quadratic Term-Structure Models","22 pages, 4 figures. arXiv admin note: substantial text overlap with
  arXiv:2106.04518",,,,"q-fin.MF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We derive an explicit asymptotic approximation for implied volatilities of
caplets under the assumption that the short-rate is described by a generic
quadratic term-structure model. In addition to providing an asymptotic accuracy
result, we perform experiments in order to gauge the numerical accuracy of our
approximation.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:34:27 GMT""}]","2022-12-09"
"2212.04426","Ramanpreet Kaur","Ramanpreet Kaur","Baker Domain for a transcendental skew-product",,,,,"math.CV","http://creativecommons.org/licenses/by/4.0/","  In this note, we demonstrate the existence of a Baker domain of a
transcendental skew-product by constructing a domain that is shown to be
absorbing using plurisubharmonic method.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:37:57 GMT""},{""version"":""v2"",""created"":""Fri, 9 Dec 2022 18:46:47 GMT""}]","2022-12-12"
"2212.04427","Diego Rodriguez-Gomez","Guillermo Arias-Tamargo, Sergio Benvenuti, Diego Rodriguez-Gomez","Infrared phases of 3d massless CS-QCD and large $N_f$","27 pages plus appendices, 4 figures",,,,"hep-th cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We compute anomalous dimensions of quartic operators which are singlets under
the $\mathrm{U}(N_f)$ global symmetry in Yang-Mills theories with Chern-Simons
level $k$ in three dimensions coupled to $N_f$ Dirac fermions. In order to have
analytic control, we consider the regime $N_f\gg N_c\gg 1$, where the problem
is reduced to the study of a flavor-adjoint and a flavor-singlet bilinears
whose square give the quartic operators of interest. We provide evidence that
these operators hit marginality, signaling instabilities which, for
$\frac{2k}{N_f}<1$ suggest the spontaneous breaking of the global symmetry, and
no symmetry breaking otherwise. For $k=N_f/2-1$ (the value corresponding to the
domain walls of 4d QCD at $\theta=\pi$), the critical value $N_f^*$ is
tantalizingly close to the lower end of the conformal window of QCD$_4$,
suggesting a connection between conformal and global symmetry breaking in the
4d theory and in its domain walls. We also study, at $k=0$, other quartic
operators containing a singlet when branched under
$\mathrm{U}\left(\frac{N_f}{2}\right)\times
\mathrm{U}\left(\frac{N_f}{2}\right)$, finding that they hit marginality
precisely at the same point as their flavor-neutral cousins. Using the same
technology we study bosonic CS-QCD$_3$, finding no hint of symmetry breaking
where our analysis is applicable.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:39:03 GMT""}]","2022-12-09"
"2212.04428","Tomos Meredith","Tomos R. L. Meredith, Graham A. Wynn, Philip A. Evans","An analysis of the effect of data processing methods on magnetic
  propeller models in short GRBs","14 pages, accepted for publication in MNRAS",,"10.1093/mnras/stac3511",,"astro-ph.HE astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present analysis of observational data from the Swift Burst Analyser for a
sample of 15 short gamma-ray bursts with extended emission (SGRBEEs) which have
been processed such that error propagation from Swift's count-rate-to-flux
conversion factor is applied to the flux measurements. We apply this
propagation to data presented by the Burst Analyser at 0.3-10 keV and also at
15-50 keV, and identify clear differences in the morphologies of the
light-curves in the different bands. In performing this analysis with data
presented at both 0.3-10 keV, at 15-50 keV, and also at a combination of both
bands, we highlight the impact of extrapolating data from their native
bandpasses on the light-curve. We then test these data by fitting to them a
magnetar-powered model for SGRBEEs, and show that while the model is consistent
with the data in both bands, the model's derived physical parameters are
generally very loosely constrained when this error propagation is included and
are inconsistent across the two bands. In this way, we highlight the importance
of the Swift data processing methodology to the details of physical model fits
to SGRBEEs.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:42:24 GMT""}]","2022-12-14"
"2212.04429","Yen Chin Ong","Yen Chin Ong","An Effective Sign Switching Dark Energy: Lotka-Volterra Model of Two
  Interacting Fluids","v2: added more clarifications and references",,,,"gr-qc astro-ph.CO math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the recent attempts to address the Hubble and $S_8$ tensions is to
consider the Universe started out not as a de Sitter-like spacetime, but rather
anti-de Sitter-like. That is, the Universe underwent an ""AdS-to-dS"" transition
at some point. We study the possibility that there are two dark energy fluids,
one of which gave rise to the anti-de Sitter-like early Universe. The
interaction is modeled by the Lotka-Volterra equations, commonly used in
population biology. We consider ""competition"" models that are further
classified as ""unfair competition"" and ""fair competition"". The former involves
a quintessence in competition with a phantom, and the second involves two
phantom fluids. Surprisingly, even in the latter scenario it is possible for
the overall dark energy to cross the phantom divide. The latter model also
allows a constant $w$ ""AdS-to-dS"" transition, thus evading the theorem that
such a dark energy must possess a singular equation of state. We also consider
a ""conversion"" model in which a phantom fluid still manages to achieve
""AdS-to-dS"" transition even if it is being converted into a negative energy
density quintessence. In these models, the energy density of the late time
effective dark energy is related to the coefficient of the quadratic
self-interaction term of the fluids, which is analogous to the resource
capacity in population biology.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:44:12 GMT""},{""version"":""v2"",""created"":""Wed, 19 Apr 2023 13:13:28 GMT""}]","2023-04-20"
"2212.04430","Travis Whyte","Travis Whyte, Andreas Stathopoulos, Eloy Romero and Kostas Orginos","Optimizing Shift Selection in Multilevel Monte Carlo for Disconnected
  Diagrams in Lattice QCD",,,,,"hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The calculation of disconnected diagram contributions to physical signals is
a computationally expensive task in Lattice QCD. To extract the physical
signal, the trace of the inverse Lattice Dirac operator, a large sparse matrix,
must be stochastically estimated. Because the variance of the stochastic
estimator is typically large, variance reduction techniques must be employed.
Multilevel Monte Carlo (MLMC) methods reduce the variance of the trace
estimator by utilizing a telescoping sequence of estimators. Frequency
Splitting is one such method that uses a sequence of inverses of shifted
operators to estimate the trace of the inverse lattice Dirac operator, however
there is no a priori way to select the shifts that minimize the cost of the
multilevel trace estimation. In this article, we present a sampling and
interpolation scheme that is able to predict the variances associated with
Frequency Splitting under displacements of the underlying space time lattice.
The interpolation scheme is able to predict the variances to high accuracy and
therefore choose shifts that correspond to an approximate minimum of the cost
for the trace estimation. We show that Frequency Splitting with the chosen
shifts displays significant speedups over multigrid deflation, and that these
shifts can be used for multiple configurations within the same ensemble with no
penalty to performance.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:44:17 GMT""}]","2022-12-09"
"2212.04431","Serena Cenatiempo","Giulia Basti, Serena Cenatiempo, Alessandro Giuliani, Alessandro
  Olgiati, Giulio Pasqualetti, Benjamin Schlein","Upper bound for the ground state energy of a dilute Bose gas of hard
  spheres","15 pages, new version with improved rate",,,,"math-ph cond-mat.quant-gas math.AP math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a gas of bosons interacting through a hard-sphere potential with
radius $\frak{a}$ in the thermodynamic limit. We derive a simple upper bound
for the ground state energy per particle at low density. Our bound captures the
leading term $4\pi \rho \frak{a}$ and shows that corrections are smaller than
$C \rho \frak{a} (\rho \frak{a}^3)^{1/2}$, for a sufficiently large constant $C
> 0$. In combination with a known lower bound, our result implies that the
first sub-leading term to the ground state energy is, in fact, of the order
$\rho \frak{a} (\rho \frak{a}^3)^{1/2}$, in agreement with the Lee-Huang-Yang
prediction.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:44:24 GMT""},{""version"":""v2"",""created"":""Tue, 31 Jan 2023 14:41:37 GMT""}]","2023-02-01"
"2212.04432","Katharina Franke","Martina Trahms, Larissa Melischek, Jacob F. Steiner, Bharti Mahendru,
  Idan Tamir, Nils Bogdanoff, Olof Peters, Gael Reecht, Clemens B. Winkelmann,
  Felix von Oppen, Katharina J. Franke","Diode effect in Josephson junctions with a single magnetic atom",,"Nature 615, 628 (2023)","10.1038/s41586-023-05743-z",,"cond-mat.supr-con cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Current flow in electronic devices can be asymmetric with bias direction, a
phenomenon underlying the utility of diodes and known as non-reciprocal charge
transport. The promise of dissipationless electronics has recently stimulated
the quest for superconducting diodes, and non-reciprocal superconducting
devices have been realized in various non-centrosymmetric systems. Probing the
ultimate limits of miniaturization, we have created atomic-scale Pb--Pb
Josephson junctions in a scanning tunneling microscope. Pristine junctions
stabilized by a single Pb atom exhibit hysteretic behavior, confirming the high
quality of the junctions, but no asymmetry between the bias directions.
Non-reciprocal supercurrents emerge when inserting a single magnetic atom into
the junction, with the preferred direction depending on the atomic species.
Aided by theoretical modelling, we trace the non-reciprocity to quasiparticle
currents flowing via Yu-Shiba-Rusinov (YSR) states inside the superconducting
energy gap. Our results open new avenues for creating atomic-scale Josephson
diodes and tuning their properties through single-atom manipulation.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:48:28 GMT""}]","2023-04-19"
"2212.04433","Jan Trlifaj","Jan Trlifaj","Categoricity for transfinite extensions of modules",,,,,"math.LO math.RT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  For each deconstructible class of modules $\mathcal D$, we prove that the
categoricity of $\mathcal D$ in a big cardinal is equivalent to its
categoricity in a tail of cardinals. We also prove Shelah's Categoricity
Conjecture for $(\mathcal D, \prec)$, where $(\mathcal D, \prec)$ is any
abstract elementary class of roots of Ext.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:50:45 GMT""}]","2022-12-09"
"2212.04434","Sayak Bhattacharjee","Sayak Bhattacharjee, Divyam Jain","Rational distance sets on a parabola using Pythagorean triplets","18 pages, 1 figure, 3 tables",,,,"math.NT math.AG math.CO","http://creativecommons.org/licenses/by/4.0/","  We study $N$-point rational distance sets ($\textrm{RDS}(N)$) on the parabola
$y=x^2$. Previous approaches to the problem include efforts made using elliptic
curves and diophantine chains, with successful analysis for $N\leq 4$. We
extend the analysis for arbitrary $N$ by establishing a correspondence between
$\textrm{RDS}(N)$s and Pythagorean triplets. Our main result gives sufficient
and necessary conditions for the existence and nature of the $\textrm{RDS}(N)$s
for arbitrary $N$. Our approach also leads to an efficient computational
algorithm to construct new $\textrm{RDS}(N)$s, and we provide multiple new
examples of $\textrm{RDS}(N)$s for four and five points. The correspondence
with Pythagorean triplets also helps to study the density of the solutions and
we reproduce density results for $N=2$ and $3$.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:53:40 GMT""}]","2022-12-09"
"2212.04435","Prosenjit Das","Janaki Raman Babu, Prosenjit Das and Animesh Lahiri","Locally nilpotent derivations on $\mathbb{A}^2$-fibrations with
  $\mathbb{A}^1$-fibration kernels","14 pages",,,,"math.AC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this paper, we give a characterization of locally nilpotent derivations on
$\mathbb{A}^2$-fibrations over Noetherian domains containing $\mathbb{Q}$
having kernel isomorphic to an $\mathbb{A}^1$-fibration.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:54:45 GMT""},{""version"":""v2"",""created"":""Thu, 16 Feb 2023 06:18:53 GMT""},{""version"":""v3"",""created"":""Tue, 21 Feb 2023 11:40:22 GMT""}]","2023-02-22"
"2212.04436","Alessandro Lovato","Bryce Fore, Jane M. Kim, Giuseppe Carleo, Morten Hjorth-Jensen,
  Alessandro Lovato","Dilute neutron star matter from neural-network quantum states","6 pages, 3 figures",,,,"nucl-th cond-mat.dis-nn quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Low-density neutron matter is characterized by fascinating emergent quantum
phenomena, such as the formation of Cooper pairs and the onset of
superfluidity. We model this density regime by capitalizing on the expressivity
of the hidden-nucleon neural-network quantum states combined with variational
Monte Carlo and stochastic reconfiguration techniques. Our approach is
competitive with the auxiliary-field diffusion Monte Carlo method at a fraction
of the computational cost. Using a leading-order pionless effective field
theory Hamiltonian, we compute the energy per particle of infinite neutron
matter and compare it with those obtained from highly realistic interactions.
In addition, a comparison between the spin-singlet and triplet two-body
distribution functions indicates the emergence pairing in the $^1S_0$ channel.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:55:25 GMT""}]","2022-12-09"
"2212.04437","Benjamin Fele","Benjamin Fele and Ajda Lampe and Peter Peer and Vitomir \v{S}truc","C-VTON: Context-Driven Image-Based Virtual Try-On Network","Accepted to WACV 2022",,"10.1109/WACV51458.2022.00226",,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Image-based virtual try-on techniques have shown great promise for enhancing
the user-experience and improving customer satisfaction on fashion-oriented
e-commerce platforms. However, existing techniques are currently still limited
in the quality of the try-on results they are able to produce from input images
of diverse characteristics. In this work, we propose a Context-Driven Virtual
Try-On Network (C-VTON) that addresses these limitations and convincingly
transfers selected clothing items to the target subjects even under challenging
pose configurations and in the presence of self-occlusions. At the core of the
C-VTON pipeline are: (i) a geometric matching procedure that efficiently aligns
the target clothing with the pose of the person in the input images, and (ii) a
powerful image generator that utilizes various types of contextual information
when synthesizing the final try-on result. C-VTON is evaluated in rigorous
experiments on the VITON and MPV datasets and in comparison to state-of-the-art
techniques from the literature. Experimental results show that the proposed
approach is able to produce photo-realistic and visually convincing results and
significantly improves on the existing state-of-the-art.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:56:34 GMT""}]","2022-12-09"
"2212.04438","Md Ishaque Khan","Md Ishaque Khan and Rajib Saha","Detection of Dipole Modulation in CMB Temperature Anisotropy Maps from
  WMAP and Planck using Artificial Intelligence","21 pages, 16 figures","2023 ApJ 947 47","10.3847/1538-4357/acbfa9",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Breakdown of rotational invariance of the primordial power spectrum manifests
in the statistical anisotropy of the observed Cosmic Microwave Background (CMB)
radiation. Hemispherical power asymmetry in the CMB may be caused due to a
dipolar modulation, indicating the presence of a preferred direction.
Appropriately re-scaled local variance maps of the CMB temperature anisotropy
data effectively encapsulate this dipolar pattern. As a first-of-its-kind
method, we train Artificial Neural Networks (ANNs) with such local variances as
input features to distinguish statistically isotropic CMB maps from dipole
modulated ones. Our trained ANNs are able to predict components of the
amplitude times the unit vector of the preferred direction for mixed sets of
modulated and unmodulated maps, with goodness of fit ($R^2$) scores $>0.97$ for
full sky, and $>0.96$ for partial sky coverage. On all observed
foreground-cleaned CMB maps, the ANNs detect the dipolar modulation signal with
overall consistent values of amplitudes and directions. This detection is
significant at $97.21\%-99.38\%$ C.L. for all full sky maps, and at
$98.34\%-100\%$ C.L. for all partial sky maps. Robustness of the signal holds
across full and partial skies, various foreground cleaning methods, inpainting
algorithms, instruments and all the different periods of observation for Planck
and WMAP satellites. The significant and robust detection of the signal, in
addition to the consistency of values of amplitude and directions, as found
independent of any pre-existing methods, further mitigates the criticisms of
look-elsewhere effects and a posteriori inferences for the preferred dipole
direction in the CMB.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:58:14 GMT""},{""version"":""v2"",""created"":""Mon, 22 May 2023 09:44:25 GMT""}]","2023-05-23"
"2212.04439","Jeanne-Marie Musca","Jeanne-Marie Musca and Anders Miltner and Kathleen Fisher and David
  Walker","Technical Report: Match-reference regular expressions and lenses",,,,,"cs.PL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A lens is a single program that specifies two data transformations at once:
one transformation converts data from source format to target format and a
second transformation inverts the process. Over the past decade, researchers
have developed many different kinds of lenses with different properties. One
class of such languages operate over regular languages. In other words, these
lenses convert strings drawn from one regular language to strings drawn from
another regular language (and back again). In this paper, we define a more
powerful language of lenses, which we call match-reference lenses, that is
capable of translating between non-regular formats that contain repeated
substrings, which is a primitive form of dependency. To define the non-regular
formats themselves, we develop a new language, match-reference regular
expressions, which are regular expressions that can bind variables to
substrings and use those substrings repeatedly. These match-reference regular
expressions are closely related to the familiar ``back-references"" that can be
found in traditional regular expression packages, but are redesigned to adhere
to conventional programming language lexical scoping conventions and to
interact smoothly with lens language infrastructure. We define the semantics of
match-reference regular expressions and match-reference lenses. We also define
a new kind of automaton, the match-reference regex automaton system (MRRAS),
for deciding string membership in the language match-reference regular
expressions. We illustrate our definitions with a variety of examples.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:59:35 GMT""}]","2022-12-09"
"2212.04441","Geoffroi C\^ot\'e","Geoffroi C\^ot\'e, Fahim Mannan, Simon Thibault, Jean-Fran\c{c}ois
  Lalonde, Felix Heide","The Differentiable Lens: Compound Lens Search over Glass Surfaces and
  Materials for Object Detection","15 pages, 12 figures, to appear in CVPR 2023 proceedings, updated to
  reflect camera-ready submission",,,,"cs.CV physics.optics","http://creativecommons.org/licenses/by-sa/4.0/","  Most camera lens systems are designed in isolation, separately from
downstream computer vision methods. Recently, joint optimization approaches
that design lenses alongside other components of the image acquisition and
processing pipeline -- notably, downstream neural networks -- have achieved
improved imaging quality or better performance on vision tasks. However, these
existing methods optimize only a subset of lens parameters and cannot optimize
glass materials given their categorical nature. In this work, we develop a
differentiable spherical lens simulation model that accurately captures
geometrical aberrations. We propose an optimization strategy to address the
challenges of lens design -- notorious for non-convex loss function landscapes
and many manufacturing constraints -- that are exacerbated in joint
optimization tasks. Specifically, we introduce quantized continuous glass
variables to facilitate the optimization and selection of glass materials in an
end-to-end design context, and couple this with carefully designed constraints
to support manufacturability. In automotive object detection, we report
improved detection performance over existing designs even when simplifying
designs to two- or three-element lenses, despite significantly degrading the
image quality.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:01:17 GMT""},{""version"":""v2"",""created"":""Mon, 27 Mar 2023 18:16:47 GMT""}]","2023-03-29"
"2212.04442","Stephane Geudens","Stephane Geudens","On deformations of coisotropic submanifolds with fixed characteristic
  foliation","35 pages, minor corrections",,,,"math.SG","http://creativecommons.org/licenses/by/4.0/","  It is well-known that the deformation problem of a compact coisotropic
submanifold $C$ in a symplectic manifold is obstructed in general. We show that
it becomes unobstructed if one only allows coisotropic deformations whose
characteristic foliation is diffeomorphic to that of $C$. This extends an
unobstructedness result in the setting of integral coisotropic submanifolds due
to Ruan.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:05:15 GMT""},{""version"":""v2"",""created"":""Thu, 15 Dec 2022 14:48:53 GMT""}]","2022-12-16"
"2212.04443","Haizhao Yang","Qiyuan Pang and Haizhao Yang","A Distributed Block Chebyshev-Davidson Algorithm for Parallel Spectral
  Clustering",,,,,"cs.LG cs.DC cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a distributed Block Chebyshev-Davidson algorithm to solve
large-scale leading eigenvalue problems for spectral analysis in spectral
clustering. First, the efficiency of the Chebyshev-Davidson algorithm relies on
the prior knowledge of the eigenvalue spectrum, which could be expensive to
estimate. This issue can be lessened by the analytic spectrum estimation of the
Laplacian or normalized Laplacian matrices in spectral clustering, making the
proposed algorithm very efficient for spectral clustering. Second, to make the
proposed algorithm capable of analyzing big data, a distributed and parallel
version has been developed with attractive scalability. The speedup by parallel
computing is approximately equivalent to $\sqrt{p}$, where $p$ denotes the
number of processes. Numerical results will be provided to demonstrate its
efficiency and advantage over existing algorithms in both sequential and
parallel computing.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:06:13 GMT""}]","2022-12-09"
"2212.04444","Assaf Goldberger","Radel Ben Av, Xuemei Chen, Assaf Goldberger, Shujie Kang and Kasso A.
  Okoudjou","Phase transitions for frame potentials]{Phase transitions for the
  minimizers of the $p^{th}$ frame potentials in $\mathbb{R}^2$",,,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Given $N$ points $X=\{x_k\}_{k=1}^N$ on the unit circle in $\mathbb{R}^2$ and
a number $0\leq p \leq \infty$ we investigate the minimizers of the functional
$\sum_{k, \ell =1}^N |\langle x_k, x_\ell\rangle|^p$. While it is known that
each of these minimizers is a spanning set for $\mathbb{R}^2$, less is known
about their number as a function of $p$ and $N$ especially for relatively small
$p$. In this paper we show that there is unique minimum for this functional for
all $p\leq \log 3/\log 2$ and all odd $N\geq 3$. In addition, we present some
numerical results suggesting the emergence of a phase transition phenomenon for
these minimizers. More specifically, for $N\geq 3$ odd, there exists a sequence
of number of points $\log 3/\log 2=p_1< p_2< \cdots < p_N\leq 2$ so that a
unique (up to some isometries) minimizer exists on each sub-intervals $(p_k,
p_{k+1})$. %In addition we conjecture that $\lim_{k\to \infty}p_{2k+1}=2$.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:07:45 GMT""}]","2022-12-09"
"2212.04445","Alfredo Roque Freire","Alfredo Roque Freire and Kameryn J. Williams","Non-tightness in class theory and second-order arithmetic",,,,,"math.LO","http://creativecommons.org/licenses/by/4.0/","  A theory T is tight if different deductively closed extensions of T (in the
same language) cannot be bi-interpretable. Many well-studied foundational
theories are tight, including PA [Visser2006], ZF, Z2, and KM [enayat2017]. In
this article we extend Enayat's investigations to subsystems of these latter
two theories. We prove that restricting the Comprehension schema of Z2 and KM
gives non-tight theories. Specifically, we show that GB and ACA0 each admit
different bi-interpretable extensions, and the same holds for their extensions
by adding Sigma^1_k-Comprehension, for k <= 1. These results provide evidence
that tightness characterizes Z2 and KM in a minimal way.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:07:48 GMT""},{""version"":""v2"",""created"":""Sun, 14 May 2023 20:34:18 GMT""}]","2023-05-16"
"2212.04446","Shailesh Trivedi","Sameer Chavan and Shailesh Trivedi","Failure of the wandering subspace property for analytic norm-increasing
  $3$-isometries","16 pages, 2 figures",,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  We construct an analytic norm-increasing $3$-isometric weighted shift on a
rootless directed tree, which does not have the wandering subspace property.
This answers a question of Shimorin [S2001, p. 185] in the negative. The
counterexample in question is built over the rootless quasi-Brownian directed
tree of valency $2.$
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:09:19 GMT""}]","2022-12-09"
"2212.04447","Xingjiang Zhou","Jiangang Yang, Yuyang Xie, Zhen Zhao, Xinwei Yi, Taimin Miao, Hailan
  Luo, Hao Chen, Bo Liang, Wenpei Zhu, Yuhan Ye, Jing-Yang You, Bo Gu, Shenjin
  Zhang, Fengfeng Zhang, Feng Yang, Zhimin Wang, Qinjun Peng, Hanqing Mao,
  Guodong Liu, Zuyan Xu, Hui Chen, Haitao Yang, Gang Su, Hongjun Gao, Lin Zhao
  and X. J. Zhou","Observation of Flat Band, Dirac Nodal Lines and Topological Surface
  States in Kagome Superconductor CsTi$_3$Bi$_5$",,,,,"cond-mat.supr-con cond-mat.mtrl-sci cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A kagome lattice of 3d transition metals hosts flat bands, Dirac fermions and
saddle points. It provides a versatile platform for achieving topological
superconductivity, anomalous Hall effect, unconventional density wave order and
quantum spin liquid when the strong correlation, spin-orbit coupling or
magnetic order are involved in such a lattice. Here, using laser-based
angle-resolved photoemission spectroscopy in combination with density
functional theory calculations, we investigate the electronic structure of the
newly discovered kagome superconductor CsTi$_3$Bi$_5$, which is isostructural
to the AV$_3$Sb$_5$ (A=K, Rb or Cs) kagome superconductors and possesses a
perfect two-dimensional kagome network of Titanium. We directly observed a
strikingly flat band derived from the local destructive interferences of Bloch
wave functions within the kagome lattices. We also identify the type-II Dirac
nodal loops around the Brillouin zone center, the type-III Dirac nodal loops
around the zone corners and type-III Dirac nodal lines along the k$_z$
direction. In addition, around the Brillouin zone center, Z2 nontrivial
topological surface states are also observed which is formed from the band
inversion due to strong spin orbital coupling. The simultaneous existence of
such multi-sets of nontrivial band structures in one kagome superconductor not
only provides good opportunities to study related physics in the kagome lattice
but also makes CsTi$_3$Bi$_5$ an ideal system to realize noval quantum
phenomena by manipulating its chemical potential with chemical doping or
pressure.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:09:32 GMT""}]","2022-12-09"
"2212.04448","Aneeq Zia","Aneeq Zia, Kiran Bhattacharyya, Xi Liu, Ziheng Wang, Max Berniker,
  Satoshi Kondo, Emanuele Colleoni, Dimitris Psychogyios, Yueming Jin, Jinfan
  Zhou, Evangelos Mazomenos, Lena Maier-Hein, Danail Stoyanov, Stefanie
  Speidel, Anthony Jarc","Objective Surgical Skills Assessment and Tool Localization: Results from
  the MICCAI 2021 SimSurgSkill Challenge","arXiv admin note: substantial text overlap with arXiv:1910.04071",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Timely and effective feedback within surgical training plays a critical role
in developing the skills required to perform safe and efficient surgery.
Feedback from expert surgeons, while especially valuable in this regard, is
challenging to acquire due to their typically busy schedules, and may be
subject to biases. Formal assessment procedures like OSATS and GEARS attempt to
provide objective measures of skill, but remain time-consuming. With advances
in machine learning there is an opportunity for fast and objective automated
feedback on technical skills. The SimSurgSkill 2021 challenge (hosted as a
sub-challenge of EndoVis at MICCAI 2021) aimed to promote and foster work in
this endeavor. Using virtual reality (VR) surgical tasks, competitors were
tasked with localizing instruments and predicting surgical skill. Here we
summarize the winning approaches and how they performed. Using this publicly
available dataset and results as a springboard, future work may enable more
efficient training of surgeons with advances in surgical data science. The
dataset can be accessed from
https://console.cloud.google.com/storage/browser/isi-simsurgskill-2021.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:14:52 GMT""}]","2022-12-09"
"2212.04452","Eduardo Ba\~nados","Eduardo Banados, Jan-Torge Schindler, Bram P. Venemans, Thomas Connor,
  Roberto Decarli, Emanuele Paolo Farina, Chiara Mazzucchelli, Romain A. Meyer,
  Daniel Stern, Fabian Walter, Xiaohui Fan, Joseph F. Hennawi, Yana Khusanova,
  Nidia Morrell, Riccardo Nanni, Gael Noirot, Antonio Pensabene, Hans-Walter
  Rix, Joseph Simon, Gijs A. Verdoes Kleijn, Zhang-Liang Xie, Da-Ming Yang,
  Andrew Connor","The Pan-STARRS1 z>5.6 quasar survey II: Discovery of 55 Quasars at
  5.6<z<6.5","Version after addressing referee report. See companion paper by
  Schindler et al",,"10.3847/1538-4365/acb3c7",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The identification of bright quasars at z>6 enables detailed studies of
supermassive black holes, massive galaxies, structure formation, and the state
of the intergalactic medium within the first billion years after the Big Bang.
We present the spectroscopic confirmation of 55 quasars at redshifts 5.6<z<6.5
and UV magnitudes -24.5<M1450<-28.5 identified in the optical Pan-STARRS1 and
near-IR VIKING surveys (48 and 7, respectively). Five of these quasars have
been independently discovered in other studies. The quasar sample shows an
extensive range of physical properties, including 17 objects with weak emission
lines, ten broad absorption line quasars, and five with strong radio emission
(radio-loud quasars). There are also a few notable sources in the sample,
including a blazar candidate at z=6.23, a likely gravitationally lensed quasar
at z=6.41, and a z=5.84 quasar in the outskirts of the nearby (D~3 Mpc) spiral
galaxy M81. The blazar candidate remains undetected in NOEMA observations of
the [CII] and underlying emission, implying a star-formation rate <30-70
Msun/yr. A significant fraction of the quasars presented here lies at the
foundation of the first measurement of the z~6 quasar luminosity function from
Pan-STARRS1 (introduced in a companion paper). The quasars presented here will
enable further studies of the high-redshift quasar population with current and
future facilities.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:19:41 GMT""}]","2023-03-15"
"2212.04453","Jean-Marc Valin","Jean-Marc Valin, Jan B\""uthe, Ahmed Mustafa","Low-Bitrate Redundancy Coding of Speech Using a
  Rate-Distortion-Optimized Variational Autoencoder","Proc. ICASSP 2023, 5 pages",,,,"eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Robustness to packet loss is one of the main ongoing challenges in real-time
speech communication. Deep packet loss concealment (PLC) techniques have
recently demonstrated improved quality compared to traditional PLC. Despite
that, all PLC techniques hit fundamental limitations when too much acoustic
information is lost. To reduce losses in the first place, data is commonly sent
multiple times using various redundancy mechanisms. We propose a neural speech
coder specifically optimized to transmit a large amount of overlapping
redundancy at a very low bitrate, up to 50x redundancy using less than 32~kb/s.
Results show that the proposed redundancy is more effective than the existing
Opus codec redundancy, and that the two can be combined for even greater
robustness.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:23:52 GMT""},{""version"":""v2"",""created"":""Fri, 24 Feb 2023 19:51:00 GMT""}]","2023-02-28"
"2212.04454","Truc Nguyen","Truc Nguyen, Phung Lai, NhatHai Phan, My T. Thai","XRand: Differentially Private Defense against Explanation-Guided Attacks","To be published at AAAI 2023",,,,"cs.LG cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent development in the field of explainable artificial intelligence (XAI)
has helped improve trust in Machine-Learning-as-a-Service (MLaaS) systems, in
which an explanation is provided together with the model prediction in response
to each query. However, XAI also opens a door for adversaries to gain insights
into the black-box models in MLaaS, thereby making the models more vulnerable
to several attacks. For example, feature-based explanations (e.g., SHAP) could
expose the top important features that a black-box model focuses on. Such
disclosure has been exploited to craft effective backdoor triggers against
malware classifiers. To address this trade-off, we introduce a new concept of
achieving local differential privacy (LDP) in the explanations, and from that
we establish a defense, called XRand, against such attacks. We show that our
mechanism restricts the information that the adversary can learn about the top
important features, while maintaining the faithfulness of the explanations.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:23:59 GMT""},{""version"":""v2"",""created"":""Sat, 10 Dec 2022 05:38:36 GMT""},{""version"":""v3"",""created"":""Wed, 14 Dec 2022 18:03:04 GMT""}]","2022-12-15"
"2212.04455","Jeremy Hare","Jeremy Hare, Oleg Kargaltsev, George Younes, George G. Pavlov, Igor
  Volkov","XMM-Newton and Chandra observations of the candidate Fermi-LAT pulsar
  4FGL J1015.5-6030","Accepted for publication in ApJ",,,,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  4FGL J1015.5-6030 is an unidentified Fermi-LAT source hosting a bright,
extended X-ray source whose X-ray spectrum is consistent with that of a young
pulsar, yet no pulsations have been found. Here we report on XMM-Newton timing
and Chandra imaging observations of the X-ray counterpart of 4FGL J1015.5-6030.
We find no significant periodicity from the source and place a 3$\sigma$
upper-limit on its pulsed fraction of 34$\%$. The Chandra observations resolve
the point source from the extended emission. We find that the point source's
spectrum is well fit by a blackbody model, with temperature $kT=0.205\pm0.009$
keV, plus a weak power-law component, which is consistent with a thermally
emitting neutron star with a magnetospheric component. The extended emission
spans angular scales of a few arcseconds up to about 30$''$ from the point
source and its spectrum is well fit by a power-law model with a photon index
$\Gamma=1.70\pm0.05$. The extended emission's spectrum and 0.5-10 keV
luminosity of 4$\times10^{32}$ erg s$^{-1}$ (at a plausible distance of 2 kpc)
are consistent with that of a pulsar wind nebula. Based on a comparison to
other GeV and X-ray pulsars, we find that this putative pulsar is likely a
middle-aged (i.e., $\tau\sim 0.1$--1 Myr) radio-quiet pulsar with
$\dot{E}\sim10^{34}-10^{35}$ erg s$^{-1}$.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:25:13 GMT""},{""version"":""v2"",""created"":""Thu, 18 May 2023 00:40:26 GMT""}]","2023-05-19"
"2212.04456","Alessandro Carones","Alessandro Carones, Marina Migliaccio, Giuseppe Puglisi, Carlo
  Baccigalupi, Domenico Marinucci, Nicola Vittorio, Davide Poletti","Multi-Clustering Needlet-ILC for CMB B-modes component separation","16 pages, 12 figures. Abstract abridged for arXiv",,,,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Cosmic Microwave Background (CMB) primordial B-modes signal is predicted
to be much lower than the polarized Galactic emission (foregrounds) in any
region of the sky pointing to the need for sophisticated component separation
methods. Among them, the blind Needlet-ILC (NILC) has great relevance given our
current poor knowledge of the B-modes foregrounds. However the expected level
of spatial variability of the foreground spectral properties complicates the
NILC subtraction of the Galactic contamination. In order to reach the ambitious
targets of future CMB experiments, we therefore propose a novel extension of
the NILC approach, the Multi-Clustering NILC (MC-NILC), which performs NILC
variance minimization on separate regions of the sky (clusters) properly chosen
to have similar spectral properties of the B-modes foregrounds emission.
Clusters are identified thresholding the ratio of B-modes maps at two separate
frequencies which is used as tracer of the spatial distribution of the spectral
indices of the Galactic emission in B modes. We consider ratios either of
simulated foregrounds-only B modes (ideal case) or of cleaned templates of
Galactic emission obtained from realistic simulations. In this work we present
an application of MC-NILC to the future LiteBIRD satellite, which targets the
observation of both reionization and recombination peaks of the primordial
B-modes angular power spectrum with a total error on the tensor-to-scalar ratio
$\delta r < 0.001$. We show that MC-NILC provides a CMB solution with residual
foregrounds and noise contamination that is significantly reduced with respect
to NILC and lower than the primordial signal targeted by LiteBIRD at all
angular scales for the ideal case and at the reionization peak for a realistic
ratio. Thus, MC-NILC will represent a powerful method to mitigate B-modes
foregrounds for future CMB polarization experiments.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:28:56 GMT""}]","2022-12-09"
"2212.04457","Rajat Arora","Rajat Arora and Ankit Shrivastava","Spatio-Temporal Super-Resolution of Dynamical Systems using
  Physics-Informed Deep-Learning","Accepted in AAAI 2023: Workshop on AI to Accelerate Science and
  Engineering (AI2ASE)",,,,"cs.LG cond-mat.mtrl-sci cs.CE","http://creativecommons.org/licenses/by/4.0/","  This work presents a physics-informed deep learning-based super-resolution
framework to enhance the spatio-temporal resolution of the solution of
time-dependent partial differential equations (PDE). Prior works on deep
learning-based super-resolution models have shown promise in accelerating
engineering design by reducing the computational expense of traditional
numerical schemes. However, these models heavily rely on the availability of
high-resolution (HR) labeled data needed during training. In this work, we
propose a physics-informed deep learning-based framework to enhance the spatial
and temporal resolution of coarse-scale (both in space and time) PDE solutions
without requiring any HR data. The framework consists of two trainable modules
independently super-resolving the PDE solution, first in spatial and then in
temporal direction. The physics based losses are implemented in a novel way to
ensure tight coupling between the spatio-temporally refined outputs at
different times and improve framework accuracy. We analyze the capability of
the developed framework by investigating its performance on an elastodynamics
problem. It is observed that the proposed framework can successfully
super-resolve (both in space and time) the low-resolution PDE solutions while
satisfying physics-based constraints and yielding high accuracy. Furthermore,
the analysis and obtained speed-up show that the proposed framework is
well-suited for integration with traditional numerical methods to reduce
computational complexity during engineering design.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:30:18 GMT""}]","2022-12-09"
"2212.04458","Louis Kirsch","Louis Kirsch, James Harrison, Jascha Sohl-Dickstein, Luke Metz","General-Purpose In-Context Learning by Meta-Learning Transformers","Published at the NeurIPS 2022 Workshop on Meta-Learning. Full version
  currently under review",,,,"cs.LG cs.AI cs.NE stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modern machine learning requires system designers to specify aspects of the
learning pipeline, such as losses, architectures, and optimizers.
Meta-learning, or learning-to-learn, instead aims to learn those aspects, and
promises to unlock greater capabilities with less manual effort. One
particularly ambitious goal of meta-learning is to train general-purpose
in-context learning algorithms from scratch, using only black-box models with
minimal inductive bias. Such a model takes in training data, and produces
test-set predictions across a wide range of problems, without any explicit
definition of an inference model, training loss, or optimization algorithm. In
this paper we show that Transformers and other black-box models can be
meta-trained to act as general-purpose in-context learners. We characterize
phase transitions between algorithms that generalize, algorithms that memorize,
and algorithms that fail to meta-train at all, induced by changes in model
size, number of tasks, and meta-optimization. We further show that the
capabilities of meta-trained algorithms are bottlenecked by the accessible
state size (memory) determining the next prediction, unlike standard models
which are thought to be bottlenecked by parameter count. Finally, we propose
practical interventions such as biasing the training distribution that improve
the meta-training and meta-generalization of general-purpose learning
algorithms.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:30:22 GMT""}]","2022-12-09"
"2212.04459","Spandan Senapati","Spandan Senapati, Ashwin Shenai, Ketan Rajawat","Proximal Algorithms for Smoothed Online Convex Optimization with
  Predictions","22 pages, 10 figures; Corrected Typos, Updated Figure 10",,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  In this paper, we consider a smoothed online convex optimization (SOCO)
problem with predictions, where the learner has access to a finite lookahead
window of time-varying stage costs, but suffers a penalty for changing its
actions at each stage. Based on the Alternating Proximal Gradient Descent
(APGD) framework, we develop Receding Horizon Alternating Proximal Descent
(RHAPD) for proximable, non-smooth and strongly convex stage costs, and
RHAPD-Smooth (RHAPD-S) for non-proximable, smooth and strongly convex stage
costs. In addition to outperforming gradient descent-based algorithms while
maintaining a comparable runtime complexity, our proposed algorithms also allow
us to solve a wider range of problems. We provide theoretical upper bounds on
the dynamic regret achieved by the proposed algorithms, which decay
exponentially with the length of the lookahead window. The performance of the
presented algorithms is empirically demonstrated via numerical experiments on
non-smooth regression and dynamic trajectory tracking problems.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:33:25 GMT""},{""version"":""v2"",""created"":""Tue, 3 Jan 2023 18:32:09 GMT""}]","2023-01-04"
"2212.04460","Yang Luo","Bo Liu, Minquan Kuang, Yang Luo, Yongkai Li, Linwei Huai, Shuting
  Peng, Zhiyuan Wei, Jianchang Shen, Bingqian Wang, Yu Miao, Xiupeng Sun,
  Zhipeng Ou, Yugui Yao, Zhiwei Wang and Junfeng He","Tunable van Hove singularity without structural instability in Kagome
  metal CsTi$_3$Bi$_5$",,,,,"cond-mat.str-el cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In Kagome metal CsV$_3$Sb$_5$, multiple intertwined orders are accompanied by
both electronic and structural instabilities. These exotic orders have
attracted much recent attention, but their origins remain elusive. The newly
discovered CsTi$_3$Bi$_5$ is a Ti-based Kagome metal to parallel CsV$_3$Sb$_5$.
Here, we report angle-resolved photoemission experiments and first-principles
calculations on pristine and Cs-doped CsTi$_3$Bi$_5$ samples. Our results
reveal that the van Hove singularity (vHS) in CsTi$_3$Bi$_5$ can be tuned in a
large energy range without structural instability, different from that in
CsV$_3$Sb$_5$. As such, CsTi$_3$Bi$_5$ provides a complementary platform to
disentangle and investigate the electronic instability with a tunable vHS in
Kagome metals.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:34:39 GMT""}]","2022-12-09"
"2212.04461","Mahsa Forouzesh","Mahsa Forouzesh and Hanie Sedghi and Patrick Thiran","Leveraging Unlabeled Data to Track Memorization",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Deep neural networks may easily memorize noisy labels present in real-world
data, which degrades their ability to generalize. It is therefore important to
track and evaluate the robustness of models against noisy label memorization.
We propose a metric, called susceptibility, to gauge such memorization for
neural networks. Susceptibility is simple and easy to compute during training.
Moreover, it does not require access to ground-truth labels and it only uses
unlabeled data. We empirically show the effectiveness of our metric in tracking
memorization on various architectures and datasets and provide theoretical
insights into the design of the susceptibility metric. Finally, we show through
extensive experiments on datasets with synthetic and real-world label noise
that one can utilize susceptibility and the overall training accuracy to
distinguish models that maintain a low memorization on the training set and
generalize well to unseen clean data.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:36:41 GMT""}]","2022-12-09"
"2212.04462","Quanlong Wang","Razin A. Shaikh, Quanlong Wang, Richie Yeung","How to sum and exponentiate Hamiltonians in ZXW calculus","26 pages, lot of diagrams, accepted to QPL 2022",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper develops practical summation techniques in ZXW calculus to reason
about quantum dynamics, such as unitary time evolution. First we give a direct
representation of a wide class of sums of linear operators, including arbitrary
qubits Hamiltonians, in ZXW calculus. As an application, we demonstrate the
linearity of the Schr\""odinger equation and give a diagrammatic representation
of the Hamiltonian in Greene-Diniz et al (Gabriel, 2022), which is the first
paper that models carbon capture using quantum computing. We then use the
Cayley-Hamilton theorem to show in principle how to exponentiate arbitrary
qubits Hamiltonians in ZXW calculus. Finally, we develop practical techniques
and show how to do Taylor expansion and Trotterization diagrammatically for
Hamiltonian simulation. This sets up the framework for using ZXW calculus to
the problems in quantum chemistry and condensed matter physics.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:38:01 GMT""}]","2022-12-09"
"2212.04463","Tejas Rao","Tejas Rao","Extending Lenstra's Primality Test to CM elliptic curves and a new
  quasi-quadratic Las Vegas algorithm for primality",,,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  For an elliptic curve with CM by $K$ defined over its Hilbert class field,
$E/H$, we extend Lenstra's finite fields test to generators of norms of certain
ideals in $\mathcal{O}_H$, yielding a sufficient $\widetilde{O}(\log^3 N)$
primality test and partially answering an open question of Lemmermeyer in the
case of CM elliptic curves. Letting $\iota,\gamma, b\in \mathcal{O}_K$,
$(\iota)$ prime, and $b$ a primitive $k$-th root of unity modulo $(\iota)^n$ we
specialize this test to rational integers of the form
$N_{K/\mathbb{Q}}(\gamma\iota^n+b)$ with the norm of $\gamma$ small, giving a
Las Vegas test for primality with average runtime $\widetilde{O}(\log^2 N)$,
that further certifies primality of such integers in $\widetilde{O}(\log^2 N)$
for nearly all choices of input parameters. The integers tested were not
previously amenable to quasi-quadratic heuristic primality certification.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:38:25 GMT""},{""version"":""v2"",""created"":""Thu, 22 Dec 2022 17:48:33 GMT""}]","2022-12-23"
"2212.04464","Antoni L\'opez-Mart\'inez","Antoni L\'opez-Mart\'inez","Recurrent subspaces in Banach spaces","23 pages",,,,"math.FA math.DS","http://creativecommons.org/licenses/by/4.0/","  We study the spaceability of the set of recurrent vectors $\text{Rec}(T)$ for
an operator $T:X\longrightarrow X$ on a Banach space $X$. In particular: we
find sufficient conditions for a quasi-rigid operator to have a recurrent
subspace; when $X$ is a complex Banach space we show that having a recurrent
subspace is equivalent to the fact that the essential spectrum of the operator
intersects the closed unit disc; and we extend the previous result to the real
case. As a consequence we obtain that: a weakly-mixing operator on a real or
complex separable Banach space has a hypercyclic subspace if and only if it has
a recurrent subspace. The results exposed exhibit a symmetry between the
hypercyclic and recurrence spaceability theories showing that, at least for the
spaceable property, hypercyclicity and recurrence can be treated as equals.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:38:57 GMT""}]","2022-12-09"
"2212.04466","Ashkan Javaherian","Ashkan Javaherian","A note on an open-source toolbox for simulation of acoustic waves:
  inclusion of time-varying source",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  Simulating propagation of acoustic waves via solving a system of
three-coupled first-order linear differential equations using a k-space
pseudo-spectral method is popular for biomedical applications, firstly because
of availability of an open-source toolbox for implementation of this numerical
approach, and secondly because of its efficiency. The k-space pseudo-spectral
method is efficient, because it allows coarser computational grids and larger
time steps than finite difference and finite element methods for the same
accuracy. The goal of this study is to compare this numerical wave solver with
an analytical solution to the wave equation using the Green's function for
computing propagation of acoustic waves in homogeneous media. This comparison
is done in the frequency domain. Using the k-Wave solver, a match to the
Green's function is obtained after modifying the approach taken for including
mass source in the linearised equation of continuity (conservation of mass) in
the associated system of wave equations.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:40:24 GMT""},{""version"":""v2"",""created"":""Fri, 9 Dec 2022 12:42:08 GMT""},{""version"":""v3"",""created"":""Mon, 30 Jan 2023 12:49:30 GMT""}]","2023-01-31"
"2212.04467","Fabian Reede","Fabian Reede","Descent of tautological sheaves from Hilbert schemes to Enriques
  manifolds","10 pages. Comments welcome",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $X$ be a K3 surface which doubly covers an Enriques surface $S$. If
$n\in\mathbb{N}$ is an odd number, then the Hilbert scheme of $n$-points
$X^{[n]}$ admits a natural quotient $S_{[n]}$. This quotient is an Enriques
manifold in the sense of Oguiso and Schr\""oer. In this paper we construct slope
stable sheaves on $S_{[n]}$ and study some of their properties.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:40:48 GMT""}]","2022-12-09"
"2212.04468","Nazmul Hasan","Nazmul Hasan, Kazi Mahmudul Hasan, Md. Tahsinul Islam, Shahnewaz
  Siddique","Investigation of Minerals Using Hyperspectral Satellite Imagery in
  Bangladesh",,,,,"eess.IV cs.SY eess.SY","http://creativecommons.org/licenses/by-sa/4.0/","  Mineral identification using remote sensing technologies is becoming more
dominant in this field since it saves time by demonstrating a more effective
way for land resources survey. In such remote sensing technologies,
hyperspectral remote sensing (HSRS) technology has increased gradually for its
efficient manner. This technology is usually used from an airborne platform,
i.e., satellite. Hence, satellite imagery remote sensing technology is now more
capable of providing accuracy in mineral identification, and mapping.
Hyperspectral satellite imagery can identify minerals more accurately compared
to traditional technologies in remote sensing by constructing a complete
reflectance of the spectrum from each pixel with its advanced imaging sensor.
Bangladesh is a developing country with an area of 1,50,000 square kilometers
located in Southeast Asia. Though it is a small country, it is enriched with
several mineral resources through rivers, forests, hills, and the Bay of
Bengal. In this study, hyperspectral imaging technology is employed on some
major identical areas (Maheshkhali, Netrokona, Panchagarh, and Patuakhali) of
Bangladesh to identify minerals there. As there are no studies done in
Bangladesh using hyperspectral imaging yet, it is a good opportunity to explore
the potentiality of HS imagery in this field. In this study, the FLAASH (Fast
Line-of-sight Atmospheric Analysis) module with necessary parameter settings is
used to filter the data, and finally, mineral identification is done by the
spectral matched filtering method. Our investigation resulted in finding some
potential minerals in those areas including Stariolite, Diasphore, Zircon,
Alunite, Quartz, and so on. This indicates that there still is enormous
potential for further exploration of minerals in Bangladesh by Hyperspectral
Satellite Imagery.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:41:02 GMT""}]","2022-12-09"
"2212.04469","Andela Sarkovic","Jonathan Hermon, An{\dj}ela \v{S}arkovi\'c and Perla Sousi","Cutoff for random walk on random graphs with a community structure",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a variant of the configuration model with an embedded community
structure and study the mixing properties of a simple random walk on it. Every
vertex has an internal $\mathrm{deg}^{\text{int}}\geq 3$ and an outgoing
$\mathrm{deg}^{\text{out}}$ number of half-edges. Given a stochastic matrix
$Q$, we pick a random perfect matching of the half-edges subject to the
constraint that each vertex $v$ has $\mathrm{deg}^{\text{int}}(v)$ neighbours
inside its community and the proportion of outgoing half-edges from community
$i$ matched to a half-edge from community $j$ is $Q(i,j)$. Assuming the number
of communities is constant and they all have comparable sizes, we prove the
following dichotomy: simple random walk on the resulting graph exhibits cutoff
if and only if the product of the Cheeger constant of $Q$ times $\log n$ (where
$n$ is the number of vertices) diverges.
  In [4], Ben-Hamou established a dichotomy for cutoff for a non-backtracking
random walk on a similar random graph model with 2 communities. We prove the
same characterisation of cutoff holds for simple random walk.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:43:22 GMT""}]","2022-12-09"
"2212.04470","Benedikt Fesl","Benedikt Fesl and Michael Koller and Wolfgang Utschick","On the Mean Square Error Optimal Estimator in One-Bit Quantized Systems",,,,,"cs.IT eess.SP math.IT","http://creativecommons.org/licenses/by/4.0/","  This paper investigates the mean square error (MSE)-optimal conditional mean
estimator (CME) in one-bit quantized systems in the context of channel
estimation with jointly Gaussian inputs. We analyze the relationship of the
generally nonlinear CME to the linear Bussgang estimator, a well-known method
based on Bussgang's theorem. We highlight a novel observation that the Bussgang
estimator is equal to the CME for different special cases, including the case
of univariate Gaussian inputs and the case of multiple pilot signals in the
absence of additive noise prior to the quantization. For the general cases we
conduct numerical simulations to quantify the gap between the Bussgang
estimator and the CME. This gap increases for higher dimensions and longer
pilot sequences. We propose an optimal pilot sequence, motivated by insights
from the CME, and derive a novel closed-form expression of the MSE for that
case. Afterwards, we find a closed-form limit of the MSE in the asymptotically
large number of pilots regime that also holds for the Bussgang estimator.
Lastly, we present numerical experiments for various system parameters and for
different performance metrics which illuminate the behavior of the optimal
channel estimator in the quantized regime. In this context, the well-known
stochastic resonance effect that appears in quantized systems can be
quantified.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:45:50 GMT""},{""version"":""v2"",""created"":""Thu, 27 Apr 2023 18:01:22 GMT""}]","2023-05-01"
"2212.04471","Matthias C. Caro","Matthias C. Caro","Learning Quantum Processes and Hamiltonians via the Pauli Transfer
  Matrix","28+31 pages, 2+1 figures",,,,"quant-ph cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning about physical systems from quantum-enhanced experiments, relying on
a quantum memory and quantum processing, can outperform learning from
experiments in which only classical memory and processing are available.
Whereas quantum advantages have been established for a variety of state
learning tasks, quantum process learning allows for comparable advantages only
with a careful problem formulation and is less understood. We establish an
exponential quantum advantage for learning an unknown $n$-qubit quantum process
$\mathcal{N}$. We show that a quantum memory allows to efficiently solve the
following tasks: (a) learning the Pauli transfer matrix of an arbitrary
$\mathcal{N}$, (b) predicting expectation values of bounded Pauli-sparse
observables measured on the output of an arbitrary $\mathcal{N}$ upon input of
a Pauli-sparse state, and (c) predicting expectation values of arbitrary
bounded observables measured on the output of an unknown $\mathcal{N}$ with
sparse Pauli transfer matrix upon input of an arbitrary state. With quantum
memory, these tasks can be solved using linearly-in-$n$ many copies of the Choi
state of $\mathcal{N}$, and even time-efficiently in the case of (b). In
contrast, any learner without quantum memory requires exponentially-in-$n$ many
queries, even when querying $\mathcal{N}$ on subsystems of adaptively chosen
states and performing adaptively chosen measurements. In proving this
separation, we extend existing shadow tomography upper and lower bounds from
states to channels via the Choi-Jamiolkowski isomorphism. Moreover, we combine
Pauli transfer matrix learning with polynomial interpolation techniques to
develop a procedure for learning arbitrary Hamiltonians, which may have
non-local all-to-all interactions, from short-time dynamics. Our results
highlight the power of quantum-enhanced experiments for learning highly complex
quantum dynamics.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:46:06 GMT""}]","2022-12-09"
"2212.04472","Gabriel Fettu","Gabriel Fettu, John E. Sipe, Oussama Moutanabbir","Mid-Infrared Optical Spin Injection and Coherent Control","8 pages, 9 figures, with a Supporting Material file",,"10.1103/PhysRevB.107.165202",,"cond-mat.mtrl-sci quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The optical injection of charge and spin currents are investigated in
Ge$_{1-x}$Sn$_{x}$ semiconductors as a function of Sn content. These emerging
silicon-compatible materials enable the modulation of these processes across
the entire mid-infrared range. Under the independent particle approximation,
the one- and two-photon interband absorption processes are elucidated, and the
evolution of the coherent control is discussed for three different polarization
configurations. To evaluate the contribution of high-energy transitions, a
full-zone 30-band k$\cdot$p is employed in the calculations. It was found that,
besides the anticipated narrowing of the direct gap and the associated shift of
the absorption to longer wavelengths, incorporating Sn in Ge also increases the
one-photon degree of spin polarization (DSP) at the $E_1$ resonance. Moreover,
as the Sn content increases, the magnitude of the response tensors near the
band edge exhibits an exponential enhancement. This behavior can be attributed
to the Sn incorporation-induced decrease in the carrier effective masses. This
trend appears to hold also at the $E_1$ resonance for pure spin current
injection, at least at low Sn compositions. The two-photon DSP at the band edge
exceeds the value in Ge to reach 60 % at a Sn content above 14 %. These results
demonstrate that Ge$_{1-x}$Sn$_{x}$ semiconductors can be exploited to achieve
the quantum coherent manipulation in the molecular fingerprint region relevant
to quantum sensing.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:46:17 GMT""}]","2023-05-03"
"2212.04473","Kunpeng Song","Kunpeng Song, Ligong Han, Bingchen Liu, Dimitris Metaxas, Ahmed
  Elgammal","Diffusion Guided Domain Adaptation of Image Generators","Project website: https://styleganfusion.github.io/",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Can a text-to-image diffusion model be used as a training objective for
adapting a GAN generator to another domain? In this paper, we show that the
classifier-free guidance can be leveraged as a critic and enable generators to
distill knowledge from large-scale text-to-image diffusion models. Generators
can be efficiently shifted into new domains indicated by text prompts without
access to groundtruth samples from target domains. We demonstrate the
effectiveness and controllability of our method through extensive experiments.
Although not trained to minimize CLIP loss, our model achieves equally high
CLIP scores and significantly lower FID than prior work on short prompts, and
outperforms the baseline qualitatively and quantitatively on long and
complicated prompts. To our best knowledge, the proposed method is the first
attempt at incorporating large-scale pre-trained diffusion models and
distillation sampling for text-driven image generator domain adaptation and
gives a quality previously beyond possible. Moreover, we extend our work to
3D-aware style-based generators and DreamBooth guidance.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:46:19 GMT""},{""version"":""v2"",""created"":""Fri, 9 Dec 2022 08:58:13 GMT""}]","2022-12-12"
"2212.04474","James Hansen","James E. Hansen (1), Makiko Sato (1), Leon Simons (2), Larissa S.
  Nazarenko (3 and 4), Isabelle Sangha (1), Karina von Schuckmann (5), Norman
  G. Loeb (6), Matthew B. Osman (7), Qinjian Jin (8), Pushker Kharecha (1),
  George Tselioudis (3), Eunbi Jeong (9), Andrew Lacis (3), Reto Ruedy (3 and
  10), Gary Russell (3), Junji Cao (11), Jing Li (12) ((1) Climate Science,
  Awareness and Solutions, Columbia University Earth Institute, New York, NY,
  USA, (2) The Club of Rome Netherlands, 's-Hertogenbosch, The Netherlands, (3)
  NASA Goddard Institute for Space Studies, New York, NY, USA, (4) Center for
  Climate Systems Research, Columbia University Earth Institute, New York, NY,
  USA, (5) Mercator Ocean International, Ramonville St.-Agne, France, (6) NASA
  Langley Research Center, Hampton, VA, USA, (7) Department of Geosciences,
  University of Arizona, Tucson, AZ, USA, (8) Department of Geography and
  Atmospheric Science, University of Kansas, Lawrence, KS, USA, (9) CSAS KOREA,
  Goyang, Gyeonggi-do, South Korea, (10) Business Integra, Inc., New York, NY,
  USA, (11) Institute of Atmospheric Physics, Chinese Academy of Sciences,
  Beijing, China, (12) Department of Atmospheric and Oceanic Sciences, School
  of Physics, Peking University, Beijing, China)","Global warming in the pipeline","62 pages, 39 figures, 1 table. Revision for journal resubmission",,,,"physics.ao-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Improved knowledge of glacial-to-interglacial global temperature change
implies that fast-feedback equilibrium climate sensitivity (ECS) is 1.2 +/-
0.3{\deg}C (2$\sigma$) per W/m$^2$. Consistent analysis of temperature over the
full Cenozoic era -- including ""slow"" feedbacks by ice sheets and trace gases
-- supports this ECS and implies that CO$_2$ was about 300 ppm in the Pliocene
and 400 ppm at transition to a nearly ice-free planet, thus exposing
unrealistic lethargy of ice sheet models. Equilibrium global warming including
slow feedbacks for today's human-made greenhouse gas (GHG) climate forcing (4.1
W/m$^2$) is 10{\deg}C, reduced to 8{\deg}C by today's aerosols. Decline of
aerosol emissions since 2010 should increase the 1970-2010 global warming rate
of 0.18{\deg}C per decade to a post-2010 rate of at least 0.27{\deg}C per
decade. Under the current geopolitical approach to GHG emissions, global
warming will likely pierce the 1.5{\deg}C ceiling in the 2020s and 2{\deg}C
before 2050. Impacts on people and nature will accelerate as global warming
pumps up hydrologic extremes. The enormity of consequences demands a return to
Holocene-level global temperature. Required actions include: 1) a global
increasing price on GHG emissions, 2) East-West cooperation in a way that
accommodates developing world needs, and 3) intervention with Earth's radiation
imbalance to phase down today's massive human-made ""geo-transformation"" of
Earth's climate. These changes will not happen with the current geopolitical
approach, but current political crises present an opportunity for reset,
especially if young people can grasp their situation.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:48:43 GMT""},{""version"":""v2"",""created"":""Mon, 12 Dec 2022 18:55:10 GMT""},{""version"":""v3"",""created"":""Tue, 23 May 2023 17:37:21 GMT""}]","2023-05-24"
"2212.04476","Xin Wang","Xin Wang, Cheng Cheng, Junqiang Ge, Xiao-Lei Meng, Emanuele Daddi,
  Haojing Yan, Tucker Jones, Matthew A. Malkan, Pablo Arrabal Haro, Gabriel
  Brammer, Masamune Oguri","A strong He II $\lambda$1640 emitter with extremely blue UV spectral
  slope at $z=8.16$: presence of Pop III stars?","Submitted",,,,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Cosmic hydrogen reionization and cosmic production of first metals are major
phase transitions of the Universe occurring during the first billion years
after the Big Bang, but still poorly explored observationally. Using the JWST
NIRSpec prism spectroscopy, we report the discovery of a sub-$L_{\ast}$ galaxy
at $z_{\rm spec}=8.1623_{-0.0008}^{+0.0007}$, dubbed RXJ2129-z8HeII, via the
detection of a series of strong rest-frame UV/optical nebular emission lines
and the clear Lyman break. A strong He II $\lambda$1640 emission is present,
the highest redshift He II line currently known. Its high rest-frame equivalent
width (EW $=19.4\pm3.2$ Angstrom) and extreme flux ratios with respect to UV
metal lines and Balmer lines raise the possibility that part of
RXJ2129-z8HeII's stellar populations could be Pop III-like. RXJ2129-z8HeII also
shows a pronounced UV continuum with an extremely steep (i.e. blue) spectral
slope of $\beta=-2.50\pm0.08$, the steepest amongst all spectroscopically
confirmed galaxies at $z\gtrsim7$, in support of its very hard ionizing
spectrum that could lead to a significant leakage of its ionizing flux.
Therefore, RXJ2129-z8HeII is representative of the key galaxy population
driving the cosmic reionization. To date, this is also the most compelling case
where trace Pop III stars might coexist with more metal-enriched stars.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:51:10 GMT""}]","2022-12-09"
"2212.04477","David Long","Long-Hin Tang, David M. Long, Anatoli Polkovnikov, Anushya Chandran,
  Pieter W. Claeys","Integrability and quench dynamics in the spin-1 central spin XX model","39 pages, 11 figures",,,,"cond-mat.str-el cond-mat.mes-hall cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Central spin models provide an idealized description of interactions between
a central degree of freedom and a mesoscopic environment of surrounding spins.
We show that the family of models with a spin-1 at the center and XX
interactions of arbitrary strength with surrounding spins is integrable.
Specifically, we derive an extensive set of conserved quantities and obtain the
exact eigenstates using the Bethe ansatz. As in the homogenous limit, the
states divide into two exponentially large classes: bright states, in which the
spin-1 is entangled with its surroundings, and dark states, in which it is not.
On resonance, the bright states further break up into two classes depending on
their weight on states with central spin polarization zero. These classes are
probed in quench dynamics wherein they prevent the central spin from reaching
thermal equilibrium. In the single spin-flip sector we explicitly construct the
bright states and show that the central spin exhibits oscillatory dynamics as a
consequence of the semilocalization of these eigenstates. We relate the
integrability to the closely related class of integrable Richardson-Gaudin
models, and conjecture that the spin-$s$ central spin XX model is integrable
for any $s$.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:52:42 GMT""},{""version"":""v2"",""created"":""Fri, 9 Dec 2022 22:37:50 GMT""},{""version"":""v3"",""created"":""Sat, 6 May 2023 20:12:03 GMT""}]","2023-06-07"
"2212.04479","Maxence Corman","Maxence Corman and William E. East","Starting inflation from inhomogeneous initial conditions with momentum","28 pages,10 figures",,,,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the circumstances under which cosmic inflation can arise from
very inhomogeneous initial conditions using numerical relativity simulations.
Previous studies have not considered cases with non-zero momentum density due
to technical challenges with solving the coupled Einstein constraint equations.
Here we address these, introducing and comparing several different ways of
constructing cosmological initial conditions with inhomogeneous scalar field
and time derivative profiles. We evolve such initial conditions with large
inhomogeneities in both single- and two-field inflationary models. We study
cases where the initial gradient and kinetic energy are much larger than the
inflationary energy scale, and black holes can form, as well as cases where the
initial scalar potential energy is comparable, as in scenarios where inflation
occurs at nearly Planckian densities, finding large-field inflation to be
generally robust. We consider examples of initial conditions where a large
scalar field velocity towards non-inflationary values would prevent inflation
from occurring in the homogeneous case, finding that the addition of large
gradients in the scalar field can actually dilute this effect, with the
increased expansion and non-vanishing restoring force leading to inflation.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:53:15 GMT""}]","2022-12-09"
"2212.04480","Brant Robertson","B. E. Robertson (1), S. Tacchella (2, 3), B. D. Johnson (4), K.
  Hainline (5), L. Whitler (5), D. J. Eisenstein (4), R. Endsley (6), M. Rieke
  (5), D. P. Stark (5), S. Alberts (5), A. Dressler (7), E. Egami (5), R.
  Hausen (8), G. Rieke (5), I. Shivaei (5), C. C. Williams (9), C. N. A.
  Willmer (5), S. Arribas (10), N. Bonaventura (11, 12), A. Bunker (13), A. J.
  Cameron (13), S. Carniani (14), S. Charlot (15), J. Chevallard (13), M. Curti
  (2, 3), E. Curtis-Lake (16), F. D'Eugenio (2, 3), P. Jakobsen (11, 12), T. J.
  Looser (2, 3), N. L\""utzgendorf (17), R. Maiolino (2, 3, 18), M. V. Maseda
  (19), T. Rawle (7), H.-W. Rix (20), R. Smit (21), H. \""Ubler (2, 3), C.
  Willott (22), J. Witstok (2, 3), S. Baum (23), R. Bhatawdekar (24), K. Boyett
  (25, 26), Z. Chen (5), A. de Graaff (20), M. Florian (5), J. M. Helton (5),
  R. E. Hviding (5), Z. Ji (5), N. Kumari (27), J. Lyu (5), E. Nelson (28), L.
  Sandles (2, 3), A. Saxena (13, 18), K. A. Suess (1, 29), F. Sun (5), M.
  Topping (5), and I. E. B. Wallace (13) ((1) University of California, Santa
  Cruz, (2) Kavli Institute for Cosmology, University of Cambridge, (3)
  Cavendish Laboratory, University of Cambridge, (4) Center for Astrophysics,
  Harvard & Smithsonian, (5) Steward Observatory, University of Arizona, (6)
  University of Texas, (7) Carnegie Observatories, (8) Johns Hopkins
  University, (9) NSF's National Optical-Infrared Astronomy Research
  Laboratory, (10) Centro de Astrobiolog\'ia, CSIC-INTA, (11) Cosmic Dawn
  Center, Copenhagen, (12) Niels Bohr Institute, University of Copenhagen, (13)
  University of Oxford, (14) Scuola Normale Superiore, Pisa (15) Sorbonne
  Universit\'e/CNRS, Institut d'Astrophysique de Paris, (16) University of
  Hertfordshire, (17) European Space Agency, (18) University College London,
  (19) University of Wisconsin-Madison, (20) Max-Planck-Institut f\""ur
  Astronomie, (21) Liverpool John Moores University, (22) NRC Herzberg, (23)
  University of Manitoba, (24) ESA/ESTEC, (25) University of Melbourne, (26)
  ARC ASTRO3D, (27) AURA for ESA, STScI, (28) University of Colorado, (29)
  KIPAC, Stanford University)","Identification and properties of intense star-forming galaxies at
  redshifts z>10","Author version of manuscript, please visit Nature Astronomy for the
  version published 04 April 2023",,"10.1038/s41550-023-01921-1",,"astro-ph.GA astro-ph.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Surveys with James Webb Space Telescope (JWST) have discovered candidate
galaxies in the first 400 Myr of cosmic time. Preliminary indications have
suggested these candidate galaxies may be more massive and abundant than
previously thought. However, without confirmed distances, their inferred
properties remain uncertain. Here we identify four galaxies located in the JWST
Advanced Deep Extragalactic Survey (JADES) Near-Infrared Camera (NIRCam)
imaging with photometric redshifts z~10-13. These galaxies include the first
redshift z>12 systems discovered with distances spectroscopically confirmed by
JWST in a companion paper. Using stellar population modelling, we find the
galaxies typically contain a hundred million solar masses in stars, in stellar
populations that are less than one hundred million years old. The moderate star
formation rates and compact sizes suggest elevated star formation rate surface
densities, a key indicator of their formation pathways. Taken together, these
measurements show that the first galaxies contributing to cosmic reionisation
formed rapidly and with intense internal radiation fields.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:54:13 GMT""},{""version"":""v2"",""created"":""Wed, 12 Apr 2023 17:04:29 GMT""}]","2023-04-13"
"2212.04481","Kartik Sharma","Kartik Sharma and Yeon-Chang Lee and Sivagami Nambi and Aditya Salian
  and Shlok Shah and Sang-Wook Kim and Srijan Kumar","A Survey of Graph Neural Networks for Social Recommender Systems","GitHub repository with the curated list of papers:
  https://github.com/claws-lab/awesome-GNN-social-recsys",,,,"cs.SI cs.IR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Social recommender systems (SocialRS) simultaneously leverage user-to-item
interactions as well as user-to-user social relations for the task of
generating item recommendations to users. Additionally exploiting social
relations is clearly effective in understanding users' tastes due to the
effects of homophily and social influence. For this reason, SocialRS has
increasingly attracted attention. In particular, with the advance of Graph
Neural Networks (GNN), many GNN-based SocialRS methods have been developed
recently. Therefore, we conduct a comprehensive and systematic review of the
literature on GNN-based SocialRS. In this survey, we first identify 80 papers
on GNN-based SocialRS after annotating 2151 papers by following the PRISMA
framework (Preferred Reporting Items for Systematic Reviews and Meta-Analysis).
Then, we comprehensively review them in terms of their inputs and architectures
to propose a novel taxonomy: (1) input taxonomy includes 5 groups of input type
notations and 7 groups of input representation notations; (2) architecture
taxonomy includes 8 groups of GNN encoder, 2 groups of decoder, and 12 groups
of loss function notations. We classify the GNN-based SocialRS methods into
several categories as per the taxonomy and describe their details. Furthermore,
we summarize the benchmark datasets and metrics widely used to evaluate the
GNN-based SocialRS methods. Finally, we conclude this survey by presenting some
future research directions.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:54:15 GMT""},{""version"":""v2"",""created"":""Mon, 12 Dec 2022 18:30:49 GMT""}]","2022-12-13"
"2212.04482","Gabriele Montefalcone","Gabriele Montefalcone, Vikas Aragam, Luca Visinelli and Katherine
  Freese","Observational Constraints on Warm Natural Inflation","23 pages, 3 figures, 1 table, Replacement due to typo on DOE
  acknowledgement number","JCAP 2303, 002 (2023)","10.1088/1475-7516/2023/03/002",,"gr-qc astro-ph.CO hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Warm natural inflation is studied for the case of the original cosine
potential. The radiation bath during inflation induces a dissipation (friction)
rate in the equation of motion for the inflaton field, which can potentially
reduce the field excursion needed for an observationally viable period of
inflation. We examine if the dissipation thus provides a mechanism to avoid the
large decay constant $f \gtrsim M_{\mathrm{pl}}$ of cold cosine natural
inflation. Whereas temperature independent dissipation has previously been
shown to alleviate the need for a trans-Planckian decay constant $f$, we
illustrate here the difficulties of accommodating a significantly sub-Planckian
decay constant ($f<10^{-1}M_{\mathrm{pl}}$) in the case of the following
temperature dependent dissipation rates, $\Gamma \propto T^c$, with
$c=\{1,3\}$. Such dissipation rates represent physically well-motivated
constructions in the literature. For each model, we map its location in the
$r$-$n_s$ plane and compare with Cosmic Microwave Background data. For $c=1 \,
(c=3)$, we find that agreement with CMB data requires that dissipation be in
the weak (moderate) regime and that the minimum allowed value of the decay
constant in the potential is $f_{\rm min} = 0.3 \, (0.8)\,M_{\mathrm{pl}}$
respectively.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:54:44 GMT""},{""version"":""v2"",""created"":""Wed, 18 Jan 2023 02:56:54 GMT""}]","2023-03-08"
"2212.04483","Tomoki Ichikawa","Tomoki Ichikawa, Yoshiki Fukao, Shohei Nobuhara, Ko Nishino","Fresnel Microfacet BRDF: Unification of Polari-Radiometric Surface-Body
  Reflection",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Computer vision applications have heavily relied on the linear combination of
Lambertian diffuse and microfacet specular reflection models for representing
reflected radiance, which turns out to be physically incompatible and limited
in applicability. In this paper, we derive a novel analytical reflectance
model, which we refer to as Fresnel Microfacet BRDF model, that is physically
accurate and generalizes to various real-world surfaces. Our key idea is to
model the Fresnel reflection and transmission of the surface microgeometry with
a collection of oriented mirror facets, both for body and surface reflections.
We carefully derive the Fresnel reflection and transmission for each microfacet
as well as the light transport between them in the subsurface. This
physically-grounded modeling also allows us to express the polarimetric
behavior of reflected light in addition to its radiometric behavior. That is,
FMBRDF unifies not only body and surface reflections but also light reflection
in radiometry and polarization and represents them in a single model.
Experimental results demonstrate its effectiveness in accuracy, expressive
power, and image-based estimation.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:55:07 GMT""}]","2022-12-09"
"2212.04484","Mohammad Mahdi Mahvari Habibabadi","Mohammad Mahdi Mahvari and Gerhard Kramer","Stability of Bernstein's Theorem and Soft Doubling for Vector Gaussian
  Channels",,,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  The stability of Bernstein's characterization of Gaussian distributions is
extended to vectors. Stability is used to develop a soft doubling argument that
establishes the optimality of Gaussian vectors for certain communications
channels with additive Gaussian noise, including two-receiver broadcast
channels. One novelty is that the argument does not require the existence of
distributions that achieve capacity.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:55:18 GMT""}]","2022-12-09"
"2212.04485","Laila Linke","Laila Linke, Sven Heydenreich, Pierre A. Burger, Peter Schneider","A roadmap to cosmological parameter analysis with third-order shear
  statistics II: Analytic covariance estimate","21 pages + appendix, 16 figures, 1 table; replaced by version
  accepted to Astronomy & Astrophysics after considering Referee comments","A&A 672, A185 (2023)","10.1051/0004-6361/202245652",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Third-order weak lensing statistics are a promising tool for cosmological
analyses since they extract cosmological information in the non-Gaussianity of
the cosmic large-scale structure. However, such analyses require precise and
accurate models for the covariance. In this second paper of a series on
third-order weak lensing statistics, we derive and validate an analytic model
for the covariance of the third-order aperture statistics $\langle
M_\mathrm{ap}^3\rangle$. We derive the covariance model from a real-space
estimator for $\langle M_\mathrm{ap}^3\rangle$. We validate the model by
comparing it to estimates from simulated Gaussian random fields (GRF) and two
sets of N-body simulations. Finally, we perform mock cosmological analyses with
the model covariance and the simulation estimate to compare the resulting
parameter constraints. We find good agreement between the model and the
simulations, both for the GRF and the $N$-body simulations. The figure-of-merit
in the $S_8$-$\Omega_\mathrm{m}$ plane from our covariance model is within 3\%
of the one obtained from the simulated covariances. We also show that our
model, which is based on an estimator using convergence maps, can be used to
obtain upper and lower bounds for the covariance of an estimator based on
three-point shear correlation functions. This second estimator is required for
realistic survey data. In our derivation, we find that the $\langle
M_\mathrm{ap}^3\rangle$ covariance cannot be obtained from the bispectrum
covariance and that it includes several `finite-field terms' that do not scale
with the inverse survey area. Our covariance model is sufficiently accurate for
analysing stage III surveys. Covariances for statistics in Fourier space cannot
always be straightforwardly converted into covariance for real-space
statistics. The modelling code is available at
https://github.com/sheydenreich/threepoint/releases/ .
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:56:32 GMT""},{""version"":""v2"",""created"":""Thu, 16 Feb 2023 19:11:52 GMT""}]","2023-04-26"
"2212.04486","Ashwinee Panda","Ashwinee Panda, Xinyu Tang, Vikash Sehwag, Saeed Mahloujifar, Prateek
  Mittal","DP-RAFT: A Differentially Private Recipe for Accelerated Fine-Tuning",,,,,"cs.LG cs.AI cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A major direction in differentially private machine learning is
differentially private fine-tuning: pretraining a model on a source of ""public
data"" and transferring the extracted features to downstream tasks.
  This is an important setting because many industry deployments fine-tune
publicly available feature extractors on proprietary data for downstream tasks.
  In this paper, we carefully integrate techniques, both new and from prior
work, to solve benchmark tasks in computer vision and natural language
processing using differentially private fine-tuning. Our key insight is that by
accelerating training with the choice of key hyperparameters, we can quickly
drive the model parameters to regions in parameter space where the impact of
noise is minimized. We obtain new state-of-the art performance on CIFAR10,
CIFAR100, FashionMNIST, STL10, and PersonaChat, including $99 \%$ on CIFAR10
for $\varepsilon=1, \delta=1e-5$-DP.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:56:37 GMT""},{""version"":""v2"",""created"":""Thu, 15 Dec 2022 18:57:30 GMT""}]","2022-12-16"
"2212.04488","Nupur Kumari","Nupur Kumari, Bingliang Zhang, Richard Zhang, Eli Shechtman, Jun-Yan
  Zhu","Multi-Concept Customization of Text-to-Image Diffusion","Project webpage: https://www.cs.cmu.edu/~custom-diffusion",,,,"cs.CV cs.GR cs.LG","http://creativecommons.org/licenses/by/4.0/","  While generative models produce high-quality images of concepts learned from
a large-scale database, a user often wishes to synthesize instantiations of
their own concepts (for example, their family, pets, or items). Can we teach a
model to quickly acquire a new concept, given a few examples? Furthermore, can
we compose multiple new concepts together? We propose Custom Diffusion, an
efficient method for augmenting existing text-to-image models. We find that
only optimizing a few parameters in the text-to-image conditioning mechanism is
sufficiently powerful to represent new concepts while enabling fast tuning (~6
minutes). Additionally, we can jointly train for multiple concepts or combine
multiple fine-tuned models into one via closed-form constrained optimization.
Our fine-tuned model generates variations of multiple, new concepts and
seamlessly composes them with existing concepts in novel settings. Our method
outperforms several baselines and concurrent works, regarding both qualitative
and quantitative evaluations, while being memory and computationally efficient.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:57:02 GMT""}]","2022-12-09"
"2212.04489","Zhixing Zhang","Zhixing Zhang, Ligong Han, Arnab Ghosh, Dimitris Metaxas, Jian Ren","SINE: SINgle Image Editing with Text-to-Image Diffusion Models","Project website: https://zhang-zx.github.io/SINE/",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent works on diffusion models have demonstrated a strong capability for
conditioning image generation, e.g., text-guided image synthesis. Such success
inspires many efforts trying to use large-scale pre-trained diffusion models
for tackling a challenging problem--real image editing. Works conducted in this
area learn a unique textual token corresponding to several images containing
the same object. However, under many circumstances, only one image is
available, such as the painting of the Girl with a Pearl Earring. Using
existing works on fine-tuning the pre-trained diffusion models with a single
image causes severe overfitting issues. The information leakage from the
pre-trained diffusion models makes editing can not keep the same content as the
given image while creating new features depicted by the language guidance. This
work aims to address the problem of single-image editing. We propose a novel
model-based guidance built upon the classifier-free guidance so that the
knowledge from the model trained on a single image can be distilled into the
pre-trained diffusion model, enabling content creation even with one given
image. Additionally, we propose a patch-based fine-tuning that can effectively
help the model generate images of arbitrary resolution. We provide extensive
experiments to validate the design choices of our approach and show promising
editing capabilities, including changing style, content addition, and object
manipulation. The code is available for research purposes at
https://github.com/zhang-zx/SINE.git .
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:57:13 GMT""}]","2022-12-09"
"2212.04490","Jesse Stryker","Saurabh V. Kadam, Indrakshi Raychowdhury, and Jesse R. Stryker","Loop-string-hadron formulation of an SU(3) gauge theory with dynamical
  quarks","35 pages plus references, 5 figures. v2 includes typo corrections,
  trivial adjustments to text sectioning, and added references","Phys. Rev. D 107, 094513 (2023)","10.1103/PhysRevD.107.094513","UMD-PP-022-11","hep-lat hep-th quant-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Towards the goal of quantum computing for lattice quantum chromodynamics, we
present a loop-string-hadron (LSH) framework in 1+1 dimensions for describing
the dynamics of SU(3) gauge fields coupled to staggered fermions. This novel
framework was previously developed for an SU(2) lattice gauge theory in
$d\leq3$ spatial dimensions and its advantages for classical and quantum
algorithms have thus far been demonstrated in $d=1$. The LSH approach uses
gauge invariant degrees of freedoms such as loop segments, string ends, and
on-site hadrons, it is free of all nonabelian gauge redundancy, and it is
described by a Hamiltonian containing only local interactions. In this work,
the SU(3) LSH framework is systematically derived from the reformulation of
Hamiltonian lattice gauge theory in terms of irreducible Schwinger bosons,
including the addition of staggered quarks. Furthermore, the superselection
rules governing the LSH dynamics are identified directly from the form of the
Hamiltonian. The SU(3) LSH Hamiltonian with open boundary conditions has been
numerically confirmed to agree with the completely gauge-fixed Hamiltonian,
which contains long-range interactions and does not generalize to either
periodic boundary conditions or to $d>1$.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:57:47 GMT""},{""version"":""v2"",""created"":""Thu, 9 Feb 2023 18:26:51 GMT""}]","2023-05-31"
"2212.04492","Hanwen Jiang","Hanwen Jiang, Zhenyu Jiang, Kristen Grauman and Yuke Zhu","Few-View Object Reconstruction with Unknown Categories and Camera Poses",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While object reconstruction has made great strides in recent years, current
methods typically require densely captured images and/or known camera poses,
and generalize poorly to novel object categories. To step toward object
reconstruction in the wild, this work explores reconstructing general
real-world objects from a few images without known camera poses or object
categories. The crux of our work is solving two fundamental 3D vision problems
-- shape reconstruction and pose estimation -- in a unified approach. Our
approach captures the synergies of these two problems: reliable camera pose
estimation gives rise to accurate shape reconstruction, and the accurate
reconstruction, in turn, induces robust correspondence between different views
and facilitates pose estimation. Our method FORGE predicts 3D features from
each view and leverages them in conjunction with the input images to establish
cross-view correspondence for estimating relative camera poses. The 3D features
are then transformed by the estimated poses into a shared space and are fused
into a neural radiance field. The reconstruction results are rendered by volume
rendering techniques, enabling us to train the model without 3D shape
ground-truth. Our experiments show that FORGE reliably reconstructs objects
from five views. Our pose estimation method outperforms existing ones by a
large margin. The reconstruction results under predicted poses are comparable
to the ones using ground-truth poses. The performance on novel testing
categories matches the results on categories seen during training. Project
page: https://ut-austin-rpl.github.io/FORGE/
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:59:02 GMT""}]","2022-12-09"
"2212.04493","Yen-Chi Cheng","Yen-Chi Cheng, Hsin-Ying Lee, Sergey Tulyakov, Alexander Schwing and
  Liangyan Gui","SDFusion: Multimodal 3D Shape Completion, Reconstruction, and Generation","In CVPR 2023. Project page and code is available at:
  https://yccyenchicheng.github.io/SDFusion/. Fix some typos",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  In this work, we present a novel framework built to simplify 3D asset
generation for amateur users. To enable interactive generation, our method
supports a variety of input modalities that can be easily provided by a human,
including images, text, partially observed shapes and combinations of these,
further allowing to adjust the strength of each input. At the core of our
approach is an encoder-decoder, compressing 3D shapes into a compact latent
representation, upon which a diffusion model is learned. To enable a variety of
multi-modal inputs, we employ task-specific encoders with dropout followed by a
cross-attention mechanism. Due to its flexibility, our model naturally supports
a variety of tasks, outperforming prior works on shape completion, image-based
3D reconstruction, and text-to-3D. Most interestingly, our model can combine
all these tasks into one swiss-army-knife tool, enabling the user to perform
shape generation using incomplete shapes, images, and textual descriptions at
the same time, providing the relative weights for each input and facilitating
interactivity. Despite our approach being shape-only, we further show an
efficient method to texture the generated shape using large-scale text-to-image
models.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:59:05 GMT""},{""version"":""v2"",""created"":""Wed, 22 Mar 2023 00:30:56 GMT""}]","2023-03-23"
"2212.04494","Nanoom Lee","Nanoom Lee, Yacine Ali-Ha\""imoud, Nils Sch\""oneberg, Vivian Poulin","What it takes to solve the Hubble tension through modifications of
  cosmological recombination","5+13 pages, 2+12 figures, version accepted for publication in PRL",,"10.1103/PhysRevLett.130.161003",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct data-driven solutions to the Hubble tension which are
perturbative modifications to the fiducial $\Lambda$CDM cosmology, using the
Fisher bias formalism. Taking as proof of principle the case of a time-varying
electron mass and fine structure constant, and focusing first on Planck CMB
data, we demonstrate that a modified recombination can solve the Hubble tension
and lower $S_8$ to match weak lensing measurements. Once baryonic acoustic
oscillation and uncalibrated supernovae data are included, however, it is not
possible to fully solve the tension with perturbative modifications to
recombination.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:59:31 GMT""},{""version"":""v2"",""created"":""Tue, 25 Apr 2023 17:14:44 GMT""}]","2023-04-26"
"2212.04495","Rishabh Dabral","Rishabh Dabral and Muhammad Hamza Mughal and Vladislav Golyanik and
  Christian Theobalt","MoFusion: A Framework for Denoising-Diffusion-based Motion Synthesis","CVPR23, 11 pages, 6 figures, 2 tables; project page:
  https://vcai.mpi-inf.mpg.de/projects/MoFusion",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conventional methods for human motion synthesis are either deterministic or
struggle with the trade-off between motion diversity and motion quality. In
response to these limitations, we introduce MoFusion, i.e., a new
denoising-diffusion-based framework for high-quality conditional human motion
synthesis that can generate long, temporally plausible, and semantically
accurate motions based on a range of conditioning contexts (such as music and
text). We also present ways to introduce well-known kinematic losses for motion
plausibility within the motion diffusion framework through our scheduled
weighting strategy. The learned latent space can be used for several
interactive motion editing applications -- like inbetweening, seed
conditioning, and text-based editing -- thus, providing crucial abilities for
virtual character animation and robotics. Through comprehensive quantitative
evaluations and a perceptual user study, we demonstrate the effectiveness of
MoFusion compared to the state of the art on established benchmarks in the
literature. We urge the reader to watch our supplementary video and visit
https://vcai.mpi-inf.mpg.de/projects/MoFusion.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:59:48 GMT""},{""version"":""v2"",""created"":""Mon, 15 May 2023 11:36:57 GMT""}]","2023-05-16"
"2212.04496","Laurin  E. Fischer","Laurin E. Fischer, Alessandro Chiesa, Francesco Tacchino, Daniel J.
  Egger, Stefano Carretta, Ivano Tavernelli","Towards universal gate synthesis and error correction in transmon qudits","9+7 pages, 7+3 figures",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gate-based quantum computers typically encode and process information in
two-dimensional units called qubits. Using $d$-dimensional qudits instead may
offer intrinsic advantages, including more efficient circuit synthesis,
problem-tailored encodings and embedded error correction. In this work, we
design a superconducting qudit-based quantum processor wherein the logical
space of transmon qubits is extended to higher-excited levels. We propose a
universal gate set featuring a two-qudit cross-resonance entangling gate, for
which we predict fidelities beyond $99\%$ in the $d=4$ case of ququarts with
realistic experimental parameters. Furthermore, we present a decomposition
routine that compiles general qudit unitaries into these elementary gates. As a
proof-of-concept application, we numerically demonstrate that an embedded error
correction sequence that encodes a qubit memory in a transmon ququart can
successfully protect against pure dephasing noise. We conclude that universal
qudit control -- a valuable extension to the operational toolbox of
superconducting quantum information processing -- is within reach of current
transmon-based architectures.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:59:53 GMT""}]","2022-12-09"
"2212.04497","Abdelrahman Shaker","Abdelrahman Shaker, Muhammad Maaz, Hanoona Rasheed, Salman Khan,
  Ming-Hsuan Yang, Fahad Shahbaz Khan","UNETR++: Delving into Efficient and Accurate 3D Medical Image
  Segmentation","Technical report",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Owing to the success of transformer models, recent works study their
applicability in 3D medical segmentation tasks. Within the transformer models,
the self-attention mechanism is one of the main building blocks that strives to
capture long-range dependencies. However, the self-attention operation has
quadratic complexity which proves to be a computational bottleneck, especially
in volumetric medical imaging, where the inputs are 3D with numerous slices. In
this paper, we propose a 3D medical image segmentation approach, named UNETR++,
that offers both high-quality segmentation masks as well as efficiency in terms
of parameters, compute cost, and inference speed. The core of our design is the
introduction of a novel efficient paired attention (EPA) block that efficiently
learns spatial and channel-wise discriminative features using a pair of
inter-dependent branches based on spatial and channel attention. Our spatial
attention formulation is efficient having linear complexity with respect to the
input sequence length. To enable communication between spatial and
channel-focused branches, we share the weights of query and key mapping
functions that provide a complimentary benefit (paired attention), while also
reducing the overall network parameters. Our extensive evaluations on five
benchmarks, Synapse, BTCV, ACDC, BRaTs, and Decathlon-Lung, reveal the
effectiveness of our contributions in terms of both efficiency and accuracy. On
Synapse, our UNETR++ sets a new state-of-the-art with a Dice Score of 87.2%,
while being significantly efficient with a reduction of over 71% in terms of
both parameters and FLOPs, compared to the best method in the literature. Code:
https://github.com/Amshaker/unetr_plus_plus.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:59:57 GMT""},{""version"":""v2"",""created"":""Wed, 22 Mar 2023 20:30:10 GMT""}]","2023-03-24"
"2212.04498","Deepak Pathak","Kenneth Shaw, Shikhar Bahl, Deepak Pathak","VideoDex: Learning Dexterity from Internet Videos","Accepted at CoRL 2022. Website at https://video-dex.github.io",,,,"cs.RO cs.AI cs.CV cs.LG cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To build general robotic agents that can operate in many environments, it is
often imperative for the robot to collect experience in the real world.
However, this is often not feasible due to safety, time, and hardware
restrictions. We thus propose leveraging the next best thing as real-world
experience: internet videos of humans using their hands. Visual priors, such as
visual features, are often learned from videos, but we believe that more
information from videos can be utilized as a stronger prior. We build a
learning algorithm, VideoDex, that leverages visual, action, and physical
priors from human video datasets to guide robot behavior. These actions and
physical priors in the neural network dictate the typical human behavior for a
particular robot task. We test our approach on a robot arm and dexterous
hand-based system and show strong results on various manipulation tasks,
outperforming various state-of-the-art methods. Videos at
https://video-dex.github.io
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:59:59 GMT""}]","2022-12-09"
"2212.04499","Yichul Choi","Yichul Choi, Ho Tat Lam, Shu-Heng Shao","Non-invertible Gauss Law and Axions","57 pages; v2: sec 7.3 added",,,"MIT-CTP/5504, YITP-SB-2022-39","hep-th cond-mat.str-el hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In axion-Maxwell theory at the minimal axion-photon coupling, we find
non-invertible 0- and 1-form global symmetries arising from the naive shift and
center symmetries. Since the Gauss law is anomalous, there is no conserved,
gauge-invariant, and quantized electric charge. Rather, using half higher
gauging, we find a non-invertible Gauss law associated with a non-invertible
1-form global symmetry, which is related to the Page charge. These symmetries
act invertibly on the axion field and Wilson line, but non-invertibly on the
monopoles and axion strings, leading to selection rules related to the Witten
effect. We also derive various crossing relations between the defects. The
non-invertible 0- and 1-form global symmetries mix with other invertible
symmetries in a way reminiscent of a higher-group symmetry. Using this
non-invertible higher symmetry structure, we derive universal inequalities on
the energy scales where different infrared symmetries emerge in any
renormalization group flow to the axion-Maxwell theory. Finally, we discuss
implications for the Weak Gravity Conjecture and the Completeness Hypothesis in
quantum gravity.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:59:59 GMT""},{""version"":""v2"",""created"":""Tue, 3 Jan 2023 03:11:38 GMT""}]","2023-01-04"
"2212.04500","Dongdong Chen","Rui Wang and Dongdong Chen and Zuxuan Wu and Yinpeng Chen and Xiyang
  Dai and Mengchen Liu and Lu Yuan and Yu-Gang Jiang","Masked Video Distillation: Rethinking Masked Feature Modeling for
  Self-supervised Video Representation Learning","CVPR 2023, code will be available at
  https://github.com/ruiwang2021/mvd",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Benefiting from masked visual modeling, self-supervised video representation
learning has achieved remarkable progress. However, existing methods focus on
learning representations from scratch through reconstructing low-level features
like raw pixel RGB values. In this paper, we propose masked video distillation
(MVD), a simple yet effective two-stage masked feature modeling framework for
video representation learning: firstly we pretrain an image (or video) model by
recovering low-level features of masked patches, then we use the resulting
features as targets for masked feature modeling. For the choice of teacher
models, we observe that students taught by video teachers perform better on
temporally-heavy video tasks, while image teachers transfer stronger spatial
representations for spatially-heavy video tasks. Visualization analysis also
indicates different teachers produce different learned patterns for students.
Motivated by this observation, we design a spatial-temporal co-teaching method
for MVD. Specifically, we distill student models from both video teachers and
image teachers by masked feature modeling. Extensive experimental results
demonstrate that video transformers pretrained with spatial-temporal
co-teaching outperform models distilled with a single teacher on a multitude of
video datasets. Our MVD with vanilla ViT achieves state-of-the-art performance
compared with previous supervised or self-supervised methods on several
challenging video downstream tasks. For example, with the ViT-Large model, our
MVD achieves 86.4% and 76.7% Top-1 accuracy on Kinetics-400 and
Something-Something-v2, outperforming VideoMAE by 1.2% and 2.4% respectively.
When a larger ViT-Huge model is adopted, MVD achieves the state-of-the-art
performance with 77.3% Top-1 accuracy on Something-Something-v2 and 41.1 mAP on
AVA v2.2. Code will be available at \url{https://github.com/ruiwang2021/mvd}.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:59:59 GMT""},{""version"":""v2"",""created"":""Mon, 6 Mar 2023 19:44:59 GMT""}]","2023-03-08"
"2212.04501","Yue Zhao","Yue Zhao, Ishan Misra, Philipp Kr\""ahenb\""uhl, Rohit Girdhar","Learning Video Representations from Large Language Models","Tech report. Project page: https://facebookresearch.github.io/LaViLa;
  Code is available at http://github.com/facebookresearch/LaViLa",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce LaViLa, a new approach to learning video-language
representations by leveraging Large Language Models (LLMs). We repurpose
pre-trained LLMs to be conditioned on visual input, and finetune them to create
automatic video narrators. Our auto-generated narrations offer a number of
advantages, including dense coverage of long videos, better temporal
synchronization of the visual information and text, and much higher diversity
of text. The video-text embedding learned contrastively with these additional
auto-generated narrations outperforms the previous state-of-the-art on multiple
first-person and third-person video tasks, both in zero-shot and finetuned
setups. Most notably, LaViLa obtains an absolute gain of 10.1% on EGTEA
classification and 5.9% Epic-Kitchens-100 multi-instance retrieval benchmarks.
Furthermore, LaViLa trained with only half the narrations from the Ego4D
dataset outperforms baseline models trained on the full set, and shows positive
scaling behavior on increasing pre-training data and model size.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:59:59 GMT""}]","2022-12-09"
"2212.04503","Thorsten Schimannek","Markus Dierigl, Paul-Konstantin Oehlmann, Thorsten Schimannek","The discrete Green-Schwarz mechanism in 6D F-Theory and Elliptic Genera
  of Non-Critical Strings","35+16 pages, 21 figures",,"10.1007/JHEP03(2023)090","LMU-ASC 33/22","hep-th math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study global anomalies of discrete gauge symmetries in six-dimensional
supergravities and their realizations in F-theory. We explicitly construct a
discrete Green-Schwarz mechanism that depends on the choice of a coupling
constant and on a certain quadratic refinement in differential cohomology. By
geometrically engineering theories with $G=\mathbb{Z}_3$ gauge symmetry and no
tensor multiplets, we observe that a particular choice of the quadratic
refinement is singled out in F-theory. This implies new Swampland constraints
on the discrete charge spectra of 6d supergravities. On the other hand, the
discrete Green-Schwarz coupling depends on the geometry of the Calabi-Yau. We
use anomaly inflow to relate this to a 't Hooft anomaly of the induced global
symmetry in the worldsheet theories of non-critical strings. Using topological
symmetry lines, we further relate this anomaly to the modular properties of
twisted-twined elliptic genera. We then argue that the latter are encoded in
the A-model topological string partition functions on different torus
fibrations that are equipped with a flat torsional B-field. This allows us to
derive a geometric expression for the global discrete anomaly in terms of the
height-pairing of a multi-section on a genus one fibered Calabi-Yau.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:00:00 GMT""}]","2023-04-05"
"2212.04504","Daniel Egana-Ugrinovic","Peizhi Du, Daniel Ega\~na-Ugrinovic, Rouven Essig, Mukul Sholapurkar","Doped Semiconductor Devices for sub-MeV Dark Matter Detection","12 pages, 7 figures",,,,"hep-ph astro-ph.CO hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dopant atoms in semiconductors can be ionized with $\sim10$ meV energy
depositions, allowing for the design of low-threshold detectors. We propose
using doped semiconductor targets to search for sub-MeV dark matter scattering
or sub-eV dark matter absorption on electrons. Currently unconstrained cross
sections could be tested with a 1 g-day exposure in a doped detector with
backgrounds at the level of existing pure semiconductor detectors, but
improvements would be needed to probe the freeze-in target. We discuss the
corresponding technological requirements and lay out a possible detector
design.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:00:00 GMT""}]","2022-12-12"
"2212.04505","Yonatan Kahn","Christian Boyd, Yonit Hochberg, Yonatan Kahn, Eric David Kramer, Noah
  Kurinsky, Benjamin V. Lehmann, To Chin Yu","Directional detection of dark matter with anisotropic response functions","v1: 20 pages, 9 figures",,,,"hep-ph cond-mat.str-el hep-ex physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Direct detection for sub-GeV dark matter is developing rapidly, with many
novel experimental ideas and theoretical methods emerging. In this work, we
extend the dielectric formalism for dark matter scattering to incorporate
anisotropic material responses, enabling directionally-sensitive experiments
with a broad class of target materials. Using a simple model of an anisotropic
electron gas, we demonstrate the importance of many-body effects such as the
plasmon, and show that even when the dark matter kinetic energies are much
smaller than the plasmon energy, the tail of an anisotropic plasmon can still
produce a sizeable daily modulation. We highlight the relevant experimental
techniques required to establish the target response, as well as the challenges
in extracting a response function which is truly free of modeling
uncertainties.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:00:00 GMT""}]","2022-12-12"
"2212.04506","Pierre Heidmann","Iosif Bena and Pierre Heidmann","The Uplifton","5 pages, 1 figure",,,,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Almost all proposals to construct de Sitter vacua with a small cosmological
constant involve flux compactifications with stabilized moduli. These give AdS
vacua, which are uplifted to de Sitter by adding antibranes in certain regions
of the compactification manifold. However, antibranes are charged, singular and
interact nontrivially with other ingredients of the compactification; this can
invalidate the de Sitter construction. In this Letter, we construct a new
ingredient for uplifting AdS solutions to de Sitter, which is neutral, smooth
and horizonless, and therefore bypasses some of the problems of antibrane
uplift.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:00:00 GMT""}]","2022-12-12"
"2212.04507","Shinya Wanajo","Shinya Wanajo, Sho Fujibayashi, Kota Hayashi, Kenta Kiuchi, Yuichiro
  Sekiguchi, Masaru Shibata","Actinide-boosting r Process in Black Hole-Neutron Star Merger Ejecta","5 pages, 4 figures",,,,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We examine nucleosynthesis in the ejecta of black hole-neutron star mergers
based on the results of self-consistent, long-term
neutrino-radiation-magnetohydrodynamics simulations for the first time. We find
that the combination of dynamical and post-merger ejecta reproduces a
solar-like r-process pattern. Moreover, the enhancement level of actinides is
highly sensitive to the distribution of both electron fraction and the velocity
of the dynamical ejecta. Our result implies that the mean electron fraction of
dynamical ejecta should be ~ 0.05-0.08 in order to reconcile the
nucleosynthetic abundances with those in r-process-enhanced, actinide-boosted
stars. This result provides an important constraint for nuclear equations of
state.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:00:01 GMT""}]","2022-12-12"
"2212.04508","Nils Quetschlich","Nils Quetschlich, Lukas Burgholzer, Robert Wille","Compiler Optimization for Quantum Computing Using Reinforcement Learning","6 pages, 3 figures, minor changes, to be published at Design
  Automation Conference (DAC), 2023",,,,"quant-ph cs.ET cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Any quantum computing application, once encoded as a quantum circuit, must be
compiled before being executable on a quantum computer. Similar to classical
compilation, quantum compilation is a sequential process with many compilation
steps and numerous possible optimization passes. Despite the similarities, the
development of compilers for quantum computing is still in its infancy --
lacking mutual consolidation on the best sequence of passes, compatibility,
adaptability, and flexibility. In this work, we take advantage of decades of
classical compiler optimization and propose a reinforcement learning framework
for developing optimized quantum circuit compilation flows. Through distinct
constraints and a unifying interface, the framework supports the combination of
techniques from different compilers and optimization tools in a single
compilation flow. Experimental evaluations show that the proposed framework --
set up with a selection of compilation passes from IBM's Qiskit and
Quantinuum's TKET -- significantly outperforms both individual compilers in 73%
of cases regarding the expected fidelity. The framework is available on GitHub
(https://github.com/cda-tum/MQTPredictor) as part of the Munich Quantum Toolkit
(MQT).
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:00:01 GMT""},{""version"":""v2"",""created"":""Tue, 4 Apr 2023 09:28:14 GMT""}]","2023-04-05"
"2212.04509","Jacob Simon","Jacob B. Simon, J\""urgen Blum, Til Birnstiel, David Nesvorn\'y","Comets and Planetesimal Formation","Planetesimal Formation Review accepted for publication in Comets III",,,,"astro-ph.EP astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  In this chapter, we review the processes involved in the formation of
planetesimals and comets. We will start with a description of the physics of
dust grain growth and how this is mediated by gas-dust interactions in
planet-forming disks. We will then delve into the various models of
planetesimal formation, describing how these planetesimals form as well as
their resulting structure. In doing so, we focus on and compare two paradigms
for planetesimal formation: the gravitational collapse of particle
over-densities (which can be produced by a variety of mechanisms) and the
growth of particles into planetesimals via collisional and gravitational
coagulation. Finally, we compare the predictions from these models with data
collected by the Rosetta and New Horizons missions and that obtained via
observations of distant Kuiper Belt Objects.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:00:01 GMT""}]","2022-12-12"
"2212.04510","Felix Wilsch","Javier Fuentes-Mart\'in, Matthias K\""onig, Julie Pag\`es, Anders Eller
  Thomsen, Felix Wilsch","A Proof of Concept for Matchete: An Automated Tool for Matching
  Effective Theories","27 pages, 2 figures, The code and example notebooks are publicly
  available at https://gitlab.com/matchete/matchete",,,"MITP-22-105, TUM-HEP-1443/22, ZU-TH-58/22","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Studying the impact of new-physics models on low-energy observables
necessitates matching to effective field theories at the relevant mass
thresholds. We introduce the first public version of Matchete, a computer tool
for matching weakly-coupled models at one-loop order. It uses functional
methods to directly compute all matching contributions in a manifestly
gauge-covariant manner, while simplification methods eliminate redundant
operators from the output. We sketch the workings of the program and provide
examples of how to match simple Standard Model extensions. The package,
documentation, and example notebooks are publicly available at
https://gitlab.com/matchete/matchete.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:00:01 GMT""}]","2022-12-12"
"2212.04511","Sophie van Mierlo","Sophie E. van Mierlo, Karina I. Caputi, Vasily Kokorev","No Need for Extreme Stellar Masses at z~7: A Test-case Study of
  COS-87259","9 pages, including 2 tables and 2 figures. Published in ApJL",,"10.3847/2041-8213/acb773",,"astro-ph.GA astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  Recent controversy regarding the existence of massive (log(M/Msun)>11)
galaxies at z>6 poses a challenge for galaxy formation theories. Hence, it is
of critical importance to understand the effects of SED fitting methods on
stellar mass estimates of Epoch of Reionization galaxies. In this work, we
perform a case study on the AGN host galaxy candidate COS-87259 with
spectroscopic redshift z=6.853, that is claimed to have an extremely high
stellar mass of log(M/Msun)~11.2. We test a suite of different SED fitting
algorithms and stellar population models on our independently measured
photometry in 17 broad bands for this source. Between five different code
setups, the stellar mass estimates for COS-87259 span log(M/Msun)=10.24-11.00,
whilst the reduced chi-squared values of the fits are all close to unity within
dchi2=1.2, so that the quality of the SED fits is basically indistinguishable.
Only when we adopt a nonparametric star formation history model within
Prospector do we retrieve a stellar mass exceeding log(M/Msun)=11. Although the
derived stellar masses change when using previously reported photometry for
this source, the nonparametric SED-fitting method always yields the highest
values. As these models are becoming increasingly popular for James Webb Space
Telescope high-redshift science, we stress the absolute importance of testing
various SED fitting routines particularly on apparently very massive galaxies
at such high redshifts.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:00:02 GMT""},{""version"":""v2"",""created"":""Wed, 1 Feb 2023 14:58:05 GMT""},{""version"":""v3"",""created"":""Tue, 7 Feb 2023 08:34:28 GMT""},{""version"":""v4"",""created"":""Fri, 10 Mar 2023 11:46:27 GMT""}]","2023-03-15"
"2212.04512","Gonzalo Torroba","Gonzalo Torroba","$T\bar T + \Lambda_2$ from a 2d gravity path integral","34 pages, 1 figure",,"10.1007/JHEP01(2023)163",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a two-dimensional gravity path integral formulation of the $T \bar
T + \Lambda_2$ deformation of quantum field theory. This provides an exactly
solvable generalization of the pure $T \bar T$ deformation that is relevant for
de Sitter and flat space holography. The path integral sheds light on quantum
aspects of these flows in curved space, most notably the Weyl anomaly, the
operator relation for the trace of the energy-momentum tensor, and the
renormalization of the composite $T \bar T$ operator. It also applies to both
the Hagedorn and the holographic signs of such flows. We present explicit
calculations for the torus and sphere partition functions that reproduce
previous results in the literature, now in path integral language. Finally, we
use the path integral representation in order to establish an explicit map with
3d gravity, and obtain new predictions for flat space holography.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:00:03 GMT""}]","2023-02-15"
"2212.04513","Felipe Diaz-Jaramillo","Roberto Bonezzi, Christoph Chiaffrino, Felipe Diaz-Jaramillo and Olaf
  Hohm","Gauge invariant double copy of Yang-Mills theory: the quartic theory","30 pages plus appendix and references",,,,"hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give an explicit gauge invariant, off-shell and local double copy
construction of gravity from Yang-Mills theory to quartic order. To this end we
use the framework of homotopy algebras, and we identify a rich new algebraic
structure associated to color-stripped Yang-Mills theory. This algebra, which
is a generalization of a Batalin-Vilkovisky algebra, is the underlying
structure necessary for double copy. We give a self-contained introduction into
these algebras by illustrating them for Chern-Simons theory in three
dimensions. We then construct N = 0 supergravity in the form of double field
theory in terms of the algebraic Yang-Mills building blocks to quartic order in
interactions. As applications of the same universal formula, we re-derive the
4-graviton scattering amplitude and compute a chiral form of the Courant
algebroid gauge structure of double field theory.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:00:03 GMT""}]","2022-12-12"
"2212.04514","Nayantara Mudur","Nayantara Mudur, Core Francisco Park, Douglas P Finkbeiner","Stellar Reddening Based Extinction Maps for Cosmological Applications","21 pages, 10 figures",,"10.3847/1538-4357/acc32c",,"astro-ph.GA astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Cosmological surveys must correct their observations for the reddening of
extragalactic objects by Galactic dust. Existing dust maps, however, have been
found to have spatial correlations with the large-scale structure of the
Universe. Errors in extinction maps can propagate systematic biases into
samples of dereddened extragalactic objects and into cosmological measurements
such as correlation functions between foreground lenses and background objects
and the primordial non-gaussianity parameter $f_{NL}$. Emission-based maps are
contaminated by the cosmic infrared background, while maps inferred from
stellar-reddenings suffer from imperfect removal of quasars and galaxies from
stellar catalogs. Thus, stellar-reddening based maps using catalogs without
extragalactic objects offer a promising path to making dust maps with minimal
correlations with large-scale structure. We present two high-latitude
integrated extinction maps based on stellar reddenings, with a point spread
function of full-width half-maximum 6.1' and 15'. We employ a strict selection
of catalog objects to filter out galaxies and quasars and measure the spatial
correlation of our extinction maps with extragalactic structure. Our galactic
extinction maps have reduced spatial correlation with large scale structure
relative to most existing stellar-reddening based and emission-based extinction
maps.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:00:03 GMT""}]","2023-05-31"
"2212.04515","Yuxi Lu","Yuxi (Lucy) Lu, Ivan Minchev, Tobias Buck, Sergey Khoperskov, Matthias
  Steinmetz, Noam Libeskind, Gabriele Cescutti, Ken C. Freeman","There is No Place Like Home -- Finding Birth Radii of Stars in the Milky
  Way","Under review at Nature Letters, submitted Oct. 19, 2022",,,,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Stars move away from their birth places over time via a process known as
radial migration, which blurs chemo-kinematic relations used for reconstructing
the Milky Way formation history. One of the ultimate goals of Galactic
Archaeology, therefore, is to find stars' birth aggregates in the disk via
chemical tagging. Here we show that stellar birth radii can be derived directly
from the data with minimum prior assumptions on the Galactic enrichment
history. We recover the time evolution of the stellar birth metallicity
gradient, $d$[Fe/H]($R$, $\tau$)/$dR$, through its inverse relation to the
metallicity range as a function of age today, allowing us to place any star
with age and metallicity measurements back to its birthplace, $R_b$. Applying
our method to a high-precision large data set of Milky Way disk subgiant stars,
we find a steepening of the birth metallicity gradient from 11 to 8 Gyr ago,
which coincides with the time of the last major merger, Gaia-Sausage-Enceladus
(GSE). This transition appears to play a major role in shaping both the
age-metallicity relation and the bimodality in the [$\alpha$/Fe]-[Fe/H] plane.
By dissecting the disk into mono-$R_b$ populations, clumps in the
low-[$\alpha$/Fe] sequence appear, which are not seen in the total sample and
coincide in time with known star-formation bursts. We estimated that the Sun
was born at $4.5 \pm 0.4$ kpc from the Galactic center. Our $R_b$ estimates
provide the missing piece needed to recover the Milky Way formation history,
while the by-product,[Fe/H]$(R$, $\tau)$, can be used as the thus-far missing
prior for chemical evolution modeling.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:00:03 GMT""}]","2022-12-12"
"2212.04516","Debasish Borah","Debasish Borah, Suruj Jyoti Das, Nobuchika Okada","Affleck-Dine Cogenesis of Baryon and Dark Matter","Version 3: 18 pages, 3 captioned figures, matches version accepted
  for publication in JHEP",,"10.1007/JHEP05(2023)004",,"hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a mechanism for cogenesis of baryon and dark matter (DM) in the
universe via the Affleck-Dine (AD) route. An AD field which breaks the lepton
number symmetry, leads to the generation of lepton asymmetry by virtue of its
cosmic evolution, which then gets transferred into lepton and dark sectors.
While the lepton asymmetry gets converted into baryon asymmetry via sphalerons,
the dark sector asymmetry leads to the final DM abundance with the symmetric
part being annihilated away due to resonantly enhanced annihilation, which we
choose to be provided by a gauged $B-L$ portal. Stringent constraints from DM
direct detection forces DM and $B-L$ gauge boson masses to be light, in the few
GeV ballpark. While a large portion of the model parameter space is already
ruled out, the remaining parameter space is within sensitivity of laboratory as
well as cosmology based experiments. The AD field also plays the role of
inflaton with the required dynamics by virtue of its non-minimal coupling to
gravity, consistent with observations.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:00:06 GMT""},{""version"":""v2"",""created"":""Wed, 4 Jan 2023 14:58:57 GMT""},{""version"":""v3"",""created"":""Thu, 20 Apr 2023 03:59:33 GMT""}]","2023-05-24"
"2212.04517","Ludwig Horer","David Andriot, Ludwig Horer, George Tringas","Negative scalar potentials and the swampland: an Anti-Trans-Planckian
  Censorship Conjecture","51 pages; v3: minor modifications and additions",,"10.1007/JHEP04(2023)139",,"hep-th gr-qc hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we derive a characterisation of negative scalar potentials,
$V<0$, in $d$-dimensional effective theories of quantum gravity. This is
achieved thanks to an Anti-Trans-Planckian Censorship Conjecture (ATCC),
inspired by a refined version of the TCC. The ATCC relies on the fact that in a
contracting universe, modes that become sub-Planckian in length violate the
validity of the effective theory. In the asymptotics of field space, we deduce
that $-V'/V \geq c_0$ when $V' \geq 0$. The rate $c_0 = 2/\sqrt{(d-1)(d-2)}$ is
successfully tested in several string compactifications for $d\geq 4$. In
addition, a new asymptotic condition, $V''/V \geq c_0^2$, is derived. By
extrapolation to anti-de Sitter solutions of radius $l$, we infer the existence
of a scalar whose mass should obey $m^2 l^2 \lesssim -2$. This property is
verified in many supersymmetric examples.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:00:07 GMT""},{""version"":""v2"",""created"":""Thu, 15 Dec 2022 18:08:27 GMT""},{""version"":""v3"",""created"":""Thu, 27 Apr 2023 10:02:46 GMT""}]","2023-05-17"
"2212.04518","Bogumi{\l} Pilecki","Bogumi{\l} Pilecki, Ian B. Thompson, Felipe Espinoza-Arancibia,
  Richard I. Anderson, Wolfgang Gieren, Weronika Narloch, Javier Minniti,
  Grzegorz Pietrzy\'nski, M\'onica Taormina, Giuseppe Bono, Gergely Hajdu","Discovery of a binary-origin classical Cepheid in a binary system with a
  59-day orbital period","6 pages, 4 figures, 1 table, published in The Astrophysical Journal
  Letters","2022, ApJL, 940, L48","10.3847/2041-8213/ac9fcc",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We report the discovery of a surprising binary configuration of the
double-mode Cepheid OGLE-LMC-CEP-1347 pulsating in the first (P_1=0.690d) and
second overtone (P_2=0.556d) modes. The orbital period (P_orb=59d) of the
system is five times shorter than the shortest known to date (310d) for a
binary Cepheid. The Cepheid itself is also the shortest-period one ever found
in a binary system and the first double-mode Cepheid in a spectroscopically
double-lined binary. OGLE-LMC-CEP-1347 is most probably on its first crossing
through the instability strip, as inferred from both its short period and fast
period increase, consistent with evolutionary models, and from the short
orbital period (not expected for binary Cepheids whose components have passed
through the red giant phase). Our evolutionary analysis yielded a
first-crossing Cepheid with a mass in a range of 2.9-3.4 Msun (lower than any
measured Cepheid mass), consistent with observations. The companion is a stable
star, at least two times fainter and less massive than the Cepheid (preliminary
mass ratio q=0.55), while also redder and thus at the subgiant or more advanced
evolutionary stage. To match these characteristics, the Cepheid has to be a
product of binary interaction, most likely a merger of two less massive stars,
which makes it the second known classical Cepheid of binary origin. Moreover,
further evolution of the components may lead to another binary interaction.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:00:25 GMT""}]","2022-12-12"
"2212.04519","Francesco Ferrari","Paul Wunderlich, Francesco Ferrari, Roser Valent\'i","Detecting topological phases in the square-octagon lattice with
  statistical methods","9 pages, 6 figures","EPJ Plus 138, 336 (2023)","10.1140/epjp/s13360-023-03937-y",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Electronic systems living on Archimedean lattices such as kagome and
square-octagon networks are presently being intensively discussed for the
possible realization of topological insulating phases. Coining the most
interesting electronic topological states in an unbiased way is however not
straightforward due to the large parameter space of possible Hamiltonians. A
possible approach to tackle this problem is provided by a recently developed
statistical learning method [T. Mertz and R. Valent\'i, Phys. Rev. Research 3,
013132 (2021)], based on the analysis of a large data sets of randomized
tight-binding Hamiltonians labeled with a topological index. In this work, we
complement this technique by introducing a feature engineering approach which
helps identifying polynomial combinations of Hamiltonian parameters that are
associated with non-trivial topological states. As a showcase, we employ this
method to investigate the possible topological phases that can manifest on the
square-octagon lattice, focusing on the case in which the Fermi level of the
system lies at a high-order van Hove singularity, in analogy to recent studies
of topological phases on the kagome lattice at the van Hove filling.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:01:02 GMT""},{""version"":""v2"",""created"":""Thu, 4 May 2023 12:37:10 GMT""}]","2023-05-05"
"2212.04520","Thomas Hughes","Thomas Hughes","The compact support property for solutions to stochastic heat equations
  with stable noise","50 pages. Minor changes in exposition",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider weak non-negative solutions to the stochastic partial
differential equation \begin{equation*} \partial_t Y_t(x) = \Delta Y_t(x) +
Y_{t-}(x)^\gamma \dot{L}(t,x), \end{equation*} for $(t,x) \in \mathbb{R}_+
\times \mathbb{R}^d$, where $\gamma > 0$ and $\dot{L}$ is a one-sided stable
noise of index $\alpha \in (1,2)$. We prove that solutions with compactly
supported initial data have compact support for all times if $\gamma \in
(2-\alpha, 1)$ for $d=1$, and if $\gamma \in [1/\alpha,1)$ in dimensions $d \in
[2,2/(\alpha-1)) \cap \mathbb{N}$. This complements known results on solutions
to the equation with Gaussian noise. We also establish a stochastic integral
formula for the density of a solution and associated moment bounds which hold
in all dimensions for which solutions are defined.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:02:35 GMT""},{""version"":""v2"",""created"":""Wed, 11 Jan 2023 21:20:15 GMT""}]","2023-01-13"
"2212.04521","Kiyam Lin","Kiyam Lin, Maximilian von Wietersheim-Kramsta, Benjamin Joachimi,
  Stephen Feeney","A simulation-based inference pipeline for cosmic shear with the
  Kilo-Degree Survey","14 pages, 8 figures; submitted to MNRAS",,,"MN-22-4878-MJ","astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  The standard approach to inference from cosmic large-scale structure data
employs summary statistics that are compared to analytic models in a Gaussian
likelihood with pre-computed covariance. To overcome the idealising assumptions
about the form of the likelihood and the complexity of the data inherent to the
standard approach, we investigate simulation-based inference (SBI), which
learns the likelihood as a probability density parameterised by a neural
network. We construct suites of simulated, exactly Gaussian-distributed data
vectors for the most recent Kilo-Degree Survey (KiDS) weak gravitational
lensing analysis and demonstrate that SBI recovers the full 12-dimensional KiDS
posterior distribution with just under $10^4$ simulations. We optimise the
simulation strategy by initially covering the parameter space by a hypercube,
followed by batches of actively learnt additional points. The data compression
in our SBI implementation is robust to suboptimal choices of fiducial parameter
values and of data covariance. Together with a fast simulator, SBI is therefore
a competitive and more versatile alternative to standard inference.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:02:54 GMT""}]","2022-12-12"
"2212.04522","Samuel Brieden","Samuel Brieden, H\'ector Gil-Mar\'in, Licia Verde","A tale of two (or more) $h$'s","42 pages, 12 figures, 3 tables, Ccmments welcome, v2 matches accepted
  version","JCAP04(2023)023","10.1088/1475-7516/2023/04/023",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  We use the large-scale structure galaxy data (LSS) from the BOSS and eBOSS
surveys, in combination with abundances information from Big Bang
Nucleosynthesis (BBN) to measure two values of the Hubble expansion rate,
$H_0=100h\,[{\rm km}\, {\rm s}^{-1}\,{\rm Mpc}^{-1}]$, each of them based on
very different physical processes. One is a (traditional) late-time-background
measurement based on determining the BAO scale and using BBN abundances on
baryons for calibrating its absolute size (BAO+BBN). This method anchors $H_0$
to the (standard) physics of the sound horizon scale at pre-recombination
times. The other is a newer early-time based measurement associated with the
broadband shape of the power spectrum. This second method anchors $H_0$ to the
physics of the matter-radiation equality scale, which also needs BBN
information for determining the suppression of baryons in the power spectrum
shape (shape+BBN). Within the $\Lambda$CDM model, we find very good consistency
among these two $H_0$'s: BAO+BBN (+growth) delivers $H_0=67.42_{-0.94}^{+0.88}$
$(67.37_{-0.95}^{+0.86})$ km s$^{-1}$Mpc$^{-1}$ , whereas the shape+BBN
(+growth) delivers $H_0 = 70.1_{-2.1}^{+2.1}$ $(70.1_{-2.1}^{+1.9})$ km
s$^{-1}$ Mpc$^{-1}$, where ""growth"" stands for information from the
late-time-perturbations captured by the growth of structure parameter. These
are the tightest sound-horizon free $H_0$ constraints from LSS data to date. As
a consequence to be viable, any $\Lambda$CDM extension proposed to address the
so-called ""Hubble tension"" needs to modify consistently not only the sound
horizon scale physics, but also the matter-radiation equality scale, in such a
way that both late- and early-based $H_0$'s return results mutually consistent
and consistent with the high $H_0$ value recovered by the standard cosmic
distance ladder (distance-redshift relation) determinations.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:08:10 GMT""},{""version"":""v2"",""created"":""Wed, 12 Apr 2023 09:30:05 GMT""}]","2023-04-13"
"2212.04523","Bingzhi Li","Bingzhi Li, Guillaume Wisniewski, Beno\^it Crabb\'e","Assessing the Capacity of Transformer to Abstract Syntactic
  Representations: A Contrastive Analysis Based on Long-distance Agreement","To appear in TACL 2022 and EMNLP 2022",,,,"cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The long-distance agreement, evidence for syntactic structure, is
increasingly used to assess the syntactic generalization of Neural Language
Models. Much work has shown that transformers are capable of high accuracy in
varied agreement tasks, but the mechanisms by which the models accomplish this
behavior are still not well understood. To better understand transformers'
internal working, this work contrasts how they handle two superficially similar
but theoretically distinct agreement phenomena: subject-verb and object-past
participle agreement in French. Using probing and counterfactual analysis
methods, our experiments show that i) the agreement task suffers from several
confounders which partially question the conclusions drawn so far and ii)
transformers handle subject-verb and object-past participle agreements in a way
that is consistent with their modeling in theoretical linguistics.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:10:46 GMT""},{""version"":""v2"",""created"":""Wed, 4 Jan 2023 13:06:16 GMT""}]","2023-01-05"
"2212.04524","Maria Filipkovska","Maria Filipkovska","IBVP for the Maxwell-Bloch equations with an arbitrary inhomogeneous
  broadening and the periodic boundary function",,,,,"math.DS math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The initial-boundary value problem (IBVP) for the Maxwell-Bloch equations
with an arbitrary inhomogeneous broadening and periodic boundary condition is
studied. This IBVP describes the propagation of an electromagnetic wave
generated by periodic pumping in a resonant medium with distributed two-level
atoms. We extended the inverse scattering transform method in the form of the
matrix Riemann-Hilbert problem for solving the considered IBVP. Using the
system of Ablowitz-Kaup-Newell-Segur equations equivalent to the system of the
Maxwell-Bloch (MB) equations, we construct the associated matrix
Riemann-Hilbert (RH) problem. Theorems on the existence, uniqueness and
smoothness properties of a solution of the constructed RH problem are proved,
and it is shown that a solution of the considered IBVP is uniquely defined by
the solution of the associated RH problem. It is proved that the RH problem
provides the causality principle. The representation of a solution of the MB
equations in terms of a solution of the associated RH problem are given. The
significance of this method also lies in the fact that, having studied the
asymptotic behavior of the constructed RH problem and equivalent ones, we can
obtain formulas for the asymptotics of a solution of the corresponding IBVP for
the MB equations.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:15:33 GMT""},{""version"":""v2"",""created"":""Wed, 14 Dec 2022 09:19:08 GMT""},{""version"":""v3"",""created"":""Mon, 26 Dec 2022 14:26:36 GMT""},{""version"":""v4"",""created"":""Mon, 27 Feb 2023 23:09:27 GMT""}]","2023-03-01"
"2212.04525","Mykola Pinchuk","Mykola Pinchuk","Monetary Uncertainty as a Determinant of the Response of Stock Market to
  Macroeconomic News",,,,,"q-fin.PR econ.GN q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  This paper examines the effect of macroeconomic news announcements (MNA) on
the stock market. Stocks exhibit a strong positive response to major MNA: 1
standard deviation of MNA surprise causes 11-25 bps higher returns. This
response is highly time-varying and is weaker during periods of high monetary
uncertainty. I decompose this response into cash flow and risk-free rate
channels. 1 standard deviation of good MNA surprise leads to plus 30 bps
returns from the cash flow channel and minus 23 bps per 1\% of monetary
uncertainty from the risk-free rate channel. Risk-free rate channel is
time-varying and is stronger when monetary uncertainty is high. High levels of
monetary uncertainty mask the strong positive response of stocks to MNA, which
explains why past research failed to detect this relation.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:16:20 GMT""}]","2022-12-12"
"2212.04526","Rigel Cappallo","Alan E. E. Rogers, John P. Barrett, Judd D. Bowman, Rigel Cappallo,
  Colin J. Lonsdale, Nivedita Mahesh, Raul A. Monsalve, Steven G. Murray, Peter
  H. Sims","Analytic approximations of scattering effects on beam chromaticity in
  21-cm global experiments",,,"10.1029/2022RS007558",,"astro-ph.IM astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Scattering from objects near an antenna produce correlated signals from
strong compact radio sources in a manner similar to those used by the Sea
Interferometer to measure the radio source positions using the fine frequency
structure in the total power spectrum of a single antenna. These fringes or
ripples due to correlated signal interference are present at a low level in the
spectrum of any single antenna and are a major source of systematics in systems
used to measure the global redshifted 21-cm signal from the early universe. In
the Sea Interferometer a single antenna on a cliff above the sea is used to add
the signal from the direct path to the signal from the path reflected from the
sea thereby forming an interferometer. This was used for mapping radio sources
with a single antenna by Bolton and Slee in the 1950s. In this paper we derive
analytic expressions to determine the level of these ripples and compare these
results in a few simple cases with electromagnetic modeling software to verify
that the analytic calculations are sufficient to obtain the magnitude of the
scattering effects on the measurements of the global 21-cm signal. These
analytic calculations are needed to evaluate the magnitude of the effects in
cases that are either too complex or take too much time to be modeled using
software.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:18:24 GMT""}]","2023-01-11"
"2212.04527","Leo Versteegen","Leo Versteegen","A proof of the 3/5-conjecture in the domination game","30 pages, 6 figures",,,,"math.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The domination game is an optimization game played by two players, Dominator
and Staller, who alternately select vertices in a graph $G$. A vertex is said
to be dominated if it has been selected or is adjacent to a selected vertex.
Each selected vertex must strictly increase the number of dominated vertices at
the time of its selection, and the game ends once every vertex in $G$ is
dominated. Dominator aims to keep the game as short as possible, while Staller
tries to achieve the opposite. In this article, we prove that for any graph $G$
on $n$ vertices, Dominator has a strategy to end the game in at most $3n/5$
moves, which was conjectured by Kinnersley, West and Zamani.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:21:24 GMT""},{""version"":""v2"",""created"":""Thu, 2 Feb 2023 11:35:35 GMT""}]","2023-02-03"
"2212.04528","Harshit Parmar","Harshit Parmar and Eric Walden","Towards Practical Application of Deep Learning in Diagnosis of
  Alzheimer's Disease","18 pages, 8 figures",,,,"cs.LG cs.AI eess.IV","http://creativecommons.org/licenses/by/4.0/","  Accurate diagnosis of Alzheimer's disease (AD) is both challenging and time
consuming. With a systematic approach for early detection and diagnosis of AD,
steps can be taken towards the treatment and prevention of the disease. This
study explores the practical application of deep learning models for diagnosis
of AD. Due to computational complexity, large training times and limited
availability of labelled dataset, a 3D full brain CNN (convolutional neural
network) is not commonly used, and researchers often prefer 2D CNN variants. In
this study, full brain 3D version of well-known 2D CNNs were designed, trained
and tested for diagnosis of various stages of AD. Deep learning approach shows
good performance in differentiating various stages of AD for more than 1500
full brain volumes. Along with classification, the deep learning model is
capable of extracting features which are key in differentiating the various
categories. The extracted features align with meaningful anatomical landmarks,
that are currently considered important in identification of AD by experts. An
ensemble of all the algorithm was also tested and the performance of the
ensemble algorithm was superior to any individual algorithm, further improving
diagnosis ability. The 3D versions of the trained CNNs and their ensemble have
the potential to be incorporated in software packages that can be used by
physicians/radiologists to assist them in better diagnosis of AD.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:21:51 GMT""}]","2022-12-12"
"2212.04529","Erick Past\'en Mr","Erick Past\'en, V\'ictor H. C\'ardenas","A fractal LTB model cannot explain Dark Energy","We show that following 10.48550/ARXIV.2302.04679, the model proposed
  requires an inhomogeneous big bang , therefore not solving the problem of DE.
  Our model construct a fractal matter model that assumes a homogeneous big
  bang, not requiring any new physics. We added a different smooth mass
  function to compare with the sharp one, not changing our principal results",,,,"astro-ph.CO gr-qc","http://creativecommons.org/publicdomain/zero/1.0/","  We revisited the problem of describing, on average, a fractal distribution of
matter using a Lemaitre-Tolman-Bondi (LTB) solution. Here we study the fractal
structure of our local universe having a fractal dimension and a scale
transition, ensuring an homogeneous bang-time function. We test our model with
the latest type Ia supernova data, the Pantheon compilation, and discuss
problems and possible improvements for it, concluding that a fractal transition
in LTB cosmology cannot be used to explain the effects of dark energy without
requiring an inhomogeneous big-bang, but it can be useful to study structures
at low scales.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:24:22 GMT""},{""version"":""v2"",""created"":""Thu, 23 Feb 2023 16:33:54 GMT""}]","2023-02-24"
"2212.04530","Gregory Voth","Patrick G. Sahrmann, Timothy D. Loose, Aleksander E.P. Durumeric,
  Gregory A. Voth","Utilizing Machine Learning to Greatly Expand the Range and Accuracy of
  Bottom-Up Coarse-Grained Models Through Virtual Particles","35 pages, 9 figures",,,,"physics.chem-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Coarse-grained (CG) models parameterized using atomistic reference data,
i.e., 'bottom up' CG models, have proven useful in the study of biomolecules
and other soft matter. However, the construction of highly accurate, low
resolution CG models of biomolecules remains challenging. We demonstrate in
this work how virtual particles, CG sites with no atomistic correspondence, can
be incorporated into CG models within the context of relative entropy
minimization (REM) as latent variables. The methodology presented, variational
derivative relative entropy minimization (VD-REM), enables optimization of
virtual particle interactions through a gradient descent algorithm aided by
machine learning. We apply this methodology to the challenging case of a
solvent-free CG model of a 1,2-dioleoyl-sn-glycero-3-phosphocholine (DOPC)
lipid bilayer and demonstrate that introduction of virtual particles captures
solvent-mediated behavior and higher-order correlations which REM alone cannot
capture in a more standard CG model based only on the mapping of collections of
atoms to the CG sites.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:30:17 GMT""}]","2022-12-12"
"2212.04531","Kushagra Tiwary","Kushagra Tiwary, Akshat Dave, Nikhil Behari, Tzofi Klinghoffer, Ashok
  Veeraraghavan, Ramesh Raskar","ORCa: Glossy Objects as Radiance Field Cameras","for more information, see https://ktiwary2.github.io/objectsascam/",,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Reflections on glossy objects contain valuable and hidden information about
the surrounding environment. By converting these objects into cameras, we can
unlock exciting applications, including imaging beyond the camera's
field-of-view and from seemingly impossible vantage points, e.g. from
reflections on the human eye. However, this task is challenging because
reflections depend jointly on object geometry, material properties, the 3D
environment, and the observer viewing direction. Our approach converts glossy
objects with unknown geometry into radiance-field cameras to image the world
from the object's perspective. Our key insight is to convert the object surface
into a virtual sensor that captures cast reflections as a 2D projection of the
5D environment radiance field visible to the object. We show that recovering
the environment radiance fields enables depth and radiance estimation from the
object to its surroundings in addition to beyond field-of-view novel-view
synthesis, i.e. rendering of novel views that are only directly-visible to the
glossy object present in the scene, but not the observer. Moreover, using the
radiance field we can image around occluders caused by close-by objects in the
scene. Our method is trained end-to-end on multi-view images of the object and
jointly estimates object geometry, diffuse radiance, and the 5D environment
radiance field.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:32:08 GMT""},{""version"":""v2"",""created"":""Mon, 12 Dec 2022 14:51:24 GMT""}]","2022-12-13"
"2212.04532","Ahmed Mustafa","Ahmed Mustafa, Jean-Marc Valin, Jan B\""uthe, Paris Smaragdis, Mike
  Goodwin","Framewise WaveGAN: High Speed Adversarial Vocoder in Time Domain with
  Very Low Computational Complexity","Accepted to ICASSP 2023, demo:
  https://ahmed-fau.github.io/fwgan_demo/",,,,"eess.AS cs.LG cs.SD eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  GAN vocoders are currently one of the state-of-the-art methods for building
high-quality neural waveform generative models. However, most of their
architectures require dozens of billion floating-point operations per second
(GFLOPS) to generate speech waveforms in samplewise manner. This makes GAN
vocoders still challenging to run on normal CPUs without accelerators or
parallel computers. In this work, we propose a new architecture for GAN
vocoders that mainly depends on recurrent and fully-connected networks to
directly generate the time domain signal in framewise manner. This results in
considerable reduction of the computational cost and enables very fast
generation on both GPUs and low-complexity CPUs. Experimental results show that
our Framewise WaveGAN vocoder achieves significantly higher quality than
auto-regressive maximum-likelihood vocoders such as LPCNet at a very low
complexity of 1.2 GFLOPS. This makes GAN vocoders more practical on edge and
low-power devices.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:38:34 GMT""},{""version"":""v2"",""created"":""Thu, 2 Mar 2023 00:45:49 GMT""}]","2023-03-03"
"2212.04533","Fatih Cagatay Akyon","Fatih Cagatay Akyon, Alptekin Temizel","Deep Architectures for Content Moderation and Movie Content Rating",,,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Rating a video based on its content is an important step for classifying
video age categories. Movie content rating and TV show rating are the two most
common rating systems established by professional committees. However, manually
reviewing and evaluating scene/film content by a committee is a tedious work
and it becomes increasingly difficult with the ever-growing amount of online
video content. As such, a desirable solution is to use computer vision based
video content analysis techniques to automate the evaluation process. In this
paper, related works are summarized for action recognition, multi-modal
learning, movie genre classification, and sensitive content detection in the
context of content moderation and movie content rating. The project page is
available at https://github.com/fcakyon/content-moderation-deep-learning.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:50:53 GMT""},{""version"":""v2"",""created"":""Mon, 12 Dec 2022 07:53:17 GMT""}]","2022-12-13"
"2212.04534","Frederick Miller","Frederick ""Forrest"" Miller, Yaren Bilge Kaya, Geri L. Dimas, Renata
  Konrad, Kayse Lee Maass, Andrew C. Trapp","On the Optimization of Benefit to Cost Ratios for Public Sector Decision
  Making",,,,,"math.OC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Decision making in the public sector centers on delivering resources and
services for the common good, emphasizing an expansive set of objectives such
as equity and efficiency, beyond immediate short term returns to reflect the
broader cares of society and public beneficiaries. Cost-benefit analysis is a
prevailing decision-making framework in the public sector that often uses the
benefit to cost ratio (BCR) to compare viable alternatives, yet no systematic
framework exists for evaluating many alternatives beyond the status quo of
doing nothing. We propose a new framework to maximize the BCR for public sector
decisions, seeking the largest improvement per marginal deployment of capacity.
Requiring a status quo representable through (constrained) decision variables,
the framework is generally applicable and useful to a broad set of decision
contexts that involve maximizing the BCR for marginal deployments of resources.
We demonstrate the applicability of our framework on a compelling case study
for the New York City runaway and homeless youth shelter system, an area of
high societal need. We represent this problem as a mixed integer linear
fractional program (MILFP) and employ Dinkelbach's algorithm that converts the
MILFP to a series of linearized mixed-integer optimization problems, making our
approach tractable for fairly large problem instances. Our optimization-based
algorithmic framework yields data-informed recommendations for making New York
City shelter expansion decisions to better serve runaway and homeless youth,
and generalizes to reveal managerial insights for optimizing the BCR. More
broadly, our algorithmic decision making framework allows for iteration and
comparison across multiple potential constraints ensuring action away from the
status quo, thereby empowering effective assessment of marginal deployment of
additional resources.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:53:48 GMT""},{""version"":""v2"",""created"":""Fri, 14 Apr 2023 14:29:56 GMT""}]","2023-04-17"
"2212.04535","Yizi Zhang","Yizi Zhang, Meimei Liu, Zhengwu Zhang, and David Dunson","Motion-Invariant Variational Auto-Encoding of Brain Structural
  Connectomes",,,,,"q-bio.NC","http://creativecommons.org/licenses/by/4.0/","  Mapping of human brain structural connectomes via diffusion MRI offers a
unique opportunity to understand brain structural connectivity and relate it to
various human traits, such as cognition. However, motion artifacts from head
movement during image acquisition can impact the connectome reconstructions,
rendering the subsequent inference results unreliable. We aim to develop a
generative model to learn low-dimensional representations of structural
connectomes that are invariant to motion artifacts, so that we can link brain
networks and human traits more accurately, and generate motion-adjusted
connectomes. We applied the proposed model to data from the Adolescent Brain
Cognitive Development (ABCD) study and the Human Connectome Project (HCP) to
investigate how our motion-invariant connectomes facilitate understanding of
the brain network and its relationship with cognition. Empirical results
demonstrate that the proposed motion-invariant variational auto-encoder
(inv-VAE) outperforms its competitors on various aspects. In particular,
motion-adjusted structural connectomes are more strongly associated with a wide
array of cognition-related traits than other approaches without motion
adjustment.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:54:25 GMT""}]","2022-12-12"
"2212.04536","A. A. Schaeffer Fry","A. A. Schaeffer Fry","On some rational extension properties for $GL_n(q)$ and even-degree
  characters fixed by order-2 Galois automorphisms","Thm. A, Cor. B, are incorrect as stated and would require additional
  assumptions on q (a result of a missing assumption in another paper).
  Withdrawn until I obtain a working solution",,,,"math.GR math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note, we prove that if every character of a finite group $G$ fixed by
an order-2 Galois automorphism has odd degree, then $G$ has a normal Sylow
$2$-subgroup. On the way, we study extensions of characters of $GL_n(q)$, $q$
odd, to the group extended by the transpose-inverse automorphism and prove that
unipotent characters of $PSL_n(q)$ extend to rational characters of its
automorphism group.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:55:02 GMT""},{""version"":""v2"",""created"":""Thu, 15 Dec 2022 16:40:22 GMT""}]","2022-12-16"
"2212.04537","Jiaqi Ma","Jiaqi Ma, Xingjian Zhang, Hezheng Fan, Jin Huang, Tianyue Li, Ting Wei
  Li, Yiwen Tu, Chenshu Zhu, Qiaozhu Mei","Graph Learning Indexer: A Contributor-Friendly and Metadata-Rich
  Platform for Graph Learning Benchmarks","Oral Presentation at LOG 2022",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Establishing open and general benchmarks has been a critical driving force
behind the success of modern machine learning techniques. As machine learning
is being applied to broader domains and tasks, there is a need to establish
richer and more diverse benchmarks to better reflect the reality of the
application scenarios. Graph learning is an emerging field of machine learning
that urgently needs more and better benchmarks. To accommodate the need, we
introduce Graph Learning Indexer (GLI), a benchmark curation platform for graph
learning. In comparison to existing graph learning benchmark libraries, GLI
highlights two novel design objectives. First, GLI is designed to incentivize
\emph{dataset contributors}. In particular, we incorporate various measures to
minimize the effort of contributing and maintaining a dataset, increase the
usability of the contributed dataset, as well as encourage attributions to
different contributors of the dataset. Second, GLI is designed to curate a
knowledge base, instead of a plain collection, of benchmark datasets. We use
multiple sources of meta information to augment the benchmark datasets with
\emph{rich characteristics}, so that they can be easily selected and used in
downstream research or development. The source code of GLI is available at
\url{https://github.com/Graph-Learning-Benchmarks/gli}.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:57:01 GMT""}]","2022-12-12"
"2212.04538","Samuel Bengtsson","S. Bengtsson, E. R. Simpson, N. Ibrakovic, S. Ek, A. Olofsson, T.
  Causer and J. Mauritsson","Experimental observation of trajectories beyond the long in high order
  harmonic generation","10 pages and 8 figures",,,,"physics.optics physics.atom-ph","http://creativecommons.org/licenses/by/4.0/","  We experimentally observe longer than long trajectory influence in high order
harmonic generation (HHG) by varying the peak intensity of the driving laser
field through either direct attenuation, or by chirping the laser pulse. Using
a theoretical Gaussian beam model to simulate spatial interference resulting
from quantum path interference we show that the measured interference patterns
cannot be solely explained by the well established short and long trajectories.
The structure change is most prominent for the more divergent, off-axis
components of the lower plateau harmonic region, affecting the direction and
amplitude of the extreme ultraviolet light emitted, and is thus of importance
for understanding and controlling the fundamentals of the HHG process.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:57:15 GMT""}]","2022-12-12"
"2212.04539","John Quigg","Erik B\'edos and S. Kaliszewski and John Quigg and Jonathan Turk","Coactions on C*-algebras and universal properties","17 pages",,,,"math.OA","http://creativecommons.org/licenses/by/4.0/","  It is well-known that the maximalization of a coaction of a locally compact
group on a C*-algebra enjoys a universal property. We show how this important
property can be deduced from a categorical framework by exploiting certain
properties of the maximalization functor for coactions. We also provide a dual
proof for the universal property of normalization of coactions.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 19:57:48 GMT""}]","2022-12-12"
"2212.04540","Huiyuan Chen","Huiyuan Chen, Xiaoting Li, Kaixiong Zhou, Xia Hu, Chin-Chia Michael
  Yeh, Yan Zheng, Hao Yang","TinyKG: Memory-Efficient Training Framework for Knowledge Graph Neural
  Recommender Systems",,,"10.1145/3523227.3546760",,"cs.IR","http://creativecommons.org/licenses/by/4.0/","  There has been an explosion of interest in designing various Knowledge Graph
Neural Networks (KGNNs), which achieve state-of-the-art performance and provide
great explainability for recommendation. The promising performance is mainly
resulting from their capability of capturing high-order proximity messages over
the knowledge graphs. However, training KGNNs at scale is challenging due to
the high memory usage. In the forward pass, the automatic differentiation
engines (\textsl{e.g.}, TensorFlow/PyTorch) generally need to cache all
intermediate activation maps in order to compute gradients in the backward
pass, which leads to a large GPU memory footprint. Existing work solves this
problem by utilizing multi-GPU distributed frameworks. Nonetheless, this poses
a practical challenge when seeking to deploy KGNNs in memory-constrained
environments, especially for industry-scale graphs.
  Here we present TinyKG, a memory-efficient GPU-based training framework for
KGNNs for the tasks of recommendation. Specifically, TinyKG uses exact
activations in the forward pass while storing a quantized version of
activations in the GPU buffers. During the backward pass, these low-precision
activations are dequantized back to full-precision tensors, in order to compute
gradients. To reduce the quantization errors, TinyKG applies a simple yet
effective quantization algorithm to compress the activations, which ensures
unbiasedness with low variance. As such, the training memory footprint of KGNNs
is largely reduced with negligible accuracy loss. To evaluate the performance
of our TinyKG, we conduct comprehensive experiments on real-world datasets. We
found that our TinyKG with INT2 quantization aggressively reduces the memory
footprint of activation maps with $7 \times$, only with $2\%$ loss in accuracy,
allowing us to deploy KGNNs on memory-constrained devices.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 20:01:34 GMT""}]","2022-12-12"
"2212.04541","Hilal Ahmad Bhat","Hilal Ahmad Bhat and Akhlad Iqbal","Generalized Hukuhara directional differentiability of interval-valued
  functions on Riemannian manifolds",,,,,"math.OC math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we show that generalized Hukuhara directional
differentiability of an interval-valued function (IVF) defined on Riemannian
manifolds is not equivalent to the directional differentiability of its center
and half-width functions and hence not to its end point functions. This
contrasts with S.-L. Chen's \cite{chen} assertion which says the equivalence
holds in terms of endpoint functions of an IVF which is defined on a Hadamard
manifold. Additionally, the paper addresses some inaccuracies made by the
author which arise when assuming the convexity of a function at a single point
in its domain. In light of these arguments, the paper presents some basic
results that relate to both the convexity and directional differentiability of
an IVF.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 20:06:21 GMT""},{""version"":""v2"",""created"":""Sun, 7 May 2023 13:45:09 GMT""}]","2023-05-09"
"2212.04542","Yonatan Bitton","Yonatan Bitton, Ron Yosef, Eli Strugo, Dafna Shahaf, Roy Schwartz,
  Gabriel Stanovsky","VASR: Visual Analogies of Situation Recognition","Accepted to AAAI 2023. Website: https://vasr-dataset.github.io/",,,,"cs.CV cs.AI cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A core process in human cognition is analogical mapping: the ability to
identify a similar relational structure between different situations. We
introduce a novel task, Visual Analogies of Situation Recognition, adapting the
classical word-analogy task into the visual domain. Given a triplet of images,
the task is to select an image candidate B' that completes the analogy (A to A'
is like B to what?). Unlike previous work on visual analogy that focused on
simple image transformations, we tackle complex analogies requiring
understanding of scenes.
  We leverage situation recognition annotations and the CLIP model to generate
a large set of 500k candidate analogies. Crowdsourced annotations for a sample
of the data indicate that humans agree with the dataset label ~80% of the time
(chance level 25%). Furthermore, we use human annotations to create a
gold-standard dataset of 3,820 validated analogies. Our experiments demonstrate
that state-of-the-art models do well when distractors are chosen randomly
(~86%), but struggle with carefully chosen distractors (~53%, compared to 90%
human accuracy). We hope our dataset will encourage the development of new
analogy-making models. Website: https://vasr-dataset.github.io/
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 20:08:49 GMT""}]","2022-12-12"
"2212.04543","Federico Toschi","Pinaki Kumar, Roberto Benzi, Jeannot Trampert and Federico Toschi","Direct observations of causal links in plastic events validates
  statistical analysis tools for seismology","6 pages, 5 figures",,,,"physics.geo-ph nlin.AO physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Earthquakes are complex physical processes driven by the stick-slip motion of
a sliding fault. After the main quake, a series of aftershocks typically
follows. These are loosely defined as events that follow a given event and
occur within prescribed space-time windows. In seismology, it is however
impossible to establish a causal relation and the popular Nearest-Neighbor
metric is commonly used to distinguish aftershocks from independent events.
Here we employ a model for earthquake dynamics, previously shown to be able to
correctly reproduce the phenomenology of earthquakes, and a technique that
allows us to separate independent and triggered events. We show that
aftershocks in our catalogue follow Omori's law and we employ the model to show
that the Nearest-Neighbor metric is effective in separating independent events
from aftershocks.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 20:09:10 GMT""}]","2022-12-12"
"2212.04544","Kirill Bronnikov","Kirill A. Bronnikov, Kodir Badalov, Rustam Ibadov","Arbitrary static, spherically symmetric space-times as solutions of
  scalar-tensor gravity","8 pages, 1 figure",,"10.1134/S0202289323010036",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is shown that an arbitrary static, spherically symmetric metric can be
presented as an exact solution of a scalar-tensor theory (STT) of gravity with
certain nonminimal coupling function $f(\phi)$ and potential $U(\phi)$. The
scalar field in this representation can change its nature from canonical to
phantom on certain coordinate spheres. This representation, however, is valid
in general not in the full range of the radial coordinate but only piecewise.
Two examples of STT representations are discussed: for the Reissner-Nordstr\""om
metric and for the Simpson-Visser regularization of the Schwarzschild metric
(the so-called black bounce space-time).
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 20:14:15 GMT""}]","2023-04-12"
"2212.04545","Magnus Ogren","F Rousse, M Carlsson, M Ogren, B Kalischer Wellander","The role of super-spreaders in modeling of SARS-CoV-2",,"Infectious Disease Modelling 7 (2022) 778-794","10.1016/j.idm.2022.10.003",,"physics.soc-ph math.PR q-bio.PE","http://creativecommons.org/licenses/by/4.0/","  In stochastic modeling of infectious diseases, it has been established that
variations in infectivity affect the probability of a major outbreak, but not
the shape of the curves during a major outbreak, which is predicted by
deterministic models [Diekmann et al., 2012]. However, such conclusions are
derived under idealized assumptions such as the population size tending to
infinity, and the individual degree of infectivity only depending on variations
in the infectiousness period. In this paper we show that the same conclusions
hold true in a finite population representing a medium size city, where the
degree of infectivity is determined by the offspring distribution, which we try
to make as realistic as possible for SARS-CoV-2. In particular, we consider
distributions with fat tails, to incorporate the existence of super-spreaders.
We also provide new theoretical results on convergence of stochastic models
which allows to incorporate any offspring distribution with a finite variance.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 20:17:12 GMT""}]","2022-12-12"
"2212.04546","Md. Alamin Talukder","Md. Alamin Talukder, Khondokar Fida Hasan, Md. Manowarul Islam, Md
  Ashraf Uddin, Arnisha Akhter, Mohammad Abu Yousuf, Fares Alharbi, Mohammad
  Ali Moni","A Dependable Hybrid Machine Learning Model for Network Intrusion
  Detection","Accepted in the Journal of Information Security and Applications
  (Scopus, Web of Science (SCIE) Journal, Quartile: Q1, Site Score: 7.6, Impact
  Factor: 4.96) on 7 December 2022","Journal of Information Security and Applications, Volume 72, Pages
  103405, Year 2023, ISSN 2214-2126","10.1016/j.jisa.2022.103405",,"cs.CR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Network intrusion detection systems (NIDSs) play an important role in
computer network security. There are several detection mechanisms where
anomaly-based automated detection outperforms others significantly. Amid the
sophistication and growing number of attacks, dealing with large amounts of
data is a recognized issue in the development of anomaly-based NIDS. However,
do current models meet the needs of today's networks in terms of required
accuracy and dependability? In this research, we propose a new hybrid model
that combines machine learning and deep learning to increase detection rates
while securing dependability. Our proposed method ensures efficient
pre-processing by combining SMOTE for data balancing and XGBoost for feature
selection. We compared our developed method to various machine learning and
deep learning algorithms to find a more efficient algorithm to implement in the
pipeline. Furthermore, we chose the most effective model for network intrusion
based on a set of benchmarked performance analysis criteria. Our method
produces excellent results when tested on two datasets, KDDCUP'99 and
CIC-MalMem-2022, with an accuracy of 99.99% and 100% for KDDCUP'99 and
CIC-MalMem-2022, respectively, and no overfitting or Type-1 and Type-2 issues.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 20:19:27 GMT""},{""version"":""v2"",""created"":""Fri, 27 Jan 2023 20:32:15 GMT""}]","2023-01-31"
"2212.04547","Xiao-Feng Qian","Xiaofeng Qian and Misagh Izadi","Bridging Coherence Optics and Classical Mechanics -- A Universal Light
  Polarization-Entanglement Complementary Relation","6 pages, 2 figures",,,,"physics.optics physics.class-ph quant-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  While optics and mechanics are two distinct branches of physics, they are
connected. It is well known that geometrical/ray treatment of light has direct
analogies to mechanical descriptions of particle motion. However, connections
between coherence wave optics and classical mechanics are rarely reported. Here
we explore links of the two for an arbitrary light field by performing a
quantitative analysis of two optical coherence properties: polarization and
entanglement (implied by a wave picture of light due to Huygens and Fresnel). A
universal complementary identity relation is obtained. More surprisingly,
optical polarization, entanglement, and their identity relation are shown to be
quantitatively associated with mechanical concepts of center of mass and moment
of inertia through the Huygens-Steiner theorem for rigid body rotation. The
obtained result bridges coherence wave optics and classical mechanics through
the two theories of Huygens.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 20:20:50 GMT""}]","2022-12-12"
"2212.04548","Kishor Kumar Bhaumik","Kishor Kumar Bhaumik, Fahim Faisal Niloy, Saif Mahmud, Simon Woo","STLGRU: Spatio-Temporal Lightweight Graph GRU for Traffic Flow
  Prediction",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Reliable forecasting of traffic flow requires efficient modeling of traffic
data. Different correlations and influences arise in a dynamic traffic network,
making modeling a complicated task. Existing literature has proposed many
different methods to capture the complex underlying spatial-temporal relations
of traffic networks. However, methods still struggle to capture different local
and global dependencies of long-range nature. Also, as more and more
sophisticated methods are being proposed, models are increasingly becoming
memory-heavy and, thus, unsuitable for low-powered devices. In this paper, we
focus on solving these problems by proposing a novel deep learning framework -
STLGRU. Specifically, our proposed STLGRU can effectively capture both local
and global spatial-temporal relations of a traffic network using
memory-augmented attention and gating mechanism. Instead of employing separate
temporal and spatial components, we show that our memory module and gated unit
can learn the spatial-temporal dependencies successfully, allowing for reduced
memory usage with fewer parameters. We extensively experiment on several
real-world traffic prediction datasets to show that our model performs better
than existing methods while the memory footprint remains lower. Code is
available at \url{https://github.com/Kishor-Bhaumik/STLGRU}.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 20:24:59 GMT""}]","2022-12-12"
"2212.04549","Nitish Anil Kumar Gupta","Nitish Gupta, Kurt Wilson, Zhishan Guo","Optimizing Real-Time Performances for Timed-Loop Racing under F1TENTH",,"Proceedings of the 43rd IEEE Real-Time Systems Symposium (RTSS),
  Industry Challenge, Houston, US, Dec. 2022",,,"cs.RO cs.SY eess.SY","http://creativecommons.org/licenses/by-sa/4.0/","  Motion planning and control in autonomous car racing are one of the most
challenging and safety-critical tasks due to high speed and dynamism. The
lower-level control nodes are expected to be highly optimized due to resource
constraints of onboard embedded processing units, although there are strict
latency requirements. Some of these guarantees can be provided at the
application level, such as using ROS2's Real-Time executors. However, the
performance can be far from satisfactory as many modern control algorithms
(such as Model Predictive Control) rely on solving complicated online
optimization problems at each iteration. In this paper, we present a simple yet
effective multi-threading technique to optimize the throughput of
online-control algorithms for resource-constrained autonomous racing platforms.
We achieve this by maintaining a systematic pool of worker threads solving the
optimization problem in parallel which can improve the system performance by
reducing latency between control input commands. We further demonstrate the
effectiveness of our method using the Model Predictive Contouring Control
(MPCC) algorithm running on Nvidia's Xavier AGX platform.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 20:30:52 GMT""}]","2022-12-12"
"2212.04550","Yili Hong","William Q. Meeker and Luis A. Escobar and Francis G. Pascual and Yili
  Hong and Peng Liu and Wayne M. Falk and Balajee Ananthasayanam","Modern Statistical Models and Methods for Estimating Fatigue-Life and
  Fatigue-Strength Distributions from Experimental Data","93 pages, 27 pages",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Engineers and scientists have been collecting and analyzing fatigue data
since the 1800s to ensure the reliability of life-critical structures.
Applications include (but are not limited to) bridges, building structures,
aircraft and spacecraft components, ships, ground-based vehicles, and medical
devices. Engineers need to estimate S-N relationships (Stress or Strain versus
Number of cycles to failure), typically with a focus on estimating small
quantiles of the fatigue-life distribution. Estimates from this kind of model
are used as input to models (e.g., cumulative damage models) that predict
failure-time distributions under varying stress patterns. Also, design
engineers need to estimate lower-tail quantiles of the closely related
fatigue-strength distribution. The history of applying incorrect statistical
methods is nearly as long and such practices continue to the present. Examples
include treating the applied stress (or strain) as the response and the number
of cycles to failure as the explanatory variable in regression analyses
(because of the need to estimate strength distributions) and ignoring or
otherwise mishandling censored observations (known as runouts in the fatigue
literature). The first part of the paper reviews the traditional modeling
approach where a fatigue-life model is specified. We then show how this
specification induces a corresponding fatigue-strength model. The second part
of the paper presents a novel alternative modeling approach where a
fatigue-strength model is specified and a corresponding fatigue-life model is
induced. We explain and illustrate the important advantages of this new
modeling approach.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 20:32:16 GMT""}]","2022-12-12"
"2212.04551","Samuel Ferraz","Samuel Ferraz, Vinicius Dias, Carlos H. C. Teixeira, George Teodoro,
  Wagner Meira Jr","Efficient Strategies for Graph Pattern Mining Algorithms on GPUs","Accepted for publication on IEEE 34th International Symposium on
  Computer Architecture and High Performance Computing (SBAC-PAD'22)",,"10.1109/SBAC-PAD55451.2022.00022",,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph Pattern Mining (GPM) is an important, rapidly evolving, and computation
demanding area. GPM computation relies on subgraph enumeration, which consists
in extracting subgraphs that match a given property from an input graph.
Graphics Processing Units (GPUs) have been an effective platform to accelerate
applications in many areas. However, the irregularity of subgraph enumeration
makes it challenging for efficient execution on GPU due to typical uncoalesced
memory access, divergence, and load imbalance. Unfortunately, these aspects
have not been fully addressed in previous work. Thus, this work proposes novel
strategies to design and implement subgraph enumeration efficiently on GPU. We
support a depth-first search style search (DFS-wide) that maximizes memory
performance while providing enough parallelism to be exploited by the GPU,
along with a warp-centric design that minimizes execution divergence and
improves utilization of the computing capabilities. We also propose a low-cost
load balancing layer to avoid idleness and redistribute work among thread warps
in a GPU. Our strategies have been deployed in a system named DuMato, which
provides a simple programming interface to allow efficient implementation of
GPM algorithms. Our evaluation has shown that DuMato is often an order of
magnitude faster than state-of-the-art GPM systems and can mine larger
subgraphs (up to 12 vertices).
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 20:34:30 GMT""}]","2022-12-12"
"2212.04552","Georgy Chernykh","Georgy Chernykh","Landweber exactness of the formal group law in $c_1$-spherical bordism",,,,,"math.AT","http://creativecommons.org/licenses/by/4.0/","  We describe the structure of the coefficient ring $W^*(pt)=\varOmega_W^*$ of
the $c_1$-spherical bordism theory for an arbitrary $SU$-bilinear
multiplication. We prove that for any $SU$-bilinear multiplication the formal
group of the theory $W^*$ is Landweber exact. Also we show that after inverting
the set $\mathcal P$ of Fermat primes there exists a complex orientation of the
localized theory $W^*[\mathcal P^{-1}]$ such that the coefficients of the
corresponding formal group law generate the whole coefficient ring
$\varOmega_W^*[\mathcal P^{-1}]$.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 20:35:29 GMT""}]","2022-12-12"
"2212.04553","Ciaran Schembri","Oana Padurariu and Ciaran Schembri","Rational points on Atkin-Lehner quotients of geometrically hyperelliptic
  Shimura curves","23 pages. Comments welcome!",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  Guo and Yang give defining equations for all geometrically hyperelliptic
Shimura curves $X_0(D,N)$. In this paper we compute the $\mathbb{Q}$-rational
points on the Atkin-Lehner quotients of these curves using a variety of
techniques. We also determine which rational points are CM for many of these
curves.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 20:36:22 GMT""}]","2022-12-12"
"2212.04554","Aidan Curtis","Aidan Curtis, Leslie Kaelbling, Siddarth Jain","Task-Directed Exploration in Continuous POMDPs for Robotic Manipulation
  of Articulated Objects",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Representing and reasoning about uncertainty is crucial for autonomous agents
acting in partially observable environments with noisy sensors. Partially
observable Markov decision processes (POMDPs) serve as a general framework for
representing problems in which uncertainty is an important factor. Online
sample-based POMDP methods have emerged as efficient approaches to solving
large POMDPs and have been shown to extend to continuous domains. However,
these solutions struggle to find long-horizon plans in problems with
significant uncertainty. Exploration heuristics can help guide planning, but
many real-world settings contain significant task-irrelevant uncertainty that
might distract from the task objective. In this paper, we propose STRUG, an
online POMDP solver capable of handling domains that require long-horizon
planning with significant task-relevant and task-irrelevant uncertainty. We
demonstrate our solution on several temporally extended versions of toy POMDP
problems as well as robotic manipulation of articulated objects using a neural
perception frontend to construct a distribution of possible models. Our results
show that STRUG outperforms the current sample-based online POMDP solvers on
several tasks.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 20:37:02 GMT""}]","2022-12-12"
"2212.04555","Takahiro Tsumura","Takahiro Tsumura and Seiji Yamada","Influence of anthropomorphic agent on human empathy through games","17 pages, 12 figures, 5 tables, submitted IEEE Access. arXiv admin
  note: substantial text overlap with arXiv:2206.06128","in IEEE Access, vol. 11, pp. 40412-40429, 2023","10.1109/ACCESS.2023.3269301",,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The social acceptance of AI agents, including intelligent virtual agents and
physical robots, is becoming more important for the integration of AI into
human society. Although the agents used in human society share various tasks
with humans, their cooperation may frequently reduce the task performance. One
way to improve the relationship between humans and AI agents is to have humans
empathize with the agents. By empathizing, humans feel positively and kindly
toward agents, which makes it easier to accept them. In this study, we focus on
tasks in which humans and agents have various interactions together, and we
investigate the properties of agents that significantly influence human empathy
toward the agents. To investigate the effects of task content, difficulty, task
completion, and an agent's expression on human empathy, two experiments were
conducted. The results of the two experiments showed that human empathy toward
the agent was difficult to maintain with only task factors, and that the
agent's expression was able to maintain human empathy. In addition, a higher
task difficulty reduced the decrease in human empathy, regardless of task
content. These results demonstrate that an AI agent's properties play an
important role in helping humans accept them.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 20:38:01 GMT""}]","2023-05-01"
"2212.04556","Shin-Ichi Tanigawa","Ryoshun Oba and Shin-ichi Tanigawa","Super Stable Tensegrities and Colin de Verdi\`{e}re Number $\nu$",,,,,"math.CO math.MG","http://creativecommons.org/licenses/by/4.0/","  A super stable tensegrity introduced by Connelly in 1982 is a globally rigid
discrete structure made from stiff bars or struts connected by cables with
tension. In this paper we show an exact relation between the maximum dimension
that a multigraph can be realized as a super stable tensegrity and Colin de
Verdi\`{e}re number~$\nu$ from spectral graph theory. As a corollary we obtain
a combinatorial characterization of multigraphs that can be realized as
3-dimensional super stable tensegrities.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 20:38:59 GMT""}]","2022-12-12"
"2212.04557","Kielan Hoch","Kielan K. W. Hoch, Quinn M. Konopacky, Christopher A. Theissen,
  Jean-Baptiste Ruffio, Travis S. Barman, Marshall D. Perrin, Bruce Macintosh,
  and Christian Marois","Assessing the C/O Ratio Formation Diagnostic: A Potential Trend with
  Companion Mass","20 pages, 12 figures",,,,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The carbon-to-oxygen (C/O) ratio in an exoplanet atmosphere has been
suggested as a potential diagnostic of planet formation. Now that a number of
exoplanets have measured C/O ratios, it is possible to examine this diagnostic
at a population level. Here, we present an analysis of currently measured C/O
ratios of directly imaged and transit/eclipse planets. First, we derive
atmospheric parameters for the substellar companion HD 284149 b using data that
were taken with the OSIRIS integral field spectrograph at the W.M. Keck
Observatory and report two non-detections from our ongoing imaging spectroscopy
survey of exoplanetary atmospheres with Keck/OSIRIS. We find an effective
temperature of $T_\mathrm{eff} = 2502$~K, with a range of 2291--2624~K, $\log
g=4.52$, with a range of 4.38--4.91, and [M/H] = 0.37, with a range of
0.10--0.55. These values are in agreement with previous studies done by
Bonavita et al. (2014, 2017). We derive a C/O of 0.589$^{+0.148}_{-0.295}$ for
HD 284149 b. We then add this measurement to the growing list of C/O ratios for
directly imaged planets from the literature, and compare them with those
available from a sample of transit/eclipse planets. There is a trend in C/O
ratio with companion mass (M$_{\mathrm{Jup}}$), with a break seen around 4
M$_{\mathrm{Jup}}$. We run a Kolmogorov-Smirnov and an Anderson-Darling test on
planets above and below this mass boundary, and find that they are two distinct
populations. This could be additional evidence of two distinct populations
possibly having two different formation pathways, with companion mass as a
primary indicator of most likely formation scenario.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 20:40:53 GMT""}]","2022-12-12"
"2212.04558","Charles Frohman","Charles Frohman, Joanna Kania-Bartoszynska, and Thang Le","Skein Algebras of Three-Manifolds at 4th Roots of Unity","22 pages, 6 figures",,,,"math.GT math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces an algebra structure on the part of the skein module of
an arbitrary $3$-manifold $M$ spanned by links that represent $0$ in
$H_1(M;\mathbb{Z}_2)$ when the value of the parameter used in the Kauffman
bracket skein relation is equal to $\pm {\bf i}$. It is proved that if $M$ has
no $2$-torsion in $H_1(M;\mathbb{Z})$ then those algebras, $K_{\pm {\bf
i}}^0(M)$, are naturally isomorphic to the corresponding algebras when the
value of the parameter is $\pm 1$. This implies that the algebra $K_{\pm{\bf
i}}^0(M)$ is the unreduced coordinate ring of the variety of
$PSL_2(\mathbb{C})$-characters of $\pi_1(M)$ that lift to
$SL_2(\mathbb{C})$-representations.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 20:58:10 GMT""}]","2022-12-12"
"2212.04559","Soumi Maiti","Soumi Maiti, Yifan Peng, Takaaki Saeki, Shinji Watanabe","SpeechLMScore: Evaluating speech generation using speech language model",,,,,"eess.AS cs.LG cs.SD","http://creativecommons.org/licenses/by/4.0/","  While human evaluation is the most reliable metric for evaluating speech
generation systems, it is generally costly and time-consuming. Previous studies
on automatic speech quality assessment address the problem by predicting human
evaluation scores with machine learning models. However, they rely on
supervised learning and thus suffer from high annotation costs and domain-shift
problems. We propose SpeechLMScore, an unsupervised metric to evaluate
generated speech using a speech-language model. SpeechLMScore computes the
average log-probability of a speech signal by mapping it into discrete tokens
and measures the average probability of generating the sequence of tokens.
Therefore, it does not require human annotation and is a highly scalable
framework. Evaluation results demonstrate that the proposed metric shows a
promising correlation with human evaluation scores on different speech
generation tasks including voice conversion, text-to-speech, and speech
enhancement.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 21:00:15 GMT""}]","2022-12-12"
"2212.04560","Anwarul Islam Sifat","Satyaprajna Sahoo, Anwarul Islam Sifat and Anamitra Pal","Data-Driven Flow and Injection Estimation in PMU-Unobservable
  Transmission Systems","5 pages, 1 figure",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by-sa/4.0/","  Fast and accurate knowledge of power flows and power injections is needed for
a variety of applications in the electric grid. Phasor measurement units (PMUs)
can be used to directly compute them at high speeds; however, a large number of
PMUs will be needed for computing all the flows and injections. Similarly, if
they are calculated from the outputs of a linear state estimator, then their
accuracy will deteriorate due to the quadratic relationship between voltage and
power. This paper employs machine learning to perform fast and accurate flow
and injection estimation in power systems that are sparsely observed by PMUs.
We train a deep neural network (DNN) to learn the mapping function between PMU
measurements and power flows/injections. The relation between power flows and
injections is incorporated into the DNN by adding a linear constraint to its
loss function. The results obtained using the IEEE 118-bus system indicate that
the proposed approach performs more accurate flow/injection estimation in
severely unobservable power systems compared to other data-driven methods.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 21:00:50 GMT""}]","2022-12-12"
"2212.04561","Ian Banfield","Ian M. Banfield","Christoffel words and the strong Fox conjecture for two-bridge knots","19 pages; 9 figures",,,,"math.GT math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The trapezoidal Fox conjecture states that the coefficient sequence of the
Alexander polynomial of an alternating knot is unimodal. We are motivated by a
harder question, the strong Fox conjecture, which asks whether the coefficient
sequence of the Alexander polynomial of alternating knots is actually
log-concave. Our approach is to introduce a polynomial $\Delta(t)$ associated
to a Christoffel word and to prove that its coefficient sequence is
log-concave. This implies the strong Fox conjecture for two-bridge knots.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 21:02:42 GMT""}]","2022-12-12"
"2212.04562","T.G Zlosnik","Tomi S Koivisto, Tom Zlosnik","Paths to gravitation via the gauging of parameterized field theories","Citations and content added",,"10.1103/PhysRevD.107.124013",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In special-relativistic physics, spacetime is imbued with a fixed,
non-dynamical metric tensor. A path to gravitational theory is to promote this
tensor to a genuine dynamical field. An alternative description of
special-relativistic physics involves no fixed geometry but instead the
inclusion of scalar fields $X^{I}(x^{\mu})$ which dynamically may take the form
of inertial coordinates in spacetime. This suggests an alternative approach to
gravity where the invariance of actions under global Poincar\'{e}
transformations of $X^{I}$ is promoted to either a local Poincar\'{e} or local
Lorentz symmetry via the introduction of gauge fields. Points of commonality
and departure of the resulting gravitational theories as compared to General
Relativity are discussed. It is shown that the model based on local Lorentz
symmetry is an extension of General Relativity that can introduce a standard of
time into the dynamics of the gravitational field and allows for spacetimes
described by a Minkowski metric or flat Euclidean signature metric despite the
gravitational gauge field possessing non-zero curvature.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 21:03:59 GMT""},{""version"":""v2"",""created"":""Thu, 8 Jun 2023 16:38:46 GMT""}]","2023-06-09"
"2212.04563","Harsiddh Kalariya","Harsiddh Kalariya, Kavish Shah and Vini Patel","An SLR on Edge Computing Security and possible threat protection",,,,,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  Mobile and Internet of Things devices are generating enormous amounts of
multi-modal data due to their exponential growth and accessibility. As a
result, these data sources must be directly analyzed in real time at the
network edge rather than relying on the cloud. Significant processing power at
the network's edge has made it possible to gather data and make decisions prior
to data being sent to the cloud. Moreover, security problems have significantly
towered as a result of the rapid expansion of mobile devices, Internet of
Things (IoT) devices, and various network points. It's much harder than ever to
guarantee the privacy of sensitive data, including customer information. This
systematic literature review depicts the fact that new technologies are a great
weapon to fight with the attack and threats to the edge computing security.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 21:10:20 GMT""}]","2022-12-12"
"2212.04564","Jongwon Park","Jongwon Park, Massimo Ricotti and Kazuyuki Sugimura","Population III star formation in an X-ray background: III. Periodic
  radiative feedback and luminosity induced by elliptical orbits","Submitted to MNRAS. Movies are available at
  https://jwpark5064.github.io/ or https://www.youtube.com/@jp_astro_simulation",,"10.1093/mnras/stad895",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We model Pop III star formation in different FUV and X-ray backgrounds,
including radiation feedback from protostars. We confirm previous results that
a moderate X-ray background increases the number of Pop III systems per unit
cosmological volume, but masses and multiplicities of the system are reduced.
The stellar mass function also agrees with previous results, and we confirm the
outward migration of the stars within the protostellar discs. We find that
nearly all Pop III star systems are hierarchical, i.e., binaries of binaries.
Typically, two equal-mass stars form near the centre of the protostellar disc
and migrate outward. Around these stars, mini-discs fragment forming binaries
that also migrate outward. Stars may also form at Lagrange points L4/L5 of the
system. Afterward, star formation becomes more stochastic due to the large
multiplicity, and zero-metallicity low-mass stars can form when rapidly ejected
from the disc. Stars in the disc often have eccentric orbits, leading to a
periodic modulation of their accretion rates and luminosities. At the
pericenter, due to strong accretion, the star can enter a red-supergiant phase
reaching nearly Eddington luminosity in the optical bands ($m_{\rm AB} \sim 34$
for a $100~M_{odot}$ star at $z=6$). During this phase, the star, rather than
its nebular lines, can be observed directly by JWST, if sufficiently magnified
by a gravitational lens. The $\sim 10,000$ AU separations and high
eccentricities of many Pop III star binaries in our simulations are favorable
parameters for IMBH mergers - and gravitational waves emission - through
orbital excitation by field stars.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 21:11:30 GMT""}]","2023-04-05"
"2212.04565","Rebekah Herrman","Rebekah Herrman and Stephen G. Z. Smith","A Proof of the Grundy domination strong product conjecture","There is an error. Some cases were not considered in the proof of
  Theorem 1",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  The Grundy domination number of a simple graph $G = (V,E)$ is the length of
the longest sequence of unique vertices $S = (v_1, \ldots, v_k)$, $v_i \in V$,
that satisfies the property $N[v_i] \setminus \cup_{j=1}^{i-1}N[v_j] \neq
\emptyset$ for each $i \in [k]$. Here, $N(v) = \{u : uv \in E\}$ and $N[v] =
N(v) \cup \{v\}$. In this note, we prove a recent conjecture about the Grundy
domination number of the strong product of two graphs. We then discuss how this
result relates to the zero forcing number of the strong product of graphs.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 21:12:44 GMT""},{""version"":""v2"",""created"":""Thu, 12 Jan 2023 20:47:17 GMT""}]","2023-01-16"
"2212.04566","Pei Zeng","Pei Zeng, Jinzhao Sun, Liang Jiang and Qi Zhao","Simple and high-precision Hamiltonian simulation by compensating Trotter
  error with linear combination of unitary operations","74 pages, 15 figures. Comments are welcome",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Trotter and linear-combination-of-unitary (LCU) are two popular Hamiltonian
simulation methods. We propose Hamiltonian simulation algorithms using LCU to
compensate Trotter error, which enjoy both of their advantages. By adding few
gates after the Kth-order Trotter, we realize a better time scaling than
2Kth-order Trotter. Our first algorithm exponentially improves the accuracy
scaling of the Kth-order Trotter formula. In the second algorithm, we consider
the detailed structure of Hamiltonians and construct LCU for Trotter errors
with commutator scaling. Consequently, for lattice Hamiltonians, the algorithm
enjoys almost linear system-size dependence and quadratically improves the
accuracy of the Kth-order Trotter.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 21:14:12 GMT""}]","2022-12-12"
"2212.04567","Yanhua Liu Ms","Yanhua Liu, Xitong Zhang, Ilya Tsvankin, and Youzuo Lin","Enhanced prediction accuracy with uncertainty quantification in
  monitoring CO2 sequestration using convolutional neural networks","42 pages (double-space), 14 figures, 1 table",,,,"physics.geo-ph cs.LG","http://creativecommons.org/licenses/by/4.0/","  Monitoring changes inside a reservoir in real time is crucial for the success
of CO2 injection and long-term storage. Machine learning (ML) is well-suited
for real-time CO2 monitoring because of its computational efficiency. However,
most existing applications of ML yield only one prediction (i.e., the
expectation) for a given input, which may not properly reflect the distribution
of the testing data, if it has a shift with respect to that of the training
data. The Simultaneous Quantile Regression (SQR) method can estimate the entire
conditional distribution of the target variable of a neural network via pinball
loss. Here, we incorporate this technique into seismic inversion for purposes
of CO2 monitoring. The uncertainty map is then calculated pixel by pixel from a
particular prediction interval around the median. We also propose a novel
data-augmentation method by sampling the uncertainty to further improve
prediction accuracy. The developed methodology is tested on synthetic
Kimberlina data, which are created by the Department of Energy and based on a
CO2 capture and sequestration (CCS) project in California. The results prove
that the proposed network can estimate the subsurface velocity rapidly and with
sufficient resolution. Furthermore, the computed uncertainty quantifies the
prediction accuracy. The method remains robust even if the testing data are
distorted due to problems in the field data acquisition. Another test
demonstrates the effectiveness of the developed data-augmentation method in
increasing the spatial resolution of the estimated velocity field and in
reducing the prediction error.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 21:25:20 GMT""}]","2022-12-12"
"2212.04568","Emma Curtis-Lake Dr.","Emma Curtis-Lake, Stefano Carniani, Alex Cameron, Stephane Charlot,
  Peter Jakobsen, Roberto Maiolino, Andrew Bunker, Joris Witstok, Renske Smit,
  Jacopo Chevallard, Chris Willott, Pierre Ferruit, Santiago Arribas, Nina
  Bonaventura, Mirko Curti, Francesco D'Eugenio, Marijn Franx, Giovanna
  Giardino, Tobias J. Looser, Nora L\""utzgendorf, Michael V. Maseda, Tim Rawle,
  Hans-Walter Rix, Bruno Rodriguez del Pino, Hannah \""Ubler, Marko Sirianni,
  Alan Dressler, Eiichi Egami, Daniel J. Eisenstein, Ryan Endsley, Kevin
  Hainline, Ryan Hausen, Benjamin D. Johnson, Marcia Rieke, Brant Robertson,
  Irene Shivaei, Daniel P. Stark, Sandro Tacchella, Christina C. Williams,
  Christopher N. A. Willmer, Rachana Bhatawdekar, Rebecca Bowler, Kristan
  Boyett, Zuyi Chen, Anna de Graaff, Jakob M. Helton, Raphael E. Hviding,
  Gareth C. Jones, Nimisha Kumari, Jianwei Lyu, Erica Nelson, Michele Perna,
  Lester Sandles, Aayush Saxena, Katherine A. Suess, Fengwu Sun, Michael W.
  Topping, Imaan E. B. Wallace, Lily Whitler","Spectroscopic confirmation of four metal-poor galaxies at z=10.3-13.2","32 pages, 8 figures, accepted to Nature Astronomy",,,,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Finding and characterising the first galaxies that illuminated the early
Universe at cosmic dawn is pivotal to understand the physical conditions and
the processes that led to the formation of the first stars. In the first few
months of operations, imaging from the James Webb Space Telescope (JWST) have
been used to identify tens of candidates of galaxies at redshift (z) greater
than 10, less than 450 million years after the Big Bang. However, none of these
candidates has yet been confirmed spectroscopically, leaving open the
possibility that they are actually low-redshift interlopers. Here we present
spectroscopic confirmation and analysis of four galaxies unambiguously detected
at redshift 10.3<z<13.2, previously selected from NIRCam imaging. The spectra
reveal that these primeval galaxies are extremely metal poor, have masses
between 10^7 and a few times 10^8 solar masses, and young ages. The damping
wings that shape the continuum close to the Lyman edge are consistent with a
fully neutral intergalactic medium at this epoch. These findings demonstrate
the rapid emergence of the first generations of galaxies at cosmic dawn.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 21:28:48 GMT""},{""version"":""v2"",""created"":""Mon, 27 Feb 2023 10:55:59 GMT""}]","2023-02-28"
"2212.04569","Pedro Jorge Freire De Carvalho Souza Mr","Sasipim Srivallapanondh, Pedro J. Freire, Bernhard Spinnler, Nelson
  Costa, Antonio Napoli, Sergei K. Turitsyn, Jaroslaw E. Prilepsky","Knowledge Distillation Applied to Optical Channel Equalization: Solving
  the Parallelization Problem of Recurrent Connection","Paper Accepted for Oral presentation - OFC 2023 (Optical Fiber
  Communication Conference)",,,,"eess.SP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To circumvent the non-parallelizability of recurrent neural network-based
equalizers, we propose knowledge distillation to recast the RNN into a
parallelizable feedforward structure. The latter shows 38\% latency decrease,
while impacting the Q-factor by only 0.5dB.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 21:31:13 GMT""}]","2022-12-12"
"2212.04570","Alireza Mofidi","Alireza Mofidi","On dominating graph of graphs, median graphs and partial cubes, and
  graphs in which complement of every minimal dominating set is minimal
  dominating",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The dominating graph of a graph G is a graph whose vertices correspond to the
dominating sets of G and two vertices are adjacent whenever their corresponding
dominating sets differ in exactly one vertex. Studying properties of dominating
graph has become an increasingly interesting subject in domination theory. On
the other hand, median graphs and partial cubes are two fundamental graph
classes in graph theory. In this paper, we make some new connections between
domination theory and the theory of median graphs and partial cubes. As the
main result, we show that the following conditions are equivalent for every
graph $G \not \simeq C_4$ with no isolated vertex, and in particular, that the
simple third condition completely characterizes first two ones in which three
concepts of dominating graphs, median graphs and complement of minimal
dominating sets get related:
  - The dominating graph of G is a median graph,
  - The complement of every minimal dominating set of G is a minimal dominating
set,
  - Every vertex of G is either of degree 1 or adjacent to a vertex of degree
1.
  As another result, we prove that the dominating graph of every graph is a
partial cube and also give some examples to show that not all partial cubes or
median graphs are isomorphic to the dominating graph of a graph. The
above-mentioned results, as another highlight of the paper, provide novel
infinite sources of examples of median graphs and partial cubes.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 21:37:12 GMT""}]","2022-12-12"
"2212.04571","Hadar Steinberg","T. R. Devidas, Tom Dvir, Enrico Rossi, Hadar Steinberg","Kondo Effect in Defect-bound Quantum Dots Coupled to NbSe$_2$",,,"10.1103/PhysRevB.107.094502",,"cond-mat.mes-hall cond-mat.mtrl-sci cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  We report the fabrication of a van der Waals tunneling device hosting a
defect-bound quantum dot coupled to NbSe$_2$. We find that upon application of
magnetic field, the device exhibits a zero-bias conductance peak. The peak,
which splits at higher fields, is associated with a Kondo effect. At the same
time, the junction retains conventional quasiparticle tunneling features at
finite bias. Such coexistence of a superconducting gap and a Kondo effect are
unusual, and are explained by noting the two-gap nature of the superconducting
state of NbSe$_2$, where a magnetic field suppresses the low energy gap
associated with the Se band. Our data shows that van der Waals architectures,
and defect-bound dots in them, can serve as a novel and effective platform for
investigating the interplay of Kondo screening and superconducting pairing in
unconventional superconductors.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 21:37:39 GMT""}]","2023-03-15"
"2212.04572","Pablo Delgado M.","Pablo M. Delgado and J\""urgen Herre","A Data-driven Cognitive Salience Model for Objective Perceptual Audio
  Quality Assessment","Accepted version of the paper submitted to ICASSP 2020","ICASSP 2022 - 2022 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP), 2022, pp. 986-990","10.1109/ICASSP43922.2022.9747064.",,"eess.AS cs.SD eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Objective audio quality measurement systems often use perceptual models to
predict the subjective quality scores of processed signals, as reported in
listening tests. Most systems map different metrics of perceived degradation
into a single quality score predicting subjective quality. This requires a
quality mapping stage that is informed by real listening test data using
statistical learning (i.e., a data-driven approach) with distortion metrics as
input features. However, the amount of reliable training data is limited in
practice, and usually not sufficient for a comprehensive training of large
learning models. Models of cognitive effects in objective systems can, however,
improve the learning model. Specifically, considering the salience of certain
distortion types, they provide additional features to the mapping stage that
improve the learning process, especially for limited amounts of training data.
We propose a novel data-driven salience model that informs the quality mapping
stage by explicitly estimating the cognitive/degradation metric interactions
using a salience measure. Systems incorporating the novel salience model are
shown to outperform equivalent systems that only use statistical learning to
combine cognitive and degradation metrics, as well as other well-known
measurement systems, for a representative validation dataset.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 21:40:01 GMT""}]","2022-12-12"
"2212.04573","Yifan Zhou","Yifan Zhou, Shubham Sonawani, Mariano Phielipp, Simon Stepputtis, Heni
  Ben Amor","Modularity through Attention: Efficient Training and Transfer of
  Language-Conditioned Policies for Robot Manipulation","2022 Conference on Robot Learning (CoRL)",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Language-conditioned policies allow robots to interpret and execute human
instructions. Learning such policies requires a substantial investment with
regards to time and compute resources. Still, the resulting controllers are
highly device-specific and cannot easily be transferred to a robot with
different morphology, capability, appearance or dynamics. In this paper, we
propose a sample-efficient approach for training language-conditioned
manipulation policies that allows for rapid transfer across different types of
robots. By introducing a novel method, namely Hierarchical Modularity, and
adopting supervised attention across multiple sub-modules, we bridge the divide
between modular and end-to-end learning and enable the reuse of functional
building blocks. In both simulated and real world robot manipulation
experiments, we demonstrate that our method outperforms the current
state-of-the-art methods and can transfer policies across 4 different robots in
a sample-efficient manner. Finally, we show that the functionality of learned
sub-modules is maintained beyond the training process and can be used to
introspect the robot decision-making process. Code is available at
https://github.com/ir-lab/ModAttn.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 21:42:53 GMT""}]","2022-12-12"
"2212.04574","Joshua Kavner","Hadi Hosseini, Joshua Kavner, Sujoy Sikdar, Rohit Vaish, Lirong Xia","Hide, Not Seek: Perceived Fairness in Envy-Free Allocations of
  Indivisible Goods","20 pages, 10 figures",,,,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fair division provides a rich computational and mathematical framework for
the allocation of indivisible goods, which has given rise to numerous fairness
concepts and their relaxations. In recent years, much attention has been given
to theoretical and computational aspects of various fairness concepts.
Nonetheless, the choice of which fairness concept is in practice perceived to
be fairer by individuals is not well understood. We consider two conceptually
different relaxations of envy-freeness and investigate how individuals perceive
the induced allocations as fair. In particular, we examine a well-studied
relaxation of envy-freeness up to one good (EF1) which is based on
counterfactual thinking that any pairwise envy can be eliminated by the
hypothetical removal of a single good from the envied agent's bundle. In
contrast, a recently proposed epistemic notion, namely envy-freeness up to $k$
hidden goods (HEF-$k$), provides a relaxation by hiding information about a
small subset of $k$ goods. Through various crowdsourcing experiments, we
empirically demonstrate that allocations achieved by withholding information
are perceived to be fairer compared to two variants of EF1.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 21:43:27 GMT""},{""version"":""v2"",""created"":""Sat, 21 Jan 2023 04:02:06 GMT""}]","2023-01-24"
"2212.04575","Xiangyu Xu","Xiangyu Xu, Li Guan, Enrique Dunn, Haoxiang Li, Gang Hua","DDM-NET: End-to-end learning of keypoint feature Detection, Description
  and Matching for 3D localization",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose an end-to-end framework that jointly learns
keypoint detection, descriptor representation and cross-frame matching for the
task of image-based 3D localization. Prior art has tackled each of these
components individually, purportedly aiming to alleviate difficulties in
effectively train a holistic network. We design a self-supervised image warping
correspondence loss for both feature detection and matching, a
weakly-supervised epipolar constraints loss on relative camera pose learning,
and a directional matching scheme that detects key-point features in a source
image and performs coarse-to-fine correspondence search on the target image. We
leverage this framework to enforce cycle consistency in our matching module. In
addition, we propose a new loss to robustly handle both definite inlier/outlier
matches and less-certain matches. The integration of these learning mechanisms
enables end-to-end training of a single network performing all three
localization components. Bench-marking our approach on public data-sets,
exemplifies how such an end-to-end framework is able to yield more accurate
localization that out-performs both traditional methods as well as
state-of-the-art weakly supervised methods.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 21:43:56 GMT""},{""version"":""v2"",""created"":""Wed, 1 Feb 2023 20:48:47 GMT""}]","2023-02-03"
"2212.04576","Duo Xu","Duo Xu, Faramarz Fekri","Generalizing LTL Instructions via Future Dependent Options",,,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  In many real-world applications of control system and robotics, linear
temporal logic (LTL) is a widely-used task specification language which has a
compositional grammar that naturally induces temporally extended behaviours
across tasks, including conditionals and alternative realizations. An important
problem in RL with LTL tasks is to learn task-conditioned policies which can
zero-shot generalize to new LTL instructions not observed in the training.
However, because symbolic observation is often lossy and LTL tasks can have
long time horizon, previous works can suffer from issues such as training
sampling inefficiency and infeasibility or sub-optimality of the found
solutions. In order to tackle these issues, this paper proposes a novel
multi-task RL algorithm with improved learning efficiency and optimality. To
achieve the global optimality of task completion, we propose to learn options
dependent on the future subgoals via a novel off-policy approach. In order to
propagate the rewards of satisfying future subgoals back more efficiently, we
propose to train a multi-step value function conditioned on the subgoal
sequence which is updated with Monte Carlo estimates of multi-step discounted
returns. In experiments on three different domains, we evaluate the LTL
generalization capability of the agent trained by the proposed method, showing
its advantage over previous representative methods.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 21:44:18 GMT""},{""version"":""v2"",""created"":""Tue, 13 Dec 2022 04:29:02 GMT""},{""version"":""v3"",""created"":""Thu, 15 Dec 2022 12:52:01 GMT""}]","2022-12-16"
"2212.04577","Emily Tucker","Anisa Young, Emily L. Tucker, Mariela Fernandez, David White, Robert
  Brookover, Brandon Harris","An Optimization Approach to Improve Equitable Access to Local Parks",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Local parks are public resources that promote human and environmental
welfare. Unfortunately, park inequities are commonplace as historically
marginalized groups may have insufficient access. Platforms exist to identify
the geographical areas that would benefit from future park improvements.
However, these platforms do not include budget, infrastructure, and
environmental considerations that are relevant to park location decisions. To
support recreational and government agencies in addressing inequities in the
distribution and quality of parks, we propose a mixed-integer program that
minimizes insufficient access, defined as weighted deviations across multiple
categories. We consider an equity-focused min-max objective and an overall
objective to minimize total weighted deviations. We apply the model to a case
study of Asheville, North Carolina. We conduct extensive data collection to
parameterize the model. In policy analyses, we consider the effects of
available budget, planning horizons, strategic demographic priorities, and
thresholds of access. The model reflects user-defined criteria and goals, and
the results suggest that the framework may be generalizable to other cities.
This study serves as the first step in the development and incorporation of
mathematical modeling to achieve social goals within the recreational setting.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 21:45:26 GMT""},{""version"":""v2"",""created"":""Wed, 14 Dec 2022 15:36:55 GMT""}]","2022-12-15"
"2212.04578","Mikhail Gubin","M.Yu. Gubin, A.V. Shesterikov, V.S. Volkov, A.V. Prokhorov","Multiresonances of quasi-trapped modes in metasurfaces based on
  nanoparticles of transition metal dichalcogenides","8 pages, 5 figures",,,,"cond-mat.mes-hall physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The features of polarization control of multiple multiresonances for
quasi-trapped modes excited by synchronization of bianisotropic dipole
responses in MoS$_2$ disks with a hole are considered. Using the numerical
calculations with analytical multipole analysis, we showed that the presence of
a strong optical anisotropy of MoS$_2$ nanoparticles provides an additional
degree of freedom and allows to observe several resonances of electric and
magnetic dipoles at once in a narrow spectral range. Based on the simulation
results, we obtained the frequency dependences for the dipole polarizabilities
of the MoS$_2$ disk with a hole, which allow one to distinguish the
contributions of the nonlocal and bianisotropic dipole responses and possessing
several features in the near infrared range. Using the polarizability spectra
of single nanoparticles and applying the tuning strategy, the design of the
MoS$_2$ metasurface supporting three resonances of quasi-trapped modes at once
in a narrow spectral range was developed. One of these resonances corresponds
to the telecom wavelength of 1550 nm. The spectrum of light reflection for
MoS$_2$ metasurface is characterized by three narrowband dips corresponding to
the wavelengths of the quasi-trapped modes. It was shown that a change in the
polarization of a wave normally incident on the metasurface to orthogonal one
leads to a change in the type of bianisotropic response excited in each MoS$_2$
disk and to the excitation of three other features in the reflection spectra of
the metasurface at wavelengths close to the initial values.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 21:51:24 GMT""},{""version"":""v2"",""created"":""Wed, 28 Dec 2022 12:18:48 GMT""}]","2022-12-29"
"2212.04579","Javid Abderezaei","Javid Abderezaei, Aymeric Pionteck, Agamdeep Chopra, Mehmet Kurt","3D Inception-Based TransMorph: Pre- and Post-operative Multi-contrast
  MRI Registration in Brain Tumors","Contribution to the BraTS-Reg Challenge at MICCAI conference",,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Deformable image registration is a key task in medical image analysis. The
Brain Tumor Sequence Registration challenge (BraTS-Reg) aims at establishing
correspondences between pre-operative and follow-up scans of the same patient
diagnosed with an adult brain diffuse high-grade glioma and intends to address
the challenging task of registering longitudinal data with major tissue
appearance changes. In this work, we proposed a two-stage cascaded network
based on the Inception and TransMorph models. The dataset for each patient was
comprised of a native pre-contrast (T1), a contrast-enhanced T1-weighted
(T1-CE), a T2-weighted (T2), and a Fluid Attenuated Inversion Recovery (FLAIR).
The Inception model was used to fuse the 4 image modalities together and
extract the most relevant information. Then, a variant of the TransMorph
architecture was adapted to generate the displacement fields. The Loss function
was composed of a standard image similarity measure, a diffusion regularizer,
and an edge-map similarity measure added to overcome intensity dependence and
reinforce correct boundary deformation. We observed that the addition of the
Inception module substantially increased the performance of the network.
Additionally, performing an initial affine registration before training the
model showed improved accuracy in the landmark error measurements between pre
and post-operative MRIs. We observed that our best model composed of the
Inception and TransMorph architectures while using an initially affine
registered dataset had the best performance with a median absolute error of
2.91 (initial error = 7.8). We achieved 6th place at the time of model
submission in the final testing phase of the BraTS-Reg challenge.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 22:00:07 GMT""}]","2022-12-12"
"2212.04580","Steven Durr","Steven Durr, Youssef Mroueh, Yuhai Tu, and Shenshen Wang","Effective Dynamics of Generative Adversarial Networks","19 pages, 21 figures",,,,"cond-mat.dis-nn cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generative adversarial networks (GANs) are a class of machine-learning models
that use adversarial training to generate new samples with the same
(potentially very complex) statistics as the training samples. One major form
of training failure, known as mode collapse, involves the generator failing to
reproduce the full diversity of modes in the target probability distribution.
Here, we present an effective model of GAN training, which captures the
learning dynamics by replacing the generator neural network with a collection
of particles in the output space; particles are coupled by a universal kernel
valid for certain wide neural networks and high-dimensional inputs. The
generality of our simplified model allows us to study the conditions under
which mode collapse occurs. Indeed, experiments which vary the effective kernel
of the generator reveal a mode collapse transition, the shape of which can be
related to the type of discriminator through the frequency principle. Further,
we find that gradient regularizers of intermediate strengths can optimally
yield convergence through critical damping of the generator dynamics. Our
effective GAN model thus provides an interpretable physical framework for
understanding and improving adversarial training.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 22:04:01 GMT""}]","2022-12-12"
"2212.04581","Onur Beker","Onur Beker, Mohammad Mohammadi, Amir Zamir","PALMER: Perception-Action Loop with Memory for Long-Horizon Planning","Website: https://palmer.epfl.ch",,,,"cs.RO cs.AI cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  To achieve autonomy in a priori unknown real-world scenarios, agents should
be able to: i) act from high-dimensional sensory observations (e.g., images),
ii) learn from past experience to adapt and improve, and iii) be capable of
long horizon planning. Classical planning algorithms (e.g. PRM, RRT) are
proficient at handling long-horizon planning. Deep learning based methods in
turn can provide the necessary representations to address the others, by
modeling statistical contingencies between observations. In this direction, we
introduce a general-purpose planning algorithm called PALMER that combines
classical sampling-based planning algorithms with learning-based perceptual
representations. For training these perceptual representations, we combine
Q-learning with contrastive representation learning to create a latent space
where the distance between the embeddings of two states captures how easily an
optimal policy can traverse between them. For planning with these perceptual
representations, we re-purpose classical sampling-based planning algorithms to
retrieve previously observed trajectory segments from a replay buffer and
restitch them into approximately optimal paths that connect any given pair of
start and goal states. This creates a tight feedback loop between
representation learning, memory, reinforcement learning, and sampling-based
planning. The end result is an experiential framework for long-horizon planning
that is significantly more robust and sample efficient compared to existing
methods.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 22:11:49 GMT""}]","2022-12-12"
"2212.04582","Nicol\'as Ayobi","Natalia Valderrama, Paola Ruiz Puentes, Isabela Hern\'andez, Nicol\'as
  Ayobi, Mathilde Verlyk, Jessica Santander, Juan Caicedo, Nicol\'as
  Fern\'andez, Pablo Arbel\'aez","Towards Holistic Surgical Scene Understanding","MICCAI 2022 Oral",,"10.1007/978-3-031-16449-1_42",,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most benchmarks for studying surgical interventions focus on a specific
challenge instead of leveraging the intrinsic complementarity among different
tasks. In this work, we present a new experimental framework towards holistic
surgical scene understanding. First, we introduce the Phase, Step, Instrument,
and Atomic Visual Action recognition (PSI-AVA) Dataset. PSI-AVA includes
annotations for both long-term (Phase and Step recognition) and short-term
reasoning (Instrument detection and novel Atomic Action recognition) in
robot-assisted radical prostatectomy videos. Second, we present Transformers
for Action, Phase, Instrument, and steps Recognition (TAPIR) as a strong
baseline for surgical scene understanding. TAPIR leverages our dataset's
multi-level annotations as it benefits from the learned representation on the
instrument detection task to improve its classification capacity. Our
experimental results in both PSI-AVA and other publicly available databases
demonstrate the adequacy of our framework to spur future research on holistic
surgical scene understanding.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 22:15:27 GMT""},{""version"":""v2"",""created"":""Tue, 13 Dec 2022 03:46:32 GMT""},{""version"":""v3"",""created"":""Sat, 18 Mar 2023 19:23:05 GMT""}]","2023-03-21"
"2212.04583","Grant Davidson","Grant Davidson, Mark Vinton, Per Ekstrand, Cong Zhou, Lars Villemoes,
  and Lie Lu","High Quality Audio Coding with MDCTNet","Five pages, five figures",,,,"eess.AS cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a neural audio generative model, MDCTNet, operating in the
perceptually weighted domain of an adaptive modified discrete cosine transform
(MDCT). The architecture of the model captures correlations in both time and
frequency directions with recurrent layers (RNNs). An audio coding system is
obtained by training MDCTNet on a diverse set of fullband monophonic audio
signals at 48 kHz sampling, conditioned by a perceptual audio encoder. In a
subjective listening test with ten excerpts chosen to be balanced across
content types, yet stressful for both codecs, the mean performance of the
proposed system for 24 kb/s variable bitrate (VBR) is similar to that of Opus
at twice the bitrate.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 22:18:20 GMT""}]","2022-12-12"
"2212.04584","Parvez Mahbub","Parvez Mahbub, Ohiduzzaman Shuvo, Mohammad Masudur Rahman","Explaining Software Bugs Leveraging Code Structures in Neural Machine
  Translation",,,,,"cs.SE","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Software bugs claim approximately 50% of development time and cost the global
economy billions of dollars. Once a bug is reported, the assigned developer
attempts to identify and understand the source code responsible for the bug and
then corrects the code. Over the last five decades, there has been significant
research on automatically finding or correcting software bugs. However, there
has been little research on automatically explaining the bugs to the
developers, which is essential but a highly challenging task. In this paper, we
propose Bugsplainer, a transformer-based generative model, that generates
natural language explanations for software bugs by learning from a large corpus
of bug-fix commits. Bugsplainer can leverage structural information and buggy
patterns from the source code to generate an explanation for a bug. Our
evaluation using three performance metrics shows that Bugsplainer can generate
understandable and good explanations according to Google's standard, and can
outperform multiple baselines from the literature. We also conduct a developer
study involving 20 participants where the explanations from Bugsplainer were
found to be more accurate, more precise, more concise and more useful than the
baselines.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 22:19:45 GMT""},{""version"":""v2"",""created"":""Mon, 2 Jan 2023 19:46:00 GMT""},{""version"":""v3"",""created"":""Thu, 16 Feb 2023 13:36:33 GMT""}]","2023-02-17"
"2212.04585","Faming Liang","Siqi Liang and Faming Liang","A Double Regression Method for Graphical Modeling of High-dimensional
  Nonlinear and Non-Gaussian Data","1 figure","Statistics and Its Interface 2023",,,"stat.ME stat.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Graphical models have long been studied in statistics as a tool for inferring
conditional independence relationships among a large set of random variables.
The most existing works in graphical modeling focus on the cases that the data
are Gaussian or mixed and the variables are linearly dependent. In this paper,
we propose a double regression method for learning graphical models under the
high-dimensional nonlinear and non-Gaussian setting, and prove that the
proposed method is consistent under mild conditions. The proposed method works
by performing a series of nonparametric conditional independence tests. The
conditioning set of each test is reduced via a double regression procedure
where a model-free sure independence screening procedure or a sparse deep
neural network can be employed. The numerical results indicate that the
proposed method works well for high-dimensional nonlinear and non-Gaussian
data.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 22:25:21 GMT""}]","2022-12-12"
"2212.04586","Weishi Wang","Weishi Wang and James D. Whitfield","Basis set generation and optimization in the NISQ era with Quiqbox.jl","15 pages, 7 figures, 5 tables, 1 listing",,,,"quant-ph cond-mat.mtrl-sci physics.chem-ph physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  In the noisy intermediate-scale quantum era, ab initio computation of the
electronic structure problem has become one of the major benchmarks for
identifying the boundary between classical and quantum computational power. The
single-particle basis set plays a key role in the electronic structure methods
implemented on both classical and quantum devices. To investigate the
consequences of the single-particle basis set, we propose a framework for more
customizable basis set generation and basis set optimization. This framework
allows configurations of composite Gaussian-type basis functions to go beyond
typical Gaussian-type basis set frameworks such as the atomic orbitals and
floating basis sets. Such basis set generations set the stage for more flexible
variational optimization of basis set parameters. To realize this framework, we
have developed an open-source electronic structure package named ``Quiqbox'' in
the Julia programming language. Both the Hartree--Fock procedure and
Gaussian-based electronic integral computations are implemented in this
package. We compare Quiqbox with the basis set optimization package DiffiQult
and find faster convergence of the basis set optimization with lower run time.
We also demonstrate the additional customizability Quiqbox brings for more
systematic basis set research with an example of constructing and optimizing
delocalized orbitals.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 22:29:04 GMT""}]","2022-12-12"
"2212.04587","Michael Pilosov PhD","Michael Pilosov, Carlos del-Castillo-Negrete, Tian Yu Yen, Troy
  Butler, Clint Dawson","Parameter Estimation with Maximal Updated Densities","Code: github.com/mathematicalmichael/mud.git",,"10.1016/j.cma.2023.115906",,"math.NA cs.NA stat.OT","http://creativecommons.org/licenses/by/4.0/","  A recently developed measure-theoretic framework solves a stochastic inverse
problem (SIP) for models where uncertainties in model output data are
predominantly due to aleatoric (i.e., irreducible) uncertainties in model
inputs (i.e., parameters). The subsequent inferential target is a distribution
on parameters. Another type of inverse problem is to quantify uncertainties in
estimates of ""true"" parameter values under the assumption that such
uncertainties should be reduced as more data are incorporated into the problem,
i.e., the uncertainty is considered epistemic. A major contribution of this
work is the formulation and solution of such a parameter identification problem
(PIP) within the measure-theoretic framework developed for the SIP. The
approach is novel in that it utilizes a solution to a stochastic forward
problem (SFP) to update an initial density only in the parameter directions
informed by the model output data. In other words, this method performs
""selective regularization"" only in the parameter directions not informed by
data. The solution is defined by a maximal updated density (MUD) point where
the updated density defines the measure-theoretic solution to the PIP. Another
significant contribution of this work is the full theory of existence and
uniqueness of MUD points for linear maps with Gaussian distributions.
Data-constructed Quantity of Interest (QoI) maps are also presented and
analyzed for solving the PIP within this measure-theoretic framework as a means
of reducing uncertainties in the MUD estimate. We conclude with a demonstration
of the general applicability of the method on two problems involving either
spatial or temporal data for estimating uncertain model parameters.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 22:31:10 GMT""},{""version"":""v2"",""created"":""Sun, 15 Jan 2023 19:04:13 GMT""},{""version"":""v3"",""created"":""Thu, 19 Jan 2023 16:29:39 GMT""}]","2023-02-15"
"2212.04588","Eliot Kapit","Eliot Kapit, Vadim Oganesyan","Small logical qubit architecture based on strong interactions and
  many-body dynamical decoupling","8 pages including supplemental information, 5 figures",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a novel superconducting logical qubit architecture, called the
Cold Echo Qubit (CEQ), which is capable of preserving quantum information for
much longer timescales than any of its component parts. The CEQ operates fully
autonomously, requiring no measurement or feedback, and is compatible with
relatively strong interaction elements, allowing for fast, high fidelity
logical gates between multiple CEQ's. Its quantum state is protected by a
combination of strong interactions and microwave driving, which implements a
form of many-body dynamical decoupling to suppress phase noise. Estimates based
on careful theoretical analysis and numerical simulations predict improvements
in lifetimes and gate fidelities by an order of magnitude or more compared to
the current state of the art, assuming no improvements in base coherence. Here,
we consider the simplest possible implementation of the CEQ, using a pair of
fluxonium qubits shunted through a shared mutual inductance. While not
necessarily the best possible implementation, it is the easiest to test
experimentally and should display coherence well past breakeven (as compared to
the limiting coherence times of its components). A more complex three-node
circuit is also presented; it is expected to roughly double the coherence of
its two-fluxonium counterpart.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 22:33:01 GMT""}]","2022-12-12"
"2212.04589","Eduardo C. Garrido-Merch\'an","Eduardo C. Garrido-Merch\'an, Javier S\'anchez-Ca\~nizares","Optimizing Integrated Information with a Prior Guided Random Search
  Algorithm",,,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  Integrated information theory (IIT) is a theoretical framework that provides
a quantitative measure to estimate when a physical system is conscious, its
degree of consciousness, and the complexity of the qualia space that the system
is experiencing. Formally, IIT rests on the assumption that if a surrogate
physical system can fully embed the phenomenological properties of
consciousness, then the system properties must be constrained by the properties
of the qualia being experienced. Following this assumption, IIT represents the
physical system as a network of interconnected elements that can be thought of
as a probabilistic causal graph, $\mathcal{G}$, where each node has an
input-output function and all the graph is encoded in a transition probability
matrix. Consequently, IIT's quantitative measure of consciousness, $\Phi$, is
computed with respect to the transition probability matrix and the present
state of the graph. In this paper, we provide a random search algorithm that is
able to optimize $\Phi$ in order to investigate, as the number of nodes
increases, the structure of the graphs that have higher $\Phi$. We also provide
arguments that show the difficulties of applying more complex black-box search
algorithms, such as Bayesian optimization or metaheuristics, in this particular
problem. Additionally, we suggest specific research lines for these techniques
to enhance the search algorithm that guarantees maximal $\Phi$.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 22:34:00 GMT""}]","2022-12-12"
"2212.04590","YiDing Jiang","Yiding Jiang, Evan Zheran Liu, Benjamin Eysenbach, Zico Kolter,
  Chelsea Finn","Learning Options via Compression","Published at NeurIPS 2022",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Identifying statistical regularities in solutions to some tasks in multi-task
reinforcement learning can accelerate the learning of new tasks. Skill learning
offers one way of identifying these regularities by decomposing pre-collected
experiences into a sequence of skills. A popular approach to skill learning is
maximizing the likelihood of the pre-collected experience with latent variable
models, where the latent variables represent the skills. However, there are
often many solutions that maximize the likelihood equally well, including
degenerate solutions. To address this underspecification, we propose a new
objective that combines the maximum likelihood objective with a penalty on the
description length of the skills. This penalty incentivizes the skills to
maximally extract common structures from the experiences. Empirically, our
objective learns skills that solve downstream tasks in fewer samples compared
to skills learned from only maximizing likelihood. Further, while most prior
works in the offline multi-task setting focus on tasks with low-dimensional
observations, our objective can scale to challenging tasks with
high-dimensional image observations.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 22:34:59 GMT""}]","2022-12-12"
"2212.04591","Chengyun Hua","Chengyun Hua, Eugene Dumitrescu, G\'abor B. Hal\'asz","Theory of the Little-Parks effect in spin-triplet superconductors",,,,,"cond-mat.supr-con","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The celebrated Little-Parks effect in mesoscopic superconducting rings has
recently gained great attention due to its potential to probe half-quantum
vortices in spin-triplet superconductors. However, despite the large number of
works reporting anomalous Little-Parks measurements attributed to
unconventional superconductivity, the general signatures of spin-triplet
pairing in the Little-Parks effect have not yet been systematically
investigated. Here we use Ginzburg-Landau theory to study the Little-Parks
effect in a spin-triplet superconducting ring that supports half-quantum
vortices; we calculate the field-induced Little-Parks oscillations of both the
critical temperature itself and the residual resistance resulting from thermal
vortex tunneling below the critical temperature. We observe two separate
critical temperatures with a single-spin superconducting state in between and
find that, due to the existence of half-quantum vortices, each minimum in the
upper critical temperature splits into two minima for the lower critical
temperature. From a rigorous calculation of the residual resistance, we confirm
that these two minima in the lower critical temperature translate into two
maxima in the residual resistance below and establish the general conditions
under which the two maxima can be practically resolved. In particular, we
identify a fundamental trade-off between sharpening each maximum and keeping
the overall magnitude of the resistance large. Our results will guide
experimental efforts in designing mesoscopic ring geometries for probing
half-quantum vortices in spin-triplet candidate materials on the device scale.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 22:39:04 GMT""}]","2022-12-12"
"2212.04592","Shiva Moshtagh","Shiva Moshtagh, Anwarul Islam Sifat, Behrouz Azimian and Anamitra Pal","Time-Synchronized State Estimation Using Graph Neural Networks in
  Presence of Topology Changes","6 pages, 2 figures",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by-sa/4.0/","  Recently, there has been a major emphasis on developing data-driven
approaches involving machine learning (ML) for high-speed static state
estimation (SE) in power systems. The emphasis stems from the ability of ML to
overcome difficulties associated with model-based approaches, such as handling
of non-Gaussian measurement noise. However, topology changes pose a stiff
challenge for performing ML-based SE because the training and test environments
become different when such changes occur. This paper circumvents this challenge
by formulating a graph neural network (GNN)-based time-synchronized state
estimator that considers the physical connections of the power system during
the training itself. The results obtained using the IEEE 118-bus system
indicate that the GNN-based state estimator outperforms both the model-based
linear state estimator and a data-driven deep neural network-based state
estimator in the presence of non-Gaussian measurement noise and topology
changes, respectively.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 22:47:03 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jun 2023 00:46:53 GMT""}]","2023-06-02"
"2212.04593","Usman Gohar","Usman Gohar, Sumon Biswas, Hridesh Rajan","Towards Understanding Fairness and its Composition in Ensemble Machine
  Learning","Accepted at ICSE 2023","ICSE 2023: The 45th International Conference on Software
  Engineering, Melbourne, Australia",,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Machine Learning (ML) software has been widely adopted in modern society,
with reported fairness implications for minority groups based on race, sex,
age, etc. Many recent works have proposed methods to measure and mitigate
algorithmic bias in ML models. The existing approaches focus on single
classifier-based ML models. However, real-world ML models are often composed of
multiple independent or dependent learners in an ensemble (e.g., Random
Forest), where the fairness composes in a non-trivial way. How does fairness
compose in ensembles? What are the fairness impacts of the learners on the
ultimate fairness of the ensemble? Can fair learners result in an unfair
ensemble? Furthermore, studies have shown that hyperparameters influence the
fairness of ML models. Ensemble hyperparameters are more complex since they
affect how learners are combined in different categories of ensembles.
Understanding the impact of ensemble hyperparameters on fairness will help
programmers design fair ensembles. Today, we do not understand these fully for
different ensemble algorithms. In this paper, we comprehensively study popular
real-world ensembles: bagging, boosting, stacking and voting. We have developed
a benchmark of 168 ensemble models collected from Kaggle on four popular
fairness datasets. We use existing fairness metrics to understand the
composition of fairness. Our results show that ensembles can be designed to be
fairer without using mitigation techniques. We also identify the interplay
between fairness composition and data characteristics to guide fair ensemble
design. Finally, our benchmark can be leveraged for further research on fair
ensembles. To the best of our knowledge, this is one of the first and largest
studies on fairness composition in ensembles yet presented in the literature.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 22:51:13 GMT""},{""version"":""v2"",""created"":""Tue, 25 Apr 2023 22:43:32 GMT""}]","2023-04-27"
"2212.04594","Sergiy Borodachov","Sergiy Borodachov","Absolute Minima of Potentials of a Certain Class of Spherical Designs","35 pages, 4 tables. Main theorem (Theorem 4.3) was presented with the
  proof in January 2022 during the Workshop ""Optimal Point Configurations on
  Manifolds"" at Erwin Schr\""odinger Institute in Vienna, Austria",,,,"math.CO math.OC","http://creativecommons.org/licenses/by/4.0/","  We use linear programming techniques to find points of absolute minimum over
the unit sphere $S^{d}$ in $\mathbb R^{d+1}$ of the total potential of a point
configuration $\omega_N\subset S^{d}$ which is a spherical $(2m-1)$-design
contained in the union of some $m$ parallel hyperplanes. The interaction
between points is described by the kernel $K({\bf x},{\bf y})=f(\left|{\bf
x}-{\bf y}\right|^2)$, where $\left|\ \!\cdot\ \!\right|$ is the Euclidean norm
in $\mathbb R^{d+1}$. The potential function $f$ is assumed to have a convex
derivative $f^{(2m-2)}$. Points of minimum do not depend on $f$ and are those
and only those which form exactly $m$ distinct dot products with points of
$\omega_N$. The proof of this theorem was presented at a workshop at ESI in
January 2022. Using this result, we find sets of universal minima of certain
six configurations on higher-dimensional spheres.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 22:54:27 GMT""}]","2022-12-12"
"2212.04595","Aman Agarwal","Aman Agarwal","Explain to me like I am five -- Sentence Simplification Using
  Transformers",,,,,"cs.CL","http://creativecommons.org/licenses/by-sa/4.0/","  Sentence simplification aims at making the structure of text easier to read
and understand while maintaining its original meaning. This can be helpful for
people with disabilities, new language learners, or those with low literacy.
Simplification often involves removing difficult words and rephrasing the
sentence. Previous research have focused on tackling this task by either using
external linguistic databases for simplification or by using control tokens for
desired fine-tuning of sentences. However, in this paper we purely use
pre-trained transformer models. We experiment with a combination of GPT-2 and
BERT models, achieving the best SARI score of 46.80 on the Mechanical Turk
dataset, which is significantly better than previous state-of-the-art results.
The code can be found at https://github.com/amanbasu/sentence-simplification.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 22:57:18 GMT""}]","2022-12-12"
"2212.04596","Max Willsey","David Cao, Rose Kunkel, Chandrakana Nandi, Max Willsey, Zachary
  Tatlock, Nadia Polikarpova","babble: Learning Better Abstractions with E-Graphs and Anti-Unification","POPL 2023",,"10.1145/3571207",,"cs.PL","http://creativecommons.org/licenses/by/4.0/","  Library learning compresses a given corpus of programs by extracting common
structure from the corpus into reusable library functions. Prior work on
library learning suffers from two limitations that prevent it from scaling to
larger, more complex inputs. First, it explores too many candidate library
functions that are not useful for compression. Second, it is not robust to
syntactic variation in the input.
  We propose library learning modulo theory (LLMT), a new library learning
algorithm that additionally takes as input an equational theory for a given
problem domain. LLMT uses e-graphs and equality saturation to compactly
represent the space of programs equivalent modulo the theory, and uses a novel
e-graph anti-unification technique to find common patterns in the corpus more
directly and efficiently.
  We implemented LLMT in a tool named BABBLE. Our evaluation shows that BABBLE
achieves better compression orders of magnitude faster than the state of the
art. We also provide a qualitative evaluation showing that BABBLE learns
reusable functions on inputs previously out of reach for library learning.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 23:00:08 GMT""}]","2022-12-12"
"2212.04597","Vadim Sotskov","Alberto Ferrari, Vadim Sotskov, Alexander V. Shapeev, Fritz K\""ormann","Modelling Surface Segregation in Compositionally Complex Alloys with
  Ab-Initio Accuracy","9 pages, 5 figures, 2 tables",,,,"cond-mat.mtrl-sci physics.chem-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Compositionally complex alloys or concentrated solid solutions are the latest
frontier in catalyst design, but mixing different elements in one catalyst may
result in surface segregation. Atomistic simulations can predict segregation
patterns, but standard approaches based on mean-field models, cluster
expansion, or classical interatomic potentials are often limited for the
description of multicomponent alloys. We present machine learning potentials
that can describe surface segregation with near DFT accuracy. The method is
used to study a complex Co-Cu-Fe-Mo-Ni quinary alloy. For this alloy, an
unexpected segregation of Co, which has a relatively high surface energy, is
observed. We rationalize this surprising mechanism in terms of simple
transition-metal chemistry.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 23:09:49 GMT""}]","2022-12-12"
"2212.04598","Nicholas Materise","Nicholas Materise, Matthieu C. Dartiailh, William M. Strickland, Javad
  Shabani, Eliot Kapit","Tunable Capacitor For Superconducting Qubits Using an InAs/InGaAs
  Heterostructure","23 pages, 7 figures",,,,"cond-mat.mes-hall quant-ph","http://creativecommons.org/licenses/by/4.0/","  Adoption of fast, parametric coupling elements has improved the performance
of superconducting qubits, enabling recent demonstrations of quantum advantage
in randomized sampling problems. The development of low loss, high contrast
couplers is critical for scaling up these systems. We present a blueprint for a
gate-tunable coupler realized with a two-dimensional electron gas in an
InAs/InGaAs heterostructure. Rigorous numerical simulations of the
semiconductor and high frequency electromagnetic behavior of the coupler and
microwave circuitry yield an on/off ratio of more than one order of magnitude.
We give an estimate of the dielectric-limited loss from the inclusion of the
coupler in a two qubit system, with coupler coherences ranging from a few to
tens of microseconds.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 23:10:55 GMT""}]","2022-12-12"
"2212.04599","Gerald V. Dunne","Gerald V. Dunne and Zachary Harris","Resurgence of the Effective Action in Inhomogeneous Fields","26 pages, 10 figures",,"10.1103/PhysRevD.107.065003",,"hep-th hep-ph math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show how background field inhomogeneities modify the non-perturbative
structure of the effective action. The simple Borel poles of the
Euler-Heisenberg effective action become branch points, and new branch points
also appear, indicating new non-perturbative effects. This information is
resurgently encoded in the perturbative weak field expansion, and becomes
physically significant for strongly inhomogeneous fields. We also show that
resurgent extrapolation methods permit the decoding of a surprising amount of
non-perturbative information from a relatively modest amount of perturbative
input, enabling accurate analytic continuations from weak field to strong
field, and of a spatially dependent magnetic background to a time dependent
electric background. These extrapolations are far superior to standard WKB and
locally constant field approximations.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 23:14:25 GMT""}]","2023-03-15"
"2212.04600","Matthew Digman","Matthew C. Digman, Neil J. Cornish","Parameter Estimation for Stellar-Origin Black Hole Mergers In LISA","13 pages, 6 figures, 1 table",,,,"gr-qc astro-ph.HE astro-ph.IM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The population of stellar origin black hole binaries (SOBHBs) detected by
existing ground-based gravitational wave detectors is an exciting target for
the future space-based Laser Interferometer Space Antenna (LISA). LISA is
sensitive to signals at significantly lower frequencies than ground-based
detectors. SOBHB signals will thus be detected much earlier in their evolution,
years to decades before they merge. The mergers will then occur in the
frequency band covered by ground-based detectors. Observing SOBHBs years before
merger can help distinguish between progenitor models for these systems. We
present a new Bayesian parameter estimation algorithm for LISA observations of
SOBHBs that uses a time-frequency (wavelet) based likelihood function. Our
technique accelerates the analysis by several orders of magnitude compared to
the standard frequency domain approach and allows for an efficient treatment of
non-stationary noise.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 23:17:02 GMT""}]","2022-12-12"
"2212.04601","Andr\'es Fernando Reyes-Lega","A.F. Reyes-Lega","Entanglement Entropy in Quantum Mechanics: An Algebraic Approach","To be published in ""Particles, Fields and Topology: Celebrating A.P.
  Balachandran"", a Festschrift volume for A.P. Balachandran",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  An algebraic approach to the study of entanglement entropy of quantum systems
is reviewed. Starting with a state on a $C^*$-algebra, one can construct a
density operator describing the state in the GNS representation state.
Applications of this approach to the study of entanglement measures for systems
of identical particles are outlined. The ambiguities in the definition of
entropy within this approach are then related to the action of unitaries in the
commutant of the representation and their relation to modular theory explained.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 23:19:28 GMT""}]","2022-12-12"
"2212.04602","Tunde Joseph Taiwo Dr","Tunde Joseph Taiwo","Exact Solution of Spherical Harmonic Potential Coupled with E and M
  fields","8 pages",,,,"quant-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Using the technique of tridiagonal representation approach; for the first
time, we extend this method to study quantum systems with literally perturbed
Hamiltonians. Specifically, we consider a quantum system in a 3D spherical
oscillator symmetric potential function coupled with an electric and a magnetic
field. We obtain the energy spectrum and wavefunction in the two cases.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 23:26:05 GMT""}]","2022-12-12"
"2212.04603","Indranil Sur Mr","Indranil Sur, Zachary Daniels, Abrar Rahman, Kamil Faber, Gianmarco J.
  Gallardo, Tyler L. Hayes, Cameron E. Taylor, Mustafa Burak Gurbuz, James
  Smith, Sahana Joshi, Nathalie Japkowicz, Michael Baron, Zsolt Kira,
  Christopher Kanan, Roberto Corizzo, Ajay Divakaran, Michael Piacentino, Jesse
  Hostetler, Aswin Raghavan","System Design for an Integrated Lifelong Reinforcement Learning Agent
  for Real-Time Strategy Games","The Second International Conference on AIML Systems, October 12--15,
  2022, Bangalore, India",,"10.1145/3564121.3565236",,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As Artificial and Robotic Systems are increasingly deployed and relied upon
for real-world applications, it is important that they exhibit the ability to
continually learn and adapt in dynamically-changing environments, becoming
Lifelong Learning Machines. Continual/lifelong learning (LL) involves
minimizing catastrophic forgetting of old tasks while maximizing a model's
capability to learn new tasks. This paper addresses the challenging lifelong
reinforcement learning (L2RL) setting. Pushing the state-of-the-art forward in
L2RL and making L2RL useful for practical applications requires more than
developing individual L2RL algorithms; it requires making progress at the
systems-level, especially research into the non-trivial problem of how to
integrate multiple L2RL algorithms into a common framework. In this paper, we
introduce the Lifelong Reinforcement Learning Components Framework (L2RLCF),
which standardizes L2RL systems and assimilates different continual learning
components (each addressing different aspects of the lifelong learning problem)
into a unified system. As an instantiation of L2RLCF, we develop a standard API
allowing easy integration of novel lifelong learning components. We describe a
case study that demonstrates how multiple independently-developed LL components
can be integrated into a single realized system. We also introduce an
evaluation environment in order to measure the effect of combining various
system components. Our evaluation environment employs different LL scenarios
(sequences of tasks) consisting of Starcraft-2 minigames and allows for the
fair, comprehensive, and quantitative comparison of different combinations of
components within a challenging common evaluation environment.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 23:32:57 GMT""}]","2022-12-12"
"2212.04604","Hengrui Zhang","Hengrui Zhang, Qitian Wu, Yu Wang, Shaofeng Zhang, Junchi Yan, Philip
  S. Yu","Localized Contrastive Learning on Graphs",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Contrastive learning methods based on InfoNCE loss are popular in node
representation learning tasks on graph-structured data. However, its reliance
on data augmentation and its quadratic computational complexity might lead to
inconsistency and inefficiency problems. To mitigate these limitations, in this
paper, we introduce a simple yet effective contrastive model named Localized
Graph Contrastive Learning (Local-GCL in short). Local-GCL consists of two key
designs: 1) We fabricate the positive examples for each node directly using its
first-order neighbors, which frees our method from the reliance on
carefully-designed graph augmentations; 2) To improve the efficiency of
contrastive learning on graphs, we devise a kernelized contrastive loss, which
could be approximately computed in linear time and space complexity with
respect to the graph size. We provide theoretical analysis to justify the
effectiveness and rationality of the proposed methods. Experiments on various
datasets with different scales and properties demonstrate that in spite of its
simplicity, Local-GCL achieves quite competitive performance in self-supervised
node representation learning tasks on graphs with various scales and
properties.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 23:36:00 GMT""}]","2022-12-12"
"2212.04605","Hongguang Liu","Muxin Han and Hongguang Liu","Covariant ${\bar{\mu}}$-scheme effective dynamics, mimetic gravity, and
  non-singular black holes: Applications to spherical symmetric quantum gravity
  and CGHS model","49 pages, 23 figures",,,,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new $\bar{\mu}$-scheme Hamiltonian effective dynamics in the
spherical symmetric sector of Loop Quantum Gravity (LQG). The effective
dynamics is generally covariant as derived from a covariant Lagrangian. The
Lagrangian belongs to the class of extended mimetic gravity Lagrangians in 4
dimensions. We apply the effective dynamics to both cosmology and black hole.
The effective dynamics reproduces the non-singular Loop-Quantum-Cosmology (LQC)
effective dynamics. From the effective dynamics, we obtain the non-singular
black hole solution, which has a killing symmetry in addition to the spherical
symmetry and reduces to the Schwarzschild geometry asymptotically near the
infinity. The black hole spacetime resolves the classical singularity and
approaches asymptotically the Nariai geometry $\mathrm{dS}_2\times S^2$ at the
future infinity in the interior of the black hole. The resulting black hole
spacetime has the complete future null infinity $\mathscr{I}^+$. Thanks to the
general covariance, the effective dynamics can be reformulated in the
light-cone gauge. We generalize the covariant $\bar{\mu}$-scheme effective
dynamics to the Callan-Giddings-Harvey-Strominger (CGHS) model and apply the
light-cone formulation to the CGHS black hole solution with the null-shell
collapse. We focus on the effective dynamics projected along the null shell.
The result shows that both the 2d scalar curvature and the derivative of
dilaton field are finite, in contrast to the divergence in the CGHS model.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 23:41:01 GMT""}]","2022-12-12"
"2212.04606","Duyal Yolcu","Duyal Yolcu","The R-algebra of Quasiknowledge and Convex Optimization","40 pages",,,,"quant-ph cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  This article develops a convex description of a classical or quantum
learner's or agent's state of knowledge about its environment, presented as a
convex subset of a commutative R-algebra. With caveats, this leads to a
generalization of certain semidefinite programs in quantum information (such as
those describing the universal query algorithm dual to the quantum adversary
bound, related to optimal learning or control of the environment) to the
classical and faulty-quantum setting, which would not be possible with a naive
description via joint probability distributions over environment and internal
memory. More philosophically, it also makes an interpretation of the set of
reduced density matrices as ""states of knowledge"" of an observer of its
environment, related to these techniques, more explicit. As another example, I
describe and solve a formal differential equation of states of knowledge in
that algebra, where an agent obtains experimental data in a Poissonian process,
and its state of knowledge evolves as an exponential power series. However,
this framework currently lacks impressive applications, and I post it in part
to solicit feedback and collaboration on those. In particular, it may be
possible to develop it into a new framework for the design of experiments, e.g.
the problem of finding maximally informative questions to ask human labelers or
the environment in machine-learning problems. The parts of the article not
related to quantum information don't assume knowledge of it.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 23:48:00 GMT""}]","2022-12-12"
"2212.04607","Joey Hong","Joey Hong and Aviral Kumar and Sergey Levine","Confidence-Conditioned Value Functions for Offline Reinforcement
  Learning","16 pages, NeurIPS 2022 DeepRL Workshop",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Offline reinforcement learning (RL) promises the ability to learn effective
policies solely using existing, static datasets, without any costly online
interaction. To do so, offline RL methods must handle distributional shift
between the dataset and the learned policy. The most common approach is to
learn conservative, or lower-bound, value functions, which underestimate the
return of out-of-distribution (OOD) actions. However, such methods exhibit one
notable drawback: policies optimized on such value functions can only behave
according to a fixed, possibly suboptimal, degree of conservatism. However,
this can be alleviated if we instead are able to learn policies for varying
degrees of conservatism at training time and devise a method to dynamically
choose one of them during evaluation. To do so, in this work, we propose
learning value functions that additionally condition on the degree of
conservatism, which we dub confidence-conditioned value functions. We derive a
new form of a Bellman backup that simultaneously learns Q-values for any degree
of confidence with high probability. By conditioning on confidence, our value
functions enable adaptive strategies during online evaluation by controlling
for confidence level using the history of observations thus far. This approach
can be implemented in practice by conditioning the Q-function from existing
conservative algorithms on the confidence. We theoretically show that our
learned value functions produce conservative estimates of the true value at any
desired confidence. Finally, we empirically show that our algorithm outperforms
existing conservative offline RL algorithms on multiple discrete control
domains.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 23:56:47 GMT""}]","2022-12-12"
"2212.04608","Hailin Wang","Xinzhu Li, Ignas Lekavicius, and Hailin Wang","Diamond nanomechanical resonators protected by a phononic band gap",,,"10.1021/acs.nanolett.2c04095",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  We report the design, fabrication, and characterization of diamond
cantilevers attached to a phononic square lattice. We show that the robust
protection of mechanical modes by phononic band gaps leads to a
three-orders-of-magnitude increase in mechanical Q-factors, with the Q-factors
exceeding 10^6 at frequencies as high as 100 MHz. Temperature dependent studies
indicate that the Q-factors obtained at a few K are still limited by the
materials loss. The high-Q diamond nanomechanical resonators provide a
promising hybrid quantum system for spin-mechanics studies.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 00:07:46 GMT""}]","2023-01-11"
"2212.04609","Federico Tartarini","Giovanni Betti, Federico Tartarini, Christine Nguyen, Stefano Schiavon","CBE Clima Tool: a free and open-source web application for climate
  analysis tailored to sustainable building design","Submitted to SoftwareX",,,,"cs.HC","http://creativecommons.org/licenses/by-sa/4.0/","  Buildings that are designed specifically to respond to the local climate can
be more comfortable, energy-efficient, and with a lower environmental impact.
However, there are many social, cultural, and economic obstacles that might
prevent the wide adoption of designing climate-adapted buildings. One of the
said obstacles can be removed by enabling practitioners to easily access and
analyse local climate data. The CBE Clima Tool (Clima) is a free and
open-source web application that offers easy access to publicly available
weather files (in EPW format) specifically created for building energy
simulation and design. It provides a series of interactive visualization of the
variables therein contained and several derived ones. It is aimed at students,
educators, and practitioners in the architecture and engineering fields. Since
its launch has been consistently recording over 3000 monthly unique users from
over 70 countries worldwide, both in professional and educational settings.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 00:13:20 GMT""}]","2022-12-12"
"2212.04610","Subrata Jana","Subrata Jana, Szymon \'Smiga, Lucian A. Constantin, and Prasanjit
  Samal","Meta-generalized gradient approximation of adiabatic connection
  semilocal correlation functional","11 pages",,,,"cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have developed a meta-generalized gradient approximation (meta-GGA)
correlation energy functional using the adiabatic connection semilocal
correlation (ACSC) approach proposed recently [L. A. Constantin, Phys. Rev. B
99, 085117 (2019)]. The construction is based on the high and low-density
limits of the Tao-Perdew-Starverov-Scuseria (TPSS) correlation energy
functional leading to the TPSS-ACSC density functional approximation, which is
one electron self-interaction free, accurate for strictly correlated, and
quasi-two-dimensional regimes. Based on simple examples, we show the advantages
and disadvantages of ACSC semilocal functionals and provide some new guidelines
for future developments.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 00:24:06 GMT""}]","2022-12-12"
"2212.04611","Shiyang Lai","Shiyang Lai","Multidimensional Service Quality Scoring System",,"Tourism Management, 95, 104665 (2022)","10.1016/j.tourman.2022.104665",,"cs.LG cs.CL stat.ME","http://creativecommons.org/licenses/by-sa/4.0/","  This supplementary paper aims to introduce the Multidimensional Service
Quality Scoring System (MSQs), a review-based method for quantifying host
service quality mentioned and employed in the paper Exit and transition:
Exploring the survival status of Airbnb listings in a time of
professionalization. MSQs is not an end-to-end implementation and is
essentially composed of three pipelines, namely Data Collection and
Preprocessing, Objects Recognition and Grouping, and Aspect-based Service
Scoring. Using the study mentioned above as a case, the technical details of
MSQs are explained in this article.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 00:29:37 GMT""}]","2022-12-12"
"2212.04612","Zayd Hammoudeh","Zayd Hammoudeh, Daniel Lowd","Training Data Influence Analysis and Estimation: A Survey",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Good models require good training data. For overparameterized deep models,
the causal relationship between training data and model predictions is
increasingly opaque and poorly understood. Influence analysis partially
demystifies training's underlying interactions by quantifying the amount each
training instance alters the final model. Measuring the training data's
influence exactly can be provably hard in the worst case; this has led to the
development and use of influence estimators, which only approximate the true
influence. This paper provides the first comprehensive survey of training data
influence analysis and estimation. We begin by formalizing the various, and in
places orthogonal, definitions of training data influence. We then organize
state-of-the-art influence analysis methods into a taxonomy; we describe each
of these methods in detail and compare their underlying assumptions, asymptotic
complexities, and overall strengths and weaknesses. Finally, we propose future
research directions to make influence analysis more useful in practice as well
as more theoretically and empirically sound. A curated, up-to-date list of
resources related to influence analysis is available at
https://github.com/ZaydH/influence_analysis_papers.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 00:32:46 GMT""}]","2022-12-12"
"2212.04613","Kyle Buettner","Kyle Buettner, Adriana Kovashka","Contrastive View Design Strategies to Enhance Robustness to Domain
  Shifts in Downstream Object Detection","To appear, 2nd International Workshop on Practical Deep Learning in
  the Wild at AAAI Conference on Artificial Intelligence 2023",,,,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Contrastive learning has emerged as a competitive pretraining method for
object detection. Despite this progress, there has been minimal investigation
into the robustness of contrastively pretrained detectors when faced with
domain shifts. To address this gap, we conduct an empirical study of
contrastive learning and out-of-domain object detection, studying how
contrastive view design affects robustness. In particular, we perform a case
study of the detection-focused pretext task Instance Localization (InsLoc) and
propose strategies to augment views and enhance robustness in
appearance-shifted and context-shifted scenarios. Amongst these strategies, we
propose changes to cropping such as altering the percentage used, adding IoU
constraints, and integrating saliency based object priors. We also explore the
addition of shortcut-reducing augmentations such as Poisson blending, texture
flattening, and elastic deformation. We benchmark these strategies on abstract,
weather, and context domain shifts and illustrate robust ways to combine them,
in both pretraining on single-object and multi-object image datasets. Overall,
our results and insights show how to ensure robustness through the choice of
views in contrastive learning.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 00:34:50 GMT""}]","2022-12-12"
"2212.04614","Manas Gupta","Manas Gupta, Sarthak Ketanbhai Modi, Hang Zhang, Joon Hei Lee, Joo
  Hwee Lim","Is Bio-Inspired Learning Better than Backprop? Benchmarking Bio Learning
  vs. Backprop",,,,,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Bio-inspired learning has been gaining popularity recently given that
Backpropagation (BP) is not considered biologically plausible. Many algorithms
have been proposed in the literature which are all more biologically plausible
than BP. However, apart from overcoming the biological implausibility of BP, a
strong motivation for using Bio-inspired algorithms remains lacking. In this
study, we undertake a holistic comparison of BP vs. multiple Bio-inspired
algorithms to answer the question of whether Bio-learning offers additional
benefits over BP. We test Bio-algorithms under different design choices such as
access to only partial training data, resource constraints in terms of the
number of training epochs, sparsification of the neural network parameters and
addition of noise to input samples. Through these experiments, we notably find
two key advantages of Bio-algorithms over BP. Firstly, Bio-algorithms perform
much better than BP when the entire training dataset is not supplied. Four of
the five Bio-algorithms tested outperform BP by upto 5% accuracy when only 20%
of the training dataset is available. Secondly, even when the full dataset is
available, Bio-algorithms learn much quicker and converge to a stable accuracy
in far lesser training epochs than BP. Hebbian learning, specifically, is able
to learn in just 5 epochs compared to around 100 epochs required by BP. These
insights present practical reasons for utilising Bio-learning beyond just their
biological plausibility and also point towards interesting new directions for
future work on Bio-learning.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 00:43:49 GMT""},{""version"":""v2"",""created"":""Wed, 4 Jan 2023 07:33:11 GMT""},{""version"":""v3"",""created"":""Fri, 17 Mar 2023 09:26:38 GMT""}]","2023-03-20"
"2212.04615","Rabayet Sadnan","Rabayet Sadnan, Nathan Gray, Anjan Bose and Anamika Dubey","Simulation-Integrated Distributed Optimal Power Flow for Unbalanced
  Power Distribution Systems","9 pages",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  Distributed optimization methods have been extensively applied for the
optimization of electric power distribution systems, especially for grid-edge
coordination. Existing distributed optimization algorithms applied to power
distribution systems require many communication rounds among the distributed
agents and may pose convergence challenges in difficult nonlinear settings. The
communication network parameters also significantly impact the algorithm's
performance. In this paper, we propose a scalable, equivalent network
approximation-based, distributed optimization algorithm that employs simulation
within optimization using the system's digital twin (DT) to solve the optimal
power problems (OPF) for a three-phase unbalanced distribution system. The
proposed approach is implemented using a cyber-physical co-simulation platform
to validate the robustness of the proposed distributed algorithm under stressed
communication. The proposed approach is thoroughly validated using the IEEE
123-bus test system.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 00:48:28 GMT""}]","2022-12-12"
"2212.04616","Sarmad Hanif","Sarmad Hanif, Rabayet Sadnan, Tylor E. Slay, Nawaf Nazir, Shiva
  Poudel, Bilal Bhatti, Andy Reiman, Jim Follum, Joseph McKinsey, Tarek
  Elgindy, Rui Yang","On Distribution Grid Optimal Power Flow Development and Integration",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Due to changes in electric distribution grid operation, new operation regimes
have been recommended. Distribution grid optimal power flow (DOPF) has received
tremendous attention in the research community, yet it has not been fully
adopted across the utility industry. Our paper recognizes this problem and
suggests a development and integration procedure for DOPF. We propose
development of DOPF as a three step procedure of 1) processing the grid, 2)
obtaining a tractable solution, and 3) implementing multiple solution
algorithms and benchmarking them to improve application reliability. For the
integration of DOPF, we demonstrate how a DOPF federate may be developed that
can be integrated in a co-simulation environment to mimic the real-world
conditions and hence improve its practicality to be deployed in the field. To
demonstrate the efficacy of the proposed methods, tests on IEEE 123-bus system
are performed where the usage of tractable formulation in DOPF algorithm
development and its comparison to the benchmark solution are demonstrated.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 00:57:11 GMT""}]","2022-12-12"
"2212.04617","Shashank Shekhar","Shashank Shekhar, Ritika Nandi, H Srikanth Kamath","UNet Based Pipeline for Lung Segmentation from Chest X-Ray Images","6 Pages",,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Biomedical image segmentation is one of the fastest growing fields which has
seen extensive automation through the use of Artificial Intelligence. This has
enabled widespread adoption of accurate techniques to expedite the screening
and diagnostic processes which would otherwise take several days to finalize.
In this paper, we present an end-to-end pipeline to segment lungs from chest
X-ray images, training the neural network model on the Japanese Society of
Radiological Technology (JSRT) dataset, using UNet to enable faster processing
of initial screening for various lung disorders. The pipeline developed can be
readily used by medical centers with just the provision of X-Ray images as
input. The model will perform the preprocessing, and provide a segmented image
as the final output. It is expected that this will drastically reduce the
manual effort involved and lead to greater accessibility in
resource-constrained locations.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 01:00:10 GMT""}]","2022-12-12"
"2212.04618","Huangwei Zhang","Pikai Zhang and Huangwei Zhang and Yun Feng Zhang and Shangpeng Li and
  Qingyang Meng","Modelling particle collisions in moderately dense curtain impacted by an
  incident shock wave",,,"10.1063/5.0138088",,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  The interactions between an incident shock and moderately dense particle
curtain are simulated with the Eulerian-Lagrangian method. A customized solver
based on OpenFOAM is extended with an improved drag model and collision model,
and then validated against two benchmark experiments. In this work, parametric
studies are performed considering different particle sizes, volume fractions,
and curtain thicknesses. It is found that smaller particle size and larger
volume fractions lead to stronger reflected shock and weaker transmitted shock.
Different expansion stages of the curtain fronts are also studied in detail.
Attention is paid to the particle collision effects on the curtain evolution
behaviours. According to our results, for the mono-dispersed particle curtain,
the collision effects on curtain front behaviors are small, even when the
initial particle volume fraction is as high as 20%. This is due to the positive
velocity gradient across the curtain after the shock wave passage, leading to
faster motion of downstream particles than the upstream ones and hence no
collision occurs. For the bi-dispersed particle curtain, the collision effects
become important in the mixing region of different-size particles. Collisions
decelerate small particles while accelerate large ones and cause velocity
scattering. Moreover, increasing the bi-dispersed curtain thickness leads to
multiple collision force peaks due to the local particle accumulations, which
is the result of the delayed separation of different particle groups. Our
results indicate that the collision model may be unnecessary to predict curtain
fronts in mono-dispersed particles, but in bi-dispersed particles, the
collision effects are important and therefore must be modelled.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 01:12:00 GMT""}]","2023-03-08"
"2212.04619","Christopher Kane","Christopher F. Kane, Dorota M. Grabowska, Benjamin Nachman and
  Christian W. Bauer","Overcoming exponential volume scaling in quantum simulations of lattice
  gauge theories","11 pages, 2 figures, Proceedings of the 39th Annual International
  Symposium on Lattice Field Theory (Lattice 2022), August 8-13 2022, Bonn,
  Germany",,,,"hep-lat quant-ph","http://creativecommons.org/licenses/by/4.0/","  Real-time evolution of quantum field theories using classical computers
requires resources that scale exponentially with the number of lattice sites.
Because of a fundamentally different computational strategy, quantum computers
can in principle be used to perform detailed studies of these dynamics from
first principles. Before performing such calculations, it is important to
ensure that the quantum algorithms used do not have a cost that scales
exponentially with the volume. In these proceedings, we present an interesting
test case: a formulation of a compact U(1) gauge theory in 2+1 dimensions free
of gauge redundancies. A naive implementation onto a quantum circuit has a gate
count that scales exponentially with the volume. We discuss how to break this
exponential scaling by performing an operator redefinition that reduces the
non-locality of the Hamiltonian. While we study only one theory as a test case,
it is possible that the exponential gate scaling will persist for formulations
of other gauge theories, including non-Abelian theories in higher dimensions.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 01:18:46 GMT""}]","2022-12-12"
"2212.04620","David Van Dijcke","David Van Dijcke","On the Non-Identification of Revenue Production Functions","12 pages",,,,"econ.EM","http://creativecommons.org/licenses/by/4.0/","  It is well-known that production functions are potentially misspecified when
revenue is used as a proxy for output. In this paper, I formalize and
strengthen this common knowledge by showing that neither the production
function nor Hicks-neutral productivity can be identified when revenue is used
as a proxy for physical output. This result holds under the standard
assumptions used in the literature for a large class of production functions,
including all commonly used parametric forms. Among the prevalent approaches to
address this issue, I show that only those which impose assumptions on the
underlying demand system can possibly identify the production function.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 01:23:11 GMT""}]","2022-12-12"
"2212.04621","Parth Dipakkumar Patel","Parth Dipakkumar Patel and Prem Trivedi","A systematic literature review on Virtual Reality and Augmented Reality
  in terms of privacy, authorization and data-leaks","9 Pages, 4 figures",,,,"cs.CR","http://creativecommons.org/publicdomain/zero/1.0/","  In recent years, VR and AR has exploded into a multimillionaire market. As
this emerging technology has spread to a variety of businesses and is rapidly
increasing among users. It is critical to address potential privacy and
security concerns that these technologies might pose. In this study, we discuss
the current status of privacy and security in VR and AR. We analyse possible
problems and risks. Besides, we will look in detail at a few of the major
concerns issues and related security solutions for AR and VR. Additionally, as
VR and AR authentication is the most thoroughly studied aspect of the problem,
we concentrate on the research that has already been done in this area.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 01:28:58 GMT""}]","2022-12-12"
"2212.04622","Yan Qin","Yan Qin, Anushiya Arunan, Chau Yuen","Digital Twin for Real-time Li-ion Battery State of Health Estimation
  with Partially Discharged Cycling Data","This paper has been accepted for IEEE Transactions on Industrial
  Informatics",,,,"cs.LG cs.AI eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To meet the fairly high safety and reliability requirements in practice, the
state of health (SOH) estimation of Lithium-ion batteries (LIBs), which has a
close relationship with the degradation performance, has been extensively
studied with the widespread applications of various electronics. The
conventional SOH estimation approaches with digital twin are end-of-cycle
estimation that require the completion of a full charge/discharge cycle to
observe the maximum available capacity. However, under dynamic operating
conditions with partially discharged data, it is impossible to sense accurate
real-time SOH estimation for LIBs. To bridge this research gap, we put forward
a digital twin framework to gain the capability of sensing the battery's SOH on
the fly, updating the physical battery model. The proposed digital twin
solution consists of three core components to enable real-time SOH estimation
without requiring a complete discharge. First, to handle the variable training
cycling data, the energy discrepancy-aware cycling synchronization is proposed
to align cycling data with guaranteeing the same data structure. Second, to
explore the temporal importance of different training sampling times, a
time-attention SOH estimation model is developed with data encoding to capture
the degradation behavior over cycles, excluding adverse influences of
unimportant samples. Finally, for online implementation, a similarity
analysis-based data reconstruction has been put forward to provide real-time
SOH estimation without requiring a full discharge cycle. Through a series of
results conducted on a widely used benchmark, the proposed method yields the
real-time SOH estimation with errors less than 1% for most sampling times in
ongoing cycles.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 01:30:10 GMT""}]","2022-12-12"
"2212.04623","Donghan Kim","Erhan Bayraktar, Donghan Kim, Abhishek Tilva","Arbitrage theory in a market of stochastic dimension",,,,,"q-fin.MF math.PR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper studies an equity market of stochastic dimension, where the number
of assets fluctuates over time. In such a market, we develop the fundamental
theorem of asset pricing, which provides the equivalence of the following
statements: (i) there exists a supermartingale num\'eraire portfolio; (ii) each
dissected market, which is of a fixed dimension between dimensional jumps, has
locally finite growth; (iii) there is no arbitrage of the first kind; (iv)
there exists a local martingale deflator; (v) the market is viable. We also
present the Optional decomposition theorem, which characterizes a given
nonnegative process as the wealth process of some investment-consumption
strategy. These results are developed in an equity market model where the price
process is given by a piecewise continuous semimartingale of stochastic
dimension. Without the continuity assumption on the price process, we present
similar results but without explicit characterization of the num\'eraire
portfolio.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 01:32:10 GMT""}]","2022-12-12"
"2212.04624","Weitian Wu","Wei-tian Wu and Xin-min Yang","The Hybridization of Branch and Bound with Metaheuristics for Nonconvex
  Multiobjective Optimization",,,,,"math.OC cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A hybrid framework combining the branch and bound method with multiobjective
evolutionary algorithms is proposed for nonconvex multiobjective optimization.
The hybridization exploits the complementary character of the two optimization
strategies. A multiobjective evolutionary algorithm is intended for inducing
tight lower and upper bounds during the branch and bound procedure. Tight
bounds such as the ones derived in this way can reduce the number of
subproblems that have to be solved. The branch and bound method guarantees the
global convergence of the framework and improves the search capability of the
multiobjective evolutionary algorithm. An implementation of the hybrid
framework considering NSGA-II and MOEA/D-DE as multiobjective evolutionary
algorithms is presented. Numerical experiments verify the hybrid algorithms
benefit from synergy of the branch and bound method and multiobjective
evolutionary algorithms.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 01:36:20 GMT""}]","2022-12-12"
"2212.04625","Vedant Mundheda","Vedant Mundheda, Karan Mirakhor, Rahul K S, Harikumar Kandath,
  Nagamanikandan Govindan","Predictive Barrier Lyapunov Function Based Control for Safe Trajectory
  Tracking of an Aerial Manipulator","European Control Conference '23",,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  This paper proposes a novel controller framework that provides trajectory
tracking for an Aerial Manipulator (AM) while ensuring the safe operation of
the system under unknown bounded disturbances. The AM considered here is a
2-DOF (degrees-of-freedom) manipulator rigidly attached to a UAV. Our proposed
controller structure follows the conventional inner loop PID control for
attitude dynamics and an outer loop controller for tracking a reference
trajectory. The outer loop control is based on the Model Predictive Control
(MPC) with constraints derived using the Barrier Lyapunov Function (BLF) for
the safe operation of the AM. BLF-based constraints are proposed for two
objectives, viz. 1) To avoid the AM from colliding with static obstacles like a
rectangular wall, and 2) To maintain the end effector of the manipulator within
the desired workspace. The proposed BLF ensures that the above-mentioned
objectives are satisfied even in the presence of unknown bounded disturbances.
The capabilities of the proposed controller are demonstrated through
high-fidelity non-linear simulations with parameters derived from a real
laboratory scale AM. We compare the performance of our controller with other
state-of-the-art MPC controllers for AM.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 01:40:00 GMT""}]","2022-12-12"
"2212.04626","Joseph C. V\'arilly","Adri\'an J. Naranjo-Alvarado and Joseph C. V\'arilly","Metaplectic and spin representations: a parallel treatment","Latex, 38 pages",,,,"math.FA math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The analogies between symplectic and orthogonal groups, regarded as
symmetries of real bilinear forms, are manifest in their (metaplectic and spin)
projective representations. In finite dimensions, those are true
representations of doubly covering groups; but one may also use group
extensions by a circle. Here we lay out a parallel treatment of of the
Mp$^\mathrm{c}$ and Spin$^\mathrm{c}$ covering groups, acting on the respective
Fock spaces by permuting certain Gaussian vectors. The cocycles of these
extensions exhibit interesting similarities.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 01:41:01 GMT""}]","2022-12-12"
"2212.04627","Guido Boffetta","G. Boffetta, A. Mazzino, S. Musacchio, M. E. Rosti","Transient inverse energy cascade in free surface turbulence","9 pages, 8 figures",,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the statistics of free-surface turbulence at large Reynolds numbers
produced by direct numerical simulations in a fluid layer at different
thickness with fixed characteristic forcing scale. We observe the production of
a transient inverse cascade, with a duration which depends on the thickness of
the layer, followed by a transition to three-dimensional turbulence initially
produced close to the bottom, no-slip boundary. By switching off the forcing,
we study the decaying turbulent regime and we find that it cannot be described
by an exponential law. Our results show that boundary conditions play a
fundamental role in the nature of turbulence produced in thin layers and give
limits on the conditions to produce a two-dimensional phenomenology.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 01:47:09 GMT""}]","2022-12-12"
"2212.04628","Daisuke Ishima","Daisuke Ishima, Kuniyasu Saitoh, Michio Otsuki, and Hisao Hayakawa","Eigenvalue analysis of stress-strain curve of two-dimensional amorphous
  solids of dispersed frictional grains with finite shear strain","22 pages, 16 figures. arXiv admin note: text overlap with
  arXiv:2207.06632","Phys. Rev. E 107, 034904 (2023)","10.1103/PhysRevE.107.034904",,"cond-mat.soft cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  The stress-strain curve of two-dimensional frictional dispersed grains
interacting with a harmonic potential without considering the dynamical slip
under a finite strain is determined by using eigenvalue analysis of the Hessian
matrix. After the configuration of grains is obtained, the stress-strain curve
based on the eigenvalue analysis is in almost perfect agreement with that
obtained by the simulation, even if there are plastic deformations caused by
stress avalanches. Unlike the naive expectation, the eigenvalues in our model
do not indicate any precursors to the stress-drop events.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 01:54:07 GMT""},{""version"":""v2"",""created"":""Tue, 21 Feb 2023 04:37:54 GMT""},{""version"":""v3"",""created"":""Fri, 3 Mar 2023 08:39:43 GMT""}]","2023-05-17"
"2212.04629","Julius Adebayo","Julius Adebayo, Michael Muelly, Hal Abelson, Been Kim","Post hoc Explanations may be Ineffective for Detecting Unknown Spurious
  Correlation",,"ICLR 2022 conference paper",,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate whether three types of post hoc model explanations--feature
attribution, concept activation, and training point ranking--are effective for
detecting a model's reliance on spurious signals in the training data.
Specifically, we consider the scenario where the spurious signal to be detected
is unknown, at test-time, to the user of the explanation method. We design an
empirical methodology that uses semi-synthetic datasets along with
pre-specified spurious artifacts to obtain models that verifiably rely on these
spurious training signals. We then provide a suite of metrics that assess an
explanation method's reliability for spurious signal detection under various
conditions. We find that the post hoc explanation methods tested are
ineffective when the spurious artifact is unknown at test-time especially for
non-visible artifacts like a background blur. Further, we find that feature
attribution methods are susceptible to erroneously indicating dependence on
spurious signals even when the model being explained does not rely on spurious
artifacts. This finding casts doubt on the utility of these approaches, in the
hands of a practitioner, for detecting a model's reliance on spurious signals.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 02:05:39 GMT""}]","2022-12-12"
"2212.04630","Lena Podina","Lena Podina, Brydon Eastman, Mohammad Kohandel","A PINN Approach to Symbolic Differential Operator Discovery with Sparse
  Data",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Given ample experimental data from a system governed by differential
equations, it is possible to use deep learning techniques to construct the
underlying differential operators. In this work we perform symbolic discovery
of differential operators in a situation where there is sparse experimental
data. This small data regime in machine learning can be made tractable by
providing our algorithms with prior information about the underlying dynamics.
Physics Informed Neural Networks (PINNs) have been very successful in this
regime (reconstructing entire ODE solutions using only a single point or entire
PDE solutions with very few measurements of the initial condition). We modify
the PINN approach by adding a neural network that learns a representation of
unknown hidden terms in the differential equation. The algorithm yields both a
surrogate solution to the differential equation and a black-box representation
of the hidden terms. These hidden term neural networks can then be converted
into symbolic equations using symbolic regression techniques like AI Feynman.
In order to achieve convergence of these neural networks, we provide our
algorithms with (noisy) measurements of both the initial condition as well as
(synthetic) experimental data obtained at later times. We demonstrate strong
performance of this approach even when provided with very few measurements of
noisy data in both the ODE and PDE regime.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 02:09:37 GMT""}]","2022-12-12"
"2212.04631","Bo Hu","Bo Hu and Jose C. Principe","The Cross Density Kernel Function: A Novel Framework to Quantify
  Statistical Dependence for Random Processes",,,,,"cs.LG cs.AI cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a novel multivariate definition of statistical dependence
using a functional methodology inspired by Alfred R\'enyi. We define a new
symmetric and self-adjoint cross density kernel through a recursive
bidirectional statistical mapping between conditional densities of continuous
random processes, which estimates their statistical dependence. Therefore, the
kernel eigenspectrum is proposed as a new multivariate statistical dependence
measure, and the formulation requires fewer assumptions about the data
generation model than current methods. The measure can also be estimated from
realizations. The proposed functional maximum correlation algorithm (FMCA) is
applied to a learning architecture with two multivariate neural networks. The
FMCA optimal solution is an equilibrium point that estimates the eigenspectrum
of the cross density kernel. Preliminary results with synthetic data and medium
size image datasets corroborate the theory. Four different strategies of
applying the cross density kernel are thoroughly discussed and implemented to
show the versatility and stability of the methodology, and it transcends
supervised learning. When two random processes are high-dimensional real-world
images and white uniform noise, respectively, the algorithm learns a factorial
code i.e., the occurrence of a code guarantees that a certain input in the
training set was present, which is quite important for feature learning.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 02:12:41 GMT""}]","2022-12-12"
"2212.04632","Wei Chen","Wei Chen, Xi Jia, Zhongqun Zhang, Hyung Jin Chang, Linlin Shen,
  Jinming Duan and Ales Leonardis","Category-Level 6D Object Pose Estimation with Flexible Vector-Based
  Rotation Representation","revised from CVPR2021 paper FS-NET. arXiv admin note: substantial
  text overlap with arXiv:2103.07054",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a novel 3D graph convolution based pipeline for
category-level 6D pose and size estimation from monocular RGB-D images. The
proposed method leverages an efficient 3D data augmentation and a novel
vector-based decoupled rotation representation. Specifically, we first design
an orientation-aware autoencoder with 3D graph convolution for latent feature
learning. The learned latent feature is insensitive to point shift and size
thanks to the shift and scale-invariance properties of the 3D graph
convolution. Then, to efficiently decode the rotation information from the
latent feature, we design a novel flexible vector-based decomposable rotation
representation that employs two decoders to complementarily access the rotation
information. The proposed rotation representation has two major advantages: 1)
decoupled characteristic that makes the rotation estimation easier; 2) flexible
length and rotated angle of the vectors allow us to find a more suitable vector
representation for specific pose estimation task. Finally, we propose a 3D
deformation mechanism to increase the generalization ability of the pipeline.
Extensive experiments show that the proposed pipeline achieves state-of-the-art
performance on category-level tasks. Further, the experiments demonstrate that
the proposed rotation representation is more suitable for the pose estimation
tasks than other rotation representations.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 02:13:43 GMT""},{""version"":""v2"",""created"":""Mon, 30 Jan 2023 00:40:05 GMT""}]","2023-01-31"
"2212.04633","Lei Liu","Lei Liu, Javier E. Santos, Ma\v{s}a Prodanovi\'c, and Michael J. Pyrcz","Mitigation of Spatial Nonstationarity with Vision Transformers",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Spatial nonstationarity, the location variance of features' statistical
distributions, is ubiquitous in many natural settings. For example, in
geological reservoirs rock matrix porosity varies vertically due to
geomechanical compaction trends, in mineral deposits grades vary due to
sedimentation and concentration processes, in hydrology rainfall varies due to
the atmosphere and topography interactions, and in metallurgy crystalline
structures vary due to differential cooling. Conventional geostatistical
modeling workflows rely on the assumption of stationarity to be able to model
spatial features for the geostatistical inference. Nevertheless, this is often
not a realistic assumption when dealing with nonstationary spatial data and
this has motivated a variety of nonstationary spatial modeling workflows such
as trend and residual decomposition, cosimulation with secondary features, and
spatial segmentation and independent modeling over stationary subdomains. The
advent of deep learning technologies has enabled new workflows for modeling
spatial relationships. However, there is a paucity of demonstrated best
practice and general guidance on mitigation of spatial nonstationarity with
deep learning in the geospatial context. We demonstrate the impact of two
common types of geostatistical spatial nonstationarity on deep learning model
prediction performance and propose the mitigation of such impacts using
self-attention (vision transformer) models. We demonstrate the utility of
vision transformers for the mitigation of nonstationarity with relative errors
as low as 10%, exceeding the performance of alternative deep learning methods
such as convolutional neural networks. We establish best practice by
demonstrating the ability of self-attention networks for modeling large-scale
spatial relationships in the presence of commonly observed geospatial
nonstationarity.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 02:16:05 GMT""}]","2022-12-12"
"2212.04634","Yuxin Wang","Yuxin Wang, Jieru Lin, Zhiwei Yu, Wei Hu, B\""orje F. Karlsson","Open-world Story Generation with Structured Knowledge Enhancement: A
  Comprehensive Survey",,,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Storytelling and narrative are fundamental to human experience, intertwined
with our social and cultural engagement. As such, researchers have long
attempted to create systems that can generate stories automatically. In recent
years, powered by deep learning and massive data resources, automatic story
generation has shown significant advances. However, considerable challenges,
like the need for global coherence in generated stories, still hamper
generative models from reaching the same storytelling ability as human
narrators. To tackle these challenges, many studies seek to inject structured
knowledge into the generation process, which is referred to as structured
knowledge-enhanced story generation. Incorporating external knowledge can
enhance the logical coherence among story events, achieve better knowledge
grounding, and alleviate over-generalization and repetition problems in
stories. This survey provides the latest and comprehensive review of this
research field: (i) we present a systematical taxonomy regarding how existing
methods integrate structured knowledge into story generation; (ii) we summarize
involved story corpora, structured knowledge datasets, and evaluation metrics;
(iii) we give multidimensional insights into the challenges of
knowledge-enhanced story generation and cast light on promising directions for
future study.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 02:19:07 GMT""},{""version"":""v2"",""created"":""Fri, 24 Mar 2023 13:20:05 GMT""}]","2023-03-27"
"2212.04635","Hyunjin Shim","Hyunjin Shim, Ho Seong Hwang, Woong-Seob Jeong, Yoshiki Toba, Minjin
  Kim, Dohyeong Kim, Hyunmi Song, Tetsuya Hashimoto, Takao Nakagawa, Ambra
  Nanni, William J. Pearson, Toshinobu Takagi","Metallicity-PAH Relation of MIR-selected Star-forming Galaxies in AKARI
  North Ecliptic Pole-wide Survey","19 pages, 9 figures, AJ, in press",,"10.3847/1538-3881/aca09c",,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We investigate the variation in the mid-infrared spectral energy
distributions of 373 low-redshift ($z<0.4$) star-forming galaxies, which
reflects a variety of polycyclic aromatic hydrocarbon (PAH) emission features.
The relative strength of PAH emission is parameterized as $q_\mathrm{PAH}$,
which is defined as the mass fraction of PAH particles in the total dust mass.
With the aid of continuous mid-infrared photometric data points covering
7-24$\mu$m and far-infrared flux densities, $q_\mathrm{PAH}$ values are derived
through spectral energy distribution fitting. The correlation between
$q_\mathrm{PAH}$ and other physical properties of galaxies, i.e., gas-phase
metallicity ($12+\mathrm{log(O/H)}$), stellar mass, and specific star-formation
rate (sSFR) are explored. As in previous studies, $q_\mathrm{PAH}$ values of
galaxies with high metallicity are found to be higher than those with low
metallicity. The strength of PAH emission is also positively correlated with
the stellar mass and negatively correlated with the sSFR. The correlation
between $q_\mathrm{PAH}$ and each parameter still exists even after the other
two parameters are fixed. In addition to the PAH strength, the application of
metallicity-dependent gas-to-dust mass ratio appears to work well to estimate
gas mass that matches the observed relationship between molecular gas and
physical parameters. The result obtained will be used to calibrate the observed
PAH luminosity-total infrared luminosity relation, based on the variation of
MIR-FIR SED, which is used in the estimation of hidden star formation.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 02:23:31 GMT""}]","2023-01-11"
"2212.04636","Jiaman Li","Jiaman Li, C. Karen Liu, Jiajun Wu","Ego-Body Pose Estimation via Ego-Head Pose Estimation","CVPR 2023",,,,"cs.CV cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Estimating 3D human motion from an egocentric video sequence plays a critical
role in human behavior understanding and has various applications in VR/AR.
However, naively learning a mapping between egocentric videos and human motions
is challenging, because the user's body is often unobserved by the front-facing
camera placed on the head of the user. In addition, collecting large-scale,
high-quality datasets with paired egocentric videos and 3D human motions
requires accurate motion capture devices, which often limit the variety of
scenes in the videos to lab-like environments. To eliminate the need for paired
egocentric video and human motions, we propose a new method, Ego-Body Pose
Estimation via Ego-Head Pose Estimation (EgoEgo), which decomposes the problem
into two stages, connected by the head motion as an intermediate
representation. EgoEgo first integrates SLAM and a learning approach to
estimate accurate head motion. Subsequently, leveraging the estimated head pose
as input, EgoEgo utilizes conditional diffusion to generate multiple plausible
full-body motions. This disentanglement of head and body pose eliminates the
need for training datasets with paired egocentric videos and 3D human motion,
enabling us to leverage large-scale egocentric video datasets and motion
capture datasets separately. Moreover, for systematic benchmarking, we develop
a synthetic dataset, AMASS-Replica-Ego-Syn (ARES), with paired egocentric
videos and human motion. On both ARES and real data, our EgoEgo model performs
significantly better than the current state-of-the-art methods.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 02:25:20 GMT""},{""version"":""v2"",""created"":""Sun, 2 Apr 2023 18:13:15 GMT""}]","2023-04-04"
"2212.04637","Meng Ji","Zhong Huang, Meng Ji","Connectivity keeping spiders in k-connected graphs","9 pages. arXiv admin note: text overlap with arXiv:2012.04816",,,,"math.CO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  W. Mader [J. Graph Theory 65 (2010), 61--69] conjectured that for any tree
$T$ of order $m$, every $k$-connected graph $G$ with
$\delta(G)\geq\lfloor\frac{3k}{2}\rfloor+m-1$ contains a tree $T'\cong T$ such
that $G-V(T')$ remains $k$-connected. In this paper, we confirm Mader's
conjecture for all the spider-trees.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 02:31:59 GMT""},{""version"":""v2"",""created"":""Fri, 12 May 2023 08:10:34 GMT""}]","2023-05-15"
"2212.04638","Aoyang Liu","Yansong Tang, Jinpeng Liu, Aoyang Liu, Bin Yang, Wenxun Dai, Yongming
  Rao, Jiwen Lu, Jie Zhou, Xiu Li","FLAG3D: A 3D Fitness Activity Dataset with Language Instruction","Accepted to CVPR2023",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the continuously thriving popularity around the world, fitness activity
analytic has become an emerging research topic in computer vision. While a
variety of new tasks and algorithms have been proposed recently, there are
growing hunger for data resources involved in high-quality data, fine-grained
labels, and diverse environments. In this paper, we present FLAG3D, a
large-scale 3D fitness activity dataset with language instruction containing
180K sequences of 60 categories. FLAG3D features the following three aspects:
1) accurate and dense 3D human pose captured from advanced MoCap system to
handle the complex activity and large movement, 2) detailed and professional
language instruction to describe how to perform a specific activity, 3)
versatile video resources from a high-tech MoCap system, rendering software,
and cost-effective smartphones in natural environments. Extensive experiments
and in-depth analysis show that FLAG3D contributes great research value for
various challenges, such as cross-domain human action recognition, dynamic
human mesh recovery, and language-guided human action generation. Our dataset
and source code are publicly available at https://andytang15.github.io/FLAG3D.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 02:33:33 GMT""},{""version"":""v2"",""created"":""Wed, 19 Apr 2023 13:31:03 GMT""}]","2023-04-20"
"2212.04639","Kun Wang","Kun Wang, Anbing Ren, Mads Fredslund Andersen, Frank Grundahl, Tao
  Chen, Pere L. Palle","FX UMa: A New Heartbeat Binary System with Linear and Non-linear Tidal
  Oscillations and delta Sct Pulsations","17 pages, 7 figures, Accepted for publication in AJ",,,,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a detailed analysis of an eclipsing double-lined binary FX UMa
based on TESS photometry and newly acquired spectroscopic observations. The
radial velocities and atmospheric parameters for each component star are
obtained from the SONG high-resolution spectra. Combined with the
radial-velocity measurements, our light-curve modeling yields absolute masses
and radii of the two components. The Fourier amplitude spectrum of the residual
light curve reveals a total of 103 frequencies with signal-to-noise ratio (S/N)
> 4, including 12 independent frequencies, 17 multiples of the orbital
frequency (Nforb), and 74 combination frequencies. Ten Nforb peaks with S/N >
10 have very high amplitudes and are likely due to tidally excited oscillations
(TEOs). The remaining Nforb peaks (4 < S/N < 10) may be originated from the
imperfect removal, or they are actually real TEOs. Four anharmonic frequencies
can pair up and sum to give exact harmonics of the orbital frequency,
suggesting the existence of non-linear tidal processes in the eccentric binary
system FX UMa. Eight independent frequencies in the range of 20 to 32
day$^{-1}$ are typical low-order pressure modes of delta Scuti pulsators.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 02:37:27 GMT""},{""version"":""v2"",""created"":""Sat, 3 Jun 2023 11:15:56 GMT""}]","2023-06-06"
"2212.04640","Debsoumya Chakraborti","Debsoumya Chakraborti, Kevin Hendrey, Ben Lund, Casey Tompkins","Rainbow saturation for complete graphs",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We call an edge-colored graph rainbow if all of its edges receive distinct
colors. An edge-colored graph $\Gamma$ is called $H$-rainbow saturated if
$\Gamma$ does not contain a rainbow copy of $H$ and adding an edge of any color
to $\Gamma$ creates a rainbow copy of $H$. The rainbow saturation number
$sat(n,{R}(H))$ is the minimum number of edges in an $n$-vertex $H$-rainbow
saturated graph. Gir\~{a}o, Lewis, and Popielarz conjectured that
$sat(n,{R}(K_r))=2(r-2)n+O(1)$ for fixed $r\geq 3$. Disproving this conjecture,
we establish that for every $r\geq 3$, there exists a constant $\alpha_r$ such
that $$r + \Omega\left(r^{1/3}\right) \le \alpha_r \le r + r^{1/2} \qquad
\text{and} \qquad sat(n,{R}(K_r)) = \alpha_r n + O(1).$$ Recently, Behague,
Johnston, Letzter, Morrison, and Ogden independently gave a slightly weaker
upper bound which was sufficient to disprove the conjecture. They also
introduced the weak rainbow saturation number, and asked whether this is equal
to the rainbow saturation number of $K_r$, since the standard weak saturation
number of complete graphs equals the standard saturation number. Surprisingly,
our lower bound separates the rainbow saturation number from the weak rainbow
saturation number, answering this question in the negative. The existence of
the constant $\alpha_r$ resolves another of their questions in the affirmative
for complete graphs. Furthermore, we show that the conjecture of Gir\~{a}o,
Lewis, and Popielarz is true if we have an additional assumption that the
edge-colored $K_r$-rainbow saturated graph must be rainbow. As an ingredient of
the proof, we study graphs which are $K_r$-saturated with respect to the
operation of deleting one edge and adding two edges.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 02:38:05 GMT""}]","2022-12-12"
"2212.04641","Tao Zhong","Tao Zhong, Dong Huang, Hai-Bing Fu","Revisiting $D$-meson twist-2, 3 distribution amplitudes","9 pages, 2 figures","Chin. Phys. C \textbf{47}, no.5,0553104 (2023)","10.1088/1674-1137/acc1cb",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  Due to the significant difference between the experimental measurements and
the theoretical predictions of standard model (SM) for the value of
$\mathcal{R}(D)$ of the semileptonic decay $B\to D\ell\bar{\nu}_{\ell}$, people
speculate that it may be the evidence of new physics beyond the SM. Usually,
the $D$-meson twist-2, 3 distribution amplitudes (DAs) $\phi_{2;D}(x,\mu)$,
$\phi_{3;D}^p(x,\mu)$ and $\phi_{3;D}^\sigma(x,\mu)$ are the main error sources
when using perturbative QCD factorization and light-cone QCD sum rules to study
$B\to D\ell\bar{\nu}_{\ell}$. Therefore, it is important to get more reasonable
and accurate behaviors for those DAs. Motivated by our previous work [Phys.
Rev. D 104, no.1, 016021 (2021)] on pionic leading-twist DA, we revisit
$D$-meson twist-2, 3 DAs $\phi_{2;D}(x,\mu)$, $\phi_{3;D}^p(x,\mu)$ and
$\phi_{3;D}^\sigma(x,\mu)$. New sum rules formulae for the $\xi$-moments of
these three DAs are suggested to obtain more accurate values. The light-cone
harmonic oscillator models for those DAs are improved, and whose model
parameters are determined by fitting the values of $\xi$-moments with the least
squares method.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 02:41:03 GMT""},{""version"":""v2"",""created"":""Thu, 6 Apr 2023 07:45:19 GMT""}]","2023-04-07"
"2212.04642","Yusuke Kousaka","Yusuke Kousaka, Taisei Sayo, Satoshi Iwasaki, Ryo Saki, Chiho Shimada,
  Hiroaki Shishido, Yoshihiko Togawa","Chirality-selected crystal growth and spin polarization over centimeters
  of transition metal disilicide crystals","9 pages, 6 figures",,"10.35848/1347-4065/aca8e2",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We performed a chirality-controlled crystal growth of transition metal
disilicide NbSi$_{2}$ and TaSi$_{2}$ by using a laser-diode-heated floating
zone (LDFZ) method. The crystal chirality was evaluated in the crystals of
centimeters in length by performing single crystal X-ray diffraction as well as
probing a spin polarization originating from chirality-induced spin selectivity
(CISS) effect. The crystals of right-handed NbSi$_{2}$ and of left-handed
TaSi$_{2}$ were obtained in the conventional LDFZ crystal growth, while the
left-handed NbSi$_{2}$ and right-handed TaSi$_{2}$ crystals were grown by the
LDFZ method with the composition-gradient feed rods. The spin polarization via
the CISS was observed over centimeters in the NbSi$_{2}$ single crystals and
the sign of the CISS signals was dependent on the chirality of crystals. The
correlation between the crystal chirality and CISS signals indicates that the
CISS measurements work as a non-destructive method for chirality determination
even in centimeter-long specimens.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 02:43:29 GMT""}]","2023-02-15"
"2212.04643","Andy Magid","Andy Magid","The Cyclic Vector Lemma","3 pages",,,,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $F$ be a differential field of characteristic zero with algebraically
closed constant field $C$. Let $E$ be a Picard--Vessiot closure of $F$, $R
\subset E$ its Picard--Vessiot ring and $\Pi$ the differential Galois group of
$E$ over $F$. Let $V$ be a differential $F$ module, finite dimensional as an
$F$ vector space. Then $V$ is singly generated as a differential $F$ module if
and only if there is a $\Pi$ module injection $\text{Hom}_F^\text{diff}(V,R)
\to R$. If $C \neq F$ such an injection always exists.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 02:46:53 GMT""},{""version"":""v2"",""created"":""Mon, 12 Dec 2022 03:15:06 GMT""}]","2022-12-13"
"2212.04644","Insoon Yang","Astghik Hakobyan, Insoon Yang","Wasserstein Distributionally Robust Control of Partially Observable
  Linear Stochastic Systems",,,,,"eess.SY cs.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Distributionally robust control (DRC) aims to effectively manage
distributional ambiguity in stochastic systems. While most existing works
address inaccurate distributional information in fully observable settings, we
consider a partially observable DRC problem for discrete-time linear systems
using the Wasserstein metric. For a tractable solution, we propose a novel
approximation method exploiting the Gelbrich bound of Wasserstein distance.
Using techniques from modern distributionally robust optimization, we derive a
closed-form expression for the optimal control policy and a tractable
semidefinite programming problem for the worst-case distribution policy in both
finite-horizon and infinite-horizon average-cost settings. The proposed method
features several salient theoretical properties, such as a guaranteed cost
property and a probabilistic out-of-sample performance guarantee, demonstrating
the distributional robustness of our controller. Furthermore, the resulting
controller is shown to ensure the closed-loop stability of the mean-state
system. The empirical performance of our method is tested through numerical
experiments on a power system frequency control problem.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 03:05:33 GMT""},{""version"":""v2"",""created"":""Thu, 22 Dec 2022 02:40:51 GMT""}]","2022-12-23"
"2212.04645","Minxian Xu","Sundas Iftikhar, Sukhpal Singh Gill, Chenghao Song, Minxian Xu,
  Mohammad Sadegh Aslanpour, Adel N. Toosi, Junhui Du, Huaming Wu, Shreya
  Ghosh, Deepraj Chowdhury, Muhammed Golec, Mohit Kumar, Ahmed M. Abdelmoniem,
  Felix Cuadrado, Blesson Varghese, Omer Rana, Schahram Dustdar and Steve Uhlig","AI-based Fog and Edge Computing: A Systematic Review, Taxonomy and
  Future Directions","49 page, 15 figures, 10 tables","Preprint for Publication in Elsevier IoT Journal 2022","10.1016/j.iot.2022.100674",,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Resource management in computing is a very challenging problem that involves
making sequential decisions. Resource limitations, resource heterogeneity,
dynamic and diverse nature of workload, and the unpredictability of fog/edge
computing environments have made resource management even more challenging to
be considered in the fog landscape. Recently Artificial Intelligence (AI) and
Machine Learning (ML) based solutions are adopted to solve this problem. AI/ML
methods with the capability to make sequential decisions like reinforcement
learning seem most promising for these type of problems. But these algorithms
come with their own challenges such as high variance, explainability, and
online training. The continuously changing fog/edge environment dynamics
require solutions that learn online, adopting changing computing environment.
In this paper, we used standard review methodology to conduct this Systematic
Literature Review (SLR) to analyze the role of AI/ML algorithms and the
challenges in the applicability of these algorithms for resource management in
fog/edge computing environments. Further, various machine learning, deep
learning and reinforcement learning techniques for edge AI management have been
discussed. Furthermore, we have presented the background and current status of
AI/ML-based Fog/Edge Computing. Moreover, a taxonomy of AI/ML-based resource
management techniques for fog/edge computing has been proposed and compared the
existing techniques based on the proposed taxonomy. Finally, open challenges
and promising future research directions have been identified and discussed in
the area of AI/ML-based fog/edge computing.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 03:05:51 GMT""}]","2022-12-26"
"2212.04646","Michael Everett","Michael Everett, Rudy Bunel, Shayegan Omidshafiei","DRIP: Domain Refinement Iteration with Polytopes for Backward
  Reachability Analysis of Neural Feedback Loops",,,,,"eess.SY cs.LG cs.SY","http://creativecommons.org/licenses/by/4.0/","  Safety certification of data-driven control techniques remains a major open
problem. This work investigates backward reachability as a framework for
providing collision avoidance guarantees for systems controlled by neural
network (NN) policies. Because NNs are typically not invertible, existing
methods conservatively assume a domain over which to relax the NN, which causes
loose over-approximations of the set of states that could lead the system into
the obstacle (i.e., backprojection (BP) sets). To address this issue, we
introduce DRIP, an algorithm with a refinement loop on the relaxation domain,
which substantially tightens the BP set bounds. Furthermore, we introduce a
formulation that enables directly obtaining closed-form representations of
polytopes to bound the BP sets tighter than prior work, which required solving
linear programs and using hyper-rectangles. Furthermore, this work extends the
NN relaxation algorithm to handle polytope domains, which further tightens the
bounds on BP sets. DRIP is demonstrated in numerical experiments on control
systems, including a ground robot controlled by a learned NN obstacle avoidance
policy.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 03:06:58 GMT""},{""version"":""v2"",""created"":""Fri, 17 Mar 2023 21:03:07 GMT""}]","2023-03-21"
"2212.04647","Arpan Kar","Arpan Kar, Tanmoy Kumar, Sourov Roy, Jure Zupan","Searching for relativistic axions in the sky","24 pages, 12 figures",,,,"hep-ph astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Relativistic axions produced in decays of ${\mathcal O}(10^{-7}-10^{-2}$
$\text{eV})$ dark matter (DM) partially convert to photons after traversing the
galactic magnetic field, giving rise to a signal observable by the Square
Kilometer Array (SKA) radio telescope. We show that for axions lighter than a
few $\times$ $10^{-13}$ eV a 100\,h SKA observation of the local dwarf galaxy
Seg I would probe parameter space not constrained by stellar cooling and
cosmological observations, with sensitivity several orders of magnitude better
than the planned dedicated axion dark matter search experiments. We quantify
the uncertainties in the SKA sensitivity projections due to two effects that
enhance the photon flux: the presence of turbulent magnetic fields inside the
galaxy, and the Bose enhancement of the DM decays to axions, where the latter,
in particular, warrants further study.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 03:19:29 GMT""}]","2022-12-12"
"2212.04648","Matthew Miles Mr","Matthew T. Miles, Ryan M. Shannon, Matthew Bailes, Daniel J. Reardon,
  Michael J. Keith, Andrew D. Cameron, Aditya Parthasarathy, Mohsen
  Shamohammadi, Renee Spiewak, Willem van Straten, Sarah Buchner, Fernando
  Camilo, Marisa Geyer, Aris Karastergiou, Michael Kramer, Maciej Serylak,
  Gilles Theureau, and Vivek Venkatraman Krishnan","The MeerKAT Pulsar Timing Array: First Data Release","18 pages, 6 figures",,"10.1093/mnras/stac3644",,"astro-ph.HE astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the first 2.5 years of data from the MeerKAT Pulsar Timing Array
(MPTA), part of MeerTime, a MeerKAT Large Survey Project. The MPTA aims to
precisely measure pulse arrival times from an ensemble of 88 pulsars visible
from the Southern Hemisphere, with the goal of contributing to the search,
detection and study of nanohertz-frequency gravitational waves as part of the
International Pulsar Timing Array. This project makes use of the MeerKAT
telescope, and operates with a typical observing cadence of two weeks using the
L-band receiver that records data from 856-1712 MHz. We provide a comprehensive
description of the observing system, software, and pipelines used and developed
for the MeerTime project. The data products made available as part of this data
release are from the 78 pulsars that had at least $30$ observations between the
start of the MeerTime programme in February 2019 and October 2021. These
include both sub-banded and band-averaged arrival times, as well as the initial
timing ephemerides, noise models, and the frequency-dependent standard
templates (portraits) used to derive pulse arrival times. After accounting for
detected noise processes in the data, the frequency-averaged residuals of $67$
of the pulsars achieved a root-mean-square residual precision of $< 1 \mu
\rm{s}$. We also present a novel recovery of the clock correction waveform
solely from pulsar timing residuals, and an exploration into preliminary
findings of interest to the international pulsar timing community. The arrival
times, standards and full Stokes parameter calibrated pulsar timing archives
are publicly available.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 03:22:32 GMT""}]","2022-12-21"
"2212.04649","Cristian Villavicencio","Cristi\'an Villavicencio","Axial coupling constant in a magnetic background","6 pages, 5 figures. The case of average flavor approximation was
  removed. Accepted for publication in PRD","Phys. Rev. D 107, 076009 (2023)","10.1103/PhysRevD.107.076009",,"hep-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The nucleon axial coupling constant $g_A$ is calculated in the presence of an
external uniform magnetic field using finite energy sum rules. The correlation
function of proton, neutron and axial-vector currents is calculated both the
hadronic and the QCD sector. Once the axial contribution in the form factor is
isolated, a double sum rule is considered, i.e., the usual QCD contour
integration for the external moments of both the proton and neutron current.
The effects of the external magnetic field come mainly through the in-medium
current-nucleon coupling constants $\lambda_N(B)$ and the hadronic thresholds
$s_0(B)$ provided by the nucleon-nucleon correlators. As a result, the axial
coupling constant decreases in the presence of the magnetic field.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 03:33:54 GMT""},{""version"":""v2"",""created"":""Thu, 5 Jan 2023 20:45:14 GMT""},{""version"":""v3"",""created"":""Mon, 3 Apr 2023 22:47:22 GMT""}]","2023-04-12"
"2212.04650","Hong-Mei Zou","Jia Wang and Dan Long and Qilin Wang and Hong-Mei Zou and Chenya Liu
  and Qianqian Ma","Protecting Entanglement of Two V-type Atoms in Dissipative Cavity by
  Dipole-Dipole Interaction","10 pages, 9 figures",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we study a coupled system of two V-type atoms interacting with
a dissipative single-mode cavity, which couples with an external environment.
Firstly, in order to diagonalize Hamiltonian of dissipative cavity, we
introduce a set of new creation and annihilation operators according to theorem
Fano. Then, we obtain the analytical solution of this model by solving the time
dependent Schrodinger equation. We also discuss in detail the influences of the
cavity-environment coupling, the SGI parameter, the initial state and the
dipole-dipole interaction between the two atoms on entanglement dynamics. The
results show that, with the SGI parameter increasing, the entanglement will
decay quicker for the initially maximal entangled state but it will decay
slower for the initially partial entangled state. For the initially product
state, the larger the SGI parameter, the more entanglement will be generated.
The strong coupling can protect entanglement to some extent, but the
dipole-dipole interaction can significantly protect entanglement. Moreover, the
dipole-dipole interaction can not only generate entanglement very effectively,
but also enhance the regulation effect of {\theta} on entanglement for the
initially partial entangled and product states.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 03:34:13 GMT""}]","2022-12-12"
"2212.04651","Yitong Li","Yitong Li, Fengxiu Zhang, Wenying Ji","Automated Integration of Infrastructure Component Status for Real-Time
  Restoration Progress Control: Case Study of Highway System in Hurricane
  Harvey",,,,,"cs.CE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Following extreme events, efficient restoration of infrastructure systems is
critical to sustaining community lifelines. During the process, effective
monitoring and control of the infrastructure restoration progress is critical.
This research proposes a systematic approach that automatically integrates
component-level restoration status to achieve real-time forecasting of overall
infrastructure restoration progress. In this research, the approach is mainly
designed for transportation infrastructure restoration following Hurricane
Harvey. In detail, the component-level restoration status is linked to the
restoration progress forecasting through network modeling and earned value
method. Once the new component restoration status is collected, the information
is automatically integrated to update the overall restoration progress
forecasting. Academically, an approach is proposed to automatically transform
the component-level restoration information to overall restoration progress. In
practice, the approach expects to ease the communication and coordination
efforts between emergency managers, thereby facilitating timely identification
and resolution of issues for rapid infrastructure restoration.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 03:43:40 GMT""}]","2022-12-12"
"2212.04652","Murray Barrett","Zhang Zhiqiang, Kyle J. Arnold, and Rattakorn Kaewuam, and M. D.
  Barrett","$^{176}$Lu$^+$ clock comparison at the $10^{-18}$ level via correlation
  spectroscopy","Main text: 6 pages and 3 figures, Supplemental: 12 pages and 6 figs",,,,"quant-ph physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We experimentally demonstrate agreement between two $^{176}$Lu$^+$ frequency
references using correlation spectroscopy. From a comparison at different
magnetic fields, we obtain a quadratic Zeeman coefficient of
$-4.89264(88)\,\mathrm{Hz/mT^2}$, which gives a corresponding fractional
frequency uncertainty contribution of just $2.5\times 10^{-20}$ for comparisons
at typical operating fields of 0.1\,mT. A subsequent comparison with both
systems at 0.1\,mT, demonstrates a fractional frequency difference of
$(-2.0\pm(3.7)_\mathrm{stat}\pm(0.9)_\mathrm{sys})\times10^{-18}$, where `stat'
and `sys' indicate statistical and systematic uncertainty, respectively.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 03:50:22 GMT""}]","2022-12-12"
"2212.04653","Ye Feng","Ye Feng, James F. Steiner, Santiago Ubach Ramirez, Lijun Gou","Using X-ray continuum-fitting to estimate the spin of MAXI J1305-704","13 pages, 10 figures, submitted to MNRAS",,"10.1093/mnras/stad442",,"astro-ph.HE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  MAXI J1305-704 is a transient X-ray binary with a black hole primary. It was
discovered on April 9, 2012, during its only known outburst. MAXI J1305-704 is
also a high inclination low-mass X-ray binary with prominent dip features in
its light curves, so we check the full catalog of 92 \emph{Swift}/XRT
continuous observations of MAXI J1305-704, focusing only on the stable spectra.
We select 13 ``gold"" spectra for which the root mean square RMS <0.075 and the
coronal scattered fraction $f_{\mathrm{sc}} \lesssim 25 \%$. These ``gold"" data
are optimal thermal-state observations for continuum-fitting modeling, in which
the disk extends to the innermost-stable circular orbit and is geometrically
thin. The black hole spin was unknown for this object before. By utilizing the
X-ray continuum fitting method with the relativistic thin disk model
\texttt{kerrbb2} and supplying the known dynamical binary system parameters, we
find MAXI J1305-704 has a moderate spin ($a_{*}=0.87_{-0.13}^{+0.07}$) at a
68.3\% confidence level. This is the first determination of MAXI J1305-704's
spin.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 03:51:41 GMT""}]","2023-02-15"
"2212.04654","Yitong Li","Ruqayah Alsayed Ebrahim, Shivanan Singh, Yitong Li, Wenying Ji","Discrete Event Simulation for Port Berth Maintenance Planning",,,,,"cs.CE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Industrial and commercial ports, which are one of the three main hubs to the
country, require 24/7 operations to maintain the goods export and import flow.
Due to the aging and weather factors, berths require regular maintenance, such
as replacing old piles, timber finders, marine ladders, rubber fenders, and
deck slabs. For efficient berth maintenance, strategies are highly desired to
minimize or eliminate any delays in operations during the maintenance. This
paper develops a discrete event simulation model using Simphony.NET for berth
maintenance processes in Doha Port, Kuwait. The model derives minimum
maintenance duration under limited resources and associated uncertainties. The
model can be used as a decision support tool to minimize interruption or delays
in the port maintenance operations.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 03:52:56 GMT""}]","2022-12-12"
"2212.04655","Ning Shuliang","Shuliang Ning, Mengcheng Lan, Yanran Li, Chaofeng Chen, Qian Chen,
  Xunlai Chen, Xiaoguang Han, Shuguang Cui","MIMO Is All You Need : A Strong Multi-In-Multi-Out Baseline for Video
  Prediction",,"AAAI 2023",,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The mainstream of the existing approaches for video prediction builds up
their models based on a Single-In-Single-Out (SISO) architecture, which takes
the current frame as input to predict the next frame in a recursive manner.
This way often leads to severe performance degradation when they try to
extrapolate a longer period of future, thus limiting the practical use of the
prediction model. Alternatively, a Multi-In-Multi-Out (MIMO) architecture that
outputs all the future frames at one shot naturally breaks the recursive manner
and therefore prevents error accumulation. However, only a few MIMO models for
video prediction are proposed and they only achieve inferior performance due to
the date. The real strength of the MIMO model in this area is not well noticed
and is largely under-explored. Motivated by that, we conduct a comprehensive
investigation in this paper to thoroughly exploit how far a simple MIMO
architecture can go. Surprisingly, our empirical studies reveal that a simple
MIMO model can outperform the state-of-the-art work with a large margin much
more than expected, especially in dealing with longterm error accumulation.
After exploring a number of ways and designs, we propose a new MIMO
architecture based on extending the pure Transformer with local spatio-temporal
blocks and a new multi-output decoder, namely MIMO-VP, to establish a new
standard in video prediction. We evaluate our model in four highly competitive
benchmarks (Moving MNIST, Human3.6M, Weather, KITTI). Extensive experiments
show that our model wins 1st place on all the benchmarks with remarkable
performance gains and surpasses the best SISO model in all aspects including
efficiency, quantity, and quality. We believe our model can serve as a new
baseline to facilitate the future research of video prediction tasks. The code
will be released.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 03:57:13 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 04:24:16 GMT""},{""version"":""v3"",""created"":""Tue, 30 May 2023 04:55:09 GMT""}]","2023-05-31"
"2212.04656","Tommaso Salvatori","Billy Byiringiro, Tommaso Salvatori, Thomas Lukasiewicz","Robust Graph Representation Learning via Predictive Coding","27 Pages, 31 Figures",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Predictive coding is a message-passing framework initially developed to model
information processing in the brain, and now also topic of research in machine
learning due to some interesting properties. One of such properties is the
natural ability of generative models to learn robust representations thanks to
their peculiar credit assignment rule, that allows neural activities to
converge to a solution before updating the synaptic weights. Graph neural
networks are also message-passing models, which have recently shown outstanding
results in diverse types of tasks in machine learning, providing
interdisciplinary state-of-the-art performance on structured data. However,
they are vulnerable to imperceptible adversarial attacks, and unfit for
out-of-distribution generalization. In this work, we address this by building
models that have the same structure of popular graph neural network
architectures, but rely on the message-passing rule of predictive coding.
Through an extensive set of experiments, we show that the proposed models are
(i) comparable to standard ones in terms of performance in both inductive and
transductive tasks, (ii) better calibrated, and (iii) robust against multiple
kinds of adversarial attacks.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 03:58:22 GMT""}]","2022-12-12"
"2212.04657","Michael LaHaye","Michael LaHaye, Huan Yang, B\'eatrice Bonga, and Zhenwei Lyu","Efficient fully precessing gravitational waveforms for binaries with
  neutron stars","Corrected minor typos and a typo in Fig 9 resulting in the incorrect
  placement in the images",,,,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  We construct an efficient frequency domain waveform for generic circular
compact object binaries that include neutron stars. The orbital precession is
solved on the radiation reaction timescale (and then transformed to the
frequency domain), which is used to map the non-precessional waveform from the
source frame of the binary to the lab frame. The treatment of orbital
precession is different from that for precessional binary black holes, as
$\chi_{\rm eff}$ is no longer conserved due to the spin-induced quadrupole
moments of neutron stars. We show that the new waveform achieves $\le 10^{-4}$
mismatch compared with waveforms generated by numerically evolved precession
for neutron star-black hole systems for $\ge 90\%$ configurations with
component mass/spin magnitude assumed in the analysis and randomized initial
spin directions. We expect this waveform to be useful to test the nature of the
mass-gap objects similar to the one discovered in GW 190814 by measuring their
spin-induced quadrupole moments, as it is possible that these mass-gap objects
are rapidly spinning. It is also applicable for the tests of black hole
mimickers in precessional binary black hole events, if the black hole mimicker
candidates have nontrivial spin-induced quadrupole moments.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 03:58:45 GMT""},{""version"":""v2"",""created"":""Mon, 19 Dec 2022 04:49:59 GMT""}]","2022-12-20"
"2212.04658","Guntur Dharma Putra","Guntur Dharma Putra, Sidra Malik, Volkan Dedeoglu, Salil S Kanhere,
  Raja Jurdak","Trust and Reputation Management for Blockchain-enabled IoT","COMSNETS 2023 Invited Paper",,,,"cs.CR cs.NI","http://creativecommons.org/licenses/by/4.0/","  In recent years, there has been an increasing interest in incorporating
blockchain for the Internet of Things (IoT) to address the inherent issues of
IoT, such as single point of failure and data silos. However, blockchain alone
cannot ascertain the authenticity and veracity of the data coming from IoT
devices. The append-only nature of blockchain exacerbates this issue, as it
would not be possible to alter the data once recorded on-chain. Trust and
Reputation Management (TRM) is an effective approach to overcome the
aforementioned trust issues. However, designing TRM frameworks for
blockchain-enabled IoT applications is a non-trivial task, as each application
has its unique trust challenges with their unique features and requirements. In
this paper, we present our experiences in designing TRM framework for various
blockchain-enabled IoT applications to provide insights and highlight open
research challenges for future opportunities.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 04:00:21 GMT""}]","2022-12-12"
"2212.04659","Ben Cameron","Ben Cameron, Ch\'inh T. Ho\`ang","A refinement on the structure of vertex-critical ($P_5$, gem)-free
  graphs",,,,,"math.CO cs.DM cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a new, stronger proof that there are only finitely many
$k$-vertex-critical ($P_5$,~gem)-free graphs for all $k$. Our proof further
refines the structure of these graphs and allows for the implementation of a
simple exhaustive computer search to completely list all $6$- and
$7$-vertex-critical $(P_5$, gem)-free graphs. Our results imply the existence
of polynomial-time certifying algorithms to decide the $k$-colourability of
$(P_5$, gem)-free graphs for all $k$ where the certificate is either a
$k$-colouring or a $(k+1)$-vertex-critical induced subgraph. Our complete lists
for $k\le 7$ allow for the implementation of these algorithms for all $k\le 6$.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 04:05:49 GMT""}]","2022-12-12"
"2212.04660","Karthick Subramani","Varun Kumar Rajendran, Aravind Ram S P, and Karthick Subramani","On the stability of inhomogeneous fluids under acoustic fields","16 pages, 6 figures",,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  In this work, we present the stability theory for inhomogeneous fluids
subjected to standing acoustic fields. Starting from the first principles, the
stability criterion is established for two fluids of different acoustic
impedance separated by a plane interface. Through stability theory and
numerical simulations we show that, in the presence of interfacial tension, the
relocation of high-impedance fluid from anti-node to node occurs when the
acoustic force overcomes interfacial tension force, which is in agreement with
recent microchannel experiments. Furthermore, we establish an acoustic Bond
number that characterizes stable (Bo_a < 1) and relocation (Bo_a > 1) regimes.
Remarkably, it is found that the critical acoustic energy density required for
relocation can be significantly reduced by increasing the channel height which
could help design acoustofluidic microchannel devices that handle immiscible
fluids.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 04:12:05 GMT""}]","2022-12-12"
"2212.04661","Meng Zhou","Meng Zhou, Xiaolan Xu, Yuxuan Zhang","An Attention-based Multi-Scale Feature Learning Network for Multimodal
  Medical Image Fusion","8 pages, 8 figures, 3 tables",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Medical images play an important role in clinical applications. Multimodal
medical images could provide rich information about patients for physicians to
diagnose. The image fusion technique is able to synthesize complementary
information from multimodal images into a single image. This technique will
prevent radiologists switch back and forth between different images and save
lots of time in the diagnostic process. In this paper, we introduce a novel
Dilated Residual Attention Network for the medical image fusion task. Our
network is capable to extract multi-scale deep semantic features. Furthermore,
we propose a novel fixed fusion strategy termed Softmax-based weighted strategy
based on the Softmax weights and matrix nuclear norm. Extensive experiments
show our proposed network and fusion strategy exceed the state-of-the-art
performance compared with reference image fusion methods on four commonly used
fusion metrics.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 04:19:43 GMT""}]","2022-12-12"
"2212.04662","Jessica Purcell","Connie On Yu Hui and Jessica S. Purcell","On the geometry of rod packings in the 3-torus","21 pages, 9 figures",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Rod packings in the 3-torus encode information of some crystal structures in
crystallography. They can be viewed as links in the 3-torus, and tools from
3-manifold geometry and topology can be used to study their complements. In
this paper, we initiate the use of geometrisation to study such packings. We
analyse the geometric structures of the complements of simple rod packings, and
find families that are hyperbolic and Seifert fibred.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 04:31:08 GMT""}]","2022-12-12"
"2212.04663","Wuzhe Xu","Wuzhe Xu, Yulong Lu and Li Wang","Transfer Learning Enhanced DeepONet for Long-Time Prediction of
  Evolution Equations",,,,,"cs.LG cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep operator network (DeepONet) has demonstrated great success in various
learning tasks, including learning solution operators of partial differential
equations. In particular, it provides an efficient approach to predict the
evolution equations in a finite time horizon. Nevertheless, the vanilla
DeepONet suffers from the issue of stability degradation in the long-time
prediction. This paper proposes a {\em transfer-learning} aided DeepONet to
enhance the stability. Our idea is to use transfer learning to sequentially
update the DeepONets as the surrogates for propagators learned in different
time frames. The evolving DeepONets can better track the varying complexities
of the evolution equations, while only need to be updated by efficient training
of a tiny fraction of the operator networks. Through systematic experiments, we
show that the proposed method not only improves the long-time accuracy of
DeepONet while maintaining similar computational cost but also substantially
reduces the sample size of the training set.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 04:37:08 GMT""}]","2022-12-12"
"2212.04664","Mahmoud Abu-samha","Mahmoud Abu-samha and Lars Bojer Madsen","Strong-field ionization and AC-Stark shifted Rydberg states in OCS","3 figures",,"10.1088/1361-6455/acc8a8",,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present theoretical results for intensity-dependent above-threshold
ionization (ATI) spectra from oriented OCS molecules probed by intense
femtosecond laser pulses with wavelengths of 800 and 400 nm. The calculations
were performed using the time-dependent Schroodinger equation within the
single-active-electron approximation and including multielectron polarization
effects. The results are in qualitative agreement with experimental data [Yu et
al., J. Phys. B: At. Mol. Opt. Phys. 50, 235602 (2017)]. In particular,
characteristic features in the ATI spectra which correspond to resonant
multiphoton ionization via highly-excited Rydberg states are captured by the
theory.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 04:38:13 GMT""}]","2023-04-26"
"2212.04665","Soumyadip Roy","Soumyadip Roy, Chaitanya Roygaga, Nathaniel Blanchard, Aparna Bharati","A Computer Vision Method for Estimating Velocity from Jumps",,"2nd Workshop on Computer Vision for Winter Sports 2023",,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Athletes routinely undergo fitness evaluations to evaluate their training
progress. Typically, these evaluations require a trained professional who
utilizes specialized equipment like force plates. For the assessment, athletes
perform drop and squat jumps, and key variables are measured, e.g. velocity,
flight time, and time to stabilization, to name a few. However, amateur
athletes may not have access to professionals or equipment that can provide
these assessments. Here, we investigate the feasibility of estimating key
variables using video recordings. We focus on jump velocity as a starting point
because it is highly correlated with other key variables and is important for
determining posture and lower-limb capacity. We find that velocity can be
estimated with a high degree of precision across a range of athletes, with an
average R-value of 0.71 (SD = 0.06).
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 04:40:36 GMT""}]","2022-12-12"
"2212.04666","Yuval Bahat","Yuval Bahat, Yuxuan Zhang, Hendrik Sommerhoff, Andreas Kolb and Felix
  Heide","Neural Volume Super-Resolution",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural volumetric representations have become a widely adopted model for
radiance fields in 3D scenes. These representations are fully implicit or
hybrid function approximators of the instantaneous volumetric radiance in a
scene, which are typically learned from multi-view captures of the scene. We
investigate the new task of neural volume super-resolution - rendering
high-resolution views corresponding to a scene captured at low resolution. To
this end, we propose a neural super-resolution network that operates directly
on the volumetric representation of the scene. This approach allows us to
exploit an advantage of operating in the volumetric domain, namely the ability
to guarantee consistent super-resolution across different viewing directions.
To realize our method, we devise a novel 3D representation that hinges on
multiple 2D feature planes. This allows us to super-resolve the 3D scene
representation by applying 2D convolutional networks on the 2D feature planes.
We validate the proposed method by super-resolving multi-view consistent views
on a diverse set of unseen 3D scenes, confirming qualitative and quantitatively
favorable quality over existing approaches.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 04:54:13 GMT""},{""version"":""v2"",""created"":""Fri, 5 May 2023 20:32:30 GMT""}]","2023-05-09"
"2212.04667","Danhua Song","Danhua Song, Mengyao Wu, Ke Wu and Jie Yang","Higher Chern-Simons based on (2-)crossed modules",,,,,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present higher Chern-Simons theories based on (2-)crossed modules. We
start from the generalized differential forms in Generalized Differential
Calculus and define the corresponding generalized connections which consist of
higher connections. Then we establish the generalized Chern-Simons forms to get
the higher Chern-Simons actions. Finally, we develop the higher second Chern
forms and Chern-Weil theorems.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 04:57:20 GMT""}]","2022-12-12"
"2212.04668","Yuyang Zhao","Yuyang Zhao, Na Zhao, Gim Hee Lee","Synthetic-to-Real Domain Generalized Semantic Segmentation for 3D Indoor
  Point Clouds",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Semantic segmentation in 3D indoor scenes has achieved remarkable performance
under the supervision of large-scale annotated data. However, previous works
rely on the assumption that the training and testing data are of the same
distribution, which may suffer from performance degradation when evaluated on
the out-of-distribution scenes. To alleviate the annotation cost and the
performance degradation, this paper introduces the synthetic-to-real domain
generalization setting to this task. Specifically, the domain gap between
synthetic and real-world point cloud data mainly lies in the different layouts
and point patterns. To address these problems, we first propose a clustering
instance mix (CINMix) augmentation technique to diversify the layouts of the
source data. In addition, we augment the point patterns of the source data and
introduce non-parametric multi-prototypes to ameliorate the intra-class
variance enlarged by the augmented point patterns. The multi-prototypes can
model the intra-class variance and rectify the global classifier in both
training and inference stages. Experiments on the synthetic-to-real benchmark
demonstrate that both CINMix and multi-prototypes can narrow the distribution
gap and thus improve the generalization ability on real-world datasets.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 05:07:43 GMT""}]","2022-12-12"
"2212.04669","Antonino Marciano","Kristian Piscicchia, Andrea Addazi, Antonino Marciano, Massimiliano
  Bazzi, Michael Cargnelli, Alberto Clozza, Luca De Paolis, Raffaele Del
  Grande, Carlo Guaraldo, Mihail Antoniu Iliescu, Matthias Laubenstein, Johann
  Marton, Marco Miliucci, Fabrizio Napolitano, Alessio Porcelli, Alessandro
  Scordo, Diana Laura Sirghi, Florin Sirghi, Oton Vazquez Doce, Johann Zmeskal,
  Catalina Curceanu","Experimental test of Non-Commutative Quantum Gravity by VIP-2 Lead","13 pages, 2 figures. arXiv admin note: substantial text overlap with
  arXiv:2209.00074",,"10.1103/PhysRevD.107.026002",,"hep-th gr-qc hep-ex hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pauli Exclusion Principle (PEP) violations induced by space-time
non-commutativity, a class of universality for several models of Quantum
Gravity, are investigated by the VIP-2 Lead experiment at the Gran Sasso
underground National Laboratory of INFN. The VIP-2 Lead experimental bound on
the non-commutative space-time scale $\Lambda$ excludes $\theta$-Poincar\'e far
above the Planck scale for non vanishing ``electric-like"" components of
$\theta_{\mu \nu}$, and up to $6.9 \cdot 10^{-2}$ Planck scales if they are
null. Therefore, this new bound represents the tightest one so far provided by
atomic transitions tests. This result strongly motivates high sensitivity
underground X-ray measurements as critical tests of Quantum Gravity and of the
very microscopic space-time structure.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 05:15:37 GMT""}]","2023-01-18"
"2212.04670","Nicholas Yama","Srivatsa Chakravarthi, Nicholas S. Yama, Alex Abulnaga, Ding Huang,
  Christian Pederson, Karine Hestroffer, Fariba Hatami, Nathalie P. de Leon,
  Kai-Mei C. Fu","Hybrid Integration of GaP Photonic Crystal Cavities with Silicon-Vacancy
  Centers in Diamond by Stamp-Transfer",,,"10.1021/acs.nanolett.2c04890",,"quant-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Optically addressable solid-state defects are emerging as one of the most
promising qubit platforms for quantum networks. Maximizing photon-defect
interaction by nanophotonic cavity coupling is key to network efficiency. We
demonstrate fabrication of gallium phosphide 1-D photonic crystal waveguide
cavities on a silicon oxide carrier and subsequent integration with implanted
silicon-vacancy (SiV) centers in diamond using a stamp-transfer technique. The
stamping process avoids diamond etching and allows fine-tuning of the cavities
prior to integration. After transfer to diamond, we measure cavity quality
factors ($Q$) of up to 8900 and perform resonant excitation of single SiV
centers coupled to these cavities. For a cavity with $Q$ of 4100, we observe a
three-fold lifetime reduction on-resonance, corresponding to a maximum
potential cooperativity of $C = 2$. These results indicate promise for high
photon-defect interaction in a platform which avoids fabrication of the quantum
defect host crystal.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 05:26:25 GMT""},{""version"":""v2"",""created"":""Tue, 13 Dec 2022 22:16:43 GMT""}]","2023-05-24"
"2212.04671","Aiyappan Srinivasan","S Aiyappan, Georges Griso and Julia Orlik","Homogenization of Helmholtz equation in a periodic layer to study
  Faraday cage-like shielding effects",,,"10.1080/17476933.2022.2155637",,"math.AP","http://creativecommons.org/licenses/by/4.0/","  The work is motivated by the Faraday cage effect. We consider the Helmholtz
equation over a 3D-domain containing a thin heterogeneous interface of
thickness $\delta \ll 1$. The layer has a $\delta-$periodic structure in the
in-plane directions and is cylindrical in the third direction. The periodic
layer has one connected component and a collection of isolated regions. The
isolated region in the thin layer represents air or liquid, and the connected
component represents a solid metal grid with a $\delta$ thickness. The main
issue is created by the contrast of the coefficients in the air and in the grid
and that the zero-order term has a complex-valued coefficient in the connected
faze while a real-valued in the complement. An asymptotic analysis with respect
to $\delta \to 0$ is provided, and the limit Helmholtz problem is obtained with
the Dirichlet condition on the interface. The periodic unfolding method is used
to find the limit.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 05:26:47 GMT""}]","2022-12-12"
"2212.04672","Zi Xu","Huiling Zhang, Junlin Wang, Zi Xu, Yu-Hong Dai","Primal Dual Alternating Proximal Gradient Algorithms for Nonsmooth
  Nonconvex Minimax Problems with Coupled Linear Constraints",,,,,"math.OC cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nonconvex minimax problems have attracted wide attention in machine learning,
signal processing and many other fields in recent years. In this paper, we
propose a primal dual alternating proximal gradient (PDAPG) algorithm and a
primal dual proximal gradient (PDPG-L) algorithm for solving nonsmooth
nonconvex-(strongly) concave and nonconvex-linear minimax problems with coupled
linear constraints, respectively. The iteration complexity of the two
algorithms are proved to be $\mathcal{O}\left( \varepsilon ^{-2} \right)$
(resp. $\mathcal{O}\left( \varepsilon ^{-4} \right)$) under nonconvex-strongly
concave (resp. nonconvex-concave) setting and $\mathcal{O}\left( \varepsilon
^{-3} \right)$ under nonconvex-linear setting to reach an
$\varepsilon$-stationary point, respectively. To our knowledge, they are the
first two algorithms with iteration complexity guarantee for solving the
nonconvex minimax problems with coupled linear constraints.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 05:32:30 GMT""},{""version"":""v2"",""created"":""Sun, 15 Jan 2023 04:21:15 GMT""}]","2023-01-18"
"2212.04673","Seonghyeon Moon","Seonghyeon Moon, Samuel S. Sohn, Honglu Zhou, Sejong Yoon, Vladimir
  Pavlovic, Muhammad Haris Khan, Mubbasir Kapadia","MSI: Maximize Support-Set Information for Few-Shot Segmentation",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  FSS(Few-shot segmentation) aims to segment a target class using a small
number of labeled images (support set). To extract the information relevant to
target class, a dominant approach in best performing FSS methods removes
background features using a support mask. We observe that this feature excision
through a limiting support mask introduces an information bottleneck in several
challenging FSS cases, e.g., for small targets and/or inaccurate target
boundaries. To this end, we present a novel method (MSI), which maximizes the
support-set information by exploiting two complementary sources of features to
generate super correlation maps. We validate the effectiveness of our approach
by instantiating it into three recent and strong FSS methods. Experimental
results on several publicly available FSS benchmarks show that our proposed
method consistently improves the performance by visible margins and leads to
faster convergence. Our code and models will be publicly released.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 05:38:07 GMT""},{""version"":""v2"",""created"":""Thu, 30 Mar 2023 05:04:25 GMT""}]","2023-03-31"
"2212.04674","Xianghan Cui","Cheng-Min Zhang, Xiang-Han Cui, Di Li, De-Hua Wang, Shuang-Qiang Wang,
  Na Wang, Jian-Wei Zhang, Bo Peng, Wei-Wei Zhu, Yi-Yan Yang, Yuan-Yue Pan","Evolution of Spin Period and Magnetic Field of the Crab Pulsar: Decay of
  the Braking Index by the Particle Wind Flow Torque","21pages, 3 figures, 2 tables, and 5 appendices, published in Universe",,"10.3390/universe8120628",,"astro-ph.HE astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  The evolutions of a neutron star's rotation and magnetic field (B-field) have
remained unsolved puzzles for over half a century. We ascribe the rotational
braking torques of pulsar to both components, the standard magnetic dipole
radiation (MDR) and particle wind flow ( MDR + Wind, hereafter named MDRW),
which we apply to the Crab pulsar (B0531 + 21), the only source with a known
age and long-term continuous monitoring by radio telescope. Based on the above
presumed simple spin-down torques, we obtain the exact analytic solution on the
rotation evolution of the Crab pulsar, together with the related outcomes as
described below: (1) unlike the constant characteristic B-field suggested by
the MDR model, this value for the Crab pulsar increases by a hundred times in
50~kyr while its real B-field has no change; (2) the rotational braking index
evolves from $\sim$3 to 1 in the long-term, however, it drops from 2.51 to 2.50
in $\sim$45 years at the present stage, while the particle flow contributes
approximately 25% of the total rotational energy loss rate; (3) strikingly, the
characteristic age has the maximum limit of $\sim$10 kyr, meaning that it is
not always a good indicator of real age. Furthermore, we discussed the
evolutionary path of the Crab pulsar from the MDR to the wind domination by
comparing it with the possible wind braking candidate pulsar PSR J1734-3333.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 05:45:22 GMT""}]","2022-12-12"
"2212.04675","Qi Jiang","Qi Jiang, Hao Sun, Xi Zhang","SemanticBEVFusion: Rethink LiDAR-Camera Fusion in Unified Bird's-Eye
  View Representation for 3D Object Detection","The first two authors contributed equally to this work",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  LiDAR and camera are two essential sensors for 3D object detection in
autonomous driving. LiDAR provides accurate and reliable 3D geometry
information while the camera provides rich texture with color. Despite the
increasing popularity of fusing these two complementary sensors, the challenge
remains in how to effectively fuse 3D LiDAR point cloud with 2D camera images.
Recent methods focus on point-level fusion which paints the LiDAR point cloud
with camera features in the perspective view or bird's-eye view (BEV)-level
fusion which unifies multi-modality features in the BEV representation. In this
paper, we rethink these previous fusion strategies and analyze their
information loss and influences on geometric and semantic features. We present
SemanticBEVFusion to deeply fuse camera features with LiDAR features in a
unified BEV representation while maintaining per-modality strengths for 3D
object detection. Our method achieves state-of-the-art performance on the
large-scale nuScenes dataset, especially for challenging distant objects. The
code will be made publicly available.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 05:48:58 GMT""}]","2022-12-12"
"2212.04676","Renjun Duan","Renjun Duan, Zongguang Li, and Shuangqian Liu","Global mild solution with polynomial tail for the Boltzmann equation in
  the whole space","33 pages. Wording improved and statements made more precise",,,,"math.AP math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We are concerned with the Cauchy problem on the Boltzmann equation in the
whole space. The goal is to construct global-in-time bounded mild solutions
near Maxwellians with the perturbation admitting a polynomial tail in large
velocities. The proof is based on the Caflisch's decomposition together with
the $L^2- L^\infty$ interplay technique developed by Guo. The full range of
both hard and soft potentials under the Grad's cutoff assumption can be
covered. The main difficulty to be overcome in case of the whole space is the
polynomial time decay of solutions which is much slower than the exponential
rate in contrast with the torus case.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 05:51:23 GMT""},{""version"":""v2"",""created"":""Tue, 31 Jan 2023 05:40:05 GMT""}]","2023-02-01"
"2212.04677","Injoon Cho","Injoon Cho, Praveen Kumar Rajendran, Taeyoung Kim, and Dongsoo Har","Reinforcement Learning for Predicting Traffic Accidents",,,,,"cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As the demand for autonomous driving increases, it is paramount to ensure
safety. Early accident prediction using deep learning methods for driving
safety has recently gained much attention. In this task, early accident
prediction and a point prediction of where the drivers should look are
determined, with the dashcam video as input. We propose to exploit the double
actors and regularized critics (DARC) method, for the first time, on this
accident forecasting platform. We derive inspiration from DARC since it is
currently a state-of-the-art reinforcement learning (RL) model on continuous
action space suitable for accident anticipation. Results show that by utilizing
DARC, we can make predictions 5\% earlier on average while improving in
multiple metrics of precision compared to existing methods. The results imply
that using our RL-based problem formulation could significantly increase the
safety of autonomous driving.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 05:53:30 GMT""}]","2022-12-12"
"2212.04678","Zahra Shaterzadeh-Yazdi","Soheil Khajavi, Zahra Shaterzadeh-Yazdi, Ali Eghrari, Mohammad Neshat","Quantum Modeling of Scanning Near-Field Optical photons Scattered by an
  Atomic-Force Microscope Tip for Quantum Metrology","5 pages and 3 figures",,,,"quant-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Scattering scanning near-field optical microscopy (s-SNOM) is a promising
technique for overcoming Abbe diffraction limit and substantially enhancing the
spatial resolution in spectroscopic imaging. The s-SNOM works by exposing an
atomic force microscope (AFM) tip to an optical electromagnetic (EM) field,
while the tip is so close to a dielectric sample that the incident beam lies
within the near-field regime and displays nonlinear behaviour. We replace the
incident EM field by photons generated by a single photon emitter, and propose
a quantum model for the suggested system by employing electric-dipole
approximation, image theory, and perturbation theory. Quantum state of
scattered photons from the AFM tip is extracted from the proposed model, which
contains information about electrical permittivity of the dielectric material
beneath the tip. The permittivity of the sample can be extracted through
spectroscopic setups. Our proposed scheme has potential applications for
high-resolution quantum sensing and metrology, especially for quantum imaging
and quantum spectroscopy.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 05:53:51 GMT""},{""version"":""v2"",""created"":""Wed, 18 Jan 2023 16:19:38 GMT""}]","2023-01-19"
"2212.04679","Yating Xu","Yating Xu, Gim Hee Lee","Motion and Context-Aware Audio-Visual Conditioned Video Prediction","Under refinement",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Existing state-of-the-art method for audio-visual conditioned video
prediction uses the latent codes of the audio-visual frames from a multimodal
stochastic network and a frame encoder to predict the next visual frame.
However, a direct inference of per-pixel intensity for the next visual frame
from the latent codes is extremely challenging because of the high-dimensional
image space. To this end, we propose to decouple the audio-visual conditioned
video prediction into motion and appearance modeling. The first part is the
multimodal motion estimation module that learns motion information as optical
flow from the given audio-visual clip. The second part is the context-aware
refinement module that uses the predicted optical flow to warp the current
visual frame into the next visual frame and refines it base on the given
audio-visual context. Experimental results show that our method achieves
competitive results on existing benchmarks.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 05:57:46 GMT""},{""version"":""v2"",""created"":""Sun, 23 Apr 2023 03:58:57 GMT""}]","2023-04-25"
"2212.04680","Dan Qiao","Dan Qiao, Yu-Xiang Wang","Near-Optimal Differentially Private Reinforcement Learning","39 pages",,,,"cs.LG cs.AI cs.CR stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by personalized healthcare and other applications involving
sensitive data, we study online exploration in reinforcement learning with
differential privacy (DP) constraints. Existing work on this problem
established that no-regret learning is possible under joint differential
privacy (JDP) and local differential privacy (LDP) but did not provide an
algorithm with optimal regret. We close this gap for the JDP case by designing
an $\epsilon$-JDP algorithm with a regret of
$\widetilde{O}(\sqrt{SAH^2T}+S^2AH^3/\epsilon)$ which matches the
information-theoretic lower bound of non-private learning for all choices of
$\epsilon> S^{1.5}A^{0.5} H^2/\sqrt{T}$. In the above, $S$, $A$ denote the
number of states and actions, $H$ denotes the planning horizon, and $T$ is the
number of steps. To the best of our knowledge, this is the first private RL
algorithm that achieves \emph{privacy for free} asymptotically as $T\rightarrow
\infty$. Our techniques -- which could be of independent interest -- include
privately releasing Bernstein-type exploration bonuses and an improved method
for releasing visitation statistics. The same techniques also imply a slightly
improved regret bound for the LDP case.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 06:03:02 GMT""},{""version"":""v2"",""created"":""Wed, 22 Feb 2023 01:12:17 GMT""}]","2023-02-23"
"2212.04681","Shohei Enomoto","Shohei Enomoto, Monikka Roslianna Busto, Takeharu Eda","Dynamic Test-Time Augmentation via Differentiable Functions",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Distribution shifts, which often occur in the real world, degrade the
accuracy of deep learning systems, and thus improving robustness is essential
for practical applications. To improve robustness, we study an image
enhancement method that generates recognition-friendly images without
retraining the recognition model. We propose a novel image enhancement method,
DynTTA, which is based on differentiable data augmentation techniques and
generates a blended image from many augmented images to improve the recognition
accuracy under distribution shifts. In addition to standard data augmentations,
DynTTA also incorporates deep neural network-based image transformation, which
further improves the robustness. Because DynTTA is composed of differentiable
functions, it is directly trained with the classification loss of the
recognition model. We experiment with widely used image recognition datasets
using various classification models, including Vision Transformer and
MLP-Mixer. DynTTA improves the robustness with almost no reduction in
classification accuracy for clean images, which is a better result than the
existing methods. Furthermore, we show that estimating the training time
augmentation for distribution-shifted datasets using DynTTA and retraining the
recognition model with the estimated augmentation significantly improves
robustness.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 06:06:47 GMT""},{""version"":""v2"",""created"":""Wed, 15 Mar 2023 04:06:46 GMT""}]","2023-03-16"
"2212.04682","Adway Das","Adway Kumar Das and Anandamohan Ghosh","Transport in deformed centrosymmetric networks","13 pages, 5 figures","Physical Review E 106, 064112 (2022)","10.1103/PhysRevE.106.064112",,"cond-mat.dis-nn cond-mat.stat-mech quant-ph","http://creativecommons.org/licenses/by/4.0/","  Centrosymmetry often mediates Perfect State Transfer (PST) in various complex
systems ranging from quantum wires to photosynthetic networks. We introduce the
Deformed Centrosymmetric Ensemble (DCE) of random matrices, $H(\lambda) \equiv
H_+ + \lambda H_-$, where $H_+$ is centrosymmetric while $H_-$ is
skew-centrosymmetric. The relative strength of the $H_\pm$ prompts the system
size scaling of the control parameter as $\lambda = N^{-\frac{\gamma}{2}}$. We
propose two quantities, $\mathcal{P}$ and $\mathcal{C}$, quantifying centro-
and skewcentro-symmetry, respectively, exhibiting second order phase
transitions at $\gamma_\text{P}\equiv 1$ and $\gamma_\text{C}\equiv -1$. In
addition, DCE posses an ergodic transition at $\gamma_\text{E} \equiv 0$. Thus
equipped with a precise control of the extent of centrosymmetry in DCE, we
study the manifestation of $\gamma$ on the transport properties of complex
networks. We propose that such random networks can be constructed using the
eigenvectors of $H(\lambda)$ and establish that the maximum transfer fidelity,
$F_T$, is equivalent to the degree of centrosymmetry, $\mathcal{P}$.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 06:13:29 GMT""}]","2022-12-12"
"2212.04683","Jessica Purcell","Marc Lackenby and Jessica S. Purcell","The triangulation complexity of elliptic and sol 3-manifolds","41 pages, 9 figures",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The triangulation complexity of a compact 3-manifold is the minimal number of
tetrahedra in any triangulation of the 3-manifold. We compute the triangulation
complexity of all elliptic 3-manifolds and all sol 3-manifolds, to within a
universally bounded multiplicative error.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 06:20:10 GMT""}]","2022-12-12"
"2212.04684","Yueying Chang","Yueying Chang and Richard O. Sinnott","Machine Learning-based Classification of Birds through Birdsong",,,,,"cs.LG cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Audio sound recognition and classification is used for many tasks and
applications including human voice recognition, music recognition and audio
tagging. In this paper we apply Mel Frequency Cepstral Coefficients (MFCC) in
combination with a range of machine learning models to identify (Australian)
birds from publicly available audio files of their birdsong. We present
approaches used for data processing and augmentation and compare the results of
various state of the art machine learning models. We achieve an overall
accuracy of 91% for the top-5 birds from the 30 selected as the case study.
Applying the models to more challenging and diverse audio files comprising 152
bird species, we achieve an accuracy of 58%
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 06:20:50 GMT""}]","2022-12-12"
"2212.04685","Tigran V. Shahbazyan","Tigran V. Shahbazyan","Purcell factor for plasmon-enhanced metal photoluminescence","7 pages, 2 figures","J. Phys. Chem. C 127, 5898 (2023)","10.1021/acs.jpcc.3c00180",,"cond-mat.mes-hall physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an analytical model for plasmonic enhancement of metal
photoluminescence (MPL) in metal nanostructures with characteristic size below
the diffraction limit. In such systems, the primary mechanism of MPL
enhancement is excitation of localized surface plasmons (LSP) by recombining
carriers followed by a photon emission due to LSP radiative decay. For
plasmonic nanostructures of arbitrary shape, we obtain a universal expression
for MPL Purcell factor that describes the plasmonic enhancement of MPL in terms
of metal dielectric function, LSP frequency, and the system volume. We find
that the lineshape of MPL spectrum is affected by the interference between
direct carrier recombination processes and those mediated by plasmonic antenna
which leads to a blueshift of MPL spectral band relative to LSP resonance in
scattering spectra observed in numerous experiments.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 06:22:04 GMT""},{""version"":""v2"",""created"":""Sat, 4 Mar 2023 02:58:02 GMT""}]","2023-06-06"
"2212.04686","Shunta Kikuchi","Shunta Kikuchi and Hiroshi Watanabe","Effect of surfactants on the elasticity of the liquid--liquid interface","14 pages, 9 figures, new discussions added",,"10.1063/5.0138733",,"cond-mat.stat-mech cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigated the effect of surfactants on an interface between two kinds
of liquid by molecular dynamics simulation. We adopted the simple bead-spring
model with two atoms as the surfactants. We controlled the interfacial tension
of the surfactant adsorbed on the interface by changing the bond length.
Although the interface's structure changed depending on the magnitude of the
interfacial tension, the interface was stable even under conditions where the
interfacial tension was virtually zero. The Fourier spectrum of the
fluctuations of the surface structure showed a crossover from $q^2$ to $q^4$
when the interfacial tension was almost zero, where $q$ is the wavenumber. This
crossover means that the bending rigidity is dominant for the restoring force
when the surfactant molecules are sufficiently absorbed on the interface and
the interfacial tension is almost zero, whereas the interfacial tension is
dominant when the interfacial tension is a finite value.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 06:29:08 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 06:56:34 GMT""},{""version"":""v3"",""created"":""Fri, 3 Mar 2023 06:16:32 GMT""}]","2023-04-05"
"2212.04687","Di Tang","Rui Zhu, Di Tang, Siyuan Tang, XiaoFeng Wang, Haixu Tang","Selective Amnesia: On Efficient, High-Fidelity and Blind Suppression of
  Backdoor Effects in Trojaned Machine Learning Models",,,,,"cs.LG cs.AI cs.CR cs.CV","http://creativecommons.org/licenses/by/4.0/","  In this paper, we present a simple yet surprisingly effective technique to
induce ""selective amnesia"" on a backdoored model. Our approach, called SEAM,
has been inspired by the problem of catastrophic forgetting (CF), a long
standing issue in continual learning. Our idea is to retrain a given DNN model
on randomly labeled clean data, to induce a CF on the model, leading to a
sudden forget on both primary and backdoor tasks; then we recover the primary
task by retraining the randomized model on correctly labeled clean data. We
analyzed SEAM by modeling the unlearning process as continual learning and
further approximating a DNN using Neural Tangent Kernel for measuring CF. Our
analysis shows that our random-labeling approach actually maximizes the CF on
an unknown backdoor in the absence of triggered inputs, and also preserves some
feature extraction in the network to enable a fast revival of the primary task.
We further evaluated SEAM on both image processing and Natural Language
Processing tasks, under both data contamination and training manipulation
attacks, over thousands of models either trained on popular image datasets or
provided by the TrojAI competition. Our experiments show that SEAM vastly
outperforms the state-of-the-art unlearning techniques, achieving a high
Fidelity (measuring the gap between the accuracy of the primary task and that
of the backdoor) within a few minutes (about 30 times faster than training a
model from scratch using the MNIST dataset), with only a small amount of clean
data (0.1% of training data for TrojAI models).
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 06:29:43 GMT""}]","2022-12-12"
"2212.04688","Keshav Kapur","Keshav Kapur, Rajitha Harikrishnan","Comparative Study of Sentiment Analysis for Multi-Sourced Social Media
  Platforms",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by-sa/4.0/","  There is a vast amount of data generated every second due to the rapidly
growing technology in the current world. This area of research attempts to
determine the feelings or opinions of people on social media posts. The dataset
we used was a multi-source dataset from the comment section of various social
networking sites like Twitter, Reddit, etc. Natural Language Processing
Techniques were employed to perform sentiment analysis on the obtained dataset.
In this paper, we provide a comparative analysis using techniques of
lexicon-based, machine learning and deep learning approaches. The Machine
Learning algorithm used in this work is Naive Bayes, the Lexicon-based approach
used in this work is TextBlob, and the deep-learning algorithm used in this
work is LSTM.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 06:33:49 GMT""}]","2023-01-24"
"2212.04689","Haitao Lin","Haitao Lin, Lirong Wu, Yongjie Xu, Yufei Huang, Siyuan Li, Guojiang
  Zhao, Stan Z. Li","Non-equispaced Fourier Neural Solvers for PDEs","27 pages",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Solving partial differential equations is difficult. Recently proposed neural
resolution-invariant models, despite their effectiveness and efficiency,
usually require equispaced spatial points of data. However, sampling in spatial
domain is sometimes inevitably non-equispaced in real-world systems, limiting
their applicability. In this paper, we propose a Non-equispaced Fourier PDE
Solver (\textsc{NFS}) with adaptive interpolation on resampled equispaced
points and a variant of Fourier Neural Operators as its components.
Experimental results on complex PDEs demonstrate its advantages in accuracy and
efficiency. Compared with the spatially-equispaced benchmark methods, it
achieves superior performance with $42.85\%$ improvements on MAE, and is able
to handle non-equispaced data with a tiny loss of accuracy. Besides, to our
best knowledge, \textsc{NFS} is the first ML-based method with mesh invariant
inference ability to successfully model turbulent flows in non-equispaced
scenarios, with a minor deviation of the error on unseen spatial points.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 06:36:54 GMT""},{""version"":""v2"",""created"":""Sat, 18 Mar 2023 08:52:33 GMT""}]","2023-03-21"
"2212.04690","Mingu Kang","Mingu Kang, Heon Song, Seonwook Park, Donggeun Yoo, S\'ergio Pereira","Benchmarking Self-Supervised Learning on Diverse Pathology Datasets","Accepted to CVPR 2023",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Computational pathology can lead to saving human lives, but models are
annotation hungry and pathology images are notoriously expensive to annotate.
Self-supervised learning has shown to be an effective method for utilizing
unlabeled data, and its application to pathology could greatly benefit its
downstream tasks. Yet, there are no principled studies that compare SSL methods
and discuss how to adapt them for pathology. To address this need, we execute
the largest-scale study of SSL pre-training on pathology image data, to date.
Our study is conducted using 4 representative SSL methods on diverse downstream
tasks. We establish that large-scale domain-aligned pre-training in pathology
consistently out-performs ImageNet pre-training in standard SSL settings such
as linear and fine-tuning evaluations, as well as in low-label regimes.
Moreover, we propose a set of domain-specific techniques that we experimentally
show leads to a performance boost. Lastly, for the first time, we apply SSL to
the challenging task of nuclei instance segmentation and show large and
consistent performance improvements under diverse settings.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 06:38:34 GMT""},{""version"":""v2"",""created"":""Tue, 18 Apr 2023 15:07:46 GMT""}]","2023-04-19"
"2212.04691","Masanori Amano","Masanori Amano","The surface of circumferences for Jenkins-Strebel differentials",,,,,"math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There are some existence problems of Jenkins-Strebel differentials on a
Riemann surface. The one of them is to find a Jenkins-Strebel differential
whose characteristic ring domains have given positive numbers as their
circumferences, for any fixed underlying Riemann surface and core curves of the
ring domains. However, the solution may not exist for some given underlying
surface, core curves, and positive numbers. In this paper, we investigate the
existence of such the solutions. Our method is to use the surface of
circumferences, which is determined by the extremal problem for Jenkins-Strebel
differentials. We can see degenerations of the characteristic ring domains of
Jenkins-Strebel differentials by the surface. Moreover, we also consider the
behavior of the surface when the underlying Riemann surface varies.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 06:48:57 GMT""}]","2022-12-12"
"2212.04692","Toshihiro Ota","Toshihiro Ota, Ryo Karakida","Attention in a family of Boltzmann machines emerging from modern
  Hopfield networks","15 pages, 3 figures. v2: added figures and various
  corrections/improvements especially in Introduction and Section 3. Published
  version",,,"RIKEN-iTHEMS-Report-22","cs.LG cs.NE stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hopfield networks and Boltzmann machines (BMs) are fundamental energy-based
neural network models. Recent studies on modern Hopfield networks have broaden
the class of energy functions and led to a unified perspective on general
Hopfield networks including an attention module. In this letter, we consider
the BM counterparts of modern Hopfield networks using the associated energy
functions, and study their salient properties from a trainability perspective.
In particular, the energy function corresponding to the attention module
naturally introduces a novel BM, which we refer to as the attentional BM
(AttnBM). We verify that AttnBM has a tractable likelihood function and
gradient for certain special cases and is easy to train. Moreover, we reveal
the hidden connections between AttnBM and some single-layer models, namely the
Gaussian--Bernoulli restricted BM and the denoising autoencoder with softmax
units coming from denoising score matching. We also investigate BMs introduced
by other energy functions and show that the energy function of dense
associative memory models gives BMs belonging to Exponential Family Harmoniums.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 06:52:36 GMT""},{""version"":""v2"",""created"":""Wed, 29 Mar 2023 02:36:58 GMT""}]","2023-03-30"
"2212.04693","Urmila Chadayammuri","Urmila Chadayammuri, Akos Bogdan, Angelo Ricarte, Priyamvada Natarajan","Constraints from dwarf galaxies on black hole seeding and growth models
  with current and future surveys","Accepted to ApJ","The Astrophysical Journal (2023), Volume 946, Number 1","10.3847/1538-4357/acbea6",,"astro-ph.GA astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Dwarf galaxies are promising test beds for constraining models of
supermassive and intermediate-mass black holes (MBH) via their black hole
occupation fraction (BHOF). Disentangling seeding from the confounding effects
of mass assembly over a Hubble time is a challenging problem, that we tackle in
this study with a suite of semi-analytical models (SAMs). We show how measured
BHOF depends on the lowest black hole mass or AGN luminosity achieved by a
survey. To tell seeding models apart, we need to detect or model all AGN
brighter than $10^{37}\ \rm{erg \ s^{-1}}$ in galaxies of $M_* \sim 10^{8-10} \
\rm{M_{\odot}}$. Shallower surveys, like eRASS, cannot distinguish between seed
models even with the compensation of a much larger survey volume. We show that
the AMUSE survey, with its inference of the MBH population underlying the
observed AGN, strongly favors heavy seed models, growing with either a
power-law Eddington Ratio Distribution Function (ERDF) or one in which black
hole accretion is tagged to the star-formation rate (AGN-MS). These two growth
channels can then be distinguished by the AGN luminosity function at $>
10^{40}\ \rm{erg \ s^{-1}}$, with the AGN-MS model requiring more accretion
than observed at z $\sim$ 0. Thus, current X-ray observations favour heavy
seeds whose Eddington ratios follow a power-law distribution. The different
models also predict different radio scaling relations, which we quantify using
the fundamental plane of black hole activity. We close with recommendations for
the design of upcoming multi-wavelength campaigns that can optimally detect
MBHs in dwarf galaxies.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 06:53:26 GMT""},{""version"":""v2"",""created"":""Tue, 13 Dec 2022 15:13:40 GMT""},{""version"":""v3"",""created"":""Tue, 4 Apr 2023 17:07:17 GMT""}]","2023-04-05"
"2212.04694","Wenzhe Liu","Wenzhe Liu, Jingguang Chen, Tongyu Li, Zhe Zhang, Fang Guan, Lei Shi,
  Jian Zi, and C. T. Chan","Imaging with an ultra-thin reciprocal lens",,,,,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Imaging is of great importance in everyday life and various fields of science
and technology. Conventional imaging is achieved by bending light rays
originating from an object with a lens. Such ray bending requires space-variant
structures, inevitably introducing a geometric center to the lens. To overcome
the limitations arising from the conventional imaging mechanism, we consider
imaging elements that employ a different mechanism, which we call reciprocal
lenses. This type of imaging element relies on ray shifting, enabled by
momentum-space-variant phase modulations in periodic structures. As such, it
has the distinct advantage of not requiring alignment with a geometric center.
Moreover, upright real images can be produced directly with a single reciprocal
lens as the directions of rays are not changed. We realized an ultra-thin
reciprocal lens based on a photonic crystal slab. We characterized the ray
shifting behavior of the reciprocal lens and demonstrated imaging. Our work
gives an alternative mechanism for imaging, and provides a new way to modulate
electromagnetic waves.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 06:56:48 GMT""}]","2022-12-12"
"2212.04695","Sakineh Rahbariyan","Sakineh Rahbariyan","On the tree-number of the power graph associated with a finite groups",,,,,"math.GR","http://creativecommons.org/publicdomain/zero/1.0/","  Given a group $G$, we define the power graph $\mathcal{P}(G)$ as follows: the
vertices are the elements of $G$ and two vertices $x$ and $y$ are joined by an
edge if $\langle x \rangle \subseteq \langle y \rangle$ or $\langle y \rangle
\subseteq \langle x \rangle$. Obviously the power graph of any group is always
connected, because the identity element of the group is adjacent to all other
vertices. We consider $\kappa(G)$, the number of spanning trees of the power
graph associated with a finite group $G$. In this paper, for a finite group
$G$, first we represent some properties of $\mathcal{P}(G)$, then we are going
to find some divisors of $\kappa(G)$, and finally we prove that the simple
group $A_6\cong L_2(9)$ is uniquely determined by tree-number of its power
graph among all finite simple groups.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 07:00:34 GMT""}]","2022-12-12"
"2212.04696","Pritam Chakraborty","Pritam Chakraborty (for the ALICE Collaboration)","Non-identical particle femtoscopy in Pb--Pb collisions at 5.02 TeV with
  ALICE","Proceedings of International Conference on High Energy Physics (ICHEP
  2022), Bologna, Italy, 6-13 July, 2022, 6 pages, 4 figures",,,,"hep-ex","http://creativecommons.org/licenses/by/4.0/","  The non-identical particle femtoscopy is a technique that is developed to
estimate the dimension of a particle-emitting medium as well as the average
pair-emission asymmetry between the particles using two-particle correlation
functions. The analysis of femtoscopic correlations for all possible charged
combinations of pion-kaon pairs in Pb$-$Pb collisions at
$\sqrt{s_{\mathrm{NN}}}=$ 5.02 TeV with ALICE at the LHC is presented in this
article. The results are extracted for different centrality classes of Pb$-$Pb
collisions using the spherical harmonics representations of the correlation
functions, $C^{\rm 0}_{\rm 0}$ and $Re C^{\rm 1}_{\rm 1}$. The evolution of the
femtoscopic parameters with multiplicity and collectivity of the system is
discussed extensively. The femtoscopic parameters are observed to increase with
the multiplicity. The non-zero values of pair-emission asymmetry and the
decrease of source-size with increasing pair-transverse momentum indicate the
presence of collectivity in the system.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 07:09:19 GMT""}]","2022-12-12"
"2212.04697","Peng Shi","Peng Shi, Heng Li, Luping Du, Xiaocong Yuan","Spin/momentum properties of the paraxial optical beams","20 pages; 6 figures, 151 references",,"10.1021/acsphotonics.2c01535",,"physics.optics","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Spin angular momentum, an elementary dynamical property of classical
electromagnetic fields, plays an important role in spin-orbit and light-matter
interactions, especially in near-field optics. The research on optical spins
has led to the discovery of phenomena such as optical spin-momentum locking and
photonic topological quasiparticles, as well as applications in high-precision
detection and nanometrology. Here, we investigate spin-momentum relations in
paraxial optical systems and show that the optical spin angular momentum
contains transverse and longitudinal spin components simultaneously. The
transverse spin originates from inhomogeneities of field and governed by the
vorticity of the kinetic momentum density, whereas the longitudinal spin
parallel to the local canonical momentum is proportional to the polarization
ellipticity of light. Moreover, the skyrmionlike spin textures arise from the
optical transverse spin can be observed in paraxial beams, and their topologies
are maintained free from the influence of the Gouy phase during propagation.
Interestingly, the optical singularities, including both phase and polarization
singularities, can also affect the spin-momentum properties significantly. Our
findings describe the intrinsic spin-momentum properties in paraxial optical
systems and apply in the analysis of the properties of spin-momentum in optical
focusing, imaging, and scattering systems.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 07:09:37 GMT""}]","2023-02-15"
"2212.04698","Shivam Gola","Shivam Gola","Pseudo scalar dark matter in a generic U$(1)_X$ model","16 pages, 6 figures, Matches with the accepted version of the
  publication",,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We consider a $U(1)_X$ extension of the Standard Model~(SM), where the
spontaneous breaking of $U(1)_X$ gauge group results in a pseudo scalar
particle which is the proposed candidate for dark matter. In the model, we
introduce three right-handed neutrinos~(RHNs) $N_R^i$ and two extra scalars
$\Phi$, $\chi$, which are SM gauge singlets but charged under $U(1)_X$ gauge
group. Right-handed neutrinos are required to have the model anomaly free and
explain the neutrino oscillation data. The heaviest scalar breaks the $U(1)_X$
gauge symmetry and the other extra scalar gives a pseudo scalar DM candidate. A
pseudo scalar dark matter~(DM) is an interesting candidate as it naturally
evades the stringent direct detection bounds due to its coupling structure. We
study the phenomenology of this pseudo-scalar DM while considering several
theoretical and experimental constraints. We find that in our model, there is a
feasible parameter space, which satisfies by the DM lifetime bound, relic and
direct detection constraints while respecting the colliders and other bounds.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 07:15:25 GMT""},{""version"":""v2"",""created"":""Mon, 9 Jan 2023 06:57:27 GMT""},{""version"":""v3"",""created"":""Thu, 25 May 2023 10:36:44 GMT""}]","2023-05-26"
"2212.04699","Geng Li","Chao-Qiang Geng, Geng Li","FCNC processes of charmed hadrons with invisible scalar","13 pages, 18 figures",,"10.1016/j.physletb.2023.137811",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We study the invisible scalar of $S$ in charmed meson and baryon decays with
flavor-changing neutral currents (FCNCs) based on the model-independent
effective Lagrangian between the quarks and invisible scalar. From the bounds
of the coupling constants extracted from the recent BES III experiment on the
decay of $D^{0}\to\pi^{0}\bar\nu\nu$, we predict that the decay branching
ratios of $D^{+}\to\pi^{+}S$, $D_s^+\to K^+S$, $\Lambda_c\to pS$,
$\Xi_c^{0(+)}\to \Sigma^{0(+)}S$, and $\Xi_c^0\to\Lambda S$ can be as large as
$10.6,~2.53,~2.39,~0.963,~5.77$, and $2.92\times10^{-4}$ with $m_{_S}\approx
1.1~{\rm GeV}$, respectively. Some of these decay modes are accessible to the
ongoing experiments, such as BES III, LHCb and Belle II, as well as the future
ones, such as FCC-ee.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 07:24:55 GMT""},{""version"":""v2"",""created"":""Sat, 4 Mar 2023 02:36:11 GMT""}]","2023-03-07"
"2212.04700","Zhimin Li","Jie Jiang, Zhimin Li, Jiangfeng Xiong, Rongwei Quan, Qinglin Lu, Wei
  Liu","Tencent AVS: A Holistic Ads Video Dataset for Multi-modal Scene
  Segmentation",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Temporal video segmentation and classification have been advanced greatly by
public benchmarks in recent years. However, such research still mainly focuses
on human actions, failing to describe videos in a holistic view. In addition,
previous research tends to pay much attention to visual information yet ignores
the multi-modal nature of videos. To fill this gap, we construct the Tencent
`Ads Video Segmentation'~(TAVS) dataset in the ads domain to escalate
multi-modal video analysis to a new level. TAVS describes videos from three
independent perspectives as `presentation form', `place', and `style', and
contains rich multi-modal information such as video, audio, and text. TAVS is
organized hierarchically in semantic aspects for comprehensive temporal video
segmentation with three levels of categories for multi-label classification,
e.g., `place' - `working place' - `office'. Therefore, TAVS is distinguished
from previous temporal segmentation datasets due to its multi-modal
information, holistic view of categories, and hierarchical granularities. It
includes 12,000 videos, 82 classes, 33,900 segments, 121,100 shots, and 168,500
labels. Accompanied with TAVS, we also present a strong multi-modal video
segmentation baseline coupled with multi-label class prediction. Extensive
experiments are conducted to evaluate our proposed method as well as existing
representative methods to reveal key challenges of our dataset TAVS.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 07:26:20 GMT""}]","2022-12-12"
"2212.04701","Zhongshu Wang","Zhongshu Wang, Lingzhi Li, Zhen Shen, Li Shen, Liefeng Bo","4K-NeRF: High Fidelity Neural Radiance Fields at Ultra High Resolutions",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present a novel and effective framework, named 4K-NeRF, to
pursue high fidelity view synthesis on the challenging scenarios of ultra high
resolutions, building on the methodology of neural radiance fields (NeRF). The
rendering procedure of NeRF-based methods typically relies on a pixel-wise
manner in which rays (or pixels) are treated independently on both training and
inference phases, limiting its representational ability on describing subtle
details, especially when lifting to a extremely high resolution. We address the
issue by exploring ray correlation to enhance high-frequency details recovery.
Particularly, we use the 3D-aware encoder to model geometric information
effectively in a lower resolution space and recover fine details through the
3D-aware decoder, conditioned on ray features and depths estimated by the
encoder. Joint training with patch-based sampling further facilitates our
method incorporating the supervision from perception oriented regularization
beyond pixel-wise loss. Benefiting from the use of geometry-aware local
context, our method can significantly boost rendering quality on high-frequency
details compared with modern NeRF methods, and achieve the state-of-the-art
visual quality on 4K ultra-high-resolution scenarios. Code Available at
\url{https://github.com/frozoul/4K-NeRF}
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 07:26:49 GMT""},{""version"":""v2"",""created"":""Tue, 4 Apr 2023 02:42:35 GMT""}]","2023-04-05"
"2212.04702","Wenting Wang","Pedro Alonso, Wenting Wang, Jun Zhang, Hekun Li, Shi Shao, Qi Guo,
  Yanqin He, Cai-Na Hao, Rui Shi","Dark against luminous matter around isolated central galaxies: a
  comparative study between modern surveys and Illustris-TNG","accepted by ApJ, comments welcome",,"10.3847/1538-4357/acbf4a",,"astro-ph.GA astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Based on independent shear measurements using the DECaLS/DR8 imaging data, we
measure the weak lensing signals around isolated central galaxies (ICGs) from
SDSS/DR7 at $z\sim0.1$. The projected stellar mass density profiles of
surrounding satellite galaxies are further deduced, using photometric sources
from the Hyper Suprime-Cam (HSC) survey (pDR3). The signals of ICGs $+$ their
extended stellar halos are taken from Wang et al.(2021). All measurements are
compared with predictions by the Illustris-TNG300-1 simulation. We find,
overall, a good agreement between observation and TNG300. In particular, a
correction to the stellar mass of massive observed ICGs is applied based on the
calibration of He et al.(2013), which brings a much better agreement with
TNG300 predicted lensing signals at $\log_{10}M_\ast/M_\odot>11.1$. In real
observation, red ICGs are hosted by more massive dark matter halos, have more
satellites and more extended stellar halos than blue ICGs at fixed stellar
mass. However, in TNG300 there are more satellites around blue ICGs at fixed
stellar mass, and the outer stellar halos of red and blue ICGs are similar. The
stellar halos of TNG galaxies are more extended compared with real observed
galaxies, especially for blue ICGs with $\log_{10}M_\ast/M_\odot>10.8$. We find
the same trend for TNG100 galaxies and for true halo central galaxies. The
tensions between TNG and real galaxies might indicate that satellite
disruptions are stronger in TNG. In both TNG300 and observation, satellites
approximately trace the underlying dark matter distribution beyond
$0.1R_{200}$, but the fraction of total stellar mass in TNG300 does not show
the same radial distribution as real galaxies.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 07:28:15 GMT""},{""version"":""v2"",""created"":""Mon, 6 Mar 2023 05:50:30 GMT""}]","2023-04-19"
"2212.04703","Pedro Jorge Freire De Carvalho Souza Dr","Pedro J. Freire, Sasipim Srivallapanondh, Michael Anderson, Bernhard
  Spinnler, Thomas Bex, Tobias A. Eriksson, Antonio Napoli, Wolfgang Schairer,
  Nelson Costa, Michaela Blott, Sergei K. Turitsyn, Jaroslaw E. Prilepsky","Implementing Neural Network-Based Equalizers in a Coherent Optical
  Transmission System Using Field-Programmable Gate Arrays","Invited paper at Journal of Lightwave Technology - IEEE",,,,"eess.SP cs.AR cs.CC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we demonstrate the offline FPGA realization of both recurrent
and feedforward neural network (NN)-based equalizers for nonlinearity
compensation in coherent optical transmission systems. First, we present a
realization pipeline showing the conversion of the models from Python libraries
to the FPGA chip synthesis and implementation. Then, we review the main
alternatives for the hardware implementation of nonlinear activation functions.
The main results are divided into three parts: a performance comparison, an
analysis of how activation functions are implemented, and a report on the
complexity of the hardware. The performance in Q-factor is presented for the
cases of bidirectional long-short-term memory coupled with convolutional NN
(biLSTM + CNN) equalizer, CNN equalizer, and standard 1-StpS digital
back-propagation (DBP) for the simulation and experiment propagation of a
single channel dual-polarization (SC-DP) 16QAM at 34 GBd along 17x70km of LEAF.
The biLSTM+CNN equalizer provides a similar result to DBP and a 1.7 dB Q-factor
gain compared with the chromatic dispersion compensation baseline in the
experimental dataset. After that, we assess the Q-factor and the impact of
hardware utilization when approximating the activation functions of NN using
Taylor series, piecewise linear, and look-up table (LUT) approximations. We
also show how to mitigate the approximation errors with extra training and
provide some insights into possible gradient problems in the LUT approximation.
Finally, to evaluate the complexity of hardware implementation to achieve 200G
and 400G throughput, fixed-point NN-based equalizers with approximated
activation functions are developed and implemented in an FPGA.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 07:28:45 GMT""},{""version"":""v2"",""created"":""Sun, 19 Feb 2023 19:01:05 GMT""}]","2023-02-21"
"2212.04704","David Holmes","Dawei Chen, Samuel Grushevsky, David Holmes, Martin M\""oller, Johannes
  Schmitt","A tale of two moduli spaces: logarithmic and multi-scale differentials","54 pages. Comments very welcome!",,,,"math.AG math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multi-scale differentials are constructed in [BCGGM3], from the viewpoint of
flat and complex geometry, for the purpose of compactifying moduli spaces of
curves together with a differential with prescribed orders of zeros and poles.
Logarithmic differentials are constructed in [MW20], as a generalization of
stable rubber maps from Gromov--Witten theory. Modulo the global residue
condition that isolates the main components of the compactification, we show
that these two kinds of differentials are equivalent, and establish an
isomorphism of their (coarse) moduli stacks. Moreover, we describe the rubber
and multi-scale spaces as an explicit blowup of the moduli space of stable
pointed rational curves in the case of genus zero, and as a global blowup of
the incidence variety compactification for arbitrary genera, which implies
their projectivity. We also propose a refined double ramification cycle formula
in the twisted Hodge bundle which interacts with the universal line bundle
class.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 07:30:57 GMT""}]","2022-12-12"
"2212.04705","Youming Deng","Youming Deng, Xueting Li, Sifei Liu, Ming-Hsuan Yang","DIP: Differentiable Interreflection-aware Physics-based Inverse
  Rendering",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a physics-based inverse rendering method that learns the
illumination, geometry, and materials of a scene from posed multi-view RGB
images. To model the illumination of a scene, existing inverse rendering works
either completely ignore the indirect illumination or model it by coarse
approximations, leading to sub-optimal illumination, geometry, and material
prediction of the scene. In this work, we propose a physics-based illumination
model that explicitly traces the incoming indirect lights at each surface point
based on interreflection, followed by estimating each identified indirect light
through an efficient neural network. Furthermore, we utilize the Leibniz's
integral rule to resolve non-differentiability in the proposed illumination
model caused by one type of environment light -- the tangent lights. As a
result, the proposed interreflection-aware illumination model can be learned
end-to-end together with geometry and materials estimation. As a side product,
our physics-based inverse rendering model also facilitates flexible and
realistic material editing as well as relighting. Extensive experiments on both
synthetic and real-world datasets demonstrate that the proposed method performs
favorably against existing inverse rendering methods on novel view synthesis
and inverse rendering.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 07:33:49 GMT""}]","2022-12-12"
"2212.04706","Sergei Nikolaev","Fabio Cacciatori and Sergei Nikolaev and Dmitrii Grigorev","The Platform for non-metallic pipes defects recognition. Design and
  Implementation",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper describes a prototype software and hardware platform to provide
support to field operators during the inspection of surface defects of
non-metallic pipes. Inspection is carried out by video filming defects created
on the same surface in real-time using a ""smart"" helmet device and other mobile
devices. The work focuses on the detection and recognition of the defects which
appears as colored iridescence of reflected light caused by the diffraction
effect arising from the presence of internal stresses in the inspected
material. The platform allows you to carry out preliminary analysis directly on
the device in offline mode, and, if a connection to the network is established,
the received data is transmitted to the server for post-processing to extract
information about possible defects that were not detected at the previous
stage. The paper presents a description of the stages of design, formal
description, and implementation details of the platform. It also provides
descriptions of the models used to recognize defects and examples of the result
of the work.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 07:34:17 GMT""}]","2022-12-12"
"2212.04707","Guangbin Zhang","Guangbin Zhang, Tianyao Huang, Yimin Liu, Xiqin Wang and Yonina C.
  Eldar","Direction Finding in Partly Calibrated Arrays Exploiting the Whole Array
  Aperture",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of direction finding using partly calibrated arrays,
a distributed subarray with position errors between subarrays. The key
challenge is to enhance angular resolution in the presence of position errors.
To achieve this goal, existing algorithms, such as subspace separation and
sparse recovery, have to rely on multiple snapshots, which increases the burden
of data transmission and the processing delay. Therefore, we aim to enhance
angular resolution using only a single snapshot. To this end, we exploit the
orthogonality of the signals of partly calibrated arrays. Particularly, we
transform the signal model into a special multiple-measurement model, show that
there is approximate orthogonality between the source signals in this model,
and then use blind source separation to exploit the orthogonality. Simulation
and experiment results both verify that our proposed algorithm achieves high
angular resolution as distributed arrays without position errors, inversely
proportional to the whole array aperture.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 07:35:00 GMT""}]","2022-12-12"
"2212.04708","Youngwoon Lee","Shivin Dass, Karl Pertsch, Hejia Zhang, Youngwoon Lee, Joseph J. Lim,
  Stefanos Nikolaidis","PATO: Policy Assisted TeleOperation for Scalable Robot Data Collection","Robotics: Science and Systems (RSS) 2023. Website:
  https://clvrai.com/pato",,,,"cs.RO cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Large-scale data is an essential component of machine learning as
demonstrated in recent advances in natural language processing and computer
vision research. However, collecting large-scale robotic data is much more
expensive and slower as each operator can control only a single robot at a
time. To make this costly data collection process efficient and scalable, we
propose Policy Assisted TeleOperation (PATO), a system which automates part of
the demonstration collection process using a learned assistive policy. PATO
autonomously executes repetitive behaviors in data collection and asks for
human input only when it is uncertain about which subtask or behavior to
execute. We conduct teleoperation user studies both with a real robot and a
simulated robot fleet and demonstrate that our assisted teleoperation system
reduces human operators' mental load while improving data collection
efficiency. Further, it enables a single operator to control multiple robots in
parallel, which is a first step towards scalable robotic data collection. For
code and video results, see https://clvrai.com/pato
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 07:38:09 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jun 2023 22:48:06 GMT""}]","2023-06-05"
"2212.04709","Nils Hermansson-Truedsson","Peter Boyle, Matteo Di Carlo, Felix Erben, Vera G\""ulpers, Maxwell T.
  Hansen, Tim Harris, Nils Hermansson-Truedsson, Raoul Hodgson, Andreas
  J\""uttner, Fionn \'O h\'Og\'ain, Antonin Portelli, James Richings, Andrew Z.
  N. Yong","Isospin-breaking corrections to light leptonic decays in lattice QCD+QED
  at the physical point","Proceedings for The 39th International Symposium on Lattice Field
  Theory, 8th-13th August, 2022, Rheinische Friedrich-Wilhelms-Universit\""at
  Bonn, Bonn, Germany",,,,"hep-lat hep-ph","http://creativecommons.org/licenses/by/4.0/","  We report on the physical-point RBC/UKQCD calculation of the leading
isospin-breaking corrections to light-meson leptonic decays. This is highly
relevant for future precision tests in the flavour physics sector, in
particular the first-row unitarity of the Cabibbo-Kobayashi-Maskawa matrix
containing the elements $V_{us}$ and $V_{ud}$. The simulations were performed
using Domain-Wall fermions for $2+1$ flavours, and with isospin-breaking
effects included perturbatively in the path integral through order $\alpha$ and
$(m_u - m_d)/\Lambda _{\mathrm{QCD}}$. We use QED$_{\mathrm{L}}$ for the
inclusion of electromagnetism, and discuss here the non-locality of this
prescription which has significant impact on the infinite-volume extrapolation.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 07:41:39 GMT""}]","2022-12-12"
"2212.04710","Marta Volonteri","Marta Volonteri, Melanie Habouzit and Monica Colpi","What if young z>9 JWST galaxies hosted massive black holes?","Published in MNRAS",,"10.1093/mnras/stad499",,"astro-ph.GA astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  JWST is discovering star forming `candidate' galaxies with photometric
redshifts $z>9$ and little attenuation. We model presumptive massive black
holes (MBHs) in such galaxies and find that their unobscured emission is
fainter than the galaxy starlight in JWST filters, and difficult to be detected
via color-color selection, and X-ray and radio observations. Only MBHs
overmassive relative to expected galaxy scaling relations, accreting at high
Eddington rates, would be detectable. Their discovery would point to the
presence of heavy MBH seeds, but care is needed to exclude the existence of
lighter seeds as only overmassive MBHs are detectable in this type of galaxies.
Conversely, if no overmassive MBHs are hosted in these galaxies, either there
are no heavy seeds or they are rare. The most massive/highest redshift
candidate galaxies can attain stellar masses in excess of 5e10 Msun by z~6 if
they grow along the SFR-mass sequence, and can nurse a MBH growing from ~1e5
Msun up to >3e7 Msun by z~6, to become hosts of some z>6 quasars. Candidate
galaxies of log(M_{gal}/Msun)~8 can not grow their putative seeds fast, unless
seeds are >1e6 Msun. The number density of the JWST candidate galaxies far
outnumbers that of the highest-z quasar hosts and this allows for about only 1
bright z~6-7 quasar every 1000 of these galaxies.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 07:45:13 GMT""},{""version"":""v2"",""created"":""Fri, 3 Mar 2023 10:27:57 GMT""}]","2023-03-06"
"2212.04711","Lanqing Guo","Lanqing Guo, Chong Wang, Wenhan Yang, Siyu Huang, Yufei Wang,
  Hanspeter Pfister, Bihan Wen","ShadowDiffusion: When Degradation Prior Meets Diffusion Model for Shadow
  Removal",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent deep learning methods have achieved promising results in image shadow
removal. However, their restored images still suffer from unsatisfactory
boundary artifacts, due to the lack of degradation prior embedding and the
deficiency in modeling capacity. Our work addresses these issues by proposing a
unified diffusion framework that integrates both the image and degradation
priors for highly effective shadow removal. In detail, we first propose a
shadow degradation model, which inspires us to build a novel unrolling
diffusion model, dubbed ShandowDiffusion. It remarkably improves the model's
capacity in shadow removal via progressively refining the desired output with
both degradation prior and diffusive generative prior, which by nature can
serve as a new strong baseline for image restoration. Furthermore,
ShadowDiffusion progressively refines the estimated shadow mask as an auxiliary
task of the diffusion generator, which leads to more accurate and robust
shadow-free image generation. We conduct extensive experiments on three popular
public datasets, including ISTD, ISTD+, and SRD, to validate our method's
effectiveness. Compared to the state-of-the-art methods, our model achieves a
significant improvement in terms of PSNR, increasing from 31.69dB to 34.73dB
over SRD dataset.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 07:48:30 GMT""},{""version"":""v2"",""created"":""Tue, 13 Dec 2022 08:56:31 GMT""}]","2022-12-14"
"2212.04712","Minjung Kim","Minjung Kim, MyeongAh Cho, Heansung Lee, Suhwan Cho, Sangyoun Lee","Occluded Person Re-Identification via Relational Adaptive Feature
  Correction Learning","ICASSP 2022",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Occluded person re-identification (Re-ID) in images captured by multiple
cameras is challenging because the target person is occluded by pedestrians or
objects, especially in crowded scenes. In addition to the processes performed
during holistic person Re-ID, occluded person Re-ID involves the removal of
obstacles and the detection of partially visible body parts. Most existing
methods utilize the off-the-shelf pose or parsing networks as pseudo labels,
which are prone to error. To address these issues, we propose a novel Occlusion
Correction Network (OCNet) that corrects features through relational-weight
learning and obtains diverse and representative features without using external
networks. In addition, we present a simple concept of a center feature in order
to provide an intuitive solution to pedestrian occlusion scenarios.
Furthermore, we suggest the idea of Separation Loss (SL) for focusing on
different parts between global features and part features. We conduct extensive
experiments on five challenging benchmark datasets for occluded and holistic
Re-ID tasks to demonstrate that our method achieves superior performance to
state-of-the-art methods especially on occluded scene.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 07:48:47 GMT""}]","2022-12-12"
"2212.04713","Moritz Ritter","Katharina Oberpriller, Moritz Ritter and Thorsten Schmidt","Robust asymptotic insurance-finance arbitrage","21 pages, 1 figure",,,,"q-fin.MF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In most cases, insurance contracts are linked to the financial markets, such
as through interest rates or equity-linked insurance products. To motivate an
evaluation rule in these hybrid markets, Artzner et al. (2022) introduced the
notion of insurance-finance arbitrage. In this paper we extend their setting by
incorporating model uncertainty. To this end, we allow statistical uncertainty
in the underlying dynamics to be represented by a set of priors $\mathscr{P}$.
Within this framework we introduce the notion of robust asymptotic
insurance-finance arbitrage and characterize the absence of such strategies in
terms of the concept of ${Q}\mathscr{P}$-evaluations. This is a nonlinear
two-step evaluation which guarantees no robust asymptotic insurance-finance
arbitrage. Moreover, the ${Q}\mathscr{P}$-evaluation dominates all two-step
evaluations as long as we agree on the set of priors $\mathscr{P}$ which shows
that those two-step evaluations do not allow for robust asymptotic
insurance-finance arbitrages. Furthermore, we introduce a doubly stochastic
model under uncertainty for surrender and survival. In this setting, we
describe conditional dependence by means of copulas and illustrate how the
${Q}\mathscr{P}$-evaluation can be used for the pricing of hybrid insurance
products.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 07:58:50 GMT""}]","2022-12-12"
"2212.04714","Yu-Feng Wu","Yu-Feng Wu","Maximal run-length function with constraints: a generalization of the
  Erd\H{o}s-R\'enyi limit theorem and the exceptional sets",,,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\mathbf{A}=\{A_i\}_{i=1}^{\infty}$ be a sequence of sets with each $A_i$
being a non-empty collection of $0$-$1$ sequences of length $i$. For $x\in
[0,1)$, the maximal run-length function $\ell_n(x,\mathbf{A})$ (with respect to
$\mathbf{A}$) is defined to the largest $k$ such that in the first $n$ digits
of the dyadic expansion of $x$ there is a consecutive subsequence contained in
$A_k$. Suppose that $\lim_{n\to\infty}(\log_2|A_n|)/n=\tau$ for some $\tau\in
[0,1]$ and one additional assumption holds, we prove a generalization of the
Erd\H{o}s-R\'enyi limit theorem which states that
\[\lim_{n\to\infty}\frac{\ell_n(x,\mathbf{A})}{\log_2n}=\frac{1}{1-\tau}\] for
Lebesgue almost all $x\in [0,1)$. For the exceptional sets, we prove under a
certain stronger assumption on $\mathbf{A}$ that the set \[\left\{x\in [0,1):
\lim_{n\to\infty}\frac{\ell_n(x,\mathbf{A})}{\log_2n}=0\text{ and }
\lim_{n\to\infty}\ell_n(x,\mathbf{A})=\infty\right\}\] has Hausdorff dimension
at least $1-\tau$.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 07:58:51 GMT""}]","2022-12-12"
"2212.04715","Nafiseh Karimimanesh","N. Karimimanesh, S. Deldar, and Z. Asmaee","Monopoles, vortices and their correlations in SU(3) gauge group","20 pages, 10 figures, Minor typo changes",,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  Topological defects such as monopoles, vortices and ""chains""of the SU(3)
gauge group are studied using its SU(2) subgroups. Two appropriate successive
gauge transformations are applied to the subgroups to identify the chains of
monopoles and vortices. Using the fact that the defects of the subgroups are
not independent, the SU(3) defects and the Lagrangian are obtained and compared
with the ones provided by Cho decomposition method. By comparing the results
with the ones which have been obtained directly for the SU(3) gauge group, the
relation and possible interactions between the defects of the subgroups are
discussed.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 08:08:16 GMT""},{""version"":""v2"",""created"":""Sun, 30 Apr 2023 14:37:28 GMT""}]","2023-05-02"
"2212.04716","Christian Berger","Christian Berger, Florian Bayer, Laurens W. Molenkamp, Tobias
  Kiessling","The topological Faraday effect cannot be observed in a realistic sample",,,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by-nc-nd/4.0/","  A striking feature of 3 dimensional (3D) topological insulators (TIs) is the
theoretically expected topological magneto-electric (TME) effect, which gives
rise to additional terms in Maxwell's laws of electromagnetism with an
universal quantized coefficient proportional to half-integer multiples of the
fine structure constant $\alpha$. In an ideal scenario one therefore expects
also quantized contributions in the magneto-optical response of TIs. We review
this premise by taking into account the trivial dielectric background of the TI
bulk and potential host substrates, and the often present contribution of
itinerant bulk carriers. We show that (i) one obtains a non-universal
magneto-optical response whenever there is impedance mismatch between different
layers and (ii) that the detectable signals due to the TME rapidly approach
vanishingly small values as the impedance mismatch is detuned from zero. We
demonstrate that it is methodologically impossible to deduce the existence of a
TME exclusively from an optical experiment in the thin film limit of 3D TIs at
high magnetic fields.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 08:15:13 GMT""}]","2022-12-12"
"2212.04717","Joey Hong","Joey Hong and Kush Bhatia and Anca Dragan","On the Sensitivity of Reward Inference to Misspecified Human Models","17 pages, 12 figures",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Inferring reward functions from human behavior is at the center of value
alignment - aligning AI objectives with what we, humans, actually want. But
doing so relies on models of how humans behave given their objectives. After
decades of research in cognitive science, neuroscience, and behavioral
economics, obtaining accurate human models remains an open research topic. This
begs the question: how accurate do these models need to be in order for the
reward inference to be accurate? On the one hand, if small errors in the model
can lead to catastrophic error in inference, the entire framework of reward
learning seems ill-fated, as we will never have perfect models of human
behavior. On the other hand, if as our models improve, we can have a guarantee
that reward accuracy also improves, this would show the benefit of more work on
the modeling side. We study this question both theoretically and empirically.
We do show that it is unfortunately possible to construct small adversarial
biases in behavior that lead to arbitrarily large errors in the inferred
reward. However, and arguably more importantly, we are also able to identify
reasonable assumptions under which the reward inference error can be bounded
linearly in the error in the human model. Finally, we verify our theoretical
insights in discrete and continuous control tasks with simulated and human
data.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 08:16:20 GMT""}]","2022-12-12"
"2212.04718","Abdorasoul Ghasemi","Samie Alizadeh, M\'arton P\'osfai, Abdorasoul Ghasemi","Controllability of complex networks: input node placement restricting
  the longest control chain","16 pages, 9 figures, supplementary",,,,"cs.CE cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The minimum number of inputs needed to control a network is frequently used
to quantify its controllability. Control of linear dynamics through a minimum
set of inputs, however, often has prohibitively large energy requirements and
there is an inherent trade-off between minimizing the number of inputs and
control energy. To better understand this trade-off, we study the problem of
identifying a minimum set of input nodes such that controllabililty is ensured
while restricting the length of the longest control chain. The longest control
chain is the maximum distance from input nodes to any network node, and recent
work found that reducing its length significantly reduces control energy. We
map the longest control chain-constraint minimum input problem to finding a
joint maximum matching and minimum dominating set. We show that this graph
combinatorial problem is NP-complete, and we introduce and validate a heuristic
approximation. Applying this algorithm to a collection of real and model
networks, we investigate how network structure affects the minimum number of
inputs, revealing, for example, that for many real networks reducing the
longest control chain requires only few or no additional inputs, only the
rearrangement of the input nodes.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 08:18:40 GMT""}]","2022-12-12"
"2212.04719","Yuying Man","Yuying Man, Shizhu Tian, Nian Li, Xiangyong Zeng","Several new infinite classes of 0-APN power functions over
  $\mathbb{F}_{2^n}$","arXiv admin note: text overlap with arXiv:2210.02207,
  arXiv:2210.15103 by other authors",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The investigation of partially APN functions has attracted a lot of research
interest recently. In this paper, we present several new infinite classes of
0-APN power functions over $\mathbb{F}_{2^n}$ by using the multivariate method
and resultant elimination, and show that these 0-APN power functions are
CCZ-inequivalent to the known ones.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 08:25:19 GMT""}]","2022-12-12"
"2212.04720","Joey Hong","Joey Hong and Branislav Kveton and Sumeet Katariya and Manzil Zaheer
  and Mohammad Ghavamzadeh","Multi-Task Off-Policy Learning from Bandit Feedback","14 pages, 3 figures",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Many practical applications, such as recommender systems and learning to
rank, involve solving multiple similar tasks. One example is learning of
recommendation policies for users with similar movie preferences, where the
users may still rank the individual movies slightly differently. Such tasks can
be organized in a hierarchy, where similar tasks are related through a shared
structure. In this work, we formulate this problem as a contextual off-policy
optimization in a hierarchical graphical model from logged bandit feedback. To
solve the problem, we propose a hierarchical off-policy optimization algorithm
(HierOPO), which estimates the parameters of the hierarchical model and then
acts pessimistically with respect to them. We instantiate HierOPO in linear
Gaussian models, for which we also provide an efficient implementation and
analysis. We prove per-task bounds on the suboptimality of the learned
policies, which show a clear improvement over not using the hierarchical model.
We also evaluate the policies empirically. Our theoretical and empirical
results show a clear advantage of using the hierarchy over solving each task
independently.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 08:26:27 GMT""}]","2022-12-12"
"2212.04721","Irfan Fachrudin Priyanta","Anas Gouda, Danny Heinrich, Mirco H\""unnefeld, Irfan Fachrudin
  Priyanta, Christopher Reining, Moritz Roidl","A Grid-based Sensor Floor Platform for Robot Localization using Machine
  Learning","This is a preprint version for IEEE I2MTC 2023",,,,"cs.LG cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Wireless Sensor Network (WSN) applications reshape the trend of warehouse
monitoring systems allowing them to track and locate massive numbers of
logistic entities in real-time. To support the tasks, classic Radio Frequency
(RF)-based localization approaches (e.g. triangulation and trilateration)
confront challenges due to multi-path fading and signal loss in noisy warehouse
environment. In this paper, we investigate machine learning methods using a new
grid-based WSN platform called Sensor Floor that can overcome the issues.
Sensor Floor consists of 345 nodes installed across the floor of our logistic
research hall with dual-band RF and Inertial Measurement Unit (IMU) sensors.
Our goal is to localize all logistic entities, for this study we use a mobile
robot. We record distributed sensing measurements of Received Signal Strength
Indicator (RSSI) and IMU values as the dataset and position tracking from Vicon
system as the ground truth. The asynchronous collected data is pre-processed
and trained using Random Forest and Convolutional Neural Network (CNN). The CNN
model with regularization outperforms the Random Forest in terms of
localization accuracy with aproximate 15 cm. Moreover, the CNN architecture can
be configured flexibly depending on the scenario in the warehouse. The
hardware, software and the CNN architecture of the Sensor Floor are open-source
under https://github.com/FLW-TUDO/sensorfloor.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 08:29:50 GMT""}]","2022-12-12"
"2212.04722","Malgorzata Worek","Giuseppe Bevilacqua, Michele Lupattelli, Daniel Stremmer, Malgorzata
  Worek","A study of additional jet activity in top quark pair production and
  decay at the LHC","9 pages, 3 figures, 3 tables, accepted for publication as a Letter in
  Physical Review D",,,"P3H-22-121, TTK-22-44","hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  We report on the calculation of the NLO QCD corrections to top quark pair
production in association with two hard jets at the LHC. We take into account
higher-order effects in both the production and decays of the top-quark pair.
The latter are treated in the narrow width approximation and $t\bar{t}$ spin
correlations are preserved throughout the calculation. This is the first time
that such a complete study for this process is conducted at NLO in QCD. We
present results for fiducial cross sections at the integrated and differential
level. Furthermore, we investigate kinematic properties of the additional light
jets and their distribution in the $pp\to t\bar{t}jj$ process. We examine jets
in production and top-quark decays as well as the mixed contribution, where the
two hardest non-$b$ jets are present simultaneously in the production and decay
processes.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 08:31:32 GMT""},{""version"":""v2"",""created"":""Sat, 13 May 2023 07:44:24 GMT""}]","2023-05-16"
"2212.04723","Wolfgang Reichel","Michael Plum and Wolfgang Reichel","Breathers and rogue waves for semilinear curl-curl wave equations",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider localized solutions of variants of the semilinear curl-curl wave
equation $s(x) \partial_t^2 U +\nabla\times\nabla\times U + q(x) U \pm V(x)
|U|^{p-1} U = 0$ for $(x,t)\in \mathbb{R}^3\times\mathbb{R}$ and arbitrary
$p>1$. Depending on the coefficients $s, q, V$ we can prove the existence of
three types of localized solutions: time-periodic solutions decaying to $0$ at
spatial infinity, time-periodic solutions tending to a nontrivial profile at
spatial infinity (both types are called breathers), and rogue waves which
converge to $0$ both at spatial and temporal infinity. Our solutions are weak
solutions and take the form of gradient fields. Thus they belong to the kernel
of the curl-operator so that due to the structural assumptions on the
coefficients the semilinear wave equation is reduced to an ODE. Since the space
dependence in the ODE is just a parametric dependence we can analyze the ODE by
phase plane techniques and thus establish the existence of the localized waves
described above. Noteworthy side effects of our analysis are the existence of
compact support breathers and the fact that one localized wave solution
$U(x,t)$ already generates a full continuum of phase-shifted solutions
$U(x,t+b(x))$ where the continuous function $b:\mathbb{R}^3\to\mathbb{R}$
belongs to a suitable admissible family.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 08:33:40 GMT""}]","2022-12-12"
"2212.04724","Walter Briec","Jean-Philippe Boussemart, Walter Briec, Herv\'e Leleu, Paola
  Ravelojaona","$\Lambda$-Returns to Scale and Individual Minimum Extrapolation
  Principle","27 pages, 8 figures",,,,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  This paper proposes to estimate the returns-to-scale of a production set by
considering the individual return of each observed firm. Each individual
returns-to-scale is estimated from the goodness of fit approach proposed by
Boussemart et al. (2019). The global technology is then constructed as the
intersection of all the individual technologies. We propose an axiomatic
foundation by introducing the notion of $\Lambda$-returns to scale that
encompasses as a special case the standard definition of $\alpha$-returns to
scale (Boussemart et al., 2009). Along this line it is shown that many
production models involving variable, non-increasing and non-decreasing
returns-to-scale appear to be special cases of models satisfying a
$\Lambda$-returns to scale assumption.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 08:35:26 GMT""}]","2022-12-12"
"2212.04725","Yuzhen Mao","Yuzhen Mao, Jianhui Sun, Dawei Zhou","Augmenting Knowledge Transfer across Graphs",,,,,"cs.LG cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a resource-rich source graph and a resource-scarce target graph, how
can we effectively transfer knowledge across graphs and ensure a good
generalization performance? In many high-impact domains (e.g., brain networks
and molecular graphs), collecting and annotating data is prohibitively
expensive and time-consuming, which makes domain adaptation an attractive
option to alleviate the label scarcity issue. In light of this, the
state-of-the-art methods focus on deriving domain-invariant graph
representation that minimizes the domain discrepancy. However, it has recently
been shown that a small domain discrepancy loss may not always guarantee a good
generalization performance, especially in the presence of disparate graph
structures and label distribution shifts. In this paper, we present TRANSNET, a
generic learning framework for augmenting knowledge transfer across graphs. In
particular, we introduce a novel notion named trinity signal that can naturally
formulate various graph signals at different granularity (e.g., node
attributes, edges, and subgraphs). With that, we further propose a domain
unification module together with a trinity-signal mixup scheme to jointly
minimize the domain discrepancy and augment the knowledge transfer across
graphs. Finally, comprehensive empirical results show that TRANSNET outperforms
all existing approaches on seven benchmark datasets by a significant margin.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 08:46:02 GMT""}]","2022-12-12"
"2212.04726","Tian Bai","Tian Bai and Mingyu Xiao","Breaking the Barrier $2^k$ for Subset Feedback Vertex Set in Chordal
  Graphs","31 pages, 9 figures. Full version",,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Subset Feedback Vertex Set problem (SFVS), to delete $k$ vertices from a
given graph such that any vertex in a vertex subset (called a terminal set) is
not in a cycle in the remaining graph, generalizes the famous Feedback Vertex
Set problem and Multiway Cut problem. SFVS remains $\mathrm{NP}$-hard even in
split and chordal graphs, and SFVS in Chordal Graphs (SFVS-C) can be considered
as a special case of the 3-Hitting Set problem. However, it is not easy to
solve SFVS-C faster than 3-Hitting Set. In 2019, Philip, Rajan, Saurabh, and
Tale (Algorithmica 2019) proved that SFVS-C can be solved in $2^k
n^{\mathcal{O}(1)}$, slightly improving the best result $2.076^k
n^{\mathcal{O}(1)}$ for 3-Hitting Set. In this paper, we break the
""$2^k$-barrier"" for SFVS-C by giving a $1.619^k n^{\mathcal{O}(1)}$-time
algorithm. Our algorithm uses reduction and branching rules based on the
Dulmage-Mendelsohn decomposition and a divide-and-conquer method.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 08:48:32 GMT""},{""version"":""v2"",""created"":""Thu, 16 Feb 2023 02:31:03 GMT""}]","2023-02-17"
"2212.04727","Dominik Christiansen","Dominik Christiansen, Malte Selig, Jens Biegert, and Andreas Knorr","Theory of X-ray absorption spectroscopy: a microscopic Bloch equation
  approach for two-dimensional solid states",,,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  We develop a self-consistent Maxwell-Bloch formalism for the interaction of
X-rays with two-dimensional crystalline materials by incorporating the Bloch
theorem and Coulomb many-body interaction. This formalism is illustrated for
graphene, by calculating the polarization-dependent XANES, formulating
expressions for the radiative and Meinter-Auger recombination of core-holes,
and the discussion of microscopic insights into the spectral oscillations of
EXAFS beyond point scattering theory. In particular, the correct inclusion of
lattice periodicity in our evaluation allows us to assign so far uninterpreted
spectral features in the Fourier transformed EXAFS spectrum.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 08:50:56 GMT""}]","2022-12-12"
"2212.04728","Barbara Catinella","Barbara Catinella, Luca Cortese, Alfred L. Tiley, Steven Janowiecki,
  Adam B. Watts, Julia J. Bryant, Scott M. Croom, Francesco d'Eugenio, Jesse
  van de Sande, Joss Bland-Hawthorn, Amelia Fraser-McKelvie, Samuel N.
  Richards, Sarah M. Sweet, Daniel J. Pisano, Nickolas Pingel, Rebecca A.
  Koopmann, Dillion Cottrill and Meghan Hill","SAMI-HI: The HI view of the H$\alpha$ Tully-Fisher relation and data
  release","18 pages, 12 figures. Accepted for publication in MNRAS",,"10.1093/mnras/stac3556",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present SAMI-HI, a survey of the atomic hydrogen content of 296 galaxies
with integral field spectroscopy available from the SAMI Galaxy Survey. The
sample spans nearly 4 dex in stellar mass ($M_\star = 10^{7.4}-10^{11.1}~ \rm
M_\odot$), redshift $z<0.06$, and includes new Arecibo observations of 153
galaxies, for which we release catalogues and HI spectra. We use these data to
compare the rotational velocities obtained from optical and radio observations
and to show how systematic differences affect the slope and scatter of the
stellar-mass and baryonic Tully-Fisher relations. Specifically, we show that
H$\alpha$ rotational velocities measured in the inner parts of galaxies (1.3
effective radii in this work) systematically underestimate HI global
measurements, with HI/H$\alpha$ velocity ratios that increase at low stellar
masses, where rotation curves are typically still rising and H$\alpha$
measurements do not reach their plateau. As a result, the H$\alpha$ stellar
mass Tully-Fisher relation is steeper (when $M_\star$ is the independent
variable) and has larger scatter than its HI counterpart. Interestingly, we
confirm the presence of a small fraction of low-mass outliers of the H$\alpha$
relation that are not present when HI velocity widths are used and are not
explained by ""aperture effects"". These appear to be highly disturbed systems
for which H$\alpha$ widths do not provide a reliable estimate of the rotational
velocity. Our analysis reaffirms the importance of taking into account
differences in velocity definitions as well as tracers used when interpreting
offsets from the Tully-Fisher relation, at both low and high redshifts and when
comparing with simulations.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 08:57:58 GMT""}]","2023-01-04"
"2212.04729","Adam Watts","Adam B. Watts, Luca Cortese, Barbara Catinella, Chris Power, Amelia
  Fraser-McKelvie, Julia J. Bryant, Scott M. Croom, Jesse van de Sande, Joss
  Bland-Hawthorn, and Brent Groves","SAMI-HI: the connection between global asymmetry in the ionised and
  neutral atomic hydrogen gas in galaxies","11 pages, 6 figures, 1 appendix, accepted for publication in MNRAS",,"10.1093/mnras/stac3643",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Observations of the neutral atomic hydrogen (HI) gas in galaxies are
predominantly spatially unresolved, in the form of a global HI spectral line.
There has been substantial work on quantifying asymmetry in global HI spectra
(`global HI asymmetry'), but due to being spatially unresolved, it remains
unknown what physical regions of galaxies the asymmetry traces, and whether the
other gas phases are affected. Using optical integral field spectrograph (IFS)
observations from the Sydney AAO Multi-object IFS (SAMI) survey for which
global HI spectra are also available (SAMI-HI), we study the connection between
asymmetry in galaxies' ionised and neutral gas reservoirs to test if and how
they can help us better understand the origin of global HI asymmetry. We
reconstruct the global H$\alpha$ spectral line from the IFS observations and
find that, while some global H$\alpha$ asymmetries can arise from disturbed
ionised gas kinematics, the majority of asymmetric cases are driven by the
distribution of H$\alpha$-emitting gas. When compared to the HI, we find no
evidence for a relationship between the global H$\alpha$ and HI asymmetry.
Further, a visual inspection reveals that cases where galaxies have
qualitatively similar H$\alpha$ and HI spectral profiles can be spurious, with
the similarity originating from an irregular 2D H$\alpha$ flux distribution.
Our results highlight that comparisons between global H$\alpha$ and HI
asymmetry are not straightforward, and that many global HI asymmetries trace
disturbances that do not significantly impact the central regions of galaxies.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 08:57:59 GMT""},{""version"":""v2"",""created"":""Tue, 20 Dec 2022 03:34:59 GMT""}]","2022-12-28"
"2212.04730","Alexander Ilyichev Dr.","A. Afanasev, I. Akushevich, A. Ilyichev, N. Merenkov","ESFRAD. FORTRAN code for calculation of QED corrections to polarized
  ep-scattering by the electron structure function method","Contribution to: 17th International Workshop on High-Energy Physics
  and Quantum Field Theory (QFTHEP 2003), 154-161",,,,"hep-ph","http://creativecommons.org/publicdomain/zero/1.0/","  The main features of the electron structure function method for calculations
of the higher order QED radiative effects to polarized deep-inelastic
ep-scattering are presented. A new FORTRAN code ESFRAD based on this method was
developed. A detailed quantitative comparison between the results of ESFRAD and
other methods implemented in the codes POLRAD and RADGEN for calculation of the
higher order radiative corrections is performed.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 08:58:34 GMT""}]","2022-12-12"
"2212.04731","Zhuyun Zhuang","Zhuyun Zhuang, Nicha Leethochawalit, Evan N. Kirby, J. W. Nightingale,
  Charles C. Steidel, Karl Glazebrook, Tania M. Barone, Hannah Skobe, Sarah M.
  Sweet, Themiya Nanayakkara, Rebecca J. Allen, Keerthi Vasan G. C., Tucker
  Jones, Glenn G. Kacprzak, Kim-Vy H. Tran, Colin Jacobs","A Glimpse of the Stellar Populations and Elemental Abundances of
  Gravitationally Lensed, Quiescent Galaxies at $z\gtrsim 1$ with Keck Deep
  Spectroscopy","18 pages, 11 figures. Accepted for publication in ApJ. The broadband
  SED fitting and stellar mass measurements updated. A new Section 5.4 is added
  to discuss the differences between the measured parameters from the SED and
  full-spectrum fitting",,"10.3847/1538-4357/acc79b",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gravitational lenses can magnify distant galaxies, allowing us to discover
and characterize the stellar populations of intrinsically faint, quiescent
galaxies that are otherwise extremely difficult to directly observe at high
redshift from ground-based telescopes. Here, we present the spectral analysis
of two lensed, quiescent galaxies at $z\gtrsim 1$ discovered by the ASTRO 3D
Galaxy Evolution with Lenses survey: AGEL1323 ($M_*\sim 10^{11.1}M_{\odot}$,
$z=1.016$, $\mu \sim 14.6$) and AGEL0014 ($M_*\sim 10^{11.5}M_{\odot}$,
$z=1.374$, $\mu \sim 4.3$). We measured the age, [Fe/H], and [Mg/Fe] of the two
lensed galaxies using deep, rest-frame-optical spectra (S/N $\gtrsim
40$~$\mathring {\mathrm A}$$^{-1}$) obtained on the Keck~I telescope. The ages
of AGEL1323 and AGEL0014 are $5.6^{+0.8}_{-0.8}$~Gyr and
$3.1^{+0.8}_{-0.3}$~Gyr, respectively, indicating that most of the stars in the
galaxies were formed less than 2~Gyr after the Big Bang. Compared to nearby
quiescent galaxies of similar masses, the lensed galaxies have lower [Fe/H] and
[Mg/H]. Surprisingly, the two galaxies have comparable [Mg/Fe] to similar-mass
galaxies at lower redshifts, despite their old ages. Using a simple analytic
chemical evolution model connecting the instantaneously recycled element Mg
with the mass-loading factors of outflows averaged over the entire star
formation history, we found that the lensed galaxies may have experienced
enhanced outflows during their star formation compared to lower-redshift
galaxies, which may explain why they quenched early.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 09:00:24 GMT""},{""version"":""v2"",""created"":""Fri, 31 Mar 2023 03:41:29 GMT""}]","2023-05-24"
"2212.04732","Zhe Liu","Zhe Liu, Chunyang Chen, Junjie Wang, Xing Che, Yuekai Huang, Jun Hu,
  Qing Wang","Fill in the Blank: Context-aware Automated Text Input Generation for
  Mobile GUI Testing","Accepted by IEEE/ACM International Conference on Software Engineering
  2023 (ICSE 2023)",,,,"cs.SE","http://creativecommons.org/publicdomain/zero/1.0/","  Automated GUI testing is widely used to help ensure the quality of mobile
apps. However, many GUIs require appropriate text inputs to proceed to the next
page which remains a prominent obstacle for testing coverage. Considering the
diversity and semantic requirement of valid inputs (e.g., flight departure,
movie name), it is challenging to automate the text input generation. Inspired
by the fact that the pre-trained Large Language Model (LLM) has made
outstanding progress in text generation, we propose an approach named QTypist
based on LLM for intelligently generating semantic input text according to the
GUI context. To boost the performance of LLM in the mobile testing scenario, we
develop a prompt-based data construction and tuning method which automatically
extracts the prompts and answers for model tuning. We evaluate QTypist on 106
apps from Google Play and the result shows that the passing rate of QTypist is
87%, which is 93% higher than the best baseline. We also integrate QTypist with
the automated GUI testing tools and it can cover 42% more app activities, 52%
more pages, and subsequently help reveal 122% more bugs compared with the raw
tool.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 09:00:38 GMT""}]","2022-12-12"
"2212.04733","Ines Cavero-Pelaez","C. Romaniega, J. M. Munoz-Castaneda and I. Cavero-Pelaez","Casimir self-energy of a \delta-\delta' sphere",,,"10.1103/PhysRevD.107.025002",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  We extend previous work on the vacuum energy of a massless scalar field in
the presence of singular potentials. We consider a single sphere denoted by the
so-called ""delta-delta prime"" interaction. Contrary to the Dirac delta
potential, we find a nontrivial one-parameter family of potentials such that
the regularization procedure gives an unambiguous result for the Casimir
self-energy. The procedure employed is based on the zeta function
regularization and the cancellation of the heat kernel coefficient a_2. The
results obtained are in agreement with particular cases, such as the Dirac
delta or Robin and Dirichlet boundary conditions.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 09:09:52 GMT""}]","2023-01-18"
"2212.04734","Yera Choi","Hyeonbin Hwang, Haanju Yoo, Yera Choi","MED-SE: Medical Entity Definition-based Sentence Embedding","8 pages, 2 figures, 9 tables",,,,"cs.LG cs.AI cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose Medical Entity Definition-based Sentence Embedding (MED-SE), a
novel unsupervised contrastive learning framework designed for clinical texts,
which exploits the definitions of medical entities. To this end, we conduct an
extensive analysis of multiple sentence embedding techniques in clinical
semantic textual similarity (STS) settings. In the entity-centric setting that
we have designed, MED-SE achieves significantly better performance, while the
existing unsupervised methods including SimCSE show degraded performance. Our
experiments elucidate the inherent discrepancies between the general- and
clinical-domain texts, and suggest that entity-centric contrastive approaches
may help bridge this gap and lead to a better representation of clinical
sentences.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 09:10:19 GMT""}]","2022-12-12"
"2212.04735","Jaume Terradas","Jaume Terradas, Thomas Neukirch","Three-dimensional solar active region magnetohydrostatic models and
  their stability using Euler potentials","Accepted for publication in A&A","A&A 671, A31 (2023)","10.1051/0004-6361/202244687",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Active regions (ARs) are typical magnetic structures found in the solar
atmosphere. We calculate several magnetohydrostatic (MHS) equilibrium models
that include the effect of a finite plasma-$\beta$ and gravity and that are
representative of these structures in three dimensions. The construction of the
models is based on the use of two Euler potentials, $\alpha$ and $\beta$, that
represent the magnetic field as ${\bf B}=\nabla \alpha \times \nabla \beta$.
The ideal MHS nonlinear partial differential equations are solved numerically
using finite elements in a fixed 3D rectangular domain. The boundary conditions
are initially chosen to correspond to a potential magnetic field (current-free)
with known analytical expressions for the corresponding Euler potentials. The
distinctive feature is that we incorporate the effect of shear by progressively
deforming the initial potential magnetic field. This procedure is quite generic
and allows us to generate a vast variety of MHS models. The thermal structure
of the ARs is incorporated through the dependence of gas pressure and
temperature on the Euler potentials. Using this method we achieve the
characteristic hot and over-dense plasma found in ARs, but we demonstrate that
the method can also be applied to study configurations with open magnetic field
lines. Furthermore, we investigate basic topologies that include neutral lines.
Our focus is on the force balance of the structures and we do not consider the
energy balance in the constructed models. In addition, we address the difficult
question of the stability of the calculated 3D models. We find that if the
plasma is convectively stable, then the system is not prone in general to
develop magnetic Rayleigh-Taylor instabilities.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 09:11:36 GMT""}]","2023-03-08"
"2212.04736","Zhe Chen","Zhe Chen, Garrett J. Blair, Chengdi Cao, Jim Zhou, Daniel Aharoni,
  Peyman Golshani, Hugh T. Blair, and Jason Cong","FPGA-Based In-Vivo Calcium Image Decoding for Closed-Loop Feedback
  Applications","11 pages, 15 figures",,,,"eess.IV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Miniaturized calcium imaging is an emerging neural recording technique that
has been widely used for monitoring neural activity on a large scale at a
specific brain region of rats or mice. Most existing calcium-image analysis
pipelines operate offline. This results in long processing latency, making it
difficult to realize closed-loop feedback stimulation for brain research. In
recent work, we have proposed an FPGA-based real-time calcium image processing
pipeline for closed-loop feedback applications. It can perform real-time
calcium image motion correction, enhancement, fast trace extraction, and
real-time decoding from extracted traces. Here, we extend this work by
proposing a variety of neural network based methods for real-time decoding and
evaluate the tradeoff among these decoding methods and accelerator designs. We
introduced the implementation of the neural network based decoders on the FPGA,
and showed their speedup against the implementation on the ARM processor. Our
FPGA implementation enables the real-time calcium image decoding with sub-ms
processing latency for closed-loop feedback applications.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 09:12:26 GMT""},{""version"":""v2"",""created"":""Mon, 17 Apr 2023 00:53:07 GMT""}]","2023-04-18"
"2212.04737","Jean Dalibard","William D. Phillips and Jean Dalibard","Experimental tests of Bell's inequalities: A first-hand account by Alain
  Aspect","Accepted for publication in the topical issue ""Quantum Optics of
  Light and Matter"" of EPJD, Edts. D. Cl\'ement, P. Grangier and J. Thywissen",,"10.1140/epjd/s10053-022-00557-6",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  On 04 October 2022, the Royal Swedish Academy of Sciences announced that the
Nobel Prize for Physics of 2022 was awarded jointly to Alain Aspect, John
Clauser, and Anton Zeilinger ""for experiments with entangled photons,
establishing the violation of Bell inequalities and pioneering quantum
information science"". What follows is an interview of Alain Aspect, conducted
by Bill Phillips and Jean Dalibard, during the summer of 2022, and completed
not long before the announcement of the Nobel Prize. The subject matter is
essentially that for which the Nobel Prize was awarded.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 09:13:17 GMT""}]","2023-01-25"
"2212.04738","Keita Imaizumi","Keita Imaizumi","Exact conditions for Quasi-normal modes of extremal M5-branes and Exact
  WKB analysis","25 pages, 8 figures",,"10.1016/j.nuclphysb.2023.116221",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the quasi-normal modes (QNMs) of a massless scalar perturbation to
the extremal M5-branes metric by using the exact WKB analysis. The exact WKB
analysis provides two exact QNMs conditions depending on the argument of the
complex frequency of the perturbation. The exact conditions show that the
discontinuity of the perturbative part of the QNMs leads the non-perturbative
part of themselves. We also find a new example of the Seiberg-Witten/gravity
correspondence, which helps us to compute the QNMs from our conditions.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 09:16:33 GMT""}]","2023-05-31"
"2212.04739","\""Onder Askin","Tim Kutta, \""Onder Askin, Martin Dunsche","Lower Bounds for R\'enyi Differential Privacy in a Black-Box Setting",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present new methods for assessing the privacy guarantees of an algorithm
with regard to R\'enyi Differential Privacy. To the best of our knowledge, this
work is the first to address this problem in a black-box scenario, where only
algorithmic outputs are available. To quantify privacy leakage, we devise a new
estimator for the R\'enyi divergence of a pair of output distributions. This
estimator is transformed into a statistical lower bound that is proven to hold
for large samples with high probability. Our method is applicable for a broad
class of algorithms, including many well-known examples from the privacy
literature. We demonstrate the effectiveness of our approach by experiments
encompassing algorithms and privacy enhancing methods that have not been
considered in related works.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 09:23:27 GMT""}]","2022-12-12"
"2212.04740","Martin Hanik","Do\u{g}a T\""urkseven and Islem Rekik and Christoph von Tycowicz and
  Martin Hanik","Predicting Shape Development: a Riemannian Method","new experiment with human motion data; fixed vertex-assignment bug in
  the prediction of the varifold-based method",,,,"cs.CV math.DG q-bio.TO","http://creativecommons.org/licenses/by/4.0/","  Predicting the future development of an anatomical shape from a single
baseline observation is a challenging task. But it can be essential for
clinical decision-making. Research has shown that it should be tackled in
curved shape spaces, as (e.g., disease-related) shape changes frequently expose
nonlinear characteristics. We thus propose a novel prediction method that
encodes the whole shape in a Riemannian shape space. It then learns a simple
prediction technique founded on hierarchical statistical modeling of
longitudinal training data. When applied to predict the future development of
the shape of the right hippocampus under Alzheimer's disease and to human body
motion, it outperforms deep learning-supported variants as well as
state-of-the-art.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 09:36:59 GMT""},{""version"":""v2"",""created"":""Sat, 11 Mar 2023 10:07:45 GMT""}]","2023-03-14"
"2212.04741","Zhengping Zhou","Ziyuan Huang, Zhengping Zhou, Yung-Yu Chuang, Jiajun Wu, C. Karen Liu","Physically Plausible Animation of Human Upper Body from a Single Image","WACV 2023",,,,"cs.CV cs.AI cs.GR cs.RO","http://creativecommons.org/licenses/by-sa/4.0/","  We present a new method for generating controllable, dynamically responsive,
and photorealistic human animations. Given an image of a person, our system
allows the user to generate Physically plausible Upper Body Animation (PUBA)
using interaction in the image space, such as dragging their hand to various
locations. We formulate a reinforcement learning problem to train a dynamic
model that predicts the person's next 2D state (i.e., keypoints on the image)
conditioned on a 3D action (i.e., joint torque), and a policy that outputs
optimal actions to control the person to achieve desired goals. The dynamic
model leverages the expressiveness of 3D simulation and the visual realism of
2D videos. PUBA generates 2D keypoint sequences that achieve task goals while
being responsive to forceful perturbation. The sequences of keypoints are then
translated by a pose-to-image generator to produce the final photorealistic
video.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 09:36:59 GMT""}]","2022-12-12"
"2212.04742","Dominik Ertel","Dominik Ertel, Marvin Schmoll, Samuel Kellerer, Anna-Lena J\""ager,
  Robin Weissenbilder, Matteo Moioli, Hamed Ahmadi, David Busto, Ioannis Makos,
  Fabio Frassetto, Luca Poletto, Claus Dieter Schr\""oter, Thomas Pfeifer,
  Robert Moshammer, and Giuseppe Sansone","Ultrastable, high-repetition-rate attosecond beamline for time-resolved
  XUV-IR coincidence spectroscopy",,,,,"physics.atom-ph","http://creativecommons.org/licenses/by/4.0/","  The implementation of attosecond photoelectron-photoion coincidence
spectroscopy for the investigation of atomic and molecular dynamics calls for a
high-repetition-rate driving source combined with experimental setups
characterized by excellent stability for data acquisition over time intervals
ranging from a few hours up to a few days. This requirement is crucial for the
investigation of processes characterized by low cross sections and for the
characterization of fully differential photoelectron(s) and photoion(s) angular
and energy distributions. We demonstrate that the implementation of
industrial-grade lasers, combined with a careful design of the delay line
implemented in the pump-probe setup, allows one to reach ultrastable
experimental conditions leading to an error in the estimation of the time
delays of only 12 as. This result opens new possibilities for the investigation
of attosecond dynamics in simple quantum systems.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 09:39:24 GMT""}]","2022-12-12"
"2212.04743","Victor Sanmartin-Lopez","Victor Sanmartin-Lopez","Codimension one Ricci soliton subgroups of nilpotent Iwasawa groups",,,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Any expanding homogeneous Ricci soliton (in particular any homogeneous
Einstein manifold of negative scalar curvature) can be obtained, up to
isometry, from a Lie subgroup of a nilpotent Iwasawa group $N$ whose induced
metric is a Ricci soliton. By nilpotent Iwasawa group we mean the nilpotent Lie
group $N$ of the Iwasawa decomposition associated with a symmetric space of
non-compact type. Motivated by this fact, in this paper we classify codimension
one Lie subgroups of any nilpotent Iwasawa group $N$ whose induced metric is a
Ricci soliton.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 09:40:49 GMT""}]","2022-12-12"
"2212.04744","Yachao Zhang","Yachao Zhang, Zonghao Li, Yuan Xie, Yanyun Qu, Cuihua Li, Tao Mei","Weakly Supervised Semantic Segmentation for Large-Scale Point Cloud",,,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  Existing methods for large-scale point cloud semantic segmentation require
expensive, tedious and error-prone manual point-wise annotations. Intuitively,
weakly supervised training is a direct solution to reduce the cost of labeling.
However, for weakly supervised large-scale point cloud semantic segmentation,
too few annotations will inevitably lead to ineffective learning of network. We
propose an effective weakly supervised method containing two components to
solve the above problem. Firstly, we construct a pretext task, \textit{i.e.,}
point cloud colorization, with a self-supervised learning to transfer the
learned prior knowledge from a large amount of unlabeled point cloud to a
weakly supervised network. In this way, the representation capability of the
weakly supervised network can be improved by the guidance from a heterogeneous
task. Besides, to generate pseudo label for unlabeled data, a sparse label
propagation mechanism is proposed with the help of generated class prototypes,
which is used to measure the classification confidence of unlabeled point. Our
method is evaluated on large-scale point cloud datasets with different
scenarios including indoor and outdoor. The experimental results show the large
gain against existing weakly supervised and comparable results to fully
supervised methods\footnote{Code based on mindspore:
https://github.com/dmcv-ecnu/MindSpore\_ModelZoo/tree/main/WS3\_MindSpore}.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 09:42:26 GMT""}]","2022-12-12"
"2212.04745","Marziyeh Bamdad","Marziyeh Bamdad, Davide Scaramuzza, Alireza Darvishy","SLAM for Visually Impaired People: A Survey","26 pages, 5 tables, 3 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent decades, several assistive technologies for visually impaired and
blind (VIB) people have been developed to improve their ability to navigate
independently and safely. At the same time, simultaneous localization and
mapping (SLAM) techniques have become sufficiently robust and efficient to be
adopted in the development of assistive technologies. In this paper, we first
report the results of an anonymous survey conducted with VIB people to
understand their experience and needs; we focus on digital assistive
technologies that help them with indoor and outdoor navigation. Then, we
present a literature review of assistive technologies based on SLAM. We discuss
proposed approaches and indicate their pros and cons. We conclude by presenting
future opportunities and challenges in this domain.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 09:45:43 GMT""}]","2022-12-12"
"2212.04746","Edoardo Filippi-Mazzola","Raffaele Argiento, Edoardo Filippi-Mazzola, Lucia Paci","Model-based clustering of categorical data based on the Hamming distance",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  A model-based approach is developed for clustering categorical data with no
natural ordering. The proposed method exploits the Hamming distance to define a
family of probability mass functions to model the data. The elements of this
family are then considered as kernels of a finite mixture model with unknown
number of components. Conjugate Bayesian inference has been derived for the
parameters of the Hamming distribution model. The mixture is framed in a
Bayesian nonparametric setting and a transdimensional blocked Gibbs sampler is
developed to provide full Bayesian inference on the number of clusters, their
structure and the group-specific parameters, facilitating the computation with
respect to customary reversible jump algorithms. The proposed model encompasses
a parsimonious latent class model as a special case, when the number of
components is fixed. Model performances are assessed via a simulation study and
reference datasets, showing improvements in clustering recovery over existing
approaches.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 09:47:20 GMT""}]","2022-12-12"
"2212.04747","Matthias Wessling","Daniel Felder, Katerina Muche, John Linkhorst, Matthias Wessling","Reminding Forgetful Organic Neuromorphic Device Networks",,"Neuromorph. Comput. Eng. 2 044014 (2022)","10.1088/2634-4386/ac9c8a",,"cs.ET cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Organic neuromorphic device networks can accelerate neural network algorithms
and directly integrate with microfluidic systems or living tissues. Proposed
devices based on the bio-compatible conductive polymer PEDOT:PSS have shown
high switching speeds and low energy demand. However, as electrochemical
systems, they are prone to self-discharge through parasitic electrochemical
reactions. Therefore, the network's synapses forget their trained conductance
states over time. This work integrates single-device high-resolution charge
transport models to simulate neuromorphic device networks and analyze the
impact of self-discharge on network performance. Simulation of a single-layer
nine-pixel image classification network reveals no significant impact of
self-discharge on training efficiency. And, even though the network's weights
drift significantly during self-discharge, its predictions remain 100\%
accurate for over ten hours. On the other hand, a multi-layer network for the
approximation of the circle function is shown to degrade significantly over
twenty minutes with a final mean-squared-error loss of 0.4. We propose to
counter the effect by periodically reminding the network based on a map between
a synapse's current state, the time since the last reminder, and the weight
drift. We show that this method with a map obtained through validated
simulations can reduce the effective loss to below 0.1 even with worst-case
assumptions. Finally, while the training of this network is affected by
self-discharge, a good classification is still obtained. Electrochemical
organic neuromorphic devices have not been integrated into larger device
networks. This work predicts their behavior under nonideal conditions,
mitigates the worst-case effects of parasitic self-discharge, and opens the
path toward implementing fast and efficient neural networks on organic
neuromorphic hardware.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 09:50:41 GMT""}]","2022-12-12"
"2212.04748","Martin \v{C}ern\'y","Martin \v{C}ern\'y","Approximations of solution concepts of cooperative games",,,,,"cs.GT","http://creativecommons.org/publicdomain/zero/1.0/","  The computation of a solution concept of a cooperative game usually depends
on values of all coalitions. However, in some applications, values of some of
the coalitions might be unknown due to various reasons. We introduce a method
to approximate standard solution concepts based only on partial information
given by a so called incomplete game. We demonstrate the ideas on the class of
minimal incomplete games. Approximations are derived for different solution
concepts including the Shapley value, the nucleolus, or the core. We show
explicit formulas for approximations of some of the solution concepts and show
how the approximability differs based on additional information about the game.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 09:53:08 GMT""}]","2022-12-12"
"2212.04749","Chu Guo","Yong Liu, Yaojian Chen, Chu Guo, Jiawei Song, Xinmin Shi, Lin Gan,
  Wenzhao Wu, Wei Wu, Haohuan Fu, Xin Liu, Dexun Chen, Guangwen Yang, Jiangang
  Gao","Validating quantum-supremacy experiments with exact and fast tensor
  network contraction","7 pages, 4 figures, comments are welcome!",,,,"quant-ph cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The quantum circuits that declare quantum supremacy, such as Google Sycamore
[Nature \textbf{574}, 505 (2019)], raises a paradox in building reliable result
references. While simulation on traditional computers seems the sole way to
provide reliable verification, the required run time is doomed with an
exponentially-increasing compute complexity. To find a way to validate current
``quantum-supremacy"" circuits with more than $50$ qubits, we propose a
simulation method that exploits the ``classical advantage"" (the inherent
``store-and-compute"" operation mode of von Neumann machines) of current
supercomputers, and computes uncorrelated amplitudes of a random quantum
circuit with an optimal reuse of the intermediate results and a minimal memory
overhead throughout the process. Such a reuse strategy reduces the original
linear scaling of the total compute cost against the number of amplitudes to a
sublinear pattern, with greater reduction for more amplitudes. Based on a
well-optimized implementation of this method on a new-generation Sunway
supercomputer, we directly verify Sycamore by computing three million exact
amplitudes for the experimentally generated bitstrings, obtaining an XEB
fidelity of $0.191\%$ which closely matches the estimated value of $0.224\%$.
Our computation scales up to $41,932,800$ cores with a sustained
single-precision performance of $84.8$ Pflops, which is accomplished within
$8.5$ days. Our method has a far-reaching impact in solving quantum many-body
problems, statistical problems as well as combinatorial optimization problems
where one often needs to contract many tensor networks which share a
significant portion of tensors in common.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 10:01:02 GMT""}]","2022-12-12"
"2212.04750","Mathias Rousset","Fr\'ed\'eric C\'erou (IRMAR, SIMSMART), Sofiane Martel (ENPC), Mathias
  Rousset (SIMSMART, IRMAR)","Fluctuations of Rare Event Simulation with Monte Carlo Splitting in the
  Small Noise Asymptotics",,,,,"math.NA cs.NA math.PR stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Diffusion processes with small noise conditioned to reach a target set are
considered. The AMS algorithm is a Monte Carlo method that is used to sample
such rare events by iteratively simulating clones of the process and selecting
trajectories that have reached the highest value of a so-called importance
function. In this paper, the large sample size relative variance of the AMS
small probability estimator is considered. The main result is a large
deviations logarithmic equivalent of the latter in the small noise asymptotics,
which is rigorously derived. It is given as a maximisation problem explicit in
terms of the quasi-potential cost function associated with the underlying small
noise large deviations. Necessary and sufficient geometric conditions ensuring
the vanishing of the obtained quantity ('weak' asymptotic efficiency) are
provided. Interpretations and practical consequences are discussed.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 10:10:16 GMT""}]","2022-12-12"
"2212.04751","Deepak Jain","David Dahiya and Deepak Jain","Revisiting the epoch of cosmic acceleration","16 pages, 4 Figures, 3 Tables",,,,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  We revisit the epoch of cosmic speed-up characterized by the redshift of
transition from a decelerated to an accelerated phase. This redshift is termed
the transition redshift ($z_t$). We use the spatially Flat and Non-Flat
variants of the most common $\Lambda$CDM and XCDM models to put constraints on
the transition redshift along with the other model parameters. The data for
this analysis comes from the recent and updated Pantheon+ Supernova dataset and
the Hubble parameter measurements obtained from Cosmic Chronometers. We
consider both datasets with their respective covariance matrices incorporating
all kinds of statistical and systematic uncertainties. We observe that using
the combined datasets of H(z) and SNe, the best fit value of transition
redshift lies in the range $0.61 < z_t < 0.82$ for all four dark energy models.
Incidentally, we observe a positive curvature for the Non-Flat models and
correlations between several model parameters.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 10:10:46 GMT""},{""version"":""v2"",""created"":""Mon, 12 Dec 2022 09:56:11 GMT""}]","2022-12-13"
"2212.04752","Michael Goldman","Michael Goldman (CMAP), Beno\^it Merlet (RAPSODI, LPP)","Set-decomposition of normal rectifiable G-chains via an abstract
  decomposition principle",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the notion of set-decomposition of a normal G-flat chain. We
show that any normal rectifiable $G$-flat chain admits a decomposition in
set-indecomposable sub-chains. This generalizes the decomposition of sets of
finite perimeter in their ``measure theoretic'' connected components due to
Ambrosio, Caselles, Masnou and Morel. It can also be seen as a variant of the
decomposition of integral currents in indecomposable components by Federer.As
opposed to previous results, we do not assume that G is boundedly compact.
Therefore we cannot rely on the compactness of sequences of chains with
uniformly bounded N-norms. We deduce instead the result from a new abstract
decomposition principle. As in earlier proofs a central ingredient is the
validity of an isoperimetric inequality. We obtain it here using the finiteness
of some h-mass to replace integrality.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 10:13:17 GMT""}]","2022-12-12"
"2212.04753","Michael Goldman","Michael Goldman (CMAP), Beno\^it Merlet (RAPSODI, LPP)","Tensor rectifiable G-flat chains",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A rigidity result for normal rectifiable $k$-chains in $\mathbb{R}^n$ with
coefficients in an Abelian normed group is established. Given some
decompositions $k=k_1+k_2$, $n=n_1+n_2$ and some rectifiable $k$-chain $A$ in
$\mathbb{R}^n$, we consider the properties:(1) The tangent planes to $\mu_A$
split as $T_x\mu_A=L^1(x)\times L^2(x)$ for some $k_1$-plane
$L^1(x)\subset\mathbb{R}^{n_1}$ and some $k_2$-plane
$L^2(x)\subset\mathbb{R}^{n_2}$.(2) $A=A_{\vert\Sigma^1\times\Sigma^2}$ for
some sets $\Sigma^1\subset\mathbb{R}^{n_1}$, $\Sigma^2\subset\mathbb{R}^{n_2}$
such that $\Sigma^1$ is $k_1$-rectifiable and $\Sigma^2$ is $k_2$-rectifiable
(we say that $A$ is $(k_1,k_2)$-rectifiable).The main result is that for normal
chains, (1) implies (2), the converse is immediate. In the proof we introduce
the new groups of tensor flat chains (or $(k_1,k_2)$-chains) in
$\mathbb{R}^{n_1}\times\mathbb{R}^{n_2}$ which generalize Fleming's $G$-flat
chains. The other main tool is White's rectifiable slices theorem. We show that
on the one hand any normal rectifiable chain satisfying~(1) identifies with a
normal rectifiable $(k_1,k_2)$-chain and that on the other hand any normal
rectifiable $(k_1,k_2)$-chain is $(k_1,k_2)$-rectifiable.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 10:15:02 GMT""}]","2022-12-12"
"2212.04754","Zhipeng Yu","Zhipeng Yu, Jin Lin, Feng Liu, Jiarong Li, Yuxuan Zhao, Yonghua Song,
  Yanhua Song, Xinzhen Zhang","Optimal Sizing and Pricing of Renewable Power to Ammonia Systems
  Considering the Limited Flexibility of Ammonia Synthesis","10 pages, 10 figures",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Converting renewable energy into ammonia has been recognized as a promising
way to realize ``green hydrogen substitution"" in the chemical industry.
However, renewable power to ammonia (RePtA) requires an essential investment in
facilities to provide a buffer against the strong volatility of renewable
energy and the limited flexibility of ammonia synthesis, which involves the
three main stakeholders, namely, power, hydrogen, and ammonia. Therefore, the
sizing and pricing of RePtA play a core role in balancing the interest demands
of investors. This paper proposes an optimal sizing and pricing method for
RePtA system planning. First, power to ammonia (P2A) is modeled as a flexible
load, especially considering the limited flexibility of ammonia synthesis,
which has been verified using real dynamic regulation data. Second, the
multi-investor economic (MIE) model is established considering both external
and internal trading modes. Then, a two-stage decomposed sizing and pricing
method is proposed to solve the problem caused by the strong coupling of
planning, operation, and trading, and information gap decision theory (IGDT)
method is utilized to handle the uncertainty of renewable generation. Finally,
real data from a real-life system in Inner Mongolia are utilized to verify the
proposed approach. The results show that the system proposed has a yield of
8.15%.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 10:19:35 GMT""}]","2022-12-12"
"2212.04755","Weiwen Xu","Weiwen Xu, Xin Li, Wenxuan Zhang, Meng Zhou, Wai Lam, Luo Si, Lidong
  Bing","From Clozing to Comprehending: Retrofitting Pre-trained Masked Language
  Model to Pre-trained Machine Reader",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present Pre-trained Machine Reader (PMR), a novel method for retrofitting
pre-trained masked language models (MLMs) to pre-trained machine reading
comprehension (MRC) models without acquiring labeled data. PMR can resolve the
discrepancy between model pre-training and downstream fine-tuning of existing
MLMs. To build the proposed PMR, we constructed a large volume of
general-purpose and high-quality MRC-style training data by using Wikipedia
hyperlinks and designed a Wiki Anchor Extraction task to guide the MRC-style
pre-training. Apart from its simplicity, PMR effectively solves extraction
tasks, such as Extractive Question Answering and Named Entity Recognition. PMR
shows tremendous improvements over existing approaches, especially in
low-resource scenarios. When applied to the sequence classification task in the
MRC formulation, PMR enables the extraction of high-quality rationales to
explain the classification process, thereby providing greater prediction
explainability. PMR also has the potential to serve as a unified model for
tackling various extraction and classification tasks in the MRC formulation.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 10:21:56 GMT""},{""version"":""v2"",""created"":""Thu, 18 May 2023 07:36:32 GMT""}]","2023-05-19"
"2212.04756","Shisen Liu","Shisen Liu and Xiaojun Chen","Lifted Stationary Points of Sparse Optimization with Complementarity
  Constraints","29 pages, 3 figures",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We aim to compute lifted stationary points of a sparse optimization problem
(P0) with complementarity constraints. We define a continuous relaxation
problem (Rv) that has the same global minimizers and optimal value with problem
(P0). Problem (Rv) is a mathematical program with complementarity constraints
(MPCC) and a difference-of-convex (DC) objective function. We define MPCC
lifted-stationarity of (Rv) and show that it is weaker than directional
stationarity, but stronger than Clarke stationarity for local optimality.
Moreover, we propose an approximation method to solve (Rv) and an augmented
Lagrangian method to solve its subproblem, which relaxes the equality
constraint in (Rv) with a tolerance. We prove the convergence of our algorithm
to an MPCC lifted-stationary point of problem (Rv) and use a sparse
optimization problem with vertical linear complementarity constraints to
demonstrate the efficiency of our algorithm on finding sparse solutions in
practice.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 10:22:49 GMT""}]","2022-12-12"
"2212.04757","Diksha Tiwari","Diksha Tiwari, Akbarali Mukhammadiev, and Paolo Giordano","Hyper-power series and generalized real analytic functions",,,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  This article is a natural continuation of the paper Tiwari, D., Giordano, P.,
Hyperseries in the non-Archimedean ring of Colombeau generalized numbers in
this journal. We study one variable hyper-power series by analyzing the notion
of radius of convergence and proving classical results such as algebraic
operations, composition and reciprocal of hyper-power series. We then define
and study one variable generalized real analytic functions, considering their
derivation, integration, a suitable formulation of the identity theorem and the
characterization by uniform upper bounds of derivatives on functionally compact
sets. On the contrary with respect to the classical use of series in the theory
of Colombeau real analytic functions, we can recover several classical examples
in a non-infinitesimal set of convergence. The notion of generalized real
analytic function reveals to be less rigid both with respect to the classical
one and to Colombeau theory, e.g. including classical non-analytic smooth
functions with flat points and several distributions, such as the Dirac delta.
On the other hand, each Colombeau real analytic function is also a generalized
real analytic function.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 10:25:01 GMT""},{""version"":""v2"",""created"":""Thu, 15 Dec 2022 10:41:52 GMT""}]","2022-12-16"
"2212.04758","Ibragim A. Tlyustangelov","Ibragim A. Tlyustangelov","On symmetries of 3-dimensional algebraic continued fractions","In russian",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  In this paper we prove in detail a criterion for an algebraic continued
fraction to have a proper palindromic symmetry in dimension $4$. We also
present a new proof of the criterion for an algebraic continued fraction to
have a proper cyclic palindromic symmetry in dimension $4$. As a
multidimensional generalization of continued fractions, we consider Klein
polyhedra.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 10:28:04 GMT""}]","2022-12-12"
"2212.04759","Yuan-Ming Hsu","Yuan-Ming Hsu, Hiroyuki Hirashita, Yen-Hsing Lin, Peter Camps and
  Maarten Baes","Effects of dust sources on dust attenuation properties in IllustrisTNG
  galaxies at $z\sim 7$","11 pages, 6 figures, accepted for publication in MNRAS",,"10.1093/mnras/stac3666",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dust emission from high-redshift galaxies gives us a clue to the origin and
evolution of dust in the early Universe. Previous studies have shown that
different sources of dust (stellar dust production and dust growth in dense
clouds) predict different ultraviolet (UV) extinction curves for galaxies at
$z\sim 7$ but that the observed attenuation curves depend strongly on the
geometry of dust and star distributions. Thus, we perform radiative transfer
calculations under the dust-stars geometries computed by a cosmological
hydrodynamic simulation (IllustrisTNG). This serves to investigate the dust
attenuation curves predicted from `realistic' geometries. We choose objects
with stellar mass and star formation rate appropriate for Lyman break galaxies
at $z\sim 7$. We find that the attenuation curves are very different from the
original extinction curves in most of the galaxies. This makes it difficult to
constrain the dominant dust sources from the observed attenuation curves. We
further include infrared dust emission in the analysis and plot the infrared
excess (IRX)-UV spectral slope ($\beta$) diagram. We find that different
sources of dust cause different IRX-$\beta$ relations for the simulated
galaxies. In particular, if dust growth is the main source of dust, a variation
of dust-to-metal ratio causes a more extended sequence with smaller IRX in the
IRX-$\beta$ diagram. Thus, the comprehensive analysis of the abundances of dust
and metals, the UV slope, and the dust emission could provide a clue to the
dominant dust sources in the Universe.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 10:28:59 GMT""}]","2022-12-28"
"2212.04760","Jernej Kamenik","Blaz Bortolato, Jernej F. Kamenik and Michele Tammaro","Learning the Composition of Ultra High Energy Cosmic Rays","28 pages + 16 page Appendix, 27 figures",,,,"astro-ph.HE hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We apply statistical inference on the Pierre Auger Open Data to discern for
the first time the full mass composition of cosmic rays at different energies.
Working with longitudinal electromagnetic profiles of cosmic ray showers, in
particular their peaking depths $X_{\rm max}$, we employ central moments of the
$X_{\rm max}$ distributions as features to discriminate between different
shower compositions. We find that already the first few moments entail the most
relevant information to infer the primary cosmic ray mass spectrum. Our
approach, based on an unbinned likelihood, allows us to consistently account
for sources of statistical uncertainties due to finite datasets, both measured
and simulated, as well as systematic effects. Finally, we provide a
quantitative comparison of different high energy hadronic interaction models
available in the atmospheric shower simulation codes.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 10:32:20 GMT""}]","2022-12-12"
"2212.04761","Jungho Lee","Jungho Lee, Minhyeok Lee, Suhwan Cho, Sungmin Woo, and Sangyoun Lee","Leveraging Spatio-Temporal Dependency for Skeleton-Based Action
  Recognition","12 pages, 5 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Skeleton-based action recognition has attracted considerable attention due to
its compact skeletal structure of the human body. Many recent methods have
achieved remarkable performance using graph convolutional networks (GCNs) and
convolutional neural networks (CNNs), which extract spatial and temporal
features, respectively. Although spatial and temporal dependencies in the human
skeleton have been explored, spatio-temporal dependency is rarely considered.
In this paper, we propose the Inter-Frame Curve Network (IFC-Net) to
effectively leverage the spatio-temporal dependency of the human skeleton. Our
proposed network consists of two novel elements: 1) The Inter-Frame Curve (IFC)
module; and 2) Dilated Graph Convolution (D-GC). The IFC module increases the
spatio-temporal receptive field by identifying meaningful node connections
between every adjacent frame and generating spatio-temporal curves based on the
identified node connections. The D-GC allows the network to have a large
spatial receptive field, which specifically focuses on the spatial domain. The
kernels of D-GC are computed from the given adjacency matrices of the graph and
reflect large receptive field in a way similar to the dilated CNNs. Our IFC-Net
combines these two modules and achieves state-of-the-art performance on three
skeleton-based action recognition benchmarks: NTU-RGB+D 60, NTU-RGB+D 120, and
Northwestern-UCLA.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 10:37:22 GMT""}]","2022-12-12"
"2212.04762","Neil Parkin Mr","Neil Parkin, Sophie Minoughan, Md Asif Iqbal","Effective, Practical PON Monitoring Beyond the Splitter",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Monitoring beyond the splitter in a PON is costly due to the need for
additional hardware. A non-standard monitoring wavelength can reduce cost and
increase the visibility of customers to 97% on a C+ GPON
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 10:37:57 GMT""}]","2022-12-12"
"2212.04763","Banibrata Mukhopadhyay","Achal Kumar, Banibrata Mukhopadhyay","Covariant formalism for the Berry connection due to gravity","6 pages; published in Scientific Voyage","Scientific Voyage 3 (2022) 19",,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is well-known that Dirac particles gain geometric phase, namely Berry
phase, while moving in an electromagnetic field. Researchers have already shown
covariant formalism for the Berry connection due to an electromagnetic field. A
similar effect is expected to happen due to the presence of Gravity. We use WKB
approximation to develop a covariant formalism of Berry-like connection in the
presence of Einstein gravity, which can be further used to describe the
Berry-like phase or simply Berry phase. We also extend this formalism for
massless Dirac particles (Weyl particles).Then we further show that this
connection can be split into two parts, one of which vanishes when the metric
is spherically symmetric and thus can be linked to the Aharonov-Bohm-like
effect in the 3 + 1 formalism. At the same time, the other term can be related
to the Pancharatnam-Berry like effect.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 10:39:04 GMT""}]","2022-12-12"
"2212.04764","Mingze Sun","Mingze Sun, Haoxiang Wang, Wei Yao, Jiawang Liu","AuE-IPA: An AU Engagement Based Infant Pain Assessment Method",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Recent studies have found that pain in infancy has a significant impact on
infant development, including psychological problems, possible brain injury,
and pain sensitivity in adulthood. However, due to the lack of specialists and
the fact that infants are unable to express verbally their experience of pain,
it is difficult to assess infant pain. Most existing infant pain assessment
systems directly apply adult methods to infants ignoring the differences
between infant expressions and adult expressions. Meanwhile, as the study of
facial action coding system continues to advance, the use of action units (AUs)
opens up new possibilities for expression recognition and pain assessment. In
this paper, a novel AuE-IPA method is proposed for assessing infant pain by
leveraging different engagement levels of AUs. First, different engagement
levels of AUs in infant pain are revealed, by analyzing the class activation
map of an end-to-end pain assessment model. The intensities of top-engaged AUs
are then used in a regression model for achieving automatic infant pain
assessment. The model proposed is trained and experimented on YouTube
Immunization dataset, YouTube Blood Test dataset, and iCOPEVid dataset. The
experimental results show that our AuE-IPA method is more applicable to infants
and possesses stronger generalization ability than end-to-end assessment model
and the classic PSPI metric.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 10:41:22 GMT""}]","2022-12-12"
"2212.04765","Giona Casiraghi","Giuseppe Russo and Manoel Horta Ribeiro and Giona Casiraghi and Luca
  Verginer","Understanding Online Migration Decisions Following the Banning of
  Radical Communities","19 pages, 3 figures, 3 tables",,,,"cs.SI cs.CL physics.soc-ph stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The proliferation of radical online communities and their violent offshoots
has sparked great societal concern. However, the current practice of banning
such communities from mainstream platforms has unintended consequences: (I) the
further radicalization of their members in fringe platforms where they migrate;
and (ii) the spillover of harmful content from fringe back onto mainstream
platforms. Here, in a large observational study on two banned subreddits,
r/The\_Donald and r/fatpeoplehate, we examine how factors associated with the
RECRO radicalization framework relate to users' migration decisions.
Specifically, we quantify how these factors affect users' decisions to post on
fringe platforms and, for those who do, whether they continue posting on the
mainstream platform. Our results show that individual-level factors, those
relating to the behavior of users, are associated with the decision to post on
the fringe platform. Whereas social-level factors, users' connection with the
radical community, only affect the propensity to be coactive on both platforms.
Overall, our findings pave the way for evidence-based moderation policies, as
the decisions to migrate and remain coactive amplify unintended consequences of
community bans.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 10:43:15 GMT""}]","2022-12-12"
"2212.04766","Jean-Christophe  Breton","Jean-Christophe Breton and Nicolas Privault","Wasserstein distance estimates for jump-diffusion processes",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We derive Wasserstein distance bounds between the probability distributions
of a stochastic integral (It\^o) process with jumps $(X_t)_{t\in [0,T]}$ and a
jump-diffusion process $(X^\ast_t)_{t\in [0,T]}$. Our bounds are expressed
using the stochastic characteristics of $(X_t)_{t\in [0,T]}$ and the
jump-diffusion coefficients of $(X^\ast_t)_{t\in [0,T]}$ evaluated in $X_t$,
and apply in particular to the case of different jump characteristics. Our
approach uses stochastic calculus arguments and $L^p$ integrability results for
the flow of stochastic differential equations with jumps, without relying on
the Stein equation.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 10:44:03 GMT""}]","2022-12-12"
"2212.04767","Yanjun Chen","Y. G. Peng, J. Y. Che, C. Chen, G. G. Xin, and Y. J. Chen","Coulomb scattering inducing time lag in strong-field tunneling
  ionization","5 pages, 4 figures",,,,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study ionization of atoms in strong elliptically-polarized laser fields.
We focus on the physical origin of the offset angle in the photoelectron
momentum distribution and its possible relation to a specific time. By
developing a model which is based on strong-field approximation and considers
the classical Coulomb scattering, we are able to quantitatively explain recent
attoclock experiments in a wide region of laser and atomic parameters. The
offset angle can be understood as arising from the scattering of the electron
by the ionic potential when the electron exits the laser-Coulomb-formed barrier
through tunneling. The scattering time is manifested as the Coulomb-induced
ionization time lag and is encoded in the offset angle.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 10:44:08 GMT""}]","2022-12-12"
"2212.04768","Banan Kerdi","Banan El-Kerdi, Andr\'e Thiaville, Stanislas Rohart, Sujit Panigrahy,
  Nuno Br\'as, Jo\~ao Sampaio and Alexandra Mougin","Evidence of Strong Dzyaloshinskii-Moriya Interaction at the
  Cobalt/Hexagonal Boron Nitride Interface",,"Nano Lett. 2023, 23, 8, 3202-3208","10.1021/acs.nanolett.2c04985",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Dzyaloshinskii-Moriya interaction (DMI) and perpendicular magnetic
anisotropy (PMA) were measured on four series of Co films (1-2.2 nm thick)
grown on Pt or Au and covered with h-BN or Cu. Clean h-BN/Co interfaces were
obtained by exfoliating h-BN and transferring it onto the Co film in situ in
the ultra-high-vacuum evaporation chamber. By comparing h-BN and Cu-covered
samples, the DMI induced by the Co/h-BN interface was extracted and found to be
comparable in strength to that of the Pt/Co interface, one of the largest known
values. The strong observed DMI despite the weak spin-orbit interaction in h-BN
supports a Rashba-like origin in agreement with recent theoretical results.
Upon combination of it with Pt/Co in Pt/Co/h-BN heterostructures, even stronger
PMA and DMI are found which stabilizes skyrmions at room temperature and a low
magnetic field.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 10:44:45 GMT""},{""version"":""v2"",""created"":""Mon, 15 May 2023 13:39:39 GMT""}]","2023-05-16"
"2212.04769","Christian Birchler","Christian Birchler, Sajad Khatiri, Bill Bosshard, Alessio Gambi,
  Sebastiano Panichella","Machine Learning-based Test Selection for Simulation-based Testing of
  Self-driving Cars Software","arXiv admin note: substantial text overlap with arXiv:2111.04666",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Simulation platforms facilitate the development of emerging Cyber-Physical
Systems (CPS) like self-driving cars (SDC) because they are more efficient and
less dangerous than field operational test cases. Despite this, thoroughly
testing SDCs in simulated environments remains challenging because SDCs must be
tested in a sheer amount of long-running test cases. Past results on software
testing optimization have shown that not all the test cases contribute equally
to establishing confidence in test subjects' quality and reliability, and the
execution of ""safe and uninformative"" test cases can be skipped to reduce
testing effort. However, this problem is only partially addressed in the
context of SDC simulation platforms. In this paper, we investigate test
selection strategies to increase the cost-effectiveness of simulation-based
testing in the context of SDCs. We propose an approach called SDC-Scissor (SDC
coSt-effeCtIve teSt SelectOR) that leverages Machine Learning (ML) strategies
to identify and skip test cases that are unlikely to detect faults in SDCs
before executing them.
  Our evaluation shows that SDC-Scissor outperforms the baselines. With the
Logistic model, we achieve an accuracy of 70%, a precision of 65%, and a recall
of 80% in selecting tests leading to a fault and improved testing
cost-effectiveness. Specifically, SDC-Scissor avoided the execution of 50% of
unnecessary tests as well as outperformed two baseline strategies.
Complementary to existing work, we also integrated SDC-Scissor into the context
of an industrial organization in the automotive domain to demonstrate how it
can be used in industrial settings.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 10:46:19 GMT""}]","2022-12-12"
"2212.04770","Johanna Wydra","Johanna Wydra (1), Alexander Marsteller (1 and 2), Robin Gr\""o{\ss}le
  (1), Florian Priester (1), Michael Sturm (1) ((1) Institute for Astroparticle
  Physics, Tritium Laboratory Karlsruhe (IAP-TLK) - Karslruhe Institute for
  Technology (KIT), (2) Center for Experimental Nuclear Physics and
  Astrophysics, Department of Physics, University of Washington (UW))","ViMA -- the spinning rotor gauge to measure the viscosity of tritium
  between 77 and 300 K","11 pages, 3 figures, Tritium Conference 2022",,,,"physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  Experimental values for the viscosity of the radioactive hydrogen isotope
tritium (T$_2$) are currently unavailable in literature. The value of this
material property over a wide temperature range is of interest for applications
in the field of fusion, neutrino physics, as well as to test ab initio
calculations. As a radioactive gas, tritium requires careful experiment design
to ensure safe and environmental contamination free measurements. In this
contribution, we present a spinning rotor gauge based, tritium compatible
design of a gas viscosity measurement apparatus (ViMA) capable of covering the
temperature range from 80 K to 300 K.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 10:46:58 GMT""}]","2022-12-12"
"2212.04771","Chenle Yu","Chenle Yu, Sara Royuela, Eduardo Qui\~nones","Taskgraph: A Low Contention OpenMP Tasking Framework",,,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  OpenMP is the de-facto standard for shared memory systems in High-Performance
Computing (HPC). It includes a task-based model that offers a high-level of
abstraction to effectively exploit highly dynamic structured and unstructured
parallelism in an easy and flexible way. Unfortunately, the run-time overheads
introduced to manage tasks are (very) high in most common OpenMP frameworks
(e.g., GCC, LLVM), which defeats the potential benefits of the tasking model,
and makes it suitable for coarse-grained tasks only. This paper presents
taskgraph, a framework that uses a task dependency graph (TDG) to represent a
region of code implemented with OpenMP tasks in order to reduce the run-time
overheads associated with the management of tasks, i.e., contention and
parallel orchestration, including task creation and synchronization. The TDG
avoids the overheads related to the resolution of task dependencies and greatly
reduces those deriving from the accesses to shared resources. Moreover, the
taskgraph framework introduces in OpenMP the record-and-replay execution model
that accelerates the taskgraph region from its second execution. Overall, the
multiple optimizations presented in this paper allow exploiting fine-grained
OpenMP tasks to cope with the trend in current applications pointing to
leverage massive on-node parallelism, fine-grained and dynamic scheduling
paradigms. The framework is implemented on LLVM 15.0. Results show that the
taskgraph implementation outperforms the vanilla OpenMP system in terms of
performance and scalability, for all structured and unstructured parallelism,
and considering coarse and fine grained tasks. Furthermore, the proposed
framework considerably reduces the performance gap between the task and the
thread models of OpenMP.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 10:50:02 GMT""}]","2022-12-12"
"2212.04772","Sarah Haigh Prof","Xinyuan Li, Mengyao Su, Yi-Chi Wang, Meng Xu, Minman Tong, Sarah J.
  Haigh, Jiatao Zhang","Telluride nanocrystals with adjustable amorphous shell thickness and
  core-shell structure modulation by aqueous cation-exchange","15 pages, 5 figures, plus supplementary information","Inorganic Chemistry 61 (2022) 3989","10.1021/acs.inorgchem.1c03675",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Engineering the structure of core-shell colloidal semiconductor nanoparticles
(CSNPs) is attractive due to the potential to enhance photo-induced charge
transfer (PICT) and induce favourable optical and electronic properties.
Nonetheless, the sensitivity of telluride CSNPs to high temperatures makes it
challenging to precisely modulate their surface crystallinity. Herein, we have
developed an efficient strategy for synthesising telluride CSNPs with thin
amorphous shells using aqueous cation exchange (ACE). By changing the synthesis
temperature in the range 40 to 110C, the crystallinity of the CdTe
nanoparticles was controllable from perfect crystals with no detectable
amorphous shell (c-CdTe) to a core-shell structure with a crystalline CdTe NP
core covered by an amorphous shell of tunable thickness up to 7-8nm (c@a-CdTe)
. A second ACE step transformed the c@a-CdTe to crystalline CdTe@HgTe
core-shell NPs. The c@a-CdTe nanoparticles synthesized at 60C and having a 4-5
nm thick amorphous shell, exhibited the highest surface-enhanced Raman
scattering activity with a high enhancement factor around 8.82x10^5, attributed
to the coupling between the amorphous shell and the crystalline core.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 10:54:20 GMT""}]","2022-12-12"
"2212.04773","Joonas Tikkanen","Joonas Tikkanen, Stefanie Kirschenmann, Nikita Kramarenko, Erik
  Br\""ucken, Pirkitta Koponen, Panja Luukka, Teemu Siiskonen, Raimo Turpeinen,
  Jennifer Ott","Pixelated silicon detector for radiation beam profile measurements",,,,,"physics.ins-det physics.med-ph","http://creativecommons.org/licenses/by/4.0/","  A pixelated silicon detector, developed originally for particle physics
experiments, was used for a beam profile measurement of a Co-60 irradiator in a
water phantom. The beam profile was compared to a profile measured with a
pinpoint ionization chamber. The differences in the pixel detector and pinpoint
chamber relative profiles were within approximately 0.02, and after calculating
correction factors with Monte Carlo simulations for the pixel detector, the
differences were decreased to almost less than 0.005. The detector's capability
to measure pulse-height was used to record an electron pulse-height spectrum in
water in the Co-60 beam, and the results agreed well with simulations.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:02:49 GMT""}]","2022-12-12"
"2212.04774","Birgit Vogel-Heuser Prof. Dr.-Ing.","Frieder Loch, Gennadiy D. Koltun, Victoria Karaseva, Dorothea
  Pantfoerder and Birgit Vogel-Heuser","Model-based training of manual procedures in automated production
  systems","25 pages,
  https://www.sciencedirect.com/science/article/pii/S0957415818300801","Mechatronics 55 (2018) 2018","10.1016/j.mechatronics.2018.05.010",,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Maintenance engineers deal with increasingly complex automated production
systems (aPSs). Such systems are characterized by an increasing computerization
or the addition of robots that collaborate with human workers. The effects of
changing or replacing components of such systems are difficult to assess since
there are complex interdependencies between process parameters and the state of
the components. This paper proposes a model-based training system that
visualizes these interdependencies using domain-independent SysML models. The
training system consists of a virtual training system for initial training and
an online support system for assistance during maintenance or changeover
procedures. Both systems use structural SysML models to visualize the state of
the machine at a certain step of a procedure. An evaluation of the system in a
changeover procedure against a paper-based manual showed promising results
regarding effectiveness, usability and attractiveness.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:03:36 GMT""}]","2022-12-12"
"2212.04775","Edward Prabu Amaladass","Abhirami S., Edward Prabu Amaladass, Prashant Sharma, Vinod K.,
  Thanikaiarasu A.V., Awadhesh Mani","Current redistribution model of anomalous resistance behaviour in
  superconductor-topological insulator heterostructures","37 pages (including references), 17 figures",,,,"cond-mat.supr-con cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Anomalous resistance upturn and downturn have been observed on the
topological insulator (TI) surface in superconductor-TI (NbN-Bi1.95Sb0.05Se3)
heterostructures at ~ mm length scales away from the interface.
Magnetotransport measurements were performed to verify that the anomaly is
caused due to the superconducting transition of the NbN layer. The possibility
of long range superconducting proximity effect due to the spin-polarized TI
surface state was ruled out due to the observation of similar anomaly in NbN-Au
and NbN-Al heterostructures. It was discovered that the unusual resistance
jumps were caused due to current redistribution at the superconductor-TI
interface on account of the geometry effects. Results obtained from finite
element analysis using COMSOL package has validated the proposed current
redistribution (CRD) model of long range resistance anomalies in
superconductor-TI and superconductor-metal heterostructures.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:07:23 GMT""}]","2022-12-12"
"2212.04776","Suppanat Supanyo","Suppanat Supanyo, Monsit Tanasittikosol and Sikarin Yoo-Kong","Vacuum stability of phantom field from the nonuniqueness of Lagrangian",,,,,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  According to the nonuniqueness principle, the homogeneous scalar field
Lagrangian can be expressed in various forms both standard and nonstandard
ones. Therefore, the standard and all possible nonstandard Lagrangians can be
linearly combined while the Klein-Gordon equation is still intact. This linear
combination of Lagrangians is used to demonstrate that the energy density of
homogeneous phantom field can possibly be bounded from below. The applications
of this new Lagrangian in the nature of the ghost condensate and the equation
of state with $w<-1$ are discussed.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:15:41 GMT""}]","2022-12-12"
"2212.04777","ALICE Publications","ALICE Collaboration","Measurement of (anti)nuclei production in p-Pb collisions at
  $\sqrt{s_{\rm NN}} = 8.16$ TeV","20 pages, 4 captioned figures, 3 tables, submitted to PLB, figures at
  http://alice-publications.web.cern.ch/node/8796",,,"CERN-EP-2022-275","nucl-ex hep-ex","http://creativecommons.org/licenses/by/4.0/","  Measurements of (anti)proton, (anti)deuteron, and (anti)$^3$He production in
the rapidity range $-1<y< 0$ as a function of the transverse momentum and event
multiplicity in p-Pb collisions at a center-of-mass energy per nucleon-nucleon
pair $\sqrt{s_{\rm NN}} = 8.16$ TeV are presented. The coalescence parameters
$B_2$ and $B_3$, measured as a function of the transverse momentum per nucleon
and of the mean charged-particle multiplicity density, confirm a smooth
evolution from low to high multiplicity across different collision systems and
energies. The ratios between (anti)deuteron and (anti)$^3$He yields and those
of (anti)protons are also reported as a function of the mean charged-particle
multiplicity density. A comparison with the predictions of the statistical
hadronization and coalescence models for different collision systems and
center-of-mass energies favors the coalescence description for the
deuteron-to-proton yield ratio with respect to the canonical statistical model.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:16:03 GMT""}]","2022-12-12"
"2212.04778","Jie Mei","Jie Mei, Tao Xia and Shijun Mao","Mass spectra of neutral mesons $K_0,\ \pi_0,\ \eta,\ \eta'$ at finite
  magnetic field, temperature and baryon chemical potential","8 pages, 4 figures",,"10.1103/PhysRevD.107.074018",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  The mass spectra of neutral mesons $K_0, \pi_0, \eta, \eta'$ on
temperature-quark chemical potential $(T-\mu)$ plane in the presence of a
constant magnetic field is investigated in the $SU(3)$ NJL model. As a
Goldstone boson of chiral symmetry breaking, the mass of $K_0$ meson increases
with temperature and/or quark chemical potential, and we observe two kinds of
mass jumps of $K_0$ meson in media, which is induced by the mass jump of
constituent quarks and the magnetic field, respectively. Due to the breaking of
isospin symmetry between $u$ and $d$ quarks in magnetic fields, the mixing of
$\pi_0-\eta- \eta'$ mesons occurs and this leads to rich structures of their
mass spectra. For instance, $\pi_0$ mass is influenced by the strange quark.
There appear the change of increase ratio of $\pi_0$ mass at high $\mu$ and
vanishing $T$ and the $\pi_0$ mass jump crossing over the threshold of two
times of strange quark mass at finite $T$ and $\mu$. The mass ordering of
$\pi_0, \ \eta,\ \eta'$ mesons varies in media, due to their mass jumps, which
are induced by the mass jump of constituent quarks or the magnetic field.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:16:23 GMT""}]","2023-04-26"
"2212.04779","Giuseppina Barletta","Giuseppina Barletta","Existence and regularity results for nonlinear elliptic equations in
  Orlicz spaces",,,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We are concerned with the existence and regularity of the solutions to the
Dirichlet problem, for a class of quasilinear elliptic equations driven by a
general differential operator, depending on $(x,u,\nabla u)$, and with a
convective term $f$. The assumptions on the members of the equation are
formulated in terms of Young's functions, therefore we work in the
Orlicz-Sobolev spaces. After establishing some auxiliary properties, that seem
new in our context, we present two existence and two regularity results. We
conclude with several examples.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:18:01 GMT""},{""version"":""v2"",""created"":""Sun, 25 Dec 2022 18:56:05 GMT""}]","2022-12-27"
"2212.04780","Yongkweon Jeon","Yongkweon Jeon, Chungman Lee, Ho-young Kim","Genie: Show Me the Data for Quantization","Accepted by CVPR 2023",,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Zero-shot quantization is a promising approach for developing lightweight
deep neural networks when data is inaccessible owing to various reasons,
including cost and issues related to privacy. By exploiting the learned
parameters ($\mu$ and $\sigma$) of batch normalization layers in an
FP32-pre-trained model, zero-shot quantization schemes focus on generating
synthetic data. Subsequently, they distill knowledge from the pre-trained model
(teacher) to the quantized model (student) such that the quantized model can be
optimized with the synthetic dataset. However, thus far, zero-shot quantization
has primarily been discussed in the context of quantization-aware training
methods, which require task-specific losses and long-term optimization as much
as retraining. We thus introduce a post-training quantization scheme for
zero-shot quantization that produces high-quality quantized networks within a
few hours. Furthermore, we propose a framework called \genie~that generates
data suited for quantization. With the data synthesized by Genie, we can
produce robust quantized models without real datasets, which is comparable to
few-shot quantization. We also propose a post-training quantization algorithm
to enhance the performance of quantized models. By combining them, we can
bridge the gap between zero-shot and few-shot quantization while significantly
improving the quantization performance compared to that of existing approaches.
In other words, we can obtain a unique state-of-the-art zero-shot quantization
approach.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:18:40 GMT""},{""version"":""v2"",""created"":""Mon, 3 Apr 2023 08:21:02 GMT""}]","2023-04-04"
"2212.04781","Abhilash Hota","Abhilash Hota, Jurgen Schonwalder","A Bayesian Model Combination-based approach to Active Malware Analysis",,,"10.1109/CSR54599.2022.9850338",,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  Active Malware Analysis involves modeling malware behavior by executing
actions to trigger responses and explore multiple execution paths. One of the
aims is making the action selection more efficient. This paper treats Active
Malware Analysis as a Bayes-Active Markov Decision Process and uses a Bayesian
Model Combination approach to train an analyzer agent. We show an improvement
in performance against other Bayesian and stochastic approaches to Active
Malware Analysis.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:19:11 GMT""}]","2022-12-12"
"2212.04782","Ali Can Karaca Dr","Ramiz Mammadli, Huma Bilgin, and Ali Can Karaca","Music Recommendation System based on Emotion, Age and Ethnicity","14 Pages, 10 Figures and 3 Tables",,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  A Music Recommendation System based on Emotion, Age, and Ethnicity is
developed in this study, using FER-2013 and ``Age, Gender, and Ethnicity (Face
Data) CSV'' datasets. The CNN architecture, which is extensively used for this
kind of purpose has been applied to the training of the models. After adding
several appropriate layers to the training end of the project, in total, 3
separate models are trained in the Deep Learning side of the project: Emotion,
Ethnicity, and Age. After the training step of these models, they are used as
classifiers on the web application side. The snapshot of the user taken through
the interface is sent to the models to predict their mood, age, and ethnic
origin. According to these classifiers, various kinds of playlists pulled from
Spotify API are proposed to the user in order to establish a functional and
user-friendly atmosphere for the music selection. Afterward, the user can
choose the playlist they want and listen to it by following the given link.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:23:39 GMT""}]","2022-12-12"
"2212.04783","Nathan Moynihan","Mariana Carrillo Gonz\'alez, William T. Emond, Nathan Moynihan,
  Justinas Rumbutis and Chris D. White","Mini-twistors and the Cotton Double Copy",,,,,"hep-th","http://creativecommons.org/licenses/by/4.0/","  The double copy relates quantities in gauge, gravity and related theories. A
well-known procedure for relating exact classical solutions is the Weyl double
copy in four spacetime dimensions, and a three-dimensional analogue of this --
the Cotton double copy -- has recently been found for topologically massive
gauge theory and gravity. In this paper, we use twistor methods to provide a
derivation of the position-space Cotton double copy, where this is seen to
arise from combining appropriate data in so-called minitwistor space. Our
methods rely on a massive generalisation of the Penrose transform linking
spacetime fields with cohomology classes in minitwistor space. We identify the
relevant transform from the twistor literature, but also show that it naturally
arises from considering scattering amplitudes in momentum space. We show that
the Cotton double copy in position space is only valid for type N solutions,
but that a simple twistor space double copy is possible for non-type N
solutions, where we use anyons to illustrate our arguments.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:24:20 GMT""}]","2022-12-12"
"2212.04784","Daniel Milne","Valentin V. Khoze, Daniel L. Milne","Gravitational waves and dark matter from classical scale invariance","v2: Minor changes, matches version accepted for publication in PRD",,"10.1103/PhysRevD.107.095012",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  In this paper we consider a minimal classically conformal U(1) model of
fermionic dark matter. We calculate the one loop effective potential which
generates the mass scale quantum mechanically via dimensional transmutaion in
the spirit of Gildener and Weinberg, and examine the effects of the new dark
sector on the Standard Model Higgs as well as how the dark fermions receive a
mass and can produce the observed relic abundance. We then consider constraints
on the model coming from collider and direct detection experiments before
calculating the thermal effects on the potential in the early universe. We
examine the nature and conditions for a strongly first order phase transition
in our model and calculate the associated gravitational wave signal and compare
to the sensitivities of current and proposed experiments.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:28:01 GMT""},{""version"":""v2"",""created"":""Thu, 4 May 2023 09:35:34 GMT""}]","2023-05-17"
"2212.04785","Shu Chen","Zhen-Yu Zheng, Xueliang Wang, Shu Chen","Exact Solution of boundary-dissipated transverse field Ising model:
  structure of Liouvillian spectrum and dynamical duality","6 pages, 4 figures",,,,"quant-ph cond-mat.other","http://creativecommons.org/licenses/by/4.0/","  We study the boundary-dissipated transverse field Ising model described by a
Lindblad Master equation and exactly solve its Liouvillian spectrum in the
whole parameter space. By mapping the Liouvillian into a Su-Schrieffer-Heeger
model with imaginary boundary potentials under a parity constraint, we solve
the rapidity spectrum analytically and thus construct the Liouvillian spectrum
strictly with a parity constraint condition. Our results demonstrate that the
Liouvillian spectrum displays four different structures, which are
characterized by different numbers of segments. By analyzing the properties of
rapidity spectrum, we can determine the phase boundaries between different
spectrum structures analytically and prove the Liouvillian gap fulfilling a
duality relation in the weak and strong dissipation region. Furthermore, we
unveil the existence of a dynamical duality, i.e., the long-time relaxation
dynamics exhibits almost the same dynamical behavior in the weak and strong
dissipation region as long as the duality relation holds true.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:30:36 GMT""}]","2022-12-12"
"2212.04786","Fernando Alonso-Fernandez","Otto Zell, Joel P{\aa}lsson, Kevin Hernandez-Diaz, Fernando
  Alonso-Fernandez, Felix Nilsson","Image-Based Fire Detection in Industrial Environments with YOLOv4","Accepted for publication at ICPRAM",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fires have destructive power when they break out and affect their
surroundings on a devastatingly large scale. The best way to minimize their
damage is to detect the fire as quickly as possible before it has a chance to
grow. Accordingly, this work looks into the potential of AI to detect and
recognize fires and reduce detection time using object detection on an image
stream. Object detection has made giant leaps in speed and accuracy over the
last six years, making real-time detection feasible. To our end, we collected
and labeled appropriate data from several public sources, which have been used
to train and evaluate several models based on the popular YOLOv4 object
detector. Our focus, driven by a collaborating industrial partner, is to
implement our system in an industrial warehouse setting, which is characterized
by high ceilings. A drawback of traditional smoke detectors in this setup is
that the smoke has to rise to a sufficient height. The AI models brought
forward in this research managed to outperform these detectors by a significant
amount of time, providing precious anticipation that could help to minimize the
effects of fires further.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:32:36 GMT""}]","2022-12-12"
"2212.04787","Roland Ketzmerick","Roland Ketzmerick and Jan Robert Schmidt","Resonance states at Casati wave numbers for the 3-disk billiard","On the occasion of the 80th birthday of Giulio Casati, 3 pages, 3
  figures",,,,"nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Resonance states of the 3-disk scattering system are presented for the first
Casati wave number $k \approx 912$ and the second Casati wave number $k \approx
91242$. They show multifractal structure in phase space, similar to the
pioneering work by Casati et al. [Physica D 131, 311 (1999)] for an open
chaotic quantum map. In position space we observe scarring along segments of
rays, related to multifractality and universal fluctuations, as recently found
for dielectric cavities. To the best of our knowledge this resonance state at
the second Casati wave number has a much larger wave number than published
resonance states for the 3-disk scattering system or any other open or closed
chaotic billiard.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:40:40 GMT""}]","2022-12-12"
"2212.04788","Ulrik Kowalk","Ulrik Kowalk, Simon Doclo, Joerg Bitzer","Geometry-aware DoA Estimation using a Deep Neural Network with
  mixed-data input features","Submitted to ICASSP 2023",,,,"eess.AS eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unlike model-based direction of arrival (DoA) estimation algorithms,
supervised learning-based DoA estimation algorithms based on deep neural
networks (DNNs) are usually trained for one specific microphone array geometry,
resulting in poor performance when applied to a different array geometry. In
this paper we illustrate the fundamental difference between supervised
learning-based and model-based algorithms leading to this sensitivity. Aiming
at designing a supervised learning-based DoA estimation algorithm that
generalizes well to different array geometries, in this paper we propose a
geometry-aware DoA estimation algorithm. The algorithm uses a fully connected
DNN and takes mixed data as input features, namely the time lags maximizing the
generalized cross-correlation with phase transform and the microphone
coordinates, which are assumed to be known. Experimental results for a
reverberant scenario demonstrate the flexibility of the proposed algorithm
towards different array geometries and show that the proposed algorithm
outperforms model-based algorithms such as steered response power with phase
transform.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:41:16 GMT""}]","2022-12-12"
"2212.04789","Luca Mariot","Marko Djurasevic, Domagoj Jakobovic, Luca Mariot, Sihem Mesnager,
  Stjepan Picek","On the Evolution of Boomerang Uniformity in Cryptographic S-boxes","15 pages, 3 figures, 4 tables",,,,"cs.NE cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  S-boxes are an important primitive that help cryptographic algorithms to be
resilient against various attacks. The resilience against specific attacks can
be connected with a certain property of an S-box, and the better the property
value, the more secure the algorithm. One example of such a property is called
boomerang uniformity, which helps to be resilient against boomerang attacks.
How to construct S-boxes with good boomerang uniformity is not always clear.
There are algebraic techniques that can result in good boomerang uniformity,
but the results are still rare. In this work, we explore the evolution of
S-boxes with good values of boomerang uniformity. We consider three different
encodings and five S-box sizes. For sizes $4\times 4$ and $5\times 5$, we
manage to obtain optimal solutions. For $6\times 6$, we obtain optimal
boomerang uniformity for the non-APN function. For larger sizes, the results
indicate the problem to be very difficult (even more difficult than evolving
differential uniformity, which can be considered a well-researched problem).
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:41:22 GMT""}]","2022-12-12"
"2212.04790","Fernando Alonso-Fernandez","August Baaz, Yonan Yonan, Kevin Hernandez-Diaz, Fernando
  Alonso-Fernandez, Felix Nilsson","Synthetic Data for Object Classification in Industrial Applications","Accepted for publication at ICPRAM",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the biggest challenges in machine learning is data collection.
Training data is an important part since it determines how the model will
behave. In object classification, capturing a large number of images per object
and in different conditions is not always possible and can be very
time-consuming and tedious. Accordingly, this work explores the creation of
artificial images using a game engine to cope with limited data in the training
dataset. We combine real and synthetic data to train the object classification
engine, a strategy that has shown to be beneficial to increase confidence in
the decisions made by the classifier, which is often critical in industrial
setups. To combine real and synthetic data, we first train the classifier on a
massive amount of synthetic data, and then we fine-tune it on real images.
Another important result is that the amount of real images needed for
fine-tuning is not very high, reaching top accuracy with just 12 or 24 images
per class. This substantially reduces the requirements of capturing a great
amount of real data.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:43:04 GMT""}]","2022-12-12"
"2212.04791","Qing Tang","Qing Tang, Jiahao Song","Learning optimal policies in potential Mean Field Games: Smoothed Policy
  Iteration algorithms",,,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  We introduce two Smoothed Policy Iteration algorithms (\textbf{SPI}s) as
rules for learning policies and methods for computing Nash equilibria in second
order potential Mean Field Games (MFGs). Global convergence is proved if the
coupling term in the MFG system satisfy the Lasry Lions monotonicity condition.
Local convergence to a stable solution is proved for system which may have
multiple solutions. The convergence analysis shows close connections between
\textbf{SPI}s and the Fictitious Play algorithm, which has been widely studied
in the MFG literature. Numerical simulation results based on finite difference
schemes are presented to supplement the theoretical analysis.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:44:05 GMT""},{""version"":""v2"",""created"":""Mon, 17 Apr 2023 06:56:03 GMT""}]","2023-04-18"
"2212.04792","David Andrade","Michael Stiassnie and David Andrade","A theoretical study of the air-sea drag-saturation in very strong winds",,,,,"physics.flu-dyn physics.ao-ph physics.geo-ph","http://creativecommons.org/licenses/by/4.0/","  The goal of this note is to provide a theoretical explanation for the
saturation of the drag coefficient in strong wind conditions. The hydrodynamic
model under consideration takes into account the important effects of airborne
droplets of water in a thin layer above the water surface that effectively
behave as a different fluid between the water and the air. Above this layer the
model is coupled with a log-wind profile for the strong winds blowing above the
sea. The main underlying mechanism governing the behavior of the drag
coefficient is the Kelvin Helmholtz instability for capillary waves on the
water surface and the continuity of shear stress along the intermediate
interface.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:48:56 GMT""}]","2022-12-12"
"2212.04793","J\""orn Schwandt","The Tracker Group of the CMS Collaboration","Evaluation of HPK $n^+$-$p$ planar pixel sensors for the CMS Phase-2
  upgrade",,,,,"physics.ins-det","http://creativecommons.org/licenses/by-nc-nd/4.0/","  To cope with the challenging environment of the planned high luminosity
upgrade of the Large Hadron Collider (HL-LHC), scheduled to start operation in
2029, CMS will replace its entire tracking system. The requirements for the
tracker are largely determined by the long operation time of 10 years with an
instantaneous peak luminosity of up to $7.5\times 10^{34}$ cm$^{-2}$s$^{-1}$ in
the ultimate performance scenario. Depending on the radial distance from the
interaction point, the silicon sensors will receive a particle fluence
corresponding to a non-ionizing energy loss of up to $\Phi_{\text{eq}} =
3.5\times 10^{16}$ cm$^{-2}$ . This paper focuses on planar pixel sensor design
and qualification up to a fluence of $\Phi_{\text{eq}} = 1.4\times 10^{16}$
cm$^{-2}$.
  For the development of appropriate planar pixel sensors an R\&D program was
initiated, which includes $n^+$-$p$ sensors on 150 mm (6'') wafers with an
active thickness of 150 $\mu m$ with pixel sizes of $100\times 25$ $\mu m^2$
and $50\times 50$ $\mu m^2$ manufactured by Hamamatsu. Single chip modules with
ROC4Sens and RD53A readout chips were made. Irradiation with protons and
neutrons, as well was an extensive test beam campaign at DESY were carried out.
This paper presents the investigation of various assemblies mainly with
ROC4Sens readout chips. It demonstrates that multiple designs fulfill the
requirements in terms of breakdown voltage, leakage current and efficiency. The
single point resolution for $50\times 50$ $\mu m^2$ pixels is measured as 4.0
$\mu m$ for non-irradiated samples, and 6.3 $\mu m$ after irradiation to
$\Phi_{\text{eq}} = 7.2\times 10^{15}$ cm$^{-2}$.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:49:09 GMT""}]","2022-12-12"
"2212.04794","Fernando Alonso-Fernandez","Jonathan Karlsson, Fredrik Strand, Josef Bigun, Fernando
  Alonso-Fernandez, Kevin Hernandez-Diaz, Felix Nilsson","Visual Detection of Personal Protective Equipment and Safety Gear on
  Industry Workers","Accepted for publication at ICPRAM",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Workplace injuries are common in today's society due to a lack of adequately
worn safety equipment. A system that only admits appropriately equipped
personnel can be created to improve working conditions. The goal is thus to
develop a system that will improve workers' safety using a camera that will
detect the usage of Personal Protective Equipment (PPE). To this end, we
collected and labeled appropriate data from several public sources, which have
been used to train and evaluate several models based on the popular YOLOv4
object detector. Our focus, driven by a collaborating industrial partner, is to
implement our system into an entry control point where workers must present
themselves to obtain access to a restricted area. Combined with facial identity
recognition, the system would ensure that only authorized people wearing
appropriate equipment are granted access. A novelty of this work is that we
increase the number of classes to five objects (hardhat, safety vest, safety
gloves, safety glasses, and hearing protection), whereas most existing works
only focus on one or two classes, usually hardhats or vests. The AI model
developed provides good detection accuracy at a distance of 3 and 5 meters in
the collaborative environment where we aim at operating (mAP of 99/89%,
respectively). The small size of some objects or the potential occlusion by
body parts have been identified as potential factors that are detrimental to
accuracy, which we have counteracted via data augmentation and cropping of the
body before applying PPE detection.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:50:03 GMT""}]","2022-12-12"
"2212.04795","Steven D. Bass","Steven D. Bass, Paolo Pedroni, Andreas Thomas","The Gerasimov-Drell-Hearn sum-rule with nuclear targets","5 pages",,,,"nucl-th hep-ph nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hadron properties are modified when the hadron is embedded in a nuclear
medium. Here we discuss the Gerasimov-Drell-Hearn, GDH, sum-rule for polarised
photoproduction from a polarised nucleon within a polarised nuclear target.
Strong enhancement is expected with the suppression of the proton and nucleon
resonance masses and enhancement of the proton's anomalous magnetic moment in
medium. This could be tested in polarised photoproduction experiments with
interesting targets being polarised deuterons, $^3$He, $^6$Li and $^7$Li. In
existing data with polarised deuterons and $^3$He the $\Delta$ resonance
excitation is shifted to slightly lower energy when compared to model
predictions where the $\Delta$ is treated with its free mass, consistent with
an enhancement in the GDH sum-rule.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:50:31 GMT""}]","2022-12-12"
"2212.04796","Cornel Marius Murea","Cornel Marius Murea and Dan Tiba","Penalization of stationary Navier-Stokes equations and applications",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the steady Navier-Stokes system with mixed boundary conditions,
in subdomains of a holdall domain. We study, via the penalization method, its
approximation properties. Error estimates and the uniqueness of the solution,
obtained in a non standard manner, are also discussed. Numerical tests,
including topological optimization applications, are presented.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:57:29 GMT""}]","2022-12-12"
"2212.04797","Valentina Masarotto","Valentina Masarotto, Victor M. Panaretos and Yoav Zemel","Transportation-Based Functional ANOVA and PCA for Covariance Operators","33 pages",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of comparing several samples of stochastic processes
with respect to their second-order structure, and describing the main modes of
variation in this second order structure, if present. These tasks can be seen
as an Analysis of Variance (ANOVA) and a Principal Component Analysis (PCA) of
covariance operators, respectively. They arise naturally in functional data
analysis, where several populations are to be contrasted relative to the nature
of their dispersion around their means, rather than relative to their means
themselves. We contribute a novel approach based on optimal (multi)transport,
where each covariance can be identified with a a centred Gaussian process of
corresponding covariance. By means of constructing the optimal simultaneous
coupling of these Gaussian processes, we contrast the (linear) maps that
achieve it with the identity with respect to a norm-induced distance. The
resulting test statistic, calibrated by permutation, is seen to distinctly
outperform the state-of-the-art, and to furnish considerable power even under
local alternatives. This effect is seen to be genuinely functional, and is
related to the potential for perfect discrimination in infinite dimensions. In
the event of a rejection of the null hypothesis stipulating equality, a
geometric interpretation of the transport maps allows us to construct a
(tangent space) PCA revealing the main modes of variation. As a necessary step
to developing our methodology, we prove results on the existence and
boundedness of optimal multitransport maps. These are of independent interest
in the theory of transport of Gaussian processes. The transportation ANOVA and
PCA are illustrated on a variety of simulated and real examples.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:59:16 GMT""}]","2022-12-12"
"2212.04798","Anders Hilmar Damm Andersen","Anders H. D. Andersen, Tobias K. S. Ritschel, Steen H{\o}rsholt, Jakob
  Kj{\o}bsted Huusom, John Bagterp J{\o}rgensen","Model-based control algorithms for the quadruple tank system: An
  experimental comparison","6 pages, 5 figures, 3 tables, to be published in Foundations of
  Computer Aided Process Operations / Chemical Process Control (FOCAPO/CPC
  2023). Hilton San Antonio Hill Country, San Antonio, Texas",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We compare the performance of proportional-integral-derivative (PID) control,
linear model predictive control (LMPC), and nonlinear model predictive control
(NMPC) for a physical setup of the quadruple tank system (QTS). We estimate the
parameters in a continuous-discrete time stochastic nonlinear model for the QTS
using a prediction-error-method based on the measured process data and a
maximum likelihood (ML) criterion. In the NMPC algorithm, we use this
identified continuous-discrete time stochastic nonlinear model. The LMPC
algorithm is based on a linearization of this nonlinear model. We tune the PID
controller using Skogestad's IMC tuning rules using a transfer function
representation of the linearized model. Norms of the observed tracking errors
and the rate of change of the manipulated variables are used to compare the
performance of the control algorithms. The LMPC and NMPC perform better than
the PID controller for a predefined time-varying setpoint trajectory. The LMPC
and NMPC algorithms have similar performance.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 12:01:57 GMT""}]","2022-12-12"
"2212.04799","Cuiling Fan","Li Xu, Cuiling Fan, Sihem Mesnager, Rong Luo, Haode Yan","Subfield Codes of Several Few-Weight Linear Codes Parametrized by
  Functions and Their Consequences","arXiv admin note: text overlap with arXiv:1804.06003,
  arXiv:2207.07262 by other authors",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Subfield codes of linear codes over finite fields have recently received much
attention. Some of these codes are optimal and have applications in secrete
sharing, authentication codes and association schemes. In this paper, the
$q$-ary subfield codes $C_{f,g}^{(q)}$ of six different families of linear
codes $C_{f,g}$ parametrized by two functions $f, g$ over a finite field
$F_{q^m}$ are considered and studied, respectively. The parameters and
(Hamming) weight distribution of $C_{f,g}^{(q)}$ and their punctured codes
$\bar{C}_{f,g}^{(q)}$ are explicitly determined. The parameters of the duals of
these codes are also analyzed. Some of the resultant $q$-ary codes
$C_{f,g}^{(q)},$ $\bar{C}_{f,g}^{(q)}$ and their dual codes are optimal and
some have the best known parameters. The parameters and weight enumerators of
the first two families of linear codes $C_{f,g}$ are also settled, among which
the first family is an optimal two-weight linear code meeting the Griesmer
bound, and the dual codes of these two families are almost MDS codes. As a
byproduct of this paper, a family of $[2^{4m-2},2m+1,2^{4m-3}]$ quaternary
Hermitian self-dual code are obtained with $m \geq 2$. As an application, we
show that three families of the derived linear codes give rise to several
infinite families of $t$-designs ($t \in \{2, 3\}$).
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 12:03:05 GMT""},{""version"":""v2"",""created"":""Tue, 7 Mar 2023 01:02:59 GMT""}]","2023-03-08"
"2212.04800","Wei Tan","Ngoc Dang Nguyen, Wei Tan, Wray Buntine, Richard Beare, Changyou Chen
  and Lan Du","AUC Maximization for Low-Resource Named Entity Recognition","10 pages, 4 figures, AAAI 2023",,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Current work in named entity recognition (NER) uses either cross entropy (CE)
or conditional random fields (CRF) as the objective/loss functions to optimize
the underlying NER model. Both of these traditional objective functions for the
NER problem generally produce adequate performance when the data distribution
is balanced and there are sufficient annotated training examples. But since NER
is inherently an imbalanced tagging problem, the model performance under the
low-resource settings could suffer using these standard objective functions.
Based on recent advances in area under the ROC curve (AUC) maximization, we
propose to optimize the NER model by maximizing the AUC score. We give evidence
that by simply combining two binary-classifiers that maximize the AUC score,
significant performance improvement over traditional loss functions is achieved
under low-resource NER settings. We also conduct extensive experiments to
demonstrate the advantages of our method under the low-resource and
highly-imbalanced data distribution settings. To the best of our knowledge,
this is the first work that brings AUC maximization to the NER setting.
Furthermore, we show that our method is agnostic to different types of NER
embeddings, models and domains. The code to replicate this work will be
provided upon request.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 12:06:15 GMT""},{""version"":""v2"",""created"":""Fri, 16 Dec 2022 09:47:43 GMT""},{""version"":""v3"",""created"":""Thu, 13 Apr 2023 18:52:56 GMT""}]","2023-04-17"
"2212.04801","Sankalpa Ghosh","Deepanshu Aggarwal, Rohit Narula, and Sankalpa Ghosh (Dept. of
  Physics, IIT Delhi)","A primer on twistronics: A massless Dirac fermion's journey to moir\'{e}
  patterns and flat bands in twisted bilayer graphene","To be published as topical review in Journal of Physics: Condensed
  Mater ( Accepted Manuscript is available online)","J. Phys.: Condens. Matter 35 143001 (2023)","10.1088/1361-648X/acb984",,"cond-mat.mes-hall cond-mat.str-el quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recent discovery of superconductivity in magic-angle twisted bilayer
graphene has sparked a renewed interest in the strongly-correlated physics of
$sp^2$ carbons, in stark contrast to preliminary investigations which were
dominated by the one-body physics of the massless Dirac fermions. We thus
provide a self-contained, theoretical perspective of the journey of graphene
from its single-particle physics-dominated regime to the strongly-correlated
physics of the flat bands. Beginning from the origin of the Dirac points in
condensed matter systems, we discuss the effect of the superlattice on the
Fermi velocity and Van Hove singularities in graphene and how it leads
naturally to investigations of the moir\'{e} pattern in van der Waals
heterostructures exemplified by graphene-hexagonal boron-nitride and twisted
bilayer graphene. Subsequently, we illuminate the origin of flat bands in
twisted bilayer graphene at the magic angles by elaborating on a broad range of
prominent theoretical works in a pedagogical way while linking them to
available experimental support, where appropriate. We conclude by providing a
list of topics in the study of the electronic properties of twisted bilayer
graphene not covered by this review but may readily be approached with the help
of this primer.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 12:09:46 GMT""},{""version"":""v2"",""created"":""Wed, 8 Feb 2023 13:33:21 GMT""}]","2023-02-17"
"2212.04802","\'Etienne Andr\'e","\'Etienne Andr\'e, Dylan Marinho, Laure Petrucci and Jaco van de Pol","Efficient Convex Zone Merging in Parametric Timed Automata","This is the author version of the manuscript of the same name
  published in the proceedings of the 20th International Conference on Formal
  Modeling and Analysis of Timed Systems (FORMATS 2022)","FORMATS'22, Springer LNCS 13465, pages 1-19, 2022","10.1007/978-3-031-15839-1_12",,"cs.FL cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Parametric timed automata are a powerful formalism for reasoning on
concurrent real-time systems with unknown or uncertain timing constants.
Reducing their state space is a significant way to reduce the inherently large
analysis times. We present here different merging reduction techniques based on
convex union of constraints (parametric zones), allowing to decrease the number
of states while preserving the correctness of verification and synthesis
results. We perform extensive experiments, and identify the best heuristics in
practice, bringing a significant decrease in the computation time on a
benchmarks library.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 12:10:28 GMT""}]","2022-12-12"
"2212.04803","Shien Li","Shien Li, Zefeng Lin, Wei Hu, Dayu Yan, Fucong Chen, Xinbo Bai, Beiyi
  Zhu, Jie Yuan, Youguo Shi, Kui Jin, Hongming Weng and Haizhong Guo","Exploration of growth conditions of TaAs Weyl semimetal thin film by
  pulsed laser deposition",,,"10.1088/1674-1056/acb913",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  TaAs, the first experimentally discovered Weyl semimetal material, has
attracted a lot of attention due to its high carrier mobility, high anisotropy,
nonmagnetic and strong interaction with light. These make it an ideal candidate
for the study of Weyl fermions and the applications in quantum computation,
thermoelectric devices, and photodetection. For further basic physics studies
and potential applications, large-size and high-quality TaAs films are urgently
needed. However, it is difficult to grow As-stoichiometry TaAs films due to the
volatilization of As during the growth. To solve this problem, the TaAs films
were attempted to grow on different substrates using targets with different As
stoichiometric ratios by pulsed laser deposition (PLD). In this work, we have
found that partial As ions of the GaAs substrate are likely to diffuse into the
TaAs films during growth, which was preliminarily confirmed by the structural
characterization, surface topography and composition analysis. As a result, the
As content in the TaAs film is improved and the TaAs phase is achieved. Our
work presents an effective method to fabricate the TaAs films by PLD, providing
the possible use of the Weyl semimetal film for functional devices.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 12:13:16 GMT""}]","2023-04-26"
"2212.04804","Markus Stricker","Markus Stricker and Lars Banko and Nik Sarazin and Niklas Siemer and
  J\""org Neugebauer and Alfred Ludwig","Computationally accelerated experimental materials characterization --
  drawing inspiration from high-throughput simulation workflows","17 pages, 4 figures, preprint",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Computational materials science is increasingly benefitting from data
management, automation, and algorithm-based decision-making in controlling
simulations. Experimental materials science is also undergoing a change and
increasingly more `machine learning' is incorporated in materials discovery
campaigns. The obvious benefits include automation, reproducibility, data
provenance, and reusability of managed data, however, is not widely available.
We demonstrate an implementation of a Gaussian Process Regression directly
controlling an experimental measurement device in pyiron, a framework designed
for high-throughput simulations, as a first step to increasingly combine
experimental and simulated data in one framework. With data from both in the
same framework, a heretofore untapped and much-needed potential for the
acceleration of materials characterization and materials discovery campaigns
becomes available.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 12:13:23 GMT""}]","2022-12-12"
"2212.04805","Dirk Witthaut","Julius Trebbien, Leonardo Rydin Gorj\~ao, Aaron Praktiknjo, Benjamin
  Sch\""afer, Dirk Witthaut","Understanding electricity prices beyond the merit order principle using
  explainable AI","13 pages, 6 figures",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Electricity prices in liberalized markets are determined by the supply and
demand for electric power, which are in turn driven by various external
influences that vary strongly in time. In perfect competition, the merit order
principle describes that dispatchable power plants enter the market in the
order of their marginal costs to meet the residual load, i.e. the difference of
load and renewable generation. Many market models implement this principle to
predict electricity prices but typically require certain assumptions and
simplifications. In this article, we present an explainable machine learning
model for the prices on the German day-ahead market, which substantially
outperforms a benchmark model based on the merit order principle. Our model is
designed for the ex-post analysis of prices and thus builds on various external
features. Using Shapley Additive exPlanation (SHAP) values, we can disentangle
the role of the different features and quantify their importance from empiric
data. Load, wind and solar generation are most important, as expected, but wind
power appears to affect prices stronger than solar power does. Fuel prices also
rank highly and show nontrivial dependencies, including strong interactions
with other features revealed by a SHAP interaction analysis. Large generation
ramps are correlated with high prices, again with strong feature interactions,
due to the limited flexibility of nuclear and lignite plants. Our results
further contribute to model development by providing quantitative insights
directly from data.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 12:18:17 GMT""}]","2022-12-12"
"2212.04806","Mengjie Zhao","Hongxia Guo, Guanghui Hu, Mengjie Zhao","Direct sampling method to inverse wave-number-dependent source problems
  (part I): determination of the support of a stationary source",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is concerned with a direct sampling method for imaging the support
of a frequency-dependent source term embedded in a homogeneous and isotropic
medium. The source term is given by the Fourier transform of a time-dependent
source whose radiating period in the time domain is known.
  The time-dependent source is supposed to be stationary in the sense that its
compact support does not vary along the time variable.
  Via a multi-frequency direct sampling method, we show that the smallest strip
containing the source support and perpendicular to the observation direction
can be recovered from far-field patterns at a fixed observation angle. With
multiple but sparse observation directions, the shape of the convex hull of the
source support can be recovered. The frequency-domain analysis performed here
can be used to handle inverse time-dependent source problems.
  Our algorithm has low computational overhead and is robust against noise.
Numerical experiments in both two and three dimensions have proved our
theoretical findings.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 12:21:34 GMT""}]","2022-12-12"
"2212.04807","Masoud Ghalaii Dr","Masoud Ghalaii and Sima Bahrani and Carlo Liorni and Federico
  Grasselli and Hermann Kampermann and Lewis Wooltorton and Rupesh Kumar and
  Stefano Pirandola and Timothy P. Spiller and Alexander Ling and Bruno Huttner
  and Mohsen Razavi","Realistic Threat Models for Satellite-Based Quantum Key Distribution","39 pages, 17 figures",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The security of prepare-and-measure satellite-based quantum key distribution
(QKD), under restricted eavesdropping scenarios, is addressed. We particularly
consider cases where the eavesdropper, Eve, has limited access to the
transmitted signal by Alice, and/or Bob's receiver station. This restriction is
modeled by lossy channels between Alice/Bob and Eve, where the transmissivity
of such channels can, in principle, be bounded by monitoring techniques. An
artefact of such lossy channels is the possibility of having bypass channels,
those which are not accessible to Eve, but may not necessarily be characterized
by the users either. This creates interesting, {\it unexplored}, scenarios for
analyzing QKD security. In this paper, we obtain generic bounds on the key rate
in the presence of bypass channels and apply them to continuous-variable QKD
protocols with Gaussian encoding with direct and reverse reconciliation. We
find regimes of operation in which the above restrictions on Eve can
considerably improve system performance. We also develop customised bounds for
several protocols in the BB84 family and show that, in certain regimes, even
the simple protocol of BB84 with weak coherent pulses is able to offer positive
key rates at high channel losses, which would otherwise be impossible under an
unrestricted Eve. In this case the limitation on Eve would allow Alice to send
signals with larger intensities than the optimal value under an ideal Eve,
which effectively reduces the effective channel loss. In all these cases, the
part of the transmitted signal that does not reach Eve can play a non-trivial
role in specifying the achievable key rate. Our work opens up new security
frameworks for spaceborne quantum communications systems.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 12:24:40 GMT""}]","2022-12-12"
"2212.04808","Muhammad Anwaar Khalid","Muhammad Anwaar Khalid, Kanwal Zulfiqar, Ulfat Bashir, Areeba Shaheen,
  Rida Iqbal, Zarnab Rizwan, Ghina Rizwan, Muhammad Moazam Fraz","CEPHA29: Automatic Cephalometric Landmark Detection Challenge 2023",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Quantitative cephalometric analysis is the most widely used clinical and
research tool in modern orthodontics. Accurate localization of cephalometric
landmarks enables the quantification and classification of anatomical
abnormalities, however, the traditional manual way of marking these landmarks
is a very tedious job. Endeavours have constantly been made to develop
automated cephalometric landmark detection systems but they are inadequate for
orthodontic applications. The fundamental reason for this is that the amount of
publicly available datasets as well as the images provided for training in
these datasets are insufficient for an AI model to perform well. To facilitate
the development of robust AI solutions for morphometric analysis, we organise
the CEPHA29 Automatic Cephalometric Landmark Detection Challenge in conjunction
with IEEE International Symposium on Biomedical Imaging (ISBI 2023). In this
context, we provide the largest known publicly available dataset, consisting of
1000 cephalometric X-ray images. We hope that our challenge will not only
derive forward research and innovation in automatic cephalometric landmark
identification but will also signal the beginning of a new era in the
discipline.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 12:25:58 GMT""},{""version"":""v2"",""created"":""Mon, 3 Apr 2023 10:27:21 GMT""}]","2023-04-04"
"2212.04809","Ryotaku Suzuki","Ryotaku Suzuki and Shinya Tomizawa","Phase and stability of black strings in Einstein-Gauss-Bonnet theory at
  large D","27 pages, 2 figures; v2: minor revisions, fixed a typo in the action,
  references added; v3: fixed minor typos, published version",,"10.1007/JHEP02(2023)101","TTI-MATHPHYS-17","hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The phase and stability of black strings in the Einstein-Gauss-Bonnet (EGB)
theory are investigated by using the large D effective theory approach. The
spacetime metric and thermodynamics are derived up to the next-to-leading order
(NLO) in the 1/D expansion. We find that the entropy current defined by the
Iyer-Wald formula follows the second law. As in the Einstein theory, the
entropy difference from the total mass produces an entropy functional for the
effective theory. Including the NLO correction, we find that for the large
Gauss-Bonnet coupling constant $\alpha_{\rm GB}$, the Gregory-Laflamme
instability of uniform black strings needs longer wavelength. Moreover, we show
that the critical dimension, beyond which non-uiform black strings becomes more
stable than uniform ones, increases as $\alpha_{\rm GB}$ becomes large, and
approaches to a finite value for $\alpha_{\rm GB}\to \infty$.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 12:27:41 GMT""},{""version"":""v2"",""created"":""Fri, 16 Dec 2022 08:16:54 GMT""},{""version"":""v3"",""created"":""Mon, 13 Feb 2023 04:13:03 GMT""}]","2023-02-14"
"2212.04810","Anudeep Appe Mr.","Anudeep Appe, Bhanu Poluparthi, Lakshmi Kasivajjula, Udai Mv, Sobha
  Bagadi, Punya Modi, Aditya Singh, Hemanth Gunupudi","Machine Learning Framework: Competitive Intelligence and Key Drivers
  Identification of Market Share Trends Among Healthcare Facilities","7 Pages 5 figures 6 tables To appear in ICHA 2022",,,,"cs.LG cs.DB","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The necessity of data driven decisions in healthcare strategy formulation is
rapidly increasing. A reliable framework which helps identify factors impacting
a Healthcare Provider Facility or a Hospital (from here on termed as Facility)
Market Share is of key importance. This pilot study aims at developing a data
driven Machine Learning - Regression framework which aids strategists in
formulating key decisions to improve the Facilitys Market Share which in turn
impacts in improving the quality of healthcare services. The US (United States)
healthcare business is chosen for the study; and the data spanning across 60
key Facilities in Washington State and about 3 years of historical data is
considered. In the current analysis Market Share is termed as the ratio of
facility encounters to the total encounters among the group of potential
competitor facilities. The current study proposes a novel two-pronged approach
of competitor identification and regression approach to evaluate and predict
market share, respectively. Leveraged model agnostic technique, SHAP, to
quantify the relative importance of features impacting the market share. The
proposed method to identify pool of competitors in current analysis, develops
Directed Acyclic Graphs (DAGs), feature level word vectors and evaluates the
key connected components at facility level. This technique is robust since its
data driven which minimizes the bias from empirical techniques. Post
identifying the set of competitors among facilities, developed Regression model
to predict the Market share. For relative quantification of features at a
facility level, incorporated SHAP a model agnostic explainer. This helped to
identify and rank the attributes at each facility which impacts the market
share.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 12:30:34 GMT""},{""version"":""v2"",""created"":""Mon, 12 Dec 2022 08:15:18 GMT""}]","2022-12-13"
"2212.04811","Vadim Sotskov","Alexander Ya. Pak, Vadim Sotskov, Arina A. Gumovskaya, Yuliya Z.
  Vassilyeva, Zhanar S. Bolatova, Yulia A. Kvashnina, Gennady Ya. Mamontov,
  Alexander V. Shapeev, and Alexander G. Kvashnin","Machine-learning Driven Synthesis of TiZrNbHfTaC5 High-Entropy Carbide","16 pages, 8 figures",,,,"cond-mat.mtrl-sci physics.chem-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Synthesis of high-entropy carbides (HEC) requires high temperatures that can
be provided by electric arc plasma method. However, the formation temperature
of a single-phase sample remains unknown. Moreover, under some temperatures
multi-phase structures can emerge. In this work we developed an approach for a
controllable synthesis of HEC TiZrNbHfTaC5 based on theoretical and
experimental techniques. We used canonical Monte Carlo (CMC) simulations with
the machine learning interatomic potentials to determine the temperature
conditions for the formation of single-phase and multi-phase samples. In full
agreement with the theory, the single-phase sample, produced with electric arc
discharge, was observed at 2000 K. Below 1200 K the sample decomposed into
(Ti-Nb-Ta)C and a mixture of (Zr-Hf-Ta)C, (Zr-Nb-Hf)C, (Zr-Nb)C, and (Zr-Ta)C.
Our results demonstrate the conditions for the formation of HEC and we
anticipate that our approach can pave the way towards targeted synthesis of
multicomponent materials.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 12:32:30 GMT""}]","2022-12-12"
"2212.04812","Neslihan Kose Cihangir","Neslihan Kose, Ranganath Krishnan, Akash Dhamasia, Omesh Tickoo,
  Michael Paulitsch","Reliable Multimodal Trajectory Prediction via Error Aligned Uncertainty
  Optimization","Accepted to ECCV 2022 workshop - Safe Artificial Intelligence for
  Automated Driving",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Reliable uncertainty quantification in deep neural networks is very crucial
in safety-critical applications such as automated driving for trustworthy and
informed decision-making. Assessing the quality of uncertainty estimates is
challenging as ground truth for uncertainty estimates is not available.
Ideally, in a well-calibrated model, uncertainty estimates should perfectly
correlate with model error. We propose a novel error aligned uncertainty
optimization method and introduce a trainable loss function to guide the models
to yield good quality uncertainty estimates aligning with the model error. Our
approach targets continuous structured prediction and regression tasks, and is
evaluated on multiple datasets including a large-scale vehicle motion
prediction task involving real-world distributional shifts. We demonstrate that
our method improves average displacement error by 1.69% and 4.69%, and the
uncertainty correlation with model error by 17.22% and 19.13% as quantified by
Pearson correlation coefficient on two state-of-the-art baselines.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 12:33:26 GMT""}]","2022-12-12"
"2212.04814","Frank Windmeijer","Nicolas Apfel and Frank Windmeijer","The Falsification Adaptive Set in Linear Models with Instrumental
  Variables that Violate the Exogeneity or Exclusion Restriction",,,,,"econ.EM stat.ME","http://creativecommons.org/licenses/by/4.0/","  For the classical linear model with an endogenous variable estimated by the
method of instrumental variables (IVs) with multiple instruments, Masten and
Poirier (2021) introduced the falsification adaptive set (FAS). When a model is
falsified, the FAS reflects the model uncertainty that arises from
falsification of the baseline model. It is the set of just-identified IV
estimands, where each relevant instrument is considered as the just-identifying
instrument in turn, whilst all other instruments are included as controls. It
therefore applies to the case where the exogeneity assumption holds and invalid
instruments violate the exclusion assumption only. We propose a generalized FAS
that reflects the model uncertainty when some instruments violate the
exogeneity assumption and/or some instruments violate the exclusion assumption.
This FAS is the set of all possible just-identified IV estimands where the
just-identifying instrument is relevant. There are a maximum of
$k_{z}2^{k_{z}-1}$ such estimands, where $k_{z}$ is the number of instruments.
If there is at least one relevant instrument that is valid in the sense that it
satisfies the exogeneity and exclusion assumptions, then this generalized FAS
is guaranteed to contain $\beta$ and therefore to be the identified set for
$\beta$.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 12:42:17 GMT""}]","2022-12-12"
"2212.04815","Supriyo Ghosh","Supriyo Ghosh (TIFR, Mumbai), Joe P. Ninan (TIFR, Mumbai), Devendra K.
  Ojha (TIFR, Mumbai), Saurabh Sharma (ARIES, Nainital)","pyTANSPEC: A Data Reduction Package for TANSPEC","10 pages, 6 figures, accepted for publication in the Special Issue of
  Journal of Astrophysics & Astronomy, 2022, Star formation studies in context
  of NIR instruments on 3.6m DOT, held at ARIES, Nainital during 4-7, May, 2022",,"10.1007/s12036-023-09926-y",,"astro-ph.IM astro-ph.GA astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The TIFR-ARIES Near Infrared Spectrometer (TANSPEC) instrument provides
simultaneous wavelength coverage from 0.55 to 2.5 micron, mounted on India's
largest ground-based telescope, 3.6-m Devasthal Optical Telescope at Nainital,
India. The TANSPEC offers three modes of observations, imaging with various
filters, spectroscopy in the low-resolution prism mode with derived R~ 100-400
and the high-resolution cross-dispersed mode (XD-mode) with derived median R~
2750 for a slit of width 0.5 arcsec. In the XD-mode, ten cross-dispersed orders
are packed in the 2048 x 2048 pixels detector to cover the full wavelength
regime. As the XD-mode is most utilized as well as for consistent data
reduction for all orders and to reduce data reduction time, a dedicated
pipeline is at the need. In this paper, we present the code for the TANSPEC
XD-mode data reduction, its workflow, input/output files, and a showcase of its
implementation on a particular dataset. This publicly available pipeline
pyTANSPEC is fully developed in Python and includes nominal human intervention
only for the quality assurance of the reduced data. Two customized
configuration files are used to guide the data reduction. The pipeline creates
a log file for all the fits files in a given data directory from its header,
identifies correct frames (science, continuum and calibration lamps) based on
the user input, and offers an option to the user for eyeballing and
accepting/removing of the frames, does the cleaning of raw science frames and
yields final wavelength calibrated spectra of all orders simultaneously.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 12:42:52 GMT""}]","2023-04-19"
"2212.04816","Ye Tian","Zhongxiang Wei, Ye Tian, Wei Chen, Liyuan Gu, and Xinming Zhang","DUNE: Improving Accuracy for Sketch-INT Network Measurement Systems","Technical report for the paper published in IEEE INFOCOM 2023",,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In-band Network Telemetry (INT) and sketching algorithms are two promising
directions for measuring network traffics in real time. To combine sketch with
INT and preserve their advantages, a representative approach is to use INT to
send a switch sketch in small pieces (called sketchlets) to end-host for
reconstructing an identical sketch. However, in this paper, we reveal that when
naively selecting buckets to sketchlets, the end-host reconstructed sketch is
inaccurate. To overcome this problem, we present DUNE, an innovative sketch-INT
network measurement system. DUNE incorporates two key innovations: First, we
design a novel scatter sketchlet that is more efficient in transferring
measurement data by allowing a switch to select individual buckets to add to
sketchlets; Second, we propose lightweight data structures for tracing
""freshness"" of the sketch buckets, and present algorithms for smartly selecting
buckets that contain valuable measurement data to send to end-host. We
theoretically prove the effectiveness of our proposed methods, and implement a
prototype on commodity programmable switch. The results of extensive
experiments driven by real-world traffics on DUNE suggest that our proposed
system can substantially improve the measurement accuracy at a trivial cost.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 12:43:28 GMT""}]","2022-12-12"
"2212.04817","Xiang-Gen Xia Prof.","Xiang-Gen Xia","A New OFDM System for IIR Channels",,,,,"eess.SP cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose a new OFDM system for an IIR channel with the form
of $B(z)/A(z)$ for two polynomials $A(z)$ and $B(z)$. Different from the
conventional OFDM transmission over an FIR channel, a guard interval of an OFDM
symbol is added such that the corresponding part at receiver is the cyclic
prefix (CP) of the received OFDM symbol. The guard interval and CP lengths are
the same and not smaller than the orders of polynomials $A(z)$ and $B(z)$. The
OFDM symbol without the guard interval is the same as the conventional OFDM
symbol without the CP. At the receiver, the IIR channel is then converted to
$N$ intersymbol interference (ISI) free subchannels, where $N$ is the number of
subcarriers of an OFDM symbol.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 12:44:49 GMT""}]","2022-12-12"
"2212.04818","Pavel Telegin","Pavel Telegin, Anton Baranov, Boris Shabanov, Artem Tikhomirov","Parallelism detection using graph labelling",,,,,"cs.MS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Usage of multiprocessor and multicore computers implies parallel programming.
Tools for preparing parallel programs include parallel languages and libraries
as well as parallelizing compilers and convertors that can perform automatic
parallelization. The basic approach for parallelism detection is analysis of
data dependencies and properties of program components, including data use and
predicates. In this article a suite of used data and predicates sets for
program components is proposed and an algorithm for computing these sets is
suggested. The algorithm is based on wave propagation on graphs with cycles and
labelling. This method allows analyzing complex program components, improving
data localization and thus providing enhanced data parallelism detection.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 12:46:24 GMT""}]","2022-12-12"
"2212.04819","Kiana Ehsani","Matt Deitke, Rose Hendrix, Luca Weihs, Ali Farhadi, Kiana Ehsani,
  Aniruddha Kembhavi","Phone2Proc: Bringing Robust Robots Into Our Chaotic World","https://allenai.org/project/phone2proc",,,,"cs.RO cs.AI cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Training embodied agents in simulation has become mainstream for the embodied
AI community. However, these agents often struggle when deployed in the
physical world due to their inability to generalize to real-world environments.
In this paper, we present Phone2Proc, a method that uses a 10-minute phone scan
and conditional procedural generation to create a distribution of training
scenes that are semantically similar to the target environment. The generated
scenes are conditioned on the wall layout and arrangement of large objects from
the scan, while also sampling lighting, clutter, surface textures, and
instances of smaller objects with randomized placement and materials.
Leveraging just a simple RGB camera, training with Phone2Proc shows massive
improvements from 34.7% to 70.7% success rate in sim-to-real ObjectNav
performance across a test suite of over 200 trials in diverse real-world
environments, including homes, offices, and RoboTHOR. Furthermore, Phone2Proc's
diverse distribution of generated scenes makes agents remarkably robust to
changes in the real world, such as human movement, object rearrangement,
lighting changes, or clutter.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:52:27 GMT""}]","2022-12-12"
"2212.04820","Dan Mikami","Takayoshi Yamaguchi, Dan Mikami, Seiji Matsumura, Naoki Saijo, Makio
  Kashino","Pose Estimation for Human Wearing Loose-Fitting Clothes: Obtaining
  Ground Truth Posture Using HFR Camera and Blinking LEDs","Extended abstract of WACV2023 workshop on Computer Vision 4 Winter
  Sports",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Human pose estimation, particularly in athletes, can help improve their
performance. However, this estimation is difficult using existing methods, such
as human annotation, if the subjects wear loose-fitting clothes such as
ski/snowboard wears. This study developed a method for obtaining the ground
truth data on two-dimensional (2D) poses of a human wearing loose-fitting
clothes. This method uses fast-flushing light-emitting diodes (LEDs). The
subjects were required to wear loose-fitting clothes and place the LED on the
target joints. The LEDs were observed directly using a camera by selecting thin
filmy loose-fitting clothes. The proposed method captures the scene at 240 fps
by using a high-frame-rate camera and renders two 30 fps image sequences by
extracting LED-on and -off frames. The temporal differences between the two
video sequences can be ignored, considering the speed of human motion. The
LED-on video was used to manually annotate the joints and thus obtain the
ground truth data. Additionally, the LED-off video, equivalent to a standard
video at 30 fps, confirmed the accuracy of existing machine learning-based
methods and manual annotations. Experiments demonstrated that the proposed
method can obtain ground truth data for standard RGB videos. Further, it was
revealed that neither manual annotation nor the state-of-the-art pose estimator
obtains the correct position of target joints.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:10:23 GMT""}]","2022-12-12"
"2212.04821","Roei Herzig","Roei Herzig, Ofir Abramovich, Elad Ben-Avraham, Assaf Arbelle, Leonid
  Karlinsky, Ariel Shamir, Trevor Darrell, Amir Globerson","PromptonomyViT: Multi-Task Prompt Learning Improves Video Transformers
  using Synthetic Scene Data","Tech report",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Action recognition models have achieved impressive results by incorporating
scene-level annotations, such as objects, their relations, 3D structure, and
more. However, obtaining annotations of scene structure for videos requires a
significant amount of effort to gather and annotate, making these methods
expensive to train. In contrast, synthetic datasets generated by graphics
engines provide powerful alternatives for generating scene-level annotations
across multiple tasks. In this work, we propose an approach to leverage
synthetic scene data for improving video understanding. We present a multi-task
prompt learning approach for video transformers, where a shared video
transformer backbone is enhanced by a small set of specialized parameters for
each task. Specifically, we add a set of ``task prompts'', each corresponding
to a different task, and let each prompt predict task-related annotations. This
design allows the model to capture information shared among synthetic scene
tasks as well as information shared between synthetic scene tasks and a real
video downstream task throughout the entire network. We refer to this approach
as ``Promptonomy'', since the prompts model task-related structure. We propose
the PromptonomyViT model (PViT), a video transformer that incorporates various
types of scene-level information from synthetic data using the ``Promptonomy''
approach. PViT shows strong performance improvements on multiple video
understanding tasks and datasets.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:55:31 GMT""},{""version"":""v2"",""created"":""Thu, 16 Mar 2023 08:07:49 GMT""}]","2023-03-17"
"2212.04822","Samson Shatashvili","A. Alekseev, S. Shatashvili and L. Takhtajan","Berezin quantization, conformal welding and the Bott-Virasoro group","26 pages",,,,"hep-th math.QA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Following Nag-Sullivan, we study the representation of the group ${\rm
Diff}^+(S^1)$ of diffeomorphisms of the circle on the Hilbert space of
holomorphic functions. Conformal welding provides a triangular decompositions
for the corresponding symplectic transformations. We apply Berezin formalism
and lift this decomposition to operators acting on the Fock space. This lift
provides quantization of conformal welding, gives a new representative of the
Bott-Virasoso cocylce class, and leads to a surprising identity for the
Takhtajan-Teo energy functional on ${\rm Diff}^+(S^1)$.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 12:53:10 GMT""}]","2022-12-12"
"2212.04824","Cormac O'Malley Mr","Cormac O'Malley, Patrick de Mars, Luis Badesa and Goran Strbac","Reinforcement Learning and Mixed-Integer Programming for Power Plant
  Scheduling in Low Carbon Systems: Comparison and Hybridisation","Submitted to Applied Energy, Dec 2022",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Decarbonisation is driving dramatic growth in renewable power generation.
This increases uncertainty in the load to be served by power plants and makes
their efficient scheduling, known as the unit commitment (UC) problem, more
difficult. UC is solved in practice by mixed-integer programming (MIP) methods;
however, there is growing interest in emerging data-driven methods including
reinforcement learning (RL). In this paper, we extensively test two MIP
(deterministic and stochastic) and two RL (model-free and with lookahead)
scheduling methods over a large set of test days and problem sizes, for the
first time comparing the state-of-the-art of these two approaches on a level
playing field. We find that deterministic and stochastic MIP consistently
produce lower-cost UC schedules than RL, exhibiting better reliability and
scalability with problem size. Average operating costs of RL are more than 2
times larger than stochastic MIP for a 50-generator test case, while the cost
is 13 times larger in the worst instance. However, the key strength of RL is
the ability to produce solutions practically instantly, irrespective of problem
size. We leverage this advantage to produce various initial solutions for warm
starting concurrent stochastic MIP solves. By producing several near-optimal
solutions simultaneously and then evaluating them using Monte Carlo methods,
the differences between the true cost function and the discrete approximation
required to formulate the MIP are exploited. The resulting hybrid technique
outperforms both the RL and MIP methods individually, reducing total operating
costs by 0.3% on average.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 12:53:33 GMT""}]","2022-12-12"
"2212.04826","Thiago P. Mayer Alegre","Jorge H. Soares, La\'is Fujii Dos Santos, Felipe G. S. Santos, Marvyn
  Inga, Yovanny A. V. Espinel, Gustavo S. Wiederhecker, Thiago P. Mayer Alegre","Third-harmonic generation in silica wedge resonators","6 pages, 6 figures",,"10.1364/JOSAB.482611",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Whispering-gallery-mode microcavities are known to have high optical quality
factor, making them suitable for nonlinear optical interactions. Here,
third-harmonic generation is observed using a relatively small radius wedge
silicon oxide optical microcavity. The small radii wedge microdisks can be
dispersion-tailored to obtain either normal or anomalous group velocity
dispersion. In our case, we operate in the normal dispersion regime preventing
frequency comb generation by suppressing infrared cascading four-wave mixing.
This allows for a clean third harmonic generation at phase-matched visible
optical modes. Tunability of the third-harmonic emission is obtained due to a
combination of the thermo-optical and Kerr effects. An additional thermal
control of the phase matching condition allows for optimizing third-harmonic
generation, and agreement between this process and couple-mode theory is
demonstrated.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 12:54:49 GMT""}]","2023-05-17"
"2212.04827","Cyprien Tamekue","Cyprien Tamekue, Dario Prandi, Yacine Chitour","Cortical origins of MacKay-type visual illusions. A case for the
  non-linearity",,,,,"q-bio.NC cs.NA math.NA math.OC nlin.PS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To study the interaction between retinal stimulation by redundant geometrical
patterns and the cortical response in the primary visual cortex (V1), we focus
on the MacKay effect (Nature, 1957) and Billock and Tsou's experiments (PNAS,
2007). Starting from a classical biological model of neuronal fields equations
with a non-linear response function, we use a controllability approach to
describe these phenomena. The external input containing a localised control
function is interpreted as a cortical representation of the static visual
stimuli used in these experiments. We prove that while the MacKay effect is
essentially a linear phenomenon (i.e., the nonlinear nature of the activation
does not play any role in its reproduction), the phenomena reported by Billock
and Tsou are wholly nonlinear and depend strongly on the shape of the
nonlinearity used to model the response function.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 12:57:14 GMT""}]","2022-12-12"
"2212.04828","Fernando Gago-Encinas","Fernando Gago-Encinas, Monika Leibscher, and Christiane P. Koch","Graph test of controllability in qubit arrays: A systematic way to
  determine the minimum number of external controls","18 pages, 7 figures, 3 tables, 3 algorithms",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  The ability to implement any desired quantum logic gate on a quantum
processing unit is equivalent to evolution-operator controllability of the
qubits. Conversely, controllability analysis can be used to minimize the
resources, i.e., the number of external controls and qubit-qubit couplings,
required for universal quantum computing. Standard controllability analysis,
consisting in the construction of the dynamical Lie algebra, is, however,
impractical already for a comparatively small number of qubits. Here, we show
how to leverage an alternative approach, based on a graph representation of the
Hamiltonian, to determine controllability of arrays of coupled qubits. We
provide a complete computational framework and exemplify it for arrays of five
qubits, inspired by the ibmq_quito architecture. We find that the number of
controls can be reduced from five to one for complex qubit-qubit couplings and
to two for standard qubit-qubit couplings.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 12:59:44 GMT""}]","2022-12-12"
"2212.04829","Jun Zhang","Jun Zhang, Peng Du, Lei Jing, Peng Xu, Li You, Wenxian Zhang","Enhanced measurement precision with continuous interrogation during
  dynamical decoupling",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dynamical decoupling (DD) is normally ineffective when applied to DC
measurement. In its straightforward implementation, DD nulls out DC signal as
well while suppressing noise. This work proposes a phase relay method (PRM)
that is capable of continuously interrogating the DC signal over many DD
cycles. We illustrate its efficacy when applied to measurement of a weak DC
magnetic field with an atomic spinor Bose-Einstein condensate. Sensitivities
approaching standard quantum limit (SQL) or Heisenberg limit (HL) are
potentially realizable for a coherent spin state (CSS) or a squeezed spin state
(SSS) of 10,000 atoms respectively, while ambient laboratory level noise is
suppressed by DD. Our work offers a practical approach to mitigate the
limitations of DD to DC measurement and will like find other applications for
resorting coherence in quantum sensing and quantum information processing
research.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:00:59 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jun 2023 16:00:25 GMT""}]","2023-06-02"
"2212.04830","Birgit Vogel-Heuser Prof. Dr.-Ing.","Eva-Maria Neumann, Birgit Vogel-Heuser, Fabian Haben, Marius Krueger
  and Timotheus Wieringa","Introduction of an Assistance System to Support Domain Experts in
  Programming Low-code to Leverage Industry 5.0","8 pages, https://ieeexplore.ieee.org/abstract/document/9839457","Robotics and Automation Letters 7 (2022) 4","10.1109/LRA.2022.3193728",,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The rapid technological leaps of Industry 4.0 increase the pressure and
demands on humans working in automation, which is one of the main motivators of
Industry 5.0. In particular, automation software development for mechatronic
systems becomes increasingly challenging, as both domain knowledge and
programming skills are required for high-quality, maintainable software.
Especially for small companies from automation and robotics without dedicated
software engineering departments, domain-specific low-code platforms become
indispensable that enable domain experts to develop code intuitively using
visual programming languages, e.g., for tasks such as retrofitting mobile
machines. However, for extensive functionalities, visual programs may become
overwhelming due to the scaling-up problem. In addition, the ever-shortening
time-to-market increases the time pressure on programmers. Thus, an assistance
system concept is introduced that can be implemented by low-code platform
suppliers based on combining data mining and static code analysis. Domain
experts are supported in developing low-code by targeted recommendations,
metric-based complexity measurement, and reducing complexity by encapsulating
functionalities. The concept is implemented for the industrial low-code
platform HAWE eDesign to program hydraulic components in mobile machines, and
its benefits are confirmed in a user study and an industrial expert workshop.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:01:30 GMT""}]","2022-12-12"
"2212.04831","Huajian Fang","Huajian Fang and Timo Gerkmann","Uncertainty Estimation in Deep Speech Enhancement Using Complex Gaussian
  Mixture Models","\copyright 2023 IEEE. Personal use of this material is permitted.
  Permission from IEEE must be obtained for all other uses, in any current or
  future media, including reprinting/republishing this material for advertising
  or promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works","ICASSP 2023 - IEEE International Conference on Acoustics, Speech
  and Signal Processing",,,"eess.AS cs.LG cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Single-channel deep speech enhancement approaches often estimate a single
multiplicative mask to extract clean speech without a measure of its accuracy.
Instead, in this work, we propose to quantify the uncertainty associated with
clean speech estimates in neural network-based speech enhancement. Predictive
uncertainty is typically categorized into aleatoric uncertainty and epistemic
uncertainty. The former accounts for the inherent uncertainty in data and the
latter corresponds to the model uncertainty. Aiming for robust clean speech
estimation and efficient predictive uncertainty quantification, we propose to
integrate statistical complex Gaussian mixture models (CGMMs) into a deep
speech enhancement framework. More specifically, we model the dependency
between input and output stochastically by means of a conditional probability
density and train a neural network to map the noisy input to the full posterior
distribution of clean speech, modeled as a mixture of multiple complex Gaussian
components. Experimental results on different datasets show that the proposed
algorithm effectively captures predictive uncertainty and that combining
powerful statistical models and deep learning also delivers a superior speech
enhancement performance.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:03:09 GMT""},{""version"":""v2"",""created"":""Mon, 15 May 2023 14:32:13 GMT""}]","2023-05-16"
"2212.04832","Fabian Wagner","Fabian Wagner, Mareike Thies, Laura Pfaff, Noah Maul, Sabrina
  Pechmann, Mingxuan Gu, Jonas Utz, Oliver Aust, Daniela Weidner, Georgiana
  Neag, Stefan Uderhardt, Jang-Hwan Choi, Andreas Maier","Noise2Contrast: Multi-Contrast Fusion Enables Self-Supervised
  Tomographic Image Denoising",,,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Self-supervised image denoising techniques emerged as convenient methods that
allow training denoising models without requiring ground-truth noise-free data.
Existing methods usually optimize loss metrics that are calculated from
multiple noisy realizations of similar images, e.g., from neighboring
tomographic slices. However, those approaches fail to utilize the multiple
contrasts that are routinely acquired in medical imaging modalities like MRI or
dual-energy CT. In this work, we propose the new self-supervised training
scheme Noise2Contrast that combines information from multiple measured image
contrasts to train a denoising model. We stack denoising with domain-transfer
operators to utilize the independent noise realizations of different image
contrasts to derive a self-supervised loss. The trained denoising operator
achieves convincing quantitative and qualitative results, outperforming
state-of-the-art self-supervised methods by 4.7-11.0%/4.8-7.3% (PSNR/SSIM) on
brain MRI data and by 43.6-50.5%/57.1-77.1% (PSNR/SSIM) on dual-energy CT X-ray
microscopy data with respect to the noisy baseline. Our experiments on
different real measured data sets indicate that Noise2Contrast training
generalizes to other multi-contrast imaging modalities.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:03:24 GMT""}]","2022-12-12"
"2212.04833","Olivier Marchal","Olivier Marchal, Nicolas Orantin, Mohamad Alameddine","Hamiltonian representation of isomonodromic deformations of general
  rational connections on $\mathfrak{gl}_2(\mathbb{C})$","61 pages + appendices. Main theorem detailed and improved",,,,"math-ph hep-th math.MP math.SG nlin.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study and build the Hamiltonian system attached to any
$\mathfrak{gl}_2(\mathbb{C})$ rational connection with arbitrary number of
non-ramified poles of arbitrary degrees. In particular, we propose the Lax
pairs expressed in terms of irregular times and monodromies associated to the
poles and a map reducing the space of irregular times to non trivial
isomonodromic times. We apply the general theory to all cases where the
associated spectral curve has genus 1 and recover the standard Painlev\'{e}
equations. We finally make the connection with the topological recursion and
the quantization of classical spectral curve from this perspective.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:04:37 GMT""},{""version"":""v2"",""created"":""Tue, 7 Feb 2023 20:04:45 GMT""},{""version"":""v3"",""created"":""Fri, 10 Mar 2023 10:09:46 GMT""},{""version"":""v4"",""created"":""Thu, 20 Apr 2023 07:05:18 GMT""}]","2023-04-21"
"2212.04834","Stefano Paesani","Tom J. Bell, Love A. Pettersson, Stefano Paesani","Optimising graph codes for measurement-based loss tolerance",,,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Graph codes play an important role in photonic quantum technologies as they
provide significant protection against qubit loss, a dominant noise mechanism.
Here, we develop methods to analyse and optimise measurement-based tolerance to
qubit loss and computational errors for arbitrary graph codes. Using these
tools we identify optimised codes with up to 12 qubits and asymptotically-large
modular constructions. The developed methods enable significant benefits for
various photonic quantum technologies, as we illustrate with novel all-photonic
quantum repeater states for quantum communication and high-threshold
fusion-based schemes for fault-tolerant quantum computing.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:06:40 GMT""}]","2022-12-12"
"2212.04835","Mitja Sadl","Mitja Sadl, Sara Collins, M. Padmanath, Sasa Prelovsek","Charmonium-like states with $J^{P}=1^{+}$ and isospin 1","9 pages, 2 figures, contribution to the 39th International Symposium
  on Lattice Field Theory (LATTICE2022)",,,"MITP-22-100","hep-lat hep-ph","http://creativecommons.org/licenses/by/4.0/","  Many mesons with properties incompatible with a $\bar cc$ structure have
already been discovered, e.g. the $Z_c$ mesons with isospin 1. We investigate
the spectrum of exotic charmonium-like mesons using lattice QCD. The focus is
on $\bar cc \bar qq$ states with $J^{PC}=1^{+\pm}$ and isospin 1. This is the
first study of four-quark states with these quantum numbers, a non-zero total
momentum and two different lattice volumes. We extract the energy levels and
determine the scattering length for $D\bar D^*$ scattering close to the
threshold using L\""uscher's formalism. Our preliminary results show that the
energy shifts for eigenstates dominated by $D\bar{D}^*$ are very small in the
$1^{++}$ channel and consistent with zero in the $1^{+-}$ channel.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:06:53 GMT""}]","2022-12-12"
"2212.04836","Hans Rabus","Hans Rabus (1), Philine Hepperle (1,2), Christoph Schlueter (3),
  Andrei Hloskovsky (3), Woon Yong Baek (1) ((1) Physikalisch-Technische
  Bundesanstalt, Braunschweig and Berlin, Germany, (2) Leibniz Universit\""at
  Hannover, Institute of Radioecology and Radiation Protection, Hannover,
  Germany, (3) Deutsches Elektronen-Synchrotron DESY, Hamburg, Germany)","Experimental benchmark data for Monte Carlo simulated radiation effects
  of gold nanoparticles. Part I: Experiment and raw data analysis","Revised manuscript after peer review; 21 pages, 15 Figures, 6 Tables
  plus 4 Supplements with altogether 14 pages, 16 figures, 2 tables","Physica Scripta, Volume 98, Number 5, 055015 (2023)","10.1088/1402-4896/accb14",,"physics.med-ph cond-mat.mtrl-sci physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  Electron emission spectra of gold nanoparticles (AuNPs) after photon
interaction were measured over the energy range between 50 eV and 9500 eV to
provide reference data for Monte Carlo radiation-transport simulations.
Experiments were performed with the HAXPES spectrometer at the PETRA III
high-brilliance beamline P22 at DESY (Hamburg, Germany) for photon energies
below and above each of the gold L-edges, i.e., at 11.9 keV, 12.0 keV, 13.7
keV, 13.8 keV, 14.3 keV, and 14.4 keV. The study focused on a sample with gold
nanoparticles with an average diameter of 11.0 nm on a thin carbon foil.
Additional measurements were performed on a sample with 5.3 nm gold
nanoparticles and on reference samples of gold and carbon foils. Further
measurements were made to calibrate the photon flux monitor, to characterize
the transmission function of the electron spectrometer and to determine the
size of the photon beam. This allowed the determination of the absolute values
of the spectral particle radiance of secondary electrons per incident photon
flux. The paper presents the experimental and raw data analysis procedures,
reviews the data obtained for the nanoparticle samples and discusses their
limitations.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:07:42 GMT""},{""version"":""v2"",""created"":""Sun, 9 Apr 2023 12:10:38 GMT""}]","2023-04-19"
"2212.04837","Fabian Gittins","Nils Andersson, Fabian Gittins","Formulating the r-mode problem for slowly rotating neutron stars","22 pages, 1 figure. Accepted for publication in ApJ","Astrophys. J. 945, 139 (2023)","10.3847/1538-4357/acbc1e",,"gr-qc astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We revisit the problem of inertial r-modes in stratified stars, drawing on a
more precise description of the composition stratification in a mature neutron
star. The results highlight issues with the traditional approach to the
problem, leading us to rethink the computational strategy for r-modes of
non-barotropic neutron stars. We outline two strategies for dealing with the
problem. For moderate to slowly rotating neutron stars the only viable
alternative may be to approach the problem numerically from the outset, while a
meaningful slow-rotation calculation can be carried out for the fastest known
spinning stars (which may be close to being driven unstable by the emission of
gravitational waves). We demonstrate that the latter approach leads to a
problem close, but not identical, to that for barotropic inertial modes. We
also suggest that these reformulations of the problem likely resolve the
long-standing problem of singular behaviour associated with a co-rotation point
in rotating relativistic neutron stars. This issue needs to be resolved in
order to guide future gravitational-wave searches.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:09:00 GMT""},{""version"":""v2"",""created"":""Wed, 1 Mar 2023 11:47:25 GMT""}]","2023-05-23"
"2212.04838","Patrick Maurer","Patrick Maurer, Carlos Gonzalez-Ballestero, and Oriol Romero-Isart","Quantum Theory of Light Interaction with a Dielectric Sphere: Towards 3D
  Ground-State Cooling","16 + 12 pages, 8 + 4 figures, 1 table",,,,"physics.optics cond-mat.mes-hall quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We theoretically analyze the motional quantum dynamics of a levitated
dielectric sphere interacting with the quantum electromagnetic field beyond the
point-dipole approximation. To this end, we derive a Hamiltonian describing the
fundamental coupling between photons and center-of-mass phonons, including
Stokes and anti-Stokes processes, and the coupling rates for a dielectric
sphere of arbitrary refractive index and size. We then derive the laser recoil
heating rates and the information radiation patterns (the angular distribution
of the scattered light that carries information about the center-of-mass
motion) and show how to evaluate them efficiently in the presence of a focused
laser beam, either in a running or a standing-wave configuration. This
information is crucial to implement active feedback cooling of optically
levitated dielectric spheres beyond the point-dipole approximation. Our results
predict several experimentally feasible configurations and parameter regimes
where optical detection and active feedback can simultaneously cool to the
ground state the three-dimensional center-of-mass motion of dielectric spheres
in the micrometer regime. Scaling up the mass of the dielectric particles that
can be cooled to the center-of-mass ground state is not only relevant for
testing quantum mechanics at large scales but also for current experimental
efforts that search for new physics (e.g. dark matter) using optically
levitated sensors.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:11:29 GMT""}]","2022-12-12"
"2212.04839","Robert Main","R. A. Main, S. Bethapudi, V. R. Marthi, M. L. Bause, D. Z. Li, H.-H.
  Lin, L. G. Spitler, R. S. Wharton","Modelling Annual Scintillation Velocity Variations of FRB 20201124A","5 pages, 5 Figures, accepted in MNRAS Letters",,"10.1093/mnrasl/slad036",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Compact radio sources exhibit scintillation, an interference pattern arising
from propagation through inhomogeneous plasma, where scintillation patterns
encode the relative distances and velocities of the source, scattering
material, and Earth. In previous work, we showed that the scintillation
velocity of the repeating fast radio burst FRB20201124A could be measured by
correlating burst spectra pairs, with low values of the scintillation velocity
and scattering timescale suggesting scattering nearby the Earth at
$\sim0.4\,$kpc. In this work, we have measured the scintillation velocity at 10
epochs spanning a year, observing an annual variation which strongly implies
the screen is within the Milky Way. Modelling the annual variation with a 1D
anisotropic or 2D isotropic screen results in a screen distance $d_{l} =
0.40\pm0.04\,$pc or $d_{l} = 0.46\pm0.06\,$pc from Earth respectively, possibly
associated with material outside of the Local Bubble or the edge of the
Orion-Eridanus Superbubble. Additional measurements particularly at times of
low effective velocity will help probe changes in screen properties, and
distinguish between screen models. Where scintillation of an FRB originates in
its host galaxy or local environment, these techniques could be used to detect
orbital motion, and probe the FRB's local ionised environment.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:12:29 GMT""},{""version"":""v2"",""created"":""Mon, 20 Mar 2023 14:29:18 GMT""}]","2023-03-29"
"2212.04840","Nicola Soave","Jack Borthwick, Xiaojun Chang, Louis Jeanjean, Nicola Soave","Normalized solutions of $L^2$-supercritical NLS equations on noncompact
  metric graphs with localized nonlinearities","arXiv admin note: text overlap with arXiv:2204.01043",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  In this paper we are concerned with the existence of normalized solutions for
nonlinear Schr\""odinger equations on noncompact metric graphs with localized
nonlinearities. In a $L^2$-supercritical regime, we obtain the existence of
solutions for any prescribed mass. This result is obtained through an approach
which could prove successful to treat more general equations on noncompact
graphs.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:14:31 GMT""},{""version"":""v2"",""created"":""Fri, 5 May 2023 10:48:25 GMT""}]","2023-05-08"
"2212.04841","Ederson Moreira dos Santos","Angelo Guimar\~aes and Ederson Moreira dos Santos","On Hamiltonian systems with critical Sobolev exponents","26 pages",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  In this paper we consider lower order perturbations of the critical
Lane-Emden system posed on a bounded smooth domain $\Omega \subset
\mathbb{R}^N$, with $N \geq3$, inspired by the classical results of Brezis and
Nirenberg \cite{BrezisNirenberg1983}. We solve the problem of finding a
positive solution for all dimensions $N \geq 4$. For the critical dimension
$N=3$ we show a new phenomenon, not observed for scalar problems. Namely, there
are parts on the critical hyperbola where solutions exist for all
$1$-homogeneous or subcritical superlinear perturbations and parts where there
are no solutions for some of those perturbations.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:19:06 GMT""}]","2022-12-12"
"2212.04842","Andr\'es Villa","Andr\'es Villa, Juan Le\'on Alc\'azar, Motasem Alfarra, Kumail
  Alhamoud, Julio Hurtado, Fabian Caba Heilbron, Alvaro Soto, Bernard Ghanem","PIVOT: Prompting for Video Continual Learning","CVPR 2023",,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  Modern machine learning pipelines are limited due to data availability,
storage quotas, privacy regulations, and expensive annotation processes. These
constraints make it difficult or impossible to train and update large-scale
models on such dynamic annotated sets. Continual learning directly approaches
this problem, with the ultimate goal of devising methods where a deep neural
network effectively learns relevant patterns for new (unseen) classes, without
significantly altering its performance on previously learned ones. In this
paper, we address the problem of continual learning for video data. We
introduce PIVOT, a novel method that leverages extensive knowledge in
pre-trained models from the image domain, thereby reducing the number of
trainable parameters and the associated forgetting. Unlike previous methods,
ours is the first approach that effectively uses prompting mechanisms for
continual learning without any in-domain pre-training. Our experiments show
that PIVOT improves state-of-the-art methods by a significant 27% on the
20-task ActivityNet setup.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:22:27 GMT""},{""version"":""v2"",""created"":""Tue, 4 Apr 2023 22:28:05 GMT""}]","2023-04-06"
"2212.04843","Bruno Rossi","Martin Macak, Matus Stovcik, Tomas Rebok, Mouzhi Ge, Bruno Rossi,
  Barbora Buhnova","CopAS: A Big Data Forensic Analytics System",,,,,"cs.CR cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the advancing digitization of our society, network security has become
one of the critical concerns for most organizations. In this paper, we present
CopAS, a system targeted at Big Data forensics analysis, allowing network
operators to comfortably analyze and correlate large amounts of network data to
get insights about potentially malicious and suspicious events. We demonstrate
the practical usage of CopAS for insider attack detection on a publicly
available PCAP dataset and show how the system can be used to detect insiders
hiding their malicious activity in the large amounts of data streams generated
during the operations of an organization within the network.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:22:41 GMT""},{""version"":""v2"",""created"":""Mon, 3 Apr 2023 08:51:18 GMT""}]","2023-04-04"
"2212.04844","Felipe Perez Stoppa","Felipe Perez Stoppa, Ester Vida\~na-Vila, Joan Navarro","Album cover art image generation with Generative Adversarial Networks",,,,,"cs.CV cs.AI cs.LG eess.IV","http://creativecommons.org/licenses/by/4.0/","  Generative Adversarial Networks (GANs) were introduced by Goodfellow in 2014,
and since then have become popular for constructing generative artificial
intelligence models. However, the drawbacks of such networks are numerous, like
their longer training times, their sensitivity to hyperparameter tuning,
several types of loss and optimization functions and other difficulties like
mode collapse. Current applications of GANs include generating photo-realistic
human faces, animals and objects. However, I wanted to explore the artistic
ability of GANs in more detail, by using existing models and learning from
them. This dissertation covers the basics of neural networks and works its way
up to the particular aspects of GANs, together with experimentation and
modification of existing available models, from least complex to most. The
intention is to see if state of the art GANs (specifically StyleGAN2) can
generate album art covers and if it is possible to tailor them by genre. This
was attempted by first familiarizing myself with 3 existing GANs architectures,
including the state of the art StyleGAN2. The StyleGAN2 code was used to train
a model with a dataset containing 80K album cover images, then used to style
images by picking curated images and mixing their styles.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:27:46 GMT""}]","2022-12-12"
"2212.04845","Jonas Bley","Jonas Bley, Vieri Mattei, Simon Goorney, Jacob Sherson, Stefan Heusler","Modelling assisted tunneling on the Bloch sphere using the Quantum
  Composer","18 pages, 10 figures, submitted to European Journal of Physics",,,,"physics.ed-ph quant-ph","http://creativecommons.org/licenses/by-sa/4.0/","  The Bloch-sphere representation is a rather simple geometric model for all
possible quantum states of a two-level system. In this article, we propose a
simple geometric model for the time dynamics of a qubit based on the
Bloch-sphere representation. The model can be applied both to time-independent
and time-dependent Hamiltonians. As explicit application, we consider time
dynamics of a particle in a double-well potential. In particular, we adopt a
recent method for off-resonant excitations, the so-called SUPER principle
(Swing-UP of the quantum emitter population) in the context of quantum
tunneling. We show that the tunneling probability can be enhanced by orders of
magnitude when an appropriate oscillation of the potential height is
introduced. Driven by a collaborative approach we call educator-developer
dialogue, an updated version of the software Quantum Composer is presented.
Here it is used for educational purposes, to map the two lowest energy states
of the 1D-Schr\""odinger equation to the Bloch sphere representation, leading to
a rather clear and intuitive physical picture for the pertinent time dynamics.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:27:51 GMT""},{""version"":""v2"",""created"":""Tue, 13 Dec 2022 15:55:45 GMT""}]","2022-12-14"
"2212.04846","Ping Jin","Lei Wang and Ping Jin","The uniqueness of vertex pairs in $\pi$-separable groups",,,,,"math.GR","http://creativecommons.org/publicdomain/zero/1.0/","  Let $G$ be a finite $\pi$-separable group, where $\pi$ is a set of primes,
and let $\chi$ be an irreducible complex character that is a $\pi$-lift of some
$\pi$-partial character of $G$.It was proved by Cossey and Lewis that all of
the vertex pairs for $\chi$ are linear and conjugate in $G$ if $2\in\pi$, but
the result can fail for $2\notin\pi$. In this paper we introduce the notion of
the twisted vertices in the case where $2\notin\pi$, and establish the
uniqueness for linear twisted vertices under the conditions that either $\chi$
is an $\mathcal N$-lift for a $\pi$-chain $\mathcal N$ of $G$ or it has a
linear Navarro vertex, thus answering a question proposed by them.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:29:43 GMT""}]","2022-12-12"
"2212.04847","Fredrik Ohlsson","Fredrik Ohlsson, Johannes G. Borgqvist, Ruth E. Baker","On the correspondence between symmetries of two-dimensional autonomous
  dynamical systems and their phase plane realisations","22 pages, 7 figures",,,,"math.DS math-ph math.DG math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the relationship between symmetries of two-dimensional autonomous
dynamical system in two common formulations; as a set of differential equations
for the derivative of each state with respect to time, and a single
differential equation in the phase plane representing the dynamics restricted
to the state space of the system. Both representations can be analysed with
respect to the symmetries of their governing differential equations, and we
establish the correspondence between the set of infinitesimal generators of the
respective formulations. Our main result is to show that every generator of a
symmetry of the autonomous system induces a well-defined vector field
generating a symmetry in the phase plane and, conversely, that every symmetry
generator in the phase plane can be lifted to a generator of a symmetry of the
original autonomous system, which is unique up to constant translations in
time. The process of lifting requires the solution of a linear partial
differential equation, which we refer to as the lifting condition. We discuss
in detail the solution of this equation in general, and exemplify the lift of
symmetries in two commonly occurring examples; a mass conserved linear model
and a non-linear oscillator model.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:34:12 GMT""}]","2022-12-12"
"2212.04848","Linxiao Wei","Shuo Gong, Yijun Hu, Linxiao Wei","Risk measurement of joint risk of portfolios: a liquidity shortfall
  aspect","45 pages, 0 figure",,,,"q-fin.RM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a novel axiomatic framework of measuring the joint risk
of a portfolio consisting of several financial positions. From the liquidity
shortfall aspect, we construct a distortion-type risk measure to measure the
joint risk of portfolios, which we referred to as multivariate distortion joint
risk measure, representing the liquidity shortfall caused by the joint risk of
portfolios. After its fundamental properties have been studied, we
axiomatically characterize it by proposing a novel set of axioms. Furthermore,
based on the representations for multivariate distortion joint risk measures,
we also propose a new class of vector-valued multivariate distortion joint risk
measures, as well as with sensible financial interpretation. Their fundamental
properties are also investigated. It turns out that this new class is large
enough, as it can not only induce new vector-valued multivariate risk measures,
but also recover some popular vector-valued multivariate risk measures known in
the literature with alternative financial interpretation. Examples are given to
illustrate the proposed multivariate distortion joint risk measures. This paper
mainly gives some theoretical results, helping one to have an insight look at
the measurement of joint risk of portfolios.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:34:40 GMT""}]","2022-12-12"
"2212.04849","Henry Soldano","Henry Soldano, Guillaume Santini, Stella Zevio","Closed pattern mining of interval data and distributional data","15p",,,,"cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss pattern languages for closed pattern mining and learning of
interval data and distributional data. We first introduce pattern languages
relying on pairs of intersection-based constraints or pairs of inclusion based
constraints, or both, applied to intervals. We discuss the encoding of such
interval patterns as itemsets thus allowing to use closed itemsets mining and
formal concept analysis programs. We experiment these languages on clustering
and supervised learning tasks. Then we show how to extend the approach to
address distributional data.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:35:20 GMT""}]","2022-12-12"
"2212.04850","Arthur Sousa De Sena","Arthur S. de Sena, Pedro H. J. Nardelli, Daniel B. da Costa, Petar
  Popovski, Constantinos B. Papadias, Merouane Debbah","RSMA for Dual-Polarized Massive MIMO Networks: A SIC-Free Approach","arXiv admin note: substantial text overlap with arXiv:2211.00851",,,,"eess.SP","http://creativecommons.org/licenses/by-sa/4.0/","  Aiming at overcoming practical issues of successive interference cancellation
(SIC), this paper proposes a dual-polarized rate-splitting multiple access
(RSMA) technique for a downlink massive multiple-input multiple-output (MIMO)
network. By modeling the effects of polarization interference, an in-depth
theoretical analysis is carried out, in which we derive tight closed-form
approximations for the outage probabilities and ergodic sum-rates. Simulation
results validate the accuracy of the theoretical analysis and confirm the
effectiveness of the proposed approach. For instance, under low to moderate
cross-polar interference, our results show that the proposed dual-polarized
MIMO-RSMA strategy outperforms the single-polarized MIMO-RSMA counterpart for
all considered levels of residual SIC error.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:38:42 GMT""}]","2022-12-12"
"2212.04851","Ian Vidamour","Dan A Allwood, Matthew O A Ellis, David Griffin, Thomas J Hayward,
  Luca Manneschi, Mohammad F KH Musameh, Simon O'Keefe, Susan Stepney, Charles
  Swindells, Martin A Trefzer, Eleni Vasilaki, Guru Venkat, Ian Vidamour, and
  Chester Wringe","A perspective on physical reservoir computing with nanomagnetic devices",,,"10.1063/5.0119040",,"cs.ET cs.LG physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Neural networks have revolutionized the area of artificial intelligence and
introduced transformative applications to almost every scientific field and
industry. However, this success comes at a great price; the energy requirements
for training advanced models are unsustainable. One promising way to address
this pressing issue is by developing low-energy neuromorphic hardware that
directly supports the algorithm's requirements. The intrinsic non-volatility,
non-linearity, and memory of spintronic devices make them appealing candidates
for neuromorphic devices. Here we focus on the reservoir computing paradigm, a
recurrent network with a simple training algorithm suitable for computation
with spintronic devices since they can provide the properties of non-linearity
and memory. We review technologies and methods for developing neuromorphic
spintronic devices and conclude with critical open issues to address before
such devices become widely used.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:43:21 GMT""}]","2023-02-08"
"2212.04852","Richard Qiu","Richard Qiu, Angelo Ricarte, Ramesh Narayan, George N. Wong, Andrew
  Chael, Daniel Palumbo","Using Machine Learning to Link Black Hole Accretion Flows with Spatially
  Resolved Polarimetric Observables","24 pages, 27 figures",,"10.1093/mnras/stad466",,"astro-ph.HE astro-ph.GA astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  We introduce a new library of 535,194 model images of the supermassive black
holes and Event Horizon Telescope (EHT) targets Sgr A* and M87*, computed by
performing general relativistic radiative transfer calculations on general
relativistic magnetohydrodynamics simulations. Then, to infer underlying black
hole and accretion flow parameters (spin, inclination, ion-to-electron
temperature ratio, and magnetic field polarity), we train a random forest
machine learning model on various hand-picked polarimetric observables computed
from each image. Our random forest is capable of making meaningful predictions
of spin, inclination, and the ion-to-electron temperature ratio, but has more
difficulty inferring magnetic field polarity. To disentangle how physical
parameters are encoded in different observables, we apply two different metrics
to rank the importance of each observable at inferring each physical parameter.
Details of the spatially resolved linear polarization morphology stand out as
important discriminators between models. Bearing in mind the theoretical
limitations and incompleteness of our image library, for the real M87* data,
our machinery favours high-spin retrograde models with large ion-to-electron
temperature ratios. Due to the time-variable nature of these targets, repeated
polarimetric imaging will further improve model inference as the EHT and
next-generation (EHT) continue to develop and monitor their targets.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:46:12 GMT""},{""version"":""v2"",""created"":""Thu, 9 Feb 2023 17:50:50 GMT""}]","2023-02-22"
"2212.04853","Andreas Athenodorou Apostolou","Andreas Athenodorou, Ed Bennett, Julian Lenz and Elli Papadopoullou","Open Science in Lattice Gauge Theory community","10 pages, 7 figures, Proceedings of the 39th International Symposium
  on Lattice Field Theory (Lattice2022), 8-13 August, 2022, Bonn, Germany",,,,"hep-lat physics.soc-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Open science aims to make scientific research processes, tools and results
accessible to all scientific communities, creating trust in science and
enabling digital competences to be realized in research, leading to increased
innovation. It provides standard and transparent pathways to conducting
research and fosters best practices for collecting, analysing, preserving,
sharing and reusing data, software, workflows and other outputs through
collaborative networks. Open Science appears to be becoming the norm with its
applications spanning throughout the whole research cycle of a project. The
importance of making Open Science a reality is nowadays reflected in funding
policies, research infrastructure and politics. In these proceedings we present
the basic Open Science principles explaining briefly best practices for
materialising Open Science. Subsequently, we present the results of the
landscaping survey of Open Science in the Lattice Gauge Theories community.
Finally, we provide directions in which the Lattice Gauge Theory community
could move in order to enhance Openness and FAIRness (Findability,
Accessibility, Interoperability, Reusability) in Science.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:46:20 GMT""}]","2022-12-12"
"2212.04854","Birgit Vogel-Heuser Prof. Dr.-Ing.","Daniel Regulin, Thomas Aicher and Birgit Vogel-Heuser","Improving transferability between different engineering stages in the
  development of automated material flow modules","11 pages, https://ieeexplore.ieee.org/abstract/document/7499821/","IEEE Transactions on Automation Science and Engineering 13 (2016)
  4","10.1109/TASE.2016.2576022",,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  For improving flexibility and robustness of the engineering of automated
production systems (aPS) in case of extending, reducing or modifying parts,
several approaches propose an encapsulation and clustering of related
functions, e.g. from the electrical, mechanical or software engineering, based
on a modular architecture. Considering the development of these modules, there
are different stages, e.g. module planning or functional engineering, which
have to be completed. A reference model that addresses the different stages for
the engineering of aPS is proposed by AutomationML. Due to these different
stages and the integration of several engineering disciplines, e.g. mechanical,
electrical/electronic or software engineering, information not limited to one
discipline are stored redundantly increasing the effort to transfer information
and the risk of inconsistency. Although, data formats for the storage and
exchange of plant engineering information exist, e.g. AutomationML, fixed
domain specific structures and relations of the information, e.g. for automated
material flow systems (aMFS), are missing. This paper presents the integration
of a meta model into the development of modules for aMFS to improve the
transferability and consistency of information between the different
engineering stages and the increasing level of detail from the coarse-grained
plant planning to the fine-grained functional engineering.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:50:52 GMT""}]","2022-12-12"
"2212.04855","Dietmar Bauer","Dietmar Bauer and Sebastian B\""uscher and Manuel Batram","Non-parametric estimation of mixed discrete choice models","Paper presented at the International Choice Modelling Conference
  (ICMC2019) in Kobe, Japan",,,,"stat.ME math.ST stat.TH","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this paper, different strands of literature are combined in order to
obtain algorithms for semi-parametric estimation of discrete choice models that
include the modelling of unobserved heterogeneity by using mixing distributions
for the parameters defining the preferences. The models use the theory on
non-parametric maximum likelihood estimation (NP-MLE) that has been developed
for general mixing models. The expectation-maximization (EM) techniques used in
the NP-MLE literature are combined with strategies for choosing appropriate
approximating models using adaptive grid techniques. \\ Jointly this leads to
techniques for specification and estimation that can be used to obtain a
consistent specification of the mixing distribution. Additionally, also
algorithms for the estimation are developed that help to decrease problems due
to the curse of dimensionality. \\ The proposed algorithms are demonstrated in
a small scale simulation study to be useful for the specification and
estimation of mixture models in the discrete choice context providing some
information on the specification of the mixing distribution. The simulations
document that some aspects of the mixing distribution such as the expectation
can be estimated reliably. They also demonstrate, however, that typically
different approximations to the mixing distribution lead to similar values of
the likelihood and hence are hard to discriminate. Therefore it does not appear
to be possible to reliably infer the most appropriate parametric form for the
estimated mixing distribution.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:51:21 GMT""}]","2022-12-12"
"2212.04856","Ludwig Rahm","Ludwig Rahm","Planar Regularity Structures","37 pages",,,,"math.CO math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Branched rough paths, used to solve ODEs on $\mathbb{R}$, have been
generalised in two different directions. In one direction, there are regularity
structures aimed at solving SPDEs on $\mathbb{R}$. In the other direction,
there are planarly branched rough paths to solve ODEs on homogeneous spaces.
This paper combines these two directions to construct planar regularity
structures, for (S)PDEs on homogeneous spaces.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:54:25 GMT""}]","2022-12-12"
"2212.04857","Hans Christian \""Ottinger","Hans Christian \""Ottinger","Quantum entanglement without superposition","4 pages",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Superposition states are at the origin of many paradoxes in quantum
mechanics. By unraveling the von Neumann equation for density matrices, we
develop a superposition-free formulation of quantum mechanics. Stochastic
quantum jumps are a key feature of this approach, in blatant contrast with the
continuity of the deterministic Schr\""odinger equation. We explain how quantum
entanglement arises. Our superposition-free formulation results offers a new
perspective on quantum mechanics.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:56:35 GMT""}]","2022-12-12"
"2212.04858","Friedemann Zenke","Manu Srinath Halvagal, Axel Laborieux, Friedemann Zenke","Predictor networks and stop-grads provide implicit variance
  regularization in BYOL/SimSiam",,,,,"cs.LG cs.AI cs.NE","http://creativecommons.org/licenses/by/4.0/","  Self-supervised learning (SSL) learns useful representations from unlabelled
data by training networks to be invariant to pairs of augmented versions of the
same input. Non-contrastive methods avoid collapse either by directly
regularizing the covariance matrix of network outputs or through asymmetric
loss architectures, two seemingly unrelated approaches. Here, by building on
DirectPred, we lay out a theoretical framework that reconciles these two views.
We derive analytical expressions for the representational learning dynamics in
linear networks. By expressing them in the eigenspace of the embedding
covariance matrix, where the solutions decouple, we reveal the mechanism and
conditions that provide implicit variance regularization. These insights allow
us to formulate a new isotropic loss function that equalizes eigenvalue
contribution and renders learning more robust. Finally, we show empirically
that our findings translate to nonlinear networks trained on CIFAR-10 and
STL-10.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:56:42 GMT""}]","2022-12-12"
"2212.04859","Alexei Morozov","A.Morozov","Equating Schur Functions","3 pages",,"10.1140/epjc/s10052-023-11398-x",,"hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We wonder if there is a way to make all Schur functions in all
representations equal. This is impossible for fixed value of time variables,
but can be achieved for averages. It appears that the corresponding measure is
just Gaussian in times, which are all independent. The generating function for
the number of Young diagrams does not straightforwardly appear as a product,
but is reproduced in a non-trivial way.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:01:50 GMT""}]","2023-04-12"
"2212.04860","Maryam Reza","Maryam Reza, Farbod Faraji, Aaron Knoll","Effects of magnetic field gradient and secondary electron emission on
  instabilities and transport in an ExB plasma configuration","22 pages, 24 figures. This article has been submitted to Journal of
  Applied Physics","Journal of Applied Physics 133(12), 2023","10.1063/5.0138223",,"physics.plasm-ph physics.comp-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Today, partially magnetized low-temperature plasmas (LTP) in an ExB
configuration, where the applied magnetic field is perpendicular to the
self-consistent electric field, have important industrial applications. Hall
thrusters, a type of electrostatic plasma propulsion, are one of the main LTP
technologies whose advancement is hindered by the not-fully-understood
underlying physics of operation, particularly, with respect to the plasma
instabilities and the associated electron cross-field transport. The
development of Hall thrusters with unconventional magnetic field topologies has
imposed further questions regarding the instabilities' characteristics and the
electrons' dynamics in these modern cross-field configurations. Accordingly, we
present in this effort a series of studies on the influence of four factors on
the plasma processes in the radial-azimuthal coordinates of a Hall thruster,
namely, the magnetic field gradient, Secondary Electron Emission,
electron-neutral collisions, and plasma number density. The studies are carried
out using the reduced-order particle-in-cell (PIC) code developed by the
authors. The setup of the radial-azimuthal simulations largely follows a
well-defined benchmark case from the literature in which the magnetic field is
oriented along the radius and a constant axial electric field is applied
perpendicular to the simulation plane. The salient finding from our
investigations is that, in the studied cases corresponding to elevated plasma
densities, an inverse energy cascade leads to the formation of a
long-wavelength, high-frequency azimuthal mode. Moreover, in the presence of
strong magnetic field gradients, this mode is fully developed and induces a
significant electron cross-field transport as well as a notable heating of the
ion population.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:03:43 GMT""}]","2023-04-04"
"2212.04861","Maciej Capinski","Maciej J. Capi\'nski, Bernd Krauskopf, Hinke M. Osinga, Piotr
  Zgliczy\'nski","Characterising blenders via covering relations and cone conditions","29 pages, 15 figures",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A blender is an invariant hyperbolic set of a diffeomorphism with the
property that its stable or unstable manifold has a dimension larger than
expected from the underlying hyperbolic splitting. We present a
characterisation of a blender based on the correct topological alignment of
sets in combination with the propagation of cones. It is applicable to
multidimensional blenders in ambient phase spaces of any dimension. The
required conditions can be verified by checking properties of a single iterate
of the diffeomorphism, which is achieved by positioning the required sets in
such a way that they form a suitable sequence of coverings. This setup is
flexible and allows for a rigorous, interval arithmetic based, computer
assisted validation. As a demonstration, we apply our approach to obtain a
computer-assisted proof of the existence of a blender in a three-dimensional
H{\'e}non-like family of diffeomorphisms over a considerable range of the
relevant parameter.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:04:09 GMT""}]","2022-12-12"
"2212.04862","Cyril Labb\'e","Laure Dumaz and Cyril Labb\'e","Anderson localization for the $1$-d Schr\""odinger operator with white
  noise potential","42 pages",,,,"math.PR cond-mat.stat-mech math-ph math.MP math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the random Schr\""odinger operator on $\mathbb{R}$ obtained by
perturbing the Laplacian with a white noise. We prove that Anderson
localization holds for this operator: almost surely the spectral measure is
pure point and the eigenfunctions are exponentially localized. We give two
separate proofs of this result. We also present a detailed construction of the
operator and relate it to the parabolic Anderson model. Finally, we discuss the
case where the noise is smoothed out.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:04:49 GMT""}]","2022-12-12"
"2212.04863","Yang-Hao Chan","Y.-H. Chan, Hong-Chen Jiang, Y.-C. Chen","Plaquette valence bond state in spin-1/2 J1-J2 XY model on square
  lattice","7 pages, 5 figures",,,,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We studied the ground state phase diagram of spin-1/2 J1-J2 XY model on the
square lattice with first- J1 and second-neighbor J2 antiferromagnetic
interactions using both iDMRG and DMRG approaches. We show that a plaquette
valence bond phase is realized in an intermediate region 0.50 <= J2/J1 <= 0.54
between a N\'eel magnetic ordered phase at J2/J1 < 0.50 and a stripy magnetic
ordered phase at J2/J1 >= 0.54. The plaquette valence bond phase is
characterized by finite dimer orders in both the horizontal and vertical
directions. Contrary to the spin-1/2 J1-J2 Heisenberg model, we do not find
numerical evidence for a quantum spin liquid phase in the J1-J2 XY model.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:10:41 GMT""}]","2022-12-12"
"2212.04864","Rawshan Ara Mowri","Rawshan Ara Mowri, Madhuri Siddula, Kaushik Roy","A Comparative Performance Analysis of Explainable Machine Learning
  Models With And Without RFECV Feature Selection Technique Towards Ransomware
  Classification","arXiv admin note: text overlap with arXiv:2210.11235",,,,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  Ransomware has emerged as one of the major global threats in recent days. The
alarming increasing rate of ransomware attacks and new ransomware variants
intrigue the researchers in this domain to constantly examine the
distinguishing traits of ransomware and refine their detection or
classification strategies. Among the broad range of different behavioral
characteristics, the trait of Application Programming Interface (API) calls and
network behaviors have been widely utilized as differentiating factors for
ransomware detection, or classification. Although many of the prior approaches
have shown promising results in detecting and classifying ransomware families
utilizing these features without applying any feature selection techniques,
feature selection, however, is one of the potential steps toward an efficient
detection or classification Machine Learning model because it reduces the
probability of overfitting by removing redundant data, improves the model's
accuracy by eliminating irrelevant features, and therefore reduces training
time. There have been a good number of feature selection techniques to date
that are being used in different security scenarios to optimize the performance
of the Machine Learning models. Hence, the aim of this study is to present the
comparative performance analysis of widely utilized Supervised Machine Learning
models with and without RFECV feature selection technique towards ransomware
classification utilizing the API call and network traffic features. Thereby,
this study provides insight into the efficiency of the RFECV feature selection
technique in the case of ransomware classification which can be used by peers
as a reference for future work in choosing the feature selection technique in
this domain.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:10:54 GMT""}]","2022-12-12"
"2212.04865","Pavel Loskot","Yue Yu and Pavel Loskot","Polynomial Distributions and Transformations","21 pages, no figures",,,,"cs.IT math.IT math.PR","http://creativecommons.org/licenses/by/4.0/","  Polynomials are common algebraic structures, which are often used to
approximate functions including probability distributions. This paper proposes
to directly define polynomial distributions in order to describe stochastic
properties of systems rather than to assume polynomials for only approximating
known or empirically estimated distributions. Polynomial distributions offer a
great modeling flexibility, and often, also mathematical tractability. However,
unlike canonical distributions, polynomial functions may have non-negative
values in the interval of support for some parameter values, the number of
their parameters is usually much larger than for canonical distributions, and
the interval of support must be finite. In particular, polynomial distributions
are defined here assuming three forms of polynomial function. The
transformation of polynomial distributions and fitting a histogram to a
polynomial distribution are considered. The key properties of polynomial
distributions are derived in closed-form. A piecewise polynomial distribution
construction is devised to ensure that it is non-negative over the support
interval. Finally, the problems of estimating parameters of polynomial
distributions and generating polynomially distributed samples are also studied.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:12:41 GMT""}]","2022-12-12"
"2212.04866","Kai Lagemann","Kai Lagemann, Christian Lagemann, Bernd Taschler, Sach Mukherjee","Deep Learning of Causal Structures in High Dimensions",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-sa/4.0/","  Recent years have seen rapid progress at the intersection between causality
and machine learning. Motivated by scientific applications involving
high-dimensional data, in particular in biomedicine, we propose a deep neural
architecture for learning causal relationships between variables from a
combination of empirical data and prior causal knowledge. We combine
convolutional and graph neural networks within a causal risk framework to
provide a flexible and scalable approach. Empirical results include linear and
nonlinear simulations (where the underlying causal structures are known and can
be directly compared against), as well as a real biological example where the
models are applied to high-dimensional molecular data and their output compared
against entirely unseen validation experiments. These results demonstrate the
feasibility of using deep learning approaches to learn causal networks in
large-scale problems spanning thousands of variables.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:12:47 GMT""}]","2022-12-12"
"2212.04867","Serena Giardiello","Luca Caloni, Serena Giardiello, Margherita Lembo, Martina Gerbino,
  Giulia Gubitosi, Massimiliano Lattanzi, Luca Pagano","Probing Lorentz-violating electrodynamics with CMB polarization",,"JCAP03(2023)018","10.1088/1475-7516/2023/03/018",,"astro-ph.CO gr-qc hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We perform a comprehensive study of the signatures of Lorentz violation in
electrodynamics on the Cosmic Microwave Background (CMB) anisotropies. In the
framework of the minimal Standard Model Extension (SME), we consider effects
generated by renormalizable operators, both CPT-odd and CPT-even. These
operators are responsible for sourcing, respectively, cosmic birefringence and
circular polarization. We propagate jointly the effects of all the relevant
Lorentz-violating parameters to CMB observables and provide constraints with
the most recent CMB datasets. We bound the CPT-even coefficient to $k_{F,E+B} <
2.31 \times 10^{-31}$ at 95\% CL. This improves previous CMB bounds by one
order of magnitude. The limits we obtain on the CPT-odd coefficients, i.e.
$|k_{(V)00}^{(3)}| < 1.54 \times 10^{-44} \; {\rm GeV}$ and $|\mathbf{k_{AF}}|
< 0.74 \times 10^{-44} \; {\rm GeV}$ at 95\% CL, are respectively one and two
orders of magnitude stronger than previous CMB-based limits, superseding also
bounds from non-CMB searches. This analysis provides the strongest constraints
to date on CPT-violating coefficients in the minimal SME from CMB searches.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:14:18 GMT""},{""version"":""v2"",""created"":""Mon, 13 Mar 2023 09:56:21 GMT""}]","2023-03-14"
"2212.04868","Hichem Sahbi","Sebastien Deschamps and Hichem Sahbi","Frugal Reinforcement-based Active Learning","arXiv admin note: text overlap with arXiv:2203.11564",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most of the existing learning models, particularly deep neural networks, are
reliant on large datasets whose hand-labeling is expensive and time demanding.
A current trend is to make the learning of these models frugal and less
dependent on large collections of labeled data. Among the existing solutions,
deep active learning is currently witnessing a major interest and its purpose
is to train deep networks using as few labeled samples as possible. However,
the success of active learning is highly dependent on how critical are these
samples when training models. In this paper, we devise a novel active learning
approach for label-efficient training. The proposed method is iterative and
aims at minimizing a constrained objective function that mixes diversity,
representativity and uncertainty criteria. The proposed approach is
probabilistic and unifies all these criteria in a single objective function
whose solution models the probability of relevance of samples (i.e., how
critical) when learning a decision function. We also introduce a novel
weighting mechanism based on reinforcement learning, which adaptively balances
these criteria at each training iteration, using a particular stateless
Q-learning model. Extensive experiments conducted on staple image
classification data, including Object-DOTA, show the effectiveness of our
proposed model w.r.t. several baselines including random, uncertainty and flat
as well as other work.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:17:45 GMT""}]","2022-12-12"
"2212.04869","Kaixuan Lu","Kaixuan Lu and Xiao Huang","RCDT: Relational Remote Sensing Change Detection with Transformer","18 pages, 11 figures,",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning based change detection methods have received wide attentoion,
thanks to their strong capability in obtaining rich features from images.
However, existing AI-based CD methods largely rely on three
functionality-enhancing modules, i.e., semantic enhancement, attention
mechanisms, and correspondence enhancement. The stacking of these modules leads
to great model complexity. To unify these three modules into a simple pipeline,
we introduce Relational Change Detection Transformer (RCDT), a novel and simple
framework for remote sensing change detection tasks. The proposed RCDT consists
of three major components, a weight-sharing Siamese Backbone to obtain
bi-temporal features, a Relational Cross Attention Module (RCAM) that
implements offset cross attention to obtain bi-temporal relation-aware
features, and a Features Constrain Module (FCM) to achieve the final refined
predictions with high-resolution constraints. Extensive experiments on four
different publically available datasets suggest that our proposed RCDT exhibits
superior change detection performance compared with other competing methods.
The therotical, methodogical, and experimental knowledge of this study is
expected to benefit future change detection efforts that involve the cross
attention mechanism.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:21:42 GMT""}]","2022-12-12"
"2212.04870","Fabian Mockert","Fabian Mockert, Christian M. Grams, Tom Brown, Fabian Neumann","Meteorological conditions during Dunkelflauten in Germany:
  Characteristics, the role of weather regimes and impacts on demand","20pages, 11figures, submitted to ""Meteorological Applications"" by
  Royal Meteorological Society
  (https://rmets.onlinelibrary.wiley.com/journal/14698080)",,,,"physics.ao-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Renewable generation from wind and solar power is strongly weather-dependent.
To plan future sustainable energy systems that are robust to this variability,
a better understanding of why and when periods of low wind and solar power
output occur is valuable. We call such periods of low wind and solar power
output `Dunkelflauten', the German word for dark wind lulls. In this article,
we analyse the meteorological conditions during Dunkelflauten in Germany by
applying the concept of weather regimes. Weather regimes are quasi-stationary,
recurrent, and persistent large-scale circulation patterns which explain
multi-day atmospheric variability (5-15 days). We use a regime definition that
allows us to distinguish four different types of blocked regimes, characterised
by high pressure situations in the North Atlantic-European region. We find that
in Germany, Dunkelflauten mainly occur in winter when the solar power output is
anyway low and when the wind power output drops for several consecutive days. A
high-pressure system over Germany, associated with the European Blocking
regime, is responsible for most of the Dunkelflauten. Dunkelflauten during the
Greenland Blocking regime are associated with colder temperatures than usual,
causing higher electricity demand and presenting a particular challenge as
space heating demand electrifies in future. Furthermore, we show that
Dunkelflauten occur predominantly when a weather regime is well-established and
persists longer than usual. Our study provides novel insight on the occurrence
and meteorological characteristics of Dunkelflauten, which is essential for
planning resilient energy systems and supporting grid operators to prepare for
potential shortages in supply.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:23:04 GMT""}]","2022-12-12"
"2212.04871","Yannic Neuhaus","Yannic Neuhaus, Maximilian Augustin, Valentyn Boreiko, Matthias Hein","Spurious Features Everywhere -- Large-Scale Detection of Harmful
  Spurious Features in ImageNet",,,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Benchmark performance of deep learning classifiers alone is not a reliable
predictor for the performance of a deployed model. In particular, if the image
classifier has picked up spurious features in the training data, its
predictions can fail in unexpected ways. In this paper, we develop a framework
that allows us to systematically identify spurious features in large datasets
like ImageNet. It is based on our neural PCA components and their
visualization. Previous work on spurious features of image classifiers often
operates in toy settings or requires costly pixel-wise annotations. In
contrast, we validate our results by checking that presence of the harmful
spurious feature of a class is sufficient to trigger the prediction of that
class. We introduce a novel dataset ""Spurious ImageNet"" and check how much
existing classifiers rely on spurious features.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:23:25 GMT""}]","2022-12-12"
"2212.04872","Zeng Yijie","Yijie Zeng, Dao-Xin Yao and Man-Rong Li","An \textit{ab initio} study of magnetic structure transitions of
  FePS$_3$ under high pressure",,"Phys.Rev.B 106, 214408 (2022)","10.1103/PhysRevB.106.214408",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent experimental work shows that FePS$_3$ undergoes phase transitions from
$C2/m$ ($\beta\sim107^{\circ}$) to $C2/m$ ($\beta\sim90^{\circ}$) at $6$ GPa
and then to metallic $P\bar{3}1m$ at $14$ GPa, with the magnetic ordering wave
vector turning from $k=(01\frac{1}{2})$ to $k=(010)$ at $2$ GPa and to
short-range magnetic order accompanying the insulator-metal transition. By
preserving the magnetic point groups in $ab \ initio$ calculations we report
the following: (1) We successfully reproduce the first magnetic structure
transition at $1.2$ GPa and briefly discuss the influence of the Hubbard U
parameter on this transition. This isostructural transition causes a change of
the Brillouin zone from base-centered monoclinic to primitive monoclinic, and
an indrect band gap to direct band gap transition. (2) There is a rotation of
the Fe-S octahedron about $0.5^\circ$ through the $[001]$ axis before the
neighboring layers shift. (3) The shift between neighboring layers is predicted
to occur at $10.0$ GPa and reverses the energy order between $d_{x^2-y^2}$ and
$d_{xy}$. (4) A sudden decrease of Fe-S bond length to $2.20$ \AA \ accompanies
the vanishing of magnetic moment in the insulator-metal transition. Our work
shows the importance of symmetries of magnetic structures in pressure-induced
phase transition of magnetic systems.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:23:26 GMT""}]","2022-12-12"
"2212.04873","Xinzhe Ni","Xinzhe Ni, Hao Wen, Yong Liu, Yatai Ji, Yujiu Yang","Multimodal Prototype-Enhanced Network for Few-Shot Action Recognition",,,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Current methods for few-shot action recognition mainly fall into the metric
learning framework following ProtoNet. However, they either ignore the effect
of representative prototypes or fail to enhance the prototypes with multimodal
information adequately. In this work, we propose a novel Multimodal
Prototype-Enhanced Network (MORN) to use the semantic information of label
texts as multimodal information to enhance prototypes, including two modality
flows. A CLIP visual encoder is introduced in the visual flow, and visual
prototypes are computed by the Temporal-Relational CrossTransformer (TRX)
module. A frozen CLIP text encoder is introduced in the text flow, and a
semantic-enhanced module is used to enhance text features. After inflating,
text prototypes are obtained. The final multimodal prototypes are then computed
by a multimodal prototype-enhanced module. Besides, there exist no evaluation
metrics to evaluate the quality of prototypes. To the best of our knowledge, we
are the first to propose a prototype evaluation metric called Prototype
Similarity Difference (PRIDE), which is used to evaluate the performance of
prototypes in discriminating different categories. We conduct extensive
experiments on four popular datasets. MORN achieves state-of-the-art results on
HMDB51, UCF101, Kinetics and SSv2. MORN also performs well on PRIDE, and we
explore the correlation between PRIDE and accuracy.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:24:39 GMT""}]","2022-12-12"
"2212.04874","Isma\""el Septembre","I. Septembre, D. D. Solnyshkov, G. Malpuech","Angular-dependent Andreev reflection on a polaritonic superfluid",,,,,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study analytically an analog of the Andreev reflection at a
normal-superfluid interface. The polariton gapped superfluid region is achieved
by quasi-resonant optical pumping. The interacting polaritons are described
with the driven-dissipative Gross-Pitaevskii equation. We find analytical
formulas for the angles and amplitudes of the reflected and transmitted
particles. There are limit angles and energies, above which Andreev
reflection/transmission cannot be observed anymore and where the Andreev wave
becomes a surface mode, exponentially localized on the interface. These
properties are confirmed by solving numerically the Gross-Pitaevskii equation
in simulations reproducing realistic experimental conditions.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:25:58 GMT""}]","2022-12-12"
"2212.04875","Minh-Long Luu","Minh-Long Luu and Zeyi Huang and Eric P. Xing and Yong Jae Lee and
  Haohan Wang","Expeditious Saliency-guided Mix-up through Random Gradient Thresholding","Accepted Long paper at 2nd Practical-DL Workshop at AAAI 2023. V2 fix
  typo",,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by-sa/4.0/","  Mix-up training approaches have proven to be effective in improving the
generalization ability of Deep Neural Networks. Over the years, the research
community expands mix-up methods into two directions, with extensive efforts to
improve saliency-guided procedures but minimal focus on the arbitrary path,
leaving the randomization domain unexplored. In this paper, inspired by the
superior qualities of each direction over one another, we introduce a novel
method that lies at the junction of the two routes. By combining the best
elements of randomness and saliency utilization, our method balances speed,
simplicity, and accuracy. We name our method R-Mix following the concept of
""Random Mix-up"". We demonstrate its effectiveness in generalization, weakly
supervised object localization, calibration, and robustness to adversarial
attacks. Finally, in order to address the question of whether there exists a
better decision protocol, we train a Reinforcement Learning agent that decides
the mix-up policies based on the classifier's performance, reducing dependency
on human-designed objectives and hyperparameter tuning. Extensive experiments
further show that the agent is capable of performing at the cutting-edge level,
laying the foundation for a fully automatic mix-up. Our code is released at
[https://github.com/minhlong94/Random-Mixup].
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:29:57 GMT""},{""version"":""v2"",""created"":""Sat, 17 Dec 2022 11:13:29 GMT""}]","2022-12-20"
"2212.04876","Katarzyna Siudzi\'nska","Katarzyna Siudzi\'nska and Micha{\l} Studzi\'nski","Enhancing phase-covariant channel performance with non-unitality",,"J. Phys. A: Math. Theor. 56, 205301 (2023)","10.1088/1751-8121/acccbf",,"quant-ph math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze quantum communication properties of phase-covariant channels
depending on their degree of non-unitality. In particular, we derive analytical
formulas for minimal and maximal channel fidelity on pure states and maximal
output purity. Next, we introduce a measure of non-unitality and show how to
manipulate between unital and maximally non-unital maps by considering
classical mixtures of quantum channels. Finally, we prove that maximal fidelity
and maximal output purity increase with non-unitality and present several
examples. Interestingly, non-unitality can also prolong quantum entanglement
and lead to its rebirth.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:31:19 GMT""}]","2023-05-03"
"2212.04877","Ivano Malavolta","Robert Bocchino, Arne Nordmann, Allison Thackston, Andreas Angerer,
  Federico Ciccozzi, Ivano Malavolta, Andreas Wortmann","Industry Best Practices in Robotics Software Engineering","10 pages, 0 figures",,,,"cs.SE cs.RO","http://creativecommons.org/licenses/by/4.0/","  Robotics software is pushing the limits of software engineering practice. The
3rd International Workshop on Robotics Software Engineering held a panel on
""the best practices for robotic software engineering"". This article shares the
key takeaways that emerged from the discussion among the panelists and the
workshop, ranging from architecting practices at the NASA/Caltech Jet
Propulsion Laboratory, model-driven development at Bosch, development and
testing of autonomous driving systems at Waymo, and testing of robotics
software at XITASO. Researchers and practitioners can build on the contents of
this paper to gain a fresh perspective on their activities and focus on the
most pressing practices and challenges in developing robotics software today.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:31:44 GMT""}]","2022-12-12"
"2212.04878","Birgit Vogel-Heuser Prof. Dr.-Ing.","Maria Witsch and Birgit Vogel-Heuser","Towards a Formal Specification Framework for Manufacturing Execution
  Systems","10 pages, https://ieeexplore.ieee.org/abstract/document/6145656","IEEE Transactions on Industrial Informatics 8 (2012) 2","10.1109/TII.2012.2186585",,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Manufacturing Execution Systems (MES) optimize production and business
processes at the same time. However, the engineering and specification of MES
is a challenging, interdisciplinary process. Especially IT and production
experts with different views and background have to cooperate. For successful
and efficient MES software projects, misunderstandings in the specification
process have to be avoided. Therefore, textual specifications need to be
complemented by unambiguous graphical models, reducing the complexity by
integrating interdisciplinary views and domain specific terms based on
different background knowledge. Today's modeling notations focus on the
detailed modeling of a certain domain specific problem area. They do not
support interdisciplinary discussion adequately. To bridge this gap a novel MES
Modeling Language (MES-ML) integrating all necessary views important for MES
and pointing out their interdependencies has been developed. Due to its formal
basis, comparable and consistent MES-models can be created for specification,
standardization, testing, and documentation of MES software. In this paper, the
authors present the formal basis of the modeling language and its core
notation. The application of MES-ML is demonstrated taking a yogurt production
as an example. Finally, the authors give some evaluation results that underline
the effectiveness and efficiency of this new modeling approach with reference
to four applications in industrial MES-projects in the domain of discrete and
hybrid manufacturing.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:33:32 GMT""}]","2022-12-12"
"2212.04879","Jean-Michel Coron","Georges Bastin, Jean-Michel Coron, Amaury Hayat","Diffusion and robustness of boundary feedback stabilization of
  hyperbolic systems","21 pages",,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  We consider the problem of boundary feedback control of
single-input-single-output (SISO) one-dimensional linear hyperbolic systems
when sensing and actuation are anti-located. The main issue of the output
feedback stabilization is that it requires dynamic control laws that include
delayed values of the output (directly or through state observers) which may
not be robust to infinitesimal uncertainties on the characteristic velocities.
The purpose of this paper is to highlight some features of this problem by
addressing the feedback stabilization of an unstable open-loop system which is
made up of two interconnected transport equations and provided with
anti-located boundary sensing and actuation. The main contribution is to show
that the robustness of the control against delay uncertainties is recovered as
soon as an arbitrary small diffusion is present in the system. Our analysis
also reveals that the effect of diffusion on stability is far from being an
obvious issue by exhibiting an alternative simple example where the presence of
diffusion has a destabilizing effect instead.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:33:38 GMT""}]","2022-12-12"
"2212.04880","Guozhen Rong","Guozhen Rong, Yongjie Yang, Wenjun Li","A Polynomial-Time Algorithm for MCS Partial Search Order on Chordal
  Graphs","12 pages",,,,"cs.DS cs.DM math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the partial search order problem (PSOP) proposed recently by
Scheffler [WG 2022]. Given a graph $G$ together with a partial order over the
vertices of $G$, this problem determines if there is an $\mathcal{S}$-ordering
that is consistent with the given partial order, where $\mathcal{S}$ is a graph
search paradigm like BFS, DFS, etc. This problem naturally generalizes the
end-vertex problem which has received much attention over the past few years.
It also generalizes the so-called ${\mathcal{F}}$-tree recognition problem
which has just been studied in the literature recently. Our main contribution
is a polynomial-time dynamic programming algorithm for the PSOP on chordal
graphs with respect to the maximum cardinality search (MCS). This resolves one
of the most intriguing open questions left in the work of Sheffler [WG 2022].
To obtain our result, we propose the notion of layer structure and study
numerous related structural properties which might be of independent interest.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:33:56 GMT""},{""version"":""v2"",""created"":""Thu, 19 Jan 2023 04:29:27 GMT""}]","2023-01-20"
"2212.04881","Aref Einizade","Aref Einizade, Samaneh Nasiri, Sepideh Hajipour Sardouie, Gari
  Clifford","ProductGraphSleepNet: Sleep Staging using Product Spatio-Temporal Graph
  Learning with Attentive Temporal Aggregation","9 pages, 6 figures",,,,"eess.SP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The classification of sleep stages plays a crucial role in understanding and
diagnosing sleep pathophysiology. Sleep stage scoring relies heavily on visual
inspection by an expert that is time consuming and subjective procedure.
Recently, deep learning neural network approaches have been leveraged to
develop a generalized automated sleep staging and account for shifts in
distributions that may be caused by inherent inter/intra-subject variability,
heterogeneity across datasets, and different recording environments. However,
these networks ignore the connections among brain regions, and disregard the
sequential connections between temporally adjacent sleep epochs. To address
these issues, this work proposes an adaptive product graph learning-based graph
convolutional network, named ProductGraphSleepNet, for learning joint
spatio-temporal graphs along with a bidirectional gated recurrent unit and a
modified graph attention network to capture the attentive dynamics of sleep
stage transitions. Evaluation on two public databases: the Montreal Archive of
Sleep Studies (MASS) SS3; and the SleepEDF, which contain full night
polysomnography recordings of 62 and 20 healthy subjects, respectively,
demonstrates performance comparable to the state-of-the-art (Accuracy:
0.867;0.838, F1-score: 0.818;0.774 and Kappa: 0.802;0.775, on each database
respectively). More importantly, the proposed network makes it possible for
clinicians to comprehend and interpret the learned connectivity graphs for
sleep stages.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:34:58 GMT""}]","2022-12-12"
"2212.04882","Michael Mislove","James Laird","Revisiting Decidable Bounded Quantification, via Dinaturality","In Mathematical Semantics of Programming Languages (MFPS) '22",,,,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  We use a semantic interpretation to investigate the problem of defining an
expressive but decidable type system with bounded quantification. Typechecking
in the widely studied System Fsub is undecidable thanks to an undecidable
subtyping relation, for which the culprit is the rule for subtyping bounded
quantification. Weaker versions of this rule, allowing decidable subtyping,
have been proposed. One of the resulting type systems (Kernel Fsub) lacks
expressiveness, another (System Fsubtop) lacks the minimal typing property and
thus has no evident typechecking algorithm.
  We consider these rules as defining distinct forms of bounded quantification,
one for interpreting type variable abstraction, and the other for type
instantiation. By giving a semantic interpretation for both in terms of
unbounded quantification, using the dinaturality of type instantiation with
respect to subsumption, we show that they can coexist within a single type
system. This does have the minimal typing property and thus a simple
typechecking procedure.
  We consider the fragments of this unified type system over types which
contain only one form of bounded quantifier. One of these is equivalent to
Kernel Fsub, while the other can type strictly more terms than System Fsubtop
but the same set of beta-normal terms. We show decidability of typechecking for
this fragment, and thus for System Fsubtop typechecking of beta-normal terms.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:35:53 GMT""},{""version"":""v2"",""created"":""Mon, 12 Dec 2022 14:22:05 GMT""},{""version"":""v3"",""created"":""Mon, 13 Feb 2023 11:50:43 GMT""},{""version"":""v4"",""created"":""Wed, 15 Feb 2023 21:31:05 GMT""},{""version"":""v5"",""created"":""Mon, 20 Feb 2023 16:06:07 GMT""}]","2023-02-21"
"2212.04883","Lucas Rickert","Lucas Rickert, Fridtjof Betz, Matthias Plock, Sven Burger, and Tobias
  Heindel","High-performance designs for fiber-pigtailed quantum-light sources based
  on quantum dots in electrically-controlled circular Bragg gratings","Main text including Method section, (15 pages, 5 figures, and 50
  references). The data sets and used code in this work is available on Zenodo
  (see reference in the main text)","Opt. Express 31, 14750 (2023)","10.1364/OE.486060",,"quant-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a numerical investigation of directly fiber-coupled hybrid
circular Bragg gratings (CBGs) featuring electrical control for operation in
the application relevant wavelength regimes around 930 nm as well as the
telecom O- and C-band. We use a surrogate model combined with a Bayesian
optimization approach to perform numerical optimization of the device
performance which takes into account robustness with respect to fabrication
tolerances. The proposed high-performance designs combine hCBGs with a
dielectric planarization and a transparent contact material, enabling >86%
direct fiber coupling efficiency (up to >93% efficiency into NA 0.8) while
exhibiting Purcell Factors >20. Especially the proposed designs for the telecom
range prove robust and can sustain expected fiber efficiencies of more than
$(82.2\pm4.1)^{+2.2}_{-5.5}$% and expected average Purcell Factors of up to
$(23.2\pm2.3)^{+3.2}_{-3.0}$ assuming conservative fabrication accuracies. The
wavelength of maximum Purcell enhancement proves to be the most affected
performance parameter by the deviations. Finally, we show that electrical field
strengths suitable for Stark-tuning of an embedded quantum dot can be reached
in the identified designs.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:37:30 GMT""}]","2023-04-21"
"2212.04884","Hugo Touvron","Hugo Touvron, Matthieu Cord, Maxime Oquab, Piotr Bojanowski, Jakob
  Verbeek, Herv\'e J\'egou","Co-training $2^L$ Submodels for Visual Recognition",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce submodel co-training, a regularization method related to
co-training, self-distillation and stochastic depth. Given a neural network to
be trained, for each sample we implicitly instantiate two altered networks,
``submodels'', with stochastic depth: we activate only a subset of the layers.
Each network serves as a soft teacher to the other, by providing a loss that
complements the regular loss provided by the one-hot label. Our approach,
dubbed cosub, uses a single set of weights, and does not involve a pre-trained
external model or temporal averaging.
  Experimentally, we show that submodel co-training is effective to train
backbones for recognition tasks such as image classification and semantic
segmentation. Our approach is compatible with multiple architectures, including
RegNet, ViT, PiT, XCiT, Swin and ConvNext. Our training strategy improves their
results in comparable settings. For instance, a ViT-B pretrained with cosub on
ImageNet-21k obtains 87.4% top-1 acc. @448 on ImageNet-val.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:38:09 GMT""}]","2022-12-12"
"2212.04885","Bal\'azs Kacskovics","Bal\'azs Kacskovics and D\'aniel Barta and M\'aty\'as Zsolt Vas\'uth","Rapidly rotating neutron stars with realistic nuclear matter equation of
  state","7 pages, 4 figures, conference proceeding",,"10.1002/asna.20220109",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We performed a comparison of three different numerical codes for constructing
equilibrium models; (I) a code for static equilibrium configurations, (II) an
implementation of the Hartle--Thorne slow-rotation approximation, (III) a
numerical solution of the full Einstein equations by \texttt{LORENE}. We aimed
to construct sequences of uniformly rotating configurations at various rotation
frequencies up to the Keplerian frequency for a hybrid hadronic--quark matter
EOS where a smooth transition is provided between two separate phases. We
investigated the difference of between the results computed by the
implementation of Hartle--Thorne slow-rotation approximation and by
\texttt{LORENE/nrotstar}, respectively. We have conclude that the codes can the
difference between the slow rotating and the fast-rotating approach increase
exponentially, reaching 6.67% for the maximal mass configuration rotating at
the Keplerian frequency.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:39:19 GMT""}]","2023-04-05"
"2212.04886","Kai Ye","Kai Ye, Hyeonjin Kim, Yi Hu, Ning Lu, Di Wu, PJ Rehm","A Modified Sequence-to-point HVAC Load Disaggregation Algorithm","To be published in the proceedings of the 2023 IEEE PES General
  Meeting",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a modified sequence-to-point (S2P) algorithm for
disaggregating the heat, ventilation, and air conditioning (HVAC) load from the
total building electricity consumption. The original S2P model is convolutional
neural network (CNN) based, which uses load profiles as inputs. We propose
three modifications. First, the input convolution layer is changed from 1D to
2D so that normalized temperature profiles are also used as inputs to the S2P
model. Second, a drop-out layer is added to improve adaptability and
generalizability so that the model trained in one area can be transferred to
other geographical areas without labelled HVAC data. Third, a fine-tuning
process is proposed for areas with a small amount of labelled HVAC data so that
the pre-trained S2P model can be fine-tuned to achieve higher disaggregation
accuracy (i.e., better transferability) in other areas. The model is first
trained and tested using smart meter and sub-metered HVAC data collected in
Austin, Texas. Then, the trained model is tested on two other areas: Boulder,
Colorado and San Diego, California. Simulation results show that the proposed
modified S2P algorithm outperforms the original S2P model and the
support-vector machine based approach in accuracy, adaptability, and
transferability.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:40:14 GMT""},{""version"":""v2"",""created"":""Sat, 25 Feb 2023 03:24:20 GMT""}]","2023-02-28"
"2212.04887","Fangyang Zheng","Yuqin Guo and Fangyang Zheng","Hermitian geometry of Lie algebras with abelian ideals of codimension
  $2$","21 pages, corrected the error in Proposition 2",,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  We examine Hermitian metrics on unimodular Lie algebras which contains a
$J$-invariant abelian ideal of codimension two, and give a classification for
all Bismut K\""ahler-like and all Bismut torsion-parallel metrics on such Lie
algebras.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:41:29 GMT""},{""version"":""v2"",""created"":""Thu, 23 Feb 2023 05:09:14 GMT""},{""version"":""v3"",""created"":""Sat, 3 Jun 2023 07:23:23 GMT""}]","2023-06-06"
"2212.04888","Fei Kong","Fei Kong","Quantum affine vertex algebras associated to untwisted quantum
  affinization algebras",,,,,"math.QA","http://creativecommons.org/licenses/by/4.0/","  Let $\mathcal U_\hbar(\hat{\mathfrak g})$ be the untwisted quantum
affinization of a symmetrizable quantum Kac-Moody algebra $\mathcal
U_\hbar({\mathfrak g})$. For $\ell\in\mathbb C$, we construct an $\hbar$-adic
quantum vertex algebra $V_{\hat{\mathfrak g},\hbar}(\ell,0)$, and establish a
one-to-one correspondence between $\phi$-coordinated $V_{\hat{\mathfrak
g},\hbar}(\ell,0)$-modules and restricted $\mathcal U_\hbar(\hat{\mathfrak
g})$-modules of level $\ell$. Suppose that $\ell$ is a positive integer. We
construct a quotient $\hbar$-adic quantum vertex algebra $L_{\hat{\mathfrak
g},\hbar}(\ell,0)$ of $V_{\hat{\mathfrak g},\hbar}(\ell,0)$, and establish a
one-to-one correspondence between certain $\phi$-coordinated $L_{\hat{\mathfrak
g},\hbar}(\ell,0)$-modules and restricted integrable $\mathcal
U_\hbar(\hat{\mathfrak g})$-modules of level $\ell$. Suppose further that
${\mathfrak g}$ is of finite type. We prove that $L_{\hat{\mathfrak
g},\hbar}(\ell,0)/\hbar L_{\hat{\mathfrak g},\hbar}(\ell,0)$ is isomorphic to
the simple affine vertex algebra $L_{\hat{\mathfrak g}}(\ell,0)$.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:42:41 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jun 2023 18:28:49 GMT""}]","2023-06-09"
"2212.04889","Graeme Stewart","Mohamed Aly, Jackson Burzynski, Bryan Cardwell, Daniel C. Craik, Tal
  van Daalen, Tomas Dado, Ayanabha Das, Antonio Delgado Peris, Caterina
  Doglioni, Peter Elmer, Engin Eren, Martin B. Eriksen, Jonas Eschle, Giulio
  Eulisse, Conor Fitzpatrick, Jos\'e Flix Molina, Alessandra Forti, Ben
  Galewsky, Sean Gasiorowski, Aman Goel, Loukas Gouskos, Enrico Guiraud,
  Kanhaiya Gupta, Stephan Hageboeck, Allison Reinsvold Hall, Lukas Heinrich,
  Alexander Held, Jos\'e M. Hern\'andez, Michel Hern\'andez Villanueva, Julius
  Hrivnac, Michel Jouvin, Teng Jian Khoo, Luke Kreczko, Nils Krumnack, Thomas
  Kuhr, Baidyanath Kundu, Eric Lancon, Johannes Lange, Paul Laycock, Kilian
  Lieret, Nicholas J. Manganelli, Pere Mato Villa, Andrzej Novak, Antonio
  Perez-Calero Yzquierdo, Jim Pivarski, Mason Proffitt, Jonas Rembser, Eduardo
  Rodrigues, Grigori Rybkin, Jana Schaarschmidt, Henry F. Schreiner, Markus
  Schulz, Andrea Sciab\`a, Sezen Sekmen, Elizabeth Sexton-Kennedy, Oksana
  Shadura, Tibor Simko, Nathan Simpson, Jaydip Singh, Nicola Skidmore, Nicholas
  Smith, Michael Sokoloff, Graeme A. Stewart, Giles C. Strong, Gokhan Unel,
  Vassil Vassilev, Mark Waterlaat, Gordon Watts, Efe Yazgan (for the HEP
  Software Foundation & IRIS-HEP)","Second Analysis Ecosystem Workshop Report",,,"10.5281/zenodo.7418818","HSF-DOC-2022-02","hep-ex","http://creativecommons.org/licenses/by/4.0/","  The second workshop on the HEP Analysis Ecosystem took place 23-25 May 2022
at IJCLab in Orsay, to look at progress and continuing challenges in scaling up
HEP analysis to meet the needs of HL-LHC and DUNE, as well as the very pressing
needs of LHC Run 3 analysis.
  The workshop was themed around six particular topics, which were felt to
capture key questions, opportunities and challenges. Each topic arranged a
plenary session introduction, often with speakers summarising the state-of-the
art and the next steps for analysis. This was then followed by parallel
sessions, which were much more discussion focused, and where attendees could
grapple with the challenges and propose solutions that could be tried. Where
there was significant overlap between topics, a joint discussion between them
was arranged.
  In the weeks following the workshop the session conveners wrote this
document, which is a summary of the main discussions, the key points raised and
the conclusions and outcomes. The document was circulated amongst the
participants for comments before being finalised here.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:42:56 GMT""}]","2022-12-12"
"2212.04890","Federico Faedo","Federico Faedo, Silke Klemm and Pietro Mariotti","Rotating black holes with Nil or SL(2,$\,\mathbb{R}$) horizons","24 pages. v2: references added. v3: minor changes, references added,
  published version. arXiv admin note: text overlap with arXiv:1401.3107 by
  other authors","JHEP 05 (2023) 138","10.1007/JHEP05(2023)138","IFUM-1104-FT","hep-th gr-qc","http://creativecommons.org/licenses/by/4.0/","  We construct rotating black holes in $N=2$, $D=5$ minimal and matter-coupled
gauged supergravity, with horizons that are homogeneous but not isotropic. Such
spaces belong to the eight Thurston model geometries, out of which we consider
the cases Nil and SL$(2,\mathbb{R})$. In the former, we use the recipe of
arXiv:hep-th/0304064 to directly rederive the solution that was obtained by
Gutowski and Reall in arXiv:hep-th/0401042 as a scaling limit from a spherical
black hole. With the same techniques, the first example of a black hole with
SL$(2,\mathbb{R})$ horizon is constructed, which is rotating and one quarter
BPS. The physical properties of this solution are discussed, and it is shown
that in the near-horizon limit it boils down to the geometry of
arXiv:hep-th/0401042, with a supersymmetry enhancement to one half. Dimensional
reduction to $D=4$ gives a new solution with hyperbolic horizon to the t$^3$
model that carries both electric and magnetic charges. Moreover, we show how to
get a nonextremal rotating Nil black hole by applying a certain scaling limit
to Kerr-AdS$_5$ with two equal rotation parameters, which consists in zooming
onto the north pole of the S$^2$ over which the S$^3$ is fibered, while
boosting the horizon velocity effectively to the speed of light.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:45:13 GMT""},{""version"":""v2"",""created"":""Thu, 19 Jan 2023 16:08:58 GMT""},{""version"":""v3"",""created"":""Tue, 23 May 2023 21:55:50 GMT""}]","2023-05-25"
"2212.04891","Xunzhu Tang","Shi Wang and Daniel Tang and Luchen Zhang and Huilin Li and Ding Han","HieNet: Bidirectional Hierarchy Framework for Automated ICD Coding",,,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  International Classification of Diseases (ICD) is a set of classification
codes for medical records. Automated ICD coding, which assigns unique
International Classification of Diseases codes with each medical record, is
widely used recently for its efficiency and error-prone avoidance. However,
there are challenges that remain such as heterogeneity, label unbalance, and
complex relationships between ICD codes. In this work, we proposed a novel
Bidirectional Hierarchy Framework(HieNet) to address the challenges.
Specifically, a personalized PageRank routine is developed to capture the
co-relation of codes, a bidirectional hierarchy passage encoder to capture the
codes' hierarchical representations, and a progressive predicting method is
then proposed to narrow down the semantic searching space of prediction. We
validate our method on two widely used datasets. Experimental results on two
authoritative public datasets demonstrate that our proposed method boosts
state-of-the-art performance by a large margin.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:51:12 GMT""}]","2022-12-12"
"2212.04892","Fabian Gittins","Fabian Gittins, Nils Andersson","The r-modes of slowly rotating, stratified neutron stars","15 pages, 8 figures. Accepted for publication in MNRAS","Mon. Not. R. Astron. Soc. 521, 3043 (2023)","10.1093/mnras/stad672",,"gr-qc astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The only r-modes that exist in a globally barotropic, rotating, Newtonian
star are the fundamental $l = |m|$ solutions, where $l$ and $m$ are the indices
of the spherical harmonic $Y_l^m$ that describe the mode's angular dependence.
This is in stark contrast to a stellar model that is non-barotropic throughout
its interior, which hosts all the $l \geq |m|$ perturbations including radial
overtones. In reality, neutron stars are stratified with locally barotropic
regions. Therefore, we explore how stratification alters a star's ability to
support r-modes. We consider the globally stratified case and examine the
behaviour of the modes as the star gets close to barotropicity. In this limit,
we find that all but the fundamental $l = |m|$ perturbations change character
and become generic inertial modes. Restricting the analysis to $l = |m|$
perturbations, we develop the r-mode equations in order to consider stellar
models that exhibit local barotropicity. Our results for such models show that
the r-mode overtones diverge and join the inertial modes. In order to see which
r-modes persist and retain their character in realistic neutron stars, these
calculations will need to be brought into full general relativity.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:51:33 GMT""},{""version"":""v2"",""created"":""Wed, 1 Mar 2023 11:08:42 GMT""}]","2023-05-23"
"2212.04893","Jiaxin Qiao","Sridip Pal, Jiaxin Qiao, Slava Rychkov","Twist accumulation in conformal field theory. A rigorous approach to the
  lightcone bootstrap","35+10 pages, 1 figure. v2: minor changes, typos corrected. v3:
  version accepted for publication by Comm.Math.Phys., with minor changes,
  typos corrected and references added",,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that in any unitary CFT, a twist gap in the spectrum of operator
product expansion (OPE) of identical scalar primary operators (i.e. $\phi\times
\phi$) implies the existence of a family of primary operators
$\mathcal{O}_{\tau, \ell}$ with spins $\ell \rightarrow \infty$ and twists
$\tau \rightarrow 2 \Delta_{\phi}$ in the same OPE spectrum. A similar
twist-accumulation result is proven for any two-dimensional Virasoro-invariant,
modular-invariant, unitary CFT with a normalizable vacuum and central charge $c
> 1$, where we show that a twist gap in the spectrum of Virasoro primaries
implies the existence of a family of Virasoro primaries $\mathcal{O}_{h,
\bar{h}}$ with $h \rightarrow \infty$ and $\bar{h} \rightarrow \frac{c -
1}{24}$ (the same is true with $h$ and $\bar{h}$ interchanged). We summarize
the similarity of the two problems and propose a general formulation of the
lightcone bootstrap.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:51:43 GMT""},{""version"":""v2"",""created"":""Wed, 28 Dec 2022 09:00:32 GMT""},{""version"":""v3"",""created"":""Wed, 17 May 2023 14:25:42 GMT""}]","2023-05-18"
"2212.04894","Sheir Yarkoni","Michele Cattelan and Sheir Yarkoni","Modeling routing problems in QUBO with application to ride-hailing",,,,,"quant-ph math.OC","http://creativecommons.org/licenses/by/4.0/","  Many emerging commercial services are based on the sharing or pooling of
resources for common use with the aim of reducing costs. Businesses such as
delivery-, mobility-, or transport-as-a-service have become standard in many
parts of the world, fulfilling on-demand requests for customers in live
settings. However, it is known that many of these problems are NP-hard, and
therefore both modeling and solving them accurately is a challenge. Here we
focus on one such routing problem, the Ride Pooling Problem (RPP), where
multiple customers can request on-demand pickups and drop-offs from shared
vehicles within a fleet. The combinatorial optimization task is to optimally
pool customer requests using the limited set of vehicles, akin to a small-scale
flexible bus route. In this work, we propose a quadratic unconstrained binary
optimization (QUBO) program and introduce efficient formulation methods for the
RPP to be solved using metaheuristics, and specifically emerging quantum
optimization algorithms.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:55:34 GMT""}]","2022-12-13"
"2212.04895","Andrei Tonkikh","Andrei Tonkikh, Pavel Ponomarev, Petr Kuznetsov, Yvonne-Anne Pignolet","CryptoConcurrency: (Almost) Consensusless Asset Transfer with Shared
  Accounts",,,,,"cs.DC","http://creativecommons.org/licenses/by/4.0/","  A typical blockchain protocol uses consensus to make sure that mutually
mistrusting users agree on the order in which their operations on shared data
are executed. However, it is known that asset transfer systems, by far the most
popular application of blockchains, can be implemented without consensus.
Assuming that no account can be accessed concurrently and every account belongs
to a single owner, one can efficiently implement an asset transfer system in a
purely asynchronous, consensus-free manner. It has also been shown that
implementing asset transfer with shared accounts is impossible without
consensus.
  In this paper, we propose CryptoConcurrency, an asset transfer protocol that
allows concurrent accesses to be processed in parallel, without involving
consensus, whenever possible. More precisely, if concurrent transfer operations
on a given account do not lead to overspending, i.e. can all be applied without
the account balance going below zero, they proceed in parallel. Otherwise, the
account's owners may have to access an external consensus object. Notably, we
avoid relying on a central, universally-trusted, consensus mechanism and allow
each account to use its own consensus implementation, which only the owners of
this account trust. This provides greater decentralization and flexibility.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:56:01 GMT""},{""version"":""v2"",""created"":""Thu, 27 Apr 2023 12:46:22 GMT""}]","2023-04-28"
"2212.04896","Philipp Mayer","Philipp Mayer and Michele Magno and Luca Benini","Self-sustaining Ultra-wideband Positioning System for Event-driven
  Indoor Localization",,,,,"eess.SY cs.SY eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Smart and unobtrusive mobile sensor nodes that accurately track their own
position have the potential to augment data collection with location-based
functions. To attain this vision of unobtrusiveness, the sensor nodes must have
a compact form factor and operate over long periods without battery recharging
or replacement. This paper presents a self-sustaining and accurate
ultra-wideband-based indoor location system with conservative infrastructure
overhead. An event-driven sensing approach allows for balancing the limited
energy harvested in indoor conditions with the power consumption of
ultra-wideband transceivers. The presented tag-centralized concept, which
combines heterogeneous system design with embedded processing, minimizes idle
consumption without sacrificing functionality. Despite modest infrastructure
requirements, high localization accuracy is achieved with error-correcting
double-sided two-way ranging and embedded optimal multilateration. Experimental
results demonstrate the benefits of the proposed system: the node achieves a
quiescent current of $47~nA$ and operates at $1.2~\mu A$ while performing
energy harvesting and motion detection. The energy consumption for position
updates, with an accuracy of $40~cm$ (2D) in realistic non-line-of-sight
conditions, is $10.84~mJ$. In an asset tracking case study within a $200~m^2$
multi-room office space, the achieved accuracy level allows for identifying 36
different desk and storage locations with an accuracy of over $95~{\%}$. The
system`s long-time self-sustainability has been analyzed over $700~days$ in
multiple indoor lighting situations.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:56:38 GMT""}]","2022-12-12"
"2212.04897","Daniel M. Kaplan","C. Gatto, C. Izzo, C. J. Johnstone, D. M. Kaplan, K. R. Lynch, D. C.
  Mancini, A. Mazzacane, B. McMorran, J. P. Miller, J. D. Phillips, T. J.
  Phillips, R. D. Reasenberg, T. J. Roberts, J. Terry","Letter of Intent: Muonium R&D/Physics Program at the MTA","3 pages, submitted to Fermilab",,,"IIT-CAPP-22-1","physics.ins-det hep-ex hep-ph","http://creativecommons.org/licenses/by/4.0/","  With the planned turn-on of the PIP-II 800 MeV superconducting proton linac,
Fermilab will potentially become the world's best laboratory at which to carry
out fundamental muon measurements, sensitive searches for symmetry violation,
and precision tests of theory. In preparation, we propose to develop the
techniques that will be needed. An R&D and physics program is proposed at the
Fermilab MeV Test Area to use the existing 400 MeV Linac to demonstrate the
efficient production of a slow muonium beam using $\mu^+$ stopped in a
~100-$\mu$m-thick layer of superfluid helium, and to use that beam to measure
muonium gravity.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:56:39 GMT""}]","2022-12-12"
"2212.04898","Dawei Wang","Xingqi Xu, Jiefei Wang, Jianhao Dai, Ruosong Mao, Han Cai, Shi-Yao
  Zhu, and Da-Wei Wang","Floquet superradiance lattices in thermal atoms","7 pages, 4 figures","Phys. Rev. Lett. 129, 273603 (2022)","10.1103/PhysRevLett.129.273603",,"cond-mat.quant-gas physics.optics quant-ph","http://creativecommons.org/licenses/by/4.0/","  Floquet modulation has been widely used in optical lattices for coherent
control of quantum gases, in particular for synthesizing artificial gauge
fields and simulating topological matters. However, such modulation induces
heating which can overwhelm the signal of quantum dynamics in ultracold atoms.
Here we report that the thermal motion, instead of being a noise source,
provides a new control knob in Floquet-modulated superradiance lattices, which
are momentum-space tight-binding lattices of collectively excited states of
atoms. The Doppler shifts combined with Floquet modulation provide effective
forces along arbitrary directions in a lattice in frequency and momentum
dimensions. Dynamic localization, dynamic delocalization and chiral edge
currents can be simultaneously observed from a single transport spectrum of
superradiance lattices in thermal atoms. Our work paves a way for simulating
Floquet topological matters in room-temperature atoms and facilitates their
applications in photonic devices.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:04:18 GMT""}]","2023-01-06"
"2212.04899","Guillermo F. Pe\~nas","Guillermo F. Pe\~nas, Ricardo Puebla and Juan Jos\'e Garc\'ia-Ripoll","Improving quantum state transfer: Correcting non-Markovian and
  distortion effects","10 pages, 5 figures",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Quantum state transfer is a key operation for quantum information processing.
The original pitch-and-catch protocols rely on flying qubits or single photons
with engineered wavepacket shapes to achieve a deterministic, fast and
high-fidelity transfer. Yet, these protocols overlook two important factors,
namely, the distortion of the wavepacket during the propagation and
non-Markovian effects during the emission and reabsorption processes due to
time-dependent controls. Here we address both difficulties in a general
quantum-optical model and propose a correction strategy to improve quantum
state transfer protocols. Including non-Markovian effects in our theoretical
description, we show how to derive control pulses that imprint phases on the
wavepacket that compensate the distortion caused by propagation. Our
theoretical results are supported by detailed numerical simulations showing
that a suitable correction strategy can improve state transfer fidelities up to
three orders of magnitude.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:06:41 GMT""},{""version"":""v2"",""created"":""Thu, 15 Dec 2022 15:37:16 GMT""}]","2022-12-16"
"2212.04900","Jeroen Winkel","Romain Tessera and Jeroen Winkel","Coarse fixed point properties","37",,,,"math.GR math.MG math.RT","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We investigate fixed point properties for isometric actions of topological
groups on a wide class of metric spaces, with a particular emphasis on Hilbert
spaces. Instead of requiring the action to be continuous, we assume that it is
``controlled"", i.e. compatible with respect to some natural left-invariant
coarse structure. For locally compact groups, we prove that these coarse fixed
point properties are equivalent to the usual ones, defined for continuous
actions. We deduce generalisations of two results of Gromov originally stated
for discrete groups. For Polish groups with bounded geometry (in the sense of
Rosendal), we prove a version of Serre's theorem on the stability of coarse
property FH under central extensions. As an application we prove that the group
$\text{Homeo}^+_{\mathbb Z}(\mathbb R)$ has property FH. Finally, we
characterise geometric property (T) for sequences of finite Cayley graphs in
terms of coarse property FH of a certain group.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:07:02 GMT""}]","2022-12-12"
"2212.04903","Jekabs Romans","Jekabs Romans, Anjali Ajayakumar, Martial Authier, Frederic Boumard,
  Lucia Caceres, Jean-Francois Cam, Arno Claessens, Samuel Damoy, Pierre
  Delahaye, Philippe Desrues, Wenling Dong, Antoine Drouart, Patricia Duchesne,
  Rafael Ferrer, Xavier Flechard, Serge Franchoo, Patrice Gangnant, Sarina
  Geldhof, Ruben P. de Groote, Nathalie Lecesne, Renan Leroy, Julien Lory,
  Franck Lutton, Vladimir Manea, Yvan Merrer, Iain Moore, Alejandro
  Ortiz-Cortes, Benoit Osmond, Julien Piot, Olivier Pochon, Sebastian Raeder,
  Antoine de Roubin, Herve Savajols, Simon Sels, Dominik Studer, Emil Traykov,
  Juha Uusitalo, Christophe Vandamme, Marine Vandebrouck, Paul Van den Bergh,
  Piet Van Duppen, and Klaus Wendt","High-resolution laser system for the S3-Low Energy Branch",,,"10.1016/j.nimb.2022.12.012",,"nucl-ex physics.atom-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper we present the first high-resolution laser spectroscopy results
obtained at the GISELE laser laboratory of the GANIL-SPIRAL2 facility, in
preparation for the first experiments with the S$^3$-Low Energy Branch. Studies
of neutron-deficient radioactive isotopes of erbium and tin represent the first
physics cases to be studied at S$^3$. The measured isotope-shift and hyperfine
structure data are presented for stable isotopes of these elements. The erbium
isotopes were studied using the $4f^{12}6s^2$ $^3H_6 \rightarrow 4f^{12}(^3
H)6s6p$ $J = 5$ atomic transition (415 nm) and the tin isotopes were studied by
the $5s^25p^2 (^3P_0) \rightarrow 5s^25p6s (^3P_1)$ atomic transition (286.4
nm), and are used as a benchmark of the laser setup. Additionally, the tin
isotopes were studied by the $5s^25p6s (^3P_1) \rightarrow 5s^25p6p (^3P_2)$
atomic transition (811.6 nm), for which new isotope-shift data was obtained and
the corresponding field-shift $F_{812}$ and mass-shift $M_{812}$ factors are
presented.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:10:51 GMT""}]","2023-01-25"
"2212.04904","Sachin S Sharma","Sachin S. Sharma, Priyanshu Chakraborty, Ritesh Kumar Pandey, and S.
  Eswara Rao","Representations of loop extended Witt algebras","Preliminary version; comments are welcome",,,,"math.RT","http://creativecommons.org/licenses/by/4.0/","  In this paper, we classify irreducible modules for loop extended Witt
algebras with finite dimensional weight spaces. They turn out to be either
modules with uniformly bounded weight spaces or highest weight modules. We
further prove that all these modules are single point evaluation modules ($n
\geq 2$). So they are actually irreducible modules for extended Witt algebras.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:12:37 GMT""}]","2022-12-12"
"2212.04905","Eniko Sz\'ekely","Enik\H{o} Sz\'ekely, Sebastian Sippel, Nicolai Meinshausen, Guillaume
  Obozinski, Reto Knutti","Robust detection and attribution of climate change under interventions",,,,,"stat.ML cs.LG stat.AP","http://creativecommons.org/licenses/by/4.0/","  Fingerprints are key tools in climate change detection and attribution (D&A)
that are used to determine whether changes in observations are different from
internal climate variability (detection), and whether observed changes can be
assigned to specific external drivers (attribution). We propose a direct D&A
approach based on supervised learning to extract fingerprints that lead to
robust predictions under relevant interventions on exogenous variables, i.e.,
climate drivers other than the target. We employ anchor regression, a
distributionally-robust statistical learning method inspired by causal
inference that extrapolates well to perturbed data under the interventions
considered. The residuals from the prediction achieve either uncorrelatedness
or mean independence with the exogenous variables, thus guaranteeing
robustness. We define D&A as a unified hypothesis testing framework that relies
on the same statistical model but uses different targets and test statistics.
In the experiments, we first show that the CO2 forcing can be robustly
predicted from temperature spatial patterns under strong interventions on the
solar forcing. Second, we illustrate attribution to the greenhouse gases and
aerosols while protecting against interventions on the aerosols and CO2
forcing, respectively. Our study shows that incorporating robustness
constraints against relevant interventions may significantly benefit detection
and attribution of climate change.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:13:40 GMT""}]","2022-12-12"
"2212.04909","Xunzhu Tang","Xunzhu Tang and Tiezhu Sun and Rujie Zhu and Shi Wang","CKG: Dynamic Representation Based on Context and Knowledge Graph",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, neural language representation models pre-trained on large corpus
can capture rich co-occurrence information and be fine-tuned in downstream
tasks to improve the performance. As a result, they have achieved
state-of-the-art results in a large range of language tasks. However, there
exists other valuable semantic information such as similar, opposite, or other
possible meanings in external knowledge graphs (KGs). We argue that entities in
KGs could be used to enhance the correct semantic meaning of language
sentences. In this paper, we propose a new method CKG: Dynamic Representation
Based on \textbf{C}ontext and \textbf{K}nowledge \textbf{G}raph. On the one
side, CKG can extract rich semantic information of large corpus. On the other
side, it can make full use of inside information such as co-occurrence in large
corpus and outside information such as similar entities in KGs. We conduct
extensive experiments on a wide range of tasks, including QQP, MRPC, SST-5,
SQuAD, CoNLL 2003, and SNLI. The experiment results show that CKG achieves SOTA
89.2 on SQuAD compared with SAN (84.4), ELMo (85.8), and BERT$_{Base}$ (88.5).
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:17:35 GMT""}]","2022-12-12"
"2212.04910","Richard Koryt\'ar","Richard Koryt\'ar and Ferdinand Evers","Current-induced mechanical torque in chiral molecular rotors",,,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  A great endeavor has been undertaken to engineer molecular rotors operated by
an electrical current. A frequently met operation principle is the transfer of
angular momentum taken from the incident flux. In this paper we present an
alternative driving agent that works also in situations where angular momentum
of the incoming flux is conserved. This situation arises typically with
molecular rotors that exhibit an easy axis of rotation. For quantitative
analysis we investigate here a classical model, where molecule and wires are
represented by a rigid curved path. We demonstrate that in the presence of
chirality the rotor generically undergoes a directed motion, provided that the
incident current exceeds a threshold value. Above threshold, the corresponding
rotation frequency (per incoming particle current) for helical geometries turns
out to be $2\pi m/M_1$, where $m/M_1$ is the ratio of the mass of an incident
charge carrier and the mass of the helix per winding number.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:18:00 GMT""}]","2022-12-12"
"2212.04911","Lin Ge","Robert H. Lyles, Yuzi Zhang, Lin Ge and Lance A. Waller","A Design and Analytic Strategy for Monitoring Disease Positivity and
  Case Characteristics in Accessible Closed Populations",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a monitoring strategy for efficient and robust estimation of
disease prevalence and case numbers within closed and enumerated populations
such as schools, workplaces, or retirement communities. The proposed design
relies largely on voluntary testing, notoriously biased (e.g., in the case of
COVID-19) due to non-representative sampling. The approach yields unbiased and
comparatively precise estimates with no assumptions about factors underlying
selection of individuals for voluntary testing, building on the strength of
what can be a small random sampling component. This component unlocks a
previously proposed ""anchor stream"" estimator, a well-calibrated alternative to
classical capture-recapture (CRC) estimators based on two data streams. We show
here that this estimator is equivalent to a direct standardization based on
""capture"", i.e., selection (or not) by the voluntary testing program, made
possible by means of a key parameter identified by design. This equivalency
simultaneously allows for novel two-stream CRC-like estimation of general means
(e.g., of continuous variables such as antibody levels or biomarkers). For
inference, we propose adaptations of a Bayesian credible interval when
estimating case counts and bootstrapping when estimating means of continuous
variables. We use simulations to demonstrate significant precision benefits
relative to random sampling alone.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:20:44 GMT""}]","2022-12-12"
"2212.04912","Christian Drischler","C. Drischler, J.A. Melendez, R.J. Furnstahl, A.J. Garcia, Xilin Zhang","BUQEYE Guide to Projection-Based Emulators in Nuclear Physics","31 pages, 10 figures, 1 table; invited contribution to the Research
  Topic ""Uncertainty Quantification in Nuclear Physics"" in Frontiers in Physics",,,,"nucl-th hep-lat hep-ph physics.data-an","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The BUQEYE collaboration (Bayesian Uncertainty Quantification: Errors in Your
EFT) presents a pedagogical introduction to projection-based, reduced-order
emulators for applications in low-energy nuclear physics. The term emulator
refers here to a fast surrogate model capable of reliably approximating
high-fidelity models. As the general tools employed by these emulators are not
yet well-known in the nuclear physics community, we discuss variational and
Galerkin projection methods, emphasize the benefits of offline-online
decompositions, and explore how these concepts lead to emulators for bound and
scattering systems that enable fast & accurate calculations using many
different model parameter sets. We also point to future extensions and
applications of these emulators for nuclear physics, guided by the mature field
of model (order) reduction. All examples discussed here and more are available
as interactive, open-source Python code so that practitioners can readily adapt
projection-based emulators for their own work.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:20:57 GMT""}]","2022-12-12"
"2212.04914","Alessandro Bottero","Alessandro G. Bottero, Carlos E. Luis, Julia Vinogradska, Felix
  Berkenkamp, Jan Peters","Information-Theoretic Safe Exploration with Gaussian Processes","Submitted to NeurIPS 2022",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a sequential decision making task where we are not allowed to
evaluate parameters that violate an a priori unknown (safety) constraint. A
common approach is to place a Gaussian process prior on the unknown constraint
and allow evaluations only in regions that are safe with high probability. Most
current methods rely on a discretization of the domain and cannot be directly
extended to the continuous case. Moreover, the way in which they exploit
regularity assumptions about the constraint introduces an additional critical
hyperparameter. In this paper, we propose an information-theoretic safe
exploration criterion that directly exploits the GP posterior to identify the
most informative safe parameters to evaluate. Our approach is naturally
applicable to continuous domains and does not require additional
hyperparameters. We theoretically analyze the method and show that we do not
violate the safety constraint with high probability and that we explore by
learning about the constraint up to arbitrary precision. Empirical evaluations
demonstrate improved data-efficiency and scalability.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:23:58 GMT""}]","2022-12-12"
"2212.04915","Holger Grosshans","Holger Grosshans, Simon Janta\v{c}","Recent progress in CFD modeling of powder flow charging during pneumatic
  conveying","arXiv admin note: substantial text overlap with arXiv:2205.08219",,,,"physics.flu-dyn","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Thus far, Computational Fluid Dynamics (CFD) simulations fail to predict the
electrostatic charging of particle-gas flows reliably. The lack of a predictive
tool leads to powder operations prone to deposits and discharges, making
chemical plants unsustainable and prime candidates for explosions. This paper
reviews the rapid progress of numerical models in recent years, their
limitations, and outlines future research. In particular, the discussion
includes CFD models for the physics and chemistry of particle electrification.
The condenser model is most popular today in CFD simulations of powder flow
electrification but fails to predict most of its features. New experiments led
to advanced models, such as the non-uniform charge model, which resolves the
local charge distribution on non-conductive particle surfaces. Further, models
relying on the surface state theory predicted bipolar charging of polydisperse
particles made of the same material. While these models were usually
implemented in CFD tools using an Eulerian-Lagrangian strategy, recently
Eulerian methods successfully described powder charging. The Eulerian framework
is computationally efficient when handling complete powders; thus, Eulerian
methods can pave the way from academic studies to application, simulating
full-scale powder processing units. Overall, even though CFD models for powder
flow charging improved, major hurdles toward a predictive tool remain.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:24:32 GMT""}]","2022-12-12"
"2212.04916","Oleh Melnyk","Oleh Melnyk","Stochastic Amplitude Flow for phase retrieval, its convergence and
  doppelg\""angers","31 pages",,,,"math.NA cs.NA math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we focus on Stochastic Amplitude Flow (SAF) for phase
retrieval, a stochastic gradient descent for the amplitude-based squared loss.
While the convergence to a critical point of (nonstochastic) Amplitude Flow is
well-understood, SAF is a much less studied algorithm. We close this gap by
deriving the convergence guarantees for SAF based on the contributions for
Amplitude Flow and analysis for stochastic gradient descent. These results are
then applied to two more algorithms, which can be seen as instances of SAF. The
first is an extension of the Kaczmarz method for phase retrieval. The second is
Ptychographic Iterative Engine, which is a popular algorithm for ptychography,
a special case of phase retrieval with the short-time Fourier transform.
  Keywords: phase retrieval, Amplitude Flow, stochastic gradient descent,
ptychography, Ptychographic Iterative Engine, Kaczmarz method.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:26:19 GMT""}]","2022-12-12"
"2212.04917","Mor Ventura","Mor Ventura and Michael Toker","TRBLLmaker -- Transformer Reads Between Lyrics Lines maker",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Even for us, it can be challenging to comprehend the meaning of songs. As
part of this project, we explore the process of generating the meaning of
songs. Despite the widespread use of text-to-text models, few attempts have
been made to achieve a similar objective. Songs are primarily studied in the
context of sentiment analysis. This involves identifying opinions and emotions
in texts, evaluating them as positive or negative, and utilizing these
evaluations to make music recommendations. In this paper, we present a
generative model that offers implicit meanings for several lines of a song. Our
model uses a decoder Transformer architecture GPT-2, where the input is the
lyrics of a song. Furthermore, we compared the performance of this architecture
with that of the encoder-decoder Transformer architecture of the T5 model. We
also examined the effect of different prompt types with the option of appending
additional information, such as the name of the artist and the title of the
song. Moreover, we tested different decoding methods with different training
parameters and evaluated our results using ROUGE. In order to build our
dataset, we utilized the 'Genious' API, which allowed us to acquire the lyrics
of songs and their explanations, as well as their rich metadata.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:27:36 GMT""}]","2022-12-12"
"2212.04918","Surajit Kalita","Surajit Kalita (UCT), Lupamudra Sarmah (IIA) and Aneta Wojnar
  (Universidad Complutense de Madrid)","Metric-affine effects in crystallization processes of white dwarfs","10 pages with 8 figures; version accepted for publication in PRD","Phys. Rev. D 107 (2023) 044072","10.1103/PhysRevD.107.044072",,"gr-qc astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze the effects of modified gravity on specific heats of electrons and
ions, Debye temperature, crystallization process, and cooling mechanism in
white dwarfs. We derive the Lane-Emden-Chandrasekhar equation and relate it to
the cooling process equations for Palatini $f(R)$ gravity. Moreover, for the
first time in the literature, we show that the gravity model plays a crucial
role not only in the mass and size of the white dwarf, but also affects their
internal properties. We further demonstrate that modified gravity can decrease
the cooling age significantly.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:27:38 GMT""},{""version"":""v2"",""created"":""Mon, 13 Feb 2023 17:28:50 GMT""}]","2023-03-07"
"2212.04919","Romain Fleury","Zhe Zhang, Pierre Delplace, Romain Fleury","Anomalous topological waves in strongly amorphous scattering networks",,,,,"physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Topological insulators are crystalline materials that have revolutionized our
ability to control wave transport. They provide us with unidirectional channels
that are immune to obstacles, defects or local disorder, and can even survive
some random deformations of their crystalline structures. However, they always
break down when the level of disorder or amorphism gets too large,
transitioning to a topologically trivial Anderson insulating phase. Here, we
demonstrate a two-dimensional amorphous topological regime that survives
arbitrarily strong levels of amorphism. We implement it for electromagnetic
waves in a non-reciprocal scattering network and experimentally demonstrate the
existence of unidirectional edge transport in the strong amorphous limit. This
edge transport is shown to be mediated by an anomalous edge state whose
topological origin is evidenced by direct topological invariant measurements.
Our findings extend the reach of topological physics to a new class of systems
in which strong amorphism can induce, enhance and guarantee the topological
edge transport instead of impeding it.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:27:39 GMT""}]","2022-12-12"
"2212.04920","Karen Alim","Adrian Misselwitz, Suzanne Lafon, Jean-Daniel Julien and Karen Alim","Flow driven control of pulse width in excitable media","9 pages, 4 figures",,"10.1103/PhysRevE.107.054218",,"nlin.PS cond-mat.soft q-bio.NC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Models of pulse formation in nerve conduction have provided manifold insight
not only into neuronal dynamics but also the non-linear dynamics of pulse
formation in general. Recent observation of neuronal electro-chemical pulses
also driving mechanical deformation of the tubular neuronal wall and thereby
generating ensuing cytoplasmic flow now question the impact of flow on the
electro-chemical dynamics of pulse formation. We, here, theoretically
investigate the classical Fitzhugh-Nagumo model now accounting for advective
coupling between the pulse propagator typically describing membrane potential
and here triggering mechanical deformations and, thus, governing flow
magnitude, and the pulse controller, a chemical species advected with the
ensuing fluid flow. Employing analytical calculations and numerical simulations
we find, that advective coupling allows for a linear control of pulse width
while leaving pulse velocity unchanged. We therefore uncover an independent
control of pulse width by fluid flow coupling.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:30:00 GMT""}]","2023-06-07"
"2212.04922","Jake Fawkes","Jake Fawkes, Robert Hu, Robin J. Evans, Dino Sejdinovic","Doubly Robust Kernel Statistics for Testing Distributional Treatment
  Effects Even Under One Sided Overlap","9 pages, Preprint",,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  As causal inference becomes more widespread the importance of having good
tools to test for causal effects increases. In this work we focus on the
problem of testing for causal effects that manifest in a difference in
distribution for treatment and control. We build on work applying kernel
methods to causality, considering the previously introduced Counterfactual Mean
Embedding framework (\textsc{CfME}). We improve on this by proposing the
\emph{Doubly Robust Counterfactual Mean Embedding} (\textsc{DR-CfME}), which
has better theoretical properties than its predecessor by leveraging
semiparametric theory. This leads us to propose new kernel based test
statistics for distributional effects which are based upon doubly robust
estimators of treatment effects. We propose two test statistics, one which is a
direct improvement on previous work and one which can be applied even when the
support of the treatment arm is a subset of that of the control arm. We
demonstrate the validity of our methods on simulated and real-world data, as
well as giving an application in off-policy evaluation.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:32:19 GMT""}]","2022-12-12"
"2212.04924","Rahul Trivedi","Rahul Trivedi, Adrian Franco Rubio, J. Ignacio Cirac","Quantum advantage and stability to errors in analogue quantum simulators",,,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Several quantum hardware platforms, while being unable to perform fully
fault-tolerant quantum computation, can still be operated as analogue quantum
simulators for addressing many-body problems. However, due to the presence of
errors, it is not clear to what extent those devices can provide us with an
advantage with respect to classical computers. In this work we consider the use
of noisy analogue quantum simulators for computing physically relevant
properties of many-body systems both in equilibrium and undergoing dynamics. We
first formulate a system-size independent notion of stability against extensive
errors, which we prove for Gaussian fermion models, as well as for a restricted
class of spin systems. Remarkably, for the Gaussian fermion models, our
analysis shows the stability of critical (gapless) models at zero temperature
which have long-range correlations. Furthermore, we analyze how this stability
may lead to a quantum advantage, for the problem of computing the thermodynamic
limits of many-body models, in the presence of a constant error rate and
without any explicit error correction.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:33:27 GMT""}]","2022-12-12"
"2212.04925","Caroline Guandalin","Caroline Guandalin, Jade Piat, Chris Clarkson, Roy Maartens","Theoretical systematics in testing the Cosmological Principle with the
  kinematic quasar dipole","13 pages, 3 figures, 2 tables",,,,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  The Cosmological Principle is part of the foundation that underpins the
standard model of the Universe. In the era of precision cosmology, when stress
tests of the standard model are uncovering various tensions and possible
anomalies, it is critical to check the viability of this Principle. A key test
is the consistency between the kinematic dipoles of the cosmic microwave
background and of the large-scale matter distribution. Results using radio
continuum and quasar samples indicate a rough agreement in the directions of
the two dipoles, but a larger than expected amplitude of the matter dipole. The
resulting tension with the radiation dipole has been estimated at $\sim
5\sigma$ for some cases, suggesting a potential new cosmological tension and a
possible violation of the Cosmological Principle. However, the standard
formalism for predicting the dipole in the 2-dimensional projection of sources
overlooks possible evolution effects in the luminosity function. In fact,
radial information from the luminosity function is necessary for a correct
projection of the 3-dimensional source distribution. Using a variety of current
models of the quasar luminosity function, we show that neglecting redshift
evolution can significantly overestimate the relative velocity amplitude. While
the models we investigate are consistent with each other and with current data,
the dipole derived from these, which depends on derivatives of the luminosity
function, can disagree by more than $3\sigma$. This theoretical systematic bias
needs to be resolved before robust conclusions can be made about a new cosmic
tension.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:34:34 GMT""}]","2022-12-12"
"2212.04926","Lihuan Sun","Lihuan Sun, Louk Rademaker, Diego Mauro, Alessandro Scarfato,
  \'Arp\'ad P\'asztor, Ignacio Guti\'errez-Lezama, Zhe Wang, Jose
  Martinez-Castro, Alberto F. Morpurgo, Christoph Renner","Determining spin-orbit coupling in graphene by quasiparticle
  interference imaging",,,,,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Inducing and controlling spin-orbit coupling (SOC) in graphene is key to
create topological states of matter, and for the realization of spintronic
devices. Placing graphene onto a transition metal dichalcogenide is currently
the most successful strategy to achieve this goal, but there is no consensus as
to the nature and the magnitude of the induced SOC. Here, we show that the
presence of backscattering in graphene-on-WSe$_2$ heterostructures can be used
to probe SOC and to determine its strength quantitatively, by imaging
quasiparticle interference with a scanning tunneling microscope. A detailed
theoretical analysis of the Fourier transform of quasiparticle interference
images reveals that the induced SOC consists of a valley-Zeeman
($\lambda_{\text{vZ}}\approx 2$ meV) and a Rashba ($\lambda_\text{R}\approx 15$
meV) term, one order of magnitude larger than what theory predicts, but in
excellent agreement with earlier transport experiments. The validity of our
analysis is confirmed by measurements on a 30 degree twist angle
heterostructure that exhibits no backscattering, as expected from symmetry
considerations. Our results demonstrate a viable strategy to determine SOC
quantitatively by imaging quasiparticle interference.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:35:22 GMT""}]","2022-12-12"
"2212.04931","Hitoshi Ikemori","Hitoshi Ikemori, Shinsaku Kitakado, Yoshimitsu Matsui, Toshiro Sato","Runge-Lenz Vector as a 3d Projection of SO(4) Moment Map in
  $\mathbb{R}^{4}\times\mathbb{R}^{4}$ Phase Space","Corrected typographical error. The final version is published in J.
  Phys. A","J. Phys. A: Math. Theor. 56 225204 (2023)","10.1088/1751-8121/accee7",,"physics.class-ph hep-th math-ph math.MP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We show, using the methods of geometric algebra, that Runge-Lenz vector in
the Kepler problem is a 3-dimensional projection of SO(4) moment map that acts
on the phase space of 4-dimensional particle motion. Thus, RL vector is a
consequence of geometric symmetry of $\mathbb{R}^4\times \mathbb{R}^4$ phase
space.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:36:19 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jun 2023 06:34:39 GMT""}]","2023-06-02"
"2212.04932","Paolo Sentinelli","Francesco Brenti, Paolo Sentinelli","Wachs permutations, Bruhat order and weak order",,,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  We study the partial orders induced on Wachs and signed Wachs permutations by
the Bruhat and weak orders of the symmetric and hyperoctahedral groups. We show
that these orders are graded, determine their rank function, characterize their
ordering and covering relations, and compute their characteristic polynomials,
when partially ordered by Bruhat order, and determine their structure
explicitly when partially ordered by right weak order.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:39:52 GMT""}]","2022-12-12"
"2212.04934","Jo\""el Mathys","Florian Gr\""otschla, Jo\""el Mathys, Roger Wattenhofer","Learning Graph Algorithms With Recurrent Graph Neural Networks","Accepted at GCLR@AAAI23, workshop on Graphs and more Complex
  structures for Learning and Reasoning",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Classical graph algorithms work well for combinatorial problems that can be
thoroughly formalized and abstracted. Once the algorithm is derived, it
generalizes to instances of any size. However, developing an algorithm that
handles complex structures and interactions in the real world can be
challenging. Rather than specifying the algorithm, we can try to learn it from
the graph-structured data. Graph Neural Networks (GNNs) are inherently capable
of working on graph structures; however, they struggle to generalize well, and
learning on larger instances is challenging. In order to scale, we focus on a
recurrent architecture design that can learn simple graph problems end to end
on smaller graphs and then extrapolate to larger instances. As our main
contribution, we identify three essential techniques for recurrent GNNs to
scale. By using (i) skip connections, (ii) state regularization, and (iii) edge
convolutions, we can guide GNNs toward extrapolation. This allows us to train
on small graphs and apply the same model to much larger graphs during
inference. Moreover, we empirically validate the extrapolation capabilities of
our GNNs on algorithmic datasets.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:42:22 GMT""}]","2022-12-12"
"2212.04935","Nidal Chamoun","M. Alhallak (Damascus Univ.), N. Chamoun (HIAST) and M. S. Eldaher
  (Damascus Univ.)","Salvaging Power-Law Inflation through Warming","pdflatex, 15 pages (epjc style), 7 tables, 4 figures, 5
  table-figures, major revision, accepted version to appear in EPJC",,,,"astro-ph.CO hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Power-Law inflation with scale factor $a \propto t^m$ is investigated in the
context of warm inflation. The treatment is performed in the weak and strong
dissipation limits. In addition, we discuss the three common cases for the
thermal dissipation coefficient $\Gamma(T)$. We compare the theoretical results
of the Power-Law model within warm inflation with the observational constraints
from Planck $2018$ and BICEP/Keck 2018, as presented by the tensor-to-scalar
ratio $r$ and spectral index $n_s$. The model results agree largely with the
observations for most of the $\Gamma(T)$ cases.
  Furthermore, in order to address the problem of exiting the inflationary
epoch, we suggest a perturbed modification to the power-law definition so that
it becomes affine, and find that this small change indicates a way for having
an exit scenario with a suitable e-foldings number. Finally, we examine this
perturbation ansatz within the context of cold inflation with exponential
potential, and we find that it can accommodate the observational data with
sufficient e-foldings.
  Our study suggests that the power-law inflation and the exponential
potential, in both warm and cold inflation contexts, can in principle be made
consistent with the observations and with a possible graceful exit.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:42:48 GMT""},{""version"":""v2"",""created"":""Tue, 30 May 2023 03:17:41 GMT""}]","2023-05-31"
"2212.04938","Joan Falc\'o-Roget","N\'estor Parga, Luis Serrano-Fern\'andez, Joan Falc\'o-Roget","Emergent Computations in Trained Artificial Neural Networks and Real
  Brains","International Summer School on Intelligent Signal Processing for
  Frontier Research and Industry, INFIERI 2021. Universidad Aut\'onoma de
  Madrid, Madrid, Spain. 23 August - 4 September 2021",,"10.1088/1748-0221/18/02/C02060",,"q-bio.NC cs.AI cs.NE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Synaptic plasticity allows cortical circuits to learn new tasks and to adapt
to changing environments. How do cortical circuits use plasticity to acquire
functions such as decision-making or working memory? Neurons are connected in
complex ways, forming recurrent neural networks, and learning modifies the
strength of their connections. Moreover, neurons communicate emitting brief
discrete electric signals. Here we describe how to train recurrent neural
networks in tasks like those used to train animals in neuroscience
laboratories, and how computations emerge in the trained networks.
Surprisingly, artificial networks and real brains can use similar computational
strategies.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:46:10 GMT""},{""version"":""v2"",""created"":""Tue, 13 Dec 2022 08:10:36 GMT""}]","2023-03-08"
"2212.04939","Hao Sun","Pengfei Huang, Hao Sun","Meromorphic Parahoric Higgs Torsors and Filtered Stokes G-local Systems
  on Curves","26 pages",,,,"math.AG math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider the wild nonabelian Hodge correspondence for
principal $G$-bundles on curves, where $G$ is a connected complex reductive
group. We establish the correspondence under a ``very good"" condition
introduced by Boalch, and thus confirm one of his conjectures. We first give a
version of Kobayashi--Hitchin correspondence, which induces a one-to-one
correspondence between stable meromorphic parahoric Higgs torsors of degree
zero (Dolbeault side) and stable meromorphic parahoric connections of degree
zero (de Rham side). Then, by introducing a notion of stability condition on
filtered Stokes local systems, we prove a one-to-one correspondence between
stable meromorphic parahoric connections of degree zero (de Rham side) and
stable filtered Stokes $G$-local systems of degree zero (Betti side). When
$G={\rm GL}_n(\mathbb{C})$, the main result in this paper reduces to
Biquad--Boalch's result.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:46:22 GMT""},{""version"":""v2"",""created"":""Mon, 6 Mar 2023 11:35:45 GMT""}]","2023-03-07"
"2212.04940","Lu Zhong","Lu Zhong and Chu Guo and Xiaoting Wang","Quantum State Tomography Inspired by Language Modeling",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum state tomography is an elementary tool to fully characterize an
unknown quantum state. As the quantum hardware scales up in size, the standard
quantum state tomography becomes increasingly challenging due to its
exponentially growing complexity. In this work, we propose a scalable solution
by considering state tomography as a language modeling task, where the unknown
quantum state is treated as an unknown language, the correlation of the quantum
state is interpreted as the semantic information specific to this language, and
the measurement outcomes are simply the text instances generated from the
language. Based on a customized transformer model from language modeling, we
demonstrate that our method can accurately reconstruct prototypical pure and
mixed quantum states using less samples than state-of-the-art methods. More
importantly, our method can reconstruct a class of similar states
simultaneously, in comparison with the existing neural network methods that
need to train a model for each unknown state.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:47:03 GMT""}]","2022-12-12"
"2212.04941","Paul Pru\v{z}ina","Paul Pru\v{z}ina, David W. Hughes and Samuel S. Pegler (University of
  Leeds)","Salt fingering staircases and the three-component Phillips effect","24 pages, 8 figures",,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  Understanding the dynamics of staircases in salt fingering convection
presents a long-standing theoretical challenge to fluid dynamicists. Although
there has been significant progress, particularly through numerical
simulations, there are a number of conflicting theoretical explanations as to
the driving mechanism underlying staircase formation. The Phillips effect
proposes that layering in stirred stratified flow is due to an antidiffusive
process, and it has been suggested that this mechanism may also be responsible
for salt fingering staircases. However, the details of this process, as well as
mathematical models to predict the evolution and merger dynamics of staircases,
have yet to be developed. We generalise the theory of the Phillips effect to a
three-component system (e.g. temperature, salinity, energy) and demonstrate the
first regularised nonlinear model of layering based on mixing-length
parameterisations. The model predicts both the inception of layering and its
long-term evolution through mergers , whilst generalising, and remaining
consistent with, previous results for double-diffusive layering based on flux
ratios. Our model of salt fingering is formulated using spatial averaging
processes and closed by a mixing length parameterised in terms of the kinetic
energy and the salt and temperature gradients. The model predicts a layering
instability for a bounded range of parameter values in the salt fingering
regime. Nonlinear solutions show that an initially unstable linear buoyancy
gradient develops into layers, which merge through a process of stronger
interfaces growing at the expense of weaker interfaces. Mergers increase the
buoyancy gradient across interfaces, and increase the buoyancy flux through the
staircase.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:51:26 GMT""},{""version"":""v2"",""created"":""Mon, 13 Feb 2023 14:26:22 GMT""}]","2023-02-14"
"2212.04942","Tenzan Araki","Tenzan Araki, James Stokes, Shravan Veerapaneni","Digital quantum simulation of Schr\""odinger dynamics using adaptive
  approximations of potential functions",,,,,"quant-ph cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Digital quantum simulation (DQS) of continuous-variable quantum systems in
the position basis requires efficient implementation of diagonal unitaries
approximating the time evolution operator generated by the potential energy
function. In this work, we provide efficient implementations suitable for
potential functions approximable by piecewise polynomials, with either uniform
or adaptively chosen subdomains. For a fixed precision of approximation, we
show how adaptive grids can significantly reduce the total gate count at the
cost of introducing a small number of ancillary qubits. We demonstrate the
circuit construction with both physically motivated and artificially designed
potential functions, and discuss their generalizations to higher dimensions.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:51:27 GMT""}]","2022-12-12"
"2212.04943","Jiajia Guo","Selim Esedoglu, Jiajia Guo and David Li","On Median Filters for Motion by Mean Curvature","41 pages, 8 figures",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The median filter scheme is an elegant, monotone discretization of the level
set formulation of motion by mean curvature. It turns out to evolve every level
set of the initial condition precisely by another class of methods known as
threshold dynamics. Median filters are, in other words, the natural level set
versions of threshold dynamics algorithms. Exploiting this connection, we
revisit median filters in light of recent progress on the threshold dynamics
method. In particular, we give a variational formulation of, and exhibit a
Lyapunov function for, median filters, resulting in energy based unconditional
stability properties. The connection also yields analogues of median filters in
the multiphase setting of mean curvature flow of networks. These new multiphase
level set methods do not require frequent redistancing, and can accommodate a
wide range of surface tensions.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:52:04 GMT""}]","2022-12-12"
"2212.04944","Sameer Sheorey","Dionysios Anninos, Dami\'an A. Galante, and Sameer U. Sheorey","Renormalisation Group Flows of the SYK Model","27 pages plus appendices, 16 figures",,,,"hep-th cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore computationally tractable deformations of the SYK model. The
deformed theories are described by the sum of two SYK Hamiltonians with
differing numbers, $q$ and $\tilde{q}$, of interacting fermions. In the large
$N$ limit, employing analytic and numerical tools, we compute finite
temperature correlation functions and thermodynamic quantities. We identify a
novel analytically solvable RG flow in the large $q$ limit. We find that, under
certain circumstances, the RG flow in the strongly coupled infrared phase
exhibits two regions of linear-in-temperature entropy, which we interpret in
terms of Schwarzian actions. Using conformal perturbation theory we compute the
leading relevant correction away from the intermediate near-conformal fixed
point. Holographic spacetimes in two spacetime dimensions that reproduce the
thermodynamics of the microphysical theory are discussed. These are flow
geometries that interpolate between two Euclidean near-AdS$_2$ spacetimes with
different radii. The Schwarzian soft mode corresponding to the AdS$_2$ region
in the deep interior resides entirely within the geometric regime.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:52:13 GMT""}]","2022-12-12"
"2212.04946","Yunhe Sheng","Yunhe Sheng","A survey on deformations, cohomologies and homotopies of relative
  Rota-Baxter Lie algebras","arXiv admin note: substantial text overlap with arXiv:2008.06714","Bulletin London Math. Soc. 54 (2022), 2045-2065","10.1112/blms.12712",,"math-ph math.MP math.QA math.RA","http://creativecommons.org/licenses/by/4.0/","  In this paper, we review deformation, cohomology and homotopy theories of
relative Rota-Baxter Lie algebras, which have attracted quite much interest
recently. Using Voronov's higher derived brackets, one can obtain an
$L_\infty$-algebra whose Maurer-Cartan elements are relative Rota-Baxter Lie
algebras. Then using the twisting method, one can obtain the $L_\infty$-algebra
that controls deformations of a relative \RB Lie algebra. Meanwhile, the
cohomologies of relative Rota-Baxter Lie algebras can also be defined with the
help of the twisted $L_\infty$-algebra. Using the controlling algebra approach,
one can also introduce the notion of homotopy relative Rota-Baxter Lie algebras
with close connection to pre-Lie$_\infty$-algebras. Finally, we briefly review
deformation, cohomology and homotopy theories of relative Rota-Baxter Lie
algebras of nonzero weights.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:57:58 GMT""}]","2022-12-15"
"2212.04950","Aobo Li","Aobo Li, Julieta Gruszko, Brady Bos, Thomas Caldwell, Esteban Le\'on,
  John Wilkerson","Ad-hoc Pulse Shape Simulation using Cyclic Positional U-Net","Accepted by NeurIPS 2022 ML4PS workshop as workshop paper; Selected
  to receive the MLST outstanding paper award",,,,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High-Purity Germanium~(HPGe) detectors have been a key technology for
rare-event searches, such as neutrinoless double-beta decay and dark matter
searches, for many decades. Pulse shape simulation is pivotal to improving the
physics reach of these experiments. In this work, we propose a Cyclic
Positional U-Net to achieve ad-hoc pulse shape simulations with high precision
and low latency. Taking the transfer learning approach, CPU-Net translates
simulated pulses to detector pulses such that they are indistinguishable. We
demonstrate CPU-Net's performance on data taken from a local HPGe detector.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:06:37 GMT""}]","2022-12-12"
"2212.04984","Pedro F da Costa","Pedro F Da Costa, Jessica Dafflon, Sergio Leonardo Mendes, Jo\~ao
  Ricardo Sato, M. Jorge Cardoso, Robert Leech, Emily JH Jones and Walter H.L.
  Pinaya","Transformer-based normative modelling for anomaly detection of early
  schizophrenia","10 pages, 2 figures, 2 tables, presented at NeurIPS22@PAI4MH",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Despite the impact of psychiatric disorders on clinical health, early-stage
diagnosis remains a challenge. Machine learning studies have shown that
classifiers tend to be overly narrow in the diagnosis prediction task. The
overlap between conditions leads to high heterogeneity among participants that
is not adequately captured by classification models. To address this issue,
normative approaches have surged as an alternative method. By using a
generative model to learn the distribution of healthy brain data patterns, we
can identify the presence of pathologies as deviations or outliers from the
distribution learned by the model. In particular, deep generative models showed
great results as normative models to identify neurological lesions in the
brain. However, unlike most neurological lesions, psychiatric disorders present
subtle changes widespread in several brain regions, making these alterations
challenging to identify. In this work, we evaluate the performance of
transformer-based normative models to detect subtle brain changes expressed in
adolescents and young adults. We trained our model on 3D MRI scans of
neurotypical individuals (N=1,765). Then, we obtained the likelihood of
neurotypical controls and psychiatric patients with early-stage schizophrenia
from an independent dataset (N=93) from the Human Connectome Project. Using the
predicted likelihood of the scans as a proxy for a normative score, we obtained
an AUROC of 0.82 when assessing the difference between controls and individuals
with early-stage schizophrenia. Our approach surpassed recent normative methods
based on brain age and Gaussian Process, showing the promising use of deep
generative models to help in individualised analyses.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:22:36 GMT""}]","2022-12-12"
"2212.05058","Liam Magee","Liam Magee, Vanicka Arora, Luke Munn","Structured Like a Language Model: Analysing AI as an Automated Subject",,,,,"cs.CY cs.AI","http://creativecommons.org/licenses/by-sa/4.0/","  Drawing from the resources of psychoanalysis and critical media studies, in
this paper we develop an analysis of Large Language Models (LLMs) as automated
subjects. We argue the intentional fictional projection of subjectivity onto
LLMs can yield an alternate frame through which AI behaviour, including its
productions of bias and harm, can be analysed. First, we introduce language
models, discuss their significance and risks, and outline our case for
interpreting model design and outputs with support from psychoanalytic
concepts. We trace a brief history of language models, culminating with the
releases, in 2022, of systems that realise state-of-the-art natural language
processing performance. We engage with one such system, OpenAI's InstructGPT,
as a case study, detailing the layers of its construction and conducting
exploratory and semi-structured interviews with chatbots. These interviews
probe the model's moral imperatives to be helpful, truthful and harmless by
design. The model acts, we argue, as the condensation of often competing social
desires, articulated through the internet and harvested into training data,
which must then be regulated and repressed. This foundational structure can
however be redirected via prompting, so that the model comes to identify with,
and transfer, its commitments to the immediate human subject before it. In
turn, these automated productions of language can lead to the human subject
projecting agency upon the model, effecting occasionally further forms of
countertransference. We conclude that critical media methods and psychoanalytic
theory together offer a productive frame for grasping the powerful new
capacities of AI-driven language systems.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 21:58:43 GMT""}]","2022-12-13"
"2212.05059","Aurelien Pelissier","Aurelien Pelissier, Miroslav Phan, Niko Beerenwinkel and Maria
  Rodriguez Martinez","Practical and scalable simulations of non-Markovian stochastic processes",,,,,"q-bio.QM","http://creativecommons.org/licenses/by/4.0/","  Discrete stochastic processes are widespread in natural systems with many
applications across physics, biochemistry, epidemiology, sociology, and
finance. While analytic solutions often cannot be derived, existing simulation
frameworks can generate stochastic trajectories compatible with the dynamical
laws underlying the random phenomena. However, most simulation algorithms
assume the system dynamics are memoryless (Markovian assumption), under which
assumption, future occurrences only depend on the present state of the system.
Mathematically, the Markovian assumption models inter-event times as
exponentially distributed variables, which enables the exact simulation of
stochastic trajectories using the seminal Gillespie algorithm. Unfortunately,
the majority of stochastic systems exhibit properties of memory, an inherently
non-Markovian attribute. Non-Markovian systems are notoriously difficult to
investigate analytically, and existing numerical methods are computationally
costly or only applicable under strong simplifying assumptions, often not
compatible with empirical observations. To address these challenges, we have
developed the Rejection-based Gillespie algorithm for non-Markovian Reactions
(REGIR), a general and scalable framework to simulate non-Markovian stochastic
systems with arbitrary inter-event time distributions. REGIR can achieve
arbitrary user-defined accuracy while maintaining the same asymptotic
computational complexity as the Gillespie algorithm. We illustrate REGIR's
modeling capabilities in three important biochemical systems, namely microbial
growth dynamics, stem cell differentiation, and RNA transcription. In all three
cases, REGIR efficiently models the underlying stochastic processes and
demonstrates its utility to accurately investigate complex non-Markovian
systems. The algorithm is implemented as a python library REGIR.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 03:55:19 GMT""},{""version"":""v2"",""created"":""Wed, 14 Dec 2022 03:00:08 GMT""},{""version"":""v3"",""created"":""Thu, 12 Jan 2023 16:07:11 GMT""}]","2023-01-13"
"2212.05060","Srinivas Siva Rama Krishna Rao Taduri Mr","Taduri Srinivasa Siva Rama Krishna Rao","Frechet differentiability and quasi-polyhedrality in spaces of operators","11 pages",,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  Let $X, Y$ be infinite dimensional, Banach spaces. Let $\mathcal{L}(X, Y)$ be
the space of bounded operators . Motivated by the fact that smoothness of norm
in the higher duals of even order of a Banach space can lead to Frechet
differentiability, we exhibit classes of Banach spaces $X, Y$ where very smooth
points (i.e., smooth points that remain smooth in the bidual) in the space of
compact operators $\mathcal{K}(X, Y)$ are Frechet smooth in $\mathcal{L}(X, Y)$
and hence in $\mathcal{K}(X, Y)$.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 04:52:39 GMT""}]","2022-12-13"
"2212.05061","John Francis","John Francis and Stephen Law","Estimating Chicago's tree cover and canopy height using multi-spectral
  satellite imagery","4 pages, 4 figures, Submitted to Tackling Climate Change with Machine
  Learning: workshop at NeurIPS 2022",,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Information on urban tree canopies is fundamental to mitigating climate
change [1] as well as improving quality of life [2]. Urban tree planting
initiatives face a lack of up-to-date data about the horizontal and vertical
dimensions of the tree canopy in cities. We present a pipeline that utilizes
LiDAR data as ground-truth and then trains a multi-task machine learning model
to generate reliable estimates of tree cover and canopy height in urban areas
using multi-source multi-spectral satellite imagery for the case study of
Chicago.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 10:12:34 GMT""}]","2022-12-13"
"2212.05062","Asma Bensalah","Asma Bensalah, Jialuo Chen, Alicia Forn\'es, Cristina Carmona-Duarte,
  Josep Llad\'os, and Miguel A.Ferrer","Towards Stroke Patients' Upper-limb Automatic Motor Assessment Using
  Smartwatches",,,"10.1007/978-3-030-68763-2_36",,"cs.HC cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Assessing the physical condition in rehabilitation scenarios is a challenging
problem, since it involves Human Activity Recognition (HAR) and kinematic
analysis methods. In addition, the difficulties increase in unconstrained
rehabilitation scenarios, which are much closer to the real use cases. In
particular, our aim is to design an upper-limb assessment pipeline for stroke
patients using smartwatches. We focus on the HAR task, as it is the first part
of the assessing pipeline. Our main target is to automatically detect and
recognize four key movements inspired by the Fugl-Meyer assessment scale, which
are performed in both constrained and unconstrained scenarios. In addition to
the application protocol and dataset, we propose two detection and
classification baseline methods. We believe that the proposed framework,
dataset and baseline results will serve to foster this research field.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:00:49 GMT""}]","2022-12-13"
"2212.05063","Asma Bensalah","Alicia Forn\'es, Asma Bensalah, Cristina Carmona-Duarte, Jialuo Chen,
  Miguel A. Ferrer, Andreas Fischer, Josep Llad\'os, Cristina Mart\'in, Eloy
  Opisso, R\'ejean Plamondon, Anna Scius-Bertrand, and Josep Maria Tormos","The RPM3D project: 3D Kinematics for Remote Patient Monitoring",,,"10.1007/978-3-031-19745-1_16",,"cs.HC cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This project explores the feasibility of remote patient monitoring based on
the analysis of 3D movements captured with smartwatches. We base our analysis
on the Kinematic Theory of Rapid Human Movement. We have validated our research
in a real case scenario for stroke rehabilitation at the Guttmann Institute5
(neurorehabilitation hospital), showing promising results. Our work could have
a great impact in remote healthcare applications, improving the medical
efficiency and reducing the healthcare costs. Future steps include more
clinical validation, developing multi-modal analysis architectures (analysing
data from sensors, images, audio, etc.), and exploring the application of our
technology to monitor other neurodegenerative diseases.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:16:32 GMT""}]","2022-12-13"
"2212.05090","Zijin Wang","Zijin Wang, Ou Zheng, Liangding Li, Mohamed Abdel-Aty, Carolina
  Cruz-Neira, Zubayer Islam","Towards Next Generation of Pedestrian and Connected Vehicle In-the-loop
  Research: A Digital Twin Co-Simulation Framework",,,"10.1109/TIV.2023.3250353",,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Digital Twin is an emerging technology that replicates real-world entities
into a digital space. It has attracted increasing attention in the
transportation field and many researchers are exploring its future applications
in the development of Intelligent Transportation System (ITS) technologies.
Connected vehicles (CVs) and pedestrians are among the major traffic
participants in ITS. However, the usage of Digital Twin in research involving
both CV and pedestrian remains largely unexplored. In this study, a Digital
Twin framework for CV and pedestrian in-the-loop simulation is proposed. The
proposed framework consists of the physical world, the digital world, and data
transmission in between. The features for the entities (CV and pedestrian) that
need digital twining are divided into external state and internal state, and
the attributes in each state are described. We also demonstrate a sample
architecture under the proposed Digital Twin framework, which is based on
Carla-Sumo Co-simulation and Cave automatic virtual environment (CAVE). A case
study that investigates Vehicle-Pedestrian (V2P) warning system is conducted to
validate the effectiveness of the presented architecture. The proposed
framework is expected to provide guidance to the future Digital Twin research,
and the architecture we build can serve as the testbed for further research and
development of ITS applications on CV and pedestrians.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 18:36:38 GMT""},{""version"":""v2"",""created"":""Wed, 18 Jan 2023 21:00:17 GMT""},{""version"":""v3"",""created"":""Sat, 11 Mar 2023 03:51:23 GMT""}]","2023-04-07"
"2212.05594","Rafael Robson Lino dos Santos","Rafael R. Lino dos Santos and Linda M. van Manen","Gravitational waves from the early universe","Submission to SciPost",,,,"astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  These lecture notes are based on the course ""Gravitational waves from the
early universe"" given at the 27th W.E. Heraeus ""Saalburg"" Summer School 2021 by
Valerie Domcke. Ongoing and future collaborations will probe different
frequency ranges of the gravitational wave spectrum, allowing for probing
different stages of the early universe and Beyond Standard Model physics. Due
to the very high energies involved, accelerators cannot probe them. Therefore,
current knowledge about new physics is limited and relies on bounds from CMB
observations and theoretical assumptions about these energy scales. While some
models are in tension with CMB data, others are unconstrained in shorter
wavelength scales. Nonetheless, each one of these models has a gravitational
wave density spectrum that can be compared to data. These lecture notes review
the formalism of gravitational waves in General Relativity and introduce
stochastic gravitational waves, primordial sources, and detection efforts.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:08:00 GMT""}]","2022-12-13"
"2212.05918","Birgit Vogel-Heuser Prof. Dr.-Ing.","Juliane Fischer, Birgit Vogel-Heuser, Heiko Schneider, Nikolai Langer,
  Markus Felger and Matthias Bengel","Measuring the Overall Complexity of Graphical and Textual IEC 61131-3
  Control Software","8 pages, https://ieeexplore.ieee.org/abstract/document/9444196/","Robotics and Automation Letters 6 (2021) 3","10.1109/LRA.2021.3084886",,"cs.SE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Software implements a significant proportion of functionality in factory
automation. Thus, efficient development and the reuse of software parts,
so-called units, enhance competitiveness. Thereby, complex control software
units are more difficult to understand, leading to increased development,
testing and maintenance costs. However, measuring complexity is challenging due
to many different, subjective views on the topic. This paper compares different
complexity definitions from literature and considers with a qualitative
questionnaire study the complexity perception of domain experts, who confirm
the importance of objective measures to compare complexity. The paper proposes
a set of metrics that measure various classes of software complexity to
identify the most complex software units as a prerequisite for refactoring. The
metrics include complexity caused by size, data structure, control flow,
information flow and lexical structure. Unlike most literature approaches, the
metrics are compliant with graphical and textual languages from the IEC 61131-3
standard. Further, a concept for interpreting the metric results is presented.
A comprehensive evaluation with industrial software from two German plant
manufacturers validates the metrics' suitability to measure complexity.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:10:44 GMT""}]","2022-12-13"
"2212.05920","Olivier Ramar\'e","Olivier Ramar\'e","A probabilistic language-free proof of an explicit Croot-Laba-Sisask
  Lemma",,,,,"math.NT math.PR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This note proposes a probabilistic language-free proof of the famous
Croot-Laba-Sisask Lemma. In between, we do the same for the Khintchine and
Marcinkiewicz-Zygmund inequalities and explicitate the implied constants.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 05:11:33 GMT""}]","2022-12-13"
"2212.05923","So Yeon Min","So Yeon Min, Yao-Hung Hubert Tsai, Wei Ding, Ali Farhadi, Ruslan
  Salakhutdinov, Yonatan Bisk, Jian Zhang","Self-Supervised Object Goal Navigation with In-Situ Finetuning",,,,,"cs.RO cs.LG","http://creativecommons.org/licenses/by/4.0/","  A household robot should be able to navigate to target objects without
requiring users to first annotate everything in their home. Most current
approaches to object navigation do not test on real robots and rely solely on
reconstructed scans of houses and their expensively labeled semantic 3D meshes.
In this work, our goal is to build an agent that builds self-supervised models
of the world via exploration, the same as a child might - thus we (1) eschew
the expense of labeled 3D mesh and (2) enable self-supervised in-situ
finetuning in the real world. We identify a strong source of self-supervision
(Location Consistency - LocCon) that can train all components of an ObjectNav
agent, using unannotated simulated houses. Our key insight is that embodied
agents can leverage location consistency as a self-supervision signal -
collecting images from different views/angles and applying contrastive
learning. We show that our agent can perform competitively in the real world
and simulation. Our results also indicate that supervised training with 3D mesh
annotations causes models to learn simulation artifacts, which are not
transferrable to the real world. In contrast, our LocCon shows the most robust
transfer in the real world among the set of models we compare to, and that the
real-world performance of all models can be further improved with
self-supervised LocCon in-situ training.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 03:41:40 GMT""},{""version"":""v2"",""created"":""Sun, 2 Apr 2023 01:39:47 GMT""}]","2023-04-04"
"2212.05925","Qiao Liu","Qiao Liu, Zhongren Chen, Wing Hung Wong","CausalEGM: a general causal inference framework by encoding generative
  modeling",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Although understanding and characterizing causal effects have become
essential in observational studies, it is challenging when the confounders are
high-dimensional. In this article, we develop a general framework
$\textit{CausalEGM}$ for estimating causal effects by encoding generative
modeling, which can be applied in both binary and continuous treatment
settings. Under the potential outcome framework with unconfoundedness, we
establish a bidirectional transformation between the high-dimensional
confounders space and a low-dimensional latent space where the density is known
(e.g., multivariate normal distribution). Through this, CausalEGM
simultaneously decouples the dependencies of confounders on both treatment and
outcome and maps the confounders to the low-dimensional latent space. By
conditioning on the low-dimensional latent features, CausalEGM can estimate the
causal effect for each individual or the average causal effect within a
population. Our theoretical analysis shows that the excess risk for CausalEGM
can be bounded through empirical process theory. Under an assumption on
encoder-decoder networks, the consistency of the estimate can be guaranteed. In
a series of experiments, CausalEGM demonstrates superior performance over
existing methods for both binary and continuous treatments. Specifically, we
find CausalEGM to be substantially more powerful than competing methods in the
presence of large sample sizes and high dimensional confounders. The software
of CausalEGM is freely available at https://github.com/SUwonglab/CausalEGM.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 20:40:57 GMT""},{""version"":""v2"",""created"":""Tue, 13 Dec 2022 02:15:25 GMT""},{""version"":""v3"",""created"":""Thu, 9 Feb 2023 02:08:32 GMT""},{""version"":""v4"",""created"":""Thu, 16 Mar 2023 21:32:56 GMT""}]","2023-03-20"
"2212.05958","Birgit Vogel-Heuser Prof. Dr.-Ing.","Juliane Fischer, Christian Lieberoth-Leden, Johannes Fottner and
  Birgit Vogel-Heuser","Design, Application and Evaluation of a Multi Agent System in the
  Logistics Domain","13 pages, https://ieeexplore.ieee.org/abstract/document/9042827/","IEEE Transactions on Automation Science and Engineering 17 (2020)
  3","10.1109/TASE.2020.2979137",,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The increasing demand for flexibility of automated production systems also
affects the automated material flow systems (aMFS) they contain and demands
reconfigurable systems. However, the centralized control concept usually
applied in aMFS hinders an easy adaptation, as the entire control software has
to be re-tested, when manually changing sub-parts of the control. As adaption
and subsequent testing are a time-consuming task, concepts for splitting the
control from one centralized to multiple, decentralized control nodes are
required. Therefore, this paper presents a holistic agent-based control concept
for aMFS, whereby the system is divided into so-called automated material flow
modules (aMFM), each being controlled by a dedicated module agent. The concept
allows the reconfiguration of aMFS, consisting of heterogeneous, stationary
aMFM, during runtime. Furthermore, it includes aspects such as uniform agent
knowledge bases through metamodel-based development, a communication ontology
considering different information types and properties, strategic route
optimization in decentralized control architecture and a visualization concept
to make decisions of the module agents comprehensible to operators and
maintenance staff. The evaluation of the concept is performed by means of
material flow simulations as well as a prototypical implementation on a
lab-sized demonstrator.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:38:14 GMT""}]","2022-12-13"
"2212.05960","Birgit Vogel-Heuser Prof. Dr.-Ing.","Sebastian Ulewicz and Birgit Vogel-Heuser","Industrially Applicable System Regression Test Prioritization in
  Production Automation","13 pages, https://ieeexplore.ieee.org/abstract/document/8320514/","IEEE Transactions on Automation Science and Engineering 1 (2018)
  99","10.1109/TASE.2018.2810280",,"cs.SE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  When changes are performed on an automated production system (aPS), new
faults can be accidentally introduced in the system, which are called
regressions. A common method for finding these faults is regression testing. In
most cases, this regression testing process is performed under high time
pressure and on-site in a very uncomfortable environment. Until now, there is
no automated support for finding and prioritizing system test cases regarding
the fully integrated aPS that are suitable for finding regressions. Thus, the
testing technician has to rely on personal intuition and experience, possibly
choosing an inappropriate order of test cases, finding regressions at a very
late stage of the test run. Using a suitable prioritization, this iterative
process of finding and fixing regressions can be streamlined and a lot of time
can be saved by executing test cases likely to identify new regressions
earlier. Thus, an approach is presented in this paper that uses previously
acquired runtime data from past test executions and performs a change
identification and impact analysis to prioritize test cases that have a high
probability to unveil regressions caused by side effects of a system change.
The approach was developed in cooperation with reputable industrial partners
active in the field of aPS engineering, ensuring a development in line with
industrial requirements. An industrial case study and an expert evaluation were
performed, showing promising results.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:44:52 GMT""}]","2022-12-13"
"2212.05965","Juan-Jose Prieto-Gutierrez","Francisco Segado-Boj, Juan Martin-Quevedo, Juan-Jose Prieto-Gutierrez","Jumping over the paywall: Strategies and motivations for scholarly
  piracy and other alternatives",,,,,"cs.DL","http://creativecommons.org/licenses/by/4.0/","  Despite the advance of the Open Access (OA) movement, most scholarly
production can only be accessed through a paywall. We conduct an international
survey among researchers (N=3,304) to measure the willingness and motivations
to use (or not use) scholarly piracy sites, and other alternatives to overcome
a paywall such as paying with their own money, institutional loans, just
reading the abstract, asking the corresponding author for a copy of the
document, asking a colleague to get the document for them, or searching for an
OA version of the paper. We also explore differences in terms of age,
professional position, country income level, discipline, and commitment to OA.
The results show that researchers most frequently look for OA versions of the
documents. However, more than 50% of the participants have used a scholarly
piracy site at least once. This is less common in high-income countries, and
among older and better-established scholars. Regarding disciplines, such
services were less used in Life & Health Sciences and Social Sciences. Those
who have never used a pirate library highlighted ethical and legal objections
or pointed out that they were not aware of the existence of such libraries.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 10:24:13 GMT""}]","2022-12-13"
"2212.05970","Sayem Mohammad Imtiaz","Sayem Mohammad Imtiaz, Fraol Batole, Astha Singh, Rangeet Pan, Breno
  Dantas Cruz, Hridesh Rajan","Decomposing a Recurrent Neural Network into Modules for Enabling
  Reusability and Replacement","Accepted at 45th international conference on software engineering
  (ICSE'2023)",,,,"cs.SE cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Can we take a recurrent neural network (RNN) trained to translate between
languages and augment it to support a new natural language without retraining
the model from scratch? Can we fix the faulty behavior of the RNN by replacing
portions associated with the faulty behavior? Recent works on decomposing a
fully connected neural network (FCNN) and convolutional neural network (CNN)
into modules have shown the value of engineering deep models in this manner,
which is standard in traditional SE but foreign for deep learning models.
However, prior works focus on the image-based multiclass classification
problems and cannot be applied to RNN due to (a) different layer structures,
(b) loop structures, (c) different types of input-output architectures, and (d)
usage of both nonlinear and logistic activation functions. In this work, we
propose the first approach to decompose an RNN into modules. We study different
types of RNNs, i.e., Vanilla, LSTM, and GRU. Further, we show how such RNN
modules can be reused and replaced in various scenarios. We evaluate our
approach against 5 canonical datasets (i.e., Math QA, Brown Corpus,
Wiki-toxicity, Clinc OOS, and Tatoeba) and 4 model variants for each dataset.
We found that decomposing a trained model has a small cost (Accuracy: -0.6%,
BLEU score: +0.10%). Also, the decomposed modules can be reused and replaced
without needing to retrain.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 03:29:38 GMT""},{""version"":""v2"",""created"":""Thu, 15 Dec 2022 02:52:34 GMT""},{""version"":""v3"",""created"":""Thu, 9 Feb 2023 11:33:25 GMT""}]","2023-02-10"
"2212.06140","Sumon Biswas","Sumon Biswas and Hridesh Rajan","Fairify: Fairness Verification of Neural Networks",,"ICSE 2023: The 45th International Conference on Software
  Engineering, Melbourne, Australia",,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Fairness of machine learning (ML) software has become a major concern in the
recent past. Although recent research on testing and improving fairness have
demonstrated impact on real-world software, providing fairness guarantee in
practice is still lacking. Certification of ML models is challenging because of
the complex decision-making process of the models. In this paper, we proposed
Fairify, an SMT-based approach to verify individual fairness property in neural
network (NN) models. Individual fairness ensures that any two similar
individuals get similar treatment irrespective of their protected attributes
e.g., race, sex, age. Verifying this fairness property is hard because of the
global checking and non-linear computation nodes in NN. We proposed sound
approach to make individual fairness verification tractable for the developers.
The key idea is that many neurons in the NN always remain inactive when a
smaller part of the input domain is considered. So, Fairify leverages whitebox
access to the models in production and then apply formal analysis based
pruning. Our approach adopts input partitioning and then prunes the NN for each
partition to provide fairness certification or counterexample. We leveraged
interval arithmetic and activation heuristic of the neurons to perform the
pruning as necessary. We evaluated Fairify on 25 real-world neural networks
collected from four different sources, and demonstrated the effectiveness,
scalability and performance over baseline and closely related work. Fairify is
also configurable based on the domain and size of the NN. Our novel formulation
of the problem can answer targeted verification queries with relaxations and
counterexamples, which have practical implications.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 23:31:06 GMT""},{""version"":""v2"",""created"":""Wed, 14 Dec 2022 02:18:09 GMT""}]","2022-12-15"
"2212.06141","Xing Lin","Ziyang Zheng, Zhengyang Duan, Hang Chen, Rui Yang, Sheng Gao, Haiou
  Zhang, Hongkai Xiong, Xing Lin","Dual adaptive training of photonic neural networks","31 pages, 11 figures",,,,"cs.LG cs.AI physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Photonic neural network (PNN) is a remarkable analog artificial intelligence
(AI) accelerator that computes with photons instead of electrons to feature low
latency, high energy efficiency, and high parallelism. However, the existing
training approaches cannot address the extensive accumulation of systematic
errors in large-scale PNNs, resulting in a significant decrease in model
performance in physical systems. Here, we propose dual adaptive training (DAT)
that allows the PNN model to adapt to substantial systematic errors and
preserves its performance during the deployment. By introducing the systematic
error prediction networks with task-similarity joint optimization, DAT achieves
the high similarity mapping between the PNN numerical models and physical
systems and high-accurate gradient calculations during the dual backpropagation
training. We validated the effectiveness of DAT by using diffractive PNNs and
interference-based PNNs on image classification tasks. DAT successfully trained
large-scale PNNs under major systematic errors and preserved the model
classification accuracies comparable to error-free systems. The results further
demonstrated its superior performance over the state-of-the-art in situ
training approaches. DAT provides critical support for constructing large-scale
PNNs to achieve advanced architectures and can be generalized to other types of
AI systems with analog computing errors.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 05:03:45 GMT""}]","2022-12-14"
"2212.06142","Shiyu Liu","Shiyu Liu, Rohan Ghosh, Mehul Motani","Towards Better Long-range Time Series Forecasting using Generative
  Forecasting","14 pages. arXiv admin note: substantial text overlap with
  arXiv:2110.08770",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Long-range time series forecasting is usually based on one of two existing
forecasting strategies: Direct Forecasting and Iterative Forecasting, where the
former provides low bias, high variance forecasts and the latter leads to low
variance, high bias forecasts. In this paper, we propose a new forecasting
strategy called Generative Forecasting (GenF), which generates synthetic data
for the next few time steps and then makes long-range forecasts based on
generated and observed data. We theoretically prove that GenF is able to better
balance the forecasting variance and bias, leading to a much smaller
forecasting error. We implement GenF via three components: (i) a novel
conditional Wasserstein Generative Adversarial Network (GAN) based generator
for synthetic time series data generation, called CWGAN-TS. (ii) a transformer
based predictor, which makes long-range predictions using both generated and
observed data. (iii) an information theoretic clustering algorithm to improve
the training of both the CWGAN-TS and the transformer based predictor. The
experimental results on five public datasets demonstrate that GenF
significantly outperforms a diverse range of state-of-the-art benchmarks and
classical approaches. Specifically, we find a 5% - 11% improvement in
predictive performance (mean absolute error) while having a 15% - 50% reduction
in parameters compared to the benchmarks. Lastly, we conduct an ablation study
to further explore and demonstrate the effectiveness of the components
comprising GenF.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:35:39 GMT""}]","2022-12-14"
"2212.06143","Shiyu Liu","Shiyu Liu, Mehul Motani","Improving Mutual Information based Feature Selection by Boosting Unique
  Relevance","13 pages",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mutual Information (MI) based feature selection makes use of MI to evaluate
each feature and eventually shortlists a relevant feature subset, in order to
address issues associated with high-dimensional datasets. Despite the
effectiveness of MI in feature selection, we notice that many state-of-the-art
algorithms disregard the so-called unique relevance (UR) of features, and
arrive at a suboptimal selected feature subset which contains a non-negligible
number of redundant features. We point out that the heart of the problem is
that all these MIBFS algorithms follow the criterion of Maximize Relevance with
Minimum Redundancy (MRwMR), which does not explicitly target UR. This motivates
us to augment the existing criterion with the objective of boosting unique
relevance (BUR), leading to a new criterion called MRwMR-BUR. Depending on the
task being addressed, MRwMR-BUR has two variants, termed MRwMR-BUR-KSG and
MRwMR-BUR-CLF, which estimate UR differently. MRwMR-BUR-KSG estimates UR via a
nearest-neighbor based approach called the KSG estimator and is designed for
three major tasks: (i) Classification Performance. (ii) Feature
Interpretability. (iii) Classifier Generalization. MRwMR-BUR-CLF estimates UR
via a classifier based approach. It adapts UR to different classifiers, further
improving the competitiveness of MRwMR-BUR for classification performance
oriented tasks. The performance of both MRwMR-BUR-KSG and MRwMR-BUR-CLF is
validated via experiments using six public datasets and three popular
classifiers. Specifically, as compared to MRwMR, the proposed MRwMR-BUR-KSG
improves the test accuracy by 2% - 3% with 25% - 30% fewer features being
selected, without increasing the algorithm complexity. MRwMR-BUR-CLF further
improves the classification performance by 3.8%- 5.5% (relative to MRwMR), and
it also outperforms three popular classifier dependent feature selection
methods.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:55:45 GMT""},{""version"":""v2"",""created"":""Sat, 17 Dec 2022 09:52:10 GMT""}]","2022-12-20"
"2212.06144","Shiyu Liu","Shiyu Liu, Rohan Ghosh, John Tan Chong Min, Mehul Motani","Optimizing Learning Rate Schedules for Iterative Pruning of Deep Neural
  Networks","23 Pages. arXiv admin note: text overlap with arXiv:2110.08764",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The importance of learning rate (LR) schedules on network pruning has been
observed in a few recent works. As an example, Frankle and Carbin (2019)
highlighted that winning tickets (i.e., accuracy preserving subnetworks) can
not be found without applying a LR warmup schedule and Renda, Frankle and
Carbin (2020) demonstrated that rewinding the LR to its initial state at the
end of each pruning cycle improves performance. In this paper, we go one step
further by first providing a theoretical justification for the surprising
effect of LR schedules. Next, we propose a LR schedule for network pruning
called SILO, which stands for S-shaped Improved Learning rate Optimization. The
advantages of SILO over existing state-of-the-art (SOTA) LR schedules are
two-fold: (i) SILO has a strong theoretical motivation and dynamically adjusts
the LR during pruning to improve generalization. Specifically, SILO increases
the LR upper bound (max_lr) in an S-shape. This leads to an improvement of 2% -
4% in extensive experiments with various types of networks (e.g., Vision
Transformers, ResNet) on popular datasets such as ImageNet, CIFAR-10/100. (ii)
In addition to the strong theoretical motivation, SILO is empirically optimal
in the sense of matching an Oracle, which exhaustively searches for the optimal
value of max_lr via grid search. We find that SILO is able to precisely adjust
the value of max_lr to be within the Oracle optimized interval, resulting in
performance competitive with the Oracle with significantly lower complexity.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:39:50 GMT""},{""version"":""v2"",""created"":""Sat, 31 Dec 2022 01:55:11 GMT""}]","2023-01-03"
"2212.06145","Shiyu Liu","Shiyu Liu, Rohan Ghosh, Dylan Tan, Mehul Motani","AP: Selective Activation for De-sparsifying Pruned Neural Networks","16 Pages",,,,"cs.LG cs.AI cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The rectified linear unit (ReLU) is a highly successful activation function
in neural networks as it allows networks to easily obtain sparse
representations, which reduces overfitting in overparameterized networks.
However, in network pruning, we find that the sparsity introduced by ReLU,
which we quantify by a term called dynamic dead neuron rate (DNR), is not
beneficial for the pruned network. Interestingly, the more the network is
pruned, the smaller the dynamic DNR becomes during optimization. This motivates
us to propose a method to explicitly reduce the dynamic DNR for the pruned
network, i.e., de-sparsify the network. We refer to our method as
Activating-while-Pruning (AP). We note that AP does not function as a
stand-alone method, as it does not evaluate the importance of weights. Instead,
it works in tandem with existing pruning methods and aims to improve their
performance by selective activation of nodes to reduce the dynamic DNR. We
conduct extensive experiments using popular networks (e.g., ResNet, VGG) via
two classical and three state-of-the-art pruning methods. The experimental
results on public datasets (e.g., CIFAR-10/100) suggest that AP works well with
existing pruning methods and improves the performance by 3% - 4%. For larger
scale datasets (e.g., ImageNet) and state-of-the-art networks (e.g., vision
transformer), we observe an improvement of 2% - 3% with AP as opposed to
without. Lastly, we conduct an ablation study to examine the effectiveness of
the components comprising AP.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:49:15 GMT""}]","2022-12-14"
"2212.06607","Birgit Vogel-Heuser Prof. Dr.-Ing.","Birgit Vogel-Heuser, Daniel Schuetz, Timo Frank and Christoph Legat","Model-driven Engineering of Manufacturing Automation Software Projects
  -- A SysML-based Approach","26 pages,
  https://www.sciencedirect.com/science/article/pii/S0957415814000853","Mechatronics 24 (2014) 7","10.1016/j.mechatronics.2014.05.003",,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper comprises a SysML-based approach to support the model-driven
engineering (MDE) of Manufacturing Automation Software Projects (MASP). The
Systems Modeling Language (SysML) is adapted to define the SysML-AT (SysML for
automation), a specialized language profile that covers (non-)functional
requirements, corresponding software applications and properties of proprietary
hardware components. Furthermore, SysML-AT supports an automated software
generation for run-time environments conforming to IEC 61131-3. A prototypical
tool support was realized for adapted SysML Parametric Diagrams (PD) inside an
industrial automation software development tool. Coupling the model editor and
online data from the provided run-time environment enables direct debugging
inside the model. The approach was evaluated by several case studies and
additional usability experiments. With the latter, the suitability of the MDE
approach for future users was proven.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:00:38 GMT""}]","2022-12-14"
"2212.06772","Cameron Mura","Cameron Mura, Emma Candelier, Lei Xie","A Tribute to Phil Bourne -- Scientist and Human","5 pages, 1 figure",,,,"q-bio.OT","http://creativecommons.org/licenses/by/4.0/","  This Special Issue of Biomolecules, commissioned in honor of Dr. Philip E.
Bourne, focuses on a new field of biomolecular data science. In this brief
retrospective, we consider the arc of Bourne's 40-year scientific and
professional career, particularly as it relates to the origins of this new
field.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 21:29:09 GMT""}]","2022-12-14"
"2212.06814","Muhammad Sharif","M. Sharif and Tayyab Naseer","Isotropization and Complexity Analysis of Decoupled Solutions in
  $f(\mathbb{R},\mathbb{T})$ Theory","29 pages, 11 figures","Eur. Phys. J. Plus 137(2022)1304",,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper formulates some new exact solutions to the field equations by
means of minimal gravitational decoupling in the context of
$f(\mathbb{R},\mathbb{T})$ gravity. For this purpose, we consider anisotropic
spherical matter distribution and add an extra source to extend the existing
solutions. We apply the transformation only on the radial metric potential that
results in two different sets of the modified field equations, each of them
corresponding to their parent source. The initial anisotropic source is
represented by the first set, and we consider two different well-behaved
solutions to close that system. On the other hand, we impose constraints on the
additional source to make the second set solvable. We, firstly, employ the
isotropization condition which leads to an isotropic system for a particular
value of the decoupling parameter. We then use the condition of zero complexity
of the total configuration to obtain the other solution. The unknowns are
determined by smoothly matching the interior and exterior spacetimes at the
hypersurface. The physical viability and stability of the obtained solutions is
analyzed by using the mass and radius of a compact star $4U 1820-30$. It is
concluded that both of our extended solutions meet all the physical
requirements for considered values of the coupling/decoupling parameters.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 02:23:05 GMT""}]","2022-12-14"
"2212.08104","Rebeca Garcia-Fandino","Alexandre Blanco-Gonzalez, Alfonso Cabezon, Alejandro Seco-Gonzalez,
  Daniel Conde-Torres, Paula Antelo-Riveiro, Angel Pineiro, Rebeca
  Garcia-Fandino","The Role of AI in Drug Discovery: Challenges, Opportunities, and
  Strategies","11 pages, 1 figure",,,,"cs.CL cs.AI cs.CY","http://creativecommons.org/licenses/by/4.0/","  Artificial intelligence (AI) has the potential to revolutionize the drug
discovery process, offering improved efficiency, accuracy, and speed. However,
the successful application of AI is dependent on the availability of
high-quality data, the addressing of ethical concerns, and the recognition of
the limitations of AI-based approaches. In this article, the benefits,
challenges and drawbacks of AI in this field are reviewed, and possible
strategies and approaches for overcoming the present obstacles are proposed.
The use of data augmentation, explainable AI, and the integration of AI with
traditional experimental methods, as well as the potential advantages of AI in
pharmaceutical research are also discussed. Overall, this review highlights the
potential of AI in drug discovery and provides insights into the challenges and
opportunities for realizing its potential in this field.
  Note from the human-authors: This article was created to test the ability of
ChatGPT, a chatbot based on the GPT-3.5 language model, to assist human authors
in writing review articles. The text generated by the AI following our
instructions (see Supporting Information) was used as a starting point, and its
ability to automatically generate content was evaluated. After conducting a
thorough review, human authors practically rewrote the manuscript, striving to
maintain a balance between the original proposal and scientific criteria. The
advantages and limitations of using AI for this purpose are discussed in the
last section.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 23:23:39 GMT""}]","2022-12-19"
"2212.08105","Xunzhu Tang","Xunzhu Tang and Rujie Zhu and Tiezhu Sun and Shi Wang","Moto: Enhancing Embedding with Multiple Joint Factors for Chinese Text
  Classification",,,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, language representation techniques have achieved great performances
in text classification. However, most existing representation models are
specifically designed for English materials, which may fail in Chinese because
of the huge difference between these two languages. Actually, few existing
methods for Chinese text classification process texts at a single level.
However, as a special kind of hieroglyphics, radicals of Chinese characters are
good semantic carriers. In addition, Pinyin codes carry the semantic of tones,
and Wubi reflects the stroke structure information, \textit{etc}.
Unfortunately, previous researches neglected to find an effective way to
distill the useful parts of these four factors and to fuse them. In our works,
we propose a novel model called Moto: Enhancing Embedding with
\textbf{M}ultiple J\textbf{o}int Fac\textbf{to}rs. Specifically, we design an
attention mechanism to distill the useful parts by fusing the four-level
information above more effectively. We conduct extensive experiments on four
popular tasks. The empirical results show that our Moto achieves SOTA 0.8316
($F_1$-score, 2.11\% improvement) on Chinese news titles, 96.38 (1.24\%
improvement) on Fudan Corpus and 0.9633 (3.26\% improvement) on THUCNews.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:45:57 GMT""}]","2022-12-19"
"2212.08111","Chenghua Lin","Noor Fazilla Abd Yusof, Chenghua Lin","Routine Outcome Monitoring in Psychotherapy Treatment using
  Sentiment-Topic Modelling Approach",,,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite the importance of emphasizing the right psychotherapy treatment for
an individual patient, assessing the outcome of the therapy session is equally
crucial. Evidence showed that continuous monitoring patient's progress can
significantly improve the therapy outcomes to an expected change. By monitoring
the outcome, the patient's progress can be tracked closely to help clinicians
identify patients who are not progressing in the treatment. These monitoring
can help the clinician to consider any necessary actions for the patient's
treatment as early as possible, e.g., recommend different types of treatment,
or adjust the style of approach. Currently, the evaluation system is based on
the clinical-rated and self-report questionnaires that measure patients'
progress pre- and post-treatment. While outcome monitoring tends to improve the
therapy outcomes, however, there are many challenges in the current method,
e.g. time and financial burden for administering questionnaires, scoring and
analysing the results. Therefore, a computational method for measuring and
monitoring patient progress over the course of treatment is needed, in order to
enhance the likelihood of positive treatment outcome. Moreover, this
computational method could potentially lead to an inexpensive monitoring tool
to evaluate patients' progress in clinical care that could be administered by a
wider range of health-care professionals.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 20:14:10 GMT""}]","2022-12-19"
"2212.09474","Birgit Vogel-Heuser Prof. Dr.-Ing.","Birgit Vogel-Heuser, Eva-Maria Neumann and Juliane Fischer","MICOSE4aPS: Industrially Applicable Maturity Metric to Improve
  Systematic Reuse of Control Software","19 pages, https://dl.acm.org/doi/abs/10.1145/3467896","ACM Transactions on Software Engineering and Methodology (TOSEM)
  Journalverlag ACM, New York, NY, USA Jahr 2022 ACM Transactions on software
  Engineering and Methodology (TOSEM) 31 (2022) 1","10.1145/3467896",,"cs.SE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  automated Production Systems (aPS) are highly complex, mechatronic systems
that usually have to operate reliably for many decades. Standardization and
reuse of control software modules is a core prerequisite to achieve the
required system quality in increasingly shorter development cycles. However,
industrial case studies in the field of aPS show that many aPS companies still
struggle with strategically reusing software. This paper proposes a
metric-based approach to objectively measure the maturity of industrial IEC
61131-based control software in aPS (MICOSE4aPS) to identify potential
weaknesses and quality issues hampering systematic reuse. Module developers in
the machine and plant manufacturing industry can directly benefit as the metric
calculation is integrated into the software engineering workflow. An in-depth
industrial evaluation in a top-ranked machine manufacturing company in food
packaging and an expert evaluation with different companies confirmed the
benefit to efficiently manage the quality of control software.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:39:27 GMT""}]","2022-12-20"
"2212.09475","Birgit Vogel-Heuser Prof. Dr.-Ing.","Martin Obermeier, Steven Braun, Birgit Vogel-Heuser","A Model Driven Approach on Object Oriented PLC Programming for
  Manufacturing Systems with regard to Usability","14 pages, https://ieeexplore.ieee.org/abstract/document/6873317","IEEE Transactions on Industrial Informatics 11 (2014) 3","10.1109/TII.2014.2346133",,"cs.SE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper presents the modular automation for reuse in manufacturing systems
(modAT4rMS) approach to support the model-driven engineering (MDE) of object
oriented manufacturing automation software with regard to its usability and
software modularity. With usability we refer to the aspects effectiveness,
efficiency and user acceptance, as defined by ISO 9241-11. The modAT4rMS
notations are based on selected features from the Unified Modeling Language
(UML) and the Systems Modeling language (SysML) and iteratively further
developed by a series of empirical studies with industrial practitioners as
well as mechatronics trainees. With modAT4rMS a MDE approach for Programmable
Logic Controller (PLC) programming was developed with the goal to facilitate
modular object oriented programming of PLC software by improving the
representation of the relationships between the structure and behavior diagram
types and by reducing the level of abstraction in the structure model.
modAT4rMS notations for PLC software structure and software behavior modeling
are presented and illustrated with a modeling example using a modAT4rMS editor
prototype. For the evaluation of the developed notations the results from a
study with 168 participants is presented, showing the benefits of this new
approach in comparison to the classic procedural paradigm (IEC 61131-3) and the
domain specific UML profile plcML in regard to programming performance and
usability aspects. Finally the advantages and limitations of the approach are
discussed and an outlook for further development is given.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:25:47 GMT""}]","2022-12-20"
"2212.09476","Birgit Vogel-Heuser Prof. Dr.-Ing.","Birgit Vogel-Heuser, Juliane Fischer, Dieter Hess, Eva-Maria Neumann,
  Marcus Wuerr","Boosting Extra-functional Code Reusability in Cyber-physical Production
  Systems: The Error Handling Case Study","13 pages, https://ieeexplore.ieee.org/abstract/document/9687320/","Transactions on Emerging Topics in Computing (TETC) 10 (2022) 1","10.1109/TETC.2022.3142816",,"cs.SE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Cyber-Physical Production Systems (CPPS) are long-living and mechatronic
systems, which include mechanics, electrics/electronics and software. The
interdisciplinary nature combined with challenges and trends in the context of
Industry 4.0 such as a high degree of customization, small lot sizes and
evolution cause a high amount of variability. Mastering the variability of
functional control software, e.g., different control variants of an actuator
type, is itself a challenge in developing and reusing CPPS software. This task
becomes even more complex when considering extra-functional software such as
operating modes, diagnosis and error handling. These software parts have high
interdependencies with functional software, often involving the human-machine
interface (HMI) to enable the intervention of operators. This paper illustrates
the challenges in documenting the dependencies of these software parts
including their variability using family models. A procedural and an
object-oriented concept for implementing error handling, which represents an
extra-functional task with high dependencies to functional software and the
HMI, are proposed. The suitability of both concepts to increase the software's
reusability and, thus, its flexibility in the context of Industry 4.0 is
discussed. Their comparison confirms the high potential of the object-oriented
extension of IEC 61131-3 to handle planned reuse of extra-functional CPPS
software successfully.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:04:08 GMT""}]","2022-12-20"
"2212.11124","Prasath Murugesan","Prasath Murugesan, Shamshu Dharwez Saganvali","An AI-Powered VVPAT Counter for Elections in India","4 pages, 4 figures",,,,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Election Commission of India has introduced Voter Verified Paper Audit
Trail since 2019. This mechanism has increased voter confidence at the time of
casting the votes. However, physical verification of the VVPATs against the
party level counts from the EVMs is done only in 5 (randomly selected) machines
per constituency. The time required to conduct physical verification becomes a
bottleneck in scaling this activity for 100% of machines in all constituencies.
We proposed an automated counter powered by image processing and machine
learning algorithms to speed up the process and address this issue.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:59:40 GMT""}]","2022-12-22"
"2212.11147","Michael Mislove","Benedetto Intrigila, Giulio Manzonetto, Nicolas Munnich","Extended Addressing Machines for PCF, with Explicit Substitutions","16 pages, 5 pages appendix","Electronic Notes in Theoretical Informatics and Computer Science,
  February 2023. Proceedings of MFPS 2022","10.46298/entics.10533",,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  Addressing machines have been introduced as a formalism to construct models
of the pure, untyped lambda-calculus. We extend the syntax of their programs by
adding instructions for executing arithmetic operations on natural numbers, and
introduce a reflection principle allowing certain machines to access their own
address and perform recursive calls. We prove that the resulting extended
addressing machines naturally model a weak call-by-name PCF with explicit
substitutions. Finally, we show that they are also well-suited for representing
regular PCF programs (closed terms) computing natural numbers.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 15:12:48 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 16:59:50 GMT""},{""version"":""v3"",""created"":""Wed, 15 Feb 2023 21:02:54 GMT""},{""version"":""v4"",""created"":""Mon, 20 Feb 2023 15:52:49 GMT""}]","2023-02-21"
"2212.11173","Boris Shminke","Boris Shminke","Python client for Isabelle server","5 pages, 1 figure, submitted to CICM 2022
  (https://cicm-conference.org/2022/)",,,,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  We contribute a Python client for the Isabelle server, which gives
researchers and students using Python as their primary programming language an
opportunity to communicate with the Isabelle server through TCP directly from a
Python script. Such an approach helps avoid the complexities of integrating the
existing Python script with languages used for Isabelle development (ML and
Scala). We also describe new features that appeared since the announcement of
the first version of the client a year ago. Finally, we give examples of the
client's applications in research and education and discuss known limitations
and possible directions for future development.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 12:05:28 GMT""}]","2022-12-22"
"2212.12002","Oswaldo Pe\~naherrera","O. S. Pe\~naherrera-Pulla and Carlos Baena and Sergio Fortes and
  Raquel Barco","ML-powered KQI estimation for XR services. A case study on 360-Video","This article has been submitted to Elsevier for possible publication.
  Copyright may be transferred without notice and this version might not be
  longer available",,,,"cs.NI cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The arise of cutting-edge technologies and services such as XR promise to
change the concepts of how day-to-day things are done. At the same time, the
appearance of modern and decentralized architectures approaches has given birth
to a new generation of mobile networks such as 5G, as well as outlining the
roadmap for B5G and posterior. These networks are expected to be the enablers
for bringing to life the Metaverse and other futuristic approaches. In this
sense, this work presents an ML-based (Machine Learning) framework that allows
the estimation of service Key Quality Indicators (KQIs). For this, only
information reachable to operators is required, such as statistics and
configuration parameters from these networks. This strategy prevents operators
from avoiding intrusion into the user data and guaranteeing privacy. To test
this proposal, 360-Video has been selected as a use case of Virtual Reality
(VR), from which specific KQIs are estimated such as video resolution, frame
rate, initial startup time, throughput, and latency, among others. To select
the best model for each KQI, a search grid with a cross-validation strategy has
been used to determine the best hyperparameter tuning. To boost the creation of
each KQI model, feature engineering techniques together with cross-validation
strategies have been used. The performance is assessed using MAE (Mean Average
Error) and the prediction time. The outcomes point out that KNR (K-Near
Neighbors) and RF (Random Forest) are the best algorithms in combination with
Feature Selection techniques. Likewise, this work will help as a baseline for
E2E-Quality-of-Experience-based network management working in conjunction with
network slicing, virtualization, and MEC, among other enabler technologies.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:30:23 GMT""}]","2022-12-26"
"2212.12339","Manuel Alberto M. Ferreira Prof. Dr.","Ros\'ario Laureano and Manuel Alberto M. Ferreira","Poincar\'e Work on Celestial Mechanics: Predictability versus
  Determinism in the Context of Restricted Three-Body Problem","7 pages and no figures",,,,"math.HO","http://creativecommons.org/licenses/by/4.0/","  The publication of Principia Mathematica in 1678 by Newton became known the
celestial bodies motion laws, which characterize the Classical Mechanics.
Thereafter made sense to search about the movement of these bodies from known
initial conditions, particularly in the 3 body problem. In this paper it is
exposed the influence of Poincar\'e work, in 1880, in this problem on the
beginning of Deterministic Chaos Theory based on the development of several new
qualitative tools. The application of such tools led him to the discovery of a
special kind of behavior: the dynamical instability. Contrary to the common
idea that this kind of behavior was first evidenced by Lorenz in 1963, the
Poincar\'e theoretical research was sufficiently clear about the existence of
chaotic deterministic behavior. Until the time of Poincar\'e, there was a tacit
assumption that the uncertainty in the output does not arise from any
randomness in the dynamical laws, since they are completely deterministic, but
rather from the lack of the infinite accuracy in the initial conditions. In
this paper it is emphasized that the issues of determinism and predictability
are distinct.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 17:13:19 GMT""}]","2022-12-26"
"2212.13106","Slobodan Prvanovic","Slobodan Prvanovic","Complexified spinor fields in operator form",,,,,"physics.gen-ph hep-ph","http://creativecommons.org/licenses/by/4.0/","  The formalism of quantum field theory in operator form, based on the anti
self-adjoint operators of the imaginary coordinate and momentum and the
self-adjoint operators of the real coordinate, momentum, energy and time, is
used in considerations of the spinor fields and related topics. The unitary
representation of the Lorentz boosts in the spin-orbital space is given. The
operators that mirror-reflect the spin are introduced and then used in
discussion of the spin parity. The conclusion that the spin is odd is used in
the analyze of the parity violation in the cobalt-60 beta decay and it is found
that the parity is not broken. The explanation why there are only right-handed
antineutrinos and left-handed neutrinos is offered on the basis of appropriate
treatment of the influence of spin on momentum. The inversion of time is
treated within the framework of the operators of time and energy and this
symmetry is represented in a way that respects the Schr\""odinger equation and
this is done by the Wick rotations of involved operators and vectors of the
complexified formalism.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 23:27:31 GMT""}]","2022-12-27"
"2212.13116","Andrei Bytsko","Andrei Bytsko","On orthogonal projections related to representations of the Hecke
  algebra on a tensor space","12 pages, LaTeX","Journal of Mathematical Physics, v.63 (2022) 081701","10.1063/5.0102693",,"math.RT math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of finding orthogonal projections $P$ of a rank $r$
that give rise to representations of the Hecke algebra $H_N(q)$ in which the
generators of the algebra act locally on the $N$-th tensor power of the space
${\mathbb C}^n$. It is shown that such projections are global minima of a
certain functional. It is also shown that a characteristic property of such
projections is that a certain positive definite matrix $A$ has only two
eigenvalues or only one eigenvalue if $P$ gives rise to a representation of the
Temperley-Lieb algebra. Apart from the parameters $n$, $r$, and $Q=q + q^{-1}$,
an additional parameter $k$ proves to be a useful characteristic of a
projection $P$. In particular, we use it to provide a lower bound for $Q$ when
the values of $n$ and $r$ are fixed and we show that $k=r n$ if and only if $P$
is of the Temperley-Lieb type. Besides, we propose an approach to constructing
projections $P$ and give some novel examples for $n=3$.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 00:15:30 GMT""}]","2023-01-04"
"2212.13120","Naoya Chiba","Naoya Chiba, Yuta Suzuki, Tatsunori Taniai, Ryo Igarashi, Yoshitaka
  Ushiku, Kotaro Saito, Kanta Ono","Neural Structure Fields with Application to Crystal Structure
  Autoencoders","16 pages , 6 figures. 13 pages Supplementary Information",,,,"cond-mat.mtrl-sci cs.LG physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Representing crystal structures of materials to facilitate determining them
via neural networks is crucial for enabling machine-learning applications
involving crystal structure estimation. Among these applications, the inverse
design of materials can contribute to next-generation methods that explore
materials with desired properties without relying on luck or serendipity. We
propose neural structure fields (NeSF) as an accurate and practical approach
for representing crystal structures using neural networks. Inspired by the
concepts of vector fields in physics and implicit neural representations in
computer vision, the proposed NeSF considers a crystal structure as a
continuous field rather than as a discrete set of atoms. Unlike existing
grid-based discretized spatial representations, the NeSF overcomes the tradeoff
between spatial resolution and computational complexity and can represent any
crystal structure. To evaluate the NeSF, we propose an autoencoder of crystal
structures that can recover various crystal structures, such as those of
perovskite structure materials and cuprate superconductors. Extensive
quantitative results demonstrate the superior performance of the NeSF compared
with the existing grid-based approach.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 16:41:41 GMT""}]","2022-12-27"
"2212.13987","Yanjiao Ruan","Ruan Yanjiao","Encryption Mechanism And Resource Allocation Optimization Based On Edge
  Computing Environment",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A method for optimizing encryption mechanism and resource allocation based on
edge computing environment is proposed. A local differential privacy algorithm
based on a histogram algorithm is used to protect user information during task
offloading, which allows accurate preservation of user contextual information
while reducing interference with the playback decision. To efficiently offload
tasks and improve offloading performance, a joint optimization algorithm for
task offloading and resource allocation is proposed that optimizes overall
latency. A balance will be found between privacy protection and task offloading
accuracy. The impact of contextual data interference on task offloading
decisions is minimized while ensuring a predefined level of privacy protection.
In the concrete connected vehicle example, the method distributes tasks among
roadside devices and neighboring vehicles with sufficient computational
resources.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 02:52:19 GMT""}]","2022-12-29"
"2212.14797","Asma Bensalah","Asma Bensalah, Alicia Forn\'es, Cristina Carmona-Duarte, and Josep
  Llad\'os","Easing Automatic Neurorehabilitation via Classification and Smoothness
  Analysis",,,"10.1007/978-3-031-19745-1_25",,"eess.SP cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Assessing the quality of movements for post-stroke patients during the
rehabilitation phase is vital given that there is no standard stroke
rehabilitation plan for all the patients. In fact, it depends basically on the
patient's functional independence and its progress along the rehabilitation
sessions. To tackle this challenge and make neurorehabilitation more agile, we
propose an automatic assessment pipeline that starts by recognizing patients'
movements by means of a shallow deep learning architecture, then measuring the
movement quality using jerk measure and related measures. A particularity of
this work is that the dataset used is clinically relevant, since it represents
movements inspired from Fugl-Meyer a well common upper-limb clinical stroke
assessment scale for stroke patients. We show that it is possible to detect the
contrast between healthy and patients movements in terms of smoothness, besides
achieving conclusions about the patients' progress during the rehabilitation
sessions that correspond to the clinicians' findings about each case.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:59:14 GMT""}]","2023-01-02"
"2301.01270","R B Yadav","RB Yadav, Subir Mukhopadhyay","Maurer-Cartan characterization, cohomology and deformations of
  equivariant Lie superalgebras","arXiv admin note: substantial text overlap with arXiv:2101.07652",,,,"math.GM","http://creativecommons.org/licenses/by/4.0/","  In this article, we give Maurer-Cartan characterizations of equivariant Lie
superalgebra structures. We introduce equivariant cohomology and equivariant
formal deformation theory of Lie superalgebras. As an application of
equivariant cohomology we study the equivariant formal deformation theory of
Lie superalgebras. As another application we characterize equivariant central
extensions of Lie superalgebras using second equivariant cohomology. We give
some examples of Lie superalgebras with an action of a group and equivariant
formal deformations of a classical Lie superalgebras.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:40:30 GMT""}]","2023-01-04"
"2301.01600","Tsvetan Zhivkov","Tsvetan Zhivkov and Elizabeth I. Sklar","5G on the Farm: Evaluating Wireless Network Capabilities for
  Agricultural Robotics","19 pages, 17 figures, 10 tables",,,,"cs.NI cs.RO","http://creativecommons.org/licenses/by/4.0/","  Global food security is an issue that is fast becoming a critical matter in
the world today. Global warming, climate change and a range of other impacts
caused by humans, such as carbon emissions, sociopolitical and economical
challenges (e.g. war), traditional workforce/labour decline and population
growth are straining global food security. The need for high-speed and reliable
wireless communication in agriculture is becoming more of a necessity rather
than a technological demonstration or showing superiority in the field.
Governments and industries around the world are seeing more urgency in
establishing communication infrastructure to scale up agricultural activities
and improve sustainability, by employing autonomous agri-robotics and
agri-technologies. The work presented here evaluates the physical performance
of 5G in an agri-robotics application, and the results are compared against 4G
and WiFi6 (a newly emerging wireless communication standard), which are
typically used in agricultural environments. In addition, a series of
simulation experiments were performed to assess the ``real-time'' operational
delay in critical tasks that may require a human-in-the-loop to support
decision making. The results lead to the conclusion that 4G cannot be used in
the agricultural domain for applications that require high throughput and
reliable communication between robot and user. Moreover, a single wireless
solution does not exist for the agricultural domain, but instead multiple
solutions can be combined to meet the necessary telecommunications
requirements. Finally, the results show that 5G greatly outperforms 4G in all
performance metrics, and on average only 18.2ms slower than WiFi6 making it
very reliable.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 14:31:21 GMT""}]","2023-01-05"
"2301.03467","Farhang Yeganegi","Arian Eamaz, Farhang Yeganegi, Deanna Needell, and Mojtaba Soltanalian","ORKA: Accelerated Kaczmarz Algorithms for Signal Recovery from One-Bit
  Samples","arXiv admin note: text overlap with arXiv:2203.08982",,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  One-bit quantization with time-varying sampling thresholds has recently found
significant utilization potential in statistical signal processing applications
due to its relatively low power consumption and low implementation cost. In
addition to such advantages, an attractive feature of one-bit analog-to-digital
converters (ADCs) is their superior sampling rates as compared to their
conventional multi-bit counterparts. This characteristic endows one-bit signal
processing frameworks with what we refer to as sample abundance. On the other
hand, many signal recovery and optimization problems are formulated as
(possibly non-convex) quadratic programs with linear feasibility constraints in
the one-bit sampling regime. We demonstrate, with a particular focus on the
nuclear norm minimization, that the sample abundance paradigm allows for the
transformation of such quadratic problems to merely a linear feasibility
problem by forming a large-scale overdetermined linear system; thus removing
the need for costly optimization constraints and objectives. To make this
achievable, we propose enhanced randomized Kaczmarz algorithms to tackle these
highly overdetermined feasibility problems. Several numerical results are
presented to illustrate the effectiveness of the proposed methodologies.
","[{""version"":""v1"",""created"":""Thu, 8 Dec 2022 20:11:23 GMT""}]","2023-01-10"
"2301.04118","Yuqi Li","Yuqi Li and Lihua Zhang","Achieving a Given Financial Goal with Optimal Deferred Term Insurance
  Purchasing Policy",,,,,"q-fin.PM math.OC math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper researches the problem of purchasing deferred term insurance in
the context of financial planning to maximize the probability of achieving a
personal financial goal. Specifically, our study starts from the perspective of
hedging death risk and longevity risk, and considers the purchase of deferred
term life insurance and deferred term pure endowment to achieve a given
financial goal for the first time in both deterministic and stochastic
framework. In particular, we consider income, consumption and risky investment
in the stochastic framework, extending previous results in
\cite{Bayraktar2016}. The time cutoff m and n make the work more difficult.
However, by establishing new controls,``\emph{quasi-ideal value}""
and``\emph{ideal value}"", we solve the corresponding ordinary differential
equations or stochastic differential equations, and give the specific
expressions for the maximum probability. Then we provide the optimal life
insurance purchasing strategies and the optimal risk investment strategies. In
general, when m \geqslant 0, n>0, deferred term insurance or term life
insurance is a better choice for those who want to achieve their financial or
bequest goals but are not financially sound. In particular, if m >0, n
\rightarrow \infty, our viewpoint also sheds light on reaching a bequest goal
by purchasing deferred whole life insurance. It is worth noting that when m=0,
n \rightarrow \infty, our problem is equivalent to achieving the just mentioned
bequest goal by purchasing whole life insurance, at which point the maximum
probability and the life insurance purchasing strategies we provide are
consistent with those in \cite{Bayraktar2014, Bayraktar2016}.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 13:48:49 GMT""}]","2023-01-11"
"2301.06081","Xiangyu Rui","Xiangyu Rui, Xiangyong Cao, Jun Shu, Qian Zhao and Deyu Meng","A Hyper-weight Network for Hyperspectral Image Denoising","16 pages",,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the hyperspectral image (HSI) denoising task, the real noise embedded in
the HSI is always complex and diverse so that many model-based HSI denoising
methods only perform well on some specific noisy HSIs. To enhance the noise
adaptation capability of current methods, we first resort to the weighted HSI
denoising model since its weight is capable of characterizing the noise in
different positions of the image. However, the weight in these weighted models
is always determined by an empirical updating formula, which does not fully
utilize the noise information contained in noisy images and thus limits their
performance improvement. In this work, we propose an automatic weighting scheme
to alleviate this issue. Specifically, the weight in the weighted model is
predicted by a hyper-weight network (i.e., HWnet), which can be learned in a
bi-level optimization framework based on the data-driven methodology. The
learned HWnet can be explicitly plugged into other weighted denoising models,
and help adjust weights for different noisy HSIs and different weighted models.
Extensive experiments verify that the proposed HWnet can help improve the
generalization ability of a weighted model to adapt to more complex noise, and
can also strengthen the weighted model by transferring the knowledge from
another weighted model. Additionally, to explain the experimental results, we
also theoretically prove the training error and generalization error upper
bound of the proposed HWnet, which should be the first generalization error
analysis in the low-level vision field as far as we know.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 03:28:07 GMT""}]","2023-01-18"
"2301.10167","Xing Lin","Tao Yan, Maoqi Zhang, Sen Wan, Kaifeng Shang, Haiou Zhang, Xun Cao,
  Xing Lin, Qionghai Dai","EEG Opto-processor: epileptic seizure detection using diffractive
  photonic computing units","22 pages, 5 figures",,,,"eess.SP cs.LG physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Electroencephalography (EEG) analysis extracts critical information from
brain signals, which has provided fundamental support for various applications,
including brain-disease diagnosis and brain-computer interface. However, the
real-time processing of large-scale EEG signals at high energy efficiency has
placed great challenges for electronic processors on edge computing devices.
Here, we propose the EEG opto-processor based on diffractive photonic computing
units (DPUs) to effectively process the extracranial and intracranial EEG
signals and perform epileptic seizure detection. The signals of EEG channels
within a second-time window are optically encoded as inputs to the constructed
diffractive neural networks for classification, which monitors the brain state
to determine whether it's the symptom of an epileptic seizure or not. We
developed both the free-space and integrated DPUs as edge computing systems and
demonstrated their applications for real-time epileptic seizure detection with
the benchmark datasets, i.e., the CHB-MIT extracranial EEG dataset and
Epilepsy-iEEG-Multicenter intracranial EEG dataset, at high computing
performance. Along with the channel selection mechanism, both the numerical
evaluations and experimental results validated the sufficient high
classification accuracies of the proposed opto-processors for supervising the
clinical diagnosis. Our work opens up a new research direction of utilizing
photonic computing techniques for processing large-scale EEG signals in
promoting its broader applications.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 05:16:14 GMT""}]","2023-01-25"
"2301.13164","Jos\'e Carlos Bellido","Jos\'e Carlos Bellido, Luis Felipe Prieto-Mart\'inez","A Rellich's result revisited and sensitivity of solutions of
  parametrized linear systems",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we revisit a result due to Franz Rellich on smoothness of
solutions of parametrized linear systems. With this result as a starting point,
we obtain finer smoothness results in an elementary fashion and propose an
efficient adjoint algorithm for computing sensitivities of $(n-1)$-deficient
systems, being $n$ the order of the system.
","[{""version"":""v1"",""created"":""Fri, 9 Dec 2022 11:04:12 GMT""}]","2023-01-31"
