"2207.07556","Victor Pacheco-Pe\~na","Tony Knightley, Alex Yakovlev, Victor Pacheco-Pe\~na","Neural network design of multilayer metamaterial for temporal
  differentiation","4 Figures, 17 pages",,,,"physics.optics physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Controlling wave-matter interactions with metamaterials (MTMs) for the
calculation of mathematical operations has become an important paradigm for
analogue computing given their ability to dramatically increase computational
processing speeds. Here, motivated by the importance of performing mathematical
operations on temporal signals, we propose, design and study multilayer MTMs
with the ability to calculate the derivative of incident modulated temporal
signals, as an example of a significant computing process for signal
processing. To do this, we make use of a neural network (NN) based algorithm to
design the multilayer structures (alternating layers of indium tin oxide (ITO)
and titanium dioxide (TiO2)) that can calculate the first temporal derivative
of the envelope of an impinging electromagnetic signal at telecom wavelengths
(modulated wavelength of 1550 nm). Different designs are presented using
multiple incident temporal signals including a modulated Gaussian as well as
modulated arbitrary functions, demonstrating an excellent agreement between the
predicted results (NN results) and the theoretical (ideal) values. It is shown
how, for all the designs, the proposed NN-based algorithm can complete its
search of design space for the layer thicknesses of the multilayer MTM after
just a few seconds, with a low mean square error in the order of (or below)
10^-4 when comparing the predicted results with the theoretical spectrum of the
ideal temporal derivative.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:02:57 GMT""},{""version"":""v2"",""created"":""Wed, 24 Aug 2022 18:46:41 GMT""}]","2022-08-26"
"2207.07557","Emmanouil Vasileios Vlatakis Gkaragkounis","Christos H. Papadimitriou, Emmanouil-Vasileios Vlatakis-Gkaragkounis,
  Manolis Zampetakis","The Computational Complexity of Multi-player Concave Games and Kakutani
  Fixed Points",,,,,"cs.CC cs.GT math.GN math.OC","http://creativecommons.org/licenses/by/4.0/","  Kakutani's Fixed Point theorem is a fundamental theorem in topology with
numerous applications in game theory and economics. Computational formulations
of Kakutani exist only in special cases and are too restrictive to be useful in
reductions. In this paper, we provide a general computational formulation of
Kakutani's Fixed Point Theorem and we prove that it is PPAD-complete. As an
application of our theorem we are able to characterize the computational
complexity of the following fundamental problems:
  (1) Concave Games. Introduced by the celebrated works of Debreu and Rosen in
the 1950s and 60s, concave $n$-person games have found many important
applications in Economics and Game Theory. We characterize the computational
complexity of finding an equilibrium in such games. We show that a general
formulation of this problem belongs to PPAD, and that finding an equilibrium is
PPAD-hard even for a rather restricted games of this kind: strongly-concave
utilities that can be expressed as multivariate polynomials of a constant
degree with axis aligned box constraints.
  (2) Walrasian Equilibrium. Using Kakutani's fixed point Arrow and Debreu we
resolve an open problem related to Walras's theorem on the existence of price
equilibria in general economies. There are many results about the PPAD-hardness
of Walrasian equilibria, but the inclusion in PPAD is only known for piecewise
linear utilities. We show that the problem with general convex utilities is in
PPAD.
  Along the way we provide a Lipschitz continuous version of Berge's maximum
theorem that may be of independent interest.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:03:33 GMT""},{""version"":""v2"",""created"":""Sat, 11 Feb 2023 22:19:38 GMT""},{""version"":""v3"",""created"":""Thu, 25 May 2023 08:03:34 GMT""}]","2023-05-26"
"2207.07558","Abdul Rahman Shaikh","Abdul Rahman Shaikh, David Koop, Hamed Alhoori, Maoyuan Sun","Toward Systematic Design Considerations of Organizing Multiple Views","Short paper with 4 pages + 1 reference page, 2 figures, 1 table,
  accepted at IEEE VIS 2022 conference",,,,"cs.HC","http://creativecommons.org/licenses/by/4.0/","  Multiple-view visualization (MV) has been used for visual analytics in
various fields (e.g., bioinformatics, cybersecurity, and intelligence
analysis). Because each view encodes data from a particular perspective,
analysts often use a set of views laid out in 2D space to link and synthesize
information. The difficulty of this process is impacted by the spatial
organization of these views. For instance, connecting information from views
far from each other can be more challenging than neighboring ones. However,
most visual analysis tools currently either fix the positions of the views or
completely delegate this organization of views to users (who must manually drag
and move views). This either limits user involvement in managing the layout of
MV or is overly flexible without much guidance. Then, a key design challenge in
MV layout is determining the factors in a spatial organization that impact
understanding. To address this, we review a set of MV-based systems and
identify considerations for MV layout rooted in two key concerns: perception,
which considers how users perceive view relationships, and content, which
considers the relationships in the data. We show how these allow us to study
and analyze the design of MV layout systematically.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:04:16 GMT""}]","2022-07-18"
"2207.07559","Anton Petrunin","Anton Petrunin","Polyhedral approximations of Riemannian manifolds","an old paper with minor updates","Turkish J. Math. 27 (2003), no. 1, 173--187",,,"math.DG math.MG","http://creativecommons.org/publicdomain/zero/1.0/","  We give a condition on the curvature tensors of Riemannian manifolds that
admit Lipschitz approximation by polyhedral metrics with curvature bounded
below or above.
  We show that this condition is also sufficient for the existence of local
approximations. We conjecture that it is also sufficient for the global
approximations and prove it in some special cases.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:04:42 GMT""}]","2022-07-18"
"2207.07560","Youngwoon Lee","Lucy Xiaoyang Shi and Joseph J. Lim and Youngwoon Lee","Skill-based Model-based Reinforcement Learning","Published at the Conference on Robot Learning (CoRL) 2022. Website:
  https://clvrai.com/skimo",,,,"cs.LG cs.AI cs.RO","http://creativecommons.org/licenses/by/4.0/","  Model-based reinforcement learning (RL) is a sample-efficient way of learning
complex behaviors by leveraging a learned single-step dynamics model to plan
actions in imagination. However, planning every action for long-horizon tasks
is not practical, akin to a human planning out every muscle movement. Instead,
humans efficiently plan with high-level skills to solve complex tasks. From
this intuition, we propose a Skill-based Model-based RL framework (SkiMo) that
enables planning in the skill space using a skill dynamics model, which
directly predicts the skill outcomes, rather than predicting all small details
in the intermediate states, step by step. For accurate and efficient long-term
planning, we jointly learn the skill dynamics model and a skill repertoire from
prior experience. We then harness the learned skill dynamics model to
accurately simulate and plan over long horizons in the skill space, which
enables efficient downstream learning of long-horizon, sparse reward tasks.
Experimental results in navigation and manipulation domains show that SkiMo
extends the temporal horizon of model-based approaches and improves the sample
efficiency for both model-based RL and skill-based RL. Code and videos are
available at https://clvrai.com/skimo
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:06:33 GMT""},{""version"":""v2"",""created"":""Sun, 11 Dec 2022 17:56:12 GMT""}]","2022-12-13"
"2207.07562","Ziv Epstein","Ziv Epstein, Hause Lin, Gordon Pennycook and David Rand","How many others have shared this? Experimentally investigating the
  effects of social cues on engagement, misinformation, and unpredictability on
  social media",,,,,"cs.SI cs.HC","http://creativecommons.org/licenses/by/4.0/","  Unlike traditional media, social media typically provides quantified metrics
of how many users have engaged with each piece of content. Some have argued
that the presence of these cues promotes the spread of misinformation. Here we
investigate the causal effect of social cues on users' engagement with social
media posts. We conducted an experiment with N=628 Americans on a custom-built
newsfeed interface where we systematically varied the presence and strength of
social cues. We find that when cues are shown, indicating that a larger number
of others have engaged with a post, users were more likely to share and like
that post. Furthermore, relative to a control without social cues, the presence
of social cues increased the sharing of true relative to false news. The
presence of social cues also makes it more difficult to precisely predict how
popular any given post would be. Together, our results suggest that -- instead
of distracting users or causing them to share low-quality news -- social cues
may, in certain circumstances, actually boost truth discernment and reduce the
sharing of misinformation. Our work suggests that social cues play important
roles in shaping users' attention and engagement on social media, and platforms
should understand the effects of different cues before making changes to what
cues are displayed and how.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:09:15 GMT""}]","2022-07-18"
"2207.07565","Irena Chen","Irena Chen and Zhenke Wu and Siob\'an D. Harlow and Carrie A.
  Karvonen-Gutierrez and Michelle M. Hood and Michael R. Elliott","Variance as a predictor of health outcomes: Subject-level trajectories
  and variability of sex hormones to predict body fat changes in peri- and
  post-menopausal women",,,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Longitudinal biomarker data and cross-sectional outcomes are routinely
collected in modern epidemiology studies, often with the goal of informing
tailored early intervention decisions. For example, hormones such as estradiol
and follicle-stimulating hormone may predict changes in womens' health during
the midlife. Most existing methods focus on constructing predictors from mean
marker trajectories. However, subject-level biomarker variability may also
provide critical information about disease risks and health outcomes. In this
paper, we develop a joint model that estimates subject-level means and
variances of longitudinal biomarkers to predict a cross-sectional health
outcome. Simulations demonstrate excellent recovery of true model parameters.
The proposed method provides less biased and more efficient estimates, relative
to alternative approaches that either ignore subject-level differences in
variances or perform two-stage estimation where estimated marker variances are
treated as observed. Analyses of women's health data reveal larger variability
of E2 or larger variability of FSH were associated with higher levels of fat
mass change and higher levels of lean mass change across the menopausal
transition.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:10:57 GMT""}]","2022-07-18"
"2207.07566","Radu Laza","Robert Friedman and Radu Laza","The higher Du Bois and higher rational properties for isolated
  singularities","19 pages; v2 - some typos corrected, minor edits, some references
  added/updated",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Higher rational and higher Du Bois singularities have recently been
introduced as natural generalizations of the standard definitions of rational
and Du Bois singularities. In this note, we discuss these properties for
isolated singularities, especially in the locally complete intersection (lci)
case. First, we reprove the fact that a $k$-rational isolated singularity is
$k$-Du Bois without any lci assumption. For isolated lci singularities, we give
a complete characterization of the $k$-Du Bois and $k$-rational singularities
in terms of standard invariants of singularities. In particular, we show that
$k$-Du Bois singularities are $(k-1)$-rational for isolated lci singularities.
In the course of the proof, we establish some new relations between invariants
of isolated lci singularities and show that many of these vanish. The methods
also lead to a quick proof of an inversion of adjunction theorem in the
isolated lci case. Finally, we discuss some results specific to the
hypersurface case.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:11:38 GMT""},{""version"":""v2"",""created"":""Sun, 23 Oct 2022 23:17:16 GMT""}]","2022-10-25"
"2207.07567","Gabriel Bartosch Caminha","G. B. Caminha, S. H. Suyu, A. Mercurio, G. Brammer, P. Bergamini, E.
  Vanzella, A. Acebron","First JWST observations of a gravitational lens: Mass model from new
  multiple images with near-infrared observations of SMACS J0723.3-7327","5 pages, 2 figures, 1 table, plus appendix. Published in A&A Letters.
  Lens model and redshift catalogue available at:
  http://cdsarc.u-strasbg.fr/viz-bin/cat/J/A+A/666/L9","A&A 666, L9 (2022)","10.1051/0004-6361/202244517",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We present our lens mass model of SMACS J0723, the first strong gravitational
lens observed by the James Webb Space Telescope (JWST). We use data from the
Hubble Space Telescope and Multi Unit Spectroscopic Explorer (MUSE) to build
our 'pre-JWST' lens model, and refine it with newly available JWST
near-infrared imaging in our JWST model. To reproduce the positions of all
multiple lensed images with good accuracy, the adopted mass parameterization
consists of one cluster-scale component, accounting mainly for the dark matter
distribution, the galaxy cluster members and an external shear component. The
pre-JWST model has, as constraints, 19 multiple images from six background
sources, of which four have secure spectroscopic redshift measurements from
this work. The JWST model has more than twice the number of constraints, 30
additional multiple images from another eleven lensed sources. Both models can
reproduce very well the multiple image positions with a $\delta_{rms}$ of
$0.39''$ and $0.51''$, for the pre-JWST and JWST models, respectively. The
total mass estimates within a radius of 128~kpc (~ the Einstein radius) are
$7.9_{-0.2}^{+0.3}\times 10^{13}\rm M_{\odot}$ and $8.7_{-0.2}^{+0.2}\times
10^{13}\rm M_{\odot}$, for the pre-JWST and JWST models, respectively. We
predict with our mass models the redshifts of the newly detected JWST sources,
which are crucial information for systems without spectroscopic measurements
for further studies and follow-up observations. Interestingly, one family
detected with JWST is found to be at a very high redshift, $z>7.5$ (68%
confidence level) and with one image having lensing magnification of
$|\mu|=9.5_{-0.8}^{+0.9}$, making it an interesting case for future studies.
The lens models, including magnification maps and redshifts estimated from the
model are made publicly available, along with the full spectroscopic redshift
catalogue from MUSE.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:15:22 GMT""},{""version"":""v2"",""created"":""Mon, 12 Sep 2022 12:42:53 GMT""},{""version"":""v3"",""created"":""Thu, 13 Oct 2022 12:53:19 GMT""}]","2022-10-14"
"2207.07568","Shailaja Keyur Sampat","Shailaja Keyur Sampat, Maitreya Patel, Subhasish Das, Yezhou Yang and
  Chitta Baral","Reasoning about Actions over Visual and Linguistic Modalities: A Survey","7 pages, 3 figures; This survey will be periodically updated with the
  latest works in this area",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  'Actions' play a vital role in how humans interact with the world and enable
them to achieve desired goals. As a result, most common sense (CS) knowledge
for humans revolves around actions. While 'Reasoning about Actions & Change'
(RAC) has been widely studied in the Knowledge Representation community, it has
recently piqued the interest of NLP and computer vision researchers. This paper
surveys existing tasks, benchmark datasets, various techniques and models, and
their respective performance concerning advancements in RAC in the vision and
language domain. Towards the end, we summarize our key takeaways, discuss the
present challenges facing this research area, and outline potential directions
for future research.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:15:46 GMT""}]","2022-07-18"
"2207.07569","Cecilia Lazzoni","Cecilia Lazzoni, Silvano Desidera, Raffaele Gratton, Alice Zurlo, Dino
  Mesa and Shrishmoy Ray","Detectability of satellites around directly imaged exoplanets and brown
  dwarfs",,,"10.1093/mnras/stac2081",,"astro-ph.EP astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Satellites around substellar companions are a heterogeneous class of objects
with a variety of different formation histories. Focusing on potentially
detectable satellites around exoplanets and brown dwarfs, we might expect to
find objects belonging to two main populations: planet-like satellites similar
to Titan or the Galileian Satellites - likely formed within the scope of core
accretion; and binary-like objects, formed within different scenarios, such as
disk instability. The properties of these potential satellites would be very
different from each other. Additionally, we expect that their characterization
would provide insightful information about the history of the system. This is
particularly important for planets/brown dwarfs discovered via direct imaging
(DI) with ambiguous origins. In this paper, we review different techniques,
applied to DI planets/brown dwarfs, that can be used to discover such
satellites. This was achieved by simulating a population of satellites around
the exoplanet $\beta$ Pic b, which served as a test case. For each simulated
satellite, the amplitude of DI, radial velocity, transit and astrometric
signals, with respect to the planet, were retrieved and compared with the
detection limits of current and future instruments. Furthermore, we compiled a
list of 38 substellar companions discovered via DI to give a preliminary
estimate on the probability of finding satellites extracted from the two
populations mentioned above, with different techniques. This simplified
approach shows that detection of planet-like satellites, though not strictly
impossible, is very improbable. On the other hand, detection of binary-like
satellites is within the capabilities of current instrumentation.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:18:46 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jul 2022 18:39:49 GMT""},{""version"":""v3"",""created"":""Tue, 26 Jul 2022 16:42:40 GMT""}]","2022-08-17"
"2207.07570","Yunhao Tang","Yunhao Tang, Mark Rowland, R\'emi Munos, Bernardo \'Avila Pires, Will
  Dabney, Marc G. Bellemare","The Nature of Temporal Difference Errors in Multi-step Distributional
  Reinforcement Learning",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the multi-step off-policy learning approach to distributional RL.
Despite the apparent similarity between value-based RL and distributional RL,
our study reveals intriguing and fundamental differences between the two cases
in the multi-step setting. We identify a novel notion of path-dependent
distributional TD error, which is indispensable for principled multi-step
distributional RL. The distinction from the value-based case bears important
implications on concepts such as backward-view algorithms. Our work provides
the first theoretical guarantees on multi-step off-policy distributional RL
algorithms, including results that apply to the small number of existing
approaches to multi-step distributional RL. In addition, we derive a novel
algorithm, Quantile Regression-Retrace, which leads to a deep RL agent
QR-DQN-Retrace that shows empirical improvements over QR-DQN on the Atari-57
benchmark. Collectively, we shed light on how unique challenges in multi-step
distributional RL can be addressed both in theory and practice.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:19:23 GMT""}]","2022-07-18"
"2207.07571","Alessandra Zanichelli","Alessandra Zanichelli, Giampaolo Serra, Karl-Heinz Mack, Gaetano
  Nicotra, Marco Bartolini, Federico Cantini, Matteo De Biaggi, Francesco
  Gaudiomonte, Claudio Bortolotti, Mauro Roma, Sergio Poppi, Francesco Bedosti,
  Simona Righini, Pietro Bolli, Andrea Orlati, Roberto Ambrosini, Carla Buemi,
  Marco Buttu, Pietro Cassaro, Paolo Leto, Andrea Mattana, Carlo Migoni, Luca
  Moscadelli, Pier Raffaele Platania, Corrado Trigilio","Towards coordinated site monitoring and common strategies for mitigation
  of Radio Frequency Interference at the Italian radio telescopes","39 pages, 10 Figures and 7 Tables. INAF Technical Report n. 149
  (2022). http://hdl.handle.net/20.500.12386/32081",,"10.20371/INAF/TechRep/149",,"astro-ph.IM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We present a project to implement a national common strategy for the
mitigation of the steadily deteriorating Radio Frequency Interference (RFI)
situation at the Italian radio telescopes. The project involves the Medicina,
Noto, and Sardinia dish antennas and comprised the definition of a coordinated
plan for site monitoring as well as the implementation of state-of-the-art
hardware and software tools for RFI mitigation. Coordinated monitoring of
frequency bands up to 40 GHz has been performed by means of continuous
observations and dedicated measurement campaigns with fixed stations and mobile
laboratories. Measurements were executed on the frequency bands allocated to
the radio astronomy and space research service for shared or exclusive use and
on the wider ones employed by the current and under-development receivers at
the telescopes. Results of the monitoring campaigns provide a reference
scenario useful to evaluate the evolution of the interference situation at the
telescopes sites and a case series to test and improve the hardware and
software tools we conceived to counteract radio frequency interference. We
developed a multi-purpose digital backend for high spectral and time resolution
observations over large bandwidths. Observational results demonstrate that the
spectrometer robustness and sensitivity enable the efficient detection and
analysis of interfering signals in radio astronomical data. A prototype
off-line software tool for interference detection and flagging has been also
implemented. This package is capable to handle the huge amount of data
delivered by the most modern instrumentation on board of the Italian radio
telecsopes, like dense focal plane arrays, and its modularity easen the
integration of new algorithms and the re-usability in different contexts or
telescopes.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:20:34 GMT""}]","2022-07-18"
"2207.07572","Sara Summerton","Sara Summerton, Ann Tivey, Rohan Shotton, Gavin Brown, Oliver C.
  Redfern, Rachel Oakley, John Radford, and David C. Wong","Outlier detection of vital sign trajectories from COVID-19 patients","4 pages, 4 figures, 1 table. Accepted to EMBC 2023, to be indexed in
  IEEE Xplore and PubMed Medline",,,,"cs.LG cs.HC eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this work, we present a novel trajectory comparison algorithm to identify
abnormal vital sign trends, with the aim of improving recognition of
deteriorating health.
  There is growing interest in continuous wearable vital sign sensors for
monitoring patients remotely at home. These monitors are usually coupled to an
alerting system, which is triggered when vital sign measurements fall outside a
predefined normal range. Trends in vital signs, such as increasing heart rate,
are often indicative of deteriorating health, but are rarely incorporated into
alerting systems.
  We introduce a dynamic time warp distance-based measure to compare time
series trajectories. We split each multi-variable sign time series into 180
minute, non-overlapping epochs. We then calculate the distance between all
pairs of epochs. Each epoch is characterized by its mean pairwise distance
(average link distance) to all other epochs, with clusters forming with nearby
epochs.
  We demonstrate in synthetically generated data that this method can identify
abnormal epochs and cluster epochs with similar trajectories. We then apply
this method to a real-world data set of vital signs from 8 patients who had
recently been discharged from hospital after contracting COVID-19. We show how
outlier epochs correspond well with the abnormal vital signs and identify
patients who were subsequently readmitted to hospital.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:22:07 GMT""},{""version"":""v2"",""created"":""Thu, 20 Apr 2023 12:41:58 GMT""}]","2023-04-21"
"2207.07573","Jianing Han","Jianing Han, Juliet Michell, and Morgan Umstead","Evidence of quadrupole-quadrupole interactions in ultracold gases",,,,,"physics.atm-clus","http://creativecommons.org/publicdomain/zero/1.0/","  Van der Waals interactions are interactions between dipoles. Similarly,
quadrupole-quadrupole interactions are interactions between quadrupoles. In
this article, we focus on the interactions between two dipoles or two
quadrupoles. Classically, we treat one Rydberg atom as a dipole; an outer
excited electron and an ion core are the two poles of a dipole. Quantum
mechanically, we consider Rydberg transition dipoles. Therefore, dipole-dipole
interactions are the interactions between two Rydberg atoms. Rydberg atoms have
quadrupole components; consequently, the interactions between two Rydberg atoms
have quadrupole-quadrupole interaction components. In this article, we examine
the dipole-dipole and quadrupole-quadrupole contribution to the interactions
between ultracold Rydberg atoms. It is shown that the evidence of
quadrupole-blockade has been observed, which is essential for fabricating more
compact quantum computers, quantum electronics, as well as quantum sensing.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:22:14 GMT""}]","2022-07-18"
"2207.07575","Rimantas Lazauskas Dr","Rimantas Lazauskas, Emiko Hiyama, Jaume Carbonell","Low energy structures in nuclear reactions with 4n in the final state","Accepted to PRL",,"10.1103/PhysRevLett.130.102501",,"nucl-th nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a reaction model to describe the fast removal of the
$\alpha$-particle core in $^8$He nucleus with eventual emission of four
neutrons. The obtained four neutron energy distributions allows to explain the
sharp low energy peak observed by studying the missing mass spectra of four
neutrons in [Nature Vol. 606, p. 678], as a consequence of dineutron-dineutron
correlations.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:24:32 GMT""},{""version"":""v2"",""created"":""Tue, 14 Feb 2023 15:14:44 GMT""}]","2023-03-29"
"2207.07576","Philippa Cole","Philippa S. Cole, Adam Coogan, Bradley J. Kavanagh and Gianfranco
  Bertone","Measuring dark matter spikes around primordial black holes with Einstein
  Telescope and Cosmic Explorer","14 pages plus appendices, 15 figures",,"10.1103/PhysRevD.107.083006",,"astro-ph.CO gr-qc hep-ph","http://creativecommons.org/licenses/by/4.0/","  Future ground-based gravitational wave observatories will be ideal probes of
the environments surrounding black holes with masses $1 -
10\,\mathrm{M_\odot}$. Binary black hole mergers with mass ratios of order
$q=m_2/m_1\lesssim10^{-3}$ can remain in the frequency band of such detectors
for months or years, enabling precision searches for modifications of their
gravitational waveforms with respect to vacuum inspirals. As a concrete example
of an environmental effect, we consider here a population of binary primordial
black holes which are expected to be embedded in dense cold dark matter spikes.
We provide a viable formation scenario for these systems compatible with all
observational constraints, and predict upper and lower limits on the merger
rates of small mass ratio pairs. Given a detected signal of one such system by
either Einstein Telescope or Cosmic Explorer, we show that the properties of
the binary and of the dark matter spike can be measured to excellent precision
with one week's worth of data, if the effect of the dark matter spike on the
waveform is taken into account. However, we show that there is a risk of biased
parameter inference or missing the events entirely if the effect of the
predicted dark matter overdensity around these objects is not properly
accounted for.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:24:34 GMT""}]","2023-04-19"
"2207.07579","Matteo Zaccanti","A. Ciamei, S. Finelli, A. Cosco, M. Inguscio, A. Trenkwalder, and M.
  Zaccanti","Double-degenerate Fermi mixtures of $^6$Li and $^{53}$Cr atoms","14 pages, 5 figures",,"10.1103/PhysRevA.106.053318",,"cond-mat.quant-gas physics.atom-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on the realization of a novel degenerate mixture of ultracold
fermionic lithium and chromium atoms. Based on an all-optical approach, with an
overall duty-cycle of about 13 seconds, we produce large and degenerate samples
of more than 2$\times 10^5$ $^6$Li atoms and $10^5$ $^{53}$Cr atoms, with both
species exhibiting normalized temperatures of about $T/T_{F}$=0.25.
Additionally, through the exploitation of a crossed bichromatic optical dipole
trap, we can controllably vary the density and degree of degeneracy of the two
components almost independently, and widely tune the lithium-to-chromium
density ratio. Our $^{6}$Li-$^{53}$Cr Fermi mixture opens the way to the
investigation of a variety of exotic few- and many-body regimes of quantum
matter, and it appears as an optimally-suited system to realize ultracold
paramagnetic polar molecules, characterized by both electric and magnetic
dipole moments. Ultimately, our strategy also provides an efficient pathway to
produce dipolar Fermi gases, or spin-mixtures, of ultracold $^{53}$Cr atoms.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:26:28 GMT""}]","2022-11-30"
"2207.07581","Marek Karliner","Marek Karliner and Jonathan R. Rosner","New strange pentaquarks","6 pages, 1 figure",,"10.1103/PhysRevD.106.036024","EFI 22-7","hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The new strange pentaquarks observed by LHCb are very likely hadronic
molecules consisting of $\Xi_c \bar D$ and $\Xi_c \bar D^{*}.$ We discuss the
experimental evidence supporting this conclusion, pointing out the similarities
and differences with the $P_c(4312)$, $P_c(4440)$ and $P_c(4457)$ pentaquarks
in the non-strange sector. The latter clearly are hadronic molecules consisting
of $\Sigma_c \bar D$ and $\Sigma_c \bar D^{*}.$ Following this line of thought,
we predict three additional strange pentaquarks, consisting of $\Xi_c^{\prime}
\bar D$ and $\Xi_c^{\prime} \bar D^{*}.$ The masses of these states are
expected to be shifted upwards by $M(\Xi_c^{\prime})-M(\Xi_c) \approx 110$ MeV
with respect to the corresponding known strange pentaquarks.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:26:52 GMT""}]","2022-09-14"
"2207.07582","Bulat Nurmievich Khabibullin","B. N. Khabibullin, E. G. Kudasheva, A. E. Salimova","Completeness of the exponential system in geometric terms of width,
  breadth and diameter","10 pages, in Russian",,,,"math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish a criterion for the completeness of an exponential system in the
spaces of functions continuous on a convex compact set and holomorphic in the
interior of this compact set, as well as in the spaces of holomorphic functions
in the convex domain in terms of the breadth of the compact set or the domain
in the direction. The main results are formulated exclusively through the
relations between the breadth in the direction, width or diameter of the
compact set or domain on the one hand and the logarithmic submeasures or
logarithmic block densities of the distribution of exponents of exponential
system on the other.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:27:43 GMT""},{""version"":""v2"",""created"":""Wed, 29 Mar 2023 16:29:59 GMT""}]","2023-03-30"
"2207.07584","Songbo Xie","Songbo Xie, Yuan-Yuan Zhao, Chao Zhang, Yun-Feng Huang, Chuan-Feng Li,
  Guang-Can Guo, and Joseph H. Eberly","Experimental Examination of Entanglement Estimates","5 pages, 4 figures","Physical Review Letters 130 (2023) 150801","10.1103/PhysRevLett.130.150801",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently a proper genuine multipartite entanglement (GME) measure has been
found for three-qubit pure states [see Xie and Eberly, Phys. Rev. Lett. 127,
040403 (2021)], but capturing useful entanglement measures for mixed states has
remained an open challenge. So far, it requires not only a full tomography in
experiments, but also huge calculational labor. A leading proposal was made by
G\""uhne, Reimpell, and Werner [Phys. Rev. Lett. 98, 110502 (2007)], who used
expectation values of entanglement witnesses to describe a lower bound
estimation of entanglement. We provide here an extension that also gives
genuine upper bounds of entanglement. This advance requires only the
expectation value of {\em any} Hermitian operator. Moreover, we identify a
class of operators $\A_1$ which not only give good estimates, but also require
a remarkably small number of experimental measurements. In this note we define
our approach and illustrate it by estimating entanglement measures for a number
of pure and mixed states prepared in our recent experiments.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:29:43 GMT""},{""version"":""v2"",""created"":""Thu, 28 Jul 2022 01:05:06 GMT""},{""version"":""v3"",""created"":""Wed, 12 Apr 2023 20:25:24 GMT""}]","2023-04-14"
"2207.07587","Madhur Behl","Trent Weiss and Madhur Behl","This is the Way: Differential Bayesian Filtering for Agile Trajectory
  Synthesis","8 pages",,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  One of the main challenges in autonomous racing is to design algorithms for
motion planning at high speed, and across complex racing courses. End-to-end
trajectory synthesis has been previously proposed where the trajectory for the
ego vehicle is computed based on camera images from the racecar. This is done
in a supervised learning setting using behavioral cloning techniques. In this
paper, we address the limitations of behavioral cloning methods for trajectory
synthesis by introducing Differential Bayesian Filtering (DBF), which uses
probabilistic B\'ezier curves as a basis for inferring optimal autonomous
racing trajectories based on Bayesian inference. We introduce a trajectory
sampling mechanism and combine it with a filtering process which is able to
push the car to its physical driving limits. The performance of DBF is
evaluated on the DeepRacing Formula One simulation environment and compared
with several other trajectory synthesis approaches as well as human driving
performance. DBF achieves the fastest lap time, and the fastest speed, by
pushing the racecar closer to its limits of control while always remaining
inside track bounds.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:32:55 GMT""}]","2022-07-18"
"2207.07588","Christian Weiss","J. L. Goity, C. Weiss, C. T. Willemyns","Target normal single-spin asymmetry in inclusive electron-nucleon
  scattering with two-photon exchange: Analysis using $1/N_c$ expansion","7 pages, 2 figures",,"10.1016/j.physletb.2022.137580","JLAB-THY-22-3662","hep-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We calculate the target normal single-spin asymmetry caused by two-photon
exchange in inclusive electron-nucleon scattering in the resonance region. Our
analysis uses the $1/N_c$ expansion of low-energy QCD and combines $N$ and
$\Delta$ intermediate and final states using the contracted $SU(4)$ spin-flavor
symmetry. The normal spin asymmetry obtained in leading-order accuracy in
$1/N_c$ has magnitude $\sim 10^{-2}$ and different sign in $ep$ and $en$
scattering. It can be measured in electron scattering at lab energies $\sim$
0.5-1.5 GeV and provides a clean probe of two-photon exchange dynamics.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:37:07 GMT""}]","2022-11-23"
"2207.07589","S\'andor Baran","\'Agnes Baran and S\'andor Baran","A two-step machine learning approach to statistical post-processing of
  weather forecasts for power generation","25 pages, 12 figures, 4 tables",,,,"stat.ML cs.LG stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  By the end of 2021, the renewable energy share of the global electricity
capacity reached 38.3% and the new installations are dominated by wind and
solar energy, showing global increases of 12.7% and 18.5%, respectively.
However, both wind and photovoltaic energy sources are highly volatile making
planning difficult for grid operators, so accurate forecasts of the
corresponding weather variables are essential for reliable electricity
predictions. The most advanced approach in weather prediction is the ensemble
method, which opens the door for probabilistic forecasting; though ensemble
forecast are often underdispersive and subject to systematic bias. Hence, they
require some form of statistical post-processing, where parametric models
provide full predictive distributions of the weather variables at hand. We
propose a general two-step machine learning-based approach to calibrating
ensemble weather forecasts, where in the first step improved point forecasts
are generated, which are then together with various ensemble statistics serve
as input features of the neural network estimating the parameters of the
predictive distribution. In two case studies based of 100m wind speed and
global horizontal irradiance forecasts of the operational ensemble pre diction
system of the Hungarian Meteorological Service, the predictive performance of
this novel method is compared with the forecast skill of the raw ensemble and
the state-of-the-art parametric approaches. Both case studies confirm that at
least up to 48h statistical post-processing substantially improves the
predictive performance of the raw ensemble for all considered forecast
horizons. The investigated variants of the proposed two-step method outperform
in skill their competitors and the suggested new approach is well applicable
for different weather quantities and for a fair range of predictive
distributions.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:38:14 GMT""}]","2022-07-18"
"2207.07590","Annalena Kalteyer","Annalena Sophie Kalteyer (for the ALICE Collaboration)","Charm production and hadronization in pp and p-Pb collisions at the LHC
  with ALICE","Proceedings of DIS2022: XXIX International Workshop on Deep-Inelastic
  Scattering and Related Subjects, Santiago de Compostela, Spain, May 2-6 2022",,,,"nucl-ex hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Studies of open-charm hadron production in pp and \pPb collisions are
performed by the ALICE Collaboration at the LHC to investigate charm-quark
hadronization mechanisms. Recent measurements of charm meson (${\rm D^0}$,
${\rm D^+}$, ${\rm D^+_{\rm s}}$, and ${\rm D^{*+}}$) and baryon
($\Lambda^+_{\rm c}$, $\Xi^{0,+}_{\rm c}$, $\Sigma^{0,++}_{\rm c}$, and
$\Omega^0_{\rm c}$) production in pp collisions at $\sqrt{s}$ = 5.02 TeV and
$\sqrt{s}$ = 13 TeV allow the determination of the charm cross section and the
fragmentation fractions at $\sqrt{s}$ = 5.02 TeV with unprecedented precision.
The measurements show that the fragmentation fractions significantly differ
from the ones measured in ${\rm e^+e^-}$ and \ep collisions. This highlights
possible differences in the hadronization process between electron induced
collisions and pp collisions at the LHC. \\ Furthermore, the first measurement
of the baryon-to-meson yield ratio $\Lambda^+_{\rm c}/{\rm D^0}$, down to
$p_{\rm T}=0$ in pp and \pPb collisions will be discussed. In p--Pb collisions
a modification of the hadronization mechanisms could be present due to cold
nuclear matter effects and collective phenomena. A systematic comparison
between data and model calculations will help to understand charm quark
hadronization in pp and p--Pb collisions.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:39:21 GMT""}]","2022-07-18"
"2207.07591","Hasna Bouraoui","Hasna Bouraoui, Chadlia Jerad, Omar Romdhani, Jeronimo Castrillon","mAPN: Modeling, Analysis, and Exploration of Algorithmic and Parallelism
  Adaptivity","26 PAGES JOURNAL PAPER",,,,"cs.DC","http://creativecommons.org/licenses/by/4.0/","  Using parallel embedded systems these days is increasing. They are getting
more complex due to integrating multiple functionalities in one application or
running numerous ones concurrently. This concerns a wide range of applications,
including streaming applications, commonly used in embedded systems. These
applications must implement adaptable and reliable algorithms to deliver the
required performance under varying circumstances (e.g., running applications on
the platform, input data, platform variety, etc.). Given the complexity of
streaming applications, target systems, and adaptivity requirements, designing
such systems with traditional programming models is daunting. This is why
model-based strategies with an appropriate Model of Computation (MoC) have long
been studied for embedded system design. This work provides algorithmic
adaptivity on top of parallelism for dynamic dataflow to express larger sets of
variants. We present a multi-Alternative Process Network (mAPN), a high-level
abstract representation in which several variants of the same application
coexist in the same graph expressing different implementations. We introduce
mAPN properties and its formalism to describe various local implementation
alternatives. Furthermore, mAPNs are enriched with metadata to Provide the
alternatives with quantitative annotations in terms of a specific metric. To
help the user analyze the rich space of variants, we propose a methodology to
extract feasible variants under user and hardware constraints. At the core of
the methodology is an algorithm for computing global metrics of an execution of
different alternatives from a compact mAPN specification. We validate our
approach by exploring several possible variants created for the Automatic
Subtitling Application (ASA) on two hardware platforms.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:39:41 GMT""}]","2022-07-18"
"2207.07592","Yaqian Guo","Yaqian Guo, Hui Liu, Oleg Janson, Ion Cosma Fulga, Jeroen van den
  Brink and Jorge I. Facio","Spin-split collinear antiferromagnets: a large-scale ab-initio study",,,"10.1016/j.mtphys.2023.100991",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It was recently discovered that, depending on their symmetries, collinear
antiferromagnets can actually break the spin degeneracy in momentum space, even
in the absence of spin-orbit coupling. Such systems, recently dubbed
altermagnets, are signalled by the emergence of a spin-momentum texture set
mainly by the crystal and magnetic structure, relativistic effects playing a
secondary role. Here we consider all collinear $q$=0 antiferromagnetic
compounds in the MAGNDATA database allowing for spin-split bands. Based on
density-functional calculations for the experimentally reported crystal and
magnetic structures, we study more than sixty compounds and introduce numerical
measures for the average momentum-space spin splitting. We highlight some
compounds that are of particular interest, either due to a relatively large
spin splitting, such as CoF$_2$ and FeSO$_4$F, or because of their low-energy
electronic structure. The latter include LiFe$_2$F$_6$, which hosts nearly flat
spin-split bands next to the Fermi energy, as well as RuO$_2$, CrNb$_4$S$_8$,
and CrSb, which are spin-split antiferromagnetic metals.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:41:44 GMT""},{""version"":""v2"",""created"":""Thu, 23 Mar 2023 23:25:59 GMT""}]","2023-03-28"
"2207.07593","David Prinz","David Prinz","Symmetric Ghost Lagrange Densities for the Coupling of Gravity to Gauge
  Theories","13 pages, article",,,,"hep-th gr-qc math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We derive and present symmetric ghost Lagrange densities for the coupling of
General Relativity to Yang--Mills theories. The graviton-ghost is constructed
with respect to the linearized de Donder gauge fixing and the gauge ghost is
constructed with respect to the covariant Lorenz gauge fixing. Both ghost
Lagrange densities together with their accompanying gauge fixing Lagrange
densities are obtained from the action of the diffeomorphism and gauge BRST and
anti-BRST operators on suitable gauge fixing bosons. In addition, we introduce
a total gauge fixing boson and show that the complete ghost and gauge fixing
Lagrange density can be generated thereof using the total BRST operator and the
total anti-BRST operator, introduced by the author in a previous article
(2022). This generalizes results from Baulieu and Thierry-Mieg (1982) to
General Relativity and covariant Yang--Mills theories.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:47:19 GMT""}]","2022-07-18"
"2207.07594","Fabricio Valencia","Cristian Ortiz, Fabricio Valencia","Morse theory on Lie groupoids","41 pages. Comments are welcome",,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  In this paper we introduce Morse Lie groupoid morphisms and we study their
main properties. We show that Morse Lie groupoid morphisms are Morita
invariant, giving rise to a good notion of Morse function on a differentiable
stack. We show a groupoid version of the Morse-Bott lemma, which allows us to
speak about the index of a non-degenerate critical subgroupoid and hence to
describe critical sub-levels by an attaching procedure in the category of
topological groupoids. Motivated by the Morse-Bott complex defined by Austin
and Braam, we introduce the groupoid Morse double complex, showing that its
total cohomology is isomorphic to the Bott-Shulman-Stasheff cohomology of the
underlying Lie groupoid. Then we study Morse Lie groupoid morphisms which are
invariant under the action of a Lie 2-group yielding an equivariant version of
the groupoid Morse double complex. We show that in this case, the associated
cohomology is isomorphic to the corresponding equivariant cohomology of the Lie
2-group action. As an application, we show that the equivariant cohomology of
toric symplectic stacks can be computed by means of groupoid Morse theory.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:47:19 GMT""}]","2022-07-18"
"2207.07595","Gabriele Coppi","Gabriele Coppi, Giulia Conenna, Sofia Savorgnano, Felipe Carrero,
  Rolando D\""unner-Planella, Nicholas Galitzki, Federico Nati, Mario Zannoni","PROTOCALC: an artificial calibrator source for CMB telescopes","Presented at SPIE Astronomical Telescopes + Instrumentation 2022",,,,"astro-ph.IM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Cosmic Microwave Background experiments need to measure polarization
properties of the incoming radiation very accurately to achieve their
scientific goals. As a result of that, it is necessary to properly characterize
these instruments. However, there are not natural sources that can be used for
this purpose. For this reason, we developed the PROTOtype CALibrator for
Cosmology, PROTOCALC, which is a calibrator source designed for the 90GHz band
of these telescopes. This source is purely polarized and the direction of the
polarization vector is known with an accuracy better than 0.1deg. This source
flew for the first time in May 2022 showing promising result
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:49:25 GMT""}]","2022-07-18"
"2207.07596","Giuseppe Stragapede","Giuseppe Stragapede and Paula Delgado-Santos and Ruben Tolosana and
  Ruben Vera-Rodriguez and Richard Guest and Aythami Morales","Mobile Keystroke Biometrics Using Transformers","6 pages, 6 figures",,,,"cs.CV cs.CR cs.HC eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Among user authentication methods, behavioural biometrics has proven to be
effective against identity theft as well as user-friendly and unobtrusive. One
of the most popular traits in the literature is keystroke dynamics due to the
large deployment of computers and mobile devices in our society. This paper
focuses on improving keystroke biometric systems on the free-text scenario.
This scenario is characterised as very challenging due to the uncontrolled text
conditions, the influence of the user's emotional and physical state, and the
in-use application. To overcome these drawbacks, methods based on deep learning
such as Convolutional Neural Networks (CNNs) and Recurrent Neural Networks
(RNNs) have been proposed in the literature, outperforming traditional machine
learning methods. However, these architectures still have aspects that need to
be reviewed and improved. To the best of our knowledge, this is the first study
that proposes keystroke biometric systems based on Transformers. The proposed
Transformer architecture has achieved Equal Error Rate (EER) values of 3.84\%
in the popular Aalto mobile keystroke database using only 5 enrolment sessions,
outperforming by a large margin other state-of-the-art approaches in the
literature.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:50:11 GMT""},{""version"":""v2"",""created"":""Tue, 4 Oct 2022 07:50:05 GMT""}]","2022-10-05"
"2207.07598","Sonia Foschiatti","Sonia Foschiatti and Eva Sincich","Stable determination of an anisotropic inclusion in the Schr\""odinger
  equation from local Cauchy data","pp. 31",,,,"math.AP math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the inverse problem of determining an inclusion contained in a
body for a Schr\""odinger type equation by means of local Cauchy data. Both the
body and the inclusion are made by inhomogeneous and anisotropic materials.
Under mild a priori assumptions on the unknown inclusion, we establish a
logarithmic stability estimate in terms of the local Cauchy data. In view of
possible applications, we also provide a stability estimate in terms of an
ad-hoc misfit functional.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:52:17 GMT""}]","2022-07-18"
"2207.07600","Mary Crone Odekon","Mary Crone Odekon, Michael G. Jones, Lucas Graham, Jessica
  Kelley-Derzon, Evan Halstead","Infall Profiles for Supercluster-Scale Filaments",,"2022, The Astrophysical Journal, Volume 935, Issue 2, id.130, 21
  pp","10.3847/1538-4357/ac815b",,"astro-ph.CO astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present theoretical expectations for infall toward supercluster-scale
cosmological filaments, motivated by the Arecibo Pisces-Perseus Supercluster
Survey (APPSS) to map the velocity field around the Pisces-Perseus Supercluster
(PPS) filament. We use a minimum spanning tree applied to dark matter halos the
size of galaxy clusters to identify 236 large filaments within the Millennium
simulation. Stacking the filaments along their principal axes, we determine a
well-defined, sharp-peaked velocity profile function that can be expressed in
terms of the maximum infall rate $V_{\rm max}$ and the distance $\rho_{\rm
max}$ between the location of maximum infall and the principal axis of the
filament. This simple, two-parameter functional form is surprisingly universal
across a wide range of linear mass densities. $V_{\rm max}$ is positively
correlated with the halo mass per length along the filament, and $\rho_{\rm
max}$ is negatively correlated with the degree to which the halos are
concentrated along the principal axis. We also assess an alternative, single
parameter method using $V_{25}$, the infall rate at a distance of 25 Mpc from
the axis of the filament. Filaments similar to the PPS have $V_{\rm max} = 612
\ \pm$ 116 km s$^{-1}$, $\rho_{\rm max} = 8.9 \pm 2.1$ Mpc, and $V_{25} =329 \
\pm$ 68 km s$^{-1}$. We create mock observations to model uncertainties
associated with viewing angle, lack of three-dimensional velocity information,
limited sample size, and distance uncertainties. Our results suggest that it
would be especially useful to measure infall for a larger sample of filaments
to test our predictions for the shape of the infall profile and the
relationships among infall rates and filament properties.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:55:52 GMT""},{""version"":""v2"",""created"":""Mon, 18 Jul 2022 17:27:20 GMT""},{""version"":""v3"",""created"":""Wed, 20 Jul 2022 21:26:08 GMT""}]","2022-09-23"
"2207.07601","Shengchao Hu","Shengchao Hu and Li Chen and Penghao Wu and Hongyang Li and Junchi Yan
  and Dacheng Tao","ST-P3: End-to-end Vision-based Autonomous Driving via Spatial-Temporal
  Feature Learning","ECCV 2022",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Many existing autonomous driving paradigms involve a multi-stage discrete
pipeline of tasks. To better predict the control signals and enhance user
safety, an end-to-end approach that benefits from joint spatial-temporal
feature learning is desirable. While there are some pioneering works on
LiDAR-based input or implicit design, in this paper we formulate the problem in
an interpretable vision-based setting. In particular, we propose a
spatial-temporal feature learning scheme towards a set of more representative
features for perception, prediction and planning tasks simultaneously, which is
called ST-P3. Specifically, an egocentric-aligned accumulation technique is
proposed to preserve geometry information in 3D space before the bird's eye
view transformation for perception; a dual pathway modeling is devised to take
past motion variations into account for future prediction; a temporal-based
refinement unit is introduced to compensate for recognizing vision-based
elements for planning. To the best of our knowledge, we are the first to
systematically investigate each part of an interpretable end-to-end
vision-based autonomous driving system. We benchmark our approach against
previous state-of-the-arts on both open-loop nuScenes dataset as well as
closed-loop CARLA simulation. The results show the effectiveness of our method.
Source code, model and protocol details are made publicly available at
https://github.com/OpenPerceptionX/ST-P3.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:57:43 GMT""},{""version"":""v2"",""created"":""Mon, 18 Jul 2022 02:36:43 GMT""}]","2022-07-19"
"2207.07602","Nicholas Hartman","Nicholas Hartman, Joseph M. Messana, Jian Kang, Abhijit S. Naik,
  Tempie H. Shearon, Kevin He","Composite Scores for Transplant Center Evaluation: A New Individualized
  Empirical Null Method",,,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Risk-adjusted quality measures are used to evaluate healthcare providers
while controlling for factors beyond their control. Existing healthcare
provider profiling approaches typically assume that the risk adjustment is
perfect and the between-provider variation in quality measures is entirely due
to the quality of care. However, in practice, even with very good models for
risk adjustment, some between-provider variation will be due to incomplete risk
adjustment, which should be recognized in assessing and monitoring providers.
Otherwise, conventional methods disproportionately identify larger providers as
outliers, even though their provider effects need not be ""extreme.'' Motivated
by efforts to evaluate the quality of care provided by transplant centers, we
develop a composite evaluation score based on a novel individualized empirical
null method, which robustly accounts for overdispersion due to unobserved risk
factors, models the marginal variance of standardized scores as a function of
the effective center size, and only requires the use of publicly-available
center-level statistics. The evaluations of United States kidney transplant
centers based on the proposed composite score are substantially different from
those based on conventional methods. Simulations show that the proposed
empirical null approach more accurately classifies centers in terms of quality
of care, compared to existing methods.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:57:58 GMT""},{""version"":""v2"",""created"":""Sat, 23 Jul 2022 17:22:41 GMT""}]","2022-07-26"
"2207.07603","Abdelmalek Abdesselam","Abdelmalek Abdesselam","Non-Abelian correlation inequalities and stable determinantal
  polynomials","17 pages, fixed minor errors and typos",,,,"math-ph hep-th math.CO math.MP math.PR math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the correlations of invariant observables for the $O(N)$ and
$\mathbb{C}\mathbb{P}^{N-1}$ models at zero coupling, namely, with respect to
the natural group-invariant measure. In the limit where one takes a large power
of the integrand, we show that these correlations become inverse powers of the
Kirchhoff polynomial. The latter therefore provide a simplified toy model for
the investigation of inequalities between products of correlations. Properties
such as ferromagnetic behavior for spin model correlations correspond, in this
asymptotic limit, to log-ultramodularity which is a consequence of the Rayleigh
property of the Kirchhoff polynomial. In addition to the above rigorous
asymptotics, the main result of this article is a general theorem which shows
that inverse half-integer powers of certain determinantal stable polynomials,
such as the Kirchhoff polynomials, satisfy generalizations of the GKS 2
inequalities and the Ginibre inequalities. We conclude with some open problems,
e.g., the question of whether the last statement holds for powers which are not
half-integers. This leads to a Hirota-bilinear analogue of the complete
monotonicity property recently investigated by Scott and Sokal.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:59:05 GMT""},{""version"":""v2"",""created"":""Tue, 2 Aug 2022 18:49:13 GMT""}]","2022-08-05"
"2207.07604","Hikmet Kirmizitas","Hikmet Kirmizitas, Nurettin Besli","Image and Texture Independent Deep Learning Noise Estimation using
  Multiple Frames",,"Elektronika Ir Elektrotechnika 2022 28(6) (42-47)","10.5755/j02.eie.30586",,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  In this study, a novel multiple-frame based image and texture independent
convolutional Neural Network (CNN) noise estimator is introduced. The estimator
works.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:02:55 GMT""}]","2023-05-23"
"2207.07605","Hugh Chen","Hugh Chen and Ian C. Covert and Scott M. Lundberg and Su-In Lee","Algorithms to estimate Shapley value feature attributions",,,,,"cs.LG cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Feature attributions based on the Shapley value are popular for explaining
machine learning models; however, their estimation is complex from both a
theoretical and computational standpoint. We disentangle this complexity into
two factors: (1)~the approach to removing feature information, and (2)~the
tractable estimation strategy. These two factors provide a natural lens through
which we can better understand and compare 24 distinct algorithms. Based on the
various feature removal approaches, we describe the multiple types of Shapley
value feature attributions and methods to calculate each one. Then, based on
the tractable estimation strategies, we characterize two distinct families of
approaches: model-agnostic and model-specific approximations. For the
model-agnostic approximations, we benchmark a wide class of estimation
approaches and tie them to alternative yet equivalent characterizations of the
Shapley value. For the model-specific approximations, we clarify the
assumptions crucial to each method's tractability for linear, tree, and deep
models. Finally, we identify gaps in the literature and promising future
research directions.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:04:41 GMT""}]","2022-07-18"
"2207.07606","Elsa Prada","Pablo San-Jose, Carlos Pay\'a, C. M. Marcus, S. Vaitiek\.enas, and
  Elsa Prada","Theory of Caroli-de Gennes-Matricon analogs in full-shell hybrid
  nanowires","17 pages, 11 figures. v3: Final version","Phys. Rev. B 107, 155423 (2023)","10.1103/PhysRevB.107.155423",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Full-shell nanowires are hybrid nanostructures consisting of a semiconducting
core encapsulated in an epitaxial superconducting shell. When subject to an
external magnetic flux, they exhibit the Little-Parks (LP) phenomenon of
flux-modulated superconductivity, an effect connected to the physics of
Abrikosov vortex lines in type-II superconductors. We show theoretically that
full-shell nanowires can host subgap states that are a variant of the Caroli-de
Gennes-Matricon (CdGM) states in vortices. These CdGM analogs are shell-induced
Van Hove singularities in core subbands. We elucidate their structure,
parameter dependence and behavior in tunneling spectroscopy through a series of
models of growing complexity. Using microscopic numerical simulations, we show
that CdGM analogs exhibit a characteristic skewness towards higher flux values
inside non-zero LP lobes resulting from the interplay of three ingredients.
First, the orbital coupling to the field shifts the energy of the CdGM analogs
proportionally to the flux and to their generalized angular momentum. Second,
CdGM analogs coalesce into degeneracy points at flux values for which their
corresponding radial wavefunctions are threaded by an integer multiple of the
flux quantum. And third, the average radii of all CdGM-analog wavefunctions
inside the core are approximately equal and are controlled by the electrostatic
band bending at the core/shell interface. As the average radius moves away from
the interface, the degeneracy points shift towards larger fluxes from the
center of the LP lobes, causing the skewness. This analysis provides a
transparent interpretation of the nanowire spectrum that allows to extract
microscopic information by measuring the number and skewness of CdGM analogs.
Moreover, it allows to derive an efficient Hamiltonian of the full-shell
nanowire in terms of a modified hollow-core model at the average radius.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:04:42 GMT""},{""version"":""v2"",""created"":""Sat, 31 Dec 2022 13:37:40 GMT""},{""version"":""v3"",""created"":""Thu, 20 Apr 2023 12:29:32 GMT""}]","2023-04-21"
"2207.07607","Soheil Behnezhad","Soheil Behnezhad","Dynamic Algorithms for Maximum Matching Size","To appear in SODA 2023",,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study fully dynamic algorithms for maximum matching. This is a
well-studied problem, known to admit several update-time/approximation
trade-offs. For instance, it is known how to maintain a 1/2-approximate
matching in $\log^{O(1)} n$ update time or a $2/3$-approximate matching in
$O(\sqrt{n})$ update time, where $n$ is the number of vertices. It has been a
long-standing open problem to determine whether either of these bounds can be
improved.
  In this paper, we show that when the goal is to maintain just the size of the
matching (and not its edge-set), then these bounds can indeed be improved.
First, we give an algorithm that takes $\log^{O(1)} n$ update-time and
maintains a $.501$-approximation ($.585$-approximation if the graph is
bipartite). Second, we give an algorithm that maintains a $(2/3 +
\Omega(1))$-approximation in $O(\sqrt{n})$ time for bipartite graphs.
  Our results build on new connections to sublinear time algorithms. In
particular, a key tool for both is an algorithm of the author for estimating
the size of maximal matchings in $\widetilde{O}(n)$ time [Behnezhad; FOCS
2021]. Our second result also builds on the edge-degree constrained subgraph
(EDCS) of Bernstein and Stein [ICALP'15, SODA'16]. In particular, while it has
been known that EDCS may not include a better than 2/3-approximation, we give a
new characterization of such tight instances which allows us to break it. We
believe this characterization might be of independent interest.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:05:05 GMT""},{""version"":""v2"",""created"":""Fri, 11 Nov 2022 19:20:50 GMT""}]","2022-11-15"
"2207.07608","Farruh Atamurotov","Ghulam Mustafa, Farruh Atamurotov, Ibrar Hussain, Sanjar Shaymatov,
  Ali \""Ovg\""un","Shadows and gravitational weak lensing by the Schwarzschild black hole
  in the string cloud background with quintessential field","12 pages, 9 figures, Accepted for publication in Chinese Physics C","Chinese Phys. C 46 125107 (2022)","10.1088/1674-1137/ac917f",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we observe that in the presence of the string cloud parameter
$a$ and the quintessence parameter $\gamma$, with the equation of state
parameter $\omega_q={-2}/{3}$ the radius of the shadow of the Schwarzschild
black hole increases as compared with the pure Schwarzschild black hole case.
The existence of both quintessential dark energy and cloud of strings magnify
the shadow size and hence the strength of the gravitational field around the
Schwarzschild black hole increases. Using the data collected by the Event
Horizon Telescope (EHT) collaboration for the M87* and Sgr A*, we obtain upper
bounds on the values of the parameters $a$ and $\gamma$. Further, we see the
effects of the parameters $a$ and $\gamma$ on the rate of emission energy for
the Schwarzschild black hole. We notice that the rate of emission energy is
higher in the presence of clouds of string and quintessence. Moreover, we study
the weak deflection angle using the Gauss-Bonnet theorem. We show the influence
of the cloud of string parameter $a$ and the quintessential parameter $\gamma$
on the weak deflection angle. We notice that both the parameters $a$ and
$\gamma$ increase the deflection angle $\alpha$.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:06:56 GMT""},{""version"":""v2"",""created"":""Mon, 5 Sep 2022 15:12:08 GMT""}]","2022-12-01"
"2207.07609","Ruiqing Mao","Ruiqing Mao, Jingyu Guo, Yukuan Jia, Yuxuan Sun, Sheng Zhou, Zhisheng
  Niu","DOLPHINS: Dataset for Collaborative Perception enabled Harmonious and
  Interconnected Self-driving",,,"10.1007/978-3-031-26348-4_29",,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Vehicle-to-Everything (V2X) network has enabled collaborative perception in
autonomous driving, which is a promising solution to the fundamental defect of
stand-alone intelligence including blind zones and long-range perception.
However, the lack of datasets has severely blocked the development of
collaborative perception algorithms. In this work, we release DOLPHINS: Dataset
for cOllaborative Perception enabled Harmonious and INterconnected
Self-driving, as a new simulated large-scale various-scenario multi-view
multi-modality autonomous driving dataset, which provides a ground-breaking
benchmark platform for interconnected autonomous driving. DOLPHINS outperforms
current datasets in six dimensions: temporally-aligned images and point clouds
from both vehicles and Road Side Units (RSUs) enabling both Vehicle-to-Vehicle
(V2V) and Vehicle-to-Infrastructure (V2I) based collaborative perception; 6
typical scenarios with dynamic weather conditions make the most various
interconnected autonomous driving dataset; meticulously selected viewpoints
providing full coverage of the key areas and every object; 42376 frames and
292549 objects, as well as the corresponding 3D annotations, geo-positions, and
calibrations, compose the largest dataset for collaborative perception; Full-HD
images and 64-line LiDARs construct high-resolution data with sufficient
details; well-organized APIs and open-source codes ensure the extensibility of
DOLPHINS. We also construct a benchmark of 2D detection, 3D detection, and
multi-view collaborative perception tasks on DOLPHINS. The experiment results
show that the raw-level fusion scheme through V2X communication can help to
improve the precision as well as to reduce the necessity of expensive LiDAR
equipment on vehicles when RSUs exist, which may accelerate the popularity of
interconnected self-driving vehicles. DOLPHINS is now available on
https://dolphins-dataset.net/.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:07:07 GMT""}]","2023-03-10"
"2207.07610","J.J. Gonz\'alez-Avil\'es","J. J. Gonz\'alez-Avil\'es, K. Murawski and T. V. Zaqarashvili","Numerical simulations of a two-fluid jet at a magnetic null point in a
  solar arcade","14 pages, 11 figures. Accepted for publication in Monthly Notices of
  the Royal Astronomical Society","Mon. Not. R. Astron. Soc. 515, Issue 4 (2022)","10.1093/mnras/stac2032",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We study the formation and evolution of jets in the solar atmosphere using
numerical simulations of partially ionized plasma. The two-fluid
magnetohydrodynamic equations with ion+electron and neutral hydrogen components
are used in two-dimensional (2D) Cartesian geometry. Numerical simulations show
that a localized nonlinear Gaussian pulse of ion and neutral pressures
initially launched from the magnetic null point of a potential arcade located
below the transition region quickly develops into a shock due to the decrease
of density with height. The shock propagates upwards into the solar corona and
lifts the cold and dense chromospheric plasma behind in the form of a
collimated jet with an inverted-Y shape. The inverted-Y shape of jets is
connected with the topology of a magnetic null point. The pulse also excites a
nonlinear wake in the chromosphere, which leads to quasi-periodic secondary
shocks. The secondary shocks lift the chromospheric plasma upwards and create
quasi-periodic jets in the lower corona. Ion and neutral fluids show generally
similar behavior, but their relative velocity is higher near the upper part of
jets, which leads to enhanced temperature or heating due to ion-neutral
collisions. Simulations of jets with inverted-Y shape and their heating may
explain the properties of some jets observed in the solar atmosphere.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:10:45 GMT""}]","2022-08-19"
"2207.07611","Shuangfei Zhai","Shuangfei Zhai, Navdeep Jaitly, Jason Ramapuram, Dan Busbridge,
  Tatiana Likhomanenko, Joseph Yitan Cheng, Walter Talbott, Chen Huang, Hanlin
  Goh, Joshua Susskind","Position Prediction as an Effective Pretraining Strategy","Accepted to ICML 2022",,,,"cs.LG cs.CV cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transformers have gained increasing popularity in a wide range of
applications, including Natural Language Processing (NLP), Computer Vision and
Speech Recognition, because of their powerful representational capacity.
However, harnessing this representational capacity effectively requires a large
amount of data, strong regularization, or both, to mitigate overfitting.
Recently, the power of the Transformer has been unlocked by self-supervised
pretraining strategies based on masked autoencoders which rely on
reconstructing masked inputs, directly, or contrastively from unmasked content.
This pretraining strategy which has been used in BERT models in NLP, Wav2Vec
models in Speech and, recently, in MAE models in Vision, forces the model to
learn about relationships between the content in different parts of the input
using autoencoding related objectives. In this paper, we propose a novel, but
surprisingly simple alternative to content reconstruction~-- that of predicting
locations from content, without providing positional information for it. Doing
so requires the Transformer to understand the positional relationships between
different parts of the input, from their content alone. This amounts to an
efficient implementation where the pretext task is a classification problem
among all possible positions for each input token. We experiment on both Vision
and Speech benchmarks, where our approach brings improvements over strong
supervised training baselines and is comparable to modern
unsupervised/self-supervised pretraining methods. Our method also enables
Transformers trained without position embeddings to outperform ones trained
with full position information.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:10:48 GMT""}]","2022-07-18"
"2207.07612","Jianhao Ma","Jianhao Ma, Salar Fattahi","Blessing of Nonconvexity in Deep Linear Models: Depth Flattens the
  Optimization Landscape Around the True Solution",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work characterizes the effect of depth on the optimization landscape of
linear regression, showing that, despite their nonconvexity, deeper models have
more desirable optimization landscape. We consider a robust and
over-parameterized setting, where a subset of measurements are grossly
corrupted with noise and the true linear model is captured via an $N$-layer
linear neural network. On the negative side, we show that this problem
\textit{does not} have a benign landscape: given any $N\geq 1$, with constant
probability, there exists a solution corresponding to the ground truth that is
neither local nor global minimum. However, on the positive side, we prove that,
for any $N$-layer model with $N\geq 2$, a simple sub-gradient method becomes
oblivious to such ``problematic'' solutions; instead, it converges to a
balanced solution that is not only close to the ground truth but also enjoys a
flat local landscape, thereby eschewing the need for ""early stopping"". Lastly,
we empirically verify that the desirable optimization landscape of deeper
models extends to other robust learning tasks, including deep matrix recovery
and deep ReLU networks with $\ell_1$-loss.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:11:26 GMT""}]","2022-07-18"
"2207.07613","Hsueh-I Lu","Yung-Chung Chiu and Kai-Yuan Lai and Hsueh-I Lu","Improved Algorithms for Recognizing Perfect Graphs and Finding Shortest
  Odd and Even Holes","29 pages, 5 figures",,,,"cs.DS math.CO","http://creativecommons.org/licenses/by/4.0/","  Various classes of induced subgraphs are involved in the deepest results of
graph theory and graph algorithms. A prominent example concerns the {\em
perfection} of $G$ that the chromatic number of each induced subgraph $H$ of
$G$ equals the clique number of $H$. The seminal Strong Perfect Graph Theorem
confirms that the perfection of $G$ can be determined by detecting odd holes in
$G$ and its complement. Chudnovsky et al. show in 2005 an $O(n^9)$ algorithm
for recognizing perfect graphs, which can be implemented to run in
$O(n^{6+\omega})$ time for the exponent $\omega<2.373$ of square-matrix
multiplication. We show the following improved algorithms.
  1. The tractability of detecting odd holes was open for decades until the
major breakthrough of Chudnovsky et al. in 2020. Their $O(n^9)$ algorithm is
later implemented by Lai et al. to run in $O(n^8)$ time, leading to the best
formerly known algorithm for recognizing perfect graphs. Our first result is an
$O(n^7)$ algorithm for detecting odd holes, implying an $O(n^7)$ algorithm for
recognizing perfect graphs.
  2. Chudnovsky et al. extend in 2021 the $O(n^9)$ algorithms for detecting odd
holes (2020) and recognizing perfect graphs (2005) into the first polynomial
algorithm for obtaining a shortest odd hole, which runs in $O(n^{14})$ time. We
reduce the time for finding a shortest odd hole to $O(n^{13})$.
  3. Conforti et al. show in 1997 the first polynomial algorithm for detecting
even holes, running in about $O(n^{40})$ time. It then takes a line of
intensive efforts in the literature to bring down the complexity to
$O(n^{31})$, $O(n^{19})$, $O(n^{11})$, and finally $O(n^9)$. On the other hand,
the tractability of finding a shortest even hole has been open for 16 years
until the very recent $O(n^{31})$ algorithm of Cheong and Lu in 2022. We
improve the time of finding a shortest even hole to $O(n^{23})$.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:12:19 GMT""}]","2022-07-18"
"2207.07614","Aliaume Lopez","Aliaume Lopez","Fixed Points and Noetherian Topologies","18 pages, 2 figures",,,,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  This paper provides a canonical construction of a Noetherian least fixed
point topology. While such least fixed point are not Noetherian in general, we
prove that under a mild assumption, one can use a topological minimal bad
sequence argument to prove that they are. We then apply this fixed point
theorem to rebuild known Noetherian topologies with a uniform proof.
  In the case of spaces that are defined inductively (such as finite words and
finite trees), we provide a uniform definition of a divisibility topology using
our fixed point theorem. We then prove that the divisibility topology is a
generalisation of the divisibility preorder introduced by Hasegawa in the case
of well-quasi-orders.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:13:38 GMT""},{""version"":""v2"",""created"":""Mon, 17 Oct 2022 09:07:13 GMT""}]","2022-10-18"
"2207.07615","Johannes Brust","Johannes J. Brust and Michael A. Saunders","PLSS: A Projected Linear Systems Solver",,,,,"math.NA cs.MS cs.NA stat.CO","http://creativecommons.org/licenses/by/4.0/","  We propose iterative projection methods for solving square or rectangular
consistent linear systems Ax = b. Existing projection methods use sketching
matrices (possibly randomized) to generate a sequence of small projected
subproblems, but even the smaller systems can be costly. We develop a process
that appends one column to the sketching matrix each iteration and converges in
a finite number of iterations whether the sketch is random or deterministic. In
general, our process generates orthogonal updates to the approximate solution
xk. By choosing the sketch to be the set of all previous residuals, we obtain a
simple recursive update and convergence in at most rank(A) iterations (in exact
arithmetic). By choosing a sequence of identity columns for the sketch, we
develop a generalization of the Kaczmarz method. In experiments on large sparse
systems, our method (PLSS) with residual sketches is competitive with LSQR and
LSMR, and with residual and identity sketches compares favorably with
state-of-the-art randomized methods.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:20:07 GMT""},{""version"":""v2"",""created"":""Fri, 2 Dec 2022 21:54:16 GMT""}]","2022-12-06"
"2207.07616","Zahari Kassabov","Zahari Kassabov, Maria Ubiali, Cameron Voisey","Parton distributions with scale uncertainties: a MonteCarlo sampling
  approach","41 pages, 12 figures","JHEP03(2023)148","10.1007/JHEP03(2023)148",,"hep-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We present the MCscales approach for incorporating scale uncertainties in
parton distribution functions (PDFs). The new methodology builds on the Monte
Carlo sampling for propagating experimental uncertainties into the PDF space
that underlies the NNPDF approach, but it extends it to the space of
factorisation and renomalisation scales. A prior probability is assigned to
each scale combinations set in the theoretical predictions used to obtain each
PDF replica in the Monte Carlo ensemble and a posterior probability is obtained
by selecting replicas that satisfy fit-quality criteria. Our approach allows
one to exactly match the scale variations in the PDFs with those in the
computation of the partonic cross sections, thus accounting for the full
correlations between the two. We illustrate the opportunities for
phenomenological exploration made possible by our methodology for a variety of
LHC observables. Sets of PDFs enriched with scale information are provided,
along with a set of tools to use them.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:23:14 GMT""},{""version"":""v2"",""created"":""Fri, 24 Mar 2023 15:04:40 GMT""}]","2023-03-27"
"2207.07617","Jassyr Salas","Jassyr Salas, Frank Bautista, Germ\'an Chaparro","A Bayesian Monte Carlo assessment of orbital stability in the late
  stages of planetary system formation","Accepted for publication in MNRAS",,"10.1093/mnras/stac3112",,"astro-ph.EP astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  The final orbital configuration of a planetary system is shaped by both its
early star-disk environment and late-stage gravitational interactions.
Assessing the relative importance of each of these factors is not
straightforward due to the observed diversity of planetary systems compounded
by observational biases. Our goal is to understand how a planetary system may
change when planetesimal accretion and planet migrations stop and secular
gravitational effects take over. Our approach starts with a novel
classification of planetary systems based on their orbital architecture,
validated using Approximate Bayesian Computation methods. We apply this scheme
to observed planetary systems and also to $\sim 400$ synthetic systems hosting
$\sim 5000$ planets, synthesized from a Monte Carlo planet population model.
Our classification scheme robustly yields four system classes according to
their planet masses and semi-major axes, for both observed and synthetic
systems. We then estimate the orbital distribution density of each of the
synthetic systems before and after dynamically evolving them for up to 1 Myr
with a gravitational+collisional $N$-body code. Using the Kullback-Leibler
divergence to statistically measure orbital configuration changes, we find that
$\lesssim 10 \%$ of synthetic planetary systems experience such changes. We
also find that this fraction belongs to a class of systems for which their
center of mass is very close to their host star. Although changes in the
orbital configuration of planetary systems may not very common, they are more
likely to happen in systems with close-in, massive planets, with F- and G-type
host-stars and stellar metallicities $\mathrm{[Fe/H]} > 0.2$.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:25:38 GMT""},{""version"":""v2"",""created"":""Fri, 11 Nov 2022 17:29:19 GMT""}]","2022-11-14"
"2207.07618","Sanjay Kapoor","Sanjay Kapoor, Filip So\'snicki, Micha{\l} Karpi\'nski","Aberration-corrected time aperture of an electro-optic time lens","7 pages, 5 figures",,,,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Recently, there has been renewed interest in electro-optic time lenses due to
their favorable properties for quantum photonic applications. Here, we propose
a new analytical approach to estimate the chirp rate of a time lens implemented
using an electro-optic phase modulator driven with a single-tone radio
frequency voltage. Our approach is based on a user-defined time aperture for
the time lens. We observe that the temporal aberrations depend on the amplitude
of the phase modulation and the effective time aperture of the time lens. We
derive an analytical expression for the maximum phase error that will allow the
user to choose the maximal aberration-limited time aperture of the time lens.
We apply our formalism to a Fourier-time lens system for the spectral
compression of Gaussian pulses and find the optimal parameters of the setup.
Our approach will provide a handy tool for efficient temporal system design
based on electro-optical time lenses.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:27:15 GMT""}]","2022-07-18"
"2207.07619","Razieh Rastgoo","Razieh Rastgoo, Kourosh Kiani, and Sergio Escalera","A Non-Anatomical Graph Structure for isolated hand gesture separation in
  continuous gesture sequences",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Continuous Hand Gesture Recognition (CHGR) has been extensively studied by
researchers in the last few decades. Recently, one model has been presented to
deal with the challenge of the boundary detection of isolated gestures in a
continuous gesture video [17]. To enhance the model performance and also
replace the handcrafted feature extractor in the presented model in [17], we
propose a GCN model and combine it with the stacked Bi-LSTM and Attention
modules to push the temporal information in the video stream. Considering the
breakthroughs of GCN models for skeleton modality, we propose a two-layer GCN
model to empower the 3D hand skeleton features. Finally, the class
probabilities of each isolated gesture are fed to the post-processing module,
borrowed from [17]. Furthermore, we replace the anatomical graph structure with
some non-anatomical graph structures. Due to the lack of a large dataset,
including both the continuous gesture sequences and the corresponding isolated
gestures, three public datasets in Dynamic Hand Gesture Recognition (DHGR),
RKS-PERSIANSIGN, and ASLVID, are used for evaluation. Experimental results show
the superiority of the proposed model in dealing with isolated gesture
boundaries detection in continuous gesture sequences
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:28:52 GMT""}]","2022-07-18"
"2207.07620","Dalton Sakthivadivel","Dalton A R Sakthivadivel","Weak Markov Blankets in High-Dimensional, Sparsely-Coupled Random
  Dynamical Systems","17 pages. Results from v1 generalised. Comments welcome",,,,"math-ph cond-mat.stat-mech math.DS math.MP math.PR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper formulates a notion of high-dimensional random dynamical systems
that couple to another system, like an embedding environment, in such a way
that each system engages in controlled exchange with the other system. Using
the adiabatic theorem and asymptotic arguments about the behaviour of systems
with many degrees of freedom, we show that this sort of controlled, but not
strictly sparse, coupling structure is ubiquitous in high-dimensional systems.
In doing so we prove a conjecture of K Friston.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:29:07 GMT""},{""version"":""v2"",""created"":""Sun, 14 Aug 2022 04:02:17 GMT""}]","2022-08-16"
"2207.07621","Nikita Drobyshev","Nikita Drobyshev, Jenya Chelishev, Taras Khakhulin, Aleksei
  Ivakhnenko, Victor Lempitsky and Egor Zakharov","MegaPortraits: One-shot Megapixel Neural Head Avatars",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this work, we advance the neural head avatar technology to the megapixel
resolution while focusing on the particularly challenging task of cross-driving
synthesis, i.e., when the appearance of the driving image is substantially
different from the animated source image. We propose a set of new neural
architectures and training methods that can leverage both medium-resolution
video data and high-resolution image data to achieve the desired levels of
rendered image quality and generalization to novel views and motion. We
demonstrate that suggested architectures and methods produce convincing
high-resolution neural avatars, outperforming the competitors in the
cross-driving scenario. Lastly, we show how a trained high-resolution neural
avatar model can be distilled into a lightweight student model which runs in
real-time and locks the identities of neural avatars to several dozens of
pre-defined source images. Real-time operation and identity lock are essential
for many practical applications head avatar systems.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:32:37 GMT""},{""version"":""v2"",""created"":""Tue, 28 Mar 2023 10:58:12 GMT""}]","2023-03-29"
"2207.07622","Javier M. Hernandez-Lopez","Jos\'e Gerardo Su\'arez-Garc\'ia Javier Miguel Hern\'andez-L\'opez,
  Eduardo Moreno-Barbosa, and Benito de Celis-Alonso","Brain MRI study for glioma segmentation using convolutional neural
  networks and original post-processing techniques with low computational
  demand","34 pages, 12 tables, 23 figures",,,,"eess.IV cs.CV physics.med-ph","http://creativecommons.org/licenses/by-sa/4.0/","  Gliomas are brain tumors composed of different highly heterogeneous
histological subregions. Image analysis techniques to identify relevant tumor
substructures have high potential for improving patient diagnosis, treatment
and prognosis. However, due to the high heterogeneity of gliomas, the
segmentation task is currently a major challenge in the field of medical image
analysis. In the present work, the database of the Brain Tumor Segmentation
(BraTS) Challenge 2018, composed of multimodal MRI scans of gliomas, was
studied. A segmentation methodology based on the design and application of
convolutional neural networks (CNNs) combined with original post-processing
techniques with low computational demand was proposed. The post-processing
techniques were the main responsible for the results obtained in the
segmentations. The segmented regions were the whole tumor, the tumor core, and
the enhancing tumor core, obtaining averaged Dice coefficients equal to 0.8934,
0.8376, and 0.8113, respectively. These results reached the state of the art in
glioma segmentation determined by the winners of the challenge.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:34:05 GMT""}]","2022-07-18"
"2207.07623","Ben Heuer","Ben Heuer","$G$-torsors on perfectoid spaces",,,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For any rigid analytic group variety $G$ over a non-archimedean field $K$
over $\mathbb Q_p$, we study $G$-torsors on adic spaces over $K$ in the
$v$-topology. Our main result is that on perfectoid spaces, $G$-torsors in the
\'etale and $v$-topology are equivalent. This generalises the known cases of
$G=\mathbb G_a$ and $G=\mathrm{GL}_n$ due to Scholze and Kedlaya--Liu.
  On a general adic space $X$ over $K$, where there can be more $v$-topological
$G$-torsors than \'etale ones, we show that for any open subgroup $U\subseteq
G$, any $G$-torsor on $X_v$ admits a reduction of structure group to $U$
\'etale-locally on $X$. This has applications in the context of the $p$-adic
Simpson correspondence: For example, we use it to show that on any adic space,
generalised $\mathbb Q_p$-representations are equivalent to $v$-vector bundles.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:35:04 GMT""}]","2022-07-18"
"2207.07624","Ondrej Bohdal","Ondrej Bohdal, Da Li, Shell Xu Hu, Timothy Hospedales","Feed-Forward Source-Free Latent Domain Adaptation via Cross-Attention","Shorter version accepted at the First Workshop of Pre-training:
  Perspectives, Pitfalls, and Paths Forward at ICML 2022",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the highly practical but comparatively under-studied problem of
latent-domain adaptation, where a source model should be adapted to a target
dataset that contains a mixture of unlabelled domain-relevant and
domain-irrelevant examples. Furthermore, motivated by the requirements for data
privacy and the need for embedded and resource-constrained devices of all kinds
to adapt to local data distributions, we focus on the setting of feed-forward
source-free domain adaptation, where adaptation should not require access to
the source dataset, and also be back propagation-free. Our solution is to
meta-learn a network capable of embedding the mixed-relevance target dataset
and dynamically adapting inference for target examples using cross-attention.
The resulting framework leads to consistent improvement on strong ERM
baselines. We also show that our framework sometimes even improves on the upper
bound of domain-supervised adaptation, where only domain-relevant instances are
provided for adaptation. This suggests that human annotated domain labels may
not always be optimal, and raises the possibility of doing better through
automated instance selection.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:37:42 GMT""}]","2022-07-18"
"2207.07625","Simon Felix Langenscheidt","Eugenia Colafranceschi, Simon Langenscheidt and Daniele Oriti","Holographic properties of superposed spin networks","36 pages, 5 figures",,,,"quant-ph gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study criteria for and properties of boundary-to-boundary holography in a
class of spin network states defined by analogy to tensor networks. In
particular, we consider superposition of states realising a genuine sum over
discrete quantum geometries. By applying random tensor techniques we map
entropy calculations to a random Ising model on the underlying graph, with
distribution of couplings determined by the relative sizes of the involved
geometries. We find that, whenever each individual geometry produces an
isometric mapping from a boundary region to its complement, the superposition
of them does the same if and only if the relative weight of each geometry is
inversely proportional to its size. Additionally, we compute average value and
variance of the input boundary region and show that the first is bounded from
below and above by, respectively, the mean and sum of the areas of the
individual-geometries. We finally describe possible extensions to our program
and highlight the conceptual issues underpinning them.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:37:47 GMT""},{""version"":""v2"",""created"":""Thu, 20 Oct 2022 16:39:35 GMT""}]","2022-10-21"
"2207.07626","Zheyu Yan","Zheyu Yan, Xiaobo Sharon Hu, Yiyu Shi","Computing-In-Memory Neural Network Accelerators for Safety-Critical
  Systems: Can Small Device Variations Be Disastrous?",,,"10.1145/3508352.3549360",,"cs.AR cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Computing-in-Memory (CiM) architectures based on emerging non-volatile memory
(NVM) devices have demonstrated great potential for deep neural network (DNN)
acceleration thanks to their high energy efficiency. However, NVM devices
suffer from various non-idealities, especially device-to-device variations due
to fabrication defects and cycle-to-cycle variations due to the stochastic
behavior of devices. As such, the DNN weights actually mapped to NVM devices
could deviate significantly from the expected values, leading to large
performance degradation. To address this issue, most existing works focus on
maximizing average performance under device variations. This objective would
work well for general-purpose scenarios. But for safety-critical applications,
the worst-case performance must also be considered. Unfortunately, this has
been rarely explored in the literature. In this work, we formulate the problem
of determining the worst-case performance of CiM DNN accelerators under the
impact of device variations. We further propose a method to effectively find
the specific combination of device variation in the high-dimensional space that
leads to the worst-case performance. We find that even with very small device
variations, the accuracy of a DNN can drop drastically, causing concerns when
deploying CiM accelerators in safety-critical applications. Finally, we show
that surprisingly none of the existing methods used to enhance average DNN
performance in CiM accelerators are very effective when extended to enhance the
worst-case performance, and further research down the road is needed to address
this problem.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:38:01 GMT""}]","2022-07-26"
"2207.07627","Xudong Lv","Xudong Lv, Ashok Ajoy","Dual-space Compressed Sensing",,,,,"eess.IV physics.app-ph physics.optics","http://creativecommons.org/licenses/by/4.0/","  Compressed sensing (CS) is a powerful method routinely employed to accelerate
image acquisition. It is particularly suited to situations when the image under
consideration is sparse but can be sampled in a basis where it is non-sparse.
Here we propose an alternate CS regime in situations where the image can be
sampled in two incoherent spaces simultaneously, with a special focus on image
sampling in Fourier reciprocal spaces (e.g. real-space and k-space).
Information is fed-forward from one space to the other, allowing new
opportunities to efficiently solve the optimization problem at the heart of CS
image reconstruction. We show that considerable gains in imaging acceleration
are then possible over conventional CS. The technique provides enhanced
robustness to noise, and is well suited to edge-detection problems. We envision
applications for imaging collections of nanodiamond (ND) particles targeting
specific regions in a volume of interest, exploiting the ability of lattice
defects (NV centers) to allow ND particles to be imaged in reciprocal spaces
simultaneously via optical fluorescence and 13C magnetic resonance imaging
(MRI) respectively. Broadly this work suggests the potential to interface CS
principles with hybrid sampling strategies to yield speedup in signal
acquisition in many practical settings.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:39:53 GMT""}]","2022-07-18"
"2207.07628","Zahra Fazli","Zahra Fazli and Ali Naji","Rectification of polymer translocation through nanopores by chiral and
  nonchiral active particles","10 pages, 7 figures",,,,"cond-mat.soft physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study unbiased translocation of a flexible polymer chain through a
membrane pore under the influence of active noise and steric exclusion using
Langevin dynamics simulations. The active noise is incorporated by introducing
nonchiral and chiral active particles on one or both sides of the membrane.
Translocation of the polymer into either side of the pore is assisted by an
effective pulling due to particle activity and is hindered by an effective
pushing due to steric repulsions between the polymer and active particles. As a
result of the competition between these effective forces, we find a transition
between two rectified ({\em cis}-to-{\em trans} and {\em trans}-to-{\em cis})
states. This transition is identified by a sharp increase of translocation
time. It varies depending on the system parameters such as particle activity,
area fraction and chirality whose effects are explored in this work.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:42:46 GMT""},{""version"":""v2"",""created"":""Mon, 18 Jul 2022 10:53:52 GMT""}]","2022-07-19"
"2207.07629","Zhiruo Zhou","Zhiruo Zhou, Hongyu Fu, Suya You, C.-C. Jay Kuo","GUSOT: Green and Unsupervised Single Object Tracking for Long Video
  Sequences",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Supervised and unsupervised deep trackers that rely on deep learning
technologies are popular in recent years. Yet, they demand high computational
complexity and a high memory cost. A green unsupervised single-object tracker,
called GUSOT, that aims at object tracking for long videos under a
resource-constrained environment is proposed in this work. Built upon a
baseline tracker, UHP-SOT++, which works well for short-term tracking, GUSOT
contains two additional new modules: 1) lost object recovery, and 2)
color-saliency-based shape proposal. They help resolve the tracking loss
problem and offer a more flexible object proposal, respectively. Thus, they
enable GUSOT to achieve higher tracking accuracy in the long run. We conduct
experiments on the large-scale dataset LaSOT with long video sequences, and
show that GUSOT offers a lightweight high-performance tracking solution that
finds applications in mobile and edge computing platforms.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:42:49 GMT""}]","2022-07-18"
"2207.07630","Arnd Behring","Arnd Behring","Zero-jettiness beam functions at N$^3$LO","12 pages, 2 figures, contribution to the proceedings of ""Loops and
  Legs in Quantum Field Theory - LL2022, 25-30 April, 2022, Ettal, Germany""",,,"CERN-TH-2022-120, TTP22-047, P3H-22-075","hep-ph","http://creativecommons.org/licenses/by/4.0/","  The zero-jettiness beam functions describe collinear emissions from initial
state legs and appear in the factorisation theorem for cross sections in the
limit of small zero-jettiness. They are an important building block for slicing
schemes for colour-singlet production at hadron colliders. We report on our
ongoing calculation of this quantity at next-to-next-to-next-to-leading order
(N$^3$LO) in QCD, highlighting in particular the aspects of partial fraction
relations and the calculation of master integrals.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:43:29 GMT""}]","2022-07-18"
"2207.07631","Zhongyi Zhang","Sascha Caron, Roberto Ruiz de Austri, Zhongyi Zhang","Mixture-of-theories Training: Can We Find New Physics and Anomalies
  Better by Mixing Physical Theories?","40 pages, 10 figures",,"10.1007/JHEP03(2023)004",,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Model-independent search strategies have been increasingly proposed in recent
years because on the one hand there has been no clear signal for new physics
and on the other hand there is a lack of a highly probable and parameter-free
extension of the standard model. For these reasons, there is no simple search
target so far. In this work, we try to take a new direction and ask the
question: bearing in mind that we have a large number of new physics theories
that go beyond the Standard Model and may contain a grain of truth, can we
improve our search strategy for unknown signals by using them ""in combination""?
In particular, we show that a signal hypothesis based on a large, intermingled
set of many different theoretical signal models can be a superior approach to
find an unknown BSM signal. Applied to a recent data challenge, we show that
""mixture-of-theories training"" outperforms strategies that optimize signal
regions with a single BSM model as well as most unsupervised strategies.
Applications of this work include anomaly detection and the definition of
signal regions in the search for signals of new physics.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:45:33 GMT""},{""version"":""v2"",""created"":""Sun, 7 Aug 2022 17:19:23 GMT""}]","2023-03-22"
"2207.07632","George Thomas","George Thomas and Jukka P. Pekola","Dynamical phase and quantum heat at fractional frequencies","6 pages, 3 figures, comments welcome","Phys. Rev. Research 5, L022036 (2023)","10.1103/PhysRevResearch.5.L022036",,"quant-ph cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate a genuine quantum feature of heat: the power emitted by a
qubit (quantum two-level system) into a reservoir under continuous driving
shows peaks as a function of frequency $f$. These resonant features appear due
to the accumulation of the dynamical phase during the driving. The position of
the $n$th maximum is given by $f=f_{\rm M}/n$, where $f_{\rm M}$ is the mean
frequency of the qubit in the cycle, and their positions are independent of the
form of the drive and the number of heat baths attached, and even the presence
or absence of spectral filtering. We show that the waveform of the drive
determines the intensity of the peaks, differently for odd and even resonances.
This quantum heat is expected to play a crucial role in the performance of
driven thermal devices such as quantum heat engines and refrigerators. We also
show that by optimizing the cycle protocol, we recover the favorable classical
limit in fast driven systems without the use of counter-diabatic drive
protocols and we demonstrate an entropy preserving non-unitary process. We
propose that this non-trivial quantum heat can be detected by observing the
steady-state power absorbed by a resistor acting as a bolometer attached to a
driven superconducting qubit.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:45:58 GMT""},{""version"":""v2"",""created"":""Mon, 22 May 2023 20:01:56 GMT""}]","2023-05-24"
"2207.07633","Bianka Kov\'acs","Bianka Kov\'acs, Gergely Palla","Model-independent methods for embedding directed networks into Euclidean
  and hyperbolic spaces",,"Commun Phys 6, 28 (2023)","10.1038/s42005-023-01143-x",,"physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The arrangement of network nodes in hyperbolic spaces has become a widely
studied problem, motivated by numerous results suggesting the existence of
hidden metric spaces behind the structure of complex networks. Although several
methods have already been developed for the hyperbolic embedding of undirected
networks, approaches able to deal with directed networks are still in their
infancy. Here, we propose a framework based on the dimension reduction of
proximity matrices reflecting the network topology, coupled with a general
conversion method transforming Euclidean node coordinates into hyperbolic ones
even for directed networks. While proposing a new measure of proximity, we also
incorporate an earlier Euclidean embedding method in our pipeline,
demonstrating the widespread applicability of our Euclidean-hyperbolic
conversion. Besides, we introduce a dimension reduction technique that maps the
nodes directly into the hyperbolic space with the aim of reproducing a distance
matrix measured on the given (un)directed network. According to mapping
accuracy, graph reconstruction performance and greedy routing score, our
methods are capable of producing high-quality embeddings for several real
networks.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:46:13 GMT""}]","2023-02-06"
"2207.07634","Peter Reimitz","Adam Coogan, Logan Morrison, Tilman Plehn, Stefano Profumo, Peter
  Reimitz","Hazma Meets HERWIG4DM: Precision Gamma-Ray, Neutrino, and Positron
  Spectra for Light Dark Matter","25 pages, 9 figures, typos fixed, added explanation about vector
  couplings, version published in JCAP","JCAP 11 (2022) 033","10.1088/1475-7516/2022/11/033",,"hep-ph astro-ph.CO astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new open-source package, Hazma 2, that computes accurate spectra
relevant for indirect dark matter searches for photon, neutrino, and positron
production from vector-mediated dark matter annihilation and for spin-one dark
matter decay. The tool bridges across the regimes of validity of two state of
the art codes: Hazma 1, which provides an accurate description below hadronic
resonances up to center-of-mass energies around 250 MeV, and HERWIG4DM, which
is based on vector meson dominance and measured form factors, and accurate well
into the few GeV range. The applicability of the combined code extends to
approximately 1.5 GeV, above which the number of final state hadrons off of
which we individually compute the photon, neutrino, and positron yield grows
exceedingly rapidly. We provide example branching ratios, particle spectra and
conservative observational constraints from existing gamma-ray data for the
well-motivated cases of decaying dark photon dark matter and vector-mediated
fermionic dark matter annihilation. Finally, we compare our results to other
existing codes at the boundaries of their respective ranges of applicability.
Hazma 2 is freely available on GitHub.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:49:08 GMT""},{""version"":""v2"",""created"":""Fri, 14 Oct 2022 19:35:34 GMT""},{""version"":""v3"",""created"":""Tue, 15 Nov 2022 18:15:36 GMT""}]","2022-11-16"
"2207.07635","Shibani Santurkar","Shibani Santurkar, Yann Dubois, Rohan Taori, Percy Liang and Tatsunori
  Hashimoto","Is a Caption Worth a Thousand Images? A Controlled Study for
  Representation Learning",,,,,"cs.CV cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  The development of CLIP [Radford et al., 2021] has sparked a debate on
whether language supervision can result in vision models with more transferable
representations than traditional image-only methods. Our work studies this
question through a carefully controlled comparison of two approaches in terms
of their ability to learn representations that generalize to downstream
classification tasks. We find that when the pre-training dataset meets certain
criteria -- it is sufficiently large and contains descriptive captions with low
variability -- image-only methods do not match CLIP's transfer performance,
even when they are trained with more image data. However, contrary to what one
might expect, there are practical settings in which these criteria are not met,
wherein added supervision through captions is actually detrimental. Motivated
by our findings, we devise simple prescriptions to enable CLIP to better
leverage the language information present in existing pre-training datasets.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:50:51 GMT""}]","2022-07-18"
"2207.07636","Min-Di Zheng","Min-Di Zheng, Feng-Zhi Chen and Hong-Hao Zhang","Explaining anomalies of $B$-physics, muon $g-2$ and $W$ mass in
  $R$-parity violating MSSM with seesaw mechanism","34 pages, 2 figures; More discussions and references added, final
  version published in EPJC",,"10.1140/epjc/s10052-022-10822-y",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recent experimental results including $R_{K^{(\ast)}}$, $R_{D^{(\ast)}}$,
$(g-2)_\mu$ and $W$ mass show deviations from the standard model (SM)
predictions, implying the clues of new physics (NP). In this work, we
investigate the explanations of these anomalies in the $R$-parity violating
minimal supersymmetric standard model (RPV-MSSM) extended with the inverse
seesaw mechanism. The non-unitarity extent $\eta_{ee}$ and the loop corrections
from the interaction $\lambda'\hat L \hat Q \hat D$ are utilized to raise the
prediction of $W$ mass through muon decays. We also find that the interaction
$\lambda'\hat L \hat Q \hat D$ involved with right-handed (RH)/singlet
(s)neutrinos can explain the $R_{K^{(\ast)}}$ and $R_{D^{(\ast)}}$ anomalies
simultaneously when considering nonzero $\lambda'_{1jk}$. For nonzero
$\lambda'_{2jk}$, this model fulfills the whole $b\to s\ell^+\ell^-$ fit but
cannot be accordant with $R_{D^{(\ast)}}$ measurements. The explanations in
both cases are also favored by $(g-2)_\mu$ data, neutrino oscillation data and
the relevant constraints we scrutinized. Furthermore, this model framework can
be tested in future experiments covering, e.g., the predicted lepton flavor
violations (LFV) at Belle II and the Future Circular Collider with $e^+e^-$
beams (FCC-ee), as well as the heavy neutrinos at future colliders.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:51:39 GMT""},{""version"":""v2"",""created"":""Tue, 11 Oct 2022 07:35:25 GMT""}]","2022-10-12"
"2207.07637","Dmitrii Semenok","I. A. Troyan, D. V. Semenok, A. G. Ivanova, A. G. Kvashnin, D. Zhou,
  A. V. Sadakov, O. A. Sobolevskiy, V. M. Pudalov, I. S. Lyubutin, A. R. Oganov","High-temperature superconductivity in hydrides","English version of the article in the Russian journal Advances in
  Physical Sciences (Physics Uspekhi), https://ufn.ru/ru/articles/2022/7/g/
  Many minor terminological errors have been corrected in the 2nd version of
  the manuscript","Phys. Usp. 65 (7) (2022)","10.3367/UFNe.2021.05.039187",,"cond-mat.supr-con cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Over the past six years (2015-2021), many superconducting hydrides with
critical temperatures $T_{C}$ up to 250 K, which are currently record highs,
have been discovered. Now we can already say that a special field of
superconductivity has developed. This is hydride superconductivity at ultrahigh
pressures. For the most part, the properties of superhydrides are well
described by the Migdal-Eliashberg theory of strong electron-phonon
interaction, especially when anharmonicity of phonons is taken into account.
The isotope effect, the effect of the magnetic field (up to 60-70 T) on the
critical temperature and critical current in the hydride samples, the
dependence of $T_{C}$ on the pressure and degree of doping were investigated.
The divergences between the theory and experiment are of interest, especially
in the field of phase stability and in the behavior of the upper critical
magnetic fields at low temperatures. This article presents a retrospective
analysis of data of 2015-2021 and describes promising directions for future
research of hydride superconductivity.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:52:09 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jul 2022 21:34:18 GMT""}]","2022-07-22"
"2207.07638","Ian Guinn","I.J. Arnquist, F.T. Avignone III, A.S. Barabash, C.J. Barton, P.J.
  Barton, K.H. Bhimani, E. Blalock, B. Bos, M. Busch, M. Buuck, T.S. Caldwell,
  Y-D. Chan, C.D. Christofferson, P.-H. Chu, M.L. Clark, C. Cuesta, J.A.
  Detwiler, Yu. Efremenko, H. Ejiri, S.R. Elliott, G.K. Giovanetti, M.P. Green,
  J. Gruszko, I.S. Guinn, V.E. Guiseppe, C.R. Haufe, R. Henning, D. Hervas
  Aguilar, E.W. Hoppe, A. Hostiuc, M.F. Kidd, I. Kim, R.T. Kouzes, T.E. Lannen
  V, A. Li, A.M. Lopez, J.M. L\'opez-Casta\~no, E.L. Martin, R.D. Martin, R.
  Massarczyk, S.J. Meijer, S. Mertens, T.K. Oli, G. Othman, L.S. Paudel, W.
  Pettus, A.W.P. Poon, D.C. Radford, A.L. Reine, K. Rielage, N.W. Ruof, D.C.
  Schaper, D. Tedeschi, R.L. Varner, S. Vasilyev, J.F. Wilkerson, C. Wiseman,
  W. Xu, C.-H. Yu, and B.X. Zhu","Final Result of the MAJORANA DEMONSTRATOR's Search for Neutrinoless
  Double-$\beta$ Decay in $^{76}$Ge","8 pages, 2 figures","Phys. Rev. Lett. 130, 062501 (2022)","10.1103/PhysRevLett.130.062501",,"nucl-ex hep-ex physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  The MAJORANA DEMONSTRATOR searched for neutrinoless double-$\beta$ decay
($0\nu\beta\beta$) of $^{76}$Ge using modular arrays of high-purity Ge
detectors operated in vacuum cryostats in a low-background shield. The arrays
operated with up to 40.4 kg of detectors (27.2 kg enriched to $\sim$88\% in
$^{76}$Ge). From these measurements, the DEMONSTRATOR has accumulated 64.5 kg
yr of enriched active exposure. With a world-leading energy resolution of 2.52
keV FWHM at the 2039 keV $Q_{\beta\beta}$ (0.12\%), we set a half-life limit of
$0\nu\beta\beta$ in $^{76}$Ge at $T_{1/2}>8.3\times10^{25}$ yr (90\% C.L.).
This provides a range of upper limits on $m_{\beta\beta}$ of $(113-269)$ meV
(90\% C.L.), depending on the choice of nuclear matrix elements.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:53:09 GMT""},{""version"":""v2"",""created"":""Fri, 10 Feb 2023 16:14:53 GMT""}]","2023-02-13"
"2207.07639","Boris Pritychenko","B. Pritychenko, B. Singh, M. Verpelli","Systematic Trends of 0$^+_2$, 1$^-_1$, 3$^-_1$ and 2$^+_1$ Excited
  States in Even-Even Nuclei","39 pages, 6 figures, 4 tables. NP/A (2022)","Nuclear Physics A 1027, 122511 (2022)","10.1016/j.nuclphysa.2022.122511","Brookhaven National Laboratory Report BNL-223167-2022-JAAM","nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The spin and parity ($J^{\pi}$) assignments in even-even nuclei were reviewed
across the nuclear chart using the Evaluated Nuclear Structure Data File
(ENSDF). The prevalence of 2$^+_1$ first or lowest excited states is confirmed.
The properties of 0$^+_2$, 1$^-_1$, and 3$^-_1$ lowest excited states were
reexamined using the ENSDF data evaluation procedures. The $J^{\pi}$ systematic
trends and correlations between level quantum numbers and nuclear physics
phenomena are discussed.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:54:22 GMT""}]","2022-07-28"
"2207.07640","Felix Wagner","G. Angloher, S. Banik, G. Benato, A. Bento, A. Bertolini, R. Breier,
  C. Bucci, J. Burkhart, L. Canonica, A. D'Addabbo, S. Di Lorenzo, L. Einfalt,
  A. Erb, F. v. Feilitzsch, N. Ferreiro Iachellini, S. Fichtinger, D. Fuchs, A.
  Fuss, A. Garai, V. M. Ghete, S. Gerster, P. Gorla, P.V. Guillaumon, S. Gupta,
  D. Hauff, M. Je\v{s}kovsk\'y, J. Jochum, M. Kaznacheeva, A. Kinast, H. Kluck,
  H. Kraus, A. Langenk\""amper, M. Mancuso, L. Marini, L. Meyer, V. Mokina, A.
  Nilima, M. Olmi, T. Ortmann, C. Pagliarone, L. Pattavina, F. Petricca, W.
  Potzel, P. Povinec, F. Pr\""obst, F. Pucci, F. Reindl, J. Rothe, K.
  Sch\""affner, J. Schieck, D. Schmiedmayer, S. Sch\""onert, C. Schwertner, M.
  Stahlberg, L. Stodolsky, C. Strandhagen, R. Strauss, I. Usherov, F. Wagner,
  M. Willers, and V. Zema","Testing spin-dependent dark matter interactions with lithium aluminate
  targets in CRESST-III","9 pages, 8 figures",,"10.1103/PhysRevD.106.092008",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the past decades, numerous experiments have emerged to unveil the nature
of dark matter, one of the most discussed open questions in modern particle
physics. Among them, the CRESST experiment, located at the Laboratori Nazionali
del Gran Sasso, operates scintillating crystals as cryogenic phonon detectors.
In this work, we present first results from the operation of two detector
modules which both have 10.46 g LiAlO$_2$ targets in CRESST-III. The lithium
contents in the crystal are $^6$Li, with an odd number of protons and neutrons,
and $^7$Li, with an odd number of protons. By considering both isotopes of
lithium and $^{27}$Al, we set the currently strongest cross section upper
limits on spin-dependent interaction of dark matter with protons and neutrons
for the mass region between 0.25 and 1.5 GeV/c$^2$.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:54:35 GMT""}]","2022-12-07"
"2207.07641","Andreas S. Kronfeld","Andreas S. Kronfeld, Tanmoy Bhattacharya, Thomas Blum, Norman H.
  Christ, Carleton DeTar, William Detmold, Robert Edwards, Anna Hasenfratz,
  Huey-Wen Lin, Swagato Mukherjee, Konstantinos Orginos, Richard Brower,
  Vincenzo Cirigliano, Zohreh Davoudi, B\'alint J\'oo, Chulwoo Jung, Christoph
  Lehner, Stefan Meinel, Ethan T. Neil, Peter Petreczky, David G. Richards,
  Alexei Bazavov, Simon Catterall, Jozef J. Dudek, Aida X. El-Khadra, Michael
  Engelhardt, George T. Fleming, Joel Giedt, Rajan Gupta, Maxwell T. Hansen,
  Taku Izubuchi, Frithjof Karsch, Jack Laiho, Keh-Fei Liu, Aaron S. Meyer,
  Enrico Rinaldi, Martin Savage, David Schaich, Phiala E. Shanahan, Stephen R.
  Sharpe, Raza Sufian, Sergey Syritsyn, Ruth S. Van de Water, Michael L.
  Wagman, Evan Weinberg, Oliver Witzel, Christopher Aubin, Peter Boyle,
  Shailesh Chandrasekharan, Ian C. Cl\""oet, Martha Constantinou, Kimmy Cushman,
  Thomas DeGrand, Zoltan Fodor, Sam Foreman, Steven Gottlieb, Daniel Hoying,
  Yong-Chull Jang, William I. Jay, Xiao-Yong Jin, Christopher Kelly, Julius
  Kuti, Henry Lamm, Meifeng Lin, Yin Lin, Andrew T. Lytle, Paul Mackenzie,
  Jeffrey Mandula, Yannick Meurice, Christopher Monahan, Colin Morningstar,
  James C. Osborn, Sungwoo Park, James N. Simone, Alexei Strelchenko, Masaaki
  Tomii, Alejandro Vaquero, Pavlos Vranas, Bigeng Wang, Walter Wilcox, Boram
  Yoon, Yong Zhao","Lattice QCD and Particle Physics","27 pp. main text, 4 pp. appendices, 29 pp. references, 1 p. index",,,"FERMILAB-CONF-22-531-T","hep-lat hep-ex hep-ph","http://creativecommons.org/licenses/by/4.0/","  Contribution from the USQCD Collaboration to the Proceedings of the US
Community Study on the Future of Particle Physics (Snowmass 2021).
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:55:04 GMT""},{""version"":""v2"",""created"":""Sun, 2 Oct 2022 15:30:44 GMT""}]","2022-10-04"
"2207.07642","Evan Smith","Evan T. Smith, Ryan Lynch, D.J. Pisano","Simulating Spectral Kurtosis Mitigation Against Realistic RFI Signals","Accepted to AJ. 19 pages, 15 figures",,"10.3847/1538-3881/ac7e47",,"astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  We investigate the effectiveness of the statistical radio frequency
interference (RFI) mitigation technique spectral kurtosis (SK) in the face of
simulated realistic RFI signals. SK estimates the kurtosis of a collection of M
power values in a single channel and provides a detection metric that is able
to discern between human-made RFI and incoherent astronomical signals of
interest. We test the ability of SK to flag signals with various representative
modulation types, data rates, duty cycles, and carrier frequencies. We flag
with various accumulation lengths M and implement multi-scale SK, which
combines information from adjacent time-frequency bins to mitigate weaknesses
in single-scale \SK. We find that signals with significant sidelobe emission
from high data rates are harder to flag, as well as signals with a 50%
effective duty cycle and weak signal-to-noise ratios. Multi-scale SK with at
least one extra channel can detect both the center channel and side-band
interference, flagging greater than 90% as long as the bin channel width is
wider in frequency than the RFI.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:55:57 GMT""}]","2022-09-14"
"2207.07643","Shunan Guo","Bingjie Xu, Shunan Guo, Eunyee Koh, Jane Hoffswell, Ryan Rossi, Fan Du","ARShopping: In-Store Shopping Decision Support Through Augmented Reality
  and Immersive Visualization","VIS 2022 Short Paper; 5 pages",,,,"cs.HC","http://creativecommons.org/licenses/by/4.0/","  Online shopping gives customers boundless options to choose from, backed by
extensive product details and customer reviews, all from the comfort of home;
yet, no amount of detailed, online information can outweigh the instant
gratification and hands-on understanding of a product that is provided by
physical stores. However, making purchasing decisions in physical stores can be
challenging due to a large number of similar alternatives and limited
accessibility of the relevant product information (e.g., features, ratings, and
reviews). In this work, we present ARShopping: a web-based prototype to
visually communicate detailed product information from an online setting on
portable smart devices (e.g., phones, tablets, glasses), within the physical
space at the point of purchase. This prototype uses augmented reality (AR) to
identify products and display detailed information to help consumers make
purchasing decisions that fulfill their needs while decreasing the
decision-making time. In particular, we use a data fusion algorithm to improve
the precision of the product detection; we then integrate AR visualizations
into the scene to facilitate comparisons across multiple products and features.
We designed our prototype based on interviews with 14 participants to better
understand the utility and ease of use of the prototype.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:56:57 GMT""}]","2022-07-18"
"2207.07644","Grace Lawrence","Grace E. Lawrence, Alan R. Duffy, Chris A. Blake, Philip F. Hopkins","Gusts in the Headwind: Uncertainties in Direct Dark Matter Detection","22 pages, 27 figures, 4 tables. Submitted to MNRAS. Comments welcome",,"10.1093/mnras/stac2447",,"astro-ph.GA astro-ph.CO astro-ph.IM hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use high-resolution, hydrodynamic, galaxy simulations from the Latte suite
of FIRE-2 simulations to investigate the inherent variation of dark matter in
sub-sampled regions around the Solar Circle of a Milky Way-type analogue galaxy
and its impact on direct dark matter detection. These simulations show that the
baryonic backreaction, as well as the assembly history of substructures, has
lasting impacts on the dark matter's spatial and velocity distributions. These
are experienced as 'gusts' of dark matter wind around the Solar Circle,
potentially complicating interpretations of direct detection experiments on
Earth. We find that the velocity distribution function in the galactocentric
frame shows strong deviations from the Maxwell Boltzmann form typically assumed
in the fiducial Standard Halo Model, indicating the presence of high-velocity
substructures. By introducing a new numerical integration technique which
removes any dependencies on the Standard Halo Model, we generate event-rate
predictions for both single-element Germanium and compound Sodium Iodide
detectors, and explore how the variability of dark matter around the Solar
Circle influences annual modulation signal predictions. We find that these
velocity substructures contribute additional astrophysical uncertainty to the
interpretation of event rates, although their impact on summary statistics such
as the peak day of annual modulation is generally low.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:57:30 GMT""}]","2022-09-28"
"2207.07645","George Stein","George Stein, Uros Seljak, Vanessa Bohm, G. Aldering, P. Antilogus, C.
  Aragon, S. Bailey, C. Baltay, S. Bongard, K. Boone, C. Buton, Y. Copin, S.
  Dixon, D. Fouchez, E. Gangler, R. Gupta, B. Hayden, W. Hillebrandt, M.
  Karmen, A. G. Kim, M. Kowalski, D. Kusters, P. F. Leget, F. Mondon, J.
  Nordin, R. Pain, E. Pecontal, R. Pereira, S. Perlmutter, K. A. Ponder, D.
  Rabinowitz, M. Rigault, D. Rubin, K. Runge, C. Saunders, G. Smadja, N.
  Suzuki, C. Tao, R. C. Thomas, M. Vincenzi","A Probabilistic Autoencoder for Type Ia Supernovae Spectral Time Series","23 pages, 8 Figures, 1 Table. Accepted to ApJ",,"10.3847/1538-4357/ac7c08",,"astro-ph.CO cs.LG","http://creativecommons.org/licenses/by/4.0/","  We construct a physically-parameterized probabilistic autoencoder (PAE) to
learn the intrinsic diversity of type Ia supernovae (SNe Ia) from a sparse set
of spectral time series. The PAE is a two-stage generative model, composed of
an Auto-Encoder (AE) which is interpreted probabilistically after training
using a Normalizing Flow (NF). We demonstrate that the PAE learns a
low-dimensional latent space that captures the nonlinear range of features that
exists within the population, and can accurately model the spectral evolution
of SNe Ia across the full range of wavelength and observation times directly
from the data. By introducing a correlation penalty term and multi-stage
training setup alongside our physically-parameterized network we show that
intrinsic and extrinsic modes of variability can be separated during training,
removing the need for the additional models to perform magnitude
standardization. We then use our PAE in a number of downstream tasks on SNe Ia
for increasingly precise cosmological analyses, including automatic detection
of SN outliers, the generation of samples consistent with the data
distribution, and solving the inverse problem in the presence of noisy and
incomplete data to constrain cosmological distance measurements. We find that
the optimal number of intrinsic model parameters appears to be three, in line
with previous studies, and show that we can standardize our test sample of SNe
Ia with an RMS of $0.091 \pm 0.010$ mag, which corresponds to $0.074 \pm 0.010$
mag if peculiar velocity contributions are removed. Trained models and codes
are released at
\href{https://github.com/georgestein/suPAErnova}{github.com/georgestein/suPAErnova}
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:58:27 GMT""}]","2022-08-17"
"2207.07646","Yin Cui","Rui Qian, Yeqing Li, Zheng Xu, Ming-Hsuan Yang, Serge Belongie, Yin
  Cui","Multimodal Open-Vocabulary Video Classification via Pre-Trained Vision
  and Language Models",,,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Utilizing vision and language models (VLMs) pre-trained on large-scale
image-text pairs is becoming a promising paradigm for open-vocabulary visual
recognition. In this work, we extend this paradigm by leveraging motion and
audio that naturally exist in video. We present \textbf{MOV}, a simple yet
effective method for \textbf{M}ultimodal \textbf{O}pen-\textbf{V}ocabulary
video classification. In MOV, we directly use the vision encoder from
pre-trained VLMs with minimal modifications to encode video, optical flow and
audio spectrogram. We design a cross-modal fusion mechanism to aggregate
complimentary multimodal information. Experiments on Kinetics-700 and VGGSound
show that introducing flow or audio modality brings large performance gains
over the pre-trained VLM and existing methods. Specifically, MOV greatly
improves the accuracy on base classes, while generalizes better on novel
classes. MOV achieves state-of-the-art results on UCF and HMDB zero-shot video
classification benchmarks, significantly outperforming both traditional
zero-shot methods and recent methods based on VLMs. Code and models will be
released.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:59:11 GMT""}]","2022-07-18"
"2207.07647","Bibek Pokharel","Bibek Pokharel, Daniel A. Lidar","Demonstration of algorithmic quantum speedup","12 pages, 6 main figures + 5 supplementary figures, 1 table",,"10.1103/PhysRevLett.130.210602",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Quantum algorithms theoretically outperform classical algorithms in solving
problems of increasing size, but computational errors must be kept to a minimum
to realize this potential. Despite the development of increasingly capable
quantum computers (QCs), an experimental demonstration of a provable
algorithmic quantum speedup employing today's non-fault-tolerant, noisy
intermediate-scale quantum (NISQ) devices has remained elusive. Here, we
unequivocally demonstrate such a speedup, quantified in terms of the scaling
with the problem size of the time-to-solution metric. We implement the
single-shot Bernstein-Vazirani algorithm, which solves the problem of
identifying a hidden bitstring that changes after every oracle query, utilizing
two different 27-qubit IBM Quantum (IBMQ) superconducting processors. The
speedup is observed on only one of the two QCs (ibmq_montreal) when the quantum
computation is protected by dynamical decoupling (DD) -- a carefully designed
sequence of pulses applied to the QC that suppresses its interaction with the
environment, but not without DD. In contrast to recent quantum supremacy
demonstrations, the quantum speedup reported here does not rely on any
additional assumptions or complexity-theoretic conjectures and solves a bona
fide computational problem, in the setting of a game with an oracle and a
verifier.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:59:47 GMT""}]","2023-06-07"
"2207.07648","Carlos  Meriles Prof","Richard Monge, Tom Delord, Nicholas Proscia, Zav Shotan, Harishankar
  Jayakumar, Jacob Henshaw, Pablo R. Zangara, Artur Lozovoi, Daniela Pagliero,
  Pablo D. Esquinazi, Toshu An, Inti Sodemann, Vinod M. Menon, Carlos A.
  Meriles","Spin dynamics of a solid-state qubit in proximity to a superconductor",,,"10.1021/acs.nanolett.2c03250",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  A broad effort is underway to understand and harness the interaction between
superconductors and spin-active color centers with an eye on the realization of
hybrid quantum devices and novel imaging modalities of superconducting
materials. Most work, however, overlooks the complex interplay between either
system and the environment created by the color center host. Here we use an
all-diamond scanning probe to investigate the spin dynamics of a single
nitrogen-vacancy (NV) center proximal to a high-critical-temperature
superconducting film in the presence of a weak magnetic field. We find that the
presence of the superconductor increases the NV spin coherence lifetime, a
phenomenon we tentatively rationalize as a change in the electric noise due to
a superconductor-induced redistribution of charge carriers near the NV site. We
build on these findings to demonstrate transverse-relaxation-time-weighted
imaging of the superconductor film. These results shed light on the complex
surface dynamics governing the spin coherence of shallow NVs while
simultaneously paving the route to new forms of noise spectroscopy and imaging
of superconductors.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:59:58 GMT""}]","2023-02-08"
"2207.07654","Mikhail Tsitsvero","Mikhail Tsitsvero","Learning inducing points and uncertainty on molecular data","8 pages, 5 figures",,,,"physics.chem-ph cs.LG physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  Uncertainty control and scalability to large datasets are the two main issues
for the deployment of Gaussian process models into the autonomous material and
chemical space exploration pipelines. One way to address both of these issues
is by introducing the latent inducing variables and choosing the right
approximation for the marginal log-likelihood objective. Here, we show that
variational learning of the inducing points in the high-dimensional molecular
descriptor space significantly improves both the prediction quality and
uncertainty estimates on test configurations from a sample molecular dynamics
dataset. Additionally, we show that inducing points can learn to represent the
configurations of the molecules of different types that were not present within
the initialization set of inducing points. Among several evaluated approximate
marginal log-likelihood objectives, we show that the predictive log-likelihood
provides both the predictive quality comparable to the exact Gaussian process
model and excellent uncertainty control. Finally, we comment on whether a
machine learning model makes predictions by interpolating the molecular
configurations in high-dimensional descriptor space. We show that despite our
intuition, and even for densely sampled molecular dynamics datasets, most of
the predictions are done in the extrapolation regime.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 10:41:41 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jul 2022 11:11:17 GMT""}]","2022-07-20"
"2207.07656","Aman Madaan","Aman Madaan, Yiming Yang","FLOWGEN: Fast and slow graph generation","Accepted at Dynamic Neural Networks Workshop (DyNN), ICML 2022",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Machine learning systems typically apply the same model to both easy and
tough cases. This is in stark contrast with humans, who tend to evoke either
fast (instinctive) or slow (analytical) thinking depending on the problem
difficulty, a property called the dual-process theory of mind. We present
FLOWGEN, a graph-generation model inspired by the dual-process theory of mind
that generates large graphs incrementally. Depending on the difficulty of
completing the graph at the current step, graph generation is routed to either
a fast (weaker) or a slow (stronger) model. These modules have identical
architectures, but vary in the number of parameters and consequently differ in
generative power. Experiments on real-world graphs show that ours can
successfully generate graphs similar to those generated by a single large
model, while being up to 2x faster.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:32:23 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jul 2022 03:29:36 GMT""},{""version"":""v3"",""created"":""Tue, 6 Sep 2022 02:37:42 GMT""},{""version"":""v4"",""created"":""Tue, 27 Sep 2022 21:04:04 GMT""},{""version"":""v5"",""created"":""Thu, 29 Sep 2022 18:11:25 GMT""}]","2022-10-03"
"2207.07657","Thomas Holoien","Thomas W.-S. Holoien, Vera L. Berger, Jason T. Hinkle, L. Galbany,
  Allison L. Strom, Patrick J. Vallely, Joseph P. Anderson, Konstantina
  Boutsia, K. D. French, Christopher S. Kochanek, Hanindyo Kuncarayakti, Joseph
  D. Lyman, Nidia Morrell, Jose L. Prieto, Sebasti\'an F. S\'anchez, K. Z.
  Stanek, Gregory L. Walth","Examining the Properties of Low-Luminosity Hosts of Type Ia Supernovae
  from ASAS-SN","13 pages, 7 figures, 2 tables. Submitted to ApJ. Full versions of the
  tables in the paper are available in machine-readable format as ancillary
  files",,,,"astro-ph.GA astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a spectroscopic analysis of 44 low-luminosity host galaxies of
Type Ia supernovae (SNe Ia) detected by the All-Sky Automated Survey for
Supernovae (ASAS-SN), using the emission lines to measure metallicities and
star formation rates. We find that although the star formation activity of our
sample is representative of general galaxies, there is some evidence that the
lowest-mass SN Ia host galaxies (log($M_\star/M_\odot$)$<8$) in our sample have
high metallicities compared to general galaxies of similar masses. We also
identify a subset of 5 galaxies with particularly high metallicities. This
highlights the need for spectroscopic analysis of more low-luminosity, low-mass
SN Ia host galaxies to test the robustness of these conclusions and their
potential impact on our understanding of SN Ia progenitors.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:00:00 GMT""}]","2022-07-19"
"2207.07658","Amelia Michele","Amelia Henkel, Francois Foucart, Geert Raaijmakers, Samaya Nissanke","A study of the agreement between binary neutron star ejecta models
  derived from numerical relativity simulations","12 pages, 5 figures",,"10.1103/PhysRevD.107.063028",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Neutron star mergers have recently become a tool to study extreme gravity,
nucleosynthesis, and the chemical composition of the Universe. To date, there
has been one joint gravitational and electromagnetic observation of a binary
neutron star merger, GW170817, as well as a solely gravitational observation,
GW190425. In order to accurately identify and interpret electromagnetic signals
of neutron star mergers, better models of the matter outflows generated by
these mergers are required. We compare a series of ejecta models to see where
they provide strong constraints on the amount of ejected mass expected from a
system, and where systematic uncertainties in current models prevent us from
reliably extracting information from observed events. We also examine 2396
neutron star equations of state compatible with GW170817 to see whether a given
ejecta mass could be reasonably produced with a neutron star of said equation
of state, and whether different ejecta models provide consistent predictions.
We find that the difference between models is often comparable to or larger
than the error generally assumed for these models, implying better constraints
on the models are needed. We also note that the extrapolation of outflow models
outside of their calibration window, while commonly needed to analyze
gravitational wave events, is extremely unreliable and occasionally leads to
completely unphysical results.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:00:00 GMT""}]","2023-04-05"
"2207.07659","Nicholas Kruczek","Nicholas Kruczek, Drew M. Miles, Brian Fleming, Randall McEntaffer,
  Kevin France, Fabien Gris\'e, Stephan McCandliss","High Efficiency Echelle Gratings for the Far Ultraviolet","21 pages, 13 figures, Accepted into Applied Optics",,"10.1364/AO.461537",,"astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  Modern grating manufacturing techniques suffer from inherent issues that
limit their peak efficiencies. The anisotropic etching of silicon facilitates
the creation of custom gratings that have sharp and atomically smooth facets,
directly addressing these issues. We describe work to fabricate and
characterize etched silicon echelles optimized for the far ultraviolet (FUV; 90
- 180 nm) bandpass. We fabricate two echelles that have similar parameters to
the mechanically ruled grating flown on the CHESS sounding rocket. We
demonstrate a 42% increase in peak order efficiency and an 83% decrease in
interorder scatter using these gratings. We also present analysis on where the
remaining efficiency resides. These demonstrated FUV echelle improvements
benefit the faint source sensitivity and high-resolution performance of future
UV observatories.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:00:00 GMT""}]","2022-08-10"
"2207.07660","Selim Hotinli","Selim C. Hotinli and Simone Ferraro and Gilbert P. Holder and Matthew
  C. Johnson and Marc Kamionkowski and Paul La Plante","Probing helium reionization with kinetic Sunyaev Zel'dovich tomography","4+2 pages, 2 figures, comments welcome",,"10.1103/PhysRevD.107.103517",,"astro-ph.CO astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Reionization of helium is expected to occur at redshifts $z\sim3$ and have
important consequences for quasar populations, galaxy formation, and the
morphology of the intergalactic medium, but there is little known empirically
about the process. Here we show that kinetic Sunyaev-Zeldovich (kSZ)
tomography, based on the combination of CMB measurements and galaxy surveys,
can be used to infer the primordial helium abundance as well as the time and
duration of helium reionization. We find a high-significance detection at
${\sim10\sigma}$ can be expected from Vera Rubin Observatory and CMB-S4 in the
near future. A more robust characterization of helium reionization will require
next-generation experiments like MegaMapper (a proposed successor to DESI) and
CMB-HD.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:00:00 GMT""}]","2023-05-16"
"2207.07661","SangEun Han","SangEun Han, Daniel J. Schultz, Yong Baek Kim","Microscopic theory of multi-stage Fermi surface reconstruction in
  higher-rank moment quantum materials","11+16 pages, 3+12 figures, 2+7 tables; the first two authors
  contributed equally to this work",,,,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Classification and understanding of quantum phase transitions and critical
phenomena in itinerant electron systems are outstanding questions in quantum
materials research. Recent experiments on heavy fermion systems with
higher-rank multipolar local moments provide a new platform to study such
questions. In particular, experiments on
$\text{Ce}_{3}\text{Pd}_{20}\text{(Si,Ge)}_{6}$ show novel quantum critical
behaviors via two consecutive magnetic field-driven quantum phase transitions.
At each transition, the derivative of the Hall conductivity jumps
discontinuously, which was attributed to sequential Fermi surface
reconstructions. Motivated by this discovery, we consider a microscopic model
of itinerant electrons coupled to local dipolar, quadrupolar, and octupolar
moments arising from $\text{Ce}^{3+}$ ions. Using renormalization group
analyses, we demonstrate that numerous transitions can occur depending on which
multipolar moments participate in the Fermi surface and which other moments are
decoupled via Kondo destruction, and identify order parameters consistent with
experiments. Our work offers a new theoretical framework for understanding
multipolar quantum materials.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:00:01 GMT""},{""version"":""v2"",""created"":""Wed, 15 Feb 2023 19:02:18 GMT""}]","2023-02-17"
"2207.07662","Jamie McDonald","Francesca Chadha-Day, Bj\""orn Garbrecht, Jamie McDonald","Superradiance in Stars: Non-equilibrium approach to damping of fields in
  stellar media","Four figures, 20 pages, comments welcome",,"10.1088/1475-7516/2022/12/008",,"hep-ph astro-ph.SR gr-qc","http://creativecommons.org/licenses/by/4.0/","  Superradiance in black holes is well-understood but a general treatment for
superradiance in stars has until now been lacking. This is surprising given the
ease with which we can observe isolated neutron stars and the array of
signatures which would result from stellar superradiance. In this work, we
present the first systematic pipeline for computing superradiance rates in
rotating stars. Our method can be used with any Lagrangian describing the
interaction between the superradiant field and the constituents of the star.
Our scheme falls into two parts: firstly we show how field theory at finite
density can be used to express the absorption of long wavelength modes into the
star in terms of microphsyical scattering processes. This allows us to derive a
damped equation of motion for the bosonic field. We then feed this into an
effective theory for long wavelengths (the so-called worldline formalism) to
describe the amplification of superradiant modes of arbitrary multipole moment
for a rapidly rotating star. Our method places stellar superradiance on a firm
theoretical footing and allows the calculation of the superradiance rate
arising from any interaction between a bosonic field and stellar matter.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:00:01 GMT""}]","2022-12-14"
"2207.07663","Mattia Trama","Mattia Trama, Vittorio Cataudella, Carmine Antonio Perroni, Francesco
  Romeo, Roberta Citro","Tunable spin and orbital Edelstein effect at (111) LaAlO$_3$/SrTiO$_3$
  interface","12 pages, 7 figures","Nanomaterials 2022, 12(14), 2494","10.3390/nano12142494",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Converting charge current into spin current is one of the main mechanisms
exploited in spintronics. One prominent example is the Edelstein effect, namely
the generation of a magnetization in response to an external electric field,
which can be realized in systems with lack of inversion symmetry. If a system
has electrons with an orbital angular momentum character, an orbital
magnetization can be generated by the applied electric field giving rise to the
so-called orbital Edelstein effect. Oxide heterostructures are the ideal
platform for these effects due to the strong spin-orbit coupling and the lack
of inversion symmetries. Beyond a gate-tunable spin Edelstein effect, we
predict an orbital Edelstein effect an order of magnitude larger then the spin
one at the (111) LaAlO$_3$/SrTiO$_3$ interface. We model the material as a
bilayer of $t_{2g}$ orbitals using a tight-binding approach, while transport
properties are obtained in the Boltzmann approach. We give an effective model
at low filling which explains the non-trivial behaviour of the Edelstein
response, showing that the hybridization between the electronic bands crucially
impacts the Edelstein susceptibility.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:00:01 GMT""}]","2022-07-21"
"2207.07664","Li Gan","Li Gan, St\'ephane Ouvry, Alexios P. Polychronakos","Combinatorics of generalized Dyck and Motzkin paths","27 pages, 11 figures","Phys. Rev. E 106, 044123 (2022)","10.1103/PhysRevE.106.044123",,"math-ph cond-mat.stat-mech hep-th math.CO math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We relate the combinatorics of periodic generalized Dyck and Motzkin paths to
the cluster coefficients of particles obeying generalized exclusion statistics,
and obtain explicit expressions for the counting of paths with a fixed number
of steps of each kind at each vertical coordinate. A class of generalized
compositions of the integer path length emerges in the analysis.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:00:02 GMT""}]","2022-10-17"
"2207.07665","Daniel Miller","Daniel Miller, Daniel Loss, Ivano Tavernelli, Hermann Kampermann,
  Dagmar Bru{\ss}, Nikolai Wyderka","Sector length distributions of graph states","20+21 pages, 8+8 figures",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The sector length distribution (SLD) of a quantum state is a collection of
local unitary invariants that quantify $k$-body correlations. We show that the
SLD of graph states can be derived by solving a graph-theoretical problem. In
this way, the mean and variance of the SLD are obtained as simple functions of
efficiently computable graph properties. Furthermore, this formulation enables
us to derive closed expressions of SLDs for some graph state families. For
cluster states, we observe that the SLD is very similar to a binomial
distribution, and we argue that this property is typical for graph states in
general. Finally, we derive an SLD-based entanglement criterion from the
majorization criterion and apply it to derive meaningful noise thresholds for
entanglement.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:00:02 GMT""}]","2022-07-19"
"2207.07666","David Roland Miran Arvidsson-Shukur","David R. M. Arvidsson-Shukur, Aidan G. McConnell, Nicole Yunger
  Halpern","Quantum simulations of time travel can power nonclassical metrology","5+1 pages. 2 figures. Comments are welcomed!",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Gambling agencies forbid late bets, placed after the winning horse crosses
the finish line. A time-traveling gambler could cheat the system. We construct
a gamble that one can win by simulating time travel with experimentally
feasible entanglement manipulation. Our gamble echoes a common metrology
protocol: A gambler must prepare probes to input into a metrology experiment.
The goal is to infer as much information per probe as possible about a
parameter's value. If the input is optimal, the information gained per probe
can exceed any value achievable classically. The gambler chooses the input
state analogously to choosing a horse. However, only after the probes are
measured does the gambler learn which input would have been optimal. The
gambler can ""place a late bet"" by effectively teleporting the optimal input
back in time, via entanglement manipulation. Our Gedankenexperiment
demonstrates that not only true time travel, but even a simulation offers a
quantum advantage in metrology.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:00:02 GMT""}]","2022-07-19"
"2207.07667","Surajit Kalita","Surajit Kalita (UCT) and Banibrata Mukhopadhyay (IISc)","Massive Neutron Stars and White Dwarfs as Noncommutative Fuzzy Spheres","13 pages with 5 figures; invited article in a special issue ""Quantum
  Gravity Phenomenology"" under section ""Foundations of Quantum Mechanics and
  Quantum Gravity"" in Universe; accepted for publication","Universe 8 (2022) 388","10.3390/universe8080388",,"gr-qc astro-ph.HE astro-ph.SR hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Over the last couple of decades, there are direct and indirect evidences for
massive compact objects than their conventional counterparts. A couple of such
examples are super-Chandrasekhar white dwarfs and massive neutron stars. The
observations of more than a dozen peculiar over-luminous type Ia supernovae
predict their origins from super-Chandrasekhar white dwarf progenitors. On the
other hand, recent gravitational wave detection and some pulsar observations
argue for massive neutron stars, lying in the famous mass-gap between lowest
astrophysical black hole and conventional highest neutron star masses. We show
that the idea of a squashed fuzzy sphere, which brings in noncommutative
geometry, can self-consistently explain either of the massive objects as if
they are actually fuzzy or squashed fuzzy spheres. Noncommutative geometry is a
branch of quantum gravity. If the above proposal is correct, it will provide
observational evidences for noncommutativity.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:00:02 GMT""}]","2022-08-15"
"2207.07668","Chen Yuan","De-Shuang Meng, Chen Yuan, Qing-guo Huang","One-loop correction to the enhanced curvature perturbation with
  local-type non-Gaussianity for the formation of primordial black holes","6 pages, 5 figures",,"10.1103/PhysRevD.106.063508",,"astro-ph.CO gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As one of the promising candidates of cold dark matter (DM), primordial black
holes (PBHs) were formed due to the collapse of over-densed regions generated
by the enhanced curvature perturbations during the radiation-dominated era. The
enhanced curvature perturbations are expected to be non-Gaussian in some
relevant inflation models and hence the higher-order loop corrections to the
curvature power spectrum might be non-negligible as well as altering the
abundance of PBHs. In this paper, we calculate the one-loop correction to the
curvature power spectrum with local-type non-Gaussianities characterizing by
$F_{\mathrm{NL}}$ and $G_{\mathrm{NL}}$ standing for the quadratic and cubic
non-Gaussian parameters, respectively. Requiring that the one-loop correction
be subdominant, we find a perturbativity condition, namely
$|2cAF_{\mathrm{NL}}^2+6AG_{\mathrm{NL}}|\ll 1$, where $c$ is a constant
coefficient which can be explicitly calculated in the given model and $A$
denotes the variance of Gaussian part of enhanced curvature perturbation, and
such a perturbativity condition can provide a stringent constraint on the
relevant inflation models for the formation of PBHs.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:00:03 GMT""}]","2022-09-21"
"2207.07669","Joachim Brod","Joachim Brod, Sandra Kvedaraite, Zachary Polonsky, Ahmed Youssef","Electroweak Corrections to the Charm-Top-Quark Contribution to
  $\epsilon_K$","12 pages, 2 figures","JHEP 12 (2022) 014","10.1007/JHEP12(2022)014",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We calculate the leading-logarithmic and next-to-leading-logarithmic
electroweak corrections to the charm-top-quark contribution to the effective
$|\Delta S| = 2$ Lagrangian, relevant for the parameter $\epsilon_K$. We find
that these corrections lead to a $-0.5\%$ shift in the corresponding Wilson
coefficient. Moreover, our calculation removes an implicit ambiguity in the
standard-model prediction of $\epsilon_K$, by fixing the renormalization scheme
of the electroweak input parameters.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:00:03 GMT""}]","2022-12-12"
"2207.07670","David Berardo","David Berardo, Julien DeWit","On the Effects of Planetary Oblateness on Exoplanet Studies","18 pages, 11 figures, Accepted for publication in the Astrophysical
  Journal",,"10.3847/1538-4357/ac82b2",,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  When studying transiting exoplanets it is common to assume a spherical planet
shape. However short rotational periods can cause a planet to bulge at its
equator, as is the case with Saturn whose equatorial radius is almost 10%
larger than its polar radius. As a new generation of instruments comes online,
it is important to continually assess the underlying assumptions of models to
ensure robust and accurate inferences. We analyze bulk samples of known
transiting planets and calculate their expected signal strength if they were to
be oblate. We find that for noise levels below 100ppm, as many as 100 planets
could have detectable oblateness. We also investigate the effects of fitting
spherical planet models to synthetic oblate lightcurves. We find that this
biases the retrieved parameters by several standard deviations for oblateness
values > 0.1-0.2. When attempting to fit an oblateness model to both spherical
and oblate lightcurves, we find that the sensitivity of such fits is correlated
with both the SNR as well as the time sampling of the data, which can mask the
oblateness signal. For typical values of these quantities for Kepler
observations, it is difficult to rule out oblateness values less than ~0.25.
This results in an accuracy wall of 10-15% for the density of planets which may
be oblate. Finally, we find that a precessing oblate planet has the ability to
mimic the signature of a long-period companion via transit timing variations,
inducing offsets at the level of 10s of seconds.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:00:03 GMT""}]","2022-08-31"
"2207.07671","Sophia K Domokos","Sophia K. Domokos and Andrew B. Royston","Supersymmetry of the D3/D5 Defect Field Theory","32 pages, 1 figure, 1 table. In v3: additional section added
  describing preliminary application of results to BPS solitons; references
  added",,"10.1007/JHEP12(2022)040",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Four-dimensional N=4 super Yang-Mills, with a codimension-one defect breaking
half of the supersymmetry, arises as the field theory description of the D3/D5
intersection in the holographic limit. This is one of the earliest, most
extensively studied, and commonly used systems in holography. In this note we
give the full R-symmetry-covariant supersymmetry variations for this system. We
also provide the supercurrents and compute the algebra of the corresponding
supercharges, obtaining the full set of central charges. We show that
magnetically charged finite-energy field configurations preserving half of the
supersymmetry are solutions to a new form of the extended Bogomolny equations,
in which the defect fields play the role of jumping data for the Nahm-like part
of the equations. In the appendices, we explain the connection between our
results and the superspace-based formulations in the literature.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:00:03 GMT""},{""version"":""v2"",""created"":""Mon, 1 Aug 2022 14:21:20 GMT""},{""version"":""v3"",""created"":""Fri, 28 Oct 2022 14:40:02 GMT""}]","2022-12-28"
"2207.07672","Stephane Munier","Anh Dung Le, Alfred H. Mueller, St\'ephane Munier","Probabilistic picture for particle number densities in stretched tips of
  the branching Brownian motion","7 pages, 1 figure. v2: significant improvements to the text, numerous
  clarifications made. Approach and results unchanged. Version accepted for
  publications in EPL","EPL, 140 (2022) 51003","10.1209/0295-5075/aca699",,"cond-mat.stat-mech hep-ph math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the framework of a stochastic picture for the one-dimensional branching
Brownian motion, we compute the probability density of the number of particles
near the rightmost one at a time $T$, that we take very large, when this
extreme particle is conditioned to arrive at a predefined position $x_T$ chosen
far ahead of its expected position $m_T$. We recover the previously-conjectured
fact that the typical number density of particles a distance $\Delta$ to the
left of the lead particle, when both $\Delta$ and $x_T-\Delta-m_T$ are large,
is smaller than the mean number density by a factor proportional to
$e^{-\zeta\Delta^{2/3}}$, where $\zeta$ is a constant that was so far
undetermined. Our picture leads to an expression for the probability density of
the particle number, from which a value for $\zeta$ may be inferred.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:00:05 GMT""},{""version"":""v2"",""created"":""Tue, 29 Nov 2022 06:50:00 GMT""}]","2022-12-13"
"2207.07673","Boris Leistedt","Boris Leistedt, Justin Alsing, Hiranya Peiris, Daniel Mortlock, Joel
  Leja","Hierarchical Bayesian inference of photometric redshifts with stellar
  population synthesis models","16 pages, 6 figures. Version accepted in APJS",,"10.3847/1538-4365/ac9d99",,"astro-ph.IM astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  We present a Bayesian hierarchical framework to analyze photometric galaxy
survey data with stellar population synthesis (SPS) models. Our method couples
robust modeling of spectral energy distributions with a population model and a
noise model to characterize the statistical properties of the galaxy
populations and real observations, respectively. By self-consistently inferring
all model parameters, from high-level hyper-parameters to SPS parameters of
individual galaxies, one can separate sources of bias and uncertainty in the
data.We demonstrate the strengths and flexibility of this approach by deriving
accurate photometric redshifts for a sample of spectroscopically-confirmed
galaxies in the COSMOS field, all with 26-band photometry and spectroscopic
redshifts. We achieve a performance competitive with publicly-released
photometric redshift catalogs based on the same data. Prior to this work, this
approach was computationally intractable in practice due to the heavy
computational load of SPS model calls; we overcome this challenge using with
neural emulators. We find that the largest photometric residuals are associated
with poor calibration for emission line luminosities and thus build a framework
to mitigate these effects. This combination of physics-based modeling
accelerated with machine learning paves the path towards meeting the stringent
requirements on the accuracy of photometric redshift estimation imposed by
upcoming cosmological surveys. The approach also has the potential to create
new links between cosmology and galaxy evolution through the analysis of
photometric datasets.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:00:05 GMT""},{""version"":""v2"",""created"":""Fri, 4 Nov 2022 21:56:50 GMT""}]","2023-01-18"
"2207.07674","Tomer Shenar","Tomer Shenar, Hugues Sana, Laurent Mahy, Jesus Maiz Apellaniz, Paul A.
  Crowther, Mariusz Gromadzki, Artemio Herrero, Norbert Langer, Pablo Marchant,
  Fabian R. N. Schneider, Koushik Sen, Igor Soszynski, S. Toonen","The Tarantula Massive Binary Monitoring VI: Characterisation of hidden
  companions in 51 single-lined O-type binaries, a flat mass-ratio
  distribution, and black-hole binary candidates","41 pages (14 main article + 27 appendix), accepted to A&A","A&A 665, A148 (2022)","10.1051/0004-6361/202244245",,"astro-ph.SR astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We aim to hunt for massive binaries hosting a black hole companion (OB+BH)
and establish the natal mass-ratio distribution of massive stars at the
subsolar metallicity environment of the Large Magellanic Cloud (LMC). We use
the shift-and-add grid disentangling technique to characterize the hidden
companions in 51 SB1 O-type and evolved B-type binaries in the LMC monitored in
the framework of the Tarantula Massive Binary Monitoring (TMBM).
  Out of the 51 SB1 systems, 43 (84%) are found to have non-degenerate stellar
companions, of which 28 are confident detections, and 15 are less certain (SB1:
or SB2:). Of these 43 targets, one is found to be a triple (VFTS 64), and two
are found to be quadruples (VFTS 120, 702). The remaining eight targets (16%)
retain an SB1 classification. Aside from the unambiguous case of VFTS 243,
analysed in detailed in a separate paper, we identify two additional OB+BH
candidates: VFTS 514 and VFTS 779. Additional black holes may be present in the
sample but at a lower probability. Our study firmly establishes a virtually
flat natal mass-ratio distribution for O-type stars at LMC metallicity,
covering the entire mass-ratio range (0.05 < q < 1) and periods in the range 0
< log P < 3 [d]. The nature of the OB+BH candidates should be verified through
future monitoring, but the frequency of OB+BH candidates is generally in line
with recent predictions at LMC metallicity.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:00:06 GMT""},{""version"":""v2"",""created"":""Wed, 5 Oct 2022 14:55:23 GMT""}]","2022-10-06"
"2207.07675","Tomer Shenar","Tomer Shenar, Hugues Sana, Laurent Mahy, Kareem El-Badry, Pablo
  Marchant, Norbert Langer, Calum Hawcroft, Matthias Fabry, Koushik Sen,
  Leonardo A. Almeida, Michael Abdul-Masih, Julia Bodensteiner, Paul A.
  Crowther, Mark Gieles, Mariusz Gromadzki, Vincent Henault-Brunet, Artemio
  Herrero, Alex de Koter, Patryk Iwanek, Szymon Koz{\l}owski, Daniel J. Lennon,
  Jesus Ma{\i}z Apellaniz, Przemys{\l}aw Mroz, Anthony F. J. Moffat, Annachiara
  Picco, Pawe{\l} Pietrukowicz, Rados{\l}aw Poleski, Krzysztof Rybicki, Fabian
  R. N. Schneider, Dorota M. Skowron, Jan Skowron, Igor Soszynski, Micha{\l} K.
  Szymanski, Silvia Toonen, Andrzej Udalski, Krzysztof Ulaczyk, Jorick S. Vink,
  Marcin Wrona","An X-ray quiet black hole born with a negligible kick in a massive
  binary within the Large Magellanic Cloud","Accepted to Nature Astronomy, 64 pages, 15 figures, 2 tables; ESO
  press release: https://www.eso.org/public/news/eso2210/; Nat Asr paper URL:
  https://www.nature.com/articles/s41550-022-01730-y",,"10.1038/s41550-022-01730-y",,"astro-ph.HE astro-ph.GA astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Stellar-mass black holes are the final remnants of stars born with more than
15 solar masses. Billions are expected to reside in the Local Group, yet only
few are known, mostly detected through X-rays emitted as they accrete material
from a companion star. Here, we report on VFTS 243: a massive X-ray faint
binary in the Large Magellanic Cloud. With an orbital period of 10.4-d, it
comprises an O-type star of 25 solar masses and an unseen companion of at least
nine solar masses. Our spectral analysis excludes a non-degenerate companion at
a 5-sigma confidence level. The minimum companion mass implies that it is a
black hole. No other X-ray quiet black hole is unambiguously known outside our
Galaxy. The (near-)circular orbit and kinematics of VFTS 243 imply that the
collapse of the progenitor into a black hole was associated with little or no
ejected material or black-hole kick. Identifying such unique binaries
substantially impacts the predicted rates of gravitational-wave detections and
properties of core-collapse supernovae across the Cosmos.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:00:09 GMT""}]","2022-07-19"
"2207.07676","Boris Leistedt","Edgar Eggert and Boris Leistedt","Spurious correlations between galaxies and multi-epoch image stacks in
  the DESI Legacy Surveys","18 pages, 8 figures. To be submitted to APJS",,"10.3847/1538-4365/acb440",,"astro-ph.CO astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  A non-negligible source of systematic bias in cosmological analyses of galaxy
surveys is the on-sky modulation caused by foregrounds and variable image
characteristics such as observing conditions. Standard mitigation techniques
perform a regression between the observed galaxy density field and sky maps of
the potential contaminants. Such maps are ad-hoc, lossy summaries of the
heterogeneous sets of co-added exposures that contribute to the survey. We
present a methodology to address this limitation, and extract the spurious
correlations between the observed distribution of galaxies and arbitrary stacks
of single-epoch exposures. We study four types of galaxies (LRGs, ELGs, QSOs,
LBGs) in the three regions of the DESI Legacy Surveys (North, South, DES),
which results in twelve samples with varying levels and type of contamination.
We find that the new technique outperforms the traditional ones in all cases,
and is able to remove higher levels of contamination. This paves the way for
new methods that extract more information from multi-epoch galaxy survey data
and mitigate large-scale biases more effectively.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:00:12 GMT""}]","2023-03-15"
"2207.07677","Jacek Ksawery Osi\'nski","Paola Arias, Nicol\'as Bernal, Jacek K. Osi\'nski, Leszek Roszkowski","Dark Matter Axions in the Early Universe with a Period of Increasing
  Temperature","28 pages, 8 figures; updated to match published version",,"10.1088/1475-7516/2023/05/028","PI/UAN-2022-719FT","hep-ph astro-ph.CO hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the production of axion dark matter through the misalignment
mechanism in the context of a nonstandard cosmological history involving early
matter domination by a scalar field with a time-dependent decay rate. In cases
where the temperature of the Universe experiences a temporary period of
increase, Hubble friction can be restored in the evolution of the axion field,
resulting in the possibility of up to three ""crossings"" of the axion mass and
the Hubble expansion rate. This has the effect of dynamically resetting the
misalignment mechanism to a new initial state for a second distinct phase of
oscillation. The resultant axion mass required for the present dark matter
relic density is never bigger than the standard-history window and can be
smaller by more than three orders of magnitude, which can be probed by upcoming
experiments such as ABRACADABRA, KLASH, ADMX, MADMAX, and ORGAN, targeting the
axion-photon coupling. This highlights the possibility of exploring the
cosmological history prior to Big Bang Nucleosynthesis through searches for
axion dark matter beyond the standard window.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:00:32 GMT""},{""version"":""v2"",""created"":""Wed, 5 Apr 2023 09:22:15 GMT""}]","2023-05-24"
"2207.07678","Roman Rafikov","Roman R. Rafikov","Radial Profiles of Surface Density in Debris Discs","16 pages, 13 figures, submitted to MNRAS, comments welcome",,"10.1093/mnras/stac3411",,"astro-ph.EP astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Resolved observations of debris discs can be used to derive radial profiles
of Azimuthally-averaged Surface Density (ASD), which carries important
information about the disc structure even in presence of non-axisymmetric
features and has improved signal-to-noise characteristics. We develop a
(semi-)analytical formalism allowing one to relate ASD to the underlying
semi-major axis and eccentricity distributions of the debris particles in a
straightforward manner. This approach does not involve the distribution of
particle apsidal angles, thus simplifying calculations. It is a much faster,
more flexible and effective way of calculating ASD than the Monte Carlo
sampling of orbital parameters of debris particles. We present explicit
analytical results based on this technique for a number of particle
eccentricity distributions, including two cases of particular practical
importance: a prescribed radial profile of eccentricity, and the Rayleigh
distribution of eccentricities. We then show how our framework can be applied
to observations of debris discs and rings for retrieving either the semi-major
axis distribution or (in some cases) the eccentricity distribution of debris,
thus providing direct information about the architecture and dynamical
processes operating in debris discs. Our approach also provides a fast and
efficient way of forward modeling observations. Applications of this technique
to other astrophysical systems, e.g. the nuclear stellar disc in M31 or tenuous
planetary rings, are also discussed.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:00:40 GMT""}]","2022-12-07"
"2207.07679","Andrey Sadofyev","Andrey V. Sadofyev, Matthew D. Sievert, Ivan Vitev","Jets in evolving matter within the opacity expansion approach","6 pages, 1 figure, DIS2021 proceedings","SciPost Phys. Proc. 8, 046 (2022)","10.21468/SciPostPhysProc.8.046",,"hep-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a recent study [1] we have extended the opacity expansion approach to
describe jet-medium interactions including medium motion effects in the context
of heavy-ion collisions. We have computed color field of the in-medium sources,
including the effects of the transverse field components and the energy
transfer between the medium and jet. The corresponding contributions are
sub-eikonal in nature, and were previously ignored in the literature. Here we
discuss how our approach can be applied to describe the medium motion effects
in the context of Deep Inelastic Scattering.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:02:20 GMT""}]","2022-07-19"
"2207.07680","Takashi Nishikawa","Chao Duan, Takashi Nishikawa, Deniz Eroglu, Adilson E. Motter","Network structural origin of instabilities in large complex systems","Includes Supplementary Materials","Science Advances 8, eabm8310 (2022)","10.1126/sciadv.abm8310",,"nlin.AO cond-mat.dis-nn cs.SY eess.SY math.DS q-bio.MN","http://creativecommons.org/licenses/by-nc-nd/4.0/","  A central issue in the study of large complex network systems, such as power
grids, financial networks, and ecological systems, is to understand their
response to dynamical perturbations. Recent studies recognize that many real
networks show nonnormality and that nonnormality can give rise to
reactivity--the capacity of a linearly stable system to amplify its response to
perturbations, oftentimes exciting nonlinear instabilities. Here, we identify
network structural properties underlying the pervasiveness of nonnormality and
reactivity in real directed networks, which we establish using the most
extensive data set of such networks studied in this context to date. The
identified properties are imbalances between incoming and outgoing network
links and paths at each node. Based on this characterization, we develop a
theory that quantitatively predicts nonnormality and reactivity and explains
the observed pervasiveness. We suggest that these results can be used to
design, upgrade, control, and manage networks to avoid or promote network
instabilities.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:02:26 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jul 2022 16:03:42 GMT""}]","2022-07-26"
"2207.07681","Jamison Burke","J. Burke, D. A. Howell, D. J. Sand, R. C. Amaro, P. J. Brown, J. E.
  Andrews, K. A. Bostroem, Y. Dong, J. Haislip, D. Hiramatsu, G. Hosseinzadeh,
  V. Kouprianov, M. J. Lundquist, C. McCully, C. Pellegrino, D. Reichart, L.
  Tartaglia, S. Valenti, and S. Yang","Early Lightcurves of Type Ia Supernovae are Consistent with
  Nondegenerate Progenitor Companions","28 pages, 10 figures",,,,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  If Type Ia supernovae (SNe~Ia) result from a white dwarf being ignited by
Roche lobe overflow from a nondegenerate companion, then as the supernova
explosion runs into the companion star its ejecta will be shocked, causing an
early blue excess in the lightcurve. A handful of these excesses have been
found in single-object studies, but inferences about the population of SNe~Ia
as a whole have been limited because of the rarity of multiwavelength followup
within days of explosion. Here we present a three-year investigation yielding
an unbiased sample of nine nearby ($z<0.01$) SNe~Ia with exemplary early data.
The data are truly multiwavelength, covering $UBVgri$ and Swift bandpasses, and
also early, with an average first epoch 16.0 days before maximum light. Of the
nine objects, three show early blue excesses. We do not find enough statistical
evidence to reject the null hypothesis that SNe~Ia predominantly arise from
Roche-lobe-overflowing single-degenerate systems ($p=0.94$). When looking at
the objects' colors, we find the objects are almost uniformly near-UV-blue, in
contrast to earlier literature samples which found that only a third of SNe~Ia
are near-UV-blue, and we find a seemingly continuous range of $B-V$ colors in
the days after explosion, again in contrast with earlier claims in the
literature. This study highlights the importance of early, truly
multiwavelength, high-cadence data in determining the progenitor systems of
SNe~Ia and in revealing their diverse early behavior.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:02:30 GMT""}]","2022-07-19"
"2207.07682","Thomas Fai","Lachlan Elam, M\'onica Qui\~nones Fr\'ias, Ying Zhang, Avital A.
  Rodal, and Thomas G. Fai","Fast solver for diffusive transport times on dynamic intracellular
  networks","14 pages, 6 figures",,,,"physics.bio-ph cond-mat.soft q-bio.QM q-bio.SC","http://creativecommons.org/licenses/by/4.0/","  The transport of particles in cells is influenced by the properties of
intracellular networks they traverse while searching for localized target
regions or reaction partners. Moreover, given the rapid turnover in many
intracellular structures, it is crucial to understand how temporal changes in
the network structure affect diffusive transport. In this work, we use network
theory to characterize complex intracellular biological environments across
scales. We develop an efficient computational method to compute the mean first
passage times for simulating a particle diffusing along two-dimensional planar
networks extracted from fluorescence microscopy imaging. We first benchmark
this methodology in the context of synthetic networks, and subsequently apply
it to live-cell data from endoplasmic reticulum tubular networks.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:03:17 GMT""}]","2022-07-19"
"2207.07683","Colin Geniet","Colin Geniet and St\'ephan Thomass\'e","First Order Logic and Twin-Width in Tournaments and Dense Oriented
  Graphs","28 pages, 5 figures",,,,"cs.LO cs.DM math.CO","http://creativecommons.org/licenses/by/4.0/","  We characterise the classes of tournaments with tractable first-order model
checking. For every hereditary class of tournaments $\mathcal T$, first-order
model checking either is fixed parameter tractable, or is AW$[*]$-hard. This
dichotomy coincides with the fact that $\mathcal T$ has either bounded or
unbounded twin-width, and that the growth of $\mathcal T$ is either at most
exponential or at least factorial. From the model-theoretic point of view, we
show that NIP classes of tournaments coincide with bounded twin-width.
Twin-width is also characterised by three infinite families of obstructions:
$\mathcal T$ has bounded twin-width if and only if it excludes one tournament
from each family. This generalises results of Bonnet et al. on ordered graphs.
  The key for these results is a polynomial time algorithm which takes as input
a tournament $T$ and compute a linear order $<$ on $V(T)$ such that the
twin-width of the birelation $(T,<)$ is at most some function of the twin-width
of $T$. Since approximating twin-width can be done in polynomial time for an
ordered structure $(T,<)$, this provides a polytime approximation of twin-width
for tournaments.
  Our results extend to oriented graphs with stable sets of bounded size, which
may also be augmented by arbitrary binary relations.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:03:21 GMT""},{""version"":""v2"",""created"":""Fri, 2 Sep 2022 15:02:23 GMT""}]","2022-09-05"
"2207.07684","Yiwei Hu","Yiwei Hu, Paul Guerrero, Milo\v{s} Ha\v{s}an, Holly Rushmeier,
  Valentin Deschaintre","Node Graph Optimization Using Differentiable Proxies",,"SIGGRAPH '22 Conference Proceedings, Vancouver, BC, Canada, 2022","10.1145/3528233.3530733",,"cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph-based procedural materials are ubiquitous in content production
industries. Procedural models allow the creation of photorealistic materials
with parametric control for flexible editing of appearance. However, designing
a specific material is a time-consuming process in terms of building a model
and fine-tuning parameters. Previous work [Hu et al. 2022; Shi et al. 2020]
introduced material graph optimization frameworks for matching target material
samples. However, these previous methods were limited to optimizing
differentiable functions in the graphs. In this paper, we propose a fully
differentiable framework which enables end-to-end gradient based optimization
of material graphs, even if some functions of the graph are non-differentiable.
We leverage the Differentiable Proxy, a differentiable approximator of a
non-differentiable black-box function. We use our framework to match structure
and appearance of an output material to a target material, through a
multi-stage differentiable optimization. Differentiable Proxies offer a more
general optimization solution to material appearance matching than previous
work.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:05:46 GMT""}]","2022-07-19"
"2207.07685","Badih Assaf","Jiashu Wang, Tianyi Wang, Mykhaylo Ozerov, Zhan Zhang, Seul-Ki Bac,
  Hoai Trinh, Maksym Zhukovskyi, Tatyana Orlova, Haile Ambaye, Jong Keum,
  Dmitry Smirnov, Valeria Lauter, Xinyu Liu, Badih A. Assaf","Magnetic proximity-induced energy gap of topological surface states",,,,,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Topological crystalline insulator surface states can acquire an energy gap
when time reversal symmetry is broken by interfacing with a magnetic insulator.
Such hybrid topological-magnetic insulator structures can be used to generate
novel anomalous Hall effects and to control the magnetic state of the insulator
in a spintronic device. In this work, the energy gap of topological surface
states in proximity with a magnetic insulator is measured using Landau level
spectroscopy. The measurements are carried out on Pb1-xSnxSe/EuSe
heterostructures grown by molecular beam epitaxy exhibiting record mobility and
a low Fermi energy enabling this measurement. We find an energy gap that does
not exceed 20meV and we show that is due to the combined effect of quantum
confinement and magnetic proximity. The presence of magnetism at the interface
is confirmed by magnetometry and neutron reflectivity. The recovered energy gap
sets an upper limit for the Fermi level needed to observe the quantized
anomalous Hall effect using magnetic proximity heterostructures.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:06:40 GMT""}]","2022-07-19"
"2207.07686","Younes Nikdelan","Gabriele Bogo, Younes Nikdelan","Ramanujan systems of Rankin-Cohen type and hyperbolic triangles","23 pages",,,"MPIM-Bonn-2022","math.NT math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the first part of the paper we characterize systems of first order
nonlinear differential equations whose space of solutions is an
$\mathfrak{sl}_2(\mathbb{C})$-module. We prove that such systems, called
Ramanujan systems of Rankin-Cohen type, have a special shape and are precisely
the ones whose solution space admits a Rankin-Cohen structure. In the second
part of the paper we consider triangle groups $\Delta(n,m,\infty)$. By means of
modular embeddings, we associate to every such group a number of systems of non
linear ODEs whose solutions are algebraically independent twisted modular
forms. In particular, all rational weight modular forms on $\Delta(n,m,\infty)$
are generated by the solutions of one such system (which is of Rankin-Cohen
type). As a corollary we find new relations for the Gauss hypergeometric
function evaluated at functions on the upper half-plane. To demonstrate the
power of our approach in the non classical setting, we construct the space of
integral weight twisted modular form on $\Delta(2,5,\infty)$ from solutions of
systems of nonlinear ODEs.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:09:43 GMT""}]","2022-07-19"
"2207.07687","Sohail Sohail","Sahil, Sohail and Sibasish Ghosh","Uncertainty Relations in Pre- and Post-Selected Systems","17 pages, 2 figures, new results added, presentation modified",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we derive Robertson-Heisenberg like uncertainty relation for
two incompatible observables in a pre- and post-selected (PPS) system. The
newly defined standard deviation and the uncertainty relation in the PPS system
have physical meanings which we present here. We demonstrate two unusual
properties in the PPS system using our uncertainty relation. First, for
commuting observables, the lower bound of the uncertainty relation in the PPS
system does not become zero even if the initially prepared state i.e.,
pre-selection is the eigenstate of both the observables when specific
post-selections are considered. This implies that for such case, two commuting
observables can disturb each other's measurement results which is in fully
contrast with the Robertson-Heisenberg uncertainty relation. Secondly, unlike
the standard quantum system, the PPS system makes it feasible to prepare
sharply a quantum state (pre-selection) for non-commuting observables. Some
applications of uncertainty and uncertainty relation in the PPS system are
provided: $(i)$ detection of mixedness of an unknown state, $(ii)$ stronger
uncertainty relation in the standard quantum system, ($iii$) ``purely quantum
uncertainty relation"" that is, the uncertainty relation which is not affected
(i.e., neither increasing nor decreasing) under the classical mixing of quantum
states, $(iv)$ state dependent tighter uncertainty relation in the standard
quantum system, and $(v)$ tighter upper bound for the out-of-time-order
correlation function.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:15:28 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jul 2022 05:49:35 GMT""},{""version"":""v3"",""created"":""Mon, 22 May 2023 18:47:56 GMT""}]","2023-05-24"
"2207.07688","Sam Kumar","Christopher Branner-Augmon, Narek Galstyan, Sam Kumar, Emmanuel Amaro,
  Amy Ousterhout, Aurojit Panda, Sylvia Ratnasamy, Scott Shenker","3PO: Programmed Far-Memory Prefetching for Oblivious Applications","14 pages",,,,"cs.OS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using memory located on remote machines, or far memory, as a swap space is a
promising approach to meet the increasing memory demands of modern datacenter
applications. Operating systems have long relied on prefetchers to mask the
increased latency of fetching pages from swap space to main memory.
Unfortunately, with traditional prefetching heuristics, performance still
degrades when applications use far memory. In this paper we propose a new
prefetching technique for far-memory applications. We focus our efforts on
memory-intensive, oblivious applications whose memory access patterns are
independent of their inputs, such as matrix multiplication. For this class of
applications we observe that we can perfectly prefetch pages without relying on
heuristics. However, prefetching perfectly without requiring significant
application modifications is challenging.
  In this paper we describe the design and implementation of 3PO, a system that
provides pre-planned prefetching for general oblivious applications. We
demonstrate that 3PO can accelerate applications, e.g., running them 30-150%
faster than with Linux's prefetcher with 20% local memory. We also use 3PO to
understand the fundamental software overheads of prefetching in a paging-based
system, and the minimum performance penalty that they impose when we run
applications under constrained local memory.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:17:48 GMT""}]","2022-07-19"
"2207.07689","Alexandr Sboev","Alexander G. Sboev, Nikolay A. Kudryshov, Ivan A. Moloshnikov, Saveliy
  V. Zavertyaev, Aleksandr V. Naumov and Roman B. Rybka","Strict baselines for Covid-19 forecasting and ML perspective for USA and
  Russia",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Currently, the evolution of Covid-19 allows researchers to gather the
datasets accumulated over 2 years and to use them in predictive analysis. In
turn, this makes it possible to assess the efficiency potential of more complex
predictive models, including neural networks with different forecast horizons.
In this paper, we present the results of a consistent comparative study of
different types of methods for predicting the dynamics of the spread of
Covid-19 based on regional data for two countries: the United States and
Russia. We used well-known statistical methods (e.g., Exponential Smoothing), a
""tomorrow-as-today"" approach, as well as a set of classic machine learning
models trained on data from individual regions. Along with them, a neural
network model based on Long short-term memory (LSTM) layers was considered, the
training samples of which aggregate data from all regions of two countries: the
United States and Russia. Efficiency evaluation was carried out using
cross-validation according to the MAPE metric. It is shown that for complicated
periods characterized by a large increase in the number of confirmed daily
cases, the best results are shown by the LSTM model trained on all regions of
both countries, showing an average Mean Absolute Percentage Error (MAPE) of
18%, 30%, 37% for Russia and 31%, 41%, 50% for US for predictions at forecast
horizons of 14, 28, and 42 days, respectively.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:21:36 GMT""}]","2022-07-19"
"2207.07690","Thibaut Vidal","\'Italo Santana, Breno Serrano, Maximilian Schiffer, Thibaut Vidal","Support Vector Machines with the Hard-Margin Loss: Optimal Training via
  Combinatorial Benders' Cuts",,,,,"cs.LG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The classical hinge-loss support vector machines (SVMs) model is sensitive to
outlier observations due to the unboundedness of its loss function. To
circumvent this issue, recent studies have focused on non-convex loss
functions, such as the hard-margin loss, which associates a constant penalty to
any misclassified or within-margin sample. Applying this loss function yields
much-needed robustness for critical applications but it also leads to an
NP-hard model that makes training difficult, since current exact optimization
algorithms show limited scalability, whereas heuristics are not able to find
high-quality solutions consistently. Against this background, we propose new
integer programming strategies that significantly improve our ability to train
the hard-margin SVM model to global optimality. We introduce an iterative
sampling and decomposition approach, in which smaller subproblems are used to
separate combinatorial Benders' cuts. Those cuts, used within a branch-and-cut
algorithm, permit to converge much more quickly towards a global optimum.
Through extensive numerical analyses on classical benchmark data sets, our
solution algorithm solves, for the first time, 117 new data sets to optimality
and achieves a reduction of 50% in the average optimality gap for the hardest
datasets of the benchmark.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:21:51 GMT""}]","2022-07-19"
"2207.07691","Eric Murphy","Eric J. Murphy","The Role of Radio Observations in Studies of Infrared-Bright Galaxies:
  Prospects for a next-generation Very Large Array","20 pages, 5 figures; Invited review for the special issue ""Recent
  Advances in Infrared Galaxies and AGN"", edited by Anna Sajina and Asantha R.
  Cooray, in Universe","2022Univ....8..329M","10.3390/universe8060329",,"astro-ph.GA astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  The bulk of the present-day stellar mass was formed in galaxies when the
universe was less than half its current age (i.e., $1 \lesssim z \lesssim 3$).
While this likely marks one of the most critical time periods for galaxy
evolution, we currently do not have a clear picture on the radial extent and
distribution of cold molecular gas and associated star formation within the
disks of galaxies during this epoch. Such observations are essential to
properly estimate the efficiency at which such galaxies convert their gas into
stars, as well as to account for the various energetic processes that govern
this efficiency. Long-wavelength (i.e., far-infrared--to--radio) observations
are critical to penetrate the high-levels of extinction associated with dusty,
infrared-bright galaxies that are driving the stellar mass assembly at such
epochs. In this article we discuss how the next-generation Very Large Array
will take a transformative step in our understanding of galaxy formation and
evolution by delivering the ability to simultaneously study the relative
distributions molecular gas and star formation on sub-kpc scales unbiased by
dust for large populations of typical galaxies in the early universe detected
by future far-infrared space missions.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:26:30 GMT""}]","2022-07-19"
"2207.07692","Jose Edson Sampaio","Jos\'e Edson Sampaio","On Lipschitz Geometry at infinity of complex analytic sets","This paper was already posted on ResearchGate in April 2021",,,,"math.CV math.AG math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we study the Lipschitz Geometry at infinity of complex
analytic sets and we obtain results on algebraicity of analytic sets and on
Bernstein's problem. Moser's Bernstein Theorem says that a minimal hypersurface
which is a graph of an entire Lipschitz function must be a hyperplane. H. B.
Lawson, Jr. and R. Osserman presented examples showing that an analogous result
for arbitrary codimension is not true. In this article, we prove a complex
non-parametric version of Moser's Bernstein Theorem. More precisely, we prove
that any entire complex analytic set in $\mathbb{C}^n$ which is Lipschitz
regular at infinity must be an affine linear subspace of $\mathbb{C}^n$. In
particular, a complex analytic set which is a graph of an entire Lipschitz
function must be affine linear subspace. That result comes as a consequence of
the following characterization of algebraic sets, which is also proved here: if
$X$ and $Y$ are entire complex analytic sets which are bi-Lipschitz
homeomorphic at infinity then $X$ is a complex algebraic set if and only if $Y$
is a complex algebraic set too. Thus, an entire complex analytic set is a
complex algebraic set if and only if it is bi-Lipschitz homeomorphic at
infinity to a complex algebraic set. No restrictions on the singular set,
dimension nor codimension are required in the results proved here.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:27:23 GMT""}]","2022-07-19"
"2207.07693","Sujeong Kim","Sujeong Kim, Abhinav Garlapati, Jonah Lubin, Amir Tamrakar, Ajay
  Divakaran","Towards Understanding Confusion and Affective States Under Communication
  Failures in Voice-Based Human-Machine Interaction",,"2021 9th International Conference on Affective Computing and
  Intelligent Interaction Workshops and Demos (ACIIW)","10.1109/ACIIW52867.2021.9666238",,"cs.HC cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a series of two studies conducted to understand user's affective
states during voice-based human-machine interactions. Emphasis is placed on the
cases of communication errors or failures. In particular, we are interested in
understanding ""confusion"" in relation with other affective states. The studies
consist of two types of tasks: (1) related to communication with a voice-based
virtual agent: speaking to the machine and understanding what the machine says,
(2) non-communication related, problem-solving tasks where the participants
solve puzzles and riddles but are asked to verbally explain the answers to the
machine. We collected audio-visual data and self-reports of affective states of
the participants. We report results of two studies and analysis of the
collected data. The first study was analyzed based on the annotator's
observation, and the second study was analyzed based on the self-report.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:32:48 GMT""}]","2022-07-19"
"2207.07694","Martin Zimmermann","Shibashis Guha, Isma\""el Jecker, Karoliina Lehtinen, Martin Zimmermann","Parikh Automata over Infinite Words",,,,,"cs.FL cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Parikh automata extend finite automata by counters that can be tested for
membership in a semilinear set, but only at the end of a run, thereby
preserving many of the desirable algorithmic properties of finite automata.
Here, we study the extension of the classical framework onto infinite inputs:
We introduce reachability, safety, B\""uchi, and co-B\""uchi Parikh automata on
infinite words and study expressiveness, closure properties, and the complexity
of verification problems.
  We show that almost all classes of automata have pairwise incomparable
expressiveness, both in the deterministic and the nondeterministic case; a
result that sharply contrasts with the well-known hierarchy in the
$\omega$-regular setting. Furthermore, emptiness is shown decidable for Parikh
automata with reachability or B\""uchi acceptance, but undecidable for safety
and co-B\""uchi acceptance. Most importantly, we show decidability of model
checking with specifications given by deterministic Parikh automata with safety
or co-B\""uchi acceptance, but also undecidability for all other types of
automata. Finally, solving games is undecidable for all types.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:34:06 GMT""},{""version"":""v2"",""created"":""Fri, 16 Dec 2022 08:42:33 GMT""},{""version"":""v3"",""created"":""Tue, 20 Dec 2022 07:26:13 GMT""}]","2022-12-21"
"2207.07695","Jos Stam","Jos Stam","An Exact Bitwise Reversible Integrator",,,,,"cs.GR cs.LG","http://creativecommons.org/licenses/by/4.0/","  At a fundamental level most physical equations are time reversible. In this
paper we propose an integrator that preserves this property at the discrete
computational level. Our simulations can be run forward and backwards and trace
the same path exactly bitwise. We achieve this by implementing theoretically
reversible integrators using a mix of fixed and floating point arithmetic. Our
main application is in efficiently implementing the reverse step in the adjoint
method used in optimization. Our integrator has applications in differential
simulations and machine learning (backpropagation).
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:35:15 GMT""}]","2022-07-19"
"2207.07696","Marissa Masden","Marissa Masden","Algorithmic Determination of the Combinatorial Structure of the Linear
  Regions of ReLU Neural Networks","23 pages, 8 figures",,,,"cs.LG cs.CG math.AT","http://creativecommons.org/licenses/by-sa/4.0/","  We algorithmically determine the regions and facets of all dimensions of the
canonical polyhedral complex, the universal object into which a ReLU network
decomposes its input space. We show that the locations of the vertices of the
canonical polyhedral complex along with their signs with respect to layer maps
determine the full facet structure across all dimensions. We present an
algorithm which calculates this full combinatorial structure, making use of our
theorems that the dual complex to the canonical polyhedral complex is cubical
and it possesses a multiplication compatible with its facet structure. The
resulting algorithm is numerically stable, polynomial time in the number of
intermediate neurons, and obtains accurate information across all dimensions.
This permits us to obtain, for example, the true topology of the decision
boundaries of networks with low-dimensional inputs. We run empirics on such
networks at initialization, finding that width alone does not increase observed
topology, but width in the presence of depth does. Source code for our
algorithms is accessible online at https://github.com/mmasden/canonicalpoly.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:36:12 GMT""}]","2022-07-19"
"2207.07697","Shishir G. Patil","Shishir G. Patil, Paras Jain, Prabal Dutta, Ion Stoica, Joseph E.
  Gonzalez","POET: Training Neural Networks on Tiny Devices with Integrated
  Rematerialization and Paging","Proceedings of the 39th International Conference on Machine Learning
  2022 (ICML 2022)",,,,"cs.LG cs.CV cs.DC stat.ML","http://creativecommons.org/licenses/by/4.0/","  Fine-tuning models on edge devices like mobile phones would enable
privacy-preserving personalization over sensitive data. However, edge training
has historically been limited to relatively small models with simple
architectures because training is both memory and energy intensive. We present
POET, an algorithm to enable training large neural networks on memory-scarce
battery-operated edge devices. POET jointly optimizes the integrated search
search spaces of rematerialization and paging, two algorithms to reduce the
memory consumption of backpropagation. Given a memory budget and a run-time
constraint, we formulate a mixed-integer linear program (MILP) for
energy-optimal training. Our approach enables training significantly larger
models on embedded devices while reducing energy consumption while not
modifying mathematical correctness of backpropagation. We demonstrate that it
is possible to fine-tune both ResNet-18 and BERT within the memory constraints
of a Cortex-M class embedded device while outperforming current edge training
methods in energy efficiency. POET is an open-source project available at
https://github.com/ShishirPatil/poet
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:36:29 GMT""}]","2022-07-19"
"2207.07698","Andreas Rupp","Vesa Kaarnioja and Andreas Rupp","Quasi-Monte Carlo and discontinuous Galerkin",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this study, we consider the development of tailored quasi-Monte Carlo
(QMC) cubatures for non-conforming discontinuous Galerkin (DG) approximations
of elliptic partial differential equations (PDEs) with random coefficients. We
consider both the affine and uniform and the lognormal models for the input
random field, and investigate the use of QMC cubatures to approximate the
expected value of the PDE response subject to input uncertainty. In particular,
we prove that the resulting QMC convergence rate for DG approximations behaves
in the same way as if continuous finite elements were chosen. Notably, the
parametric regularity bounds for DG, which are developed in this work, are also
useful for other methods such as sparse grids. Numerical results underline our
analytical findings.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:37:31 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jul 2022 13:58:50 GMT""},{""version"":""v3"",""created"":""Wed, 7 Sep 2022 12:31:15 GMT""},{""version"":""v4"",""created"":""Wed, 15 Mar 2023 11:04:31 GMT""}]","2023-03-16"
"2207.07699","Gregor Bano","Denis Horvath, Cyril Slab\'y, Zolt\'an Tomori, Andrej Hovan, Pavol
  Miskovsky, Gregor B\'an\'o","The bouncing dynamics of inertial self-propelled particles reveals
  directional asymmetry",,,"10.1103/PhysRevE.107.024603",,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study aims to examine experimental conditions in which active particles
are forced by their surroundings to move forward and backward in a continuous
oscillatory manner. The experimental design is based on using a vibrating
self-propelled toy-robot called hexbug, which is placed inside a narrow channel
closed on one end by a rigid moving wall. Using the end-wall velocity as a
controlling factor, the main forward mode of the hexbug movement can be turned
to mostly rearward mode. We investigate the bouncing hexbug motion on both
experimental and theoretical grounds. The Brownian model of active particles
with inertia is employed in the theoretical framework. The model itself uses a
pulsed Langevin equation in order to simulate abrupt changes in velocity that
mimic hexbug propulsion in the moments when its legs make contact with the base
plate. Significant directional asymmetry is caused by the legs bending
backward. We demonstrate that the simulation successfully reproduces the
experimental characteristics of hexbug motion after regressing the spatial and
temporal statistical characteristics, especially when directional asymmetry is
under consideration.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:40:41 GMT""},{""version"":""v2"",""created"":""Mon, 1 May 2023 17:43:19 GMT""}]","2023-05-02"
"2207.07700","Maria Ganzha","Karolina Bogacka, Katarzyna Wasielewska-Michniewska, Marcin Paprzycki,
  Maria Ganzha, Anastasiya Danilenka, Lambis Tassakos, Eduardo Garro","Introducing Federated Learning into Internet of Things ecosystems --
  preliminary considerations","Conference IEEE 8th World Forum on Internet of Things submission",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Federated learning (FL) was proposed to facilitate the training of models in
a distributed environment. It supports the protection of (local) data privacy
and uses local resources for model training. Until now, the majority of
research has been devoted to ""core issues"", such as adaptation of machine
learning algorithms to FL, data privacy protection, or dealing with the effects
of uneven data distribution between clients. This contribution is anchored in a
practical use case, where FL is to be actually deployed within an Internet of
Things ecosystem. Hence, somewhat different issues that need to be considered,
beyond popular considerations found in the literature, are identified.
Moreover, an architecture that enables the building of flexible, and adaptable,
FL solutions is introduced.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:48:57 GMT""}]","2022-07-19"
"2207.07701","Ruth Shir","E. Rabinovici, A. S\'anchez-Garrido, R. Shir and J. Sonner","Krylov complexity from integrability to chaos","18 pages + appendices; v2: Minor corrections + added references",,"10.1007/JHEP07(2022)151",,"hep-th cond-mat.str-el quant-ph","http://creativecommons.org/licenses/by/4.0/","  We apply a notion of quantum complexity, called ""Krylov complexity"", to study
the evolution of systems from integrability to chaos. For this purpose we
investigate the integrable XXZ spin chain, enriched with an integrability
breaking deformation that allows one to interpolate between integrable and
chaotic behavior. K-complexity can act as a probe of the integrable or chaotic
nature of the underlying system via its late-time saturation value that is
suppressed in the integrable phase and increases as the system is driven to the
chaotic phase. We furthermore ascribe the (under-)saturation of the late-time
bound to the amount of disorder present in the Lanczos sequence, by mapping the
complexity evolution to an auxiliary off-diagonal Anderson hopping model. We
compare the late-time saturation of K-complexity in the chaotic phase with that
of random matrix ensembles and find that the chaotic system indeed approaches
the RMT behavior in the appropriate symmetry class. We investigate the
dependence of the results on the two key ingredients of K-complexity: the
dynamics of the Hamiltonian and the character of the operator whose time
dependence is followed.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:51:13 GMT""},{""version"":""v2"",""created"":""Wed, 10 Aug 2022 20:45:42 GMT""}]","2022-08-12"
"2207.07702","Junichi Koganemaru","Junichi Koganemaru and Ian Tice","Traveling wave solutions to the inclined or periodic free boundary
  incompressible Navier-Stokes equations","45 pages, 3 figures; v2: minor errors and typos corrected",,,,"math.AP math.FA","http://creativecommons.org/licenses/by/4.0/","  This paper concerns the construction of traveling wave solutions to the free
boundary incompressible Navier-Stokes system. We study a single layer of
viscous fluid in a strip-like domain that is bounded below by a flat rigid
surface and above by a moving surface. The fluid is acted upon by a bulk force
and a surface stress that are stationary in a coordinate system moving parallel
to the fluid bottom. We also assume that the fluid is subject to a uniform
gravitational force that can be resolved into a sum of a vertical component and
a component lying in the direction of the traveling wave velocity. This
configuration arises, for instance, in the modeling of fluid flow down an
inclined plane. We also study the effect of periodicity by allowing the fluid
cross section to be periodic in various directions. The horizontal component of
the gravitational field gives rise to stationary solutions that are pure shear
flows, and we construct our solutions as perturbations of these by means of an
implicit function argument. An essential component of our analysis is the
development of some new functional analytic properties of a scale of
anisotropic Sobolev spaces, including that these spaces are an algebra in the
supercritical regime, which may be of independent interest.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:51:27 GMT""},{""version"":""v2"",""created"":""Sun, 11 Sep 2022 12:06:01 GMT""}]","2022-09-13"
"2207.07703","Hossam Farag","Hossam Farag, Cedomir Stefanovic and Mikael Gidlund","Distributed Backlog-Aware D2D Communication for Heterogeneous IIoT
  Applications",,,,,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  Delay and Age-of-Information (AoI) are two crucial performance metrics for
emerging time-sensitive applications in Industrial Internet of Things (IIoT).
In order to achieve optimal performance, studying the inherent interplay
between these two parameters in non-trivial task. In this work, we consider a
Device-to-Device (D2D)-based heterogeneous IIoT network that supports two types
of traffic flows, namely AoI-orientated. First, we introduce a distributed
backlog-aware random access protocol that allows the AoI-orientated nodes to
opportunistically access the channel based on the queue occupancy of the
delay-oriented node. Then, we develop an analytical framework to evaluate the
average delay and the average AoI, and formulate an optimization problem to
minimize the AoI under a given delay constraint. Finally, we provide numerical
results to demonstrate the impact of different network parameters on the
performance in terms of the average delay and the average AoI. We also give the
numerical solutions of the optimal parameters that minimize the AoI subject to
a delay constraint.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:57:19 GMT""}]","2022-07-19"
"2207.07704","Ian Swift","Ian P. Swift, Sana Ebrahimi, Azade Nova, Abolfazl Asudeh","Maximizing Fair Content Spread via Edge Suggestion in Social Networks","16 pages, 17 figures, 8 tables. VLDB '22. Technical Report",,,,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Content spread inequity is a potential unfairness issue in online social
networks, disparately impacting minority groups. In this paper, we view
friendship suggestion, a common feature in social network platforms, as an
opportunity to achieve an equitable spread of content. In particular, we
propose to suggest a subset of potential edges (currently not existing in the
network but likely to be accepted) that maximizes content spread while
achieving fairness. Instead of re-engineering the existing systems, our
proposal builds a fairness wrapper on top of the existing friendship suggestion
components.
  We prove the problem is NP-hard and inapproximable in polynomial time unless
P = NP. Therefore, allowing relaxation of the fairness constraint, we propose
an algorithm based on LP-relaxation and randomized rounding with fixed
approximation ratios on fairness and content spread. We provide multiple
optimizations, further improving the performance of our algorithm in practice.
Besides, we propose a scalable algorithm that dynamically adds subsets of
nodes, chosen via iterative sampling, and solves smaller problems corresponding
to these nodes. Besides theoretical analysis, we conduct comprehensive
experiments on real and synthetic data sets. Across different settings, our
algorithms found solutions with nearzero unfairness while significantly
increasing the content spread. Our scalable algorithm could process a graph
with half a million nodes on a single machine, reducing the unfairness to
around 0.0004 while lifting content spread by 43%.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 18:59:19 GMT""},{""version"":""v2"",""created"":""Sat, 6 Aug 2022 17:56:35 GMT""},{""version"":""v3"",""created"":""Tue, 20 Dec 2022 19:50:10 GMT""}]","2022-12-22"
"2207.07705","Zachary Burns","Zachary Burns, Zhaowei Liu","Untrained, physics-informed neural networks for structured illumination
  microscopy","Preprint for journal submission. 21 Pages. 5 main text figures. 6
  supplementary figures",,"10.1364/OE.476781",,"eess.IV cs.CV physics.optics","http://creativecommons.org/licenses/by/4.0/","  In recent years there has been great interest in using deep neural networks
(DNN) for super-resolution image reconstruction including for structured
illumination microscopy (SIM). While these methods have shown very promising
results, they all rely on data-driven, supervised training strategies that need
a large number of ground truth images, which is experimentally difficult to
realize. For SIM imaging, there exists a need for a flexible, general, and
open-source reconstruction method that can be readily adapted to different
forms of structured illumination. We demonstrate that we can combine a deep
neural network with the forward model of the structured illumination process to
reconstruct sub-diffraction images without training data. The resulting
physics-informed neural network (PINN) can be optimized on a single set of
diffraction limited sub-images and thus doesn't require any training set. We
show with simulated and experimental data that this PINN can be applied to a
wide variety of SIM methods by simply changing the known illumination patterns
used in the loss function and can achieve resolution improvements that match
well with theoretical expectations.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:02:07 GMT""}]","2023-03-22"
"2207.07706","Shounak Naik","Shounak Naik, Rajaswa Patil, Swati Agarwal, Veeky Baths","Probing Semantic Grounding in Language Models of Code with
  Representational Similarity Analysis","Under review at ADMA 2022",,,,"cs.CL cs.IR cs.PL","http://creativecommons.org/licenses/by/4.0/","  Representational Similarity Analysis is a method from cognitive neuroscience,
which helps in comparing representations from two different sources of data. In
this paper, we propose using Representational Similarity Analysis to probe the
semantic grounding in language models of code. We probe representations from
the CodeBERT model for semantic grounding by using the data from the IBM
CodeNet dataset. Through our experiments, we show that current pre-training
methods do not induce semantic grounding in language models of code, and
instead focus on optimizing form-based patterns. We also show that even a
little amount of fine-tuning on semantically relevant tasks increases the
semantic grounding in CodeBERT significantly. Our ablations with the input
modality to the CodeBERT model show that using bimodal inputs (code and natural
language) over unimodal inputs (only code) gives better semantic grounding and
sample efficiency during semantic fine-tuning. Finally, our experiments with
semantic perturbations in code reveal that CodeBERT is able to robustly
distinguish between semantically correct and incorrect code.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:04:43 GMT""}]","2022-07-19"
"2207.07707","Matthias Benjamin Jungfleisch","Weipeng Wu, Sergi Lendinez, Mojtaba Taghipour Kaffash, Richard D.
  Schaller, Haidan Wen, and M. Benjamin Jungfleisch","Controlling polarization of spintronic THz emitter by remanent
  magnetization texture",,"Appl. Phys. Lett. 121, 052401 (2022)","10.1063/5.0096252",,"cond-mat.mtrl-sci cond-mat.mes-hall physics.app-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Terahertz (THz) sciences and technologies have contributed to a rapid
development of a wide range of applications and expanded the frontiers in
fundamental science. Spintronic terahertz emitters offer conceptual advantages
since the spin orientation in the magnetic layer can be easily controlled
either by the externally applied magnetic field or by the internal magnetic
field distribution determined by the specific shape of the magnetic elements.
Here, we report a switchable terahertz source based on micropatterned magnetic
heterostructures driven by femtosecond laser pulses. We show that the precise
tunability of the polarization state is facilitated by the underlying
magnetization texture of the magnetic layer that is dictated by the shape of
the microstructure. These results also reveal the underlying physical
mechanisms of a nonuniform magnetization state on the generation of ultrafast
spin currents in the magnetic heterostructures. Our findings indicate that the
emission of the linearly polarized THz waves can be switched on and off by
saturating the sample using a biasing magnetic field, opening fascinating
perspectives for integrated on-chip THz devices with wide-ranging potential
applications.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:07:02 GMT""}]","2022-08-04"
"2207.07708","\'Edouard Bonnet","Pierre Berg\'e, \'Edouard Bonnet, Hugues D\'epr\'es, R\'emi Watrigant","Approximating Highly Inapproximable Problems on Graphs of Bounded
  Twin-Width","32 pages, 3 figures, 1 table",,,,"cs.DS cs.CC cs.DM math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For any $\varepsilon > 0$, we give a polynomial-time
$n^\varepsilon$-approximation algorithm for Max Independent Set in graphs of
bounded twin-width given with an $O(1)$-sequence. This result is derived from
the following time-approximation trade-off: We establish an
$O(1)^{2^q-1}$-approximation algorithm running in time $\exp(O_q(n^{2^{-q}}))$,
for every integer $q \geqslant 0$. Guided by the same framework, we obtain
similar approximation algorithms for Min Coloring and Max Induced Matching. In
general graphs, all these problems are known to be highly inapproximable: for
any $\varepsilon > 0$, a polynomial-time $n^{1-\varepsilon}$-approximation for
any of them would imply that P$=$NP [Hastad, FOCS '96; Zuckerman, ToC '07;
Chalermsook et al., SODA '13]. We generalize the algorithms for Max Independent
Set and Max Induced Matching to the independent (induced) packing of any fixed
connected graph $H$. In contrast, we show that such approximation guarantees on
graphs of bounded twin-width given with an $O(1)$-sequence are very unlikely
for Min Independent Dominating Set, and somewhat unlikely for Longest Path and
Longest Induced Path. Regarding the existence of better approximation
algorithms, there is a (very) light evidence that the obtained approximation
factor of $n^\varepsilon$ for Max Independent Set may be best possible. This is
the first in-depth study of the approximability of problems in graphs of
bounded twin-width. Prior to this paper, essentially the only such result was
a~polynomial-time $O(1)$-approximation algorithm for Min Dominating Set [Bonnet
et al., ICALP '21].
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:07:07 GMT""},{""version"":""v2"",""created"":""Sun, 25 Sep 2022 18:32:32 GMT""}]","2022-09-27"
"2207.07709","Jin Won Kim","Jin Won Kim","Duality for nonlinear filtering","Ph.D. Thesis of the author",,,,"math.OC math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This thesis is concerned with the stochastic filtering problem for a hidden
Markov model (HMM) with the white noise observation model. For this filtering
problem, we make three types of original contributions: (1) dual
controllability characterization of stochastic observability, (2) dual minimum
variance optimal control formulation of the stochastic filtering problem, and
(3) filter stability analysis using the dual optimal control formulation.
  For the first contribution of this thesis, a backward stochastic differential
equation (BSDE) is proposed as the dual control system. The observability
(detectability) of the HMM is shown to be equivalent to the controllability
(stabilizability) of the dual control system. For the linear-Gaussian model,
the dual relationship reduces to classical duality in linear systems theory.
  The second contribution is to transform the minimum variance estimation
problem into an optimal control problem. The constraint is given by the dual
control system. The optimal solution is obtained via two approaches: (1) by an
application of maximum principle and (2) by the martingale characterization of
the optimal value. The optimal solution is used to derive the nonlinear filter.
  The third contribution is to carry out filter stability analysis by studying
the dual optimal control problem. Two approaches are presented through Chapters
7 and 8. In Chapter 7, conditional Poincar\'e inequality (PI) is introduced.
Based on conditional PI, various convergence rates are obtained and related to
literature. In Chapter 8, the stabilizability of the dual control system is
shown to be a necessary and sufficient condition for filter stability on
certain finite state space model.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:07:59 GMT""}]","2022-07-19"
"2207.07710","Eric Yeh","Eric Yeh, Pedro Sequeira, Jesse Hostetler, Melinda Gervasio","Outcome-Guided Counterfactuals for Reinforcement Learning Agents from a
  Jointly Trained Generative Latent Space",,,,,"cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a novel generative method for producing unseen and plausible
counterfactual examples for reinforcement learning (RL) agents based upon
outcome variables that characterize agent behavior. Our approach uses a
variational autoencoder to train a latent space that jointly encodes
information about the observations and outcome variables pertaining to an
agent's behavior. Counterfactuals are generated using traversals in this latent
space, via gradient-driven updates as well as latent interpolations against
cases drawn from a pool of examples. These include updates to raise the
likelihood of generated examples, which improves the plausibility of generated
counterfactuals. From experiments in three RL environments, we show that these
methods produce counterfactuals that are more plausible and proximal to their
queries compared to purely outcome-driven or case-based baselines. Finally, we
show that a latent jointly trained to reconstruct both the input observations
and behavioral outcome variables produces higher-quality counterfactuals over
latents trained solely to reconstruct the observation inputs.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:09:54 GMT""}]","2022-07-19"
"2207.07711","Michele Modugno","Aitor Ala\~na, Nicol\`o Antolini, Giulio Biagioni, I\~nigo L.
  Egusquiza, and Michele Modugno","Crossing the superfluid-supersolid transition of an elongated dipolar
  condensate","9 pages, 8 figures",,,,"cond-mat.quant-gas","http://creativecommons.org/licenses/by/4.0/","  We provide a theoretical characterization of the dynamical crossing of the
superfluid-supersolid phase transition for a dipolar condensate confined in an
elongated trap, as observed in the recent experiment by G. Biagioni et al.
[Phys. Rev. X 12, 021019 (2022)]. By means of the extended Gross-Pitaevskii
theory, which includes the Lee-Huang-Yang quantum fluctuation correction, we
first analyze the ground state configurations of the system as a function of
the interparticle scattering length, for both trap configurations employed in
the experiment. Then, we discuss the effects of the ramp velocity, by which the
scattering length is tuned across the transition, on the collective excitations
of the system in both the superfluid and supersolid phases. We find that, when
the transverse confinement is sufficiently strong and the transition has a
smooth (continuous) character, the system essentially displays a (quasi) 1D
behavior, its excitation dynamics being dominated by the axial breathing modes.
Instead, for shallower transverse trapping, when the transition becomes
discontinuous, the collective excitations of the supersolid display a coupling
with the transverse modes, signalling the onset of a dimensional crossover.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:11:29 GMT""}]","2022-07-19"
"2207.07712","Jason Wu","Jason Wu and Titus Barik and Xiaoyi Zhang and Colin Lea and Jeffrey
  Nichols and Jeffrey P. Bigham","Reflow: Automatically Improving Touch Interactions in Mobile
  Applications through Pixel-based Refinements",,,,,"cs.HC","http://creativecommons.org/licenses/by/4.0/","  Touch is the primary way that users interact with smartphones. However,
building mobile user interfaces where touch interactions work well for all
users is a difficult problem, because users have different abilities and
preferences. We propose a system, Reflow, which automatically applies small,
personalized UI adaptations, called refinements -- to mobile app screens to
improve touch efficiency. Reflow uses a pixel-based strategy to work with
existing applications, and improves touch efficiency while minimally disrupting
the design intent of the original application. Our system optimizes a UI by (i)
extracting its layout from its screenshot, (ii) refining its layout, and (iii)
re-rendering the UI to reflect these modifications. We conducted a user study
with 10 participants and a heuristic evaluation with 6 experts and found that
applications optimized by Reflow led to, on average, 9% faster selection time
with minimal layout disruption. The results demonstrate that Reflow's
refinements useful UI adaptations to improve touch interactions.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:11:49 GMT""}]","2022-07-19"
"2207.07713","Zhengyi Wang","Zhengyi Wang, Ji Yao, Xiangkun Liu, Dezi Liu, Zuhui Fan, Bin Hu","Forecast of cross-correlation of CSST cosmic shear tomography with
  AliCPT-1 CMB lensing","21 pages, 13 figures",,"10.1093/mnras/stad1592",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a forecast study on the cross-correlation between cosmic shear
tomography from the Chinese Survey Space Telescope (CSST) and CMB lensing from
Ali CMB Polarization Telescope (AliCPT-1) in Tibet. The correlated galaxy and
CMB lensing signals were generated from Gaussian realizations based on inputted
auto- and cross-spectra. To account for the error budget, we considered the CMB
lensing reconstruction noise based on the AliCPT-1 lensing reconstruction
pipeline; shape noise of the galaxy lensing measurement; CSST photo-$z$ error;
photo-$z$ bias; intrinsic alignment effect, and multiplicative bias. The
AliCPT-1 CMB lensing mock data were generated according to two experimental
stages, namely the ``4 modules*yr'' and ``48 modules*yr'' cases. We estimate
the cross-spectra in 4 tomographic bins according to the CSST photo-$z$
distribution in the range of $z\in[0,4)$. After reconstructing the
pseudo-cross-spectra from the realizations, we calculate the signal-to-noise
ratio (SNR). By combining the 4 photo-$z$ bins, the total cross-correlation
SNR$\approx15$ (AliCPT-1 ``4 modules*yr'') and SNR$\approx22$ (AliCPT-1 ``48
modules*yr''). Finally, we study the cosmological application of this
cross-correlation signal. Excluding intrinsic alignment (IA) in the template
fitting would lead to roughly a $0.6\sigma$ increment in $\sigma_8$ due to the
negative IA contribution to the galaxy lensing data. For AliCPT-1 first and
second stages, the cross-correlation of CSST cosmic shear with CMB lensing
gives errors on the clustering amplitude $\sigma_{\sigma_8}=^{+0.043}_{-0.038}$
or $\sigma_{S_8}=\pm 0.031$ and $\sigma_{\sigma_8}=^{+0.030}_{-0.027}$ or
$\sigma_{S_8}=\pm 0.018$, respectively.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:12:38 GMT""},{""version"":""v2"",""created"":""Mon, 29 May 2023 08:04:15 GMT""}]","2023-06-07"
"2207.07714","Ver\'onica Moreno Vero","Gabriel Pena, Ver\'onica Moreno, Nestor Barraza","Measuring COVID-19 spreading speed through the mean time between
  infections indicator",,,,,"q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose to use the mean time between infections (MTBI) metric as obtained
from a recently introduced non-homogeneous Markov stochastic model. Different
types of parameter calibration are performed. We estimate the MTBI using data
from different time windows and from the whole stage history and compare the
results. In order to detect waves and stages in the input data, a preprocessing
filtering technique is applied. The results of applying this indicator to the
COVID-19 reported data of infections from Argentina, Germany and the United
States are shown. We find that the MTBI behaves similarly with respect to the
different data inputs, whereas the model parameters completely change their
behaviour. Evolution over time of the parameters and the MTBI indicator is also
shown. We show evidence to support the claim that the MTBI is a rather good
indicator in order to measure the spreading speed of an epidemic, having
similar values whatever the input data size.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:12:53 GMT""}]","2022-07-19"
"2207.07715","Werner Krauth","Botao Li, Yoshihiko Nishikawa, Philipp Hoellmer, Louis Carillo, A. C.
  Maggs, Werner Krauth","Hard-disk computer simulations -- a historic perspective","21 pages, 13 figures, open-source repository",,"10.1063/5.0126437",,"cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  We discuss historic pressure computations for the hard-disk model performed
since 1953, and compare them to results that we obtain with a powerful
event-chain Monte Carlo and a massively parallel Metropolis algorithm. Like
other simple models in the sciences, such as the Drosophila model of biology,
the hard-disk model has needed monumental effort to be understood. In
particular, we argue that the difficulty of estimating the pressure has not
been fully realized in the decades-long controversy over the hard-disk
phase-transition scenario. We present the physics of the hard-disk model, the
definition of the pressure and its unbiased estimators, several of which are
new. We further treat different sampling algorithms and crucial criteria for
bounding mixing times in the absence of analytical predictions. Our definite
results for the pressure, for up to one million disks, may serve as benchmarks
for future sampling algorithms. A synopsis of hard-disk pressure data as well
as different versions of the sampling algorithms and pressure estimators are
made available in an open-source repository.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:15:46 GMT""}]","2023-01-04"
"2207.07716","Diogo L. Pires","Diogo L. Pires and Mark Broom","More can be better: An analysis of single-mutant fixation probability
  functions under $2\times2$ games","23 pages, 8 figures","Proceedings of Royal Society A. 478: 20220577","10.1098/rspa.2022.0577",,"q-bio.PE","http://creativecommons.org/licenses/by/4.0/","  Evolutionary game theory has proved to be a powerful tool to probe the
self-organisation of collective behaviour by considering frequency-dependent
fitness in evolutionary processes. It has shown that the stability of a
strategy depends not only on the payoffs received after each encounter but also
on the population's size. Here, we study $2\times2$ games in well-mixed finite
populations by analysing the fixation probabilities of single mutants as
functions of population size. We proved that 9 out of the 24 possible games
always lead to monotonically decreasing functions, similarly to fixed fitness
scenarios. However, fixation functions showed increasing regions under 12
distinct anti-coordination, coordination, and dominance games. Perhaps
counter-intuitively, this establishes that single-mutant strategies often
benefit from being in larger populations. Fixation functions that increase from
a global minimum to a positive asymptotic value are pervasive but may have been
easily concealed by the weak selection limit. We obtained sufficient conditions
to observe fixation increasing for small populations and three distinct ways
this can occur. Finally, we describe fixation functions with increasing regions
bounded by two extremes under intermediate population sizes. We associate their
occurrence with transitions from having one global extreme to other shapes.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:15:51 GMT""},{""version"":""v2"",""created"":""Fri, 28 Oct 2022 11:01:40 GMT""},{""version"":""v3"",""created"":""Tue, 29 Nov 2022 14:37:10 GMT""}]","2023-01-11"
"2207.07717","Alexander Kasprzyk","Tom Coates, Johannes Hofscheier and Alexander Kasprzyk","Machine Learning the Dimension of a Polytope","13 pages, 7 figures",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  We use machine learning to predict the dimension of a lattice polytope
directly from its Ehrhart series. This is highly effective, achieving almost
100% accuracy. We also use machine learning to recover the volume of a lattice
polytope from its Ehrhart series, and to recover the dimension, volume, and
quasi-period of a rational polytope from its Ehrhart series. In each case we
achieve very high accuracy, and we propose mathematical explanations for why
this should be so.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:18:41 GMT""}]","2022-07-19"
"2207.07718","Nasrallah Nasrallah","Nasrallah F. Nasrallah, Karl Schilcher","Isovector Meson Masses from QCD Sum Rules","Typos and misprints corrected",,"10.1142/S0217732323500098",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We present a calculation of the masses of the isovector mesons ( vector,
scalar and pseudoscalar including the established recurrences) using a new
method of finite energy QCD sum rules. The method is based on the idea of
choosing a suitable integration kernel which minimizes the occurring integral
over the cut in the complex energy (squared) plane. We obtain remarkably stable
results in a wide range R, where R is the radius of the integration contour.
The sum rule predictions agree with the experimental values within the expected
accuracy showing that QCD describes single resonances.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:21:27 GMT""},{""version"":""v2"",""created"":""Thu, 18 Aug 2022 14:51:54 GMT""},{""version"":""v3"",""created"":""Sat, 5 Nov 2022 15:40:13 GMT""}]","2023-05-17"
"2207.07719","Masih Haseli","Masih Haseli, Jorge Cort\'es","Temporal Forward-Backward Consistency, Not Residual Error, Measures the
  Prediction Accuracy of Extended Dynamic Mode Decomposition","7 pages",,,,"eess.SY cs.LG cs.SY math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Extended Dynamic Mode Decomposition (EDMD) is a popular data-driven method to
approximate the action of the Koopman operator on a linear function space
spanned by a dictionary of functions. The accuracy of EDMD model critically
depends on the quality of the particular dictionary's span, specifically on how
close it is to being invariant under the Koopman operator. Motivated by the
observation that the residual error of EDMD, typically used for dictionary
learning, does not encode the quality of the function space and is sensitive to
the choice of basis, we introduce the novel concept of consistency index. We
show that this measure, based on using EDMD forward and backward in time,
enjoys a number of desirable qualities that make it suitable for data-driven
modeling of dynamical systems: it measures the quality of the function space,
it is invariant under the choice of basis, can be computed in closed form from
the data, and provides a tight upper-bound for the relative root mean square
error of all function predictions on the entire span of the dictionary.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:22:22 GMT""},{""version"":""v2"",""created"":""Sat, 8 Oct 2022 19:08:49 GMT""},{""version"":""v3"",""created"":""Mon, 7 Nov 2022 03:55:28 GMT""}]","2022-11-08"
"2207.07720","Eric Setterqvist","Eric Setterqvist, Natan Kruglyak, Robert Forchheimer","Local Approximations, Real Interpolation and Machine Learning","arXiv admin note: substantial text overlap with arXiv:2204.13141",,,,"cs.LG math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We suggest a novel classification algorithm that is based on local
approximations and explain its connections with Artificial Neural Networks
(ANNs) and Nearest Neighbour classifiers. We illustrate it on the datasets
MNIST and EMNIST of images of handwritten digits. We use the dataset MNIST to
find parameters of our algorithm and apply it with these parameters to the
challenging EMNIST dataset. It is demonstrated that the algorithm misclassifies
0.42% of the images of EMNIST and therefore significantly outperforms
predictions by humans and shallow artificial neural networks (ANNs with few
hidden layers) that both have more than 1.3% of errors
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:26:31 GMT""}]","2022-07-19"
"2207.07721","Gaurab Hore","Tucker McElroy, Anindya Roy, Gaurab Hore","FLIP: A Utility Preserving Privacy Mechanism for Time Series","19 pages, 5 figures",,,,"cs.CR stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Guaranteeing privacy in released data is an important goal for data-producing
agencies. There has been extensive research on developing suitable privacy
mechanisms in recent years. Particularly notable is the idea of noise addition
with the guarantee of differential privacy. There are, however, concerns about
compromising data utility when very stringent privacy mechanisms are applied.
Such compromises can be quite stark in correlated data, such as time series
data. Adding white noise to a stochastic process may significantly change the
correlation structure, a facet of the process that is essential to optimal
prediction. We propose the use of all-pass filtering as a privacy mechanism for
regularly sampled time series data, showing that this procedure preserves
utility while also providing sufficient privacy guarantees to entity-level time
series.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:27:09 GMT""}]","2022-07-19"
"2207.07722","Hannah Lang","Sanjana Das, Hannah Lang, Hamilton Wan, Nancy Xu","The Distribution of Error Terms of Smoothed Summatory Totient Functions","15 pages, 2 figures",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  We consider the summatory function of the totient function after applications
of a suitable smoothing operator and study the limiting behavior of the
associated error term. Under several conditional assumptions, we show that the
smoothed error term possesses a limiting logarithmic distribution through a
framework consolidated by Akbary--Ng--Shahabi. To obtain this result, we prove
a truncated version of Perron's inversion formula for arbitrary Riesz typical
means. We conclude with a conditional proof that at least two applications of
the smoothing operator are necessary and sufficient to bound the growth of the
error term by $\sqrt{x}$.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:29:04 GMT""}]","2022-07-19"
"2207.07723","Yunyi Li","Yunyi Li, Maria De-Arteaga, Maytal Saar-Tsechansky","More Data Can Lead Us Astray: Active Data Acquisition in the Presence of
  Label Bias",,,,,"cs.LG cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An increased awareness concerning risks of algorithmic bias has driven a
surge of efforts around bias mitigation strategies. A vast majority of the
proposed approaches fall under one of two categories: (1) imposing algorithmic
fairness constraints on predictive models, and (2) collecting additional
training samples. Most recently and at the intersection of these two
categories, methods that propose active learning under fairness constraints
have been developed. However, proposed bias mitigation strategies typically
overlook the bias presented in the observed labels. In this work, we study
fairness considerations of active data collection strategies in the presence of
label bias. We first present an overview of different types of label bias in
the context of supervised learning systems. We then empirically show that, when
overlooking label bias, collecting more data can aggravate bias, and imposing
fairness constraints that rely on the observed labels in the data collection
process may not address the problem. Our results illustrate the unintended
consequences of deploying a model that attempts to mitigate a single type of
bias while neglecting others, emphasizing the importance of explicitly
differentiating between the types of bias that fairness-aware algorithms aim to
address, and highlighting the risks of neglecting label bias during data
collection.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:30:50 GMT""}]","2022-07-19"
"2207.07724","Jason Parker","Jason T. Parker, Jessica DeBerardinis, Simo A. M\""akiharju","Enhanced Laboratory X-ray Particle Tracking Velocimetry With Newly
  Developed Tungsten-Coated O(50 $\mu$m) Tracers","Submitted to Experiments in Fluids for consideration for publication",,"10.1007/s00348-022-03530-6",,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  Tracer particles designed specifically for X-ray particle tracking and
imaging velocimetry (XPTV and XPIV) are necessary to widen the range of flows
that can be studied with these techniques. In this study, we demonstrate in-lab
XPTV using new, custom-designed $O$(50 $\mu$m) diameter tungsten-coated hollow
carbon spheres and a single energy threshold photon counting detector. To
explore the measurement quality enhancement enabled by the new tracer particles
and photon counting detector, a well understood Poiseulle pipe flow is
measured. The data show agreement with the analytical solution for the
depth-averaged velocity profile. The experiment also shows that the
tungsten-coated particles achieve higher contrast and are better localized than
previously available silver-coated particles, making faster and more precise
measurements attainable. The particles are manufactured with a readily scalable
chemical vapor deposition process.
  We further show that laboratory XPTV is practical with currently available
energy-resolving photon counting detectors (PCDs), despite their presently
lower spatiotemporal resolution compared to scintillating detectors. This
finding suggests that energy-thresholding identification of different classes
of tracers is feasible, further motivating the exploration of the X-ray tracer
particle design space. The latest generation of PCDs are incorporating multiple
energy thresholds, and have higher count rate limits. In the near future one
could potentially expand on the work presented and track multiple tracer
species and scalar fields simultaneously.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:31:54 GMT""}]","2022-11-30"
"2207.07725","Bruno Murta","Bruno Murta, Pedro M. Q. Cruz and J. Fern\'andez-Rossier","Preparing Valence-Bond-Solid states on noisy intermediate-scale quantum
  computers","Main text: 17 pages, 7 figures. Appendices: 10 pages, 5 figures. QASM
  files to be added in next version of preprint","Phys. Rev. Research 5, 013190 (2023)","10.1103/PhysRevResearch.5.013190",,"quant-ph cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  Quantum state preparation is a key step in all digital quantum simulation
algorithms. Here we propose methods to initialize on a gate-based quantum
computer a general class of quantum spin wave functions, the so-called
Valence-Bond-Solid (VBS) states, that are important for two reasons. First, VBS
states are the exact ground states of a class of interacting quantum spin
models introduced by Affleck, Kennedy, Lieb and Tasaki (AKLT). Second, the
two-dimensional VBS states are universal resource states for measurement-based
quantum computing. We find that schemes to prepare VBS states based on their
tensor-network representations yield quantum circuits that are too deep to be
within reach of noisy intermediate-scale quantum (NISQ) computers. We then
apply the general non-deterministic method herein proposed to the preparation
of the spin-1 and spin-3/2 VBS states, the ground states of the AKLT models
defined in one dimension and in the honeycomb lattice, respectively. Shallow
quantum circuits of depth independent of the lattice size are explicitly
derived for both cases, making use of optimization schemes that outperform
standard basis gate decomposition methods. Given the probabilistic nature of
the proposed routine, two strategies that achieve a quadratic reduction of the
repetition overhead for any VBS state defined on a bipartite lattice are
devised. Our approach should permit to use NISQ processors to explore the AKLT
model and variants thereof, outperforming conventional numerical methods in the
near future.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:40:15 GMT""},{""version"":""v2"",""created"":""Wed, 21 Sep 2022 09:48:14 GMT""}]","2023-04-13"
"2207.07726","David Joseph Wrisley","Estelle Gu\'eville and David Joseph Wrisley","Transcribing Medieval Manuscripts for Machine Learning",,,,,"cs.DL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In the early twentieth century, many scholars focused on the preparation of
editions and translations of texts previously available only to the few
specialists able to read archaic hands and privileged enough to travel to work
in person with them in manuscript. Valuable scholarship in its own right, the
preparation of these editions and translations for particular texts deemed
important enough to justify the effort and time, laid the foundation for
generations of scholarship in medieval studies. On the other hand, for many
materials in historical archival collections, including already digitised
collections, medievalists have only had the time to create partial
transcriptions, if any at all. Access to textual material from the medieval
period has increased greatly in recent years with digitisation, and we are able
to imagine many new research projects in decades to come. What challenges do
new frontiers of automation in the archives raise with respect to medieval
studies and in particular to the ways we transcribe? In this article, we argue
that if medievalists hope to pursue the kinds of analysis that goes on in
advanced computational research, we will need new kinds of transcriptions,
intentionally theorized not only for human reading, but also for machine
processing. We already have mature methods for remediating generations of
editions of medieval works such as Optical Character Recognition (OCR), but we
can ask ourselves if these are the kinds of text we want to use for future
computational analysis. We suggest instead that one way forward is by going
back to the scriptorium.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:49:09 GMT""},{""version"":""v2"",""created"":""Mon, 6 Mar 2023 19:04:28 GMT""}]","2023-03-08"
"2207.07727","Vidya Setlur","Vidya Setlur, Michael Correll, Sarah Battersby","OSCAR: A Semantic-based Data Binning Approach","5 pages (4 pages text + 1 page references), 3 figures",,,,"cs.HC","http://creativecommons.org/licenses/by/4.0/","  Binning is applied to categorize data values or to see distributions of data.
Existing binning algorithms often rely on statistical properties of data.
However, there are semantic considerations for selecting appropriate binning
schemes. Surveys, for instance, gather respondent data for demographic-related
questions such as age, salary, number of employees, etc., that are bucketed
into defined semantic categories. In this paper, we leverage common semantic
categories from survey data and Tableau Public visualizations to identify a set
of semantic binning categories. We employ these semantic binning categories in
OSCAR: a method for automatically selecting bins based on the inferred semantic
type of the field. We conducted a crowdsourced study with 120 participants to
better understand user preferences for bins generated by OSCAR vs. binning
provided in Tableau. We find that maps and histograms using binned values
generated by OSCAR are preferred by users as compared to binning schemes based
purely on the statistical properties of the data.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:49:36 GMT""}]","2022-07-19"
"2207.07728","Sanjay Gosain","Sanjay Gosain, Jack Harvey, Valentin Martinez-Pillet, Tom Woods, Frank
  Hill","A Compact Full-disk Solar Magnetograph based on miniaturization of GONG
  instrument","13 pages, 6 figures",,"10.1088/1538-3873/acca49","NSO Technical Report No. NSO-NISP-2022-002","astro-ph.IM astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Designing compact instruments is the key for the scientific exploration by
smaller spacecrafts such as cubesats or by deep space missions. Such missions
require compact instrument designs to have minimal instrument mass. Here we
present a proof of concept for miniaturization of the Global Oscillation
Network Group GONG instrument. GONG instrument routinely obtains solar full
disk Doppler and magnetic field maps of the solar photosphere using Ni 676 nm
absorption line. A key concept for miniaturization of GONG optical design is to
replace the bulky Lyot filter with a narrow-band interference filter and reduce
the length of feed telescope. We present validation of the concept via
numerical modeling as well as by proof of concept observations.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:50:12 GMT""}]","2023-05-10"
"2207.07729","Markus Nemitz","Savita V. Kendre, Gus. T. Teran, Lauryn Whiteside, Tyler Looney, Ryley
  Wheelock, Surya Ghai, and Markus P. Nemitz","Printable Flexible Robots for Remote Learning","9 pages, 4 figures, peer reviewed and presented paper at American
  Society of Engineering Education, April 22-23rd, 2022 - Wentworth Institute
  of Technology",,,,"cs.RO cs.CY","http://creativecommons.org/licenses/by/4.0/","  The COVID-19 pandemic has revealed the importance of digital fabrication to
enable online learning, which remains a challenge for robotics courses. We
introduce a teaching methodology that allows students to participate remotely
in a hands-on robotics course involving the design and fabrication of robots.
Our methodology employs 3D printing techniques with flexible filaments to
create innovative soft robots; robots are made from flexible, as opposed to
rigid, materials. Students design flexible robotic components such as
actuators, sensors, and controllers using CAD software, upload their designs to
a remote 3D printing station, monitor the print with a web camera, and inspect
the components with lab staff before being mailed for testing and assembly. At
the end of the course, students will have iterated through several designs and
created fluidically-driven soft robots. Our remote teaching methodology enables
educators to utilize 3D printing resources to teach soft robotics and cultivate
creativity among students to design novel and innovative robots. Our
methodology seeks to democratize robotics engineering by decoupling hands-on
learning experiences from expensive equipment in the learning environment.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:51:54 GMT""}]","2022-07-19"
"2207.07730","Jorge A Mendez","Jorge A. Mendez and Eric Eaton","How to Reuse and Compose Knowledge for a Lifetime of Tasks: A Survey on
  Continual Learning and Functional Composition",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  A major goal of artificial intelligence (AI) is to create an agent capable of
acquiring a general understanding of the world. Such an agent would require the
ability to continually accumulate and build upon its knowledge as it encounters
new experiences. Lifelong or continual learning addresses this setting, whereby
an agent faces a continual stream of problems and must strive to capture the
knowledge necessary for solving each new task it encounters. If the agent is
capable of accumulating knowledge in some form of compositional representation,
it could then selectively reuse and combine relevant pieces of knowledge to
construct novel solutions. Despite the intuitive appeal of this simple idea,
the literatures on lifelong learning and compositional learning have proceeded
largely separately. In an effort to promote developments that bridge between
the two fields, this article surveys their respective research landscapes and
discusses existing and future connections between them.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:53:20 GMT""}]","2022-07-19"
"2207.07731","Amit Jena","Amit Jena, Tong Huang, S. Sivaranjani, Dileep Kalathil, Le Xie","Distributed Learning of Neural Lyapunov Functions for Large-Scale
  Networked Dissipative Systems",,,,,"eess.SY cs.LG cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers the problem of characterizing the stability region of a
large-scale networked system comprised of dissipative nonlinear subsystems, in
a distributed and computationally tractable way. One standard approach to
estimate the stability region of a general nonlinear system is to first find a
Lyapunov function for the system and characterize its region of attraction as
the stability region. However, classical approaches, such as sum-of-squares
methods and quadratic approximation, for finding a Lyapunov function either do
not scale to large systems or give very conservative estimates for the
stability region. In this context, we propose a new distributed learning based
approach by exploiting the dissipativity structure of the subsystems. Our
approach has two parts: the first part is a distributed approach to learn the
storage functions (similar to the Lyapunov functions) for all the subsystems,
and the second part is a distributed optimization approach to find the Lyapunov
function for the networked system using the learned storage functions of the
subsystems. We demonstrate the superior performance of our proposed approach
through extensive case studies in microgrid networks.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 20:03:53 GMT""}]","2022-07-19"
"2207.07732","S\'ebastien Lachapelle","S\'ebastien Lachapelle and Simon Lacoste-Julien","Partial Disentanglement via Mechanism Sparsity","Appears in: The First Workshop on Causal Representation Learning (CRL
  2022) at UAI. 26 pages",,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  Disentanglement via mechanism sparsity was introduced recently as a
principled approach to extract latent factors without supervision when the
causal graph relating them in time is sparse, and/or when actions are observed
and affect them sparsely. However, this theory applies only to ground-truth
graphs satisfying a specific criterion. In this work, we introduce a
generalization of this theory which applies to any ground-truth graph and
specifies qualitatively how disentangled the learned representation is expected
to be, via a new equivalence relation over models we call consistency. This
equivalence captures which factors are expected to remain entangled and which
are not based on the specific form of the ground-truth graph. We call this
weaker form of identifiability partial disentanglement. The graphical criterion
that allows complete disentanglement, proposed in an earlier work, can be
derived as a special case of our theory. Finally, we enforce graph sparsity
with constrained optimization and illustrate our theory and algorithm in
simulations.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 20:06:12 GMT""}]","2022-07-19"
"2207.07733","Makana Silva","Makana Silva and Christopher Hirata","Dynamical perturbations around an extreme mass ratio inspiral near
  resonance","19 pages, 5 figures, 1 table, to be submitted to PRD",,"10.1103/PhysRevD.106.084058",,"gr-qc astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Extreme mass ratio inspirals (EMRIs) -- systems with a compact object
orbiting a much more massive (e.g., galactic center) black hole -- are of
interest both as a new probe of the environments of galactic nuclei, and their
waveforms are a precision test of the Kerr metric. This work focuses on the
effects of an external perturbation due to a third body around an EMRI system.
This perturbation will affect the orbit most significantly when the inner body
crosses a resonance with the outer body, and result in a change of the
conserved quantities (energy, angular momentum, and Carter constant) or
equivalently of the actions, which results in a subsequent phase shift of the
waveform that builds up over time. We present a general method for calculating
the changes in action during a resonance crossing, valid for generic orbits in
the Kerr spacetime. We show that these changes are related to the gravitational
waveforms emitted by the two bodies (quantified by the amplitudes of the Weyl
scalar $\psi_4$ at the horizon and at $\infty$) at the frequency corresponding
to the resonance. This allows us to compute changes in the action variables for
each body, without directly computing the explicit metric perturbations, and
therefore we can carry out the computation by calling an existing black hole
perturbation theory code. We show that our calculation can probe resonant
interactions in both the static and dynamical limit. We plan to use this
technique for future investigations of third-body effects in EMRIs and their
potential impact on waveforms for LISA.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 20:09:32 GMT""}]","2022-11-09"
"2207.07734","Haiyi Mao","Haiyi Mao, Minxue Jia, Jason Xiaotian Dou, Haotian Zhang, Panayiotis
  V. Benos","COEM: Cross-Modal Embedding for MetaCell Identification","5 pages, 2 figures, ICML workshop on computational biology",,,,"q-bio.GN cs.AI cs.GL","http://creativecommons.org/licenses/by/4.0/","  Metacells are disjoint and homogeneous groups of single-cell profiles,
representing discrete and highly granular cell states. Existing metacell
algorithms tend to use only one modality to infer metacells, even though
single-cell multi-omics datasets profile multiple molecular modalities within
the same cell. Here, we present \textbf{C}ross-M\textbf{O}dal
\textbf{E}mbedding for \textbf{M}etaCell Identification (COEM), which utilizes
an embedded space leveraging the information of both scATAC-seq and scRNA-seq
to perform aggregation, balancing the trade-off between fine resolution and
sufficient sequencing coverage. COEM outperforms the state-of-the-art method
SEACells by efficiently identifying accurate and well-separated metacells
across datasets with continuous and discrete cell types. Furthermore, COEM
significantly improves peak-to-gene association analyses, and facilitates
complex gene regulatory inference tasks.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 20:17:50 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jul 2022 03:10:31 GMT""}]","2022-07-26"
"2207.07735","W.D. van Suijlekom","Mick Gielen and Walter D. van Suijlekom","Operator systems for tolerance relations on finite sets","16 pages",,,,"math.OA","http://creativecommons.org/licenses/by/4.0/","  We study the duals of a certain class of finite-dimensional operator systems,
namely the class of operator systems associated to tolerance relations on
finite sets or equivalently the class of operator systems that are associated
with graphs. In the case where the graphs associated with these operator
systems are chordal we are able to find concrete realizations of their duals as
sitting inside of finite-dimensional $C^*$-algebras. We then use these concrete
realizations to compute the $C^*$-envelopes, propagation numbers and extremal
rays of these duals in the chordal case. Finally, we exemplify our results by
applying them to operator systems of band matrices.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 20:18:13 GMT""}]","2022-07-19"
"2207.07736","James Gleeson","James Gleeson, Daniel Snider, Yvonne Yang, Moshe Gabel, Eyal de Lara,
  Gennady Pekhimenko","Optimizing Data Collection in Deep Reinforcement Learning","MLBench 2022 ( https://memani1.github.io/mlbench22/ ) camera ready
  submission",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reinforcement learning (RL) workloads take a notoriously long time to train
due to the large number of samples collected at run-time from simulators.
Unfortunately, cluster scale-up approaches remain expensive, and commonly used
CPU implementations of simulators induce high overhead when switching back and
forth between GPU computations. We explore two optimizations that increase RL
data collection efficiency by increasing GPU utilization: (1) GPU
vectorization: parallelizing simulation on the GPU for increased hardware
parallelism, and (2) simulator kernel fusion: fusing multiple simulation steps
to run in a single GPU kernel launch to reduce global memory bandwidth
requirements. We find that GPU vectorization can achieve up to $1024\times$
speedup over commonly used CPU simulators. We profile the performance of
different implementations and show that for a simple simulator, ML compiler
implementations (XLA) of GPU vectorization outperform a DNN framework (PyTorch)
by $13.4\times$ by reducing CPU overhead from repeated Python to DL backend API
calls. We show that simulator kernel fusion speedups with a simple simulator
are $11.3\times$ and increase by up to $1024\times$ as simulator complexity
increases in terms of memory bandwidth requirements. We show that the speedups
from simulator kernel fusion are orthogonal and combinable with GPU
vectorization, leading to a multiplicative speedup.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 20:22:31 GMT""}]","2022-07-19"
"2207.07737","Tom Steudtner","Gudrun Hiller, Tim H\""ohne, Daniel F. Litim, Tom Steudtner","Portals into Higgs vacuum stability","18 pages, 16 figures. v2: match published version",,"10.1103/PhysRevD.106.115004","DO-TH 21/08","hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address the notorious metastability of the standard model (SM) and promote
it to a model building task: What are the new ingredients required to stabilize
the SM up to the Planck scale without encountering subplanckian Landau poles?
Using the SM extended by vector-like fermions (VLFs), we chart out the
corresponding landscape of Higgs stability. We find that the gauge portal
mechanism, triggered by new SM charge carriers, opens up sizeable room for
stability in a minimally invasive manner. We also find models with Higgs
criticality, and Yukawa portals opening up at stronger coupling. Several models
allow for VLFs in the TeV-range, which can be searched for at the LHC. For
nontrivial flavor structure severe flavor-changing neutral current constraints
arise which complement those from stability, and push lower fermion masses up
to $\mathcal{O}(10^3\,\text{TeV})$.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 20:22:35 GMT""},{""version"":""v2"",""created"":""Wed, 30 Nov 2022 20:02:39 GMT""}]","2022-12-14"
"2207.07739","Chen Liu","Chen Liu, Xiaomeng Dong, Michael Potter, Hsi-Ming Chang, Ravi Soni","Adversarial Focal Loss: Asking Your Discriminator for Hard Examples",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  Focal Loss has reached incredible popularity as it uses a simple technique to
identify and utilize hard examples to achieve better performance on
classification. However, this method does not easily generalize outside of
classification tasks, such as in keypoint detection. In this paper, we propose
a novel adaptation of Focal Loss for keypoint detection tasks, called
Adversarial Focal Loss (AFL). AFL not only is semantically analogous to Focal
loss, but also works as a plug-and-chug upgrade for arbitrary loss functions.
While Focal Loss requires output from a classifier, AFL leverages a separate
adversarial network to produce a difficulty score for each input. This
difficulty score can then be used to dynamically prioritize learning on hard
examples, even in absence of a classifier. In this work, we show AFL's
effectiveness in enhancing existing methods in keypoint detection and verify
its capability to re-weigh examples based on difficulty.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 20:26:32 GMT""}]","2022-07-19"
"2207.07740","Quoc Hung Ngo","Quoc Hung Ngo, Tahar Kechadi, Nhien-An Le-Khac","Knowledge Representation in Digital Agriculture: A Step Towards
  Standardised Model",,"Computers and Electronics in Agriculture 199 (2022): 107127","10.1016/j.compag.2022.107127",,"cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In recent years, data science has evolved significantly. Data analysis and
mining processes become routines in all sectors of the economy where datasets
are available. Vast data repositories have been collected, curated, stored, and
used for extracting knowledge. And this is becoming commonplace. Subsequently,
we extract a large amount of knowledge, either directly from the data or
through experts in the given domain. The challenge now is how to exploit all
this large amount of knowledge that is previously known for efficient
decision-making processes. Until recently, much of the knowledge gained through
a number of years of research is stored in static knowledge bases or
ontologies, while more diverse and dynamic knowledge acquired from data mining
studies is not centrally and consistently managed. In this research, we propose
a novel model called ontology-based knowledge map to represent and store the
results (knowledge) of data mining in crop farming to build, maintain, and
enrich the process of knowledge discovery. The proposed model consists of six
main sets: concepts, attributes, relations, transformations, instances, and
states. This model is dynamic and facilitates the access, updates, and
exploitation of the knowledge at any time. This paper also proposes an
architecture for handling this knowledge-based model. The system architecture
includes knowledge modelling, extraction, assessment, publishing, and
exploitation. This system has been implemented and used in agriculture for crop
management and monitoring. It is proven to be very effective and promising for
its extension to other domains.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 20:31:56 GMT""}]","2022-07-19"
"2207.07741","Paul M. Terwilliger","Paul Terwilliger","Tridiagonal pairs, alternating elements, and distance-regular graphs","39 pages, 9 diagrams",,,,"math.CO math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The positive part $U^+_q$ of $U_q(\hat{\mathfrak{sl}}_2)$ has a presentation
with two generators $W_0$, $W_1$ and two relations called the $q$-Serre
relations. The algebra $U^+_q$ contains some elements, said to be alternating.
There are four kinds of alternating elements, denoted $\lbrace
W_{-k}\rbrace_{k\in \mathbb N}$, $\lbrace W_{k+1}\rbrace_{k\in \mathbb N}$,
$\lbrace G_{k+1}\rbrace_{k\in \mathbb N}$, $\lbrace {\tilde G}_{k+1}\rbrace_{k
\in \mathbb N}$. The alternating elements of each kind mutually commute. A
tridiagonal pair is an ordered pair of diagonalizable linear maps $A, A^*$ on a
nonzero, finite-dimensional vector space $V$, that each act in a (block)
tridiagonal fashion on the eigenspaces of the other one. Let $A$, $A^*$ denote
a tridiagonal pair on $V$. Associated with this pair are six well-known direct
sum decompositions of $V$; these are the eigenspace decompositions of $A$ and
$A^*$, along with four decompositions of $V$ that are often called split.
  In our main results, we assume that $A$, $A^*$ has $q$-Serre type. Under this
assumption $A$, $A^*$ satisfy the $q$-Serre relations, and $V$ becomes an
irreducible $U^+_q$-module on which $W_0=A$ and $W_1=A^*$. We describe how the
alternating elements of $U^+_q$ act on the above six decompositions of $V$. We
show that for each decomposition, every alternating element acts in either a
(block) diagonal, (block) upper bidiagonal, (block) lower bidiagonal, or
(block) tridiagonal fashion. We investigate two special cases in detail. In the
first case the eigenspaces of $A$ and $A^*$ all have dimension one. In the
second case $A$ and $A^*$ are obtained by adjusting the adjacency matrix and a
dual adjacency matrix of a distance-regular graph that has classical parameters
and is formally self-dual.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 20:32:06 GMT""}]","2022-07-19"
"2207.07742","Jakub Rozlivek","Jan Docekal, Jakub Rozlivek, Jiri Matas, and Matej Hoffmann","Human keypoint detection for close proximity human-robot interaction","8 pages 8 figures","IEEE-RAS International Conference on Humanoid Robots (Humanoids
  2022)","10.1109/Humanoids53995.2022.10000133",,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the performance of state-of-the-art human keypoint detectors in the
context of close proximity human-robot interaction. The detection in this
scenario is specific in that only a subset of body parts such as hands and
torso are in the field of view. In particular, (i) we survey existing datasets
with human pose annotation from the perspective of close proximity images and
prepare and make publicly available a new Human in Close Proximity (HiCP)
dataset; (ii) we quantitatively and qualitatively compare state-of-the-art
human whole-body 2D keypoint detection methods (OpenPose, MMPose, AlphaPose,
Detectron2) on this dataset; (iii) since accurate detection of hands and
fingers is critical in applications with handovers, we evaluate the performance
of the MediaPipe hand detector; (iv) we deploy the algorithms on a humanoid
robot with an RGB-D camera on its head and evaluate the performance in 3D human
keypoint detection. A motion capture system is used as reference.
  The best performing whole-body keypoint detectors in close proximity were
MMPose and AlphaPose, but both had difficulty with finger detection. Thus, we
propose a combination of MMPose or AlphaPose for the body and MediaPipe for the
hands in a single framework providing the most accurate and robust detection.
We also analyse the failure modes of individual detectors -- for example, to
what extent the absence of the head of the person in the image degrades
performance. Finally, we demonstrate the framework in a scenario where a
humanoid robot interacting with a person uses the detected 3D keypoints for
whole-body avoidance maneuvers.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 20:33:29 GMT""},{""version"":""v2"",""created"":""Thu, 9 Feb 2023 19:51:34 GMT""}]","2023-02-13"
"2207.07743","Chuang Niu","Chuang Niu and Ge Wang","HOME: High-Order Mixed-Moment-based Embedding for Representation
  Learning",,,,,"cs.LG cs.AI cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Minimum redundancy among different elements of an embedding in a latent space
is a fundamental requirement or major preference in representation learning to
capture intrinsic informational structures. Current self-supervised learning
methods minimize a pair-wise covariance matrix to reduce the feature redundancy
and produce promising results. However, such representation features of
multiple variables may contain the redundancy among more than two feature
variables that cannot be minimized via the pairwise regularization. Here we
propose the High-Order Mixed-Moment-based Embedding (HOME) strategy to reduce
the redundancy between any sets of feature variables, which is to our best
knowledge the first attempt to utilize high-order statistics/information in
this context. Multivariate mutual information is minimum if and only if
multiple variables are mutually independent, which suggests the necessary
conditions of factorized mixed moments among multiple variables. Based on these
statistical and information theoretic principles, our general HOME framework is
presented for self-supervised representation learning. Our initial experiments
show that a simple version in the form of a three-order HOME scheme already
significantly outperforms the current two-order baseline method (i.e., Barlow
Twins) in terms of the linear evaluation on representation features.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 20:34:49 GMT""}]","2022-07-19"
"2207.07744","Kourosh Shoele","Patrick S. Eastham, Hadi Mohammadigoushki, Kourosh Shoele","Squirmer locomotion in a yield stress fluid",,,"10.1017/jfm.2022.743",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An axisymmetric squirmer in a Bingham viscoplastic fluid is studied
numerically to determine the effect of a yield stress environment on
locomotion. The nonlinearity of the governing equations necessitates numerical
methods, which is accomplished by solving a variable-viscosity Stokes equation
with a Finite Element approach. The effects of stroke modes, both pure and
combined, are investigated and it is found that for the treadmill or ""neutral""
mode, the swimmer in a yield stress fluid has a lower swimming velocity and
uses more power. However, the efficiency of swimming reaches its maximum at a
finite yield limit. In addition, for higher yield limits, higher stroke modes
can increase the swimming velocity and hydrodynamic efficiency of the treadmill
swimmer. The higher-order odd-numbered squirming modes, particularly the third
stroke mode, can generate propulsion by themselves that increases in strength
as the viscoplastic nonlinearity increases till a specific limit. These results
are closely correlated with the confinement effects induced by the viscoplastic
rigid surface surrounding the swimming body, showing that swimmers in
viscoplastic environments, both biological and artificial, could potentially
employ other non-standard swimming strategies to optimize their locomotion.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 20:35:06 GMT""}]","2022-09-28"
"2207.07745","Congying Wang","Congying Wang, Jia Yu","GLIN: A Lightweight Learned Indexing Mechanism for Complex Geometries",,,,,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Although spatial index structures shorten the query response time, they rely
on complex tree structures to narrow down the search space. Such structures in
turn yield additional storage overhead and take a toll on index maintenance.
Recently, there has been a flurry on works attempting to leverage
machine-Learning(ML) models to simplify the index structures. Some follow-up
works extend the idea to support geospatial point data. These approaches
partition the multidimensional space to cells and assign IDs to these cells
using space-filling curve(e.g., Z-order curve) or mathematical equations. These
approaches work well for geospatial points but are not able to handle complex
geometries such as polygons and trajectories which are widely available in
geospatial data.
  This paper introduces GLIN, a lightweight learned index for spatial range
queries on complex geometries. To achieve that, GLIN transforms geometries to
Z-address intervals, and builds a hierarchical model to learn the cumulative
distribution function between these intervals and the record positions. The
lightweight hierarchical model greatly shortens the index probing time.
Furthermore, GLIN augments spatial query windows using an add-on function to
guarantee the query accuracy for both Contains and Intersects spatial
relationships. Our experiments on real-world and synthetic datasets show that
GLIN occupies 40-70 times less storage overhead than popular spatial indexes
such as Quad-Tree while still showing similar query response time in medium
selectivity queries. Moreover, GLIN's maintenance speed is around 1.5 times
higher on insertion and 3-5 times higher on deletion.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 20:36:37 GMT""}]","2022-07-19"
"2207.07746","Karthik Reddy Peddireddy","Karthik R. Peddireddy, Ryan Clairmont, and Rae M. Robertson-Anderson","Polymer threadings and rigidity dictate the viscoelasticity and
  nonlinear relaxation dynamics of entangled ring-linear blends and their
  composites with rigid rod microtubules","22 pages, 8 figures",,"10.1122/8.0000529",,"cond-mat.soft cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Mixtures of polymers of varying topologies and stiffnesses display complex
emergent rheological properties that often cannot be predicted from their
single-component counterparts. For example, entangled blends of ring and linear
polymers have been shown to exhibit enhanced shear thinning and viscosity, as
well as prolonged relaxation timescales, compared to pure solutions of rings or
linear chains. These emergent properties arise in part from the synergistic
threading of rings by linear polymers. Topology has also been shown to play an
important role in composites of flexible (e.g., DNA) and stiff (e.g.,
microtubules) polymers, whereby rings promote mixing while linear polymers
induce de-mixing and flocculation of stiff polymers, with these
topology-dependent interactions giving rise to highly distinct rheological
signatures. To shed light on these intriguing phenomena, we use optical
tweezers microrheology to measure the linear and nonlinear rheological
properties of entangled ring-linear DNA blends and their composites with rigid
microtubules. We show that the linear viscoelasticity is primarily dictated by
the microtubules at lower frequencies, but their contributions become frozen
out at frequencies above the DNA entanglement rate. In the nonlinear regime, we
reveal that mechanical response features, such as shear thinning, stress
softening and multi-modal relaxation dynamics are mediated by entropic
stretching, threading, and flow alignment of entangled DNA, as well as forced
de-threading, disentanglement, and clustering. The contributions of each of
these mechanisms depend on the strain rate as well as the entanglement density
and stiffness of the polymers, leading to non-monotonic rate dependences of
mechanical properties that are most pronounced for highly concentrated
ring-linear blends rather than DNA-MT composites.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 20:45:05 GMT""}]","2022-11-23"
"2207.07747","Paul M. Terwilliger","Paul Terwilliger","Distance-regular graphs, the subconstituent algebra, and the
  $Q$-polynomial property","60 pages; typos corrected",,,,"math.CO math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This survey paper contains a tutorial introduction to distance-regular
graphs, with an emphasis on the subconstituent algebra and the $Q$-polynomial
property.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 20:45:08 GMT""},{""version"":""v2"",""created"":""Sat, 27 Aug 2022 21:09:36 GMT""}]","2022-08-30"
"2207.07748","Ioannis Chatzigeorgiou","Ioannis Chatzigeorgiou and Francisco A. Monteiro","Symbol-Level GRAND for High-Order Modulation over Flat Fading Channels","5 pages, 5 figures, 1 table",,"10.1109/LCOMM.2022.3227593",,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Guessing random additive noise decoding (GRAND) is a noise-centric decoding
method, which is suitable for ultra-reliable low-latency communications, as it
supports high-rate error correction codes that generate short-length codewords.
GRAND estimates transmitted codewords by guessing the error patterns that
altered them during transmission. The guessing process requires the generation
and testing of error patterns that are arranged in increasing order of Hamming
weight. This approach is fitting for binary transmission over additive white
Gaussian noise channels. This letter considers transmission of coded and
modulated data over flat fading channels and proposes a variant of GRAND, which
leverages information on the modulation scheme and the fading channel. In the
core of the proposed variant, referred to as symbol-level GRAND, is an
analytical expression that computes the probability of occurrence of an error
pattern and determines the order with which error patterns are tested.
Simulation results demonstrate that symbol-level GRAND produces estimates of
the transmitted codewords notably faster than the original GRAND at the cost of
a small increase in memory requirements.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 20:46:33 GMT""}]","2022-12-12"
"2207.07749","Md Masudur Rahman","Md Masudur Rahman and Yexiang Xue","Bootstrap State Representation using Style Transfer for Better
  Generalization in Deep Reinforcement Learning","Accepted at ECML-PKDD 2022",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Deep Reinforcement Learning (RL) agents often overfit the training
environment, leading to poor generalization performance. In this paper, we
propose Thinker, a bootstrapping method to remove adversarial effects of
confounding features from the observation in an unsupervised way, and thus, it
improves RL agents' generalization. Thinker first clusters experience
trajectories into several clusters. These trajectories are then bootstrapped by
applying a style transfer generator, which translates the trajectories from one
cluster's style to another while maintaining the content of the observations.
The bootstrapped trajectories are then used for policy learning. Thinker has
wide applicability among many RL settings. Experimental results reveal that
Thinker leads to better generalization capability in the Procgen benchmark
environments compared to base algorithms and several data augmentation
techniques.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 20:49:45 GMT""}]","2022-07-19"
"2207.07750","Rubab Amin","Rubab Amin, James Greenberg, Brendan Heffernan, Tadao Nagatsuma, and
  Antoine Rolland","Exceeding octave tunable Terahertz waves with zepto-second level timing
  noise","31 pages",,,,"physics.optics physics.app-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Spectral purity of any millimeter wave (mmW) source is of the utmost interest
in low-noise applications. Optical synthesis via photomixing is an attractive
source for such mmWs, which usually involves expensive spectrally pure lasers
with narrow linewidths approaching monochromaticity due to their inherent
fabrication costs or specifications. Here, we report an alternative option for
enhancing the spectral purity of inexpensive semiconductor diode lasers via a
self-injection locking technique through corresponding Stokes waves from a
fiber Brillouin cavity exhibiting greatly improved phase noise levels and large
wavelength tunability of ~1.8 nm. We implement a system with two self-injected
diode lasers on a common Brillouin cavity aimed at difference frequency
generation in the mmW and THz region. We generate tunable sub-mmW (0.3 and 0.5
THz) waves by beating the self-injected two wavelength Stokes light on a
uni-travelling carrier photodiode and characterize the noise performance. The
sub-mmW features miniscule timing noise levels in the zepto-second (zs.Hz^-0.5)
scale outperforming the state of the art dissipative Kerr soliton based
micro-resonator setups while offering broader frequency tunability. These
results suggest a viable inexpensive alternative for mmW sources aimed at
low-noise applications featuring lab-scale footprints and rack-mounted
portability while paving the way for chip-scale photonic integration.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 20:53:07 GMT""}]","2022-07-19"
"2207.07751","Lishuo Pan","Lishuo Pan, Sandeep Manjanna, M. Ani Hsieh","MARLAS: Multi Agent Reinforcement Learning for cooperated Adaptive
  Sampling","15 pages, 9 figures, accepted to DARS 2022",,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  The multi-robot adaptive sampling problem aims at finding trajectories for a
team of robots to efficiently sample the phenomenon of interest within a given
endurance budget of the robots. In this paper, we propose a robust and scalable
approach using Multi-Agent Reinforcement Learning for cooperated Adaptive
Sampling (MARLAS) of quasi-static environmental processes. Given a prior on the
field being sampled, the proposed method learns decentralized policies for a
team of robots to sample high-utility regions within a fixed budget. The
multi-robot adaptive sampling problem requires the robots to coordinate with
each other to avoid overlapping sampling trajectories. Therefore, we encode the
estimates of neighbor positions and intermittent communication between robots
into the learning process. We evaluated MARLAS over multiple performance
metrics and found it to outperform other baseline multi-robot sampling
techniques. Additionally, we demonstrate scalability with both the size of the
robot team and the size of the region being sampled. We further demonstrate
robustness to communication failures and robot failures. The experimental
evaluations are conducted both in simulations on real data and in real robot
experiments on demo environmental setup.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 20:57:29 GMT""},{""version"":""v2"",""created"":""Sat, 1 Oct 2022 21:00:19 GMT""},{""version"":""v3"",""created"":""Tue, 28 Feb 2023 20:42:04 GMT""}]","2023-03-02"
"2207.07752","Laurent Mahy","L. Mahy, H. Sana, T. Shenar, K. Sen, N. Langer, P. Marchant, M.
  Abdul-Masih, G. Banyard, J. Bodensteiner, D. M. Bowman, K. Dsilva, M. Fabry,
  C. Hawcroft, S. Janssens, T. Van Reeth and C. Eldridge","Identifying quiescent compact objects in massive Galactic single-lined
  spectroscopic binaries","20 pages (31 pages of Appendix), 19 figures, A&A in press. The
  abstract is shorter than in the paper, and some figures, and tables have been
  cut in the paper",,"10.1051/0004-6361/202243147",,"astro-ph.SR astro-ph.GA astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Aims. To search for these rare objects, we study 32 Galactic O-type stars
that were reported as SB1s in the literature. In our sample we include Cyg X-1,
which is known to host an accreting stellar-mass BH, and HD 74194, a supergiant
fast X-ray transient, in order to validate our methodology. The final goal is
to characterise the nature of the unseen companions to determine if they are MS
stars, stripped helium stars, triples, or compact objects such as neutron stars
or stellar-mass BHs. Methods. After measuring radial velocities and deriving
orbital solutions for all the systems in our sample, we performed spectral
disentangling to extract putative signatures of faint secondary companions from
the composite spectra. We derived stellar parameters for the visible stars and
estimated the mass ranges of the secondary stars using the binary mass
function. Variability observed in the photometric TESS light curves was also
searched for indications of the presence of putative companions, degenerate or
not. Results. In 17 of the 32 systems reported as SB1s, we extract secondary
signatures, down to mass ratios of ~0.15. For the 17 newly detected
double-lined spectroscopic binaries (SB2s), we derive physical properties of
the individual components and discuss why they have not been detected as such
before. Among the remaining systems, we identify nine systems with possible NS
or low-mass MS companions. For Cyg X-1 and HD 130298, we are not able to
extract any signatures for the companions, and the minimum masses of their
companions are estimated to be about 7Msun. Our simulations show that
secondaries with such a mass should be detectable from our dataset, no matter
their nature: MS stars, stripped helium stars or even triples. While this is
expected for Cyg X-1, confirming our methodology, our simulations also strongly
suggest that HD 130298 could be another candidate to host a stellar-mass BH.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 21:02:28 GMT""}]","2022-08-31"
"2207.07753","Jeroen Van Der Donckt","Jeroen Van Der Donckt, Jonas Van Der Donckt, Emiel Deprost, Nicolas
  Vandenbussche, Michael Rademaker, Gilles Vandewiele, Sofie Van Hoecke","Do Not Sleep on Traditional Machine Learning: Simple and Interpretable
  Techniques Are Competitive to Deep Learning for Sleep Scoring","The first two authors contributed equally. Accepted to Biomedical
  Signal Processing and Control",,"10.1016/j.bspc.2022.104429",,"stat.ML cs.AI cs.LG eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Over the last few years, research in automatic sleep scoring has mainly
focused on developing increasingly complex deep learning architectures.
However, recently these approaches achieved only marginal improvements, often
at the expense of requiring more data and more expensive training procedures.
Despite all these efforts and their satisfactory performance, automatic sleep
staging solutions are not widely adopted in a clinical context yet. We argue
that most deep learning solutions for sleep scoring are limited in their
real-world applicability as they are hard to train, deploy, and reproduce.
Moreover, these solutions lack interpretability and transparency, which are
often key to increase adoption rates. In this work, we revisit the problem of
sleep stage classification using classical machine learning. Results show that
competitive performance can be achieved with a conventional machine learning
pipeline consisting of preprocessing, feature extraction, and a simple machine
learning model. In particular, we analyze the performance of a linear model and
a non-linear (gradient boosting) model. Our approach surpasses state-of-the-art
(that uses the same data) on two public datasets: Sleep-EDF SC-20 (MF1 0.810)
and Sleep-EDF ST (MF1 0.795), while achieving competitive results on Sleep-EDF
SC-78 (MF1 0.775) and MASS SS3 (MF1 0.817). We show that, for the sleep stage
scoring task, the expressiveness of an engineered feature vector is on par with
the internally learned representations of deep learning models. This
observation opens the door to clinical adoption, as a representative feature
vector allows to leverage both the interpretability and successful track record
of traditional machine learning models.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 21:03:11 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jul 2022 12:56:54 GMT""},{""version"":""v3"",""created"":""Wed, 14 Dec 2022 12:24:01 GMT""}]","2022-12-15"
"2207.07754","Kyoung Min Yoo","Kyoung Min Yoo, May Hlaing, Sourabh Jain, James Fan, Yue An, and Ray
  T. Chen","Lab-on-a-Chip Optical Biosensor Platform: Micro Ring Resonator
  Integrated with Near-Infrared Fourier Transform Spectrometer","23 pages, 9 figures including supplementary",,,,"physics.optics physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A micro-ring-resonator (MRR) optical biosensor based on the evanescent field
sensing mechanism has been extensively studied due to its high sensitivity and
compact device size. However, a suitable on-chip integrated spectrometer device
has to be demonstrated for the lab-on-a-chip applications, which can read the
resonance wavelength shift from MRR biosensors based on minuscule changes in
refractive index. In this paper, we demonstrated the design and experimental
results of the near-infrared lab-on-a-chip optical biosensor platform that
monolithically integrates the MRR and the on-chip spectrometer on the
silicon-on-insulator (SOI) wafer, which can eliminate the external optical
spectrum analyzer for scanning the wavelength spectrum. The symmetric add-drop
MRR biosensor is designed to have a free spectral range (FSR) of ~19 nm, and a
bulk sensitivity of ~73 nm/RIU; then the drop-port output resonance peaks are
reconstructed from the integrated spatial-heterodyne Fourier transform
spectrometer (SHFTS) with the spectral resolution of ~3.1 nm and bandwidth of
~50 nm, which results in the limit of detection of 0.042 RIU. The MRR output
spectrum with air- and water-claddings are measured and reconstructed from the
MRR-SHFTS integrated device experimentally to validate the wavelength shifting
measurement.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 21:05:01 GMT""}]","2022-07-19"
"2207.07755","Arash Amini","Arash Amini, Cong Zheng, Qiyu Sun and Nader Motee","Carleman Linearization of Nonlinear Systems and Its Finite-Section
  Approximations","25 Pages, 10 figures",,,,"math.DS cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Carleman linearization is one of the mainstream approaches to lift a
finite-dimensional nonlinear dynamical system into an infinite-dimensional
linear system with the promise of providing accurate approximations of the
original nonlinear system over larger regions around the equilibrium for longer
time horizons with respect to the conventional first-order linearization
approach. Finite-section approximations of the lifted system has been widely
used to study dynamical and control properties of the original nonlinear
system. In this context, some of the outstanding problems are to determine
under what conditions, as the finite-section order (i.e., truncation length)
increases, the trajectory of the resulting approximate linear system from the
finite-section scheme converges to that of the original nonlinear system and
whether the time interval over which the convergence happens can be quantified
explicitly. In this paper, we provide explicit error bounds for the
finite-section approximation and prove that the convergence is indeed
exponential with respect to the finite-section order. For a class of nonlinear
systems, it is shown that one can achieve exponential convergence over the
entire time horizon up to infinity. Our results are practically plausible as
our proposed error bound estimates can be used to compute proper truncation
lengths for a given application, e.g., determining proper sampling period for
model predictive control and reachability analysis for safety verifications. We
validate our theoretical findings through several illustrative simulations.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 21:05:30 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jul 2022 21:42:26 GMT""}]","2022-07-21"
"2207.07756","Donald Robinson","Donald A. Robinson, Michael E. Foster, Christopher H. Bennett, Austin
  Bhandarkar, Elizabeth R. Webster, Aleyna Celebi, Nisa Celebi, Elliot J.
  Fuller, Vitalie Stavila, Catalin D. Spataru, David S. Ashby, Matthew J.
  Marinella, Raga Krishnakumar, Mark D. Allendorf, and A. Alec Talin","Tunable intervalence charge transfer in ruthenium Prussian blue analogue
  enables stable and efficient biocompatible artificial synapses",,,,,"cond-mat.mtrl-sci cond-mat.dis-nn physics.app-ph physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  Emerging concepts for neuromorphic computing, bioelectronics, and
brain-computer interfacing inspire new research avenues aimed at understanding
the relationship between oxidation state and conductivity in unexplored
materials. Here, we present ruthenium Prussian blue analogue (RuPBA), a mixed
valence coordination compound with an open framework structure and ability to
conduct both ionic and electronic charge, for flexible artificial synapses that
reversibly switch conductance by more than four orders of magnitude based on
electrochemically tunable oxidation state. Retention of programmed states is
improved by nearly two orders of magnitude compared to the extensively studied
organic polymers, thus reducing the frequency, complexity and energy costs
associated with error correction schemes. We demonstrate dopamine detection
using RuPBA synapses and biocompatibility with neuronal cells, evoking
prospective application for brain-computer interfacing. By application of
electron transfer theory to in-situ spectroscopic probing of intervalence
charge transfer, we elucidate a switching mechanism whereby the degree of mixed
valency between N-coordinated Ru sites controls the carrier concentration and
mobility, as supported by DFT.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 21:06:43 GMT""}]","2022-07-19"
"2207.07757","Cheng-Ming Li","Cheng-Ming Li, Shu-Yu Zuo, Ya-Peng Zhao, Hui-Jun Mu, Yong-Feng Huang","The study of nonstrange quark stars within a modified NJL model","9 pages, 9 figures",,"10.1103/PhysRevD.106.116009",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, a modified Nambu-Jona-Lasinio (NJL) model with proper-time
regularization is employed to study the structure of nonstrange quark stars.
The coupling constant of four-fermion interaction in the conventional NJL model
is modified as $G=G_1+G_2\langle\bar{\psi}\psi\rangle$ to highlight the
feedback of quark propagator to gluon propagator. To study the dependence of
the equation of state (EOS) on this modification as well as the vacuum
pressure, we choose nine representative EOSs for comparison. It is found that a
smaller $G_1$ leads to a stiffer EOS, and a higher vacuum pressure (i.e., a
smaller bag constant) yields a softer EOS at low energy density. It is further
shown that the heaviest quark star under this modified NJL model satisfies not
only the recent mass measurement of PSR J0740+6620, but also the radius
constraints from X-ray timing observations. The corresponding tidal
deformability is also in agreement with the observations of GW170817.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 21:19:48 GMT""},{""version"":""v2"",""created"":""Sat, 8 Oct 2022 13:08:12 GMT""}]","2022-12-28"
"2207.07758","Yizhe Xu","Yizhe Xu, Nikolaos Ignatiadis, Erik Sverdrup, Scott Fleming, Stefan
  Wager, Nigam Shah","Treatment Heterogeneity for Survival Outcomes","A chapter of the 'Handbook of Matching and Weighting Adjustments for
  Causal Inference'",,,,"stat.AP","http://creativecommons.org/licenses/by/4.0/","  Estimation of conditional average treatment effects (CATEs) plays an
essential role in modern medicine by informing treatment decision-making at a
patient level. Several metalearners have been proposed recently to estimate
CATEs in an effective and flexible way by re-purposing predictive machine
learning models for causal estimation. In this chapter, we summarize the
literature on metalearners and provide concrete guidance for their application
for treatment heterogeneity estimation from randomized controlled trials' data
with survival outcomes. The guidance we provide is supported by a comprehensive
simulation study in which we vary the complexity of the underlying baseline
risk and CATE functions, the magnitude of the heterogeneity in the treatment
effect, the censoring mechanism, and the balance in treatment assignment. To
demonstrate the applicability of our findings, we reanalyze the data from the
Systolic Blood Pressure Intervention Trial (SPRINT) and the Action to Control
Cardiovascular Risk in Diabetes (ACCORD) study. While recent literature reports
the existence of heterogeneous effects of intensive blood pressure treatment
with multiple treatment effect modifiers, our results suggest that many of
these modifiers may be spurious discoveries. This chapter is accompanied by
survlearners, an R package that provides well-documented implementations of the
CATE estimation strategies described in this work, to allow easy use of our
recommendations as well as the reproduction of our numerical study.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 21:20:52 GMT""},{""version"":""v2"",""created"":""Tue, 6 Sep 2022 17:41:19 GMT""}]","2022-09-07"
"2207.07759","Qi Chang","Qi Chang, Danish Ahmad, Jennifer Toth, Rebecca Bascom, William E.
  Higgins","ESFPNet: efficient deep learning architecture for real-time lesion
  segmentation in autofluorescence bronchoscopic video","SPIE 2023 drafts update",,"10.1117/12.2647897",,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lung cancer tends to be detected at an advanced stage, resulting in a high
patient mortality rate. Thus, much recent research has focused on early disease
detection Bronchoscopy is the procedure of choice for an effective noninvasive
way of detecting early manifestations (bronchial lesions) of lung cancer. In
particular, autofluorescence bronchoscopy (AFB) discriminates the
autofluorescence properties of normal (green) and diseased tissue (reddish
brown) with different colors. Because recent studies show AFB's high
sensitivity in searching lesions, it has become a potentially pivotal method in
bronchoscopic airway exams. Unfortunately, manual inspection of AFB video is
extremely tedious and error prone, while limited effort has been expended
toward potentially more robust automatic AFB lesion analysis. We propose a
real-time (processing throughput of 27 frames/sec) deep-learning architecture
dubbed ESFPNet for accurate segmentation and robust detection of bronchial
lesions in AFB video streams. The architecture features an encoder structure
that exploits pretrained Mix Transformer (MiT) encoders and an efficient
stage-wise feature pyramid (ESFP) decoder structure. Segmentation results from
the AFB airway-exam videos of 20 lung cancer patients indicate that our
approach gives a mean Dice index = 0.756 and an average Intersection of Union =
0.624, results that are superior to those generated by other recent
architectures. Thus, ESFPNet gives the physician a potential tool for confident
real-time lesion segmentation and detection during a live bronchoscopic airway
exam. Moreover, our model shows promising potential applicability to other
domains, as evidenced by its state-of-the-art (SOTA) performance on the
CVC-ClinicDB, ETIS-LaribPolypDB datasets, and superior performance on the
Kvasir, CVC-ColonDB datasets.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 21:21:26 GMT""},{""version"":""v2"",""created"":""Thu, 25 Aug 2022 20:28:21 GMT""},{""version"":""v3"",""created"":""Fri, 9 Dec 2022 04:21:41 GMT""}]","2023-05-24"
"2207.07760","Oliver Siebert","Marius Lemm and Oliver Siebert","Thermal Area Law for Lattice Bosons","13 pages; 1 figure; v1->v2: result extended, new title",,,,"quant-ph cond-mat.stat-mech math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A physical system is said to satisfy a thermal area law if the mutual
information between two adjacent regions in the Gibbs state is controlled by
the area of their boundary. Thermal area laws have been derived for systems
with bounded local interactions such as quantum spin systems. However, for
lattice bosons these arguments break down because the interactions are
unbounded. We rigorously derive a thermal area law for a class of bosonic
Hamiltonians in any dimension which includes the paradigmatic Bose-Hubbard
model. The main idea to go beyond bounded interactions is to introduce a
quasi-free reference state with artificially decreased chemical potential by
means of a double Peierls-Bogoliubov estimate.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 21:28:00 GMT""},{""version"":""v2"",""created"":""Sun, 2 Oct 2022 14:23:36 GMT""}]","2022-10-04"
"2207.07761","Hunter Ray","Hunter Ray, Ryan Singer, Nisar Ahmed","A Review of the Operational Use of UAS in Public Safety Emergency
  Incidents","Accepted to the International Conference of Unmanned Aerial Systems
  (ICUAS) 2022",,,,"cs.HC cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  The domain of public safety in the form of search \& rescue, wildland
firefighting, structure firefighting, and law enforcement operations have drawn
great interest in the field of aerospace engineering, human-robot teaming,
autonomous systems, and robotics. However, a divergence exists in the
assumptions made in research and how state-of-the-art technologies may
realistically transition into an operational capacity. To aid in the alignment
between researchers, technologists, and end users, we aim to provide
perspective on how small Uncrewed Aerial Systems (sUAS) have been applied in
114 real world incidents as part of a technical rescue team from 2016 to 2021.
We highlight the main applications, integration, tasks, and challenges of
employing UAS within five primary use cases including searches, evidence
collection, SWAT, wildland firefighting, and structure firefighting. Within
these use cases, key incidents are featured that provide perspective on the
evolving and dynamic nature of UAS tasking during an operation. Finally, we
highlight key technical directions for improving the utilization and efficiency
of employing aerial technology in all emergency types.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 21:29:08 GMT""}]","2022-07-19"
"2207.07762","Andriaherimanana Sarobidy Razafimahatratra","Angelot Behajaina, Roghayeh Maleki, Andriaherimanana Sarobidy
  Razafimahatratra","Intersection density of imprimitive groups of degree $pq$",,,,,"math.CO math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A subset $\mathcal{F}$ of a finite transitive group $G\leq
\operatorname{Sym}(\Omega)$ is \emph{intersecting} if any two elements of
$\mathcal{F}$ agree on an element of $\Omega$. The \emph{intersection density}
of $G$ is the number $\rho(G) = \max\left\{ \frac{\mathcal{|F|}}{|G|/|\Omega|}
\mid \mathcal{F}\subset G \mbox{ is intersecting} \right\}$.
  Recently, Hujdurovi\'{c} et al. [Finite Fields Appl., 78 (2022), 101975]
disproved a conjecture of Meagher et al. (Conjecture~6.6~(3) in [ J.~Combin.
Theory, Ser. A 180 (2021), 105390]) by constructing equidistant cyclic codes
which yield transitive groups of degree $pq$, where $p = \frac{q^k-1}{q-1}$ and
$q$ are odd primes, and whose intersection density equal to $q$.
  In this paper, we use the cyclic codes given by Hujdurovi\'{c} et al. and
their permutation automorphisms to construct a family of transitive groups $G$
of degree $pq$ with $\rho(G) = \frac{q}{k}$, whenever $k<q<p=\frac{q^k-1}{q-1}$
are odd primes. Moreover, we extend their construction using cyclic codes of
higher dimension to obtain a new family of transitive groups of degree a
product of two odd primes $q<p = \frac{q^k-1}{q-1}$, and whose intersection
density are equal to $q$. Finally, we prove that if $G\leq
\operatorname{Sym}(\Omega)$ of degree a product of two arbitrary odd primes
$p>q$ and $\left\langle \bigcup_{\omega\in \Omega} G_\omega \right\rangle$ is a
proper subgroup, then $\rho(G) \in \{1,q\}$.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 21:34:59 GMT""}]","2022-07-19"
"2207.07763","Diego Fallas  Padilla","Diego Fallas Padilla, Han Pu, Guo-Jing Cheng, Yu-Yu Zhang","Understanding the quantum Rabi ring using analogies to quantum magnetism","14 pages, 6 figures",,"10.1103/PhysRevLett.129.183602",,"quant-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We map a quantum Rabi ring, consisting of $N$ cavities arranged in a ring
geometry, into an effective magnetic model containing the XY exchange and the
Dzyaloshinskii Moriya (DM) interactions. The analogue of the latter is induced
by an artificial magnetic field, which modulates photon hopping between
nearest-neighbor cavities with a phase. The mean-field behavior of both systems
is almost identical, facilitating the description of the different phases in
the quantum optical model through simple arguments of competing magnetic
interactions. For the square geometry ($N=4$) the rich phase diagram exhibits
three superradiant phases denoted as ferro-superradiant, antiferro-superradiant
and chiral superradiant. In particular, the DM interaction is responsible for
the chiral phase in which the energetically degenerate configurations of the
order parameters are similar to the in-plane magnetizations of skyrmions with
different helicities. The antiferro-superradiant phase is suppressed in the
triangle geometry ($N=3$) as geometric frustration contributes to stabilize the
chiral phase even for small values of the DM interaction. The chiral phases for
odd and even $N$ show a different scaling behavior close to the phase
transition. The equivalent behavior on both systems opens the possibility of
simulating chiral magnetism in a few-body quantum optical platform, as well as
understanding one system using the insights gained from the other.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 21:37:04 GMT""}]","2022-10-27"
"2207.07764","Atreyee Kundu","Atreyee Kundu","Input/output-to-state stability of switched systems under restricted
  switching","14 pages, no figure",,,,"math.OC cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper deals with input/output-to-state stability (IOSS) of
continuous-time switched nonlinear systems. Given a family of systems, possibly
containing unstable dynamics, and a set of restrictions on admissible switches
between the subsystems and admissible dwell times on the subsystems, we
identify a class of switching signals that obeys these restrictions and
preserves stability of the resulting switched system. The primary apparatus for
our analysis is multiple Lyapunov-like functions. Input-to-state stability
(ISS) and global asymptotic stability (GAS) of switched systems under
pre-specified restrictions on switching signals fall as special cases of our
results when no outputs (resp., also inputs) are considered.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 21:37:08 GMT""}]","2022-07-19"
"2207.07765","Hilson Shrestha","Hilson Shrestha, Kathleen Cachel, Mallak Alkhathlan, Elke
  Rundensteiner and Lane Harrison","FairFuse: Interactive Visual Support for Fair Consensus Ranking","5 pages, 4 figures; supplement: 4 pages",,,,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fair consensus building combines the preferences of multiple rankers into a
single consensus ranking, while ensuring any group defined by a protected
attribute (such as race or gender) is not disadvantaged compared to other
groups. Manually generating a fair consensus ranking is time-consuming and
impractical -- even for a fairly small number of candidates. While algorithmic
approaches for auditing and generating fair consensus rankings have been
developed, these have not been operationalized in interactive systems. To
bridge this gap, we introduce FairFuse, a visualization system for generating,
analyzing, and auditing fair consensus rankings. We construct a data model
which includes base rankings entered by rankers, augmented with measures of
group fairness, and algorithms for generating consensus rankings with varying
degrees of fairness. We design novel visualizations that encode these measures
in a parallel-coordinates style rank visualization, with interactions for
generating and exploring fair consensus rankings. We describe use cases in
which FairFuse supports a decision-maker in ranking scenarios in which fairness
is important, and discuss emerging challenges for future efforts supporting
fairness-oriented rank analysis. Code and demo videos available at
https://osf.io/hd639/.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 21:37:53 GMT""},{""version"":""v2"",""created"":""Mon, 1 Aug 2022 22:12:04 GMT""}]","2022-08-03"
"2207.07766","Pingzhi Li","Pingzhi Li, Johannes W. van der Jagt, Maarten Beens, Julian
  Hintermayr, Marcel Verheijen, Ren\'e Bruikman, Beatriz Barcones, Rom\'eo
  Juge, Reinoud Lavrijsen, Dafin\'e Ravelosona, Bert Koopmans","Enhancing All-Optical Switching of Magnetization by He Ion Irradiation",,,"10.1063/5.0111466",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/publicdomain/zero/1.0/","  All-optical switching (AOS) of magnetization by a single femtosecond laser
pulse in Co/Gd based synthetic ferrimagnets is the fastest magnetization
switching process. On the other hand, He ion irradiation has become a promising
tool for interface engineering of spintronic material platforms, giving rise to
significant modification of magnetic properties. In this paper, we explore the
use of He ion irradiation to enhance single pulse AOS of Co/Gd bilayer-based
synthetic ferrimagnets. The intermixing of the constituent magnetic layers by
He ion irradiation was both numerically simulated and experimentally verified.
We theoretically modelled the effects of intermixing on AOS using the layered
microscopic 3-temperature model and found that AOS is enhanced significantly by
breaking the pristine Co/Gd interface through intermixing. Following this
notion, we studied the threshold fluence of AOS as a function of He ion
irradiation fluence. We found that the AOS threshold fluence can be reduced by
almost 30%. Our study reveals the control of AOS by He ion irradiation, which
opens up an industrially compatible approach for local AOS engineering.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 21:42:12 GMT""}]","2022-11-09"
"2207.07767","Eric Luxenberg","Eric Luxenberg and Stephen Boyd and Mykel Kochenderfer and Misha van
  Beek and Wen Cao and Steven Diamond and Alex Ulitsky and Kunal Menda and Vidy
  Vairavamurthy","Strategic Asset Allocation with Illiquid Alternatives",,,,,"math.OC cs.SY eess.SY q-fin.PM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address the problem of strategic asset allocation (SAA) with portfolios
that include illiquid alternative asset classes. The main challenge in
portfolio construction with illiquid asset classes is that we do not have
direct control over our positions, as we do in liquid asset classes. Instead we
can only make commitments; the position builds up over time as capital calls
come in, and reduces over time as distributions occur, neither of which the
investor has direct control over. The effect on positions of our commitments is
subject to a delay, typically of a few years, and is also unknown or
stochastic. A further challenge is the requirement that we can meet the capital
calls, with very high probability, with our liquid assets.
  We formulate the illiquid dynamics as a random linear system, and propose a
convex optimization based model predictive control (MPC) policy for allocating
liquid assets and making new illiquid commitments in each period. Despite the
challenges of time delay and uncertainty, we show that this policy attains
performance surprisingly close to a fictional setting where we pretend the
illiquid asset classes are completely liquid, and we can arbitrarily and
immediately adjust our positions. In this paper we focus on the growth problem,
with no external liabilities or income, but the method is readily extended to
handle this case.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 21:53:36 GMT""}]","2022-07-19"
"2207.07768","Igor Bondarev PhD DSc (Habilitation)","Igor V. Bondarev","Controlling Single-Photon Emission with Ultrathin Transdimensional
  Plasmonic Films","19 pages, 3 figures, 68 references","Annalen der Physik (Berlin) 2200331 (2022)","10.1002/andp.202200331",,"physics.optics cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  We study theoretically the properties of a two-level quantum dipole emitter
near an ultrathin transdimensional plasmonic film. Our model system mimics a
solid-state single-photon source device. Using realistic experimental
parameters, we compute the spontaneous and stimulated emission intensity
profiles as functions of the excitation frequency and film thickness, followed
by the analysis of the second-order photon correlations to explore the photon
antibunching effect. We show that ultrathin transdimensional plasmonic films
can greatly improve photon antibunching with thickness reduction, which allows
one to control quantum properties of light and make them more pronounced.
Knowledge of these features is advantageous for solid-state single-photon
source device engineering and overall for the development of the new integrated
quantum photonics material platform based on the transdimensional plasmonic
films.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 22:03:35 GMT""}]","2023-04-06"
"2207.07769","Vinod Subramanian","Vinod Subramanian, Siddharth Gururani, Emmanouil Benetos, Mark Sandler","Anomalous behaviour in loss-gradient based interpretability methods","Accepted at ICLR RobustML workshop 2021",,,,"cs.LG cs.AI cs.IR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Loss-gradients are used to interpret the decision making process of deep
learning models. In this work, we evaluate loss-gradient based attribution
methods by occluding parts of the input and comparing the performance of the
occluded input to the original input. We observe that the occluded input has
better performance than the original across the test dataset under certain
conditions. Similar behaviour is observed in sound and image recognition tasks.
We explore different loss-gradient attribution methods, occlusion levels and
replacement values to explain the phenomenon of performance improvement under
occlusion.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 22:04:27 GMT""}]","2022-07-19"
"2207.07770","Alexander Polishchuk","Nikita Markarian, Alexander Polishchuk","Compatible Feigin-Odesskii Poisson brackets","15 pages, v2: strengthened Corollary C for even n",,,,"math.AG","http://creativecommons.org/licenses/by/4.0/","  We prove that several Feigin-Odesskii Poisson brackets associated with normal
elliptic curves in ${\mathbb P}^n$ are compatible if and only if they are
contained in a scroll or in a Veronese surface in ${\mathbb P}^5$ (with an
exception of one case when $n=3$). In the case $n=3$ we determine the quartic
corresponding to the Schouten bracket of two (non-compatible) Poisson brackets
associated with normal elliptic curves $E_1$ and $E_2$.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 22:27:08 GMT""},{""version"":""v2"",""created"":""Sat, 30 Jul 2022 15:13:39 GMT""}]","2022-08-02"
"2207.07771","Lei Zhang","Lei Zhang, Tianying Chen, Olivia Seow, Tim Chong, Sven Kratz, Yu Jiang
  Tham, Andr\'es Monroy-Hern\'andez, Rajan Vaish, Fannie Liu","Auggie: Encouraging Effortful Communication through Handcrafted Digital
  Experiences","To appear at the 25th ACM Conference On Computer-Supported
  Cooperative Work And Social Computing (CSCW '22). 25 pages",,,,"cs.HC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Digital communication is often brisk and automated. From auto-completed
messages to ""likes,"" research has shown that such lightweight interactions can
affect perceptions of authenticity and closeness. On the other hand, effort in
relationships can forge emotional bonds by conveying a sense of caring and is
essential in building and maintaining relationships. To explore effortful
communication, we designed and evaluated Auggie, an iOS app that encourages
partners to create digitally handcrafted Augmented Reality (AR) experiences for
each other. Auggie is centered around crafting a 3D character with photos,
animated movements, drawings, and audio for someone else. We conducted a
two-week-long field study with 30 participants (15 pairs), who used Auggie with
their partners remotely. Our qualitative findings show that Auggie participants
engaged in meaningful effort through the handcrafting process, and felt closer
to their partners, although the tool may not be appropriate in all situations.
We discuss design implications and future directions for systems that encourage
effortful communication.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 22:31:44 GMT""}]","2022-07-19"
"2207.07772","Chun-Hua Guo","Chun-Hua Guo, Wen-Wei Lin, Ching-Sung Liu","A new modified Newton iteration for computing nonnegative Z-eigenpairs
  of nonnegative tensors",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  We propose a new modification of Newton iteration for finding some
nonnegative Z-eigenpairs of a nonnegative tensor. The method has local
quadratic convergence to a nonnegative eigenpair of a nonnegative tensor, under
the usual assumption guaranteeing the local quadratic convergence of the
original Newton iteration.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 22:33:39 GMT""}]","2022-07-19"
"2207.07773","Haohe Liu","Haohe Liu, Xubo Liu, Xinhao Mei, Qiuqiang Kong, Wenwu Wang, Mark D.
  Plumbley","Segment-level Metric Learning for Few-shot Bioacoustic Event Detection","2nd place in the DCASE 2022 Challenge Task 5. Submitted to the DCASE
  2022 workshop",,,,"eess.AS cs.AI cs.SD eess.SP","http://creativecommons.org/licenses/by/4.0/","  Few-shot bioacoustic event detection is a task that detects the occurrence
time of a novel sound given a few examples. Previous methods employ metric
learning to build a latent space with the labeled part of different sound
classes, also known as positive events. In this study, we propose a
segment-level few-shot learning framework that utilizes both the positive and
negative events during model optimization. Training with negative events, which
are larger in volume than positive events, can increase the generalization
ability of the model. In addition, we use transductive inference on the
validation set during training for better adaptation to novel classes. We
conduct ablation studies on our proposed method with different setups on input
features, training data, and hyper-parameters. Our final system achieves an
F-measure of 62.73 on the DCASE 2022 challenge task 5 (DCASE2022-T5) validation
set, outperforming the performance of the baseline prototypical network 34.02
by a large margin. Using the proposed method, our submitted system ranks 2nd in
DCASE2022-T5. The code of this paper is fully open-sourced at
https://github.com/haoheliu/DCASE_2022_Task_5.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 22:41:30 GMT""}]","2022-07-19"
"2207.07774","Lucas Aimaretto","Lucas Aimaretto (1), Diego Dujovne (2) ((1) Facultad de Ciencias
  Exactas, F\'isicas y Naturales, Universidad Nacional de C\'ordoba, (2)
  Escuela de Inform\'atica y Telecomunicaciones, Universidad Diego Portales)","BDPC: Controlling Application Delay in 6TiSCH networks for the
  Industrial Internet of Things","This work has been submitted to Elsevier for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible",,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the essential requirements of wireless industrial Internet of Things
(IoT) systems is to have an extremely high packet delivery rate, generally over
99.9% and comply wih realtime deadline constraints. In industrial IoT networks,
packets arriving after the deadline become part of packet loss and lose meaning
when they arrive late. However, currently available industial IoT proposals aim
to minimize End-to-End delay without taking into account simultaneous realtime
and reliability constraints. In this paper, we propose a new mechanism, called
BDPC (Bounded Delay Packet Control) to tackle this challenge. BDPC combines the
knowledge of a node's traffic delay to the destination (root) with the time
budget of a data packet traversing the industrial IoT network, to allocate
network resources to comply the system maximum delay requirements using an
adaptive and distributed algorithm. Unlike the general aim to minimze
end-to-end delay, we propose that data packets must arrive before the deadline,
but not faster. Our results show, for example, that by using BDPC, the number
of packets arriving before the deadline can be improved more than 2.6 times
compared to the case when using the default Minimal Scheduling Function from
the standard. As a further advantage, BDPC involves minor modifications to the
6TiSCH protocol stack, which makes it compatible with current implementations.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 22:44:16 GMT""},{""version"":""v2"",""created"":""Wed, 31 Aug 2022 12:39:35 GMT""},{""version"":""v3"",""created"":""Sun, 29 Jan 2023 01:37:39 GMT""}]","2023-01-31"
"2207.07775","Yuval Wigderson","Jacob Fox and Yuval Wigderson","Ramsey multiplicity and the Tur\'an coloring","38 pages. This version corrects an error in Lemmas 2.1 and 4.1 of the
  previous version",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Extending an earlier conjecture of Erd\H{o}s, Burr and Rosta conjectured that
among all two-colorings of the edges of a complete graph, the uniformly random
coloring asymptotically minimizes the number of monochromatic copies of any
fixed graph $H$. This conjecture was disproved independently by Sidorenko and
Thomason. The first author later found quantitatively stronger counterexamples,
using the Tur\'an coloring, in which one of the two colors spans a balanced
complete multipartite graph.
  We prove that the Tur\'an coloring is extremal for an infinite family of
graphs, and that it is the unique extremal coloring. This yields the first
determination of the Ramsey multiplicity constant of a graph for which the
Burr--Rosta conjecture fails.
  We also prove an analogous three-color result. In this case, our result is
conditional on a certain natural conjecture on the behavior of two-color Ramsey
numbers.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 22:49:50 GMT""},{""version"":""v2"",""created"":""Mon, 9 Jan 2023 07:27:13 GMT""}]","2023-01-10"
"2207.07776","Minho Jin","Minho Jin, Chelsea J.-T. Ju, Zeya Chen, Yi-Chieh Liu, Jasha Droppo,
  and Andreas Stolcke","Adversarial Reweighting for Speaker Verification Fairness",,,,,"eess.AS cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address performance fairness for speaker verification using the
adversarial reweighting (ARW) method. ARW is reformulated for speaker
verification with metric learning, and shown to improve results across
different subgroups of gender and nationality, without requiring annotation of
subgroups in the training data. An adversarial network learns a weight for each
training sample in the batch so that the main learner is forced to focus on
poorly performing instances. Using a min-max optimization algorithm, this
method improves overall speaker verification fairness. We present three
different ARWformulations: accumulated pairwise similarity, pseudo-labeling,
and pairwise weighting, and measure their performance in terms of equal error
rate (EER) on the VoxCeleb corpus. Results show that the pairwise weighting
method can achieve 1.08% overall EER, 1.25% for male and 0.67% for female
speakers, with relative EER reductions of 7.7%, 10.1% and 3.0%, respectively.
For nationality subgroups, the proposed algorithm showed 1.04% EER for US
speakers, 0.76% for UK speakers, and 1.22% for all others. The absolute EER gap
between gender groups was reduced from 0.70% to 0.58%, while the standard
deviation over nationality groups decreased from 0.21 to 0.19.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 22:50:31 GMT""}]","2022-07-19"
"2207.07777","Ram\'on Pozuelo Ruiz","Ram\'on Pozuelo, Qiang Li, Philipp Schlatter, Ricardo Vinuesa","New insight into the spectra of turbulent boundary layers with pressure
  gradients",,,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the availability of new high-Reynolds-number ($Re$) databases of
turbulent boundary layers (TBLs) it has been possible to identify in detail
certain regions of the boundary layer with more complex behavior. In this study
we consider a unique database at moderately-high $Re$, with a near-constant
adverse pressure gradient (APG) (Pozuelo {\it et al.}, {\it J. Fluid Mech.},
{\bf 939}, A34, 2022), and perform spectral analysis of the Reynolds stresses,
focusing on the streamwise component. We assess different regions of the APG
TBL, comparing this case with the zero-pressure-gradient (ZPG) TBL, and
identify the relevant scaling parameters as well as the contribution of the
scales of different sizes. The small scales in the near-wall region up to the
near-wall spectral peak have been found to scale using viscous units. In APG
TBLs, the largest scales close to the wall have a better scaling with the
boundary-layer thickness ($\delta_{99}$), and they are significantly affected
by the APG. In the overlap and wake regions of the boundary layer, the small
energetic scales exhibit a good scaling with the displacement thickness
($\delta^*$) while the larger scales and the outer spectral peak are better
scaled with the boundary-layer thickness. Also note that the wall-normal
location of the spectral outer peak scales with the displacement thickness
rather than the boundary layer thickness. The various scalings exhibited by the
spectra in APG TBLs are reported here for the first time, and shed light on the
complex phenomena present in these flows of great scientific and technological
importance.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 22:52:42 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jul 2022 21:05:26 GMT""}]","2022-07-25"
"2207.07778","Sajjad Feizollah","Sajjad Feizollah (1 and 2), Christine L. Tardif (1 and 2 and 3) ((1)
  Department of Neurology and Neurosurgery, Faculty of Medicine and Health
  Sciences, McGill University, Montreal, Canada, (2) McConnell Brain Imaging
  Centre, Montreal Neurological Institute, McGill University, Montreal, Canada,
  (3) Department of Biomedical Engineering, Faculty of Medicine and Health
  Sciences, McGill University, Montreal, Canada)","High-resolution diffusion-weighted imaging at 7 Tesla: single-shot
  readout trajectories and their impact on signal-to-noise ratio, spatial
  resolution and accuracy",,,"10.1016/j.neuroimage.2023.120159",,"physics.med-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Diffusion MRI (dMRI) is a valuable imaging technique to study the brain in
vivo. However, the resolution of dMRI is limited by the low signal-to-noise
ratio (SNR) of this technique. Various acquisition strategies have been
developed to achieve high resolutions, but they require long scan times.
Imaging at ultra-high fields (UHF) could further increase the SNR of
single-shot dMRI; however, the shorter T2* and the greater field
non-uniformities will degrade image quality. In this study, we investigated the
trade-off between the SNR and resolution of different k-space trajectories,
including echo planar imaging (EPI), partial Fourier EPI, and spiral, over a
range of resolutions at 7T. The effective resolution, spatial specificity and
sharpening effect were measured from the point spread function (PSF) of the
simulated diffusion sequences for a nominal resolution range of 0.6-1.8 mm.
In-vivo scans were acquired using the three readout trajectories. Field probes
were used to measure dynamic magnetic fields up to the 3rd order of spherical
harmonics. Using a static field map and the measured trajectories image
artifacts were corrected, leaving T2* effects as the primary source of
blurring. The effective resolution was examined in fractional anisotropy (FA)
maps. In-vivo scans were acquired to calculate the SNR. EPI trajectories had
the highest specificity, effective resolution, and image sharpening effect, but
also had substantially lower SNR. Spirals had significantly higher SNR, but
lower specificity. Line plots of the in-vivo scans in phase and frequency
encode directions showed ~0.2 units difference in FA values between the
different trajectories. The difference between the effective and nominal
resolution is greater for spirals than for EPI. However, the higher SNR of
spiral trajectories at UHFs allows us to achieve higher effective resolutions
compared to EPI and PF-EPI trajectories.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 23:00:56 GMT""},{""version"":""v2"",""created"":""Fri, 3 Feb 2023 22:05:21 GMT""}]","2023-05-30"
"2207.07779","Yi Zhou","Runhua Xu, Nathalie Baracaldo, Yi Zhou, Ali Anwar, Swanand Kadhe,
  Heiko Ludwig","DeTrust-FL: Privacy-Preserving Federated Learning in Decentralized Trust
  Setting",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Federated learning has emerged as a privacy-preserving machine learning
approach where multiple parties can train a single model without sharing their
raw training data. Federated learning typically requires the utilization of
multi-party computation techniques to provide strong privacy guarantees by
ensuring that an untrusted or curious aggregator cannot obtain isolated replies
from parties involved in the training process, thereby preventing potential
inference attacks. Until recently, it was thought that some of these secure
aggregation techniques were sufficient to fully protect against inference
attacks coming from a curious aggregator. However, recent research has
demonstrated that a curious aggregator can successfully launch a disaggregation
attack to learn information about model updates of a target party. This paper
presents DeTrust-FL, an efficient privacy-preserving federated learning
framework for addressing the lack of transparency that enables isolation
attacks, such as disaggregation attacks, during secure aggregation by assuring
that parties' model updates are included in the aggregated model in a private
and secure manner. DeTrust-FL proposes a decentralized trust consensus
mechanism and incorporates a recently proposed decentralized functional
encryption (FE) scheme in which all parties agree on a participation matrix
before collaboratively generating decryption key fragments, thereby gaining
control and trust over the secure aggregation process in a decentralized
setting. Our experimental evaluation demonstrates that DeTrust-FL outperforms
state-of-the-art FE-based secure multi-party aggregation solutions in terms of
training time and reduces the volume of data transferred. In contrast to
existing approaches, this is achieved without creating any trust dependency on
external trusted entities.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 23:07:20 GMT""}]","2022-07-19"
"2207.07780","Sandeep Chowdhary","Sandeep Chowdhary, Iacopo Iacopini, Federico Battiston","Quantifying human performance in chess","8 pages, 5 figures",,,,"physics.soc-ph cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  From sports to science, the recent availability of large-scale data has
allowed to gain insights on the drivers of human innovation and success in a
variety of domains. Here we quantify human performance in the popular game of
chess by leveraging a very large dataset comprising of over 120 million games
between almost 1 million players. We find that individuals encounter hot
streaks of repeated success, longer for beginners than for expert players, and
even longer cold streaks of unsatisfying performance. Skilled players can be
distinguished from the others based on their gaming behaviour. Differences
appear from the very first moves of the game, with experts tending to
specialize and repeat the same openings while beginners explore and diversify
more. However, experts experience a broader response repertoire, and display a
deeper understanding of different variations within the same line. Over time,
the opening diversity of a player tends to decrease, hinting at the development
of individual playing styles. Nevertheless, we find that players are often not
able to recognize their most successful openings. Overall, our work contributes
to quantifying human performance in competitive settings, providing a first
large-scale quantitative analysis of individual careers in chess, helping
unveil the determinants separating elite from beginner performance.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 23:13:17 GMT""}]","2022-07-19"
"2207.07781","Ali Arab","Ali Arab, Dev Arora, Jialin Lu, Martin Ester","Subgroup Discovery in Unstructured Data",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Subgroup discovery is a descriptive and exploratory data mining technique to
identify subgroups in a population that exhibit interesting behavior with
respect to a variable of interest. Subgroup discovery has numerous applications
in knowledge discovery and hypothesis generation, yet it remains inapplicable
for unstructured, high-dimensional data such as images. This is because
subgroup discovery algorithms rely on defining descriptive rules based on
(attribute, value) pairs, however, in unstructured data, an attribute is not
well defined. Even in cases where the notion of attribute intuitively exists in
the data, such as a pixel in an image, due to the high dimensionality of the
data, these attributes are not informative enough to be used in a rule. In this
paper, we introduce the subgroup-aware variational autoencoder, a novel
variational autoencoder that learns a representation of unstructured data which
leads to subgroups with higher quality. Our experimental results demonstrate
the effectiveness of the method at learning subgroups with high quality while
supporting the interpretability of the concepts.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 23:13:54 GMT""}]","2022-07-19"
"2207.07782","Jiawei Xu","Jiawei Xu, Onur Dizdar, and Bruno Clerckx","Rate-Splitting Multiple Access for Short-Packet Uplink Communications: A
  Finite Blocklength Error Probability Analysis","5 pages, 4 figures",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this letter, we investigate Rate-Splitting Multiple Access (RSMA) for an
uplink communication system with finite blocklength. Considering a two-user
Single-Input Single-Output (SISO) Multiple Access Channel (MAC), we study the
impact of Signal-to-Noise Ratio (SNR), blocklength, power allocation and target
rate on the error probability performance of RSMA where one user message is
split. We demonstrate that RSMA can improve the error probability performance
significantly compared to Non-Orthogonal Multiple Access (NOMA) and RSMA can
have a larger rate region than NOMA.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 23:41:56 GMT""},{""version"":""v2"",""created"":""Mon, 26 Sep 2022 12:22:09 GMT""},{""version"":""v3"",""created"":""Fri, 9 Dec 2022 17:35:18 GMT""}]","2022-12-12"
"2207.07783","Kyle Min","Kyle Min, Sourya Roy, Subarna Tripathi, Tanaya Guha, Somdeb Majumdar","Learning Long-Term Spatial-Temporal Graphs for Active Speaker Detection","ECCV 2022 camera ready (Supplementary videos: on ECVA soon). This
  paper supersedes arXiv:2112.01479",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Active speaker detection (ASD) in videos with multiple speakers is a
challenging task as it requires learning effective audiovisual features and
spatial-temporal correlations over long temporal windows. In this paper, we
present SPELL, a novel spatial-temporal graph learning framework that can solve
complex tasks such as ASD. To this end, each person in a video frame is first
encoded in a unique node for that frame. Nodes corresponding to a single person
across frames are connected to encode their temporal dynamics. Nodes within a
frame are also connected to encode inter-person relationships. Thus, SPELL
reduces ASD to a node classification task. Importantly, SPELL is able to reason
over long temporal contexts for all nodes without relying on computationally
expensive fully connected graph neural networks. Through extensive experiments
on the AVA-ActiveSpeaker dataset, we demonstrate that learning graph-based
representations can significantly improve the active speaker detection
performance owing to its explicit spatial and temporal structure. SPELL
outperforms all previous state-of-the-art approaches while requiring
significantly lower memory and computational resources. Our code is publicly
available at https://github.com/SRA2/SPELL
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 23:43:17 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jul 2022 01:30:35 GMT""},{""version"":""v3"",""created"":""Wed, 12 Oct 2022 12:17:46 GMT""}]","2022-10-13"
"2207.07784","Evan Arena","Evan J. Arena","Weak gravitational flexion in various spacetimes: Exotic lenses and
  modified gravity","11 pages, 2 figures; accepted for publication in Phys.Rev.D","Phys. Rev. D 106, 064019 (2022)","10.1103/PhysRevD.106.064019",,"gr-qc astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Exotic objects such as the Ellis wormhole are expected to act as
gravitational lenses. Much like their nonexotic counterparts, information about
these lenses can be found by considering the strong and weak lensing fields
they induce. In this work, we consider how weak gravitational lensing flexion
can provide information beyond that of shear. We find that directional flexion
can distinguish between the case of a positive or negative convergence where
directional shear cannot, and therefore can provide a unique lensing signature
for objects with an Ellis wormhole-type metric. We also consider cosmic
flexion, the flexion correlation function whose signal originates from the
large-scale structure of the Universe, in the context of modified gravity. We
find flexion to be a unique probe of parametric models of modified gravity,
particularly in the case of scale-dependent phenomenological post-general
relativity functions.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 23:45:30 GMT""},{""version"":""v2"",""created"":""Fri, 9 Sep 2022 16:49:21 GMT""}]","2022-09-12"
"2207.07785","Frederik Werner Isaksen","Frederik Werner Isaksen and Ulrik Lund Andersen","Mechanical cooling and squeezing using optimal control","17 pages, 9 figures. Latest update: Figures now also works in
  grayscale. Supplemental material incorporated in main text as an appendix",,"10.1103/PhysRevA.107.023512",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A mechanical system can be optimally controlled through continuous
measurements of its position followed by feedback. We revisit the complete
formalism for predicting the performance of such as system without invoking the
standard rotating wave approximations and the adiabatic approximation. Using
this formalism we deduce both the conditional and unconditional state of a
mechanical oscillator using the optimal control and feedback that leads to
mechanical cooling and mechanical squeezing. We find large discrepancies
between the exact solutions and the approximate solutions stressing the
importance of using the complete model. We also highlight the importance of
distinguishing between the conditional and unconditional state by demonstrating
that these two cannot coincide in a typical control scheme, even with infinite
feedback strength.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 23:45:35 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jul 2022 13:50:19 GMT""},{""version"":""v3"",""created"":""Tue, 20 Dec 2022 10:21:38 GMT""},{""version"":""v4"",""created"":""Fri, 27 Jan 2023 11:10:22 GMT""}]","2023-03-01"
"2207.07786","Nicki Mullins","Nicki Mullins (Illinois U., Urbana), Gabriel S. Denicol (Niteroi,
  Fluminense U.), Jorge Noronha (Illinois U., Urbana)","Far-from-equilibrium kinetic dynamics of $\lambda \phi^4$ theory in an
  expanding universe","19 pages, 5 figures",,"10.1103/PhysRevD.106.056024",,"hep-ph gr-qc nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the far-from-equilibrium behavior of the Boltzmann equation
for a gas of massless scalar field particles with quartic (tree level)
self-interactions ($\lambda \phi^4$) in Friedmann-Lemaitre-Robertson-Walker
spacetime. Using a new covariant generating function for the moments of the
Boltzmann distribution function, we analytically determine a subset of the
spectrum and the corresponding eigenfunctions of the linearized Boltzmann
collision operator. We show how the covariant generating function can be also
used to find the exact equations for the moments in the full nonlinear regime.
Different than the case of a ultrarelativistic gas of hard spheres (where the
total cross section is constant), for $\lambda \phi^4$ the fact that the cross
section decreases with energy implies that moments of arbitrarily high order
directly couple to low order moments. Numerical solutions for the scalar field
case are presented and compared to those found for a gas of hard spheres.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 23:47:48 GMT""}]","2022-10-12"
"2207.07787","Riccardo Muolo","Lorenzo Giambagli and Lucille Calmon and Riccardo Muolo and Timoteo
  Carletti and Ginestra Bianconi","Diffusion-driven instability of topological signals coupled by the Dirac
  operator",,,"10.1103/PhysRevE.106.064314",,"nlin.PS cond-mat.stat-mech math-ph math.DS math.MP nlin.AO","http://creativecommons.org/licenses/by/4.0/","  The study of reaction-diffusion systems on networks is of paramount relevance
for the understanding of nonlinear processes in systems where the topology is
intrinsically discrete, such as the brain. Until now reaction-diffusion systems
have been studied only when species are defined on the nodes of a network.
However, in a number of real systems including, e.g., the brain and the
climate, dynamical variables are not only defined on nodes but also on links,
faces and higher-dimensional cells of simplicial or cell complexes, leading to
topological signals. In this work we study reaction-diffusion processes of
topological signals coupled through the Dirac operator. The Dirac operator
allows topological signals of different dimension to interact or cross-diffuse
as it projects the topological signals defined on simplices or cells of a given
dimension to simplices or cells of one dimension up or one dimension down. By
focusing on the framework involving nodes and links we establish the conditions
for the emergence of Turing patterns and we show that the latter are never
localized only on nodes or only on links of the network. Moreover when the
topological signals display Turing pattern their projection does as well. We
validate the theory hereby developed on a benchmark network model and on square
lattices with periodic boundary conditions.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 23:48:10 GMT""},{""version"":""v2"",""created"":""Wed, 30 Nov 2022 07:40:29 GMT""},{""version"":""v3"",""created"":""Thu, 30 Mar 2023 21:20:24 GMT""}]","2023-04-03"
"2207.07788","Albert Chen","Reza Hosseini, Albert Chen, Kaixu Yang, Sayan Patra, Yi Su, Saad Eddin
  Al Orjany, Sishi Tang, Parvez Ahammad","Greykite: Deploying Flexible Forecasting at Scale at LinkedIn","In Proceedings of the 28th ACM SIGKDD Conference on Knowledge
  Discovery and Data Mining (KDD '22), August 14-18, 2022, Washington, DC, USA.
  ACM, New York, NY, USA, 11 pages",,"10.1145/3534678.3539165",,"cs.LG stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Forecasts help businesses allocate resources and achieve objectives. At
LinkedIn, product owners use forecasts to set business targets, track outlook,
and monitor health. Engineers use forecasts to efficiently provision hardware.
Developing a forecasting solution to meet these needs requires accurate and
interpretable forecasts on diverse time series with sub-hourly to quarterly
frequencies. We present Greykite, an open-source Python library for forecasting
that has been deployed on over twenty use cases at LinkedIn. Its flagship
algorithm, Silverkite, provides interpretable, fast, and highly flexible
univariate forecasts that capture effects such as time-varying growth and
seasonality, autocorrelation, holidays, and regressors. The library enables
self-serve accuracy and trust by facilitating data exploration, model
configuration, execution, and interpretation. Our benchmark results show
excellent out-of-the-box speed and accuracy on datasets from a variety of
domains. Over the past two years, Greykite forecasts have been trusted by
Finance, Engineering, and Product teams for resource planning and allocation,
target setting and progress tracking, anomaly detection and root cause
analysis. We expect Greykite to be useful to forecast practitioners with
similar applications who need accurate, interpretable forecasts that capture
complex dynamics common to time series related to human activity.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 23:57:10 GMT""}]","2022-07-19"
"2207.07789","Yanran Wang","Yanran Wang, James O'Keeffe, Qiuchen Qian and David Boyle","QuaDUE-CCM: Interpretable Distributional Reinforcement Learning using
  Uncertain Contraction Metrics for Precise Quadrotor Trajectory Tracking","18 pages, 9 figures, Quadrotor trajectory tracking, Learning-based
  control",,,,"cs.RO cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accuracy and stability are common requirements for Quadrotor trajectory
tracking systems. Designing an accurate and stable tracking controller remains
challenging, particularly in unknown and dynamic environments with complex
aerodynamic disturbances. We propose a Quantile-approximation-based
Distributional-reinforced Uncertainty Estimator (QuaDUE) to accurately identify
the effects of aerodynamic disturbances, i.e., the uncertainties between the
true and estimated Control Contraction Metrics (CCMs). Taking inspiration from
contraction theory and integrating the QuaDUE for uncertainties, our novel
CCM-based trajectory tracking framework tracks any feasible reference
trajectory precisely whilst guaranteeing exponential convergence. More
importantly, the convergence and training acceleration of the distributional RL
are guaranteed and analyzed, respectively, from theoretical perspectives. We
also demonstrate our system under unknown and diverse aerodynamic forces. Under
large aerodynamic forces (>2m/s^2), compared with the classic data-driven
approach, our QuaDUE-CCM achieves at least a 56.6% improvement in tracking
error. Compared with QuaDRED-MPC, a distributional RL-based approach,
QuaDUE-CCM achieves at least a 3 times improvement in contraction rate.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 23:57:23 GMT""}]","2022-07-19"
"2207.07790","Fanglin Chen","Fanglin Chen, Xiao Liu, Bo Tang, Feiyu Xiong, Serim Hwang, and Guomian
  Zhuang","BCRLSP: An Offline Reinforcement Learning Framework for Sequential
  Targeted Promotion","8 pages, DRL4IR@SIGIR",,,,"cs.LG cs.IR","http://creativecommons.org/licenses/by/4.0/","  We utilize an offline reinforcement learning (RL) model for sequential
targeted promotion in the presence of budget constraints in a real-world
business environment. In our application, the mobile app aims to boost customer
retention by sending cash bonuses to customers and control the costs of such
cash bonuses during each time period. To achieve the multi-task goal, we
propose the Budget Constrained Reinforcement Learning for Sequential Promotion
(BCRLSP) framework to determine the value of cash bonuses to be sent to users.
We first find out the target policy and the associated Q-values that maximizes
the user retention rate using an RL model. A linear programming (LP) model is
then added to satisfy the constraints of promotion costs. We solve the LP
problem by maximizing the Q-values of actions learned from the RL model given
the budget constraints. During deployment, we combine the offline RL model with
the LP model to generate a robust policy under the budget constraints. Using
both online and offline experiments, we demonstrate the efficacy of our
approach by showing that BCRLSP achieves a higher long-term customer retention
rate and a lower cost than various baselines. Taking advantage of the near
real-time cost control method, the proposed framework can easily adapt to data
with a noisy behavioral policy and/or meet flexible budget constraints.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 00:10:12 GMT""}]","2022-07-19"
"2207.07791","Mengyuan Li","Mengyuan Li, Arman Kazemi, Ann Franchesca Laguna and X. Sharon Hu","Associative Memory Based Experience Replay for Deep Reinforcement
  Learning","9 pages, 9 figures. The work was accepted by the 41st International
  Conference on Computer-Aided Design (ICCAD), 2022, San Diego",,,,"cs.AR cs.ET cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Experience replay is an essential component in deep reinforcement learning
(DRL), which stores the experiences and generates experiences for the agent to
learn in real time. Recently, prioritized experience replay (PER) has been
proven to be powerful and widely deployed in DRL agents. However, implementing
PER on traditional CPU or GPU architectures incurs significant latency overhead
due to its frequent and irregular memory accesses. This paper proposes a
hardware-software co-design approach to design an associative memory (AM) based
PER, AMPER, with an AM-friendly priority sampling operation. AMPER replaces the
widely-used time-costly tree-traversal-based priority sampling in PER while
preserving the learning performance. Further, we design an in-memory computing
hardware architecture based on AM to support AMPER by leveraging parallel
in-memory search operations. AMPER shows comparable learning performance while
achieving 55x to 270x latency improvement when running on the proposed hardware
compared to the state-of-the-art PER running on GPU.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 00:12:12 GMT""}]","2022-07-19"
"2207.07792","Lin Sok","Lin Sok","Hulls of special typed linear codes and constructions of new EAQECCs","13 pages",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study Euclidean and Hermitian hulls of generalized
Reed-Solomon codes and twisted generalized Reed-Solomon codes, as well as the
Hermitian hulls of Roth-Lempel typed codes. We present explicit constructions
of MDS and AMDS linear codes for which their hull dimensions are well
determined. As an application, we provide several classes of
entanglement-assisted quantum error correcting codes with new parameters.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 00:27:31 GMT""}]","2022-07-19"
"2207.07793","Xiaoyu Liang","Xiaoyu Liang, Yaguan Qian, Jianchang Huang, Xiang Ling, Bin Wang,
  Chunming Wu, and Wassim Swaileh","Towards the Desirable Decision Boundary by Moderate-Margin Adversarial
  Training",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Adversarial training, as one of the most effective defense methods against
adversarial attacks, tends to learn an inclusive decision boundary to increase
the robustness of deep learning models. However, due to the large and
unnecessary increase in the margin along adversarial directions, adversarial
training causes heavy cross-over between natural examples and adversarial
examples, which is not conducive to balancing the trade-off between robustness
and natural accuracy. In this paper, we propose a novel adversarial training
scheme to achieve a better trade-off between robustness and natural accuracy.
It aims to learn a moderate-inclusive decision boundary, which means that the
margins of natural examples under the decision boundary are moderate. We call
this scheme Moderate-Margin Adversarial Training (MMAT), which generates
finer-grained adversarial examples to mitigate the cross-over problem. We also
take advantage of logits from a teacher model that has been well-trained to
guide the learning of our model. Finally, MMAT achieves high natural accuracy
and robustness under both black-box and white-box attacks. On SVHN, for
example, state-of-the-art robustness and natural accuracy are achieved.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 00:57:23 GMT""}]","2022-07-19"
"2207.07794","Magno Machado","L.S. Moriggi, M.V.T. Machado","Nuclear Modification Factor in Small System Collisions within
  Perturbative QCD Including Thermal Effects","12 pages, 4 figures. Contribution to MDPI Physics Special Issue ""Jean
  Cleymans: A Life for Physics"", dedicated to the memory of Professor Jean
  Cleymans",,,,"hep-ph hep-ex nucl-ex","http://creativecommons.org/licenses/by/4.0/","  In this paper, dedicated to the memory of the late Prof. Jean Cleymans, the
nuclear modification factors, $R_{xA}$, are investigated for pion production in
small system collisions, measured by PHENIX experiment at RHIC (Relativistic
Heavy Ion Collider). The theoretical framework is the transverse momentum
$k_T$-factorization formalism for hard processes at small momentum fraction,
$x$. Evidence for collective expansion and thermal effects for pions, produced
at equilibrium, is studied based on phenomenological parametrization of
blast-wave type in the relaxation time approximation. The dependencies on the
centrality and on the projectile species are discussed in terms of the behavior
of Cronin peak and the suppression of $R_{xA}$ at large transverse momentum,
$p_T$. The multiplicity of produced particles, which is sensitive to the soft
sector of the spectra, is also included in the present analysis.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 00:57:44 GMT""}]","2022-07-19"
"2207.07795","Daqian Shi","Daqian Shi, Xiaolei Diao, Hao Tang, Xiaomin Li, Hao Xing, Hao Xu","RCRN: Real-world Character Image Restoration Network via Skeleton
  Extraction","Accepted to ACM MM 2022",,"10.1145/3503161.3548344",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Constructing high-quality character image datasets is challenging because
real-world images are often affected by image degradation. There are
limitations when applying current image restoration methods to such real-world
character images, since (i) the categories of noise in character images are
different from those in general images; (ii) real-world character images
usually contain more complex image degradation, e.g., mixed noise at different
noise levels. To address these problems, we propose a real-world character
restoration network (RCRN) to effectively restore degraded character images,
where character skeleton information and scale-ensemble feature extraction are
utilized to obtain better restoration performance. The proposed method consists
of a skeleton extractor (SENet) and a character image restorer (CiRNet). SENet
aims to preserve the structural consistency of the character and normalize
complex noise. Then, CiRNet reconstructs clean images from degraded character
images and their skeletons. Due to the lack of benchmarks for real-world
character image restoration, we constructed a dataset containing 1,606
character images with real-world degradation to evaluate the validity of the
proposed method. The experimental results demonstrate that RCRN outperforms
state-of-the-art methods quantitatively and qualitatively.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 01:02:52 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jul 2022 17:52:13 GMT""}]","2022-07-20"
"2207.07796","Tianying Wang","Roulan Jiang, Xiang Zhan and Tianying Wang","A Flexible Zero-Inflated Poisson-Gamma model with application to
  microbiome read counts",,,,,"stat.ME stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In microbiome studies, it is of interest to use a sample from a population of
microbes, such as the gut microbiota community, to estimate the population
proportion of these taxa. However, due to biases introduced in sampling and
preprocessing steps, these observed taxa abundances may not reflect true taxa
abundance patterns in the ecosystem. Repeated measures, including longitudinal
study designs, may be potential solutions to mitigate the discrepancy between
observed abundances and true underlying abundances. Yet, widely observed
zero-inflation and over-dispersion issues can distort downstream statistical
analyses aiming to associate taxa abundances with covariates of interest. To
this end, we propose a Zero-Inflated Poisson Gamma (ZIPG) framework to address
the aforementioned challenges. From a perspective of measurement errors, we
accommodate the discrepancy between observations and truths by decomposing the
mean parameter in Poisson regression into a true abundance level and a
multiplicative measurement of sampling variability from the microbial
ecosystem. Then, we provide a flexible model by connecting both mean abundance
and the variability to different covariates, and build valid statistical
inference procedures for both parameter estimation and hypothesis testing.
Through comprehensive simulation studies and real data applications, the
proposed ZIPG method provides significant insights into distinguished
differential variability and abundance.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 01:04:06 GMT""},{""version"":""v2"",""created"":""Mon, 10 Oct 2022 12:00:52 GMT""}]","2022-10-11"
"2207.07797","Lei Hsiung","Lei Hsiung, Yun-Yun Tsai, Pin-Yu Chen, Tsung-Yi Ho","CARBEN: Composite Adversarial Robustness Benchmark","IJCAI 2022 Demo Track; The demonstration is at
  https://hsiung.cc/CARBEN/",,,,"cs.CV cs.AI cs.HC","http://creativecommons.org/licenses/by/4.0/","  Prior literature on adversarial attack methods has mainly focused on
attacking with and defending against a single threat model, e.g., perturbations
bounded in Lp ball. However, multiple threat models can be combined into
composite perturbations. One such approach, composite adversarial attack (CAA),
not only expands the perturbable space of the image, but also may be overlooked
by current modes of robustness evaluation. This paper demonstrates how CAA's
attack order affects the resulting image, and provides real-time inferences of
different models, which will facilitate users' configuration of the parameters
of the attack level and their rapid evaluation of model prediction. A
leaderboard to benchmark adversarial robustness against CAA is also introduced.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 01:08:44 GMT""}]","2022-07-19"
"2207.07798","Daqian Shi","Daqian Shi, Xiaolei Diao, Lida Shi, Hao Tang, Yang Chi, Chuntao Li,
  Hao Xu","CharFormer: A Glyph Fusion based Attentive Framework for High-precision
  Character Image Denoising","Accepted by ACM MM 2022",,"10.1145/3503161.3548208",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Degraded images commonly exist in the general sources of character images,
leading to unsatisfactory character recognition results. Existing methods have
dedicated efforts to restoring degraded character images. However, the
denoising results obtained by these methods do not appear to improve character
recognition performance. This is mainly because current methods only focus on
pixel-level information and ignore critical features of a character, such as
its glyph, resulting in character-glyph damage during the denoising process. In
this paper, we introduce a novel generic framework based on glyph fusion and
attention mechanisms, i.e., CharFormer, for precisely recovering character
images without changing their inherent glyphs. Unlike existing frameworks,
CharFormer introduces a parallel target task for capturing additional
information and injecting it into the image denoising backbone, which will
maintain the consistency of character glyphs during character image denoising.
Moreover, we utilize attention-based networks for global-local feature
interaction, which will help to deal with blind denoising and enhance denoising
performance. We compare CharFormer with state-of-the-art methods on multiple
datasets. The experimental results show the superiority of CharFormer
quantitatively and qualitatively.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 01:11:30 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jul 2022 17:46:58 GMT""}]","2022-07-20"
"2207.07799","Seongjin Ahn","Seongjin Ahn and Sankar Das Sarma","Hydrodynamics, viscous electron fluid, and Wiedeman-Franz law in 2D
  semiconductors","5 pages, 5 figures","Phys. Rev. B 106, L081303 (2022)","10.1103/PhysRevB.106.L081303",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Considering theoretically the transition between hydrodynamic and ballistic
regimes in 2D semiconductors, we show that electrons in high-mobility 2D GaAs
are by far the best system for the direct observation of collective
hydrodynamic effects even in bulk transport properties independent of
complicated transport features in narrow constrictions and small systems where
Gurzhi phenomena are typically studied experimentally. We predict a strong
hydrodynamics-induced generic violation of the Wiedeman-Franz law in bulk 2D
GaAs systems for mobilities as modest as $10^6 \mathrm{cm}^2/Vs$ and densities
$1$-$5\times10^{11} \mathrm{cm}^{-2}$ in the temperature range of $T=1$-$40K$.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 01:15:04 GMT""}]","2022-10-11"
"2207.07800","Kevin O'Bryant","Kevin O'Bryant","On the size of finite Sidon sets","16 pages, 10 images",,,,"math.NT math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A Sidon set is a set of integers containing no nontrivial solutions to the
equation $a+b=c+d$. We improve on the lower bound on the diameter of a Sidon
set with $k$ elements: if $k$ is sufficiently large and ${\cal A}$ is a Sidon
set with $k$ elements, then $diam({\cal A})\ge k^2-1.99405 k^{3/2}$.
Alternatively, if $n$ is sufficiently large, then the largest subset of
$\{1,2,\dots,n\}$ that is a Sidon set has cardinality at most $n^{1/2}+0.99703
n^{1/4}$. While these are only slight numerical improvements on
Balogh-F\""uredi-Roy (arXiv:2103:15850v2), we use a method that is logically
simpler.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 01:17:30 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jul 2022 20:02:49 GMT""}]","2022-07-27"
"2207.07801","Irtaza Khalid","Irtaza Khalid, Carrie A. Weidner, Edmond A. Jonckheere, Sophie G.
  Shermer, Frank C. Langbein","Statistically Characterising Robustness and Fidelity of Quantum Controls
  and Quantum Control Algorithms","13+11 pages, 6+10 figures, revised version, accepted by Phys. Rev. A",,"10.1103/PhysRevA.107.032606",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Robustness of quantum operations or controls is important to build reliable
quantum devices. The robustness-infidelity measure (RIM$_p$) is introduced to
statistically quantify the robustness and fidelity of a controller as the
p-order Wasserstein distance between the fidelity distribution of the
controller under any uncertainty and an ideal fidelity distribution. The
RIM$_p$ is the p-th root of the p-th raw moment of the infidelity distribution.
Using a metrization argument, we justify why RIM$_1$ (the average infidelity)
suffices as a practical robustness measure. Based on the RIM$_p$, an
algorithmic robustness-infidelity measure (ARIM) is developed to quantify the
expected robustness and fidelity of controllers found by a control algorithm.
The utility of the RIM and ARIM is demonstrated by considering the problem of
robust control of spin-$\tfrac{1}{2}$ networks using energy landscape shaping
subject to Hamiltonian uncertainty. The robustness and fidelity of individual
control solutions as well as the expected robustness and fidelity of
controllers found by different popular quantum control algorithms are
characterized. For algorithm comparisons, stochastic and non-stochastic
optimization objectives are considered, with the goal of effective RIM
optimization in the latter. Although high fidelity and robustness are often
conflicting objectives, some high fidelity, robust controllers can usually be
found, irrespective of the choice of the quantum control algorithm. However,
for noisy optimization objectives, adaptive sequential decision making
approaches such as reinforcement learning have a cost advantage compared to
standard control algorithms and, in contrast, the infidelities obtained are
more consistent with higher RIM values for low noise levels.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 01:19:57 GMT""},{""version"":""v2"",""created"":""Wed, 1 Mar 2023 21:08:47 GMT""}]","2023-03-29"
"2207.07802","Changxing Ding","Zhiyin Shao, Xinyu Zhang, Meng Fang, Zhifeng Lin, Jian Wang, Changxing
  Ding","Learning Granularity-Unified Representations for Text-to-Image Person
  Re-identification","Accepted by ACM Multimedia 2022",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Text-to-image person re-identification (ReID) aims to search for pedestrian
images of an interested identity via textual descriptions. It is challenging
due to both rich intra-modal variations and significant inter-modal gaps.
Existing works usually ignore the difference in feature granularity between the
two modalities, i.e., the visual features are usually fine-grained while
textual features are coarse, which is mainly responsible for the large
inter-modal gaps. In this paper, we propose an end-to-end framework based on
transformers to learn granularity-unified representations for both modalities,
denoted as LGUR. LGUR framework contains two modules: a Dictionary-based
Granularity Alignment (DGA) module and a Prototype-based Granularity
Unification (PGU) module. In DGA, in order to align the granularities of two
modalities, we introduce a Multi-modality Shared Dictionary (MSD) to
reconstruct both visual and textual features. Besides, DGA has two important
factors, i.e., the cross-modality guidance and the foreground-centric
reconstruction, to facilitate the optimization of MSD. In PGU, we adopt a set
of shared and learnable prototypes as the queries to extract diverse and
semantically aligned features for both modalities in the granularity-unified
feature space, which further promotes the ReID performance. Comprehensive
experiments show that our LGUR consistently outperforms state-of-the-arts by
large margins on both CUHK-PEDES and ICFG-PEDES datasets. Code will be released
at https://github.com/ZhiyinShao-H/LGUR.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 01:26:10 GMT""}]","2022-07-19"
"2207.07803","Jiahao Qi","Jiahao Qi, Zhiqiang Gong, Xingyue Liu, Kangcheng Bin, Chen Chen,
  Yongqian Li, Wei Xue, Yu Zhang, and Ping Zhong","Masked Spatial-Spectral Autoencoders Are Excellent Hyperspectral
  Defenders","14 pages, 9 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning methodology contributes a lot to the development of
hyperspectral image (HSI) analysis community. However, it also makes HSI
analysis systems vulnerable to adversarial attacks. To this end, we propose a
masked spatial-spectral autoencoder (MSSA) in this paper under self-supervised
learning theory, for enhancing the robustness of HSI analysis systems. First, a
masked sequence attention learning module is conducted to promote the inherent
robustness of HSI analysis systems along spectral channel. Then, we develop a
graph convolutional network with learnable graph structure to establish global
pixel-wise combinations.In this way, the attack effect would be dispersed by
all the related pixels among each combination, and a better defense performance
is achievable in spatial aspect.Finally, to improve the defense transferability
and address the problem of limited labelled samples, MSSA employs spectra
reconstruction as a pretext task and fits the datasets in a self-supervised
manner.Comprehensive experiments over three benchmarks verify the effectiveness
of MSSA in comparison with the state-of-the-art hyperspectral classification
methods and representative adversarial defense strategies.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 01:33:13 GMT""}]","2022-07-19"
"2207.07804","Christopher Stokes","Christopher Stokes","On Gauss factorials and their connection to the cyclotomic
  $\lambda$-invariants of imaginary quadratic fields",,,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we establish a connection between the Gauss factorials and
Iwasawa's cyclotomic $\lambda$-invariant for an imaginary quadratic field $K$.
As a result, we will explain a corespondance between the 1-exceptional primes
of Cosgrave and Dilcher for $m = 3$ and $m = 4$, and the primes for which the
$\lambda$-invariants for $K = \mathbb{Q}(\sqrt{-3})$ and $K = \mathbb{Q}(i)$ is
greater than one, respectively. We refer to the latter primes as
``non-trivial'' for their respective fields. We will also see that similar
correspondences are true for $K = \mathbb{Q}(\sqrt{-d})$ when $d = 2,5$ and
$6$. As a corollary we find that primes $p$ of the form $p^2 = 3x^2 + 3x + 1$
are always non-trivial for $K = \mathbb{Q}(\sqrt{-3})$. Last, we show that the
non-trivial primes $p$ for $K = \mathbb{Q}(i)$ and $K = \mathbb{Q}(\sqrt{-3})$
are characterized by modulo $p^2$ congruences involving Euler and Glaisher
numbers respectively.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 01:33:30 GMT""},{""version"":""v2"",""created"":""Thu, 3 Nov 2022 16:11:02 GMT""},{""version"":""v3"",""created"":""Fri, 2 Dec 2022 01:19:23 GMT""}]","2022-12-05"
"2207.07805","Micah Buuck","M. Buuck, A. Mishra, E. Charles, N. Di Lalla, O. Hitchcock, M.E.
  Monzani, N. Omodei, T. Shutt","Low-Energy Electron-Track Imaging for a Liquid Argon
  Time-Projection-Chamber Telescope Concept using Probabilistic Deep Learning",,,"10.3847/1538-4357/aca329",,"astro-ph.IM","http://creativecommons.org/licenses/by-sa/4.0/","  The GammaTPC is an MeV-scale single-phase liquid argon
time-projection-chamber gamma-ray telescope concept with a novel dual-scale
pixel-based charge-readout system. It promises to enable a significant
improvement in sensitivity to MeV-scale gamma-rays over previous telescopes.
The novel pixel-based charge readout allows for imaging of the tracks of
electrons scattered by Compton interactions of incident gamma-rays. The two
primary contributors to the accuracy of a Compton telescope in reconstructing
an incident gamma-ray's original direction are its energy and position
resolution. In this work, we focus on using deep learning to optimize the
reconstruction of the initial position and direction of electrons scattered in
Compton interactions, including using probabilistic models to estimate
predictive uncertainty. We show that the deep learning models are able to
predict locations of Compton scatters of MeV-scale gamma-rays from simulated
pixel-based data to better than 0.6 mm RMS error, and are sensitive to the
initial direction of the scattered electron. We compare and contrast different
deep learning uncertainty estimation algorithms for reconstruction
applications. Additionally, we show that event-by-event estimates of the
uncertainty of the locations of the Compton scatters can be used to select
those events that were reconstructed most accurately, leading to improvement in
locating the origin of gamma-ray sources on the sky.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 01:33:47 GMT""},{""version"":""v2"",""created"":""Thu, 17 Nov 2022 20:33:44 GMT""}]","2023-01-25"
"2207.07806","Doruk Senkal","Eric Rosen and Doruk Senkal","CHARM: A Hierarchical Deep Learning Model for Classification of Complex
  Human Activities Using Motion Sensors","8 pages, 5 figures",,,,"cs.LG eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we report a hierarchical deep learning model for
classification of complex human activities using motion sensors. In contrast to
traditional Human Activity Recognition (HAR) models used for event-based
activity recognition, such as step counting, fall detection, and gesture
identification, this new deep learning model, which we refer to as CHARM
(Complex Human Activity Recognition Model), is aimed for recognition of
high-level human activities that are composed of multiple different low-level
activities in a non-deterministic sequence, such as meal preparation, house
chores, and daily routines. CHARM not only quantitatively outperforms
state-of-the-art supervised learning approaches for high-level activity
recognition in terms of average accuracy and F1 scores, but also automatically
learns to recognize low-level activities, such as manipulation gestures and
locomotion modes, without any explicit labels for such activities. This opens
new avenues for Human-Machine Interaction (HMI) modalities using wearable
sensors, where the user can choose to associate an automated task with a
high-level activity, such as controlling home automation (e.g., robotic vacuum
cleaners, lights, and thermostats) or presenting contextually relevant
information at the right time (e.g., reminders, status updates, and
weather/news reports). In addition, the ability to learn low-level user
activities when trained using only high-level activity labels may pave the way
to semi-supervised learning of HAR tasks that are inherently difficult to
label.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 01:36:54 GMT""}]","2022-07-19"
"2207.07807","Kaito Kimura","Kaito Kimura","Asymptotic stability of depths of localizations of modules","8 pages",,,,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let R be a commutative noetherian ring, I an ideal of R, and M a finitely
generated R-module. The asymptotic behavior of the quotient modules M/I^n M of
M is an actively studied subject in commutative algebra. The main result of
this paper asserts that the depth of the localization of M/I^n M at any prime
ideal of R is stable for large integers n that do not depend on the prime
ideal, if the module M or M/I^n M is Cohen-Macaulay for some n>0, or the ring R
is one of the following: a homomorphic image of a Cohen-Macaulay ring, a
semi-local ring, an excellent ring, a quasi-excellent and catenary ring, and an
acceptable ring.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 01:50:42 GMT""}]","2022-07-19"
"2207.07808","Desheng Li","Desheng Li, Ruijing Wang, Luyan Zhou","A Note on the Krein-Rutman Theorem for Sectorial Operators","17 pages",,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  In this note we present some generalized versions of the Krein-Rutman theorem
for sectorial operators. They are formulated in a fashion that can be easily
applied to elliptic operators. Another feature of these generalized versions is
that they contain some information on the generalized eigenspaces associated
with non-principal eigenvalues, which are helpful in the study of the dynamics
of evolution equations in ordered Banach spaces.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 01:53:43 GMT""}]","2022-07-19"
"2207.07809","Haoqiang Huang","Siu-Wing Cheng, Haoqiang Huang","Curve Simplification and Clustering under Fr\'echet Distance","30 pages; Corrected some wrong descriptions concerning related work;
  Add some figures for illustration",,,,"cs.CG cs.DS","http://creativecommons.org/licenses/by/4.0/","  We present new approximation results on curve simplification and clustering
under Fr\'echet distance. Let $T = \{\tau_i : i \in [n] \}$ be polygonal curves
in $R^d$ of $m$ vertices each. Let $l$ be any integer from $[m]$. We study a
generalized curve simplification problem: given error bounds $\delta_i > 0$ for
$i \in [n]$, find a curve $\sigma$ of at most $l$ vertices such that
$d_F(\sigma,\tau_i) \le \delta_i$ for $i \in [n]$. We present an algorithm that
returns a null output or a curve $\sigma$ of at most $l$ vertices such that
$d_F(\sigma,\tau_i) \le \delta_i + \epsilon\delta_{\max}$ for $i \in [n]$,
where $\delta_{\max} = \max_{i \in [n]} \delta_i$. If the output is null, there
is no curve of at most $l$ vertices within a Fr\'echet distance of $\delta_i$
from $\tau_i$ for $i \in [n]$. The running time is $\tilde{O}\bigl(n^{O(l)}
m^{O(l^2)} (dl/\epsilon)^{O(dl)}\bigr)$. This algorithm yields the first
polynomial-time bicriteria approximation scheme to simplify a curve $\tau$ to
another curve $\sigma$, where the vertices of $\sigma$ can be anywhere in
$R^d$, so that $d_F(\sigma,\tau) \le (1+\epsilon)\delta$ and $|\sigma| \le
(1+\alpha) \min\{|c| : d_F(c,\tau) \le \delta\}$ for any given $\delta > 0$ and
any fixed $\alpha, \epsilon \in (0,1)$. The running time is
$\tilde{O}\bigl(m^{O(1/\alpha)} (d/(\alpha\epsilon))^{O(d/\alpha)}\bigr)$.
  By combining our technique with some previous results in the literature, we
obtain an approximation algorithm for $(k,l)$-median clustering. Given $T$, it
computes a set $\Sigma$ of $k$ curves, each of $l$ vertices, such that $\sum_{i
\in [n]} \min_{\sigma \in \Sigma} d_F(\sigma,\tau_i)$ is within a factor
$1+\epsilon$ of the optimum with probability at least $1-\mu$ for any given
$\mu, \epsilon \in (0,1)$. The running time is $\tilde{O}\bigl(n m^{O(kl^2)}
\mu^{-O(kl)} (dkl/\epsilon)^{O((dkl/\epsilon)\log(1/\mu))}\bigr)$.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 01:55:33 GMT""},{""version"":""v2"",""created"":""Wed, 7 Sep 2022 02:38:37 GMT""},{""version"":""v3"",""created"":""Tue, 8 Nov 2022 00:20:23 GMT""}]","2022-11-09"
"2207.07810","Ji Chen","Yubing Qian, Weizhong Fu, Weiluo Ren, Ji Chen","Interatomic force from neural network based variational quantum Monte
  Carlo",,"J. Chem. Phys. 157, 164104 (2022)","10.1063/5.0112344",,"physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  Accurate ab initio calculations are of fundamental importance in physics,
chemistry, biology, and materials science, which have witnessed rapid
development in the last couple of years with the help of machine learning
computational techniques such as neural networks. Most of the recent efforts
applying neural networks to ab initio calculation have been focusing on the
energy of the system. In this study, we take a step forward and look at the
interatomic force obtained with neural network wavefunction methods by
implementing and testing several commonly used force estimators in variational
quantum Monte Carlo (VMC). Our results show that neural network ansatz can
improve the calculation of interatomic force upon traditional VMC. The relation
between the force error and the quality of neural network, the contribution of
different force terms, and the computational cost of each term are also
discussed to provide guidelines for future applications. Our work demonstrates
that it is promising to apply neural network wavefunction methods in simulating
structures/dynamics of molecules/materials and provide training data for
developing accurate force fields.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 01:59:47 GMT""},{""version"":""v2"",""created"":""Wed, 26 Oct 2022 00:31:41 GMT""}]","2022-10-27"
"2207.07811","Liang Li","Xiao-Feng He and Liang Li and Stephane Lanteri and Kun Li","Model order reduction for parameterized electromagnetic problems using
  matrix decomposition and deep neural networks","25 pages, 16 figures",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A non-intrusive model order reduction (MOR) method for solving parameterized
electromagnetic scattering problems is proposed in this paper. A database
collecting snapshots of high-fidelity solutions is built by solving the
parameterized time-domain Maxwell equations for some values of the material
parameters using a fullwave solver based on a high order discontinuous Galerkin
time-domain (DGTD) method. To perform a prior dimensionality reduction, a set
of reduced basis (RB) functions are extracted from the database via a two-step
proper orthogonal decomposition (POD) method. Projection coefficients of the
reduced basis functions are further compressed through a convolutional
autoencoder (CAE) network. Singular value decomposition (SVD) is then used to
extract the principal components of the reduced-order matrices generated by
CAE, and a cubic spline interpolation-based (CSI) approach is employed for
approximating the dominating time- and parameter-modes of the reduced-order
matrices. The generation of the reduced basis and the training of the CAE and
CSI are accomplished in the offline stage, thus the RB solution for given
time/parameter values can be quickly recovered via outputs of the interpolation
model and decoder network. In particular, the offline and online stages of the
proposed RB method are completely decoupled, which ensures the validity of the
method. The performance of the proposed CAE-CSI ROM is illustrated with
numerical experiments for scattering of a plane wave by a 2-D dielectric disk
and a multi-layer heterogeneous medium.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 02:21:06 GMT""}]","2022-07-19"
"2207.07812","Weiqing Ren","Weiqing Ren, Yuben Qu, Chao Dong, Yuqian Jing, Hao Sun, Qihui Wu, Song
  Guo","A Survey on Collaborative DNN Inference for Edge Intelligence",,,,,"cs.DC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the vigorous development of artificial intelligence (AI), the
intelligent applications based on deep neural network (DNN) change people's
lifestyles and the production efficiency. However, the huge amount of
computation and data generated from the network edge becomes the major
bottleneck, and traditional cloud-based computing mode has been unable to meet
the requirements of real-time processing tasks. To solve the above problems, by
embedding AI model training and inference capabilities into the network edge,
edge intelligence (EI) becomes a cutting-edge direction in the field of AI.
Furthermore, collaborative DNN inference among the cloud, edge, and end device
provides a promising way to boost the EI. Nevertheless, at present, EI oriented
collaborative DNN inference is still in its early stage, lacking a systematic
classification and discussion of existing research efforts. Thus motivated, we
have made a comprehensive investigation on the recent studies about EI oriented
collaborative DNN inference. In this paper, we firstly review the background
and motivation of EI. Then, we classify four typical collaborative DNN
inference paradigms for EI, and analyze the characteristics and key
technologies of them. Finally, we summarize the current challenges of
collaborative DNN inference, discuss the future development trend and provide
the future research direction.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 02:32:35 GMT""}]","2022-07-19"
"2207.07813","Vainavi Viswanath","Vainavi Viswanath, Kaushik Shivakumar, Justin Kerr, Brijen
  Thananjeyan, Ellen Novoseller, Jeffrey Ichnowski, Alejandro Escontrela,
  Michael Laskey, Joseph E. Gonzalez, Ken Goldberg","Autonomously Untangling Long Cables",,,,,"cs.RO cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cables are ubiquitous in many settings and it is often useful to untangle
them. However, cables are prone to self-occlusions and knots, making them
difficult to perceive and manipulate. The challenge increases with cable
length: long cables require more complex slack management to facilitate
observability and reachability. In this paper, we focus on autonomously
untangling cables up to 3 meters in length using a bilateral robot. We develop
RGBD perception and motion primitives to efficiently untangle long cables and
novel gripper jaws specialized for this task. We present Sliding and Grasping
for Tangle Manipulation (SGTM), an algorithm that composes these primitives to
iteratively untangle cables with success rates of 67% on isolated overhand and
figure-eight knots and 50% on more complex configurations. Supplementary
material, visualizations, and videos can be found at
https://sites.google.com/view/rss-2022-untangling/home.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 02:35:09 GMT""},{""version"":""v2"",""created"":""Sun, 31 Jul 2022 19:24:31 GMT""}]","2022-08-02"
"2207.07814","Fekadu L. Bayisa Dr.","Fekadu L. Bayisa, Markus {\AA}dahl, Patrik Ryd\'en, Ottmar Cronie","Spatial point process via regularisation modelling of ambulance call
  risk",,,,,"stat.AP stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study investigates the spatial distribution of emergency alarm call
events to identify spatial covariates associated with the events and discern
hotspot regions for the events. The study is motivated by the problem of
developing optimal dispatching strategies for prehospital resources such as
ambulances. To achieve our goals, we model the spatially varying call
occurrence risk as an intensity function of an inhomogeneous spatial Poisson
process that we assume is a log-linear function of some underlying spatial
covariates. The spatial covariates used in this study are related to road
network coverage, population density, and the socio-economic status of the
population in Skellefte{\aa}, Sweden. A new heuristic algorithm has been
developed to select an optimal estimate of the kernel bandwidth in order to
obtain the non-parametric intensity estimate of the events and to generate
other covariates. Since we consider a large number of spatial covariates as
well as their products, and since some of them may be strongly correlated,
lasso-like elastic-net regularisation has been used in the log-likelihood
intensity modeling to perform variable selection and reduce variance inflation
from overfitting and bias from underfitting. As a result of the variable
selection, the fitted model structure contains individual covariates of both
road network and demographic types. We discovered that hotspot regions of calls
have been observed along dense parts of the road network. Evaluation of the
model also suggests that the estimated model is stable and can be used to
generate a reliable intensity estimate over the region, which can be used as an
input in the problem of designing prehospital resource dispatching strategies.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 02:37:50 GMT""}]","2022-07-19"
"2207.07815","Junxuan Li","Junxuan Li and Hongdong Li","Self-calibrating Photometric Stereo by Neural Inverse Rendering","Accepted to ECCV 2022. Code: https://github.com/junxuan-li/SCPS-NIR",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  This paper tackles the task of uncalibrated photometric stereo for 3D object
reconstruction, where both the object shape, object reflectance, and lighting
directions are unknown. This is an extremely difficult task, and the challenge
is further compounded with the existence of the well-known generalized
bas-relief (GBR) ambiguity in photometric stereo. Previous methods to resolve
this ambiguity either rely on an overly simplified reflectance model, or assume
special light distribution. We propose a new method that jointly optimizes
object shape, light directions, and light intensities, all under general
surfaces and lights assumptions. The specularities are used explicitly to solve
uncalibrated photometric stereo via a neural inverse rendering process. We
gradually fit specularities from shiny to rough using novel progressive
specular bases. Our method leverages a physically based rendering equation by
minimizing the reconstruction error on a per-object-basis. Our method
demonstrates state-of-the-art accuracy in light estimation and shape recovery
on real-world datasets.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 02:46:15 GMT""}]","2022-07-19"
"2207.07816","Prasanna Kumar Muthukumar","Michael Shoemate and Kevin Jett and Ethan Cowan and Sean Colbath and
  James Honaker and Prasanna Muthukumar","Sotto Voce: Federated Speech Recognition with Differential Privacy
  Guarantees",,,,,"cs.CR cs.CL","http://creativecommons.org/licenses/by-sa/4.0/","  Speech data is expensive to collect, and incredibly sensitive to its sources.
It is often the case that organizations independently collect small datasets
for their own use, but often these are not performant for the demands of
machine learning. Organizations could pool these datasets together and jointly
build a strong ASR system; sharing data in the clear, however, comes with
tremendous risk, in terms of intellectual property loss as well as loss of
privacy of the individuals who exist in the dataset. In this paper, we offer a
potential solution for learning an ML model across multiple organizations where
we can provide mathematical guarantees limiting privacy loss. We use a
Federated Learning approach built on a strong foundation of Differential
Privacy techniques. We apply these to a senone classification prototype and
demonstrate that the model improves with the addition of private data while
still respecting privacy.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 02:48:54 GMT""}]","2022-07-19"
"2207.07817","Menglu Yu","Menglu Yu and Bo Ji and Hridesh Rajan and Jia Liu","On Scheduling Ring-All-Reduce Learning Jobs in Multi-Tenant GPU Clusters
  with Communication Contention","Accepted in Proc. ACM Mobihoc, July 2022",,,,"cs.DC","http://creativecommons.org/licenses/by/4.0/","  Powered by advances in deep learning (DL) techniques, machine learning and
artificial intelligence have achieved astonishing successes. However, the
rapidly growing needs for DL also led to communication- and resource-intensive
distributed training jobs for large-scale DL training, which are typically
deployed over GPU clusters. To sustain the ever-increasing demand for DL
training, the so-called ""ring-all-reduce"" (RAR) technologies have recently
emerged as a favorable computing architecture to efficiently process network
communication and computation load in GPU clusters. The most salient feature of
RAR is that it removes the need for dedicated parameter servers, thus
alleviating the potential communication bottleneck. However, when multiple
RAR-based DL training jobs are deployed over GPU clusters, communication
bottlenecks could still occur due to contentions between DL training jobs. So
far, there remains a lack of theoretical understanding on how to design
contention-aware resource scheduling algorithms for RAR-based DL training jobs,
which motivates us to fill this gap in this work. Our main contributions are
three-fold: i) We develop a new analytical model that characterizes both
communication overhead related to the worker distribution of the job and
communication contention related to the co-location of different jobs; ii)
Based on the proposed analytical model, we formulate the problem as a
non-convex integer program to minimize the makespan of all RAR-based DL
training jobs. To address the unique structure in this problem that is not
amenable for optimization algorithm design, we reformulate the problem into an
integer linear program that enables provable approximation algorithm design
called SJF-BCO (Smallest Job First with Balanced Contention and Overhead); and
iii) We conduct extensive experiments to show the superiority of SJF-BCO over
existing schedulers.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 02:49:40 GMT""},{""version"":""v2"",""created"":""Sun, 14 Aug 2022 22:32:07 GMT""}]","2022-08-16"
"2207.07818","Lei Zhu","Lei Zhu, Qian Chen, Lujia Jin, Yunfei You, and Yanye Lu","Bagging Regional Classification Activation Maps for Weakly Supervised
  Object Localization","Accepted by ECCV 2022",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Classification activation map (CAM), utilizing the classification structure
to generate pixel-wise localization maps, is a crucial mechanism for weakly
supervised object localization (WSOL). However, CAM directly uses the
classifier trained on image-level features to locate objects, making it prefers
to discern global discriminative factors rather than regional object cues. Thus
only the discriminative locations are activated when feeding pixel-level
features into this classifier. To solve this issue, this paper elaborates a
plug-and-play mechanism called BagCAMs to better project a well-trained
classifier for the localization task without refining or re-training the
baseline structure. Our BagCAMs adopts a proposed regional localizer generation
(RLG) strategy to define a set of regional localizers and then derive them from
a well-trained classifier. These regional localizers can be viewed as the base
learner that only discerns region-wise object factors for localization tasks,
and their results can be effectively weighted by our BagCAMs to form the final
localization map. Experiments indicate that adopting our proposed BagCAMs can
improve the performance of baseline WSOL methods to a great extent and obtains
state-of-the-art performance on three WSOL benchmarks. Code are released at
https://github.com/zh460045050/BagCAMs.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 03:03:01 GMT""}]","2022-07-19"
"2207.07819","Seo Hyoung Chang","Kook Tae Kim, Yeong Jae Shinb, Sung-Jin Kang, Ryung Kim, Miyoung Kim,
  Tae Won Noh, Yongseong Choi, Seo Hyoung Chang, Dong Ryeol Lee","Experimental verification of polar structures in ultrathin BaTiO_{3}
  layers using resonant x-ray reflectivity","26 pages, 5 figures",,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Functional devices with ultrathin ferroelectric layers have been attracted as
a promising candidate for next-generation memory and logic device applications.
Using the ultrathin ferroelectric layers, particularly approaching the
two-dimensional limit, however, it is still challenging to control
ferroelectric switching and to observe ferroelectricity by spectroscopic tools.
In particular, conventional methods such as electrical measurements and
piezoelectric response force microscopy are very limited due to leakage
currents and the smallness of the ferroelectric signals. Here, we show that the
ferroelectricity of ultrathin SrRuO3/BaTiO3/SrRuO3 heterostructures grown on
SrTiO3(100) substrates can be measured using resonant x-ray reflectivity
(RXRR). This experimental technique can provide an element-specific electronic
depth profile as well as increased sensitivity to Ti off-center displacements
at the Ti K pre-edge. The depth-sensitivity of RXRR selectively detects the
strong polarization dependence of the Ti pre-edge features of ultrathin BaTiO3
layers while discriminating the contribution of the SrTiO3 substrate. This
technique verified that the BaTiO3 layer can be ferroelectric down to the
lowest experimental limit of a critical thickness of 2.5 unit cells. Our
results can open a novel way to explore ultrathin ferroelectric-based
nano-electronic devices.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 03:03:38 GMT""}]","2022-07-19"
"2207.07820","Ryan Denlinger","Thomas Chen, Ryan Denlinger, Nata\v{s}a Pavlovi\'c","On an $L^2$ critical Boltzmann equation","AMS Latex, 119 pages",,,,"math.AP math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove the existence of a class of large global scattering solutions of
Boltzmann's equation with constant collision kernel in two dimensions. These
solutions are found for $L^2$ perturbations of an underlying initial data which
is Gaussian jointly in space and velocity. Additionally, the perturbation is
required to satisfy natural physical constraints for the total mass and second
moments, corresponding to conserved or controlled quantities. The space $L^2$
is a scaling critical space for the equation under consideration. If the
initial data is Schwartz then the solution is unique and again Schwartz on any
bounded time interval.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 03:04:47 GMT""},{""version"":""v2"",""created"":""Thu, 27 Oct 2022 14:58:18 GMT""}]","2022-10-28"
"2207.07821","Chen-Huan Wu","Chen-Huan Wu","Statistic behaviors of gauge-invariance-dominated 1D chiral current
  random model",,,,,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  By considering energy flow, we construct the one-dimensional (1d) model
consisting of the quasiparticles caused by asymmetric hopping (in carrier
position space) or the complex bosonic potential whose varying gradience with a
chiral ordering plays the role of ingredience of quasiparticles. A bosonic
potential can be generated and the chaotic dynamics of chiral excitations after
disorder average can be investigated in the presence of gauge invariance. This
feature is also shared by the well-known non-Hermitian systems.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 03:08:54 GMT""},{""version"":""v2"",""created"":""Sat, 14 Jan 2023 23:47:51 GMT""}]","2023-01-18"
"2207.07822","Samson Zhou","Sepideh Mahabadi, David P. Woodruff, Samson Zhou","Adaptive Sketches for Robust Regression with Importance Sampling","RANDOM 2022",,,,"cs.LG cs.DS","http://creativecommons.org/licenses/by/4.0/","  We introduce data structures for solving robust regression through stochastic
gradient descent (SGD) by sampling gradients with probability proportional to
their norm, i.e., importance sampling. Although SGD is widely used for large
scale machine learning, it is well-known for possibly experiencing slow
convergence rates due to the high variance from uniform sampling. On the other
hand, importance sampling can significantly decrease the variance but is
usually difficult to implement because computing the sampling probabilities
requires additional passes over the data, in which case standard gradient
descent (GD) could be used instead. In this paper, we introduce an algorithm
that approximately samples $T$ gradients of dimension $d$ from nearly the
optimal importance sampling distribution for a robust regression problem over
$n$ rows. Thus our algorithm effectively runs $T$ steps of SGD with importance
sampling while using sublinear space and just making a single pass over the
data. Our techniques also extend to performing importance sampling for
second-order optimization.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 03:09:30 GMT""}]","2022-07-19"
"2207.07823","Xi Zhao","Yao Tian, Xi Zhao, Xiaofang Zhou","DB-LSH: Locality-Sensitive Hashing with Query-based Dynamic Bucketing","Accepted by ICDE 2022",,,,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Among many solutions to the high-dimensional approximate nearest neighbor
(ANN) search problem, locality sensitive hashing (LSH) is known for its
sub-linear query time and robust theoretical guarantee on query accuracy.
Traditional LSH methods can generate a small number of candidates quickly from
hash tables but suffer from large index sizes and hash boundary problems.
Recent studies to address these issues often incur extra overhead to identify
eligible candidates or remove false positives, making query time no longer
sub-linear. To address this dilemma, in this paper we propose a novel LSH
scheme called DB-LSH which supports efficient ANN search for large
high-dimensional datasets. It organizes the projected spaces with
multi-dimensional indexes rather than using fixed-width hash buckets. Our
approach can significantly reduce the space cost as by avoiding the need to
maintain many hash tables for different bucket sizes. During the query phase of
DB-LSH, a small number of high-quality candidates can be generated efficiently
by dynamically constructing query-based hypercubic buckets with the required
widths through index-based window queries. For a dataset of $n$ $d$-dimensional
points with approximation ratio $c$, our rigorous theoretical analysis shows
that DB-LSH achieves a smaller query cost ${O(n^{\rho^*} d\log n)}$, where
${\rho^*}$ is bounded by ${1/c^{\alpha}}$ while the bound is ${1/c}$ in the
existing work. An extensive range of experiments on real-world data
demonstrates the superiority of DB-LSH over state-of-the-art methods on both
efficiency and accuracy.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 03:18:11 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jul 2022 16:18:31 GMT""}]","2022-07-21"
"2207.07824","Zhenyuan Yuan","Zhenyuan Yuan and Minghui Zhu","Distributed Safe Learning and Planning for Multi-robot Systems",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  This paper considers the problem of online multi-robot motion planning with
general nonlinear dynamics subject to unknown external disturbances. We propose
dSLAP, a distributed safe learning and planning framework that allows the
robots to safely navigate through the environments by coupling online learning
and motion planning. Gaussian process regression is used to online learn the
disturbances with uncertainty quantification. The safe motion planning
algorithm ensures collision avoidance against the learning uncertainty and
utilizes set-valued analysis to achieve fast adaptation in response to the
newly learned models. A model predictive control problem is then formulated and
solved to return a control policy that balances between actively exploring the
unknown disturbances and reaching goal regions. Sufficient conditions are
established to guarantee the safety of the robots in the absence of backup
policy. Monte Carlo simulations are conducted for evaluation.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 03:18:12 GMT""},{""version"":""v2"",""created"":""Fri, 5 Aug 2022 04:45:13 GMT""},{""version"":""v3"",""created"":""Thu, 22 Dec 2022 04:27:28 GMT""},{""version"":""v4"",""created"":""Fri, 23 Dec 2022 04:02:18 GMT""}]","2022-12-26"
"2207.07825","Richard Kohar","Richard Kohar, Fran\c{c}ois Rivest and Alain Gosselin","ChronosPerseus: Randomized Point-based Value Iteration with Importance
  Sampling for POSMDPs","33 pages, 9 figures",,,,"cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In reinforcement learning, agents have successfully used environments modeled
with Markov decision processes (MDPs). However, in many problem domains, an
agent may suffer from noisy observations or random times until its subsequent
decision. While partially observable Markov decision processes (POMDPs) have
dealt with noisy observations, they have yet to deal with the unknown time
aspect. Of course, one could discretize the time, but this leads to Bellman's
Curse of Dimensionality. To incorporate continuous sojourn-time distributions
in the agent's decision making, we propose that partially observable
semi-Markov decision processes (POSMDPs) can be helpful in this regard. We
extend \citet{Spaan2005a} randomized point-based value iteration (PBVI)
\textsc{Perseus} algorithm used for POMDP to POSMDP by incorporating continuous
sojourn time distributions and using importance sampling to reduce the solver
complexity. We call this new PBVI algorithm with importance sampling for
POSMDPs -- \textsc{ChronosPerseus}. This further allows for compressed complex
POMDPs requiring temporal state information by moving this information into
state sojourn time of a POMSDP. The second insight is that keeping a set of
sampled times and weighting it by its likelihood can be used in a single
backup; this helps further reduce the algorithm complexity. The solver also
works on episodic and non-episodic problems. We conclude our paper with two
examples, an episodic bus problem and a non-episodic maintenance problem.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 03:31:47 GMT""}]","2022-07-19"
"2207.07826","Wentao Chen","Wentao Chen, Zhang Zhang, Wei Wang, Liang Wang, Zilei Wang, Tieniu Tan","Cross-Domain Cross-Set Few-Shot Learning via Learning Compact and
  Aligned Representations","Accepted by ECCV 2022",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Few-shot learning (FSL) aims to recognize novel queries with only a few
support samples through leveraging prior knowledge from a base dataset. In this
paper, we consider the domain shift problem in FSL and aim to address the
domain gap between the support set and the query set. Different from previous
cross-domain FSL work (CD-FSL) that considers the domain shift between base and
novel classes, the new problem, termed cross-domain cross-set FSL (CDSC-FSL),
requires few-shot learners not only to adapt to the new domain, but also to be
consistent between different domains within each novel class. To this end, we
propose a novel approach, namely stabPA, to learn prototypical compact and
cross-domain aligned representations, so that the domain shift and few-shot
learning can be addressed simultaneously. We evaluate our approach on two new
CDCS-FSL benchmarks built from the DomainNet and Office-Home datasets
respectively. Remarkably, our approach outperforms multiple elaborated
baselines by a large margin, e.g., improving 5-shot accuracy by 6.0 points on
average on DomainNet. Code is available at
https://github.com/WentaoChen0813/CDCS-FSL
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 03:40:38 GMT""}]","2022-07-19"
"2207.07827","Mingjie Li","Xiaoyun Zhao, Rui Liu, Mingjie Li, Guangsi Shi, Mingfei Han, Changlin
  Li, Ling Chen, and Xiaojun Chang","Generalizable Memory-driven Transformer for Multivariate Long Sequence
  Time-series Forecasting","Tech report",,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  Multivariate long sequence time-series forecasting (M-LSTF) is a practical
but challenging problem. Unlike traditional timer-series forecasting tasks,
M-LSTF tasks are more challenging from two aspects: 1) M-LSTF models need to
learn time-series patterns both within and between multiple time features; 2)
Under the rolling forecasting setting, the similarity between two consecutive
training samples increases with the increasing prediction length, which makes
models more prone to overfitting. In this paper, we propose a generalizable
memory-driven Transformer to target M-LSTF problems. Specifically, we first
propose a global-level memory component to drive the forecasting procedure by
integrating multiple time-series features. In addition, we adopt a progressive
fashion to train our model to increase its generalizability, in which we
gradually introduce Bernoulli noises to training samples. Extensive experiments
have been performed on five different datasets across multiple fields.
Experimental results demonstrate that our approach can be seamlessly plugged
into varying Transformer-based models to improve their performances up to
roughly 30%. Particularly, this is the first work to specifically focus on the
M-LSTF tasks to the best of our knowledge.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 04:05:15 GMT""},{""version"":""v2"",""created"":""Sun, 21 May 2023 08:30:56 GMT""},{""version"":""v3"",""created"":""Wed, 31 May 2023 15:37:31 GMT""}]","2023-06-01"
"2207.07828","Cong Wang","Cong Wang and Jinshan Pan and Xiao-Ming Wu","Structural Prior Guided Generative Adversarial Transformers for
  Low-Light Image Enhancement",,,,,"cs.CV eess.IV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We propose an effective Structural Prior guided Generative Adversarial
Transformer (SPGAT) to solve low-light image enhancement. Our SPGAT mainly
contains a generator with two discriminators and a structural prior estimator
(SPE). The generator is based on a U-shaped Transformer which is used to
explore non-local information for better clear image restoration. The SPE is
used to explore useful structures from images to guide the generator for better
structural detail estimation. To generate more realistic images, we develop a
new structural prior guided adversarial learning method by building the skip
connections between the generator and discriminators so that the discriminators
can better discriminate between real and fake features. Finally, we propose a
parallel windows-based Swin Transformer block to aggregate different level
hierarchical features for high-quality image restoration. Experimental results
demonstrate that the proposed SPGAT performs favorably against recent
state-of-the-art methods on both synthetic and real-world datasets.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 04:05:40 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jul 2022 04:00:36 GMT""}]","2022-07-20"
"2207.07829","Subramanya Nageshrao","Subramanya Nageshrao, Yousaf Rahman, Vladimir Ivanovic, Mrdjan
  Jankovic, Eric Tseng, Michael Hafner, and Dimitar Filev","Robust AI Driving Strategy for Autonomous Vehicles",,,,,"cs.RO cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  There has been significant progress in sensing, perception, and localization
for automated driving, However, due to the wide spectrum of traffic/road
structure scenarios and the long tail distribution of human driver behavior, it
has remained an open challenge for an intelligent vehicle to always know how to
make and execute the best decision on road given available sensing / perception
/ localization information. In this chapter, we talk about how artificial
intelligence and more specifically, reinforcement learning, can take advantage
of operational knowledge and safety reflex to make strategical and tactical
decisions. We discuss some challenging problems related to the robustness of
reinforcement learning solutions and their implications to the practical design
of driving strategies for autonomous vehicles. We focus on automated driving on
highway and the integration of reinforcement learning, vehicle motion control,
and control barrier function, leading to a robust AI driving strategy that can
learn and adapt safely.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 04:09:10 GMT""}]","2022-07-19"
"2207.07830","Suman Banerjee","Poonam Sharma, Suman Banerjee","Profit Maximization using Social Networks in Two-Phase Setting","15 Pages, 6 Figures",,,,"cs.DB","http://creativecommons.org/licenses/by/4.0/","  Now-a-days, \emph{Online Social Networks} have been predominantly used by
commercial houses for viral marketing where the goal is to maximize profit. In
this paper, we study the problem of Profit Maximization in the two\mbox{-}phase
setting. The input to the problem is a \emph{social network} where the users
are associated with a cost and benefit value, and a fixed amount of budget
splitted into two parts. Here, the cost and the benefit associated with a node
signify its incentive demand and the amount of benefit that can be earned by
influencing that user, respectively. The goal of this problem is to find out
the optimal seed sets for both phases such that the aggregated profit at the
end of the diffusion process is maximized. First, we develop a mathematical
model based on the \emph{Independent Cascade Model} of diffusion that captures
the aggregated profit in an \emph{expected} sense. Subsequently, we show that
selecting an optimal seed set for the first phase even considering the optimal
seed set for the second phase can be selected efficiently, is an
$\textsf{NP}$-Hard Problem. Next, we propose two solution methodologies, namely
the \emph{single greedy} and the \emph{double greedy} approach for our problem
that works based on marginal gain computation. A detailed analysis of both
methodologies has been done to understand their time and space requirements. We
perform an extensive set of experiments to demonstrate the effectiveness and
efficiency of the proposed approaches with real-world datasets. From the
experiments, we observe that the proposed solution approaches lead to more
profit compared to the baseline methods and in particular, the double greedy
approach leads to up to $5 \%$ improvement compared to its single\mbox{-}phase
counterpart.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 04:13:42 GMT""}]","2022-07-19"
"2207.07831","Suman Banerjee","Mayank Singhal and Suman Banerjee","Utility Driven Job Selection Problem on Road Networks","Accepted @ACIIDS 2022 as a Full Paper. 13 Pages. 6 Figures",,,,"cs.DB","http://creativecommons.org/licenses/by/4.0/","  In this paper, we study the problem of \textsc{Utility Driven Job Selection}
on Road Networks for which the inputs are: a road network with the vertices as
the set of Point-Of-Interests (Henceforth mentioned as POI) and the edges are
road segments joining the POIs, a set of jobs with their originating POI,
starting time, duration, and the utility. A worker can earn the utility
associated with the job if (s)he performs this. As the jobs are originating at
different POIs, the worker has to move from one POI to the other one to take up
the job. Some budget is available for this purpose. Any two jobs can be taken
up by the worker only if the finishing time of the first job plus traveling
time from the POI of the first job to the second one should be less than or
equal to the starting time of the second job. We call this constraint as the
temporal constraint. The goal of this problem is to choose a subset of the jobs
to maximize the earned utility such that the budget and temporal constraints
should not be violated. We present two solution approaches with detailed
analysis. First one of them works based on finding the locally optimal job at
the end of every job and we call this approach as the \emph{Best First Search
Approach}. The other approach is based on the Nearest Neighbor Search on road
networks. We perform a set of experiments with real\mbox{-}world trajectory
datasets to demonstrate the efficiency and effectiveness of the proposed
solution approaches. We observe that the proposed approaches lead to more
utility compared to baseline methods.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 04:35:59 GMT""}]","2022-07-19"
"2207.07832","William Chang","William Chang, Hassan Hamad, Keith M. Chugg","Approximation Capabilities of Neural Networks using Morphological
  Perceptrons and Generalizations","7 pages",,,,"cs.LG cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Standard artificial neural networks (ANNs) use sum-product or
multiply-accumulate node operations with a memoryless nonlinear activation.
These neural networks are known to have universal function approximation
capabilities. Previously proposed morphological perceptrons use max-sum, in
place of sum-product, node processing and have promising properties for circuit
implementations. In this paper we show that these max-sum ANNs do not have
universal approximation capabilities. Furthermore, we consider proposed
signed-max-sum and max-star-sum generalizations of morphological ANNs and show
that these variants also do not have universal approximation capabilities. We
contrast these variations to log-number system (LNS) implementations which also
avoid multiplications, but do exhibit universal approximation capabilities.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 04:41:37 GMT""}]","2022-07-19"
"2207.07833","Zhiqian Chen","Zonghan Zhang and Zhiqian Chen","Understanding Influence Maximization via Higher-Order Decomposition","SIAM Data Mining 2023",,,,"cs.SI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Given its vast application on online social networks, Influence Maximization
(IM) has garnered considerable attention over the last couple of decades. Due
to the intricacy of IM, most current research concentrates on estimating the
first-order contribution of the nodes to select a seed set, disregarding the
higher-order interplay between different seeds. Consequently, the actual
influence spread frequently deviates from expectations, and it remains unclear
how the seed set quantitatively contributes to this deviation. To address this
deficiency, this work dissects the influence exerted on individual seeds and
their higher-order interactions utilizing the Sobol index, a variance-based
sensitivity analysis. To adapt to IM contexts, seed selection is phrased as
binary variables and split into distributions of varying orders. Based on our
analysis with various Sobol indices, an IM algorithm dubbed SIM is proposed to
improve the performance of current IM algorithms by over-selecting nodes
followed by strategic pruning. A case study is carried out to demonstrate that
the explanation of the impact effect can dependably identify the key
higher-order interactions among seeds. SIM is empirically proved to be superior
in effectiveness and competitive in efficiency by experiments on synthetic and
real-world graphs.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 04:44:16 GMT""},{""version"":""v2"",""created"":""Mon, 20 Feb 2023 22:17:39 GMT""},{""version"":""v3"",""created"":""Mon, 27 Feb 2023 14:43:48 GMT""},{""version"":""v4"",""created"":""Thu, 13 Apr 2023 13:53:45 GMT""}]","2023-04-14"
"2207.07834","Biswanath Layek","Biswanath Layek, Deepthi Godaba Venkata, Pradeepkumar Yadav","Glitches due to (quasi) neutron-vortex scattering in the superfluid
  inner crust of a pulsar","12 pages, 5 figures, Accepted for publication in PRD",,"10.1103/PhysRevD.107.023004",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We revisit the mechanism of vortex unpinning caused by the neutron-vortex
scattering \cite{prad1} in the inner crust of a pulsar. The strain energy
released by the crustquake is assumed to be absorbed in some part of the inner
crust and causes pair-breaking quasi-neutron excitations from the existing free
neutron superfluid in the bulk of the inner crust. The scattering of these
quasi-neutrons with the vortex core normal neutrons unpins a large number of
vortices from the thermally affected regions and results in pulsar glitches. We
consider the geometry of a cylindrical shell of the affected pinning region to
study the implications of the vortex unpinning in the context of pulsar
glitches. We find that a pulsar can release about $\sim 10^{11} - 10^{13}$
vortices by this mechanism. These numbers are equivalent to the glitch size of
orders $\sim 10^{-11} - 10^{-9}$ for Vela-like pulsars with the characteristic
age $\tau \simeq 10^4$ years. We also suggest a possibility of a vortex
avalanche triggered by the movement of the unpinned vortices. A rough estimate
of the glitch size caused by an avalanche shows an encouraging result.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 04:55:49 GMT""},{""version"":""v2"",""created"":""Sat, 24 Dec 2022 16:58:17 GMT""}]","2023-01-18"
"2207.07835","Kevin Green","Fangzhou Yu, Ryan Batke, Jeremy Dao, Jonathan Hurst, Kevin Green, Alan
  Fern","Dynamic Bipedal Maneuvers through Sim-to-Real Reinforcement Learning","In review for the 2022 IEEE-RAS International Conference on Humanoid
  Robots. 8 pages, 8 figures, 3 tables",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For legged robots to match the athletic capabilities of humans and animals,
they must not only produce robust periodic walking and running, but also
seamlessly switch between nominal locomotion gaits and more specialized
transient maneuvers. Despite recent advancements in controls of bipedal robots,
there has been little focus on producing highly dynamic behaviors. Recent work
utilizing reinforcement learning to produce policies for control of legged
robots have demonstrated success in producing robust walking behaviors.
However, these learned policies have difficulty expressing a multitude of
different behaviors on a single network. Inspired by conventional
optimization-based control techniques for legged robots, this work applies a
recurrent policy to execute four-step, 90 degree turns trained using reference
data generated from optimized single rigid body model trajectories. We present
a novel training framework using epilogue terminal rewards for learning
specific behaviors from pre-computed trajectory data and demonstrate a
successful transfer to hardware on the bipedal robot Cassie.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 04:57:59 GMT""}]","2022-07-19"
"2207.07836","Suman Banerjee","Mayank Singhal and Suman Banerjee","Envy\mbox{-}free Trip Planning in Group Trip Planning Query Problem","Accepted as a Full Paper @ 25th International Conference on
  Network-Based Information Systems (NBiS-2022). 12 Pages. 6 Figures",,,,"cs.DB","http://creativecommons.org/licenses/by/4.0/","  In recent times, Group Trip Planning Query (henceforth referred to as GTP
Query) is one of the well\mbox{-}studied problems in Spatial Databases. The
inputs to the problem are a road network where the vertices represent the
Point-of-Interests (mentioned as POIs henceforth) and they are grouped into
different categories, edges represent the road segments, and edge weight
represents the distance and a group of users along with their source and
destination location. This problem asks to return one POI from every category
such that the aggregated distance traveled by the group is minimized. As the
objective is to minimize the aggregated distance, the existing solution
methodologies do not consider the individual distances traveled by the group
members. To address this issue, we introduce and study the \textsc{Envy Free
Group Trip Planning Query} Problem. Along with the inputs of the GTP Query
Problem, in this variant, we also have a threshold distance $D$ such that
aggregated distance traveled by the group is minimized and for any member pairs
the difference between their individual distance traveled is less than equal to
$D$. However, it may so happen that a given $D$ value no such set POIs are
found. To tackle this issue, we introduce the surrogate problem \textsc{Envy
Free Group Trip Planning Query with Minimum Additional Distance} Problem which
asks what is the minimum distance to be added with $D$ to obtain at least one
solution. For these problems, we design efficient solution approaches and
experiment with real-world datasets. From the experiments, we observe that the
proposed solution approaches lead to less aggregated distance compared to
baseline methods with reasonable computational overhead.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 04:59:55 GMT""}]","2022-07-19"
"2207.07837","Christopher Mutschler","Mohammad Alawieh, Ernst Eberlein, Stephan J\""ackel, Norbert Franke,
  Birendra Ghimire, Tobias Feigl, George Yammine, Christopher Mutschler","Complementary Semi-Deterministic Clusters for Realistic Statistical
  Channel Models for Positioning","6 pages, 10 figures",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Positioning benefits from channel models that capture geometric effects and,
in particular, from the signal properties of the first arriving path and the
spatial consistency of the propagation condition of multiple links. The models
that capture the physical effects observed in a realistic deployment scenario
are essential for assessing the potential benefits of enhancements in
positioning methods. Channel models based on ray-tracing simulations and
statistical channel models, which are current state-of-the-art methods employed
to evaluate performance of positioning in 3GPP systems, do not fully capture
important aspects applicable to positioning. Hence, we propose an extension of
existing statistical channel models with semi-deterministic clusters (SDCs).
SDCs allow channels to be simulated using three types of clusters: fixed-,
specular-, and random-clusters. Our results show that the proposed model aligns
with measurements obtained in a real deployment scenario. Thus, our channel
models can be used to develop advanced positioning solutions based on machine
learning, which enable positioning with centimeter level accuracy in NLOS and
multipath scenarios.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 05:01:27 GMT""},{""version"":""v2"",""created"":""Mon, 8 Aug 2022 14:01:24 GMT""}]","2022-08-09"
"2207.07838","Christopher Mutschler","Mohammad Alawieh, George Yammine, Ernst Eberlein, Birendra Ghimire,
  Norbert Franke, Stephan J\""ackel, Tobias Feigl, Christopher Mutschler","Towards Realistic Statistical Channel Models For Positioning: Evaluating
  the Impact of Early Clusters","5 pages, 12 figures",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Physical effects such as reflection, refraction, and diffraction cause a
radio signal to arrive from a transmitter to a receiver in multiple replicas
that have different amplitude and rotation. Bandwidth-limited signals, such as
positioning reference signals, have a limited time resolution. In reality, the
signal is often reflected in the close vicinity of a transmitter and receiver,
which causes the displacement of the observed peak from the true peak expected
according to the line of sight (LOS) geometry between the transmitter and
receiver. In this paper, we show that the existing channel model specified for
performance evaluation within 3GPP fails to model the above phenomena. As a
result, the simulation results deviate significantly from the measured values.
Based on our measurement and simulation results, we propose a model for
incorporating the signal reflection by obstacles in the vicinity of transmitter
or receiver, so that the outcome of the model corresponds to the measurement
made in such scenario.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 05:07:54 GMT""},{""version"":""v2"",""created"":""Mon, 8 Aug 2022 14:29:59 GMT""}]","2022-08-09"
"2207.07839","Siu-Wing Cheng","Siu-Wing Cheng and Man Ting Wong","On Non-Negative Quadratic Programming in Geometric Optimization",,,,,"cs.CG","http://creativecommons.org/licenses/by/4.0/","  We present experimental and theoretical results on a method that applies a
numerical solver iteratively to solve several non-negative quadratic
programming problems in geometric optimization. The method gains efficiency by
exploiting the potential sparsity of the intermediate solutions. We implemented
the method to call quadprog of MATLAB iteratively. In comparison with a single
call of quadprog, we obtain a 10-fold speedup on two proximity graph problems
in $\mathbb{R}^d$ on some public data sets, a 10-fold speedup on the minimum
enclosing ball problem on random points in a unit cube in $\mathbb{R}^d$, and a
5-fold speedup on the polytope distance problem on random points from a cube in
$\mathbb{R}^d$ when the input size is significantly larger than the dimension;
we also obtain a 2-fold or more speedup on deblurring some gray-scale space and
thermal images via non-negative least square. We compare with two minimum
enclosing ball software by G\""{a}rtner and Fischer et al.; for 1000 nearly
cospherical points or random points in a unit cube, the iterative method
overtakes the software by G\""{a}rtner at 20 dimensions and the software by
Fischer et al. at 170 dimensions. In the image deblurring experiments, the
iterative method compares favorably with other software that can solve
non-negative least square, including FISTA with backtracking, SBB, FNNLS, and
lsqnonneg of MATLAB. We analyze theoretically the number of iterations taken by
the iterative scheme to reduce the gap between the current solution value and
the optimum by a factor $e$. Under certain assumptions, we prove a bound
proportional to the square root of the number of variables.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 05:10:16 GMT""}]","2022-07-19"
"2207.07840","Kaile Du","Kaile Du, Linyan Li, Fan Lyu, Fuyuan Hu, Zhenping Xia, Fenglei Xu","Class-Incremental Lifelong Learning in Multi-Label Classification","arXiv admin note: substantial text overlap with arXiv:2203.05534",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Existing class-incremental lifelong learning studies only the data is with
single-label, which limits its adaptation to multi-label data. This paper
studies Lifelong Multi-Label (LML) classification, which builds an online
class-incremental classifier in a sequential multi-label classification data
stream. Training on the data with Partial Labels in LML classification may
result in more serious Catastrophic Forgetting in old classes. To solve the
problem, the study proposes an Augmented Graph Convolutional Network (AGCN)
with a built Augmented Correlation Matrix (ACM) across sequential partial-label
tasks. The results of two benchmarks show that the method is effective for LML
classification and reducing forgetting.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 05:14:07 GMT""}]","2022-07-19"
"2207.07841","Yuri Yu. Tarasevich","Yuri Yu. Tarasevich, Andrei V. Eserkepov, Irina V. Vodolazskaya","Random 2D nanowire networks: Finite-size effect and the effect of
  busbar/nanowire contact resistance on their electrical conductivity","10 pages, 11 figures, 1 table, 33 references","Journal of Applied Physics, Vol.132, Iss. 12, 125105 (2022)","10.1063/5.0110523",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have studied the resistance of two-dimensional random percolating networks
of zero-width metallic nanowires (rings or sticks). We toke into account the
nanowire resistance per unit length, the junction (nanowire/nanowire contact)
resistance, and the busbar/nanowire contact resistance. Using a mean-field
approximation (MFA), we derived the total resistance of the nanoring-based
networks as a function of their geometrical and physical parameters. We have
proposed a way of accounting for the contribution of the busbar/nanowire
contact resistance toward the network resistance. The MFA predictions have been
confirmed by our Monte Carlo (MC) numerical simulations. Our study evidenced
that the busbar/nanowire contact resistance has a significant effect on the
electrical conductivity when the junction resistance dominates over wire
resistance.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 05:21:10 GMT""},{""version"":""v2"",""created"":""Fri, 26 Aug 2022 03:23:11 GMT""}]","2022-09-26"
"2207.07842","Sota Kato","Sota Kato, Kazuhiro Hotta","Adaptive t-vMF Dice Loss for Multi-class Medical Image Segmentation",,,,,"eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dice loss is widely used for medical image segmentation, and many improvement
loss functions based on such loss have been proposed. However, further Dice
loss improvements are still possible. In this study, we reconsidered the use of
Dice loss and discovered that Dice loss can be rewritten in the loss function
using the cosine similarity through a simple equation transformation. Using
this knowledge, we present a novel t-vMF Dice loss based on the t-vMF
similarity instead of the cosine similarity. Based on the t-vMF similarity, our
proposed Dice loss is formulated in a more compact similarity loss function
than the original Dice loss. Furthermore, we present an effective algorithm
that automatically determines the parameter $\kappa$ for the t-vMF similarity
using a validation accuracy, called Adaptive t-vMf Dice loss. Using this
algorithm, it is possible to apply more compact similarities for easy classes
and wider similarities for difficult classes, and we are able to achieve an
adaptive training based on the accuracy of the class. Through experiments
conducted on four datasets using a five-fold cross validation, we confirmed
that the Dice score coefficient (DSC) was further improved in comparison with
the original Dice loss and other loss functions.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 05:23:43 GMT""}]","2022-07-19"
"2207.07843","Einan Gardi","Samuel Abreu, Ruth Britto, Claude Duhr, Einan Gardi and James Matthew","The Diagrammatic Coaction","19 pages, Talk presented at Loop and Legs in Quantum Field Theory -
  LL2022, 25-30 April, 2022, Ettal, Germany",,,"CERN-TH-2022-122, BONN-TH-2022-18","hep-th hep-ph","http://creativecommons.org/licenses/by/4.0/","  The diagrammatic coaction underpins the analytic structure of Feynman
integrals, their cuts and the differential equations they admit. The coaction
maps any diagram into a tensor product of its pinches and cuts. These
correspond respectively to differential forms defining master integrals, and
integration contours which place a subset of the propagators on shell. In a
canonical basis these forms and contours are dual to each other. In this talk I
review our present understanding of this algebraic structure and its
manifestation for dimensionally-regularized Feynman integrals that are
expandable to polylogarithms around integer dimensions. Using one- and two-loop
integral examples, I will explain the duality between forms and contours, and
the correspondence between the local coaction acting on the Laurent
coefficients in the dimensional regulator and the global coaction acting on
generalised hypergeometric functions.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 05:28:58 GMT""}]","2022-07-19"
"2207.07844","Klavs Hansen","Klavs Hansen and Jos Engelen","Comment on 'Phase transition temperatures of 405-725 K in superfluid
  ultra-dense hydrogen clusters on metal surfaces' [AIP Advances 6, 045111
  (2016)]","4 pages",,,,"physics.atm-clus","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The article in \cite{HolmlidAIPA2016} has recently come to our attention. It
makes a number of extraordinary claims that each contradict well established
facts in several fields, ranging from atomic and molecular physics to
superconductivity and superfluidity, with practically no supporting evidence.
We think it worthwhile to rectify the literature with this comment.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 05:31:53 GMT""}]","2022-07-19"
"2207.07845","Matthew Guild","David R. Schipf, Matthew D. Guild and Caleb F. Sieck","Tunable piezoelectric metamaterial for Lamb waves using periodic shunted
  circuits","30 pages, 10 figures",,,,"physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Piezoelectric elastic metamaterials offer the ability to overcome the fixed,
narrow bandwidth characteristics of passive elastic metamaterials. Interesting
ultrasonic band gaps exist in piezoelectric plate metamaterials with periodic
electrodes connected to shunted circuits. These band gaps result from an
avoided crossing between electrical and mechanical bands, and can arise at
lower frequencies than Bloch wave band gaps. Current analytical modeling
techniques for these systems are numerically cumbersome, and assume an
infinitely periodic plate. We present an approximate two-dimensional analytical
model that can be used to directly calculate scattering coefficients for finite
length plates. This model is shown to predict a band diagram that compares well
with diagrams obtained from finite element analysis (FEA). Lower than 10%
difference in the estimation of the location of the band gap was found for a
plate thickness of $2$ mm, electrode width of $1$ mm, and gap between
electrodes greater than $1.2$ mm. We calculate effective impedances and
effective wavenumbers from global scattering coefficients. The calculated
effective normalized wavenumber swings from positive values
($0<k_{\mathrm{eff}}\leq 1$) to negative values ($0>k_{\mathrm{eff}}\geq -1$)
at the low-frequency band gap, resembling wavenumbers for negative stiffness
Helmholtz resonator metamaterials. This presents a new perspective on periodic
shunted circuit piezoelectric plates as electrically tunable, negative
stiffness metamaterials analogous to Helmholtz resonator lined acoustic
waveguides.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 05:35:03 GMT""}]","2022-07-19"
"2207.07846","Xuan Lin","Xuan Lin, Feng Xu, Alexander Schperberg, and Dennis Hong","Learning Near-global-optimal Strategies for Hybrid Non-convex Model
  Predictive Control of Single Rigid Body Locomotion",,,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  Convex model predictive controls (MPCs) with a single rigid body model have
demonstrated strong performance on real legged robots. However, convex MPCs are
limited by their assumptions such as small rotation angle and pre-defined gait,
limiting the richness of potential solutions. We remove those assumptions and
solve the complete mixed-integer non-convex programming with single rigid body
model. We first collect datasets of pre-solved problems offline, then learn the
problem-solution map to solve this optimization fast for MPC. If warm-starts
can be found, offline problems can be solved close to the global optimality.
The proposed controller is tested by generating various gaits and behaviors
depending on the initial conditions. Hardware test demonstrates online gait
generation and adaptation running at more than 50 Hz based on sensor feedback.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 05:58:09 GMT""},{""version"":""v2"",""created"":""Mon, 26 Sep 2022 18:34:00 GMT""}]","2022-09-28"
"2207.07847","Junyuan Lin","Xiaozhe Hu, Junyuan Lin","Solving Graph Laplacians via Multilevel Sparsifiers",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider effective preconditioners for solving Laplacians of general
weighted graphs. Theoretically, spectral sparsifiers (SSs) provide
preconditioners of optimal computational complexity. However, they are not easy
to use for real-world applications due to the implementation complications.
Multigrid (MG) methods, on the contrary, are computationally efficient but lack
of theoretical justifications. To bridge the gap between theory and practice,
we adopt ideas of MG and SS methods and proposed preconditioners that can be
used in practice with theoretical guarantees. We expand the original graph
based on a multilevel structure to obtain an equivalent expanded graph.
Although the expanded graph has a low diameter, a favorable property for
constructing SSs, it has negatively weighted edges, which is an unfavorable
property for the SSs. We design an algorithm to properly eliminate the
negatively weighted edges and prove that the resulting expanded graph with
positively weighted edges is spectrally equivalent to the expanded graph, thus,
the original graph. Due to the low-diameter property of the positively-weighted
expanded graph preconditioner (PEGP), existing algorithms for finding SSs can
be easily applied. To demonstrate the advantage of working with the PEGP, we
propose a type of SS, multilevel sparsifier preconditioner (MSP), that can be
constructed in an easy and deterministic manner. We provide some preliminary
numerical experiments to verify our theoretical findings and illustrate the
practical effectiveness of PEGP and MSP in real-world applications.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 06:01:57 GMT""},{""version"":""v2"",""created"":""Mon, 29 Aug 2022 22:51:43 GMT""}]","2022-08-31"
"2207.07848","Xiang Yu","Xiaoshan Chen, Xun Li, Fahuai Yi, Xiang Yu","Optimal consumption under a drawdown constraint over a finite horizon","Keywords: Optimal consumption, drawdown constraint, parabolic
  variational inequality, gradient constraint, free boundary",,,,"math.OC q-fin.MF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies a finite horizon utility maximization problem on excessive
consumption under a drawdown constraint up to the bankruptcy time. Our control
problem is an extension of the one considered in Bahman et al. (2019) to the
model with a finite horizon and also an extension of the one considered in Jeon
and Oh (2022) to the model with zero interest rate. Contrary to Bahman et al.
(2019), we encounter a parabolic nonlinear HJB variational inequality with a
gradient constraint, in which some time-dependent free boundaries complicate
the analysis significantly. Meanwhile, our methodology is built on technical
PDE arguments, which differs substantially from the martingale approach in Jeon
and Oh (2022). Using dual transform and considering some auxiliary parabolic
variational inequalities with both gradient and function constraints, we
establish the existence and uniqueness of the classical solution to the HJB
variational inequality and characterize all associated free boundaries in
analytical form. Consequently, the piecewise optimal feedback controls and some
time-dependent thresholds of the wealth variable for different control
expressions can be obtained.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 06:02:58 GMT""}]","2022-07-19"
"2207.07849","Yong Chen Dr.","Weiqi Peng, Yong Chen","Long-time asymptotics for a fourth-order dispersive nonlinear
  Schr\""{o}dinger equation with nonzero boundary conditions",,,,,"math.AP nlin.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we consider the long-time asymptotics for the Cauchy problem of
a fourth-order dispersive nonlinear Schr\""{o}dinger equation with nonzero
boundary conditions at infinity. Firstly, in order to construct the basic
Riemann-Hilbert problem associated with nonzero boundary conditions, we
analysis direct scattering problem. Then we deform the corresponding matrix
Riemann-Hilbert problem to explicitly solving models via using the nonlinear
steepest descent method and employing the $g$-function mechanism to eliminate
the exponential growths of the jump matrices. Finally, we obtain the asymptotic
stage of modulation instability for the fourth-order dispersive nonlinear
Schr\""{o}dinger equation.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 06:03:47 GMT""},{""version"":""v2"",""created"":""Sat, 22 Oct 2022 06:39:51 GMT""}]","2022-10-25"
"2207.07850","Viet Anh Trinh","Viet Anh Trinh, Pegah Ghahremani, Brian King, Jasha Droppo, Andreas
  Stolcke and Roland Maas","Reducing Geographic Disparities in Automatic Speech Recognition via
  Elastic Weight Consolidation","Accepted for publication at Interspeech 2022",,,,"eess.AS cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an approach to reduce the performance disparity between geographic
regions without degrading performance on the overall user population for ASR. A
popular approach is to fine-tune the model with data from regions where the ASR
model has a higher word error rate (WER). However, when the ASR model is
adapted to get better performance on these high-WER regions, its parameters
wander from the previous optimal values, which can lead to worse performance in
other regions. In our proposed method, we utilize the elastic weight
consolidation (EWC) regularization loss to identify directions in parameters
space along which the ASR weights can vary to improve for high-error regions,
while still maintaining performance on the speaker population overall. Our
results demonstrate that EWC can reduce the word error rate (WER) in the region
with highest WER by 3.2% relative while reducing the overall WER by 1.3%
relative. We also evaluate the role of language and acoustic models in ASR
fairness and propose a clustering algorithm to identify WER disparities based
on geographic region.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 06:04:52 GMT""}]","2022-07-19"
"2207.07851","Makoto Matsumoto","Makoto Matsumoto and Kento Ogawa and Takayuki Okuda","Functoriality of Bose-Mesner algebras and profinite association schemes",,,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  We show that taking the set of primitive idempotents of commutative
association schemes is a functor from the category of commutative association
schemes with surjective morphisms to the category of finite sets with
surjective partial functions. We then consider projective systems of
commutative association schemes consisting of surjections (which we call
profinite association schemes), for which Bose-Mesner algebra is defined, and
describe a Delsarte theory on such schemes. This is another method for
generalizing association schemes to those on infinite sets, related with the
approach by Barg and Skriganov. Relation with $(t,m,s)$-nets and
$(t,s)$-sequences is studied. We reprove some of the results of Martin-Stinson
from this viewpoint.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 06:45:00 GMT""}]","2022-07-19"
"2207.07852","Yuqi Liu","Yuqi Liu, Pengfei Xiong, Luhui Xu, Shengming Cao and Qin Jin","TS2-Net: Token Shift and Selection Transformer for Text-Video Retrieval","Accepted by ECCV2022",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Text-Video retrieval is a task of great practical value and has received
increasing attention, among which learning spatial-temporal video
representation is one of the research hotspots. The video encoders in the
state-of-the-art video retrieval models usually directly adopt the pre-trained
vision backbones with the network structure fixed, they therefore can not be
further improved to produce the fine-grained spatial-temporal video
representation. In this paper, we propose Token Shift and Selection Network
(TS2-Net), a novel token shift and selection transformer architecture, which
dynamically adjusts the token sequence and selects informative tokens in both
temporal and spatial dimensions from input video samples. The token shift
module temporally shifts the whole token features back-and-forth across
adjacent frames, to preserve the complete token representation and capture
subtle movements. Then the token selection module selects tokens that
contribute most to local spatial semantics. Based on thorough experiments, the
proposed TS2-Net achieves state-of-the-art performance on major text-video
retrieval benchmarks, including new records on MSRVTT, VATEX, LSMDC,
ActivityNet, and DiDeMo.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 06:50:27 GMT""}]","2022-07-19"
"2207.07853","Wontae Kim","Sumiya Baasandorj, Sun-Sig Byun, Wontae Kim","Self-improving properties of very weak solutions to the double phase
  systems","Remark 1.3 has been added. References have been added",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove the self-improving property of very weak solutions to non-uniformly
elliptic problems of double phase type in divergence form under sharp
assumptions on the nonlinearity.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 06:54:32 GMT""},{""version"":""v2"",""created"":""Tue, 20 Sep 2022 04:09:07 GMT""}]","2022-09-21"
"2207.07854","Xinglong Zhu","Xing-Long Zhu, Wei-Yuan Liu, Min Chen, Su-Ming Weng, Paul McKenna,
  Zheng-Ming Sheng, and Jie Zhang","Bunched proton acceleration from a laser-irradiated cone target",,,,,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Laser-driven ion acceleration is an attractive technique for compact
high-energy ion sources. Currently, among various physical and technical issues
to be solved, the boost of ion energy and the reduction of energy spread
represent the key challenges with this technique. Here we present a scheme to
tackle these challenges by using a hundred-terawatt-class laser pulse
irradiating a cone target. Three-dimensional particle-in-cell simulations show
that a large number of electrons are dragged out of the cone walls and
accelerated to hundreds of MeV by the laser fields inside the cone. When these
energetic dense electron beams pass through the cone target tip into vacuum, a
very high bunching acceleration field, up to tens of TV/m, quickly forms.
Protons are accelerated and simultaneously bunched by this field, resulting in
quasi-monoenergetic proton beams with hundred MeV energy and low energy spread
of ~2%. Results exploring the scaling of the proton beam energy with laser and
target parameters are presented, indicating that the scheme is robust. This
opens a new route for compact high-energy proton sources from fundamental
research to biomedical applications.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 07:04:19 GMT""}]","2022-07-19"
"2207.07855","Alexander L Fradkov","Alexander Fradkov","Dynamics and Stability under Iterated Sanctions and Counter-sanctions",,,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  In the paper a simple discrete dynamical model for dynamics of two
antagonistic agents (opponents) under iterated sanctions and counter-sanctions
is proposed. The model is inspired with Osipov-Lanchester model for combats.
Simple stability criteria are derived both for the full information case and
for stochastic uncertainty case. The results provide some important qualitative
conclusions that are interpreted in terms of international stability
preservation.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 07:04:24 GMT""}]","2022-07-19"
"2207.07856","Iskander A. Taimanov","Iskander A. Taimanov","Surfaces via spinors and soliton equations","18 pages",,,,"math.DG math.AP nlin.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article surveys the Weierstrass representation of surfaces in the three-
and four-dimensional spaces, with an emphasis on its relation to the Willmore
functional. We also describe an application of this representation to
constructing a new type of solutions to the Davey-Stewartson II equation. They
have regular initial data, gain one-point singularities at certain moments of
time, and extend to smooth solutions for the remaining times.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 07:05:43 GMT""}]","2022-07-19"
"2207.07857","Purba Mukherjee","Purba Mukherjee","Non-parametric Reconstruction Of Some Cosmological Parameters","Thesis accepted for the award of PhD degree of IISER Kolkata, June
  2022",,,,"astro-ph.CO gr-qc","http://creativecommons.org/licenses/by/4.0/","  The present thesis is devoted to the non-parametric reconstruction of some
cosmological parameters using diverse observational datasets. The Universe is
assumed to be spatially homogeneous and isotropic, thus described by the FLRW
metric. The first chapter provides a brief introduction to cosmology and
focuses on the reconstruction methods. An assessment of the cosmic
distance-duality relation is discussed in chapter 2. In chapter 3, a
non-parametric reconstruction of the cosmological jerk parameter is carried
out. Chapter 4 explores the possibility of a non-gravitational interaction in
the cosmic dark sector. In chapter 5, attempts are made to revisit a
non-parametric reconstruction of the cosmic deceleration parameter using
various combinations of recently updated background datasets and the growth
rate of structure measurements from the redshift-space distortions. Finally,
chapter 6 contains the concluding remarks and relevant discussion regarding the
overall work presented in the thesis.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 07:06:43 GMT""}]","2022-07-19"
"2207.07858","Zhongzhan Huang","Zhongzhan Huang, Senwei Liang, Mingfu Liang, Wei He, Haizhao Yang and
  Liang Lin","The Lottery Ticket Hypothesis for Self-attention in Convolutional Neural
  Network","Technical report. arXiv admin note: text overlap with
  arXiv:2011.14058",,,,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently many plug-and-play self-attention modules (SAMs) are proposed to
enhance the model generalization by exploiting the internal information of deep
convolutional neural networks (CNNs). In general, previous works ignore where
to plug in the SAMs since they connect the SAMs individually with each block of
the entire CNN backbone for granted, leading to incremental computational cost
and the number of parameters with the growth of network depth. However, we
empirically find and verify some counterintuitive phenomena that: (a)
Connecting the SAMs to all the blocks may not always bring the largest
performance boost, and connecting to partial blocks would be even better; (b)
Adding the SAMs to a CNN may not always bring a performance boost, and instead
it may even harm the performance of the original CNN backbone. Therefore, we
articulate and demonstrate the Lottery Ticket Hypothesis for Self-attention
Networks: a full self-attention network contains a subnetwork with sparse
self-attention connections that can (1) accelerate inference, (2) reduce extra
parameter increment, and (3) maintain accuracy. In addition to the empirical
evidence, this hypothesis is also supported by our theoretical evidence.
Furthermore, we propose a simple yet effective reinforcement-learning-based
method to search the ticket, i.e., the connection scheme that satisfies the
three above-mentioned conditions. Extensive experiments on widely-used
benchmark datasets and popular self-attention networks show the effectiveness
of our method. Besides, our experiments illustrate that our searched ticket has
the capacity of transferring to some vision tasks, e.g., crowd counting and
segmentation.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 07:08:59 GMT""}]","2022-07-19"
"2207.07859","Jianfei Yang","Jianfei Yang, Xinyan Chen, Dazhuo Wang, Han Zou, Chris Xiaoxuan Lu,
  Sumei Sun, Lihua Xie","SenseFi: A Library and Benchmark on Deep-Learning-Empowered WiFi Human
  Sensing","A benchmark and model zoo for WiFi CSI Human sensing based on deep
  learning methods. Accepted by Patterns, Cell Press",,,,"cs.LG cs.AI eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  WiFi sensing has been evolving rapidly in recent years. Empowered by
propagation models and deep learning methods, many challenging applications are
realized such as WiFi-based human activity recognition and gesture recognition.
However, in contrast to deep learning for visual recognition and natural
language processing, no sufficiently comprehensive public benchmark exists. In
this paper, we review the recent progress on deep learning enabled WiFi
sensing, and then propose a benchmark, SenseFi, to study the effectiveness of
various deep learning models for WiFi sensing. These advanced models are
compared in terms of distinct sensing tasks, WiFi platforms, recognition
accuracy, model size, computational complexity, feature transferability, and
adaptability of unsupervised learning. It is also regarded as a tutorial for
deep learning based WiFi sensing, starting from CSI hardware platform to
sensing algorithms. The extensive experiments provide us with experiences in
deep model design, learning strategy skills and training techniques for
real-world applications. To the best of our knowledge, this is the first
benchmark with an open-source library for deep learning in WiFi sensing
research. The benchmark codes are available at
https://github.com/xyanchen/WiFi-CSI-Sensing-Benchmark.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 07:23:45 GMT""},{""version"":""v2"",""created"":""Fri, 16 Dec 2022 12:44:36 GMT""},{""version"":""v3"",""created"":""Fri, 17 Feb 2023 06:11:04 GMT""}]","2023-02-20"
"2207.07860","Matthias Maier","Matthias Maier, John N. Shadid, Ignacio Tomas","Structure-preserving finite-element schemes for the Euler-Poisson
  equations",,,"10.4208/cicp.OA-2022-0205",,"math.NA cs.NA physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss structure-preserving numerical discretizations for repulsive and
attractive Euler-Poisson equations that find applications in fluid-plasma and
self-gravitation modeling. The scheme is fully discrete and structure
preserving in the sense that it maintains a discrete energy law, as well as
hyperbolic invariant domain properties, such as positivity of the density and a
minimum principle of the specific entropy. A detailed discussion of algorithmic
details is given, as well as proofs of the claimed properties. We present
computational experiments corroborating our analytical findings and
demonstrating the computational capabilities of the scheme.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 07:26:36 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jul 2022 11:23:27 GMT""},{""version"":""v3"",""created"":""Thu, 19 Jan 2023 21:37:57 GMT""},{""version"":""v4"",""created"":""Thu, 27 Apr 2023 05:02:39 GMT""}]","2023-05-10"
"2207.07861","Hongtao Wen","Hongtao Wen, Jianhang Yan, Wanli Peng, Yi Sun","TransGrasp: Grasp Pose Estimation of a Category of Objects by
  Transferring Grasps from Only One Labeled Instance","Accepted to European Conference on Computer Vision (ECCV) 2022",,,,"cs.RO cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Grasp pose estimation is an important issue for robots to interact with the
real world. However, most of existing methods require exact 3D object models
available beforehand or a large amount of grasp annotations for training. To
avoid these problems, we propose TransGrasp, a category-level grasp pose
estimation method that predicts grasp poses of a category of objects by
labeling only one object instance. Specifically, we perform grasp pose transfer
across a category of objects based on their shape correspondences and propose a
grasp pose refinement module to further fine-tune grasp pose of grippers so as
to ensure successful grasps. Experiments demonstrate the effectiveness of our
method on achieving high-quality grasps with the transferred grasp poses. Our
code is available at https://github.com/yanjh97/TransGrasp.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 07:27:27 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jul 2022 02:44:56 GMT""},{""version"":""v3"",""created"":""Mon, 25 Jul 2022 07:46:20 GMT""}]","2022-07-26"
"2207.07862","MinKi Jeong","Minki Jeong, Wanyeong Jung","MAC-DO: Charge Based Multi-Bit Analog In-Memory Accelerator Compatible
  with DRAM Using Output Stationary Mapping","14 pages, 22 figures",,,,"cs.AR cs.DC cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks (DNN) have been proved for its effectiveness in various
areas such as classification problems, image processing, video segmentation,
and speech recognition. The accelerator-in-memory (AiM) architectures are a
promising solution to efficiently accelerate DNNs as they can avoid the memory
bottleneck of the traditional von Neumann architecture. As the main memory is
usually DRAM in many systems, a highly parallel multiply-accumulate (MAC) array
within the DRAM can maximize the benefit of AiM by reducing both the distance
and amount of data movement between the processor and the main memory. This
paper presents an analog MAC array based AiM architecture named MAC-DO. In
contrast with previous in-DRAM accelerators, MAC-DO makes an entire DRAM array
participate in MAC computations simultaneously without idle cells, leading to
higher throughput and energy efficiency. This improvement is made possible by
exploiting a new analog computation method based on charge steering. In
addition, MAC-DO innately supports multi-bit MACs with good linearity. MAC-DO
is still compatible with current 1T1C DRAM technology without any modifications
of a DRAM cell and array. A MAC-DO array can accelerate matrix multiplications
based on output stationary mapping and thus supports most of the computations
performed in DNNs. Our evaluation using transistor-level simulation shows that
a test MAC-DO array with 16 x 16 MAC-DO cells achieves 188.7 TOPS/W, and shows
97.07% Top-1 accuracy for MNIST dataset without retraining.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 07:33:20 GMT""},{""version"":""v2"",""created"":""Wed, 9 Nov 2022 12:02:37 GMT""}]","2022-11-10"
"2207.07863","Jonathan Pan","Jonathan Pan","Deep Set Classifier for Financial Forensics: An application to detect
  money laundering","To be improved. Will be uploading a revised paper with major changes",,,,"cs.CR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Financial forensics has an important role in the field of finance to detect
and investigate the occurrence of finance related crimes like money laundering.
However, as with other forms of criminal activities, the forensics analysis of
such activities is a complex undertaking with attempts by the adversaries to
constantly upgrade their ability to evade detection. Also, the extent of the
volume and complexity of financial activities or transactions further
complicates the task of performing financial forensics. Machine Learning or
Artificial Intelligence algorithms could be used to deal with such
complexities. However, the challenge of limitedly available labeled datasets
especially with fraudulent activities limits the means to develop efficient
algorithms. Additionally, the complexity of defining precise search patterns of
evasive fraudulent transactions further complicates this challenge. In this
paper, we developed a novel deep set classifier algorithm based on meta
learning and applied it to deal with the complexity deriving patterns of
interest with sample of limitedly labelled transactions to detect fraudulent
cryptocurrency money laundering transactions. We a unique approach to train our
model with progressive provision of samples and the test result exceeds leading
research algorithms.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 07:37:10 GMT""},{""version"":""v2"",""created"":""Thu, 9 Mar 2023 04:18:11 GMT""}]","2023-03-10"
"2207.07864","Andrzej A. Zdziarski","Andrzej A. Zdziarski and Elise Egron","What are the Composition and Power of the Jet in Cyg X-1?","ApJL, in press",,"10.3847/2041-8213/ac81bf",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We calculate the electron-positron pair production rate at the base of the
jet of Cyg X-1 by collisions of photons from its hot accretion flow using the
measurement of its average soft gamma-ray spectra by the Compton Gamma Ray
Observatory and INTEGRAL satellites. We have found that this rate approximately
equals the flow rate of the leptons emitting the observed synchrotron
radio-to-IR spectrum of the jet, calculated using an extended jet model
following that of Blandford \& Koenigl. This coincidence shows the jet
composition is likely to be pair-dominated. The same coincidences were found
before in the microquasar MAXI J1820+070 and in the radio galaxy 3C 120, which
shows that the considered mechanism can be universal for at least some classes
of relativistic jets. Furthermore, we recalculate the jet power of Cyg X-1. The
presence of pairs can strongly reduces the power in the bulk motion of ions,
which then limits the parameter space at which the jet can power the $\sim$5-pc
nebular structure present in its vicinity.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 07:37:39 GMT""}]","2022-08-17"
"2207.07865","Dylan Helliwell","Emily Frost, Dylan Helliwell, Suki Shergill","A new perspective on taxicab conic sections","42 pages, 17 figures, submitted to The Art of Discrete and Applied
  Mathematics",,,,"math.MG","http://creativecommons.org/licenses/by/4.0/","  We explore taxicab conic sections from the perspective of slicing taxicab
cones by planes, as opposed to the more well-studied approach from the
perspective of distance formulations. After establishing a significant amount
of structural framework, a complete characterization of the resulting taxicab
conic sections is established, and a number of special cases are explored.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 07:38:35 GMT""}]","2022-07-19"
"2207.07866","Subhasis Adhikari","S. Adhikari, Y. Wang, P. Spaeth, F. Scalerandi, W. Albrecht, J. Liu,
  M. Orrit","Magnetization Switching of Single Magnetite Nanoparticles Monitored
  Optically",,,,,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Magnetic nanomaterials record information as fast as picoseconds in computer
memories but retain it for millions of years in ancient rocks. This exceedingly
broad range of times is covered by hopping over a potential energy barrier
through temperature, ultrafast optical excitation for demagnetization or
magnetization manipulation, mechanical stress, or microwaves. As switching
depends on nanoparticle size, shape, orientation, and material properties, only
single-nanoparticle studies can eliminate ensemble heterogeneity. Here, we push
the sensitivity of photothermal magnetic circular dichroism down to individual
20-nm magnetite nanoparticles. Single-particle magnetization curves display
superparamagnetic to ferromagnetic behaviors, depending on size, shape, and
orientation. Some nanoparticles undergo thermally activated switching on time
scales of milliseconds to minutes. Surprisingly, the switching barrier appears
to vary in time, leading to dynamical heterogeneity. Our observations will help
to identify and eventually control the nanoscale parameters influencing the
switching of magnetic nanoparticles, an important step for applications in many
fields.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 07:43:05 GMT""}]","2022-07-19"
"2207.07867","Xiaotian Lin","Xiaotian Lin, Leiyang Xu, Qiang Wang","Automatic dataset generation for specific object detection","5 pages, 4 figures, accepted by ICIP 2022",,,,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the past decade, object detection tasks are defined mostly by large public
datasets. However, building object detection datasets is not scalable due to
inefficient image collecting and labeling. Furthermore, most labels are still
in the form of bounding boxes, which provide much less information than the
real human visual system. In this paper, we present a method to synthesize
object-in-scene images, which can preserve the objects' detailed features
without bringing irrelevant information. In brief, given a set of images
containing a target object, our algorithm first trains a model to find an
approximate center of the object as an anchor, then makes an outline regression
to estimate its boundary, and finally blends the object into a new scene. Our
result shows that in the synthesized image, the boundaries of objects blend
very well with the background. Experiments also show that SOTA segmentation
models work well with our synthesized data.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 07:44:33 GMT""}]","2022-07-19"
"2207.07868","Zixuan Zhou","Zixuan Zhou and Xuefei Ning and Yi Cai and Jiashu Han and Yiping Deng
  and Yuhan Dong and Huazhong Yang and Yu Wang","CLOSE: Curriculum Learning On the Sharing Extent Towards Better One-shot
  NAS","accepted by ECCV 2022 (14 pages main texts)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One-shot Neural Architecture Search (NAS) has been widely used to discover
architectures due to its efficiency. However, previous studies reveal that
one-shot performance estimations of architectures might not be well correlated
with their performances in stand-alone training because of the excessive
sharing of operation parameters (i.e., large sharing extent) between
architectures. Thus, recent methods construct even more over-parameterized
supernets to reduce the sharing extent. But these improved methods introduce a
large number of extra parameters and thus cause an undesirable trade-off
between the training costs and the ranking quality. To alleviate the above
issues, we propose to apply Curriculum Learning On Sharing Extent (CLOSE) to
train the supernet both efficiently and effectively. Specifically, we train the
supernet with a large sharing extent (an easier curriculum) at the beginning
and gradually decrease the sharing extent of the supernet (a harder
curriculum). To support this training strategy, we design a novel supernet
(CLOSENet) that decouples the parameters from operations to realize a flexible
sharing scheme and adjustable sharing extent. Extensive experiments demonstrate
that CLOSE can obtain a better ranking quality across different computational
budget constraints than other one-shot supernets, and is able to discover
superior architectures when combined with various search strategies. Code is
available at https://github.com/walkerning/aw_nas.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 07:45:17 GMT""}]","2022-07-19"
"2207.07869","Shunli Wang","Shunli Wang, Shuaibing Wang, Bo Jiao, Dingkang Yang, Liuzhen Su, Peng
  Zhai, Chixiao Chen, Lihua Zhang","CA-SpaceNet: Counterfactual Analysis for 6D Pose Estimation in Space","8 pages, 6 figures, IROS-2022 conference paper",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reliable and stable 6D pose estimation of uncooperative space objects plays
an essential role in on-orbit servicing and debris removal missions.
Considering that the pose estimator is sensitive to background interference,
this paper proposes a counterfactual analysis framework named CASpaceNet to
complete robust 6D pose estimation of the spaceborne targets under complicated
background. Specifically, conventional methods are adopted to extract the
features of the whole image in the factual case. In the counterfactual case, a
non-existent image without the target but only the background is imagined. Side
effect caused by background interference is reduced by counterfactual analysis,
which leads to unbiased prediction in final results. In addition, we also carry
out lowbit-width quantization for CA-SpaceNet and deploy part of the framework
to a Processing-In-Memory (PIM) accelerator on FPGA. Qualitative and
quantitative results demonstrate the effectiveness and efficiency of our
proposed method. To our best knowledge, this paper applies causal inference and
network quantization to the 6D pose estimation of space-borne targets for the
first time. The code is available at
https://github.com/Shunli-Wang/CA-SpaceNet.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 07:48:19 GMT""}]","2022-07-19"
"2207.07870","Qie Sima","Yuhong Deng, Qie Sima, Di Guo, Huaping Liu, Yi Wang and Fuchun Sun","Scene Graph for Embodied Exploration in Cluttered Scenario",,,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  The ability to handle objects in cluttered environment has been long
anticipated by robotic community. However, most of works merely focus on
manipulation instead of rendering hidden semantic information in cluttered
objects. In this work, we introduce the scene graph for embodied exploration in
cluttered scenarios to solve this problem. To validate our method in cluttered
scenario, we adopt the Manipulation Question Answering (MQA) tasks as our test
benchmark, which requires an embodied robot to have the active exploration
ability and semantic understanding ability of vision and language.As a general
solution framework to the task, we propose an imitation learning method to
generate manipulations for exploration. Meanwhile, a VQA model based on dynamic
scene graph is adopted to comprehend a series of RGB frames from wrist camera
of manipulator along with every step of manipulation is conducted to answer
questions in our framework.The experiments on of MQA dataset with different
interaction requirements demonstrate that our proposed framework is effective
for MQA task a representative of tasks in cluttered scenario.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 07:48:22 GMT""},{""version"":""v2"",""created"":""Wed, 22 Feb 2023 09:22:29 GMT""}]","2023-02-23"
"2207.07871","Sushant Dutta","Sushant Dutta, Veeresh Singh, C. H. Ishwara Chandra, Yogesh Wadadekar
  and Abhijit Kayal","Characteristics of remnant radio galaxies detected in the deep radio
  continuum observations from the SKA pathfinders","14 pages, 3 figures, 3 tables, accepted for publication in the
  Journal of Astrophysics and Astronomy (to appear in the special issue of
  Indian participation in the SKA)","Journal of Astrophysics and Astronomy, 43, Article number: 96
  (2022)","10.1007/s12036-022-09883-y",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The cessation of AGN activity in radio galaxies leads to a remnant phase
during which jets are no longer sustained, but lobes can be detected for a
period of time before they fade away due to radiative and dynamical energy
losses. The time-scale of the remnant phase and AGN duty cycle are vital to
understanding the evolution of radio galaxies. In this paper, we report new
band-3 observations with the upgraded Giant Meterwave Radio Telescope (uGMRT)
for five remnant radio galaxies. Our uGMRT observations reveal emission of
low-surface-brightness in all five remnants with 400 MHz surface brightness in
the range of 36$-$201 mJy arcmin$^{-2}$. With band-3 uGMRT observations, we
discover wing-shaped radio morphology in one of our sample sources. Using radio
observations at 150 MHz, 325 MHz, 400 MHz, and 1.5 GHz, we model the radio
spectral energy distributions (SEDs) of our sample sources with the continuous
injection-off model (CI$_{\rm OFF}$), that assumes an active phase with
continuous injection followed by a remnant phase. We obtain total source ages
($t_{\rm s}$) in the range of 20.3 Myr to 41.4 Myr with $t_{\rm OFF}$/$t_{\rm
s}$ distributed in the range of 0.16 to 0.63, which in turn suggests them to
belong to different evolutionary phases. We note that, in comparison to the
remnants reported in the literature, our sample sources tend to show lower
spectral ages that can be explained by the combined effects of more dominant
inverse Compton losses for our sources present at the relatively higher
redshifts and possible rapid expansion of lobes in their less dense
environments.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 07:55:52 GMT""}]","2022-12-19"
"2207.07872","Luca Cavalli","Luca Cavalli, Marc Pollefeys, Daniel Barath","NeFSAC: Neurally Filtered Minimal Samples","Published in the 17th European Conference on Computer Vision (ECCV
  2022)",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Since RANSAC, a great deal of research has been devoted to improving both its
accuracy and run-time. Still, only a few methods aim at recognizing invalid
minimal samples early, before the often expensive model estimation and quality
calculation are done. To this end, we propose NeFSAC, an efficient algorithm
for neural filtering of motion-inconsistent and poorly-conditioned minimal
samples. We train NeFSAC to predict the probability of a minimal sample leading
to an accurate relative pose, only based on the pixel coordinates of the image
correspondences. Our neural filtering model learns typical motion patterns of
samples which lead to unstable poses, and regularities in the possible motions
to favour well-conditioned and likely-correct samples. The novel lightweight
architecture implements the main invariants of minimal samples for pose
estimation, and a novel training scheme addresses the problem of extreme class
imbalance. NeFSAC can be plugged into any existing RANSAC-based pipeline. We
integrate it into USAC and show that it consistently provides strong speed-ups
even under extreme train-test domain gaps - for example, the model trained for
the autonomous driving scenario works on PhotoTourism too. We tested NeFSAC on
more than 100k image pairs from three publicly available real-world datasets
and found that it leads to one order of magnitude speed-up, while often finding
more accurate results than USAC alone. The source code is available at
https://github.com/cavalli1234/NeFSAC.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 08:02:05 GMT""}]","2022-07-19"
"2207.07873","Xinzhe Zhang","Xin-zhe Zhang, Lei-hua Liu, Taotao Qiu","Mimetic Curvaton","9 pages, 4 figures, looking forward to every comment, have been
  accepted by Phys. Rev. D",,"10.1103/PhysRevD.107.043510",,"hep-th astro-ph.CO gr-qc hep-ph","http://creativecommons.org/licenses/by/4.0/","  In this paper, we investigate the primordial perturbations of inflation model
induced from the multi-field mimetic gravity, where there are two field during
inflation, and thus both adiabatic and isocurvature perturbation modes are
generated. We show that although it is true that the original adiabatic
perturbation mode loses the kinetic term due to the constraint equation, by
applying the curvaton mechanism where one of the field is viewed as curvaton
field, the adiabatic perturbation can actually be transferred from the
isocurvature one at the end of inflation. Detailed calculations are performed
for both inflationary and the consequent matter-dominant epochs. Therefore, the
so-called ""non-propagating problem"" of the adiabatic mode will actually do no
harm to the multi-field mimetic inflation models.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 08:03:25 GMT""},{""version"":""v2"",""created"":""Fri, 22 Jul 2022 07:15:53 GMT""},{""version"":""v3"",""created"":""Fri, 6 Jan 2023 02:38:06 GMT""}]","2023-02-22"
"2207.07874","Huaxiong Li","Zizheng Huang, Haoxing Chen, Ziqi Wen, Chao Zhang, Huaxiong Li, Bo
  Wang, Chunlin Chen","Model-Aware Contrastive Learning: Towards Escaping the Dilemmas",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Contrastive learning (CL) continuously achieves significant breakthroughs
across multiple domains. However, the most common InfoNCE based methods suffer
from some existing dilemmas, e.g., uniformity-tolerance dilemma (UTD) and the
gradient reduction. It has been identified that UTD can lead to unexpected
performance degradation. We argue that the fixity of temperature is to blame
for UTD. To tackle this challenge, we enrich the CL loss family by presenting a
Model-Aware Contrastive Learning (MACL) strategy, whose temperature is adaptive
to the magnitude of alignment that reflects the basic confidence of the
instance discrimination task, then enables CL loss to adjust the penalty
strength for hard negatives adaptively. Regarding another dilemma, the gradient
reduction issue, we derive the limits of an involved gradient scaling factor,
which allows us to explain from a unified perspective why some recent
approaches are effective with fewer negative samples, and summarily present a
gradient reweighting to escape this dilemma. Extensive remarkable empirical
results in vision, sentence, and graph modality validate our approach's general
improvement for representation learning and downstream tasks.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 08:21:55 GMT""},{""version"":""v2"",""created"":""Wed, 17 Aug 2022 15:38:30 GMT""},{""version"":""v3"",""created"":""Mon, 6 Feb 2023 13:57:57 GMT""}]","2023-02-07"
"2207.07875","Fabio Ferreira","Diane Wagner, Fabio Ferreira, Danny Stoll, Robin Tibor Schirrmeister,
  Samuel M\""uller, Frank Hutter","On the Importance of Hyperparameters and Data Augmentation for
  Self-Supervised Learning","Accepted at the ICML 2022 Pre-training Workshop",,,,"cs.LG cs.AI cs.CV","http://creativecommons.org/licenses/by/4.0/","  Self-Supervised Learning (SSL) has become a very active area of Deep Learning
research where it is heavily used as a pre-training method for classification
and other tasks. However, the rapid pace of advancements in this area comes at
a price: training pipelines vary significantly across papers, which presents a
potentially crucial confounding factor. Here, we show that, indeed, the choice
of hyperparameters and data augmentation strategies can have a dramatic impact
on performance. To shed light on these neglected factors and help maximize the
power of SSL, we hyperparameterize these components and optimize them with
Bayesian optimization, showing improvements across multiple datasets for the
SimSiam SSL approach. Realizing the importance of data augmentations for SSL,
we also introduce a new automated data augmentation algorithm, GroupAugment,
which considers groups of augmentations and optimizes the sampling across
groups. In contrast to algorithms designed for supervised learning,
GroupAugment achieved consistently high linear evaluation accuracy across all
datasets we considered. Overall, our results indicate the importance and likely
underestimated role of data augmentation for SSL.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 08:31:11 GMT""}]","2022-07-19"
"2207.07876","Luca Dell'Anna","Gianluca Francica, Luca Dell'Anna","Anomalous universal adiabatic dynamics: The case of the Fredkin model","5 pages, 5 figures","Phys. Rev. Research 5, L012048 (2023)","10.1103/PhysRevResearch.5.L012048",,"cond-mat.stat-mech quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When a system is driven across a second-order quantum phase transition, the
number of defects which are produced scales with the speed of the variation of
the tuning parameter according to a universal law described by the Kibble-Zurek
mechanism. We study a possible breakdown of this prediction proving that the
number of defects can exhibit another universal scaling law which is still
related only to the critical exponents $z$ and $\nu$, but differs from the
Kibble-Zurek result. Finally we provide an example, the deformed Fredkin spin
chain, where this violation of the standard adiabatic dynamics can occur.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 08:32:46 GMT""},{""version"":""v2"",""created"":""Mon, 27 Mar 2023 19:34:57 GMT""}]","2023-03-29"
"2207.07877","Chongze Wang","Chongze Wang, Shuyuan Liu, Hyunsoo Jeon, Yu Jia, Jun-Hyung Cho","Charge density wave and superconductivity in the kagome metal
  CsV$_3$Sb$_5$ around a pressure-induced quantum critical point",,,"10.1103/PhysRevMaterials.6.094801",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using first-principles density functional theory calculations, we investigate
the pressure-induced quantum phase transition (QPT) from the charge density
wave (CDW) to the pristine phase in the layered kagome metal CsV$_3$Sb$_5$
consisting of three-atom-thick Sb$-$V$_3$Sb$-$Sb and one-atom-thick Cs layers.
The CDW structure having the formation of trimeric and hexameric V atoms with
buckled Sb honeycomb layers features an increase in the lattice parameter along
the $c$ axis, compared to its counterpart pristine structure having the ideal
V$_3$Sb kagome and planar Sb honeycomb layers. Consequently, as pressure
increases, the relatively smaller volume of the pristine phase contributes to
reducing the enthalpy difference between the CDW and pristine phases, yielding
a pressure-induced QPT at a critical pressure $P_c$ of ${\sim}$2 GPa.
Furthermore, we find that (i) the superconducting transition temperature $T_c$
increases around $P_c$ due to a phonon softening associated with the periodic
lattice distortion of V trimers and hexamers and that (ii) above $P_c$, optical
phonon modes are hardened with increasing pressure, leading to monotonous
decreases in the electron-phonon coupling constant and $T_c$. Our findings not
only demonstrate that the uniaxial strain along the $c$ axis plays an important
role in the QPT observed in CsV$_3$Sb$_5$, but also provide an explanation for
the observed superconductivity around $P_c$ in terms of a phonon-mediated
superconducting mechanism.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 08:34:29 GMT""}]","2022-10-04"
"2207.07878","Saurabh Sharma","Saurabh Sharma, Devendra K. Ojha, Arpan Ghosh, Joe P. Ninan, Supriyo
  Ghosh, Swarna K. Ghosh, P. Manoj, Milind B. Naik, Savio L. A. D'Costa, B.
  Krishna Reddy, Nandish Nanjappa, Rakesh Pandey, Tirthendu Sinha, Neelam
  Panwar, Susmitha Antony, Harmeen Kaur, Sanjit Sahu, Tarun Bangia, Satheesha
  S. Poojary, Rajesh B. Jadhav, Shailesh B. Bhagat, Ganesh S. Meshram, Harshit
  Shah, John T. Rayner, Douglas W. Toomey, and Pradeep R. Sandimani","TANSPEC: TIFR-ARIES Near Infrared Spectrometer","35 pages, Accepted for publication in - Publications of the
  Astronomical Society of the Pacific (PASP)",,"10.1088/1538-3873/ac81eb",,"astro-ph.IM astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the design and performance of the TANSPEC, a medium-resolution
$0.55-2.5~\mu$m cryogenic spectrometer and imager, now in operation at the
3.6-m Devasthal Optical Telescope (DOT), Nainital, India. The TANSPEC provides
three modes of operation which include, photometry with broad- and narrow-band
filters, spectroscopy with short slits of 20$^{\prime \prime}$ length and
different widths (from 0.5$^{\prime \prime}$ to 4.0$^{\prime \prime}$) in
cross-dispersed mode at a resolving power R of $\sim$2750, and spectroscopy
with long slits of 60$^{\prime \prime}$ length and different widths (from
0.5$^{\prime \prime}$ to 4.0$^{\prime \prime}$) in prism mode at a resolving
power R of $\sim$100-350. TANSPEC's imager mode provides a field of view of
60$^{\prime \prime} \times 60^{\prime \prime}$ with a plate scale of
0.245$^{\prime \prime}$/pixel on the 3.6-m DOT. The TANSPEC was successfully
commissioned during April-May 2019 and the subsequent characterization and
astronomical observations are presented here. The TANSPEC has been made
available to the worldwide astronomical community for science observations from
October 2020.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 08:53:08 GMT""}]","2022-08-31"
"2207.07879","Rahul Mukerjee","Rahul Mukerjee","A Statistical Approach to Broken Stick Problems",,,,,"math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  Let a stick be broken at random at n-1 points to form n pieces. We consider
three problems on forming k-gons with k out of these n pieces, and show how a
statistical approach, through a linear transformation of variables, yields
simple solutions that also allow fast computation.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 08:54:45 GMT""}]","2022-07-19"
"2207.07880","Lei Zhang","Lei Zhang, Alessandro Ridolfi, Harsha Blumer, Paulo Freire, Richard N.
  Manchester, Maura McLaughlin, Kyle Kremer, Andrew D. Cameron, Zhiyu Zhang,
  Jan Behrend, Marta Burgay, Sarah Buchner, David J. Champion, Weiwei Chen, Shi
  Dai, Yi Feng, Xiaoting Fu, Meng Guo, George Hobbs, Evan F. Keane, Michael
  Kramer, Lina Levin, Xiangdong Li, Mengmeng Ni, Jingshan Pan, Prajwal V.
  Padmanabh, Andrea Possenti, Scott M. Ransom, Chao-Wei Tsai, Vivek Venkatraman
  Krishnan, Pei Wang, Jie Zhang, Qijun Zhi, Yongkun Zhang, Di Li","Radio detection of an elusive millisecond pulsar in the Globular Cluster
  NGC 6397",,,"10.3847/2041-8213/ac81c3",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the discovery of a new 5.78 ms-period millisecond pulsar (MSP), PSR
J1740-5340B (NGC 6397B), in an eclipsing binary system discovered with the
Parkes radio telescope (now also known as Murriyang), Australia, and confirmed
with the MeerKAT radio telescope in South Africa. The measured orbital period,
1.97 days, is the longest among all eclipsing binaries in globular clusters
(GCs) and consistent with that of the coincident X-ray source U18, previously
suggested to be a 'hidden MSP'. Our XMM-Newton observations during NGC 6397B's
radio quiescent epochs detected no X-ray flares. NGC 6397B is either a
transitional MSP or an eclipsing binary in its initial stage of mass transfer
after the companion star left the main sequence. The discovery of NGC 6397B
potentially reveals a subgroup of extremely faint and heavily obscured binary
pulsars, thus providing a plausible explanation to the apparent dearth of
binary neutron stars in core-collapsed GCs as well as a critical constraint on
the evolution of GCs.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 08:55:26 GMT""}]","2022-08-03"
"2207.07881","Jianzhu Huai","Jianzhu Huai, Yukai Lin, Yujia Zhang","NOCT: Nonlinear Observability with Constraints and Time Offset","20 pages, 5 figures",,,"LIESMARS-TR-22-1","eess.SY cs.SY","http://creativecommons.org/licenses/by-sa/4.0/","  Nonlinear systems of affine control inputs overarch many sensor fusion
instances. Analyzing whether a state variable in such a nonlinear system can be
estimated (i.e., observability) informs better estimator design. Among the
research on local observability of nonlinear systems, approaches based on
differential geometry have attracted much attention for the solid theoretic
foundation and suitability to automated deduction. Such approaches usually work
with a system model of unconstrained control inputs and assume that the control
inputs and observation outputs are timestamped by the same clock. To our
knowledge, it has not been shown how to conduct the observability analysis with
additional constraints enforced on the system's observations or control inputs.
To this end, we propose procedures to convert a system model of affine control
inputs with linear constraints into a constraint-free standard model which is
apt to be analyzed by the classic observability analysis procedure. Then, the
whole analysis procedure is illustrated by applying to the well-studied visual
inertial odometry (VIO) system which estimates the camera-IMU relative pose and
time offset. The findings about unobservable variables under degenerate motion
concur with those obtained with linearized VIO systems in other studies,
whereas the findings about observability of time offset extend those in
previous studies. These findings are further validated by simulation.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 09:09:37 GMT""}]","2022-07-19"
"2207.07882","Utku Zorba","Ertu\u{g}rul Ekiz, Oguzhan Kasikci, Mehmet Ozkan, Cemal Berfu Senisik,
  and Utku Zorba","Non-Relativistic and Ultra-Relativistic Scaling Limits of Multimetric
  Gravity","32 pages, v2, references updated, version appeared in JHEP","JHEP 10 (2022) 151","10.1007/JHEP10(2022)151",,"hep-th gr-qc","http://creativecommons.org/licenses/by/4.0/","  We present a method of contraction that can be applied to re-construct the
recent extended non-relativistic and ultra-relativistic algebras as well as
corresponding action principles. The methodology involves the use of multiple
copies of Poincar\'e algebra. Consequently, the contraction defines
non-relativistic or ultra-relativistic limits of multimetric theories of
gravity. In particular, we show that the non-relativistic scaling limit of
bi-metric gravity corresponds to the recent formulation of an action principle
for Newtonian gravity with a constant background mass density.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 09:29:32 GMT""},{""version"":""v2"",""created"":""Mon, 24 Oct 2022 07:28:00 GMT""}]","2022-10-25"
"2207.07883","Wei Liu","Zhilu Lai, Wei Liu, Xudong Jian, Kiran Bacsa, Limin Sun, Eleni Chatzi","Neural modal ordinary differential equations: Integrating physics-based
  modeling with neural ordinary differential equations for modeling
  high-dimensional monitored structures","Accepted for publication in Data-Centric Engineering","Data-Centric Engineering, Volume 3, 2022, e34","10.1017/dce.2022.35",,"cs.LG cs.CE physics.data-an","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The order/dimension of models derived on the basis of data is commonly
restricted by the number of observations, or in the context of monitored
systems, sensing nodes. This is particularly true for structural systems (e.g.,
civil or mechanical structures), which are typically high-dimensional in
nature. In the scope of physics-informed machine learning, this paper proposes
a framework -- termed Neural Modal ODEs -- to integrate physics-based modeling
with deep learning for modeling the dynamics of monitored and high-dimensional
engineered systems. Neural Ordinary Differential Equations -- Neural ODEs are
exploited as the deep learning operator. In this initiating exploration, we
restrict ourselves to linear or mildly nonlinear systems. We propose an
architecture that couples a dynamic version of variational autoencoders with
physics-informed Neural ODEs (Pi-Neural ODEs). An encoder, as a part of the
autoencoder, learns the abstract mappings from the first few items of
observational data to the initial values of the latent variables, which drive
the learning of embedded dynamics via physics-informed Neural ODEs, imposing a
modal model structure on that latent space. The decoder of the proposed model
adopts the eigenmodes derived from an eigen-analysis applied to the linearized
portion of a physics-based model: a process implicitly carrying the spatial
relationship between degrees-of-freedom (DOFs). The framework is validated on a
numerical example, and an experimental dataset of a scaled cable-stayed bridge,
where the learned hybrid model is shown to outperform a purely physics-based
approach to modeling. We further show the functionality of the proposed scheme
within the context of virtual sensing, i.e., the recovery of generalized
response quantities in unmeasured DOFs from spatially sparse data.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 09:30:20 GMT""},{""version"":""v2"",""created"":""Wed, 30 Nov 2022 05:58:25 GMT""}]","2022-12-01"
"2207.07884","Deacon Linkhorn","Deacon Linkhorn","Model-completeness for the lattice of finite unions of closed intervals
  of a dense linear order",,,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let I be a dense linear order with a left endpoint but no right endpoint. We
consider the lattice L(I) of finite unions of closed intervals of I. This
lattice arises naturally in the setting of o-minimality, as these are precisely
the closed definable sets in any o-minimal expansion of I. Our main result says
that L(I), the expansion of the lattice by constants for the empty set and the
smallest element of I (viewed as a singleton subset) as well as four unary
functions, is model-complete. The proof of the main result makes use of
previous results regarding the weak monadic second order theory of I from the
authors PhD thesis.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 09:36:43 GMT""}]","2022-07-19"
"2207.07885","Jingjia Huang","Jingjia Huang, Yinan Li, Jiashi Feng, Xinglong Wu, Xiaoshuai Sun and
  Rongrong Ji","Clover: Towards A Unified Video-Language Alignment and Fusion Model","Update Tri-modal Alignment task",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Building a universal Video-Language model for solving various video
understanding tasks (\emph{e.g.}, text-video retrieval, video question
answering) is an open challenge to the machine learning field. Towards this
goal, most recent works build the model by stacking uni-modal and cross-modal
feature encoders and train it with pair-wise contrastive pre-text tasks. Though
offering attractive generality, the resulted models have to compromise between
efficiency and performance. They mostly adopt different architectures to deal
with different downstream tasks. We find this is because the pair-wise training
cannot well \emph{align} and \emph{fuse} features from different modalities. We
then introduce \textbf{Clover}\textemdash a Correlated Video-Language
pre-training method\textemdash towards a universal Video-Language model for
solving multiple video understanding tasks with neither performance nor
efficiency compromise. It improves cross-modal feature alignment and fusion via
a novel tri-modal alignment pre-training task. Additionally, we propose to
enhance the tri-modal alignment via incorporating learning from semantic masked
samples and a new pair-wise ranking loss. Clover establishes new
state-of-the-arts on multiple downstream tasks, including three retrieval tasks
for both zero-shot and fine-tuning settings, and eight video question answering
tasks. Codes and pre-trained models will be released at
\url{https://github.com/LeeYN-43/Clover}.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 09:38:52 GMT""},{""version"":""v2"",""created"":""Sun, 31 Jul 2022 17:33:09 GMT""},{""version"":""v3"",""created"":""Tue, 20 Dec 2022 17:35:13 GMT""}]","2022-12-21"
"2207.07886","Juan G\'omez-Luna","Juan G\'omez-Luna, Yuxin Guo, Sylvan Brocard, Julien Legriel, Remy
  Cimadomo, Geraldo F. Oliveira, Gagandeep Singh, Onur Mutlu","An Experimental Evaluation of Machine Learning Training on a Real
  Processing-in-Memory System","Our open-source software is available at
  https://github.com/CMU-SAFARI/pim-ml",,,,"cs.AR cs.AI cs.DC cs.LG","http://creativecommons.org/licenses/by/4.0/","  Training machine learning (ML) algorithms is a computationally intensive
process, which is frequently memory-bound due to repeatedly accessing large
training datasets. As a result, processor-centric systems (e.g., CPU, GPU)
suffer from costly data movement between memory units and processing units,
which consumes large amounts of energy and execution cycles. Memory-centric
computing systems, i.e., with processing-in-memory (PIM) capabilities, can
alleviate this data movement bottleneck.
  Our goal is to understand the potential of modern general-purpose PIM
architectures to accelerate ML training. To do so, we (1) implement several
representative classic ML algorithms (namely, linear regression, logistic
regression, decision tree, K-Means clustering) on a real-world general-purpose
PIM architecture, (2) rigorously evaluate and characterize them in terms of
accuracy, performance and scaling, and (3) compare to their counterpart
implementations on CPU and GPU. Our evaluation on a real memory-centric
computing system with more than 2500 PIM cores shows that general-purpose PIM
architectures can greatly accelerate memory-bound ML workloads, when the
necessary operations and datatypes are natively supported by PIM hardware. For
example, our PIM implementation of decision tree is $27\times$ faster than a
state-of-the-art CPU version on an 8-core Intel Xeon, and $1.34\times$ faster
than a state-of-the-art GPU version on an NVIDIA A100. Our K-Means clustering
on PIM is $2.8\times$ and $3.2\times$ than state-of-the-art CPU and GPU
versions, respectively.
  To our knowledge, our work is the first one to evaluate ML training on a
real-world PIM architecture. We conclude with key observations, takeaways, and
recommendations that can inspire users of ML workloads, programmers of PIM
architectures, and hardware designers & architects of future memory-centric
computing systems.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 09:39:53 GMT""},{""version"":""v2"",""created"":""Thu, 20 Apr 2023 08:55:17 GMT""},{""version"":""v3"",""created"":""Sun, 23 Apr 2023 21:15:15 GMT""},{""version"":""v4"",""created"":""Fri, 19 May 2023 15:08:58 GMT""}]","2023-05-22"
"2207.07887","Adrian Langer","Adrian Langer","Approximation of semistable bundles on smooth algebraic varieties","11 pages",,,,"math.AG","http://creativecommons.org/licenses/by/4.0/","  We prove some strong results on approximation of strongly semistable bundles
with vanishing numerical Chern classes by filtrations, whose quotients are line
bundles of similar slope. This generalizes some earlier results of
Parameswaran-Subramanian in the curve case and Koley-Parameswaran in the
surface case and it confirms the conjecture posed by Koley and Parameswaran.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 09:43:58 GMT""}]","2022-07-19"
"2207.07888","Davide Buffelli","Davide Buffelli, Pietro Li\`o, Fabio Vandin","SizeShiftReg: a Regularization Method for Improving Size-Generalization
  in Graph Neural Networks","Accepted at NeurIPS 2022",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the past few years, graph neural networks (GNNs) have become the de facto
model of choice for graph classification. While, from the theoretical
viewpoint, most GNNs can operate on graphs of any size, it is empirically
observed that their classification performance degrades when they are applied
on graphs with sizes that differ from those in the training data. Previous
works have tried to tackle this issue in graph classification by providing the
model with inductive biases derived from assumptions on the generative process
of the graphs, or by requiring access to graphs from the test domain. The first
strategy is tied to the quality of the assumptions made for the generative
process, and requires the use of specific models designed after the explicit
definition of the generative process of the data, leaving open the question of
how to improve the performance of generic GNN models in general settings. On
the other hand, the second strategy can be applied to any GNN, but requires
access to information that is not always easy to obtain. In this work we
consider the scenario in which we only have access to the training data, and we
propose a regularization strategy that can be applied to any GNN to improve its
generalization capabilities from smaller to larger graphs without requiring
access to the test data. Our regularization is based on the idea of simulating
a shift in the size of the training graphs using coarsening techniques, and
enforcing the model to be robust to such a shift. Experimental results on
standard datasets show that popular GNN models, trained on the 50% smallest
graphs in the dataset and tested on the 10% largest graphs, obtain performance
improvements of up to 30% when trained with our regularization strategy.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 09:50:45 GMT""},{""version"":""v2"",""created"":""Thu, 20 Oct 2022 17:55:47 GMT""}]","2022-10-21"
"2207.07889","Zhenchao Jin","Zhenchao Jin, Dongdong Yu, Luchuan Song, Zehuan Yuan, Lequan Yu","You Should Look at All Objects","Accepted by ECCV2022",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Feature pyramid network (FPN) is one of the key components for object
detectors. However, there is a long-standing puzzle for researchers that the
detection performance of large-scale objects are usually suppressed after
introducing FPN. To this end, this paper first revisits FPN in the detection
framework and reveals the nature of the success of FPN from the perspective of
optimization. Then, we point out that the degraded performance of large-scale
objects is due to the arising of improper back-propagation paths after
integrating FPN. It makes each level of the backbone network only has the
ability to look at the objects within a certain scale range. Based on these
analysis, two feasible strategies are proposed to enable each level of the
backbone to look at all objects in the FPN-based detection frameworks.
Specifically, one is to introduce auxiliary objective functions to make each
backbone level directly receive the back-propagation signals of various-scale
objects during training. The other is to construct the feature pyramid in a
more reasonable way to avoid the irrational back-propagation paths. Extensive
experiments on the COCO benchmark validate the soundness of our analysis and
the effectiveness of our methods. Without bells and whistles, we demonstrate
that our method achieves solid improvements (more than 2%) on various detection
frameworks: one-stage, two-stage, anchor-based, anchor-free and
transformer-based detectors.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 09:59:34 GMT""}]","2022-07-19"
"2207.07890","Chia-Rui Chang","Chia-Rui Chang, Yue Song, Fan Li, Rui Wang","Covariate Adjustment in Randomized Clinical Trials with Missing
  Covariate and Outcome Data",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When analyzing data from randomized clinical trials, covariate adjustment can
be used to account for chance imbalance in baseline covariates and to increase
precision of the treatment effect estimate. A practical barrier to covariate
adjustment is the presence of missing data. In this paper, in the light of
recent theoretical advancement, we first review several covariate adjustment
methods with incomplete covariate data. We investigate the implications of the
missing data mechanism on estimating the average treatment effect in randomized
clinical trials with continuous or binary outcomes. In parallel, we consider
settings where the outcome data are fully observed or are missing at random; in
the latter setting, we propose a full weighting approach that combines inverse
probability weighting for adjusting missing outcomes and overlap weighting for
covariate adjustment. We highlight the importance of including the interaction
terms between the missingness indicators and covariates as predictors in the
models. We conduct comprehensive simulation studies to examine the
finite-sample performance of the proposed methods and compare with a range of
common alternatives. We find that conducting the proposed adjustment methods
generally improves the precision of treatment effect estimates regardless of
the imputation methods when the adjusted covariate is associated with the
outcome. We apply the methods to the Childhood Adenotonsillectomy Trial to
assess the effect of adenotonsillectomy on neurocognitive functioning scores.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 10:05:08 GMT""},{""version"":""v2"",""created"":""Wed, 17 May 2023 02:07:24 GMT""}]","2023-05-18"
"2207.07891","Kenneth Duru","Kenneth Duru and Christopher Williams and Frederick Fung","Accurate simulations of nonlinear dynamic shear ruptures on pre-existing
  faults in 3D elastic solids with dual-pairing SBP methods","35 pages",,,,"math.NA cs.NA physics.comp-ph physics.geo-ph","http://creativecommons.org/licenses/by/4.0/","  In this paper we derive and analyse efficient and stable numerical methods
for accurate numerical simulations of nonlinear dynamic shear ruptures on
non-planar faults embedded in 3D elastic solids using dual-paring (DP)
summation by parts (SBP) finite difference (FD) methods. Specifically, for
nonlinear dynamic earthquake ruptures, we demonstrate that the DP SBP FD
operators [K. Mattsson. J. Comput. Phys., 335:283-310, 2017] generate spurious
catastrophic high frequency wave modes that do not diminish with mesh
refinement. Meanwhile our new dispersion relation preserving (DRP) SBP FD
operators [C. Williams and K Duru, arXiv:2110.04957, 2021] have more accurate
numerical dispersion relation properties and do not support poisonous spurious
high frequency wave modes. Numerical simulations are performed in 3D with
geometrically complex fault surfaces verifying the efficacy of the method. Our
method accurately reproduces community developed dynamic rupture benchmark
problems, proposed by Southern California Earthquake Center, with less
computational effort than standard methods based on traditional SBP FD
operators.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 10:06:59 GMT""}]","2022-07-19"
"2207.07892","Sneha Mavi","Sneha Mavi, Anuj Bishnoi","Abstract Key Polynomials and MacLane-Vaqui\'e chains","To appear in International Journal of Algebra and Computation. arXiv
  admin note: substantial text overlap with arXiv:2204.06428",,,,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, for a valued field $(K, v)$ of arbitrary rank and an extension
$w$ of $v$ to $K(X),$ a relation between induced complete sequences of abstract
key polynomials and MacLane-Vaqui\'e chains is given.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 10:11:39 GMT""},{""version"":""v2"",""created"":""Wed, 28 Sep 2022 05:38:21 GMT""}]","2022-09-29"
"2207.07893","Haris Fawad","Haris Fawad, P{\aa}l Ryalen, Vasiliki Tsarpali, Kristian Heldal,
  Kjetil R{\o}ysland","Hypothetical Treatment Accelerations: Estimating Causal Effects of
  Kidney Transplants from Observational Data",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  Patients with end-stage kidney disease can expect to wait for several years
before they receive a transplant, all the while their health deteriorates. How
would the survival change if we managed to reduce these waiting times? To
provide an answer, we present a continuous-time marginal structural model (MSM)
of hypothetical scenarios in which the time until treatment is changed. In
these scenarios, the treatment process is defined on a hypothetical time scale
where time passes at a different rate compared to the time actually observed.
Changing the time of the treatment process corresponds to changing the joint
probability distribution, thereby making it possible to identify and estimate
hypothetical parameters from observational data using previously developed
methodology. We demonstrate this treatment-accelerated MSM using observational
data from a Norwegian cohort of elderly patients with kidney failure. This
model can potentially be useful to health authorities looking to assess the
impacts of reducing the waiting times for organ transplantation in a given
patient population.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 10:21:06 GMT""}]","2022-07-19"
"2207.07894","Muhammad Abdullah Jamal","Muhammad Abdullah Jamal, Omid Mohareri","Multi-Modal Unsupervised Pre-Training for Surgical Operating Room
  Workflow Analysis","International Conference on Medical Image Computing and Computer
  Assisted Intervention (MICCAI'22)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data-driven approaches to assist operating room (OR) workflow analysis depend
on large curated datasets that are time consuming and expensive to collect. On
the other hand, we see a recent paradigm shift from supervised learning to
self-supervised and/or unsupervised learning approaches that can learn
representations from unlabeled datasets. In this paper, we leverage the
unlabeled data captured in robotic surgery ORs and propose a novel way to fuse
the multi-modal data for a single video frame or image. Instead of producing
different augmentations (or 'views') of the same image or video frame which is
a common practice in self-supervised learning, we treat the multi-modal data as
different views to train the model in an unsupervised manner via clustering. We
compared our method with other state of the art methods and results show the
superior performance of our approach on surgical video activity recognition and
semantic segmentation.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 10:32:27 GMT""}]","2022-07-19"
"2207.07895","Haimei Zhao","Haimei Zhao, Jing Zhang, Sen Zhang, Dacheng Tao","JPerceiver: Joint Perception Network for Depth, Pose and Layout
  Estimation in Driving Scenes","Accepted by ECCV 2022",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Depth estimation, visual odometry (VO), and bird's-eye-view (BEV) scene
layout estimation present three critical tasks for driving scene perception,
which is fundamental for motion planning and navigation in autonomous driving.
Though they are complementary to each other, prior works usually focus on each
individual task and rarely deal with all three tasks together. A naive way is
to accomplish them independently in a sequential or parallel manner, but there
are many drawbacks, i.e., 1) the depth and VO results suffer from the inherent
scale ambiguity issue; 2) the BEV layout is directly predicted from the
front-view image without using any depth-related information, although the
depth map contains useful geometry clues for inferring scene layouts. In this
paper, we address these issues by proposing a novel joint perception framework
named JPerceiver, which can simultaneously estimate scale-aware depth and VO as
well as BEV layout from a monocular video sequence. It exploits the cross-view
geometric transformation (CGT) to propagate the absolute scale from the road
layout to depth and VO based on a carefully-designed scale loss. Meanwhile, a
cross-view and cross-modal transfer (CCT) module is devised to leverage the
depth clues for reasoning road and vehicle layout through an attention
mechanism. JPerceiver can be trained in an end-to-end multi-task learning way,
where the CGT scale loss and CCT module promote inter-task knowledge transfer
to benefit feature learning of each task. Experiments on Argoverse, Nuscenes
and KITTI show the superiority of JPerceiver over existing methods on all the
above three tasks in terms of accuracy, model size, and inference speed. The
code and models are available
at~\href{https://github.com/sunnyHelen/JPerceiver}{https://github.com/sunnyHelen/JPerceiver}.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 10:33:59 GMT""}]","2022-07-19"
"2207.07896","Dongjiang Cao","Dongjiang Cao, Ruofeng Liu, Hao Li, Shuai Wang, Wenchao Jiang, Chris
  Xiaoxuan Lu","Cross Vision-RF Gait Re-identification with Low-cost RGB-D Cameras and
  mmWave Radars","24 pages, 20 figures, accepted to IMWUT",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Human identification is a key requirement for many applications in everyday
life, such as personalized services, automatic surveillance, continuous
authentication, and contact tracing during pandemics, etc. This work studies
the problem of cross-modal human re-identification (ReID), in response to the
regular human movements across camera-allowed regions (e.g., streets) and
camera-restricted regions (e.g., offices) deployed with heterogeneous sensors.
By leveraging the emerging low-cost RGB-D cameras and mmWave radars, we propose
the first-of-its-kind vision-RF system for cross-modal multi-person ReID at the
same time. Firstly, to address the fundamental inter-modality discrepancy, we
propose a novel signature synthesis algorithm based on the observed specular
reflection model of a human body. Secondly, an effective cross-modal deep
metric learning model is introduced to deal with interference caused by
unsynchronized data across radars and cameras. Through extensive experiments in
both indoor and outdoor environments, we demonstrate that our proposed system
is able to achieve ~92.5% top-1 accuracy and ~97.5% top-5 accuracy out of 56
volunteers. We also show that our proposed system is able to robustly
reidentify subjects even when multiple subjects are present in the sensors'
field of view.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 10:34:25 GMT""}]","2022-07-19"
"2207.07897","Yarden Rotem","Yarden Rotem and Nathaniel Shimoni and Lior Rokach and Bracha Shapira","Transfer learning for time series classification using synthetic data
  generation","This preprint has not undergone peer review or any post-submission
  im- provement or corrections. The Version of Record of this contribution is
  published in LNCS 13301, CSCML 2022, and is available online at
  https://link.springer.com/chapter/10.1007/978-3-031-07689-3 18",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose an innovative Transfer learning for Time series
classification method. Instead of using an existing dataset from the UCR
archive as the source dataset, we generated a 15,000,000 synthetic univariate
time series dataset that was created using our unique synthetic time series
generator algorithm which can generate data with diverse patterns and angles
and different sequence lengths. Furthermore, instead of using classification
tasks provided by the UCR archive as the source task as previous studies did,we
used our own 55 regression tasks as the source tasks, which produced better
results than selecting classification tasks from the UCR archive
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 10:35:14 GMT""}]","2022-07-19"
"2207.07898","Minhyeok Lee","Minhyeok Lee, Chaewon Park, Suhwan Cho, Sangyoun Lee","SPSN: Superpixel Prototype Sampling Network for RGB-D Salient Object
  Detection","Accepted to European Conference on Computer Vision (ECCV) 2022",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  RGB-D salient object detection (SOD) has been in the spotlight recently
because it is an important preprocessing operation for various vision tasks.
However, despite advances in deep learning-based methods, RGB-D SOD is still
challenging due to the large domain gap between an RGB image and the depth map
and low-quality depth maps. To solve this problem, we propose a novel
superpixel prototype sampling network (SPSN) architecture. The proposed model
splits the input RGB image and depth map into component superpixels to generate
component prototypes. We design a prototype sampling network so that the
network only samples prototypes corresponding to salient objects. In addition,
we propose a reliance selection module to recognize the quality of each RGB and
depth feature map and adaptively weight them in proportion to their
reliability. The proposed method makes the model robust to inconsistencies
between RGB images and depth maps and eliminates the influence of non-salient
objects. Our method is evaluated on five popular datasets, achieving
state-of-the-art performance. We prove the effectiveness of the proposed method
through comparative experiments.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 10:43:14 GMT""}]","2022-07-19"
"2207.07899","Kuantay Boshkayev","Kuantay Boshkayev, Gulmira Nurbakyt, Hernando Quevedo, Gulnara
  Suliyeva, Abylaikhan Tlemissov, Zhanerke Tlemissova, Anar Dalelkhankyzy,
  Aliya Taukenova, Ainur Urazalina, Zden\v{e}k Stuchl\'ik","Adiabatic theory in Kerr spacetimes","11 pages, 2 figures, 1 table. arXiv admin note: text overlap with
  arXiv:2205.04217",,,,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  We present the main aspects of the adiabatic theory and show that it can be
used to study the motion of test particles in general relativity. The theory is
based upon the use of vector elements of the orbits and adiabatic invariants.
To prove the applicability of the adiabatic theory in Einstein's gravity, we
derive a particular representation of the Kerr metric in harmonic coordinates,
which allows us to obtain a general formula for the perihelion shift of test
particles orbiting on the non-equatorial plane of a rotating central object. We
show that the principle of superposition is fulfilled for the individual
effects of the gravitational source mass and angular momentum up to the second
order. We demonstrate that the adiabatic theory, along with its simplicity,
leads to correct results, which in the limiting cases correspond to the ones
reported in the literature.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 10:45:17 GMT""},{""version"":""v2"",""created"":""Mon, 22 May 2023 15:50:07 GMT""}]","2023-05-23"
"2207.07900","Juze Zhang","Juze Zhang, Jingya Wang, Ye Shi, Fei Gao, Lan Xu, Jingyi Yu","Mutual Adaptive Reasoning for Monocular 3D Multi-Person Pose Estimation","Accepted by ACM MM 2022",,,,"cs.CV cs.AI cs.GR","http://creativecommons.org/licenses/by/4.0/","  Inter-person occlusion and depth ambiguity make estimating the 3D poses of
monocular multiple persons as camera-centric coordinates a challenging problem.
Typical top-down frameworks suffer from high computational redundancy with an
additional detection stage. By contrast, the bottom-up methods enjoy low
computational costs as they are less affected by the number of humans. However,
most existing bottom-up methods treat camera-centric 3D human pose estimation
as two unrelated subtasks: 2.5D pose estimation and camera-centric depth
estimation. In this paper, we propose a unified model that leverages the mutual
benefits of both these subtasks. Within the framework, a robust structured 2.5D
pose estimation is designed to recognize inter-person occlusion based on depth
relationships. Additionally, we develop an end-to-end geometry-aware depth
reasoning method that exploits the mutual benefits of both 2.5D pose and
camera-centric root depths. This method first uses 2.5D pose and geometry
information to infer camera-centric root depths in a forward pass, and then
exploits the root depths to further improve representation learning of 2.5D
pose estimation in a backward pass. Further, we designed an adaptive fusion
scheme that leverages both visual perception and body geometry to alleviate
inherent depth ambiguity issues. Extensive experiments demonstrate the
superiority of our proposed model over a wide range of bottom-up methods. Our
accuracy is even competitive with top-down counterparts. Notably, our model
runs much faster than existing bottom-up and top-down methods.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 10:54:40 GMT""}]","2022-07-19"
"2207.07901","Mahyuddin K. M. Nasution","Mahyuddin K. M. Nasution, Rahmat Hidayat, and Rahmad Syah","Computer Science","18, 2 figures","International Journal on Advanced Science Engineering Information
  Technology, 12(3), 2022",,"123","cs.CY","http://creativecommons.org/publicdomain/zero/1.0/","  Possible for science itself, conceptually, to have and will understand
differently, let alone science also seen as technology, such as computer
science. After all, science and technology are viewpoints diverse by either
individual, community, or social. Generally, it depends on socioeconomic
capabilities. So it is with computer science has become a phenomenon and
fashionable, where based on the stream of documents, various issues arise in
either its theory or implementation, adapting different communities, or
designing curriculum holds in the education system.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 10:54:57 GMT""}]","2022-07-19"
"2207.07902","Allen Juntao Fang","Allen Juntao Fang","Linear stability of the slowly-rotating Kerr-de Sitter family",,,,,"gr-qc math-ph math.AP math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we prove that the slowly-rotating Kerr-de Sitter family of
black holes are linearly stable as a family of solutions to the Einstein vacuum
equations with $\Lambda>0$ in harmonic (wave) gauge. This article is part of a
series that provides a novel proof of the full nonlinear stability of the
slowly-rotating Kerr-de Sitter family. This paper and its follow-up offer a
self-contained alternative approach to nonlinear stability of the Kerr-de
Sitter family from the original work of Hintz and Vasy by interpreting
quasinormal modes as $H^k$ eigenvalues of an operator on a Hilbert space, and
using integrated local energy decay estimates to prove the existence of a
spectral gap. In particular, we avoid the construction of a meromorphic
continuation of the resolvent. We also do not compactify the spacetime, thus
avoiding the use of $b$-calculus and instead only use standard
pseudo-differential arguments in a neighborhood of the trapped set; and avoid
constraint damping altogether. The methods in the current paper offer an
explicit example of how to use the vectorfield method to achieve resolvent
estimates on a trapping background.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 10:55:22 GMT""}]","2022-07-19"
"2207.07903","Shahid Shah","Mir Shahnawaz Ahmed and Shahid Mehraj Shah","Unsupervised Ensemble Based Deep Learning Approach for Attack Detection
  in IoT Network","18 Pages, 10 Figures, 6 Tables",,,,"cs.IT cs.CR cs.LG math.IT","http://creativecommons.org/licenses/by/4.0/","  The Internet of Things (IoT) has altered living by controlling devices/things
over the Internet. IoT has specified many smart solutions for daily problems,
transforming cyber-physical systems (CPS) and other classical fields into smart
regions. Most of the edge devices that make up the Internet of Things have very
minimal processing power. To bring down the IoT network, attackers can utilise
these devices to conduct a variety of network attacks. In addition, as more and
more IoT devices are added, the potential for new and unknown threats grows
exponentially. For this reason, an intelligent security framework for IoT
networks must be developed that can identify such threats. In this paper, we
have developed an unsupervised ensemble learning model that is able to detect
new or unknown attacks in an IoT network from an unlabelled dataset. The
system-generated labelled dataset is used to train a deep learning model to
detect IoT network attacks. Additionally, the research presents a feature
selection mechanism for identifying the most relevant aspects in the dataset
for detecting attacks. The study shows that the suggested model is able to
identify the unlabelled IoT network datasets and DBN (Deep Belief Network)
outperform the other models with a detection accuracy of 97.5% and a false
alarm rate of 2.3% when trained using labelled dataset supplied by the proposed
approach.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 11:12:32 GMT""}]","2022-07-19"
"2207.07904","Niccol\`o Zagli","Niccol\`o Zagli, Grigorios A. Pavliotis, Valerio Lucarini, Alexander
  Alecio","Dimension reduction of noisy interacting systems","Accepted Version of the manuscript",,,,"cond-mat.stat-mech math-ph math.MP nlin.CD","http://creativecommons.org/licenses/by/4.0/","  We consider a class of models describing an ensemble of identical interacting
agents subject to multiplicative noise. In the thermodynamic limit, these
systems exhibit continuous and discontinuous phase transitions in a, generally,
nonequilibrium setting. We provide a systematic dimension reduction methodology
for constructing low dimensional, reduced-order dynamics based on the cumulants
of the probability distribution of the infinite system. We show that the low
dimensional dynamics returns the correct diagnostic properties since it
produces a quantitatively accurate representation of the stationary phase
diagram of the system that we compare with exact analytical results and
numerical simulations. Moreover, we prove that the reduced order dynamics
yields also the prognostic, i.e., time dependent properties, as it provides the
correct response of the system to external perturbations. On the one hand, this
validates the use of our complexity reduction methodology since it retains
information not only of the invariant measure of the system but also of the
transition probabilities and time dependent correlation properties of the
stochastic dynamics. On the other hand, the breakdown of linear response
properties is a key signature of the occurrence of a phase transition. We show
that the reduced response operators capture the correct diverging resonant
behaviour by quantitatively assessing the singular nature of the susceptibility
of the system and the appearance of a pole for real value of frequencies.
Hence, this methodology can be interpreted as a low dimensional, reduced order
approach to the investigation and detection of critical phenomena in high
dimensional interacting systems in settings where order parameters are not
known.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 11:24:00 GMT""},{""version"":""v2"",""created"":""Fri, 23 Dec 2022 13:01:02 GMT""},{""version"":""v3"",""created"":""Thu, 26 Jan 2023 17:41:03 GMT""}]","2023-01-27"
"2207.07905","Valerio Faraoni","Shin'ichi Nojiri, Sergei D. Odintsov, Valerio Faraoni","Alternative entropies and consistent black hole thermodynamics","20 pages, LateX, to appear in Int. J. Geom. Meth. Mod. Phys",,"10.1142/S0219887822502103",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While the Bekenstein-Hawking entropy is the unique notion of entropy that
makes classical black hole thermodynamics consistent, alternative entropy
notions (R\'enyi, Tsallis, and generalized constructs) abound in the
literature. We explore conditions under which they are part of a consistent
horizon thermodynamics for certain classes of modified gravity black holes. We
provide examples in which black hole masses and temperatures going hand-in-hand
with these alternative entropies coincide with their usual counterparts
associated with the Bekenstein-Hawking entropy.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 11:24:12 GMT""}]","2022-12-07"
"2207.07906","Carlos Lopez","Carlos Lopez-Coba, Sebastian F. Sanchez, Lihwai Lin, Joseph P.
  Anderson, Kai-Yang Lin, Irene Cruz-Gonzalez, L. Galbany, Jorge K.
  Barrera-Ballesteros","Exploring stellar and ionized gas non--circular motions in barred
  galaxies with MUSE","17 pages, 11 Figures, submitted to ApJ",,"10.3847/1538-4357/ac937b",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We present MUSE integral field stellar and ionized velocity maps for a sample
of 14 barred galaxies. Most of these objects exhibit ""S""-shape iso-velocities
in the bar region indicative of the presence of streaming motions in the
velocity fields. % By applying circular rotation models we observe that bars
leave symmetric structures in the residual maps of the stellar velocity. %which
demonstrates the capabilities of the MUSE instrument for detecting kinematic
bar signatures. % We built non-circular rotation models using the \xs~tool to
characterize the observed velocity fields. In particular we adopt bisymmetric
models and a harmonic decomposition for a bar potential for describing the
non-axisymmetric velocities. We find that both models reproduce the observed
kinematic features. % The position angle of the oval distortion estimated from
the bisymmetric model correlates with the photometric bar position angle
$(\rho_{pearson} = 0.95)$, which suggest that non-circular velocities are
caused by the bar. However because of the low amplitudes of the $s_3$ harmonic
we can not rule out radial flows as possible source. % Because of the weak
detection of \ha~in our objects we are not able to compare gas to stellar
non-circular motions in our sample, although we show that when galaxies are gas
rich the oval distortion is also observed but with larger amplitudes. %
Finally, we do not find evidence that the amplitude of the non-circular motions
is dependent on the bar size, stellar mass or the global SFR.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 11:39:48 GMT""}]","2022-11-09"
"2207.07907","Isao Watanabe","Muhamad Darwis Umar, Katsuhiko Ishida, Rie Murayama, Dita Puspita
  Sari, Utami Widyaiswari, Marco Fronzi, Harion Rozak, Wan Nurfadhilah Zaharim,
  Isao Watanabe, Masahiko Iwasaki","Muon-Spin Motion at the Crossover Regime between Gaussian and Lorentzian
  Distribution of Magnetic Fields","23 pages, 10 figures, see https://doi.org/10.1093/ptep/ptab074","Prog. Theor. Exp. Phys. 2021, 083I01 (17 pages)",,,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  The muon spin relaxation method ({\mu}SR) is a powerful microscopic tool to
probe electronic states of materials observing local magnetic field
distributions on the muon. It often happens that a distribution of local
magnetic fields shows intermediate state between Gaussian and Lorentzian
shapes. In order to generally describe intermediate field distributions, we
dealt the convolution of two isotropic distributions in the three dimension and
derived exact muon-spin relaxation functions which can be applied to all
crossover regimes between the Gaussian and Lorentzian.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 11:42:27 GMT""}]","2022-07-19"
"2207.07908","Gabriele D'Acunto","Gabriele D'Acunto, Paolo Di Lorenzo, Sergio Barbarossa","Multiscale Causal Structure Learning",,,,,"cs.LG stat.ME stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The inference of causal structures from observed data plays a key role in
unveiling the underlying dynamics of the system. This paper exposes a novel
method, named Multiscale-Causal Structure Learning (MS-CASTLE), to estimate the
structure of linear causal relationships occurring at different time scales.
Differently from existing approaches, MS-CASTLE takes explicitly into account
instantaneous and lagged inter-relations between multiple time series,
represented at different scales, hinging on stationary wavelet transform and
non-convex optimization. MS-CASTLE incorporates, as a special case, a
single-scale version named SS-CASTLE, which compares favorably in terms of
computational efficiency, performance and robustness with respect to the state
of the art onto synthetic data. We used MS-CASTLE to study the multiscale
causal structure of the risk of 15 global equity markets, during covid-19
pandemic, illustrating how MS-CASTLE can extract meaningful information thanks
to its multiscale analysis, outperforming SS-CASTLE. We found that the most
persistent and strongest interactions occur at mid-term time resolutions.
Moreover, we identified the stock markets that drive the risk during the
considered period: Brazil, Canada and Italy. The proposed approach can be
exploited by financial investors who, depending to their investment horizon,
can manage the risk within equity portfolios from a causal perspective.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 11:47:32 GMT""}]","2022-07-19"
"2207.07909","Sreenath Kizhakkumpurath Manikandan","Sreenath K. Manikandan","Autonomous quantum clocks using athermal resources","13 pages, 7 figures",,,,"quant-ph cond-mat.mes-hall gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Here we explore the possibility of precise time-keeping in quantum systems
using athermal resources. We show that quantum measurement engineered
reservoirs can be used as athermal resources to drive the ticks of a quantum
clock. Two and three level quantum systems act as transducers in our model,
converting the quantum measurement induced noise to produce a series of ticks.
The ticking rate of the clock is maximized when the measured observable
maximally non-commutes with the clock's Hamiltonian. We use the large deviation
principle to characterize the statistics of observed ticks within a given
time-period and show that it can be sub-Poissonian -- quantified by Mandel's Q
parameter -- alluding to the quantum nature of the clock. We discuss the
accuracy and efficiency of the clock, and extend our framework to include
hybrid quantum clocks fueled by both measurements, and thermal resources. We
make comparisons to relatable recent proposals for quantum clocks, and discuss
alternate device implementations harvesting the quantum measurement engineered
non-equilibrium conditions, beyond the clock realization.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 11:49:38 GMT""},{""version"":""v2"",""created"":""Sun, 8 Jan 2023 11:12:08 GMT""}]","2023-01-10"
"2207.07913","Chaofan Zheng","Chaofan Zheng, Lianli Gao, Xinyu Lyu, Pengpeng Zeng, Abdulmotaleb El
  Saddik, Heng Tao Shen","Dual-branch Hybrid Learning Network for Unbiased Scene Graph Generation",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The current studies of Scene Graph Generation (SGG) focus on solving the
long-tailed problem for generating unbiased scene graphs. However, most
de-biasing methods overemphasize the tail predicates and underestimate head
ones throughout training, thereby wrecking the representation ability of head
predicate features. Furthermore, these impaired features from head predicates
harm the learning of tail predicates. In fact, the inference of tail predicates
heavily depends on the general patterns learned from head ones, e.g., ""standing
on"" depends on ""on"". Thus, these de-biasing SGG methods can neither achieve
excellent performance on tail predicates nor satisfying behaviors on head ones.
To address this issue, we propose a Dual-branch Hybrid Learning network (DHL)
to take care of both head predicates and tail ones for SGG, including a
Coarse-grained Learning Branch (CLB) and a Fine-grained Learning Branch (FLB).
Specifically, the CLB is responsible for learning expertise and robust features
of head predicates, while the FLB is expected to predict informative tail
predicates. Furthermore, DHL is equipped with a Branch Curriculum Schedule
(BCS) to make the two branches work well together. Experiments show that our
approach achieves a new state-of-the-art performance on VG and GQA datasets and
makes a trade-off between the performance of tail predicates and head ones.
Moreover, extensive experiments on two downstream tasks (i.e., Image Captioning
and Sentence-to-Graph Retrieval) further verify the generalization and
practicability of our method.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 11:53:50 GMT""}]","2022-07-19"
"2207.07914","Ting Wang","Wen Qi Wei, An He, Bo Yang, Jing-Zhi Huang, Dong Han, Min Ming, Zi Hao
  Wang, Xuhan Guo, Yikai Su, Jian Jun Zhang, Ting Wang","Monolithic Integration of Embedded III-V Lasers on SOI",,,,,"physics.optics physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Silicon photonic integration has gained great success in many application
fields owing to the excellent optical device properties and complementary
metal-oxide semiconductor (CMOS) compatibility. Realizing monolithic
integration of III-V lasers and silicon photonic components on single silicon
wafer is recognized as a long-standing obstacle for ultra-dense photonic
integration, which can provide considerable economical, energy efficient and
foundry-scalable on-chip light sources, that has not been reported yet. Here,
we demonstrate embedded InAs/GaAs quantum dot (QD) lasers directly grown on
trenched silicon-on-insulator (SOI) substrate, enabling monolithic integration
with butt-coupled silicon waveguides. By utilizing the patterned grating
structures inside pre-defined SOI trenches and unique epitaxial method via
molecular beam epitaxy (MBE), high-performance embedded InAs QD lasers with
out-coupled silicon waveguide are achieved on such template. By resolving the
epitaxy and fabrication challenges in such monolithic integrated architecture,
embedded III-V lasers on SOI with continuous-wave lasing up to 85 oC are
obtained. The maximum output power of 6.8 mW can be measured from the end tip
of the butt-coupled silicon waveguides, with estimated coupling efficiency of
approximately -7.35 dB. The results presented here provide a scalable and
low-cost epitaxial method for realization of on-chip light sources directly
coupling to the silicon photonic components for future high-density photonic
integration.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 11:59:45 GMT""}]","2022-07-19"
"2207.07918","Amit Bhati Dr.","Amit Bhati, Neha Gour, Pritee Khanna, Aparajita Ojha","Discriminative Kernel Convolution Network for Multi-Label Ophthalmic
  Disease Detection on Imbalanced Fundus Image Dataset",,,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  It is feasible to recognize the presence and seriousness of eye disease by
investigating the progressions in retinal biological structure. Fundus
examination is a diagnostic procedure to examine the biological structure and
anomaly of the eye. Ophthalmic diseases like glaucoma, diabetic retinopathy,
and cataract are the main reason for visual impairment around the world. Ocular
Disease Intelligent Recognition (ODIR-5K) is a benchmark structured fundus
image dataset utilized by researchers for multi-label multi-disease
classification of fundus images. This work presents a discriminative kernel
convolution network (DKCNet), which explores discriminative region-wise
features without adding extra computational cost. DKCNet is composed of an
attention block followed by a squeeze and excitation (SE) block. The attention
block takes features from the backbone network and generates discriminative
feature attention maps. The SE block takes the discriminative feature maps and
improves channel interdependencies. Better performance of DKCNet is observed
with InceptionResnet backbone network for multi-label classification of ODIR-5K
fundus images with 96.08 AUC, 94.28 F1-score and 0.81 kappa score. The proposed
method splits the common target label for an eye pair based on the diagnostic
keyword. Based on these labels oversampling and undersampling is done to
resolve class imbalance. To check the biasness of proposed model towards
training data, the model trained on ODIR dataset is tested on three publicly
available benchmark datasets. It is found to give good performance on
completely unseen fundus images also.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 12:03:27 GMT""}]","2022-07-19"
"2207.07919","Poornima Singh Thakur","Poornima Singh Thakur, Pritee Khanna, Tanuja Sheorey, Aparajita Ojha","Explainable vision transformer enabled convolutional neural network for
  plant disease identification: PlantXViT","21 pages, 11 figures, 7 tables",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Plant diseases are the primary cause of crop losses globally, with an impact
on the world economy. To deal with these issues, smart agriculture solutions
are evolving that combine the Internet of Things and machine learning for early
disease detection and control. Many such systems use vision-based machine
learning methods for real-time disease detection and diagnosis. With the
advancement in deep learning techniques, new methods have emerged that employ
convolutional neural networks for plant disease detection and identification.
Another trend in vision-based deep learning is the use of vision transformers,
which have proved to be powerful models for classification and other problems.
However, vision transformers have rarely been investigated for plant pathology
applications. In this study, a Vision Transformer enabled Convolutional Neural
Network model called ""PlantXViT"" is proposed for plant disease identification.
The proposed model combines the capabilities of traditional convolutional
neural networks with the Vision Transformers to efficiently identify a large
number of plant diseases for several crops. The proposed model has a
lightweight structure with only 0.8 million trainable parameters, which makes
it suitable for IoT-based smart agriculture services. The performance of
PlantXViT is evaluated on five publicly available datasets. The proposed
PlantXViT network performs better than five state-of-the-art methods on all
five datasets. The average accuracy for recognising plant diseases is shown to
exceed 93.55%, 92.59%, and 98.33% on Apple, Maize, and Rice datasets,
respectively, even under challenging background conditions. The efficiency in
terms of explainability of the proposed model is evaluated using
gradient-weighted class activation maps and Local Interpretable Model Agnostic
Explanation.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 12:05:06 GMT""}]","2022-07-19"
"2207.07920","Taekyung Kim","Taekyung Kim, Hojin Lee, Wonsuk Lee","Physics Embedded Neural Network Vehicle Model and Applications in
  Risk-Aware Autonomous Driving Using Latent Features","2022 IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS). Our video can be found at https://youtu.be/rPN0hGCW0R4",,,,"cs.RO cs.AI","http://creativecommons.org/licenses/by/4.0/","  Non-holonomic vehicle motion has been studied extensively using physics-based
models. Common approaches when using these models interpret the wheel/ground
interactions using a linear tire model and thus may not fully capture the
nonlinear and complex dynamics under various environments. On the other hand,
neural network models have been widely employed in this domain, demonstrating
powerful function approximation capabilities. However, these black-box learning
strategies completely abandon the existing knowledge of well-known physics. In
this paper, we seamlessly combine deep learning with a fully differentiable
physics model to endow the neural network with available prior knowledge. The
proposed model shows better generalization performance than the vanilla neural
network model by a large margin. We also show that the latent features of our
model can accurately represent lateral tire forces without the need for any
additional training. Lastly, We develop a risk-aware model predictive
controller using proprioceptive information derived from the latent features.
We validate our idea in two autonomous driving tasks under unknown friction,
outperforming the baseline control framework.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 12:06:55 GMT""}]","2022-07-19"
"2207.07921","Karl Schrader","Karl Schrader, Tobias Alt, Joachim Weickert, Michael Ertel","CNN-based Euler's Elastica Inpainting with Deep Energy and Deep Image
  Prior","In Proceedings of the 10th European Workshop on Visual Information
  Processing, Lisbon, 2022",,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Euler's elastica constitute an appealing variational image inpainting model.
It minimises an energy that involves the total variation as well as the level
line curvature. These components are transparent and make it attractive for
shape completion tasks. However, its gradient flow is a singular, anisotropic,
and nonlinear PDE of fourth order, which is numerically challenging: It is
difficult to find efficient algorithms that offer sharp edges and good rotation
invariance. As a remedy, we design the first neural algorithm that simulates
inpainting with Euler's Elastica. We use the deep energy concept which employs
the variational energy as neural network loss. Furthermore, we pair it with a
deep image prior where the network architecture itself acts as a prior. This
yields better inpaintings by steering the optimisation trajectory closer to the
desired solution. Our results are qualitatively on par with state-of-the-art
algorithms on elastica-based shape completion. They combine good rotation
invariance with sharp edges. Moreover, we benefit from the high efficiency and
effortless parallelisation within a neural framework. Our neural elastica
approach only requires 3x3 central difference stencils. It is thus much simpler
than other well-performing algorithms for elastica inpainting. Last but not
least, it is unsupervised as it requires no ground truth training data.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 12:11:28 GMT""},{""version"":""v2"",""created"":""Tue, 14 Mar 2023 09:10:08 GMT""}]","2023-03-15"
"2207.07922","Yong Liu","Yong Liu, Ran Yu, Fei Yin, Xinyuan Zhao, Wei Zhao, Weihao Xia, Yujiu
  Yang","Learning Quality-aware Dynamic Memory for Video Object Segmentation","Accepted by ECCV2022",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, several spatial-temporal memory-based methods have verified that
storing intermediate frames and their masks as memory are helpful to segment
target objects in videos. However, they mainly focus on better matching between
the current frame and the memory frames without explicitly paying attention to
the quality of the memory. Therefore, frames with poor segmentation masks are
prone to be memorized, which leads to a segmentation mask error accumulation
problem and further affect the segmentation performance. In addition, the
linear increase of memory frames with the growth of frame number also limits
the ability of the models to handle long videos. To this end, we propose a
Quality-aware Dynamic Memory Network (QDMN) to evaluate the segmentation
quality of each frame, allowing the memory bank to selectively store accurately
segmented frames to prevent the error accumulation problem. Then, we combine
the segmentation quality with temporal consistency to dynamically update the
memory bank to improve the practicability of the models. Without any bells and
whistles, our QDMN achieves new state-of-the-art performance on both DAVIS and
YouTube-VOS benchmarks. Moreover, extensive experiments demonstrate that the
proposed Quality Assessment Module (QAM) can be applied to memory-based methods
as generic plugins and significantly improves performance. Our source code is
available at https://github.com/workforai/QDMN.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 12:18:04 GMT""}]","2022-07-19"
"2207.07923","Kevin A. Villegas Rosales","K. A. Villegas Rosales, P. T. Madathil, Y. J. Chung, L. N. Pfeiffer,
  K. W. West, K. W. Baldwin, M. Shayegan","Composite Fermion Mass",,"Phys. Rev. B 106 L041301, (2022)","10.1103/PhysRevB.106.L041301",,"cond-mat.mes-hall","http://creativecommons.org/publicdomain/zero/1.0/","  Composite fermions (CFs), exotic quasi-particles formed by pairing an
electron and an even number of magnetic flux quanta emerge at high magnetic
fields in an interacting electron system, and can explain phenomena such as the
fractional quantum Hall state (FQHS) and other many-body phases. CFs possess an
effective mass ($m_{CF}$) whose magnitude is inversely related to the most
fundamental property of a FQHS, namely its energy gap. We present here
experimental measurements of $m_{CF}$ in ultra-high quality two-dimensional
electron systems confined to GaAs quantum wells of varying thickness. An
advantage of measuring $m_{CF}$ over gap measurements is that mass values are
insensitive to disorder and are therefore ideal for comparison with theoretical
calculations, especially for high-order FQHS. Our data reveal that $m_{CF}$
increases with increasing well width, reflecting a decrease in the energy gap
as the electron layer becomes thicker and the in-plane Coulomb energy softens.
Comparing our measured masses with available theoretical results, we find
significant quantitative discrepancies, highlighting that more rigorous and
accurate calculations are needed to explain the experimental data.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 12:20:37 GMT""}]","2022-07-19"
"2207.07924","Tomoyuki Kubota","Tomoyuki Kubota, Yudai Suzuki, Shumpei Kobayashi, Quoc Hoan Tran,
  Naoki Yamamoto, and Kohei Nakajima","Quantum Noise-Induced Reservoir Computing",,,,,"quant-ph cs.LG physics.data-an","http://creativecommons.org/licenses/by/4.0/","  Quantum computing has been moving from a theoretical phase to practical one,
presenting daunting challenges in implementing physical qubits, which are
subjected to noises from the surrounding environment. These quantum noises are
ubiquitous in quantum devices and generate adverse effects in the quantum
computational model, leading to extensive research on their correction and
mitigation techniques. But do these quantum noises always provide
disadvantages? We tackle this issue by proposing a framework called quantum
noise-induced reservoir computing and show that some abstract quantum noise
models can induce useful information processing capabilities for temporal input
data. We demonstrate this ability in several typical benchmarks and investigate
the information processing capacity to clarify the framework's processing
mechanism and memory profile. We verified our perspective by implementing the
framework in a number of IBM quantum processors and obtained similar
characteristic memory profiles with model analyses. As a surprising result,
information processing capacity increased with quantum devices' higher noise
levels and error rates. Our study opens up a novel path for diverting useful
information from quantum computer noises into a more sophisticated information
processor.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 12:21:48 GMT""}]","2022-07-19"
"2207.07925","Gerardo Urrutia","Gerardo Urrutia, Fabio De Colle and Diego L\'opez-C\'amara","Three-dimensional numerical simulations of structured GRB jets","9 pages, 5 Figures; Added discussion; Accepted for publication in
  MNRAS",,"10.1093/mnras/stac3401",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  After the detection of GRB 170817A, the first unambiguous off-axis gamma-ray
burst (GRB), several studies tried to understand the structure of GRB jets. The
initial jet structure (directly produced by the central engine) can be
partially preserved, or can be completely modified by the interaction with the
environment. In this study, we perform three-dimensional, special relativistic
hydrodynamics simulations of long GRB jets evolving through a massive
progenitor star. Different jet scenarios were considered: Top-hat, Gaussian
jets dominated by pressure or by kinetic energy, as well as a model of a
supernova (SN) plus a jet both propagating through the progenitor. We found
that, while propagating inside the progenitor star, jets with different initial
structures are nearly indistinguishable. Kinetic dominated jets are faster and
more collimated than pressure dominated jets. The dynamics of jets inside the
progenitor star strongly depends on the presence of an associated SN, which can
substantially decelerate the jet propagation. We show that the initial
structure of GRB jets is preserved, or not, mainly depending on the jet
collimation. The initial structure is preserved in uncollimated jets, i.e. jets
which move through low density environments. Meanwhile, jets which move through
dense environments are shaped by the interaction with the medium and remain
collimated.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 12:27:19 GMT""},{""version"":""v2"",""created"":""Thu, 17 Nov 2022 16:59:02 GMT""}]","2022-12-07"
"2207.07926","Isao Watanabe","Muhammad Redo Ramadhan, Budi Adiperdana, Irwan Ramli, Dita Puspita
  Sari, Anita Eka Putri, Utami Wydiaiswari, Harion Rozak, Wan Nurfadhilah
  Zaharim, Azwar Manaf, Budhy Kurniawan Mohamed Ismail Mohamed-Ibrahim, Shukri
  Sulaiman, Takayuki Kawamata, Tadashi Adachi, Yoji Koike, Isao Watanabe","Estimation of the on-site Coulomb potential 1 and covalent state in
  La2CuO4 by muon spin rotation 2 and density functional theory calculations","11 pages, 10 figures see
  https://link.aps.org/doi/10.1103/PhysRevResearch.4.033044",,"10.1103/PhysRevResearch.4.033044",,"cond-mat.str-el","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The on-site Coulomb potential, U, and the covalent state of electronic
orbitals play key roles for the Cooper pair symmetry and exotic electromagnetic
properties of high-Tc superconducting cuprates. In this paper, we demonstrate a
way to determine the value of U and present the whole picture of the covalent
state of Cu spins in the mother system of the La-based high-Tc superconducting
cuprate, La2CuO4, by combining the muon spin rotation ({\mu}SR) and the density
functional theory (DFT) calculation. We reveal local deformations of the CuO6
octahedron followed by changes in Cu-spin distributions caused by the injected
muon. Adjusting the DFT and muSR results, U and the minimum charge-transfer
energy between the upper Hubbard band and the O 2p band were optimized to be
4.87(4) and 1.24(1) eV, respectively.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 12:29:07 GMT""}]","2022-07-19"
"2207.07927","Dominic Vella","Finn Box, Lucie Domino, Tiago Outerelo Corvo, Mokhtar Adda-Bedia,
  Vincent D\'emery, Dominic Vella and Benny Davidovitch","Delamination from an adhesive sphere: Curvature-induced dewetting versus
  buckling","File includes supplementary information appendix","Proc. Natl Acad. Sci. USA 120, e2212290120 (2023)","10.1073/pnas.2212290120",,"cond-mat.soft cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Everyday experience confirms the tendency of adhesive films to detach from
spheroidal regions of rigid substrates -- what is a petty frustration when
placing a sticky bandage onto an elbow or knee is a more serious matter in the
coating and painting industries. Irrespective of their resistance to bending, a
key driver of such phenomena is Gauss' \textit{Theorema Egregium}, which
implies that naturally flat sheets cannot conform to doubly-curved surfaces
without developing a strain whose magnitude grows sharply with the curved area.
Previous attempts to characterize the onset of curvature-induced delamination,
and the complex patterns it gives rise to, assumed a dewetting-like mechanism
in which the propensity of two materials to form contact through interfacial
energy is modified by an elastic energy penalty. We show that this approach may
characterize moderately bendable adhesive sheets, but fails qualitatively to
describe the curvature-induced delamination of ultrathin films, whose mechanics
is governed by their propensity to buckle under minute levels of compression.
Combining mechanical and geometrical considerations, we introduce a minimal
model for curvature-induced delamination that accounts for two elementary
buckling motifs, shallow ""rucks"" and localized ""folds"". We predict nontrivial
scaling rules for the onset of curvature-induced delamination and various
features of the emerging patterns, which compare well with experimental
observations. Beyond gaining control on the use of ultrathin adhesives in
cutting edge technologies such as stretchable electronics, our analysis is a
significant step towards quantifying the multiscale morphological complexity
that emerges upon imposing geometrical and mechanical constraints on highly
bendable solid objects.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 12:32:23 GMT""}]","2023-03-22"
"2207.07928","Uddalok Sen","Uddalok Sen, Detlef Lohse, and Maziyar Jalaal","Elastocapillary Worthington jets",,,,,"physics.flu-dyn cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The retraction of an impacting droplet on a non-wetting substrate is often
associated with the formation of a Worthington jet, which is fed by the
retracting liquid. A non-Newtonian rheology of the liquid is known to affect
the retraction of the impacting droplet. Here we present a novel phenomenon
related to the impact of viscoelastic droplets on non-wettable substrates. We
reveal that the viscoelasticity of the liquid results in an
\emph{elastocapillary} regime in the stretching Worthington jet, distinguished
by a pinned contact line and a slender jet that does not detach from the
droplet. We identify the impact conditions, in the Weber number -- Deborah
number phase space, for observing these \emph{elastocapillary} Worthington
jets. Such jets exhibit an effectively nearly linear (in time) variation of the
strain rate. Upon further extension, the jet exhibits beads-on-a-string
structures, characteristic of the \emph{elastocapillary} thinning of slender
viscoelastic liquid filaments. The \emph{elastocapillary} Worthington jet is
not only relevant for a droplet impact on a solid substrate scenario, but can
also be expected in other configurations where a Worthington jet is observed
for viscoelastic liquids, such as drop impact on a liquid pool and bubble
bursting at an interface.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 12:37:14 GMT""},{""version"":""v2"",""created"":""Tue, 17 Jan 2023 07:49:36 GMT""}]","2023-01-18"
"2207.07929","Yong Guo","Yong Guo, Jingdong Wang, Qi Chen, Jiezhang Cao, Zeshuai Deng, Yanwu
  Xu, Jian Chen, Mingkui Tan","Towards Lightweight Super-Resolution with Dual Regression Learning","Journal extension of DRN for lightweight super-resolution",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks have exhibited remarkable performance in image
super-resolution (SR) tasks by learning a mapping from low-resolution (LR)
images to high-resolution (HR) images. However, the SR problem is typically an
ill-posed problem and existing methods would come with several limitations.
First, the possible mapping space of SR can be extremely large since there may
exist many different HR images that can be downsampled to the same LR image. As
a result, it is hard to directly learn a promising SR mapping from such a large
space. Second, it is often inevitable to develop very large models with
extremely high computational cost to yield promising SR performance. In
practice, one can use model compression techniques to obtain compact models by
reducing model redundancy. Nevertheless, it is hard for existing model
compression methods to accurately identify the redundant components due to the
extremely large SR mapping space. To alleviate the first challenge, we propose
a dual regression learning scheme to reduce the space of possible SR mappings.
Specifically, in addition to the mapping from LR to HR images, we learn an
additional dual regression mapping to estimate the downsampling kernel and
reconstruct LR images. In this way, the dual mapping acts as a constraint to
reduce the space of possible mappings. To address the second challenge, we
propose a lightweight dual regression compression method to reduce model
redundancy in both layer-level and channel-level based on channel pruning.
Specifically, we first develop a channel number search method that minimizes
the dual regression loss to determine the redundancy of each layer. Given the
searched channel numbers, we further exploit the dual regression manner to
evaluate the importance of channels and prune the redundant ones. Extensive
experiments show the effectiveness of our method in obtaining accurate and
efficient SR models.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 12:46:10 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jul 2022 08:26:04 GMT""},{""version"":""v3"",""created"":""Wed, 27 Jul 2022 21:54:54 GMT""}]","2022-07-29"
"2207.07930","Yan-Liang Shi","Yan-Liang Shi, Roxana Zeraati, Anna Levina, Tatiana A. Engel","Spatial and temporal correlations in neural networks with structured
  connectivity","25 pages, 20 figures",,,,"q-bio.NC cond-mat.dis-nn cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  Correlated fluctuations in the activity of neural populations reflect the
network's dynamics and connectivity. The temporal and spatial dimensions of
neural correlations are interdependent. However, prior theoretical work mainly
analyzed correlations in either spatial or temporal domains, oblivious to their
interplay. We show that the network dynamics and connectivity jointly define
the spatiotemporal profile of neural correlations. We derive analytical
expressions for pairwise correlations in networks of binary units with
spatially arranged connectivity in one and two dimensions. We find that spatial
interactions among units generate multiple timescales in auto- and
cross-correlations. Each timescale is associated with fluctuations at a
particular spatial frequency, making a hierarchical contribution to the
correlations. External inputs can modulate the correlation timescales when
spatial interactions are nonlinear, and the modulation effect depends on the
operating regime of network dynamics. These theoretical results open new ways
to relate connectivity and dynamics in cortical networks via measurements of
spatiotemporal neural correlations.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 12:47:32 GMT""}]","2022-07-19"
"2207.07931","Yu-Shan Tai","Yu-Shan Tai, Cheng-Yang Chang, Chieh-Fang Teng, and AnYeu (Andy) Wu","Learnable Mixed-precision and Dimension Reduction Co-design for
  Low-storage Activation",,,,,"eess.IV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Recently, deep convolutional neural networks (CNNs) have achieved many
eye-catching results. However, deploying CNNs on resource-constrained edge
devices is constrained by limited memory bandwidth for transmitting large
intermediated data during inference, i.e., activation. Existing research
utilizes mixed-precision and dimension reduction to reduce computational
complexity but pays less attention to its application for activation
compression. To further exploit the redundancy in activation, we propose a
learnable mixed-precision and dimension reduction co-design system, which
separates channels into groups and allocates specific compression policies
according to their importance. In addition, the proposed dynamic searching
technique enlarges search space and finds out the optimal bit-width allocation
automatically. Our experimental results show that the proposed methods improve
3.54%/1.27% in accuracy and save 0.18/2.02 bits per value over existing
mixed-precision methods on ResNet18 and MobileNetv2, respectively.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 12:53:52 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jul 2022 02:36:17 GMT""}]","2022-07-20"
"2207.07932","Jiazhen Liu","Jiazhen Liu, Xirong Li, Qijie Wei, Jie Xu, Dayong Ding","Semi-Supervised Keypoint Detector and Descriptor for Retinal Image
  Matching","Accepted to ECCV 2022",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For retinal image matching (RIM), we propose SuperRetina, the first
end-to-end method with jointly trainable keypoint detector and descriptor.
SuperRetina is trained in a novel semi-supervised manner. A small set of
(nearly 100) images are incompletely labeled and used to supervise the network
to detect keypoints on the vascular tree. To attack the incompleteness of
manual labeling, we propose Progressive Keypoint Expansion to enrich the
keypoint labels at each training epoch. By utilizing a keypoint-based improved
triplet loss as its description loss, SuperRetina produces highly
discriminative descriptors at full input image size. Extensive experiments on
multiple real-world datasets justify the viability of SuperRetina. Even with
manual labeling replaced by auto labeling and thus making the training process
fully manual-annotation free, SuperRetina compares favorably against a number
of strong baselines for two RIM tasks, i.e. image registration and identity
verification. SuperRetina will be open source.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 12:55:20 GMT""}]","2022-07-19"
"2207.07933","Qian Ye","Qian Ye, Ling Jiang, Wang Zhen, Yuyang Du","Consistency of Implicit and Explicit Features Matters for Monocular 3D
  Object Detection","10 pages, 5 figures",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Low-cost autonomous agents including autonomous driving vehicles chiefly
adopt monocular 3D object detection to perceive surrounding environment. This
paper studies 3D intermediate representation methods which generate
intermediate 3D features for subsequent tasks. For example, the 3D features can
be taken as input for not only detection, but also end-to-end prediction and/or
planning that require a bird's-eye-view feature representation. In the study,
we found that in generating 3D representation previous methods do not maintain
the consistency between the objects' implicit poses in the latent space,
especially orientations, and the explicitly observed poses in the Euclidean
space, which can substantially hurt model performance. To tackle this problem,
we present a novel monocular detection method, the first one being aware of the
poses to purposefully guarantee that they are consistent between the implicit
and explicit features. Additionally, we introduce a local ray attention
mechanism to efficiently transform image features to voxels at accurate 3D
locations. Thirdly, we propose a handcrafted Gaussian positional encoding
function, which outperforms the sinusoidal encoding function while retaining
the benefit of being continuous. Results show that our method improves the
state-of-the-art 3D intermediate representation method by 3.15%. We are ranked
1st among all the reported monocular methods on both 3D and BEV detection
benchmark on KITTI leaderboard as of th result's submission time.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 13:00:32 GMT""},{""version"":""v2"",""created"":""Sun, 27 Nov 2022 09:14:10 GMT""}]","2022-11-29"
"2207.07934","Xiaolin Chen","Xiaolin Chen, Xuemeng Song, Liqiang Jing, Shuo Li, Linmei Hu, and
  Liqiang Nie","Multimodal Dialog Systems with Dual Knowledge-enhanced Generative
  Pretrained Language Model",,,,,"cs.CL cs.HC cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Text response generation for multimodal task-oriented dialog systems, which
aims to generate the proper text response given the multimodal context, is an
essential yet challenging task. Although existing efforts have achieved
compelling success, they still suffer from two pivotal limitations: 1) overlook
the benefit of generative pre-training, and 2) ignore the textual context
related knowledge. To address these limitations, we propose a novel dual
knowledge-enhanced generative pretrained language model for multimodal
task-oriented dialog systems (DKMD), consisting of three key components: dual
knowledge selection, dual knowledge-enhanced context learning, and
knowledge-enhanced response generation. To be specific, the dual knowledge
selection component aims to select the related knowledge according to both
textual and visual modalities of the given context. Thereafter, the dual
knowledge-enhanced context learning component targets seamlessly integrating
the selected knowledge into the multimodal context learning from both global
and local perspectives, where the cross-modal semantic relation is also
explored. Moreover, the knowledge-enhanced response generation component
comprises a revised BART decoder, where an additional dot-product
knowledge-decoder attention sub-layer is introduced for explicitly utilizing
the knowledge to advance the text response generation. Extensive experiments on
a public dataset verify the superiority of the proposed DKMD over
state-of-the-art competitors.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 13:02:54 GMT""}]","2022-07-19"
"2207.07935","Amir Shirian","Amir Shirian, Krishna Somandepalli, Victor Sanchez, Tanaya Guha","Visually-aware Acoustic Event Detection using Heterogeneous Graphs",,,,,"cs.SD cs.LG cs.MM eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Perception of auditory events is inherently multimodal relying on both audio
and visual cues. A large number of existing multimodal approaches process each
modality using modality-specific models and then fuse the embeddings to encode
the joint information. In contrast, we employ heterogeneous graphs to
explicitly capture the spatial and temporal relationships between the
modalities and represent detailed information about the underlying signal.
Using heterogeneous graph approaches to address the task of visually-aware
acoustic event classification, which serves as a compact, efficient and
scalable way to represent data in the form of graphs. Through heterogeneous
graphs, we show efficiently modelling of intra- and inter-modality
relationships both at spatial and temporal scales. Our model can easily be
adapted to different scales of events through relevant hyperparameters.
Experiments on AudioSet, a large benchmark, shows that our model achieves
state-of-the-art performance.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 13:09:25 GMT""}]","2022-07-19"
"2207.07936","O. I. Morozov","I.S. Krasil'shchik, O.I. Morozov","Lagrangian extensions of multi-dimensional integrable equations. I. The
  five-dimensional Mart{\'{\i}}nez Alonso--Shabat equation",,,,,"nlin.SI","http://creativecommons.org/licenses/by/4.0/","  We study a Lagrangian extension of the 5d Mart\'inez Alonso--Shabat equation
$\mathcal{E}$ \begin{equation*} u_{yz}=u_{tx}+u_y\,u_{xs}-u_x\,u_{ys}
\end{equation*} that coincides with the cotangent equation $\mathcal{T^*E}$ to
the latter. We describe the Lie algebra structure of its symmetries (which
happens to be quite nontrivial and is described in terms of deformations) and
construct two families of recursion operators for symmetries. Each family
depends on two parameters. We prove that all the operators from the first
family are hereditary, but not compatible in the sense of the Nijenhuis
bracket. We also construct two new parametric Lax pairs that depend on
higher-order derivatives of the unknown functions.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 13:10:17 GMT""}]","2022-07-19"
"2207.07937","Lynnette Hui Xian Ng","Adya Danaditya, Lynnette Hui Xian Ng, Kathleen M. Carley","From Curious Hashtags to Polarized Effect: Profiling Coordinated Actions
  in Indonesian Twitter Discourse","To appear in Social Network Analysis and Mining",,,,"cs.SI cs.CY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Coordinated campaigns in the digital realm have become an increasingly
important area of study due to their potential to cause political polarization
and threats to security through real-world protests and riots. In this paper,
we introduce a methodology to profile two case studies of coordinated actions
in Indonesian Twitter discourse. Combining network and narrative analysis
techniques, this six-step pipeline begins with DISCOVERY of coordinated actions
through hashtag-hijacking; identifying WHO are involved through the extraction
of discovered agents; framing of what these actors did (DID WHAT) in terms of
information manipulation maneuvers; TO WHOM these actions were targeted through
correlation analysis; understanding WHY through narrative analysis and
description of IMPACT through analysis of the observed conversation
polarization. We describe two case studies, one international and one regional,
in the Indonesian Twittersphere. Through these case studies, we unearth two
seemingly related coordinated activities, discovered by deviating hashtags that
do not fit the discourse, characterize the coordinated group profile and
interaction, and describe the impact of their activity on the online
conversation.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 13:17:30 GMT""}]","2022-07-19"
"2207.07938","Sophie Grivaux","Sophie Grivaux, Etienne Matheron, Quentin Menet","Generic properties of l_p-contractions and similar operator topologies","39 p",,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  If $X$ is a separable reflexive Banach space, there are several natural
Polish topologies on $\mathcal{B}(X)$, the set of contraction operators on $X$
(none of which being clearly ``more natural'' than the others), and hence
several a priori different notions of genericity -- in the Baire category sense
-- for properties of contraction operators. So it makes sense to investigate to
which extent the generic properties, i.e. the comeager sets, really depend on
the chosen topology on $\mathcal{B}(X)$. In this paper, we focus on
$\ell_p\,$-$\,$spaces, $1<p\neq 2<\infty$. We show that for some pairs of
natural Polish topologies on $\mathcal B_1(\ell_p)$, the comeager sets are in
fact the same; and our main result asserts that for $p=3$ or $3/2$ and in the
real case, all topologies on $\mathcal B_1(\ell_p)$ lying between the Weak
Operator Topology and the Strong$^*$ Operator Topology share the same comeager
sets. Our study relies on the consideration of continuity points of the
identity map for two different topologies on $\mathcal{B}_1 (\ell_p)$. The
other essential ingredient in the proof of our main result is a careful
examination of norming vectors for finite-dimensional contractions of a special
type.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 13:19:11 GMT""},{""version"":""v2"",""created"":""Wed, 26 Oct 2022 20:12:10 GMT""}]","2022-10-28"
"2207.07939","Niels Benedikter","Niels Benedikter and Davide Desio","Two Comments on the Derivation of the Time-Dependent Hartree-Fock
  Equation","12 pages, contribution to the Proceedings of the Intensive Period
  ""INdAM Quantum Meetings (IQM22)"" at Politecnico di Milano, March - May 2022",,,,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We revisit the derivation of the time-dependent Hartree-Fock equation for
interacting fermions in a regime coupling a mean-field and a semiclassical
scaling, contributing two comments to the result obtained in 2014 by
Benedikter, Porta, and Schlein. First, the derivation holds in arbitrary space
dimension. Second, by using an explicit formula for the unitary implementation
of particle-hole transformations, we cast the proof in a form similar to the
coherent state method of Rodnianski and Schlein for bosons.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 13:28:58 GMT""}]","2022-07-19"
"2207.07940","Junlin He","Wei Wu, Junlin He, Yu Qiao, Guoheng Fu, Li Liu and Jin Yu","HQANN: Efficient and Robust Similarity Search for Hybrid Queries with
  Structured and Unstructured Constraints",,,,,"cs.DB cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The in-memory approximate nearest neighbor search (ANNS) algorithms have
achieved great success for fast high-recall query processing, but are extremely
inefficient when handling hybrid queries with unstructured (i.e., feature
vectors) and structured (i.e., related attributes) constraints. In this paper,
we present HQANN, a simple yet highly efficient hybrid query processing
framework which can be easily embedded into existing proximity graph-based ANNS
algorithms. We guarantee both low latency and high recall by leveraging
navigation sense among attributes and fusing vector similarity search with
attribute filtering. Experimental results on both public and in-house datasets
demonstrate that HQANN is 10x faster than the state-of-the-art hybrid ANNS
solutions to reach the same recall quality and its performance is hardly
affected by the complexity of attributes. It can reach 99\% recall@10 in just
around 50 microseconds On GLOVE-1.2M with thousands of attribute constraints.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 13:29:26 GMT""}]","2022-07-19"
"2207.07941","Ali Ramezani-Kebrya","Ali Ramezani-Kebrya and Iman Tabrizian and Fartash Faghri and Petar
  Popovski","MixTailor: Mixed Gradient Aggregation for Robust Learning Against
  Tailored Attacks","To appear at the Transactions on Machine Learning Research (TMLR)",,,,"cs.LG cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Implementations of SGD on distributed systems create new vulnerabilities,
which can be identified and misused by one or more adversarial agents.
Recently, it has been shown that well-known Byzantine-resilient gradient
aggregation schemes are indeed vulnerable to informed attackers that can tailor
the attacks (Fang et al., 2020; Xie et al., 2020b). We introduce MixTailor, a
scheme based on randomization of the aggregation strategies that makes it
impossible for the attacker to be fully informed. Deterministic schemes can be
integrated into MixTailor on the fly without introducing any additional
hyperparameters. Randomization decreases the capability of a powerful adversary
to tailor its attacks, while the resulting randomized aggregation scheme is
still competitive in terms of performance. For both iid and non-iid settings,
we establish almost sure convergence guarantees that are both stronger and more
general than those available in the literature. Our empirical studies across
various datasets, attacks, and settings, validate our hypothesis and show that
MixTailor successfully defends when well-known Byzantine-tolerant schemes fail.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 13:30:37 GMT""},{""version"":""v2"",""created"":""Fri, 23 Sep 2022 12:09:52 GMT""}]","2022-09-26"
"2207.07942","Haoke Xu","HaoKe Xu, Mingqiang Gu, Fucong Fei, YiSheng Gu, Dang Liu, QiaoYan Yu,
  ShaSha Xue, XuHui Ning, Bo Chen, Hangkai Xie, Zhen Zhu, Dandan Guan, Shiyong
  Wang, Yaoyi Li, Canhua Liu, Qihang Liu, Fengqi Song, Hao Zheng, Jinfeng Jia","Observation of magnetism induced topological edge state in
  antiferromagnetic topological insulator MnBi4Te7",,,"10.1021/acsnano.2c03622",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Breaking time reversal symmetry in a topological insulator may lead to
quantum anomalous Hall effect and axion insulator phase. MnBi4Te7 is a recently
discovered antiferromagnetic topological insulator with TN ~12.5 K, which is
constituted of alternatively stacked magnetic layer (MnBi2Te4) and non-magnetic
layer (Bi2Te3). By means of scanning tunneling spectroscopy, we clearly observe
the electronic state present at a step edge of a magnetic MnBi2Te4 layer but
absent at non-magnetic Bi2Te3 layers at 4.5 K. Furthermore, we find that as the
temperature rises above TN, the edge state vanishes, while the point defect
induced state persists upon temperature increasing. These results confirm the
observation of magnetism induced edge states. Our analysis based on an axion
insulator theory reveals that the nontrivial topological nature of the observed
edge state.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 13:32:11 GMT""}]","2022-07-19"
"2207.07943","Johannes Bl\""umlein","J. Bl\""umlein, P. Marquard, C. Schneider, and K. Sch\""onwald","The 3-loop anomalous dimensions from off-shell operator matrix elements","12 pages Latex, Contributeion to the Proceedings of LL2022","PoS (LL2022) 048",,"DESY 19--061, DO-TH 20/09, TTP22--048, RISC Report Series 22--09,
  SAGEX 20--20","hep-ph hep-ex hep-th","http://creativecommons.org/licenses/by/4.0/","  We report on the calculation of the three-loop polarized and unpolarized
flavor non-singlet and the polarized singlet anomalous dimensions using
massless off-shell operator matrix elements in a gauge-variant framework. We
also reconsider the unpolarized two-loop singlet anomalous dimensions and
correct errors in the foregoing literature.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 13:33:20 GMT""}]","2022-07-19"
"2207.07944","Taehyeong Kim","Taehyeong Kim and Jaemin Park","On a lower bound of Hausdorff dimension of weighted singular vectors","28 pages",,,,"math.NT math.DS","http://creativecommons.org/licenses/by/4.0/","  Let $w=(w_1,\dots,w_d)$ be an ordered $d$-tuple of positive real numbers such
that $\sum_{i}w_i =1$ and $w_1\geq \cdots \geq w_d$. A $d$-dimensional vector
$x=(x_1,\dots,x_d)\in\mathbb{R}^d$ is said to be $w$-singular if for every
$\epsilon>0$ there exists $T_0>1$ such that for all $T>T_0$ the system of
inequalities \[ \max_{1\leq i\leq d}|qx_i - p_i|^{\frac{1}{w_i}} <
\frac{\epsilon}{T} \quad\text{and}\quad 0<q<T \] have an integer solution
$(\mathbf{p},q)=(p_1,\dots,p_d,q)\in \mathbb{Z}^d \times \mathbb{Z}$. In this
paper, we prove that Hausdorff dimension of the set of $w$-singular vectors in
$\mathbb{R}^d$ is bounded below by $d-\frac{1}{1+w_1}$. This result extends
partially the previous result of Liao et al. [Hausdorff dimension of weighted
singular vectors in $\mathbb{R}^2$, J. Eur. Math. Soc. \textbf{22} (2020),
833-875].
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 13:35:30 GMT""}]","2022-07-19"
"2207.07945","Hanbyel Cho","Hanbyel Cho, Yekang Lee, Jaemyung Yu, Junmo Kim","Stochastic Attribute Modeling for Face Super-Resolution",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  When a high-resolution (HR) image is degraded into a low-resolution (LR)
image, the image loses some of the existing information. Consequently, multiple
HR images can correspond to the LR image. Most of the existing methods do not
consider the uncertainty caused by the stochastic attribute, which can only be
probabilistically inferred. Therefore, the predicted HR images are often blurry
because the network tries to reflect all possibilities in a single output
image. To overcome this limitation, this paper proposes a novel face
super-resolution (SR) scheme to take into the uncertainty by stochastic
modeling. Specifically, the information in LR images is separately encoded into
deterministic and stochastic attributes. Furthermore, an Input Conditional
Attribute Predictor is proposed and separately trained to predict the partially
alive stochastic attributes from only the LR images. Extensive evaluation shows
that the proposed method successfully reduces the uncertainty in the learning
process and outperforms the existing state-of-the-art approaches.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 13:38:05 GMT""}]","2022-07-19"
"2207.07946","Taihei Oki","Taihei Oki, Tasuku Soma","Algebraic Algorithms for Fractional Linear Matroid Parity via
  Non-commutative Rank",,,,,"math.OC cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Matrix representations are a powerful tool for designing efficient algorithms
for combinatorial optimization problems such as matching, and linear matroid
intersection and parity. In this paper, we initiate the study of matrix
representations using the concept of non-commutative rank (nc-rank), which has
recently attracted attention in the research of Edmonds' problem. We reveal
that the nc-rank of the matrix representation of linear matroid parity
corresponds to the optimal value of fractional linear matroid parity: a
half-integral relaxation of linear matroid parity. Based on our representation,
we present an algebraic algorithm for the fractional linear matroid parity
problem by building a new technique to incorporate the search-to-decision
reduction into the half-integral problem represented via the nc-rank. We
further present a faster divide-and-conquer algorithm for finding a maximum
fractional matroid matching and an algebraic algorithm for finding a dual
optimal solution. They together lead to an algebraic algorithm for the weighted
fractional linear matroid parity problem. Our algorithms are significantly
simpler and faster than the existing algorithms.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 13:40:01 GMT""}]","2022-07-19"
"2207.07947","Dietmar Ferger","Dietmar Ferger","Exact and asymptotic goodness-of-fit tests based on the maximum and its
  location of the empirical process",,,,,"math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  The supremum of the standardized empirical process is a promising statistic
for testing whether the distribution function $F$ of i.i.d. real random
variables is either equal to a given distribution function $F_0$ (hypothesis)
or $F \ge F_0$ (one-sided alternative). Since \cite{r5} it is well-known that
an affine-linear transformation of the suprema converge in distribution to the
Gumbel law as the sample size tends to infinity. This enables the construction
of an asymptotic level-$\alpha$ test. However, the rate of convergence is
extremely slow. As a consequence the probability of the type I error is much
larger than $\alpha$ even for sample sizes beyond $10.000$. Now, the
standardization consists of the weight-function $1/\sqrt{F_0(x)(1-F_0(x))}$.
Substituting the weight-function by a suitable random constant leads to a new
test-statistic, for which we can derive the exact distribution (and the limit
distribution) under the hypothesis. A comparison via a Monte-Carlo simulation
shows that the new test is uniformly better than the Smirnov-test and an
appropriately modified test due to \cite{r20}. Our methodology also works for
the two-sided alternative $F \neq F_0$.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 13:40:43 GMT""}]","2022-07-19"
"2207.07948","Sudeep Salgia","Sudeep Salgia, Sattar Vakili, Qing Zhao","Collaborative Learning in Kernel-based Bandits for Distributed Users",,,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  We study collaborative learning among distributed clients facilitated by a
central server. Each client is interested in maximizing a personalized
objective function that is a weighted sum of its local objective and a global
objective. Each client has direct access to random bandit feedback on its local
objective, but only has a partial view of the global objective and relies on
information exchange with other clients for collaborative learning. We adopt
the kernel-based bandit framework where the objective functions belong to a
reproducing kernel Hilbert space. We propose an algorithm based on surrogate
Gaussian process (GP) models and establish its order-optimal regret performance
(up to polylogarithmic factors). We also show that the sparse approximations of
the GP models can be employed to reduce the communication overhead across
clients.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 13:41:42 GMT""},{""version"":""v2"",""created"":""Mon, 17 Apr 2023 15:45:37 GMT""}]","2023-04-18"
"2207.07949","Jakub Tetek","Christoph Grunau, Ahmet Alper \""Oz\""udo\u{g}ru, V\'aclav Rozho\v{n},
  Jakub T\v{e}tek","A Nearly Tight Analysis of Greedy k-means++",,,,,"cs.DS cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The famous $k$-means++ algorithm of Arthur and Vassilvitskii [SODA 2007] is
the most popular way of solving the $k$-means problem in practice. The
algorithm is very simple: it samples the first center uniformly at random and
each of the following $k-1$ centers is then always sampled proportional to its
squared distance to the closest center so far. Afterward, Lloyd's iterative
algorithm is run. The $k$-means++ algorithm is known to return a $\Theta(\log
k)$ approximate solution in expectation.
  In their seminal work, Arthur and Vassilvitskii [SODA 2007] asked about the
guarantees for its following \emph{greedy} variant: in every step, we sample
$\ell$ candidate centers instead of one and then pick the one that minimizes
the new cost. This is also how $k$-means++ is implemented in e.g. the popular
Scikit-learn library [Pedregosa et al.; JMLR 2011].
  We present nearly matching lower and upper bounds for the greedy $k$-means++:
We prove that it is an $O(\ell^3 \log^3 k)$-approximation algorithm. On the
other hand, we prove a lower bound of $\Omega(\ell^3 \log^3 k / \log^2(\ell\log
k))$. Previously, only an $\Omega(\ell \log k)$ lower bound was known
[Bhattacharya, Eube, R\""oglin, Schmidt; ESA 2020] and there was no known upper
bound.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 13:49:07 GMT""}]","2022-07-19"
"2207.07950","Oliver Attie","Oliver Attie and Sylvain Cappell","Surgery On Foliations",,,,,"math.OA math.AT math.DG math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we set up two surgery theories and two kinds of Whitehead
torsion for foliations. First, we construct a bounded surgery theory and
bounded Whitehead torsion for foliations, which correspond to the Connes'
foliation algebra in the K-theory of operator algebras, in the sense that there
is an analogy between surgery theory and index theory, and a Novikov Conjecture
for bounded surgery on foliations in analogy with the foliated Novikov
conjecture of P.Baum and A.Connes in operator theory. This surgery theory
classifies the leaves topologically. Secondly, we construct a bounded geometry
surgery for foliations, which is a generalization of blocked surgery, and a
bounded geometry Whitehead torsion. The classifications in this surgery theory
include the specification of the Riemannian metrics of the leaves up to
quasi=isometry. We state Borel conjectures for foliations, which solves a
problem posed by S.Weinberger \cite{Wein}, and verify these in some cases of
geometrical interest.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 13:49:37 GMT""}]","2022-07-19"
"2207.07951","Minghan Chu","Minghan Chu, Xiaohua Wu, David E. Rival","Quantification of Reynolds-averaged-Navier-Stokes model form uncertainty
  in transitional boundary layer and airfoil flows",,,"10.1063/5.0107547",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is well known that Boussinesq turbulent-viscosity hypothesis can introduce
uncertainty in predictions for complex flow features such as separation,
reattachment, and laminar-turbulent transition. This study adopts a recent
physics-based uncertainty quantification (UQ) approach to address such model
form uncertainty in Reynolds-averaged Naiver- Stokes (RANS) simulations. Thus
far, almost all UQ studies have focused on quantifying the model form
uncertainty in turbulent flow scenarios. The focus of the study is to advance
our understanding of the performance of the UQ approach on two different
transitional flow scenarios: a flat plate and a SD7003 airfoil, to close this
gap. For the T3A (flat-plate flow) flow, most of the model form uncertainty is
concentrated in the laminar-turbulent transition region. For the SD7003 airfoil
flow, the eigenvalue perturbations reveal a decrease as well as an increase in
the length of the separation bubble. As a consequence, the uncertainty bounds
successfully encompass the reattachment point. Likewise, the region of reverse
flow that appear in the separation bubble is either suppressed or bolstered by
the eigenvalue perturbations. In this context, the UQ methodology is applied to
transition and show great results. This is the first successful RANS UQ study
for transitional flows.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 13:53:29 GMT""}]","2022-10-19"
"2207.07952","Aleks Jevnikar","Daniele Bartolucci, Yeyao Hu, Aleks Jevnikar, Wen Yang","Generic properties of the Rabinowitz continuum","14 pages. arXiv admin note: substantial text overlap with
  arXiv:2106.04331","Adv. Nonlinear Stud. 23(1) (2023), 20220062","10.1515/ans-2022-0062",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we prove that generically, in the sense of domain variations,
the unbounded Rabinowitz continuum of solutions to a nonlinear eigenvalue
problem is a simple analytic curve. The global bifurcation diagram resembles
the classic model case of the Gel'fand problem in dimension two.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 14:05:55 GMT""}]","2023-06-09"
"2207.07953","Matthieu Zins","Matthieu Zins, Gilles Simon, Marie-Odile Berger","Level Set-Based Camera Pose Estimation From Multiple 2D/3D
  Ellipse-Ellipsoid Correspondences","published at IROS 2022",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose an object-based camera pose estimation from a
single RGB image and a pre-built map of objects, represented with ellipsoidal
models. We show that contrary to point correspondences, the definition of a
cost function characterizing the projection of a 3D object onto a 2D object
detection is not straightforward. We develop an ellipse-ellipse cost based on
level sets sampling, demonstrate its nice properties for handling partially
visible objects and compare its performance with other common metrics. Finally,
we show that the use of a predictive uncertainty on the detected ellipses
allows a fair weighting of the contribution of the correspondences which
improves the computed pose. The code is released at
https://gitlab.inria.fr/tangram/level-set-based-camera-pose-estimation.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 14:09:54 GMT""},{""version"":""v2"",""created"":""Fri, 19 Aug 2022 13:51:59 GMT""}]","2022-08-22"
"2207.07954","Marc Herrmann","Marc Herrmann, Martin Obaidi, Larissa Chazette, Jil Kl\""under","On the Subjectivity of Emotions in Software Projects: How Reliable are
  Pre-Labeled Data Sets for Sentiment Analysis?","Accepted for publication in the Elsevier Journal of Systems and
  Software: Special Issue on Human-Centric Software Engineering - Approaches,
  Technologies, and Applications",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Social aspects of software projects become increasingly important for
research and practice. Different approaches analyze the sentiment of a
development team, ranging from simply asking the team to so-called sentiment
analysis on text-based communication. These sentiment analysis tools are
trained using pre-labeled data sets from different sources, including GitHub
and Stack Overflow. In this paper, we investigate if the labels of the
statements in the data sets coincide with the perception of potential members
of a software project team. Based on an international survey, we compare the
median perception of 94 participants with the pre-labeled data sets as well as
every single participant's agreement with the predefined labels. Our results
point to three remarkable findings: (1) Although the median values coincide
with the predefined labels of the data sets in 62.5% of the cases, we observe a
huge difference between the single participant's ratings and the labels; (2)
there is not a single participant who totally agrees with the predefined
labels; and (3) the data set whose labels are based on guidelines performs
better than the ad hoc labeled data set.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 14:10:29 GMT""}]","2022-07-19"
"2207.07955","Sakshi Chhabra","Sakshi Chhabra and Ashutosh Kumar Singh","A Comprehensive Vision on Cloud Computing Environment: Emerging
  Challenges and Future Research Directions",,,,,"cs.DC","http://creativecommons.org/licenses/by/4.0/","  Cloud computing has become the backbone of the computing industry and offers
subscription-based on-demand services. Through virtualization, which produces a
virtual instance of a computer system running in an abstracted hardware layer,
it has made it possible for us to share resources among many users. Contrary to
early distributed computing models, it guarantees limitless computing resources
through its expansive cloud datacenters, and it has been immensely popular in
recent years because to its constantly expanding infrastructure, user base, and
hosted data volume. These datacenters enormous and sophisticated workloads
present a number of problems, including issues with resource use, power
consumption, scalability, operational expense, security and many more. In this
context, the article provides a comprehensive overview of the most prevalent
problems with sharing and communication in organizations of all sizes. There is
discussion of a taxonomy of security, load balancing, and the main difficulties
encountered in protecting sensitive data. A complete examination of current
state-of-the-art contributions, resource management analysis methodologies,
load balancing solutions, empowering heuristics, and multi-objective
learning-based approaches are required. In its final section, the paper
examines, reviews, and suggests future research directions in the area of
secure VM placements.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 14:10:46 GMT""}]","2022-07-19"
"2207.07956","Shunhao Oh","Hridesh Kedia, Shunhao Oh and Dana Randall","Local Stochastic Algorithms for Alignment in Self-Organizing Particle
  Systems","long version of paper published in RANDOM 2022",,,,"cs.DC cs.ET math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present local distributed, stochastic algorithms for \emph{alignment} in
self-organizing particle systems (SOPS) on two-dimensional lattices, where
particles occupy unique sites on the lattice, and particles can make spatial
moves to neighboring sites if they are unoccupied. Such models are abstractions
of programmable matter, composed of individual computational particles with
limited memory, strictly local communication abilities, and modest
computational capabilities. We consider oriented particle systems, where
particles are assigned a vector pointing in one of $q$ directions, and each
particle can compute the angle between its direction and the direction of any
neighboring particle, although without knowledge of global orientation with
respect to a fixed underlying coordinate system. Particles move stochastically,
with each particle able to either modify its direction or make a local spatial
move along a lattice edge during a move. We consider two settings: (a) where
particle configurations must remain simply connected at all times and (b) where
spatial moves are unconstrained and configurations can disconnect.
  Taking inspiration from the Potts and clock models from statistical physics,
we prove that for any $q \geq 2,$ these self-organizing particle systems can be
made to collectively align along a single dominant direction (analogous to a
solid or ordered state) or remain non-aligned, in which case the fraction of
particles oriented along any direction is nearly equal (analogous to a gaseous
or disordered state). Moreover, we show that with appropriate settings of the
input parameters, we can achieve \emph{compression} and \emph{expansion},
controlling how tightly gathered the particles are, as well as \emph{alignment}
or \emph{nonalignment}, producing a single dominant orientation or not.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 14:12:43 GMT""},{""version"":""v2"",""created"":""Wed, 14 Sep 2022 10:41:19 GMT""}]","2022-09-15"
"2207.07957","Bakir Farhi","Abdelmalek Bedhouche and Bakir Farhi","On some products taken over the prime numbers","23 pages",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  This paper is devoted to study some expressions of the type $\prod_{p}
p^{\lfloor\frac{x}{f(p)}\rfloor}$, where $x$ is a nonnegative real number, $f$
is an arithmetic function satisfying some conditions, and the product is over
the primes $p$. We begin by proving that such expressions can be expressed by
using the $\mathrm{lcm}$ function, without any reference to prime numbers; we
illustrate this result with several examples. The rest of the paper is devoted
to study the two particular cases related to $f(m) = m$ and $f(m) = m - 1$. In
both cases, we found arithmetic properties and analytic estimates for the
underlying expressions. We also put forward an important conjecture for the
case $f(m) = m - 1$, which depends on the counting of the prime numbers of a
special form.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 14:27:35 GMT""}]","2022-07-19"
"2207.07958","Javier Duarte","Javier Duarte and Nhan Tran and Ben Hawks and Christian Herwig and
  Jules Muhizi and Shvetank Prakash and Vijay Janapa Reddi","FastML Science Benchmarks: Accelerating Real-Time Scientific Edge
  Machine Learning","9 pages, 4 figures, Contribution to 3rd Workshop on Benchmarking
  Machine Learning Workloads on Emerging Hardware (MLBench) at 5th Conference
  on Machine Learning and Systems (MLSys)",,,"FERMILAB-CONF-22-534-PPD-SCD","cs.LG physics.comp-ph physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  Applications of machine learning (ML) are growing by the day for many unique
and challenging scientific applications. However, a crucial challenge facing
these applications is their need for ultra low-latency and on-detector ML
capabilities. Given the slowdown in Moore's law and Dennard scaling, coupled
with the rapid advances in scientific instrumentation that is resulting in
growing data rates, there is a need for ultra-fast ML at the extreme edge. Fast
ML at the edge is essential for reducing and filtering scientific data in
real-time to accelerate science experimentation and enable more profound
insights. To accelerate real-time scientific edge ML hardware and software
solutions, we need well-constrained benchmark tasks with enough specifications
to be generically applicable and accessible. These benchmarks can guide the
design of future edge ML hardware for scientific applications capable of
meeting the nanosecond and microsecond level latency requirements. To this end,
we present an initial set of scientific ML benchmarks, covering a variety of ML
and embedded system techniques.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 14:30:15 GMT""}]","2022-07-19"
"2207.07959","Genni Fragnelli","Alessandro Camasta, Genni Fragnelli","Fourth order differential operators with interior degeneracy and
  generalized Wentzell boundary conditions",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we consider the fourth order operators A1u := (au"")"" and A2u :=
au"""" in divergence form and non divergence form, respectively, where a, defined
in [0, 1] with values in R+, degenerates in an interior point of the interval.
Using the semigroup technique, under suitable assumptions on a, we study the
generation property of these operators associated to generalized Wentzell
boundary conditions, proving the well posedness of the corresponding parabolic
problems.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 14:35:26 GMT""},{""version"":""v2"",""created"":""Mon, 12 Dec 2022 18:39:48 GMT""},{""version"":""v3"",""created"":""Fri, 23 Dec 2022 18:06:26 GMT""}]","2022-12-26"
"2207.07960","Hongping Deng","Hongping Deng, Gordon I. Ogilvie","Standing solitary waves as transitions to spiral structures in
  gravitationally unstable accretion disks","6 pages, 4 figures, ApJL accepted",,"10.3847/2041-8213/ac81c0",,"astro-ph.EP astro-ph.GA nlin.PS","http://creativecommons.org/licenses/by/4.0/","  Astrophysical disks that are sufficiently cold and dense are linearly
unstable to the formation of axisymmetric rings as a result of the disk's
gravity. In practice, spiral structures are formed, which may in turn produce
bound fragments. We study a nonlinear dynamical path that can explain the
development of spirals in a local model of a gaseous disk on the subcritical
side of the gravitational instability bifurcation. Axisymmetric equilibria can
be radially periodic or localized, in the form of standing solitary waves. The
solitary solutions have an energy slightly larger than a smooth disk. They are
further unstable to non-axisymmetric perturbations with a wide range of
azimuthal wavenumbers. The solitary waves may act as a pathway to spirals and
fragmentation.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 14:46:44 GMT""}]","2022-08-17"
"2207.07961","Peize Liu","Peize Liu","Deformation Quantisation via Kontsevich Formality Theorem","Master's dissertation",,,,"math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  This dissertation is an exposition of Kontsevich's proof of the formality
theorem and the classification of deformation quantisation on a Poisson
manifold. We begin with an account of the physical background and introduce the
Weyl-Moyal product as the first example. Then we develop the deformation theory
via differential graded Lie algebras and $\mathrm{L}_\infty$-algebras, which
allows us to reformulate the classification of deformation quantisation as the
existence of a $\mathrm{L}_\infty$-quasi-isomorphism between two differential
graded Lie algebras, known as the formality theorem. Next we present
Kontsevich's proof of the formality theorem in $\mathbb{R}^d$ and his
construction of the star product. We conclude with a brief discussion of the
globalisation of Kontsevich star product on Poisson manifolds.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 14:51:30 GMT""}]","2022-07-19"
"2207.07962","Xingjiang Zhou","Hongtao Yan, Qiang Gao, Chunyao Song, Chaohui Yin, Yiwen Chen,
  Fengfeng Zhang, Feng Yang, Shenjin Zhang, Qinjun Peng, Guodong Liu, Lin Zhao,
  Zuyan Xu and Xingjiang Zhou","Conservation of the particle-hole symmetry in the pseudogap state in
  optimally-doped Bi2Sr2CuO6+{\delta} superconductor",,"Chinese Physics B 31, 087401 (2022)","10.1088/1674-1056/ac7214",,"cond-mat.supr-con cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The pseudogap state is one of the most enigmatic characteristics in the
anomalous normal state properties of the high temperature cuprate
superconductors. A central issue is to reveal whether there is a symmetry
breaking and which symmetries are broken across the pseudogap transition. By
performing high resolution laser-based angle-resolved photoemission
measurements on the optimally-doped Bi2Sr1.6La0.4CuO6+{\delta} superconductor,
we report the observations of the particle-hole symmetry conservation in both
the superconducting state and the pseudogap state along the entire Fermi
surface. These results provide key insights in understanding the nature of the
pseudogap and its relation with high temperature superconductivity.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 15:00:22 GMT""}]","2022-07-19"
"2207.07963","Adam Cartisano","Adam Cartisano","Bounding Pinch Point Schemes of Projected Surfaces","12 pages",,,,"math.AG","http://creativecommons.org/licenses/by/4.0/","  Let $X$ be a smooth surface and let $\varphi:X\to\mathbb{P}^N$, with $N\geq
4$, be a finitely ramified map which is birational onto its image $Y =
\varphi(X)$, with $Y$ non-degenerate in $\mathbb{P}^N$. In this paper, we
produce a lower bound for the length of the pinch scheme of a general linear
projection of $Y$ to $\mathbb{P}^3.$ We then prove that the lower bound is
realized if and only if $Y$ is a rational normal scroll.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 15:04:03 GMT""},{""version"":""v2"",""created"":""Tue, 9 Aug 2022 15:26:38 GMT""},{""version"":""v3"",""created"":""Thu, 8 Sep 2022 17:08:03 GMT""}]","2022-09-09"
"2207.07964","Peeter Laud","Mohammad Anagreh and Peeter Laud","A Parallel Privacy-Preserving Shortest Path Protocol from a Path Algebra
  Problem","30 pages, 7 figures, 4 tables",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present a secure multiparty computation (SMC) protocol for
single-source shortest distances (SSSD) in undirected graphs, where the
location of edges is public, but their length is private. The protocol works in
the Arithmetic Black Box (ABB) model on top of the separator tree of the graph,
achieving good time complexity if the subgraphs of the graph have small
separators (which is the case for e.g. planar graphs); the achievable
parallelism is significantly higher than that of classical SSSD algorithms
implemented on top of an ABB.
  We implement our protocol on top of the Sharemind MPC platform, and perform
extensive benchmarking over different network environments. We compare our
algorithm against the baseline picked from classical algorithms -
privacy-preserving Bellman-Ford algorithm (with public edges).
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 15:05:09 GMT""}]","2022-07-19"
"2207.07965","Qihang Yao","Qihang Yao, Manoj Chandrasekaran, Constantine Dovrolis","Root-Cause Analysis of Activation Cascade Differences in Brain Networks","14 pages, 4 figures, submitted to Brain Informatics 2022",,,,"q-bio.NC","http://creativecommons.org/licenses/by/4.0/","  Diffusion MRI imaging and tractography algorithms have enabled the mapping of
the macro-scale connectome of the entire brain. At the functional level,
probably the simplest way to study the dynamics of macro-scale brain activity
is to compute the ""activation cascade"" that follows the artificial stimulation
of a source region. Such cascades can be computed using the Linear Threshold
model on a weighted graph representation of the connectome. The question we
focus on is: if we are given such activation cascades for two groups, say A and
B (e.g. Controls versus a mental disorder), what is the smallest set of brain
connectivity (graph edge weight) changes that are sufficient to explain the
observed differences in the activation cascades between the two groups? We have
developed and computationally validated an efficient algorithm, TRACED, to
solve the previous problem. We argue that this approach to compare the
connectomes of two groups, based on activation cascades, is more insightful
than simply identifying ""static"" network differences (such as edges with large
weight or centrality differences). We have also applied the proposed method in
the comparison between a Major Depressive Disorder (MDD) group versus healthy
controls and briefly report the resulting set of connections that cause most of
the observed cascade differences.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 15:07:30 GMT""}]","2022-07-19"
"2207.07966","Joao Pedro Papalardo Azevedo","Jo\~ao Azevedo and Pavel Shumyatsky","Compact groups with high commuting probability of monothetic subgroups","Final version accepted by Journal of Algebra; typos corrected",,"10.1016/j.jalgebra.2023.02.021",,"math.GR","http://creativecommons.org/licenses/by/4.0/","  If $H$ is a subgroup of a compact group $G$, the probability that a random
element of $H$ commutes with a random element of $G$ is denoted by $Pr(H,G)$.
Let $\langle g\rangle$ stand for the monothetic subgroup generated by an
element $g\in G$ and let $K$ be a subgroup of $G$. We prove that $Pr(\langle
x\rangle,G)>0$ for any $x\in K$ if and only if $G$ has an open normal subgroup
$T$ such that $K/C_K(T)$ is torsion. In particular, $Pr(\langle x\rangle,G)>0$
for any $x\in G$ if and only if $G$ is virtually central-by-torsion, that is,
there is an open normal subgroup $T$ such that $G/Z(T)$ is torsion. We also
deduce a number of corollaries of this result.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 15:17:15 GMT""},{""version"":""v2"",""created"":""Sun, 5 Mar 2023 21:56:02 GMT""}]","2023-03-07"
"2207.07967","Lise-Marie Seill\'e","L.-M. Seill\'e, V. Buat, W. Haddad, A.Boselli, M.Boquien, L.Ciesla, Y.
  Roehlly, D.Burgarella","Spatial disconnection between stellar and dust emissions: the test of
  the Antennae Galaxies (Arp 244)","13 pages, 9 figures, Accepted for publication in Astronomy &
  Astrophysics","A&A 665, A137 (2022)","10.1051/0004-6361/202243702",,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The detection with of the Atacama Large Millimeter Array (ALMA) of dust-rich
high redshift galaxies whose cold dust emission is spatially disconnected from
the ultraviolet emission bears a challenge for modelling their spectral energy
distributions (SED) with codes based on an energy budget between the stellar
and dust components. We test the validity of energy balance modelling on a
nearby resolved galaxy with vastly different ultraviolet and infrared spatial
distributions and infer what information can be reliably retrieved from the
analysis of the full spectral energy distribution. We use 15 broadband images
of the Antennae Galaxies ranging from far-ultraviolet to far-infrared and
divide Arp 244 into 58 square ~1 kpc$^2$ regions. We fit the data with CIGALE
to determine the star formation rate, stellar mass and dust attenuation of each
region. We compare these quantities for the addition of the 58 regions to the
ones obtained for Arp 244 as a whole and find that both estimates are
consistent within one sigma. We present the spatial distribution of these
physical parameters as well as the shape of the attenuation curve across the
Antennae Galaxies . We also observe a flattening of the attenuation curves with
increasing attenuation and dust surface density in agreement with the
predictions of hydrodynamical simulations coupled with radiative transfer
modelling.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 15:25:00 GMT""}]","2022-09-21"
"2207.07968","Philipp Linnartz","Philipp Linnartz, Alexander Winkens, Andreas Ulbig","Assessing the impact of cyber attacks manipulating distributed energy
  resources on power system operation","In proceedings of the 11th Bulk Power Systems Dynamics and Control
  Symposium (IREP 2022), July 25-30, 2022, Banff, Canada",,,"IREP2022-38","eess.SY cs.SY","http://creativecommons.org/licenses/by-sa/4.0/","  Successful cyber attacks on power systems cause severe disruptions. One
possible manipulation strategy is the utilization of distributed energy
resources (DERs) to disturb power system operation. In addition to the impact
on bulk power system frequency, local cascading effects caused by DER control
and protection can increase the severity of this strategy. To investigate these
effects, manipulation scenarios including the disconnection as well as the
manipulation of active (P) and reactive power (Q) setpoints of DERs are
derived. The impact is analyzed using time-domain simulations and quantified
using assessment criteria such as voltage band violation and plant protection
triggering. Though DER disconnection leads to high amounts of lost P injection
the manipulation of Q setpoints offers potential to disconnect additional DERs
through local cascading effects. To mitigate the impact of the manipulation
scenarios automated tap changer operation as well as a limitation of remotely
accessible Q is suitable.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 15:30:13 GMT""}]","2022-07-19"
"2207.07969","Shintaro Negishi","Shintaro Negishi","A Study of Long-term Energy-mix Optimization Model: A Case Study in
  Japan","6pages","Proceedings of The International Conference on Electrical
  Engineering 2022 (ICEE2022)",,"1-0150","eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There is a strong need to reduce greenhouse gas emissions to deal with
climate change. In the power sector, changing the power generation method in
the medium and long term is needed to reduce greenhouse gas emissions. This
paper proposes a long-term energy-mix optimization mod-el to obtain the process
of carbon neutrality in the power system. The proposed model models power
supply and demand at an hourly granularity and determines the generation
capacity that minimizes the long-term energy supply cost. Compared with the
models proposed in previous studies, the proposed model can determine the
installed capacity to maintain the balance of power supply and demand by adding
the capacity of regulation reserve required by fluctuations in the output of
variable renewable energy as a constraint condition. A Japan energy mix
calculation is reported as a case study of the proposed model. This model can
clarify the roadmap to achieving each country's emission reduction target and
support the government's decision-making.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 15:40:51 GMT""}]","2022-07-20"
"2207.07970","Matheus Cavalcante","Matheus Cavalcante, Domenic W\""uthrich, Matteo Perotti, Samuel Riedel,
  Luca Benini","Spatz: A Compact Vector Processing Unit for High-Performance and
  Energy-Efficient Shared-L1 Clusters","9 pages. Accepted for publication in the 2022 International
  Conference on Computer-Aided Design (ICCAD 2022)",,"10.1145/3508352.3549367",,"cs.AR","http://creativecommons.org/licenses/by/4.0/","  While parallel architectures based on clusters of Processing Elements (PEs)
sharing L1 memory are widespread, there is no consensus on how lean their PE
should be. Architecting PEs as vector processors holds the promise to greatly
reduce their instruction fetch bandwidth, mitigating the Von Neumann Bottleneck
(VNB). However, due to their historical association with supercomputers,
classical vector machines include micro-architectural tricks to improve the
Instruction Level Parallelism (ILP), which increases their instruction fetch
and decode energy overhead. In this paper, we explore for the first time vector
processing as an option to build small and efficient PEs for large-scale
shared-L1 clusters. We propose Spatz, a compact, modular 32-bit vector
processing unit based on the integer embedded subset of the RISC-V Vector
Extension version 1.0. A Spatz-based cluster with four Multiply-Accumulate
Units (MACUs) needs only 7.9 pJ per 32-bit integer multiply-accumulate
operation, 40% less energy than an equivalent cluster built with four Snitch
scalar cores. We analyzed Spatz' performance by integrating it within MemPool,
a large-scale many-core shared-L1 cluster. The Spatz-based MemPool system
achieves up to 285 GOPS when running a 256x256 32-bit integer matrix
multiplication, 70% more than the equivalent Snitch-based MemPool system. In
terms of energy efficiency, the Spatz-based MemPool system achieves up to 266
GOPS/W when running the same kernel, more than twice the energy efficiency of
the Snitch-based MemPool system, which reaches 128 GOPS/W. Those results show
the viability of lean vector processors as high-performance and
energy-efficient PEs for large-scale clusters with tightly-coupled L1 memory.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 15:54:30 GMT""}]","2022-07-21"
"2207.08719","Lukasz Matysiak","Lukasz Matysiak","A polynomial composites","22 pages. arXiv admin note: substantial text overlap with
  arXiv:2104.09657",,,,"math.AC","http://creativecommons.org/publicdomain/zero/1.0/","  Polynomial composites were introduced by Anderson, Anderson, and Zafrullah.
In this paper we study many different algebraic properties of polynomial
composites like ACCP, atomic, SR property. We study relationships between
Noetherian polynomial composites certain field extensions.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:39:12 GMT""}]","2022-07-19"
"2207.08807","Peter Boyvalenkov","Peter Boyvalenkov, Peter Dragnev, Douglas Hardin, Edward Saff, Maya
  Stoyanova","On polarization of spherical codes and designs",,,,,"math.CO math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article we investigate the $N$-point min-max and the max-min
polarization problems on the sphere for a large class of potentials in
$\mathbb{R}^n$. We derive universal lower and upper bounds on the polarization
of spherical designs of fixed dimension, strength, and cardinality. The bounds
are universal in the sense that they are a convex combination of potential
function evaluations with nodes and weights independent of the class of
potentials. As a consequence of our lower bounds, we obtain the
Fazekas-Levenshtein bounds on the covering radius of spherical designs.
Utilizing the existence of spherical designs, our polarization bounds are
extended to general configurations. As examples we completely solve the min-max
polarization problem for $120$ points on $\mathbb{S}^3$ and show that the
$600$-cell is universally optimal for that problem. We also provide alternative
methods for solving the max-min polarization problem when the number of points
$N$ does not exceed the dimension $n$ and when $N=n+1$. We further show that
the cross-polytope has the best max-min polarization constant among all
spherical $2$-designs of $N=2n$ points for $n=2,3,4$; for $n\geq 5$, this
statement is conditional on a well-known conjecture that the cross-polytope has
the best covering radius. This max-min optimality is also established for all
so-called centered codes.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 21:03:37 GMT""}]","2022-07-20"
"2207.08808","Haobo Ji","Xin Feng, Haobo Ji, Wenjie Pei, Fanglin Chen, Guangming Lu","Global-Local Stepwise Generative Network for Ultra High-Resolution Image
  Restoration","This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While the research on image background restoration from regular size of
degraded images has achieved remarkable progress, restoring ultra
high-resolution (e.g., 4K) images remains an extremely challenging task due to
the explosion of computational complexity and memory usage, as well as the
deficiency of annotated data. In this paper we present a novel model for ultra
high-resolution image restoration, referred to as the Global-Local Stepwise
Generative Network (GLSGN), which employs a stepwise restoring strategy
involving four restoring pathways: three local pathways and one global pathway.
The local pathways focus on conducting image restoration in a fine-grained
manner over local but high-resolution image patches, while the global pathway
performs image restoration coarsely on the scale-down but intact image to
provide cues for the local pathways in a global view including semantics and
noise patterns. To smooth the mutual collaboration between these four pathways,
our GLSGN is designed to ensure the inter-pathway consistency in four aspects
in terms of low-level content, perceptual attention, restoring intensity and
high-level semantics, respectively. As another major contribution of this work,
we also introduce the first ultra high-resolution dataset to date for both
reflection removal and rain streak removal, comprising 4,670 real-world and
synthetic images. Extensive experiments across three typical tasks for image
background restoration, including image reflection removal, image rain streak
removal and image dehazing, show that our GLSGN consistently outperforms
state-of-the-art methods.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 12:13:22 GMT""},{""version"":""v2"",""created"":""Wed, 17 May 2023 15:24:41 GMT""}]","2023-05-18"
"2207.09221","Bhan Lam","Zhen-Ting Ong, Bhan Lam, Kenneth Ooi, Karn N. Watcharasupat, Trevor
  Wong, and Woon-Seng Gan","Do uHear? Validation of uHear App for Preliminary Screening of Hearing
  Ability in Soundscape Studies","Full paper submitted to 24th International Congress on Acoustics",,,,"eess.AS stat.AP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Studies involving soundscape perception often exclude participants with
hearing loss to prevent impaired perception from affecting experimental
results. Participants are typically screened with pure tone audiometry, the
""gold standard"" for identifying and quantifying hearing loss at specific
frequencies, and excluded if a study-dependent threshold is not met. However,
procuring professional audiometric equipment for soundscape studies may be
cost-ineffective, and manually performing audiometric tests is
labour-intensive. Moreover, testing requirements for soundscape studies may not
require sensitivities and specificities as high as that in a medical diagnosis
setting. Hence, in this study, we investigate the effectiveness of the uHear
app, an iOS application, as an affordable and automatic alternative to a
conventional audiometer in screening participants for hearing loss for the
purpose of soundscape studies or listening tests in general. Based on
audiometric comparisons with the audiometer of 163 participants, the uHear app
was found to have high precision (98.04%) when using the World Health
Organization (WHO) grading scheme for assessing normal hearing. Precision is
further improved (98.69%) when all frequencies assessed with the uHear app is
considered in the grading, which lends further support to this cost-effective,
automated alternative to screen for normal hearing.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 08:19:30 GMT""}]","2022-07-20"
"2207.10648","Michael Desmond","Michael Desmond, Evelyn Duesterwald, Vatche Isahagian, Vinod Muthusamy","A No-Code Low-Code Paradigm for Authoring Business Automations Using
  Natural Language",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Most business process automation is still developed using traditional
automation technologies such as workflow engines. These systems provide domain
specific languages that require both business knowledge and programming skills
to effectively use. As such, business users often lack adequate programming
skills to fully leverage these code oriented environments. We propose a
paradigm for the construction of business automations using natural language.
The approach applies a large language model to translate business rules and
automations described in natural language, into a domain specific language
interpretable by a business rule engine. We compare the performance of various
language model configurations, across various target domains, and explore the
use of constrained decoding to ensure syntactically correct generation of
output.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 19:17:55 GMT""}]","2022-07-22"
"2207.10806","Andrew Critch PhD","Andrew Critch","WordSig: QR streams enabling platform-independent self-identification
  that's impossible to deepfake",,,,,"cs.CR cs.AI cs.CY","http://creativecommons.org/licenses/by/4.0/","  Deepfakes can degrade the fabric of society by limiting our ability to trust
video content from leaders, authorities, and even friends. Cryptographically
secure digital signatures may be used by video streaming platforms to endorse
content, but these signatures are applied by the content distributor rather
than the participants in the video. We introduce WordSig, a simple protocol
allowing video participants to digitally sign the words they speak using a
stream of QR codes, and allowing viewers to verify the consistency of
signatures across videos. This allows establishing a trusted connection between
the viewer and the participant that is not mediated by the content distributor.
Given the widespread adoption of QR codes for distributing hyperlinks and
vaccination records, and the increasing prevalence of celebrity deepfakes, 2022
or later may be a good time for public figures to begin using and promoting
QR-based self-authentication tools.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:23:01 GMT""}]","2022-07-25"
"2207.10807","Md. Abbas Ali Khan","Md. Abbas Ali Khan, Mphammad Hanif Ali, AKM Fazlul Haque, Md. Tarek
  Habib","A Machine Learning Approach for Driver Identification Based on CAN-BUS
  Sensor Data",,,,,"cs.LG eess.SP","http://creativecommons.org/licenses/by/4.0/","  Driver identification is a momentous field of modern decorated vehicles in
the controller area network (CAN-BUS) perspective. Many conventional systems
are used to identify the driver. One step ahead, most of the researchers use
sensor data of CAN-BUS but there are some difficulties because of the variation
of the protocol of different models of vehicle. Our aim is to identify the
driver through supervised learning algorithms based on driving behavior
analysis. To determine the driver, a driver verification technique is proposed
that evaluate driving pattern using the measurement of CAN sensor data. In this
paper on-board diagnostic (OBD-II) is used to capture the data from the CAN-BUS
sensor and the sensors are listed under SAE J1979 statement. According to the
service of OBD-II, drive identification is possible. However, we have gained
two types of accuracy on a complete data set with 10 drivers and a partial data
set with two drivers. The accuracy is good with less number of drivers compared
to the higher number of drivers. We have achieved statistically significant
results in terms of accuracy in contrast to the baseline algorithm
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 00:38:21 GMT""}]","2022-07-25"
"2207.11132","Justice Darko","Justice Darko and Hyoshin Park","Proactive Distributed Constraint Optimization of Heterogeneous Incident
  Vehicle Teams","14 pages, 13 figures, 2 tables, journal",,,,"eess.SY cs.AI cs.MA cs.SY","http://creativecommons.org/licenses/by/4.0/","  Traditionally, traffic incident management (TIM) programs coordinate the
deployment of emergency resources to immediate incident requests without
accommodating the interdependencies on incident evolutions in the environment.
However, ignoring inherent interdependencies on the evolution of incidents in
the environment while making current deployment decisions is shortsighted, and
the resulting naive deployment strategy can significantly worsen the overall
incident delay impact on the network. The interdependencies on incident
evolution in the environment, including those between incident occurrences, and
those between resource availability in near-future requests and the anticipated
duration of the immediate incident request, should be considered through a
look-ahead model when making current-stage deployment decisions. This study
develops a new proactive framework based on the distributed constraint
optimization problem (DCOP) to address the above limitations, overcoming
conventional TIM models that cannot accommodate the dependencies in the TIM
problem. Furthermore, the optimization objective is formulated to incorporate
Unmanned Aerial Vehicles (UAVs). The UAVs' role in TIM includes exploring
uncertain traffic conditions, detecting unexpected events, and augmenting
information from roadway traffic sensors. Robustness analysis of our model for
multiple TIM scenarios shows satisfactory performance using local search
exploration heuristics. Overall, our model reports a significant reduction in
total incident delay compared to conventional TIM models. With UAV support, we
demonstrate a further decrease in the overall incident delay through the
shorter response time of emergency vehicles, and a reduction in uncertainties
associated with the estimated incident delay impact.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 13:43:58 GMT""},{""version"":""v2"",""created"":""Fri, 5 Aug 2022 01:54:29 GMT""}]","2022-08-08"
"2207.11146","Abdallah Chehade","Mayuresh Savargaonkar and Abdallah Chehade","VTrackIt: A Synthetic Self-Driving Dataset with Infrastructure and
  Pooled Vehicle Information",,,,,"cs.CV cs.AI cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Artificial intelligence solutions for Autonomous Vehicles (AVs) have been
developed using publicly available datasets such as Argoverse, ApolloScape,
Level5, and NuScenes. One major limitation of these datasets is the absence of
infrastructure and/or pooled vehicle information like lane line type, vehicle
speed, traffic signs, and intersections. Such information is necessary and not
complementary to eliminating high-risk edge cases. The rapid advancements in
Vehicle-to-Infrastructure and Vehicle-to-Vehicle technologies show promise that
infrastructure and pooled vehicle information will soon be accessible in near
real-time. Taking a leap in the future, we introduce the first comprehensive
synthetic dataset with intelligent infrastructure and pooled vehicle
information for advancing the next generation of AVs, named VTrackIt. We also
introduce the first deep learning model (InfraGAN) for trajectory predictions
that considers such information. Our experiments with InfraGAN show that the
comprehensive information offered by VTrackIt reduces the number of high-risk
edge cases. The VTrackIt dataset is available upon request under the Creative
Commons CC BY-NC-SA 4.0 license at http://vtrackit.irda.club.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 16:00:33 GMT""}]","2022-07-25"
"2207.11192","Jong Chul Ye","Sangyun Lee, Hyungjin Chung, Jaehyeon Kim, Jong Chul Ye","Progressive Deblurring of Diffusion Models for Coarse-to-Fine Image
  Synthesis","NeurIPS 2022 SBM workshop",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Recently, diffusion models have shown remarkable results in image synthesis
by gradually removing noise and amplifying signals. Although the simple
generative process surprisingly works well, is this the best way to generate
image data? For instance, despite the fact that human perception is more
sensitive to the low frequencies of an image, diffusion models themselves do
not consider any relative importance of each frequency component. Therefore, to
incorporate the inductive bias for image data, we propose a novel generative
process that synthesizes images in a coarse-to-fine manner. First, we
generalize the standard diffusion models by enabling diffusion in a rotated
coordinate system with different velocities for each component of the vector.
We further propose a blur diffusion as a special case, where each frequency
component of an image is diffused at different speeds. Specifically, the
proposed blur diffusion consists of a forward process that blurs an image and
adds noise gradually, after which a corresponding reverse process deblurs an
image and removes noise progressively. Experiments show that the proposed model
outperforms the previous method in FID on LSUN bedroom and church datasets.
Code is available at https://github.com/sangyun884/blur-diffusion.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 15:00:21 GMT""},{""version"":""v2"",""created"":""Mon, 21 Nov 2022 12:44:45 GMT""}]","2022-11-22"
"2207.12321","Yafu Tian","Yafu Tian, Alexander Carballo, Ruifeng Li and Kazuya Takeda","RSG-Net: Towards Rich Sematic Relationship Prediction for Intelligent
  Vehicle in Complex Environments","6 pages, 7 figures, accepted by IEEE-IV 2021 conference","[C]//2021 IEEE Intelligent Vehicles Symposium (IV). IEEE, 2021:
  546-552","10.1109/IV48863.2021.9575491",,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  Behavioral and semantic relationships play a vital role on intelligent
self-driving vehicles and ADAS systems. Different from other research focused
on trajectory, position, and bounding boxes, relationship data provides a human
understandable description of the object's behavior, and it could describe an
object's past and future status in an amazingly brief way. Therefore it is a
fundamental method for tasks such as risk detection, environment understanding,
and decision making. In this paper, we propose RSG-Net (Road Scene Graph Net):
a graph convolutional network designed to predict potential semantic
relationships from object proposals, and produces a graph-structured result,
called ""Road Scene Graph"". The experimental results indicate that this network,
trained on Road Scene Graph dataset, could efficiently predict potential
semantic relationships among objects around the ego-vehicle.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 12:40:17 GMT""}]","2022-07-26"
"2207.14638","Jonathan Sobel","Jonathan A. Sobel, Ronit Almog, Leo Anthony Celi, Michal
  Gaziel-Yablowitz, Danny Eytan, Joachim A. Behar","Building Trust: Lessons from the Technion-Rambam Machine Learning in
  Healthcare Datathon Event","13 pages, 4 figures, 29 references",,,,"cs.DB cs.LG stat.AP","http://creativecommons.org/licenses/by/4.0/","  A datathon is a time-constrained competition involving data science applied
to a specific problem. In the past decade, datathons have been shown to be a
valuable bridge between fields and expertise . Biomedical data analysis
represents a challenging area requiring collaboration between engineers,
biologists and physicians to gain a better understanding of patient physiology
and of guide decision processes for diagnosis, prognosis and therapeutic
interventions to improve care practice. Here, we reflect on the outcomes of an
event that we organized in Israel at the end of March 2022 between the MIT
Critical Data group, Rambam Health Care Campus (Rambam) and the Technion Israel
Institute of Technology (Technion) in Haifa. Participants were asked to
complete a survey about their skills and interests, which enabled us to
identify current needs in machine learning training for medical problem
applications. This work describes opportunities and limitations in medical data
science in the Israeli context.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 14:53:56 GMT""},{""version"":""v2"",""created"":""Tue, 2 Aug 2022 12:42:16 GMT""}]","2022-08-03"
"2208.01740","Ralvi Isufaj","Ralvi Isufaj, Marsel Omeri, Miquel Angel Piera, Jaume Saez Valls,
  Christian Eduardo Verdonk Gallego","From Single Aircraft to Communities: A Neutral Interpretation of Air
  Traffic Complexity Dynamics","21 pages, 30 figures, 2 tables, submitted to Research Transportation
  Part C",,,,"cs.AI cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Present air traffic complexity metrics are defined considering the interests
of different management layers of ATM. These layers have different objectives
which in practice compete to maximize their own goals, which leads to
fragmented decision making. This fragmentation together with competing KPAs
requires transparent and neutral air traffic information to pave the way for an
explainable set of actions. In this paper, we introduce the concept of single
aircraft complexity, to determine the contribution of each aircraft to the
overall complexity of air traffic. Furthermore, we describe a methodology
extending this concept to define complex communities, which are groups of
interdependent aircraft that contribute the majority of the complexity in a
certain airspace. In order to showcase the methodology, a tool that visualizes
different outputs of the algorithm is developed. Through use-cases based on
synthetic and real historical traffic, we first show that the algorithm can
serve to formalize controller decisions as well as guide controllers to better
decisions. Further, we investigate how the provided information can be used to
increase transparency of the decision makers towards different airspace users,
which serves also to increase fairness and equity. Lastly, a sensitivity
analysis is conducted in order to systematically analyse how each input affects
the methodology.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 21:21:13 GMT""}]","2022-08-04"
"2208.04152","Herbert J Bernstein","Herbert J. Bernstein, Lawrence C. Andrews, Mario Xerri","An Invertible Seven-Dimensional Dirichlet Cell Characterization of
  Lattices","37 pages, 2 figures, general copy-edit, update matrices to full 2D
  display",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Characterization of crystallographic lattices is an important tool in
structure solution, crystallographic database searches and clustering of
diffraction images in serial crystallography. Characterization of lattices by
Niggli-reduced cells (based on the three shortest non-coplanar lattice edge
vectors) or by Delaunay-reduced cells (based on four edge vectors summing to
zero and all meeting at obtuse or right angles) are commonly used. The Niggli
cell derives from Minkowski reduction. The Delaunay cell derives from Selling
reduction. All are related to the Wigner-Seitz (or Dirichlet, or Voronoi) cell
of the lattice, which consists of the points at least as close to a chosen
lattice point than they are to any other lattice point. Starting from a
Niggli-reduced cell, the Dirichlet cell is characterized by the planes
determined by thirteen lattice half-edges: the midpoints of the three Niggli
cell edges, the six Niggli cell face diagonals and the four body-diagonals, but
seven of the edge lengths are sufficient: three edge lengths, the three shorter
of each pair of face-diagonal lengths and the shortest body-diagonal length,
from which the Niggli-reduced cell may be recovered.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 00:56:01 GMT""},{""version"":""v2"",""created"":""Wed, 9 Nov 2022 17:31:54 GMT""},{""version"":""v3"",""created"":""Mon, 26 Dec 2022 04:08:28 GMT""}]","2022-12-27"
"2208.04682","Philip Bourne","Philip E. Bourne, Vivien Bonazzi, Amy Brand, Bonnie Carroll, Ian
  Foster, Ramanathan V. Guha, Robert Hanisch, Sallie Ann Keller, Mary Lee
  Kennedy, Christine Kirkpatrick, Barend Mons, Sarah M. Nusser, Michael
  Stebbins, George Strawn, and Alex Szalay","Playing catch-up in building an open research commons","3 pages on the AAS template",,"10.1126/science.abo5947",,"cs.DL cs.GL","http://creativecommons.org/publicdomain/zero/1.0/","  On August 2, 2021 a group of concerned scientists and US funding agency and
federal government officials met for an informal discussion to explore the
value and need for a well-coordinated US Open Research Commons (ORC); an
interoperable collection of data and compute resources within both the public
and private sectors which are easy to use and accessible to all.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 17:34:00 GMT""}]","2022-10-12"
"2208.04709","Chaofeng Wang","Yifeng Tian, Chaofeng Wang, Ashish Asutosh, Junghoon Woo, and Peter
  Adriaens","Blockchain-enabled tokenization for sustainable and inclusive
  infrastructure investment",,,,,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  Infrastructure is critical for enabling society to function and the economy
to thrive, but there is an increasing mismatch between the need for
infrastructure investments and available capital, which is in consequence of
constraints on public resources and limited capacity to leverage the private
sector co-financing under the current system. With the emergence of distributed
ledger technology, such as blockchain-enabled tokenization, there is a
significant potential to improve investment liquidity, transparency, efficiency
and create new economic models to integrate non-financial values to promote
sustainability and inclusiveness. This research analyzed 21 projects to
investigate how tokenization is implemented in energy infrastructure projects.
Exploratory case study analyses were conducted, which shows the diversity of
tokenization arrangements. The state of the art, potential benefits,
implications, and obstacles associated with the application of tokenization in
infrastructure investment and development are discussed. The purpose of this
research is to understand tokenization within the context of the energy sector
but also to forecast its application in a broad spectrum of infrastructure
projects (e.g., transportation, telecommunication, healthcare, education).
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 01:39:33 GMT""}]","2022-08-10"
"2208.04710","Chaofeng Wang","Yifeng Tian, Chaofeng Wang, Junghoon Woo, Zheng Lu, and Peter Adriaens","The future of blockchain-enabled tokenization in infrastructure
  investment and development: A Delphi-based scenario analysis",,,,,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  Spurred by the emerging blockchain technology and increased interest in
tokenization, this forecasting research built on extensive literature and
aggregated expertise to explore the potential implementation of
blockchain-enabled tokenization in infrastructure investment and development.
The Delphi-based scenario analysis approach was applied to gather long-term
forecasts and assessments of a research panel consisting of 39 experts in
blockchain tokenization and infrastructure development on how tokenization will
influence the future of infrastructure finance and identify scenarios of
potential applications and impact. International experts were segregated into
two groups salient to this topical area based on both experience ad
self-identification: infrastructure development and blockchain tokenization.
Twenty-three projections for 2035, developed from a literature review, case
study analysis, and expert interviews, concerning perspectives of both the
supply and demand side for the adoption of blockchain tokenization, were
assessed in a two-round Delphi analysis. Regulatory, economic, social, and
technological perspectives of tokenization were taken into consideration.
Assessments were based on both probability and impact of occurrence. Three
groups of scenarios resulted from quantitative and qualitative analysis,
reflecting agreement and differentiation between both expert groups. The
results of this study clearly underlined the potential of tokenization in
infrastructure. Uncertainties and barriers confronting the technologies'
diffusion were discussed. This study contributes to the transfer of general
technical-driven blockchain-enabled tokenization knowledge to
infrastructure-specific tokenization knowledge. Long-term strategic planning is
supported by this study with the scenario data acting as a starting point for
blockchain-related efforts in infrastructure development.
","[{""version"":""v1"",""created"":""Sat, 16 Jul 2022 01:36:00 GMT""},{""version"":""v2"",""created"":""Thu, 1 Dec 2022 03:08:21 GMT""}]","2022-12-02"
"2208.04711","Hector G. T. Torres","Hector G. T. Torres","The Transform-o-meter: A method to forecast the transformative impact of
  innovation",,,,,"cs.CY cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the advent of Transformative Artificial Intelligence, it is now more
important than ever to be able to both measure and forecast the transformative
impact/potential of innovation. However, current methods fall short when faced
with this task. This paper introduces the Transform-o-meter; a methodology that
can be used to achieve the aforementioned goal, and be applied to any
innovation, both material and immaterial. While this method can effectively be
used for the mentioned purpose, it should be taken as a first approach; to be
iterated, researched, and expanded further upon.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 20:24:17 GMT""}]","2022-08-10"
"2208.12559","Antonio Tadeu Azevedo Gomes","Antonio Tadeu Azevedo Gomes and Larissa Miguez da Silva and Frederic
  Valentin","Physics-Aware Neural Networks for Boundary Layer Linear Problems","10 pages, 10 figures",,,,"math.NA cs.LG cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Physics-Informed Neural Networks (PINNs) are machine learning tools that
approximate the solution of general partial differential equations (PDEs) by
adding them in some form as terms of the loss/cost function of a Neural
Network. Most pieces of work in the area of PINNs tackle non-linear PDEs.
Nevertheless, many interesting problems involving linear PDEs may benefit from
PINNs; these include parametric studies, multi-query problems, and parabolic
(transient) PDEs. The purpose of this paper is to explore PINNs for linear PDEs
whose solutions may present one or more boundary layers. More specifically, we
analyze the steady-state reaction-advection-diffusion equation in regimes in
which the diffusive coefficient is small in comparison with the reactive or
advective coefficients. We show that adding information about these
coefficients as predictor variables in a PINN results in better prediction
models than in a PINN that only uses spatial information as predictor
variables. This finding may be instrumental in multiscale problems where the
coefficients of the PDEs present high variability in small spatiotemporal
regions of the domain, and therefore PINNs may be employed together with domain
decomposition techniques to efficiently approximate the PDEs locally at each
partition of the spatiotemporal domain, without resorting to different learned
PINN models at each of these partitions.
","[{""version"":""v1"",""created"":""Fri, 15 Jul 2022 21:15:06 GMT""}]","2022-08-29"
