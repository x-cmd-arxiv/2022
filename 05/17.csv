"2205.07773","Hartmut Winkler","Hartmut Winkler","A revised simplified scattering model for the moonlit sky brightness
  profile based on photometry at SAAO","Accepted for publication in Monthly Notices of the Royal Astronomical
  Society",,"10.1093/mnras/stac1387",,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents multi-filter measurements of the night sky brightness at
the South African Astronomical Observatory (SAAO) in Sutherland in the presence
of a bright moon. The observations cover a wide range of sky directions, lunar
phases and lunar positions. A revised simplified scattering model is developed
for estimating the sky brightness due to moonlight that more accurately
reflects the atmospheric extinction of the lunar beam compared to models
frequently applied in astronomical studies. Contributions to night sky
brightness due to sources other than moonlight are quantified and subtracted
from the total sky background radiation to determine the spectral intensity and
angular distribution of scattered moonlight. The atmospheric scattering phase
function is then derived by comparing the sky brightening to the strength of
the incoming lunar beam, estimated using a novel approach. The phase function
is shown to be an excellent match to the combined theoretical Rayleigh and Mie
scattering functions, the latter with a Henyey--Greenstein form instead of the
exponential angular relationship often used in previous studies. Where
deviations between measured and model sky brightness are evident in some bands
these are explained by contributions from multiple scattering or airglow, and
are quantified accordingly. The model constitutes an effective tool to predict
sky brightness at SAAO in optical photometric bands, especially with a bright
moon present. The methodology can also be readily be adapted for use at other
astronomical sites. The paper furthermore presents $UBV(RI)_c$ and
Str{\""o}mgren photometry for 49 stars, most with no prior such data.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:03:12 GMT""}]","2022-05-25"
"2205.07774","Xiaoting Shao","Xiaoting Shao, Kristian Kersting","Gradient-based Counterfactual Explanations using Tractable Probabilistic
  Models",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Counterfactual examples are an appealing class of post-hoc explanations for
machine learning models. Given input $x$ of class $y_1$, its counterfactual is
a contrastive example $x^\prime$ of another class $y_0$. Current approaches
primarily solve this task by a complex optimization: define an objective
function based on the loss of the counterfactual outcome $y_0$ with hard or
soft constraints, then optimize this function as a black-box. This ""deep
learning"" approach, however, is rather slow, sometimes tricky, and may result
in unrealistic counterfactual examples. In this work, we propose a novel
approach to deal with these problems using only two gradient computations based
on tractable probabilistic models. First, we compute an unconstrained
counterfactual $u$ of $x$ to induce the counterfactual outcome $y_0$. Then, we
adapt $u$ to higher density regions, resulting in $x^{\prime}$. Empirical
evidence demonstrates the dominant advantages of our approach.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:05:43 GMT""}]","2022-05-17"
"2205.07775","Songbo Hou","Songbo Hou, Jiamin Sun","Existence of solutions to Chern-Simons-Higgs equations on graphs","13 pages","Calculus of Variations and Partial Differential Equations, volume
  61, Article number: 139 (2022)",,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $G=(V,E)$ be a finite graph. We consider the existence of solutions to a
generalized Chern-Simons-Higgs equation $$ \Delta u=-\lambda e^{g(u)}\left(
e^{g(u)}-1\right)^2+4\pi\sum\limits_{j=1}^{N}\delta_{p_j} $$ on $G$, where
$\lambda$ is a positive constant; $g(u)$ is the inverse function of
$u=f(\upsilon)=1+\upsilon-e^{\upsilon}$ on $(-\infty, 0]$; $N$ is a positive
integer; $p_1, p_2, \cdot\cdot\cdot, p_N$ are distinct vertices of $V$ and
$\delta_{p_j}$ is the Dirac delta mass at $p_j$. We prove that there is
critical value $\lambda_c$ such that the generalized Chern-Simons-Higgs
equation has a solution if and only if $\lambda\geq \lambda_c$ . We also prove
the existence of solutions to the Chern-Simons-Higgs equation
  $$ \Delta u=\lambda e^{u}(e^{u}-1)+4\pi\sum\limits_{j=1}^{N}\delta_{p_j} $$
on $G$ when $\lambda$ takes the critical value $\lambda_c$ and this completes
the results of An Huang, Yong Lin and Shing-Tung Yau (Commun. Math. Phys. 377,
613-621 (2020)).
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:06:50 GMT""}]","2022-05-24"
"2205.07776","Zhaoting Chen","Zhaoting Chen (1), Laura Wolz (1), Richard Battye (1) ((1) Jodrell
  Bank Centre for Astrophysics)","Towards Optimal Foreground Mitigation Strategies for Interferometric HI
  Intensity Mapping in the Low-Redshift Universe","20 pages, 19 figures. Updated to match the published version in MNRAS","Monthly Notices of the Royal Astronomical Society, Volume 518,
  Issue 2, January 2023, Pages 2971-2990","10.1093/mnras/stac3288",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  We conduct the first case study towards developing optimal foreground
mitigation strategies for neutral hydrogen (HI) intensity mapping using radio
interferometers at low redshifts. A pipeline for simulation, foreground
mitigation and power spectrum estimation is built, which can be used for
ongoing and future surveys using MeerKAT and Square Kilometre Array Observatory
(SKAO). It simulates realistic sky signals to generate visibility data given
instrument and observation specifications, which is subsequently used to
perform foreground mitigation and power spectrum estimation. A quadratic
estimator formalism is developed to estimate the temperature power spectrum in
visibility space. Using MeerKAT telescope specifications for observations in
the redshift range z~0.25-0.30 corresponding to the MeerKAT International GHz
Tiered Extragalactic Exploration (MIGHTEE) survey, we present a case study
where we compare different approaches of foreground mitigation. We find that
component separation in visibility space provides a more accurate estimation of
HI clustering comparing to foreground avoidance, with the uncertainties being
30 per cent smaller. Power spectrum estimation from image is found to be less
robust with larger bias and more information loss when compared to estimation
in visibility. We conclude that for z~0.25-0.30, the MIGHTEE survey will be
capable of measuring the HI power spectrum from k~0.5 Mpc$^{-1}$ to k~10
Mpc$^{-1}$ with high accuracy. We are the first to show that, at low redshift,
component separation in visibility space suppresses foreground contamination at
large line-of-sight scales, allowing measurement of HI power spectrum closer to
the foreground wedge, crucial for data analysis towards future detections.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:07:43 GMT""},{""version"":""v2"",""created"":""Wed, 7 Dec 2022 11:12:09 GMT""}]","2022-12-08"
"2205.07777","Irina Kostitsyna","Bahareh Banyassady and Mark de Berg and Karl Bringmann and Kevin
  Buchin and Henning Fernau and Dan Halperin and Irina Kostitsyna and Yoshio
  Okamoto and Stijn Slot","Unlabeled Multi-Robot Motion Planning with Tighter Separation Bounds","A shorter version of this paper appeared in the Proceedings of the
  38th International Symposium on Computational Geometry (SoCG 2022)",,,,"cs.CG cs.RO","http://creativecommons.org/licenses/by/4.0/","  We consider the unlabeled motion-planning problem of $m$ unit-disc robots
moving in a simple polygonal workspace of $n$ edges. The goal is to find a
motion plan that moves the robots to a given set of $m$ target positions. For
the unlabeled variant, it does not matter which robot reaches which target
position as long as all target positions are occupied in the end.
  If the workspace has narrow passages such that the robots cannot fit through
them, then the free configuration space, representing all possible unobstructed
positions of the robots, will consist of multiple connected components. Even if
in each component of the free space the number of targets matches the number of
start positions, the motion-planning problem does not always have a solution
when the robots and their targets are positioned very densely. In this paper,
we prove tight bounds on how much separation between start and target positions
is necessary to always guarantee a solution. Moreover, we describe an algorithm
that always finds a solution in time $O(n \log n + mn + m^2)$ if the separation
bounds are met. Specifically, we prove that the following separation is
sufficient: any two start positions are at least distance $4$ apart, any two
target positions are at least distance $4$ apart, and any pair of a start and a
target positions is at least distance $3$ apart. We further show that when the
free space consists of a single connected component, the separation between
start and target positions is not necessary.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:09:27 GMT""}]","2022-05-17"
"2205.07778","Petar Rajkovic","Petar Rajkovic, Andjelija Djordjevic, Aleksandar Milenkovic, Dragan
  Jankovic","The Role of Resource Awareness in Medical Information System Life Cycle","8 pages, 9 figures, for workshop RAW 2022",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  During the process of medical information system development, resource
awareness is neglected. It is often assumed that the underlying hardware will
always have enough memory, processing power, and network bandwidth.
Unfortunately, this approach seems not so feasible in every case, and these
assumptions, if proven wrong, will harm the initial development run, a later
system upgrade, and life cycle in general. This paper aims to raise a resource
awareness problem that could still influence all information system deployment
and maintenance steps. As an example, we described the influence of the general
hardware and network limitations on the information system design,
functionality update process, and external system integration. Our research
results are a set of guidelines that should be applied to support resource
awareness, as an important part of the system design.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:09:44 GMT""}]","2022-05-17"
"2205.07779","Hila Shoshan","Hila Shoshan, Erel Segal-Halevi and Noam Hazon","Efficient Nearly-Fair Division with Capacity Constraints","13 pages, 3 figures",,,,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of fairly and efficiently allocating indivisible
items (goods or bads) under capacity constraints. In this setting, we are given
a set of categorized items. Each category has a capacity constraint (the same
for all agents), that is an upper bound on the number of items an agent can
receive from each category. Our main result is a polynomial-time algorithm that
solves the problem for two agents with additive utilities over the items. When
each category contains items that are all goods (positively evaluated) or all
chores (negatively evaluated) for each of the agents, our algorithm finds a
feasible allocation of the items, which is both Pareto-optimal and envy-free up
to one item. In the general case, when each item can be a good or a chore
arbitrarily, our algorithm finds an allocation that is Pareto-optimal and
envy-free up to one good and one chore.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:12:24 GMT""},{""version"":""v2"",""created"":""Tue, 28 Feb 2023 13:00:32 GMT""}]","2023-03-01"
"2205.07780","David Richter","David Richter, David Kretzler, Pascal Weisenburger, Guido Salvaneschi,
  Sebastian Faust, Mira Mezini","Prisma: A Tierless Language for Enforcing Contract-Client Protocols in
  Decentralized Applications (Extended Version)","This is the extended version including appendices of the paper to be
  published in TOPLAS; an extended abstract was published in ECOOP 2022",,,,"cs.PL","http://creativecommons.org/licenses/by/4.0/","  Decentralized applications (dApps) consist of smart contracts that run on
blockchains and clients that model collaborating parties. dApps are used to
model financial and legal business functionality. Today, contracts and clients
are written as separate programs -- in different programming languages --
communicating via send and receive operations. This makes distributed program
flow awkward to express and reason about, increasing the potential for
mismatches in the client-contract interface, which can be exploited by
malicious clients, potentially leading to huge financial losses. In this paper,
we present Prisma, a language for tierless decentralized applications, where
the contract and its clients are defined in one unit and pairs of send and
receive actions that ""belong together"" are encapsulated into a single
direct-style operation, which is executed differently by sending and receiving
parties. This enables expressing distributed program flow via standard control
flow and renders mismatching communication impossible. We prove formally that
our compiler preserves program behavior in presence of an attacker controlling
the client code. We systematically compare Prisma with mainstream and advanced
programming models for dApps and provide empirical evidence for its
expressiveness and performance.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:12:52 GMT""},{""version"":""v2"",""created"":""Mon, 15 May 2023 14:33:12 GMT""}]","2023-05-16"
"2205.07781","Luiz Capretz Dr.","Luiz Fernando Capretz, Jingdong Jia, Pradeep Waychal, Shuib Basri","Social Aspects of Software Testing: Comparative Studies in Asia","10 pages. arXiv admin note: substantial text overlap with
  arXiv:1906.11015","10th World Conference on Information Systems and Technologies
  (WorldCIST 2022), Budva, Montenegro, Lecture Notes in Networks and Systems
  (LNNS), Volume 468, pp. 346-355, Springer, 2022","10.1007/978-3-031-04826-5_34",,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  This study attempts to understand motivators and de-motivators that influence
the decisions of software students to take up and sustain software testing
careers across three different Asian countries, i.e., China, India, and
Malaysia. The re-search question can be framed as How many software students
across different Asian geographies are keen to take up testing careers, and
what are the reasons for their choices? Towards an answer, we developed a
cross-sectional but simple survey-based instrument. In this work, we
investigated how software students perceived the software testing role. The
results from China and India revealed that students are not very keen on taking
up a software tester career, but the Malaysia students show a more positive
attitude towards software testing. The study also pointed out the importance of
considering software testing activities as a set of human-dependent tasks and
emphasized the need for further re-search that examines critically individual
assessments of software testers about software testing activities. This
investigation can academics involved in software testing courses to understand
the impacting factors on the motivation and de-motivators of their students, as
well as to try convey positive view of testing as challenging and requires
critical thinking and innovative ideas.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:13:25 GMT""}]","2022-05-17"
"2205.07782","Isaac P\'erez Castillo","Isaac P\'erez Castillo","Spectral properties of the generalized diluted Wishart ensemble","7 pages, 2 figures",,,,"cond-mat.dis-nn cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  The celebrated Mar\v{c}enko-Pastur law, that considers the asymptotic
spectral density of random covariance matrices, has found a great number of
applications in physics, biology, economics, engineering, among others. Here,
using techniques from statistical mechanics of spin glasses, we derive simple
formulas concerning the spectral density of generalized diluted Wishart
matrices. These are defined as $\bm{F}\equiv \frac{1}{2d}\left( \bm{X}\bm{Y}^T+
\bm{Y}\bm{X}^T\right)$, where $\bm{X}$ and $\bm{Y}$ are diluted $N\times P$
rectangular matrices, whose entries correspond to the links of doubly-weighted
random bipartite Poissonian graphs following the distribution
$P(x_{i}^\mu,y_{i}^{\mu})=\frac{d}{N}\varrho(x_{i}^{\mu},y_{i}^{\mu})+\left(1-\frac{d}{N}\right)\delta_{x_{i}^{\mu},0}\delta_{y_{i}^{\mu},0}$,
with the probability density $\varrho(x,y)$ controlling the correlation between
the matrices entries of $\bm{X}$ and $\bm{Y}$. Our results cover several
interesting cases by varying the parameters of the matrix ensemble, namely, the
dilution of the graph $d$, the rectangularity of the matrices $\alpha=N/P$, and
the degree of correlation of the matrix entries via the density $\varrho(x,y)$.
Finally, we compare our findings to numerical diagonalisation showing excellent
agreement.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:14:05 GMT""}]","2022-05-17"
"2205.07783","Vladimir Lifschitz","Vladimir Lifschitz","Strong Equivalence of Logic Programs with Counting","Paper presented at the 38th International Conference on Logic
  Programming (ICLP 2022), 16 pages",,,,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  In answer set programming, two groups of rules are considered strongly
equivalent if they have the same meaning in any context. In some cases, strong
equivalence of programs in the input language of the grounder gringo can be
established by deriving rules of each program from rules of the other. The
possibility of such proofs has been demonstrated for a subset of that language
that includes comparisons, arithmetic operations, and simple choice rules, but
not aggregates. This method is extended here to a class of programs in which
some uses of the #count aggregate are allowed. This paper is under
consideration for acceptance in TPLP.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:14:54 GMT""}]","2022-05-17"
"2205.07784","Andrew Coates","Andrew Coates, Fethi M. Ramazano\u{g}lu","The intrinsic pathology of self-interacting vector fields","5+4 pages, 3+2 figures. Minor changes to bring into line with
  published version","Phys. Rev. Lett. 129, 151103 (2022)","10.1103/PhysRevLett.129.151103",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that self-interacting vector field theories exhibit unphysical
behaviour even when they are not coupled to any external field. This means any
theory featuring such vectors is in danger of being unphysical, an alarming
prospect for many proposals in cosmology, gravity, high energy physics and
beyond. The problem arises when vector fields with healthy configurations
naturally reach a point where time evolution is mathematically ill-defined. We
develop tools to easily identify this issue, and provide a simple and unifying
framework to investigate it.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:15:24 GMT""},{""version"":""v2"",""created"":""Sun, 22 May 2022 15:25:59 GMT""},{""version"":""v3"",""created"":""Wed, 29 Jun 2022 21:22:53 GMT""},{""version"":""v4"",""created"":""Tue, 4 Oct 2022 16:47:20 GMT""}]","2022-10-05"
"2205.07785","Viktoriia Kornich","Viktoriia Kornich, Bj\""orn Trauzettel","Andreev bound states in junctions formed by conventional and
  $\mathcal{PT}$-symmetric non-Hermitian superconductors",,"Phys. Rev. Research 4, 033201 (2022)","10.1103/PhysRevResearch.4.033201",,"cond-mat.supr-con cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study theoretically a junction of a $\mathcal{PT}$-symmetric non-Hermitian
superconductor (PTS) placed between two conventional superconductors. We show
that due to non-Hermitian electron-electron interaction in the PTS region and
the combination of symmetries, only discrete values of phases of the
conventional superconductors yield solutions for Andreev bound states.
Remarkably, in the case of $0$ and $\pi$, we obtain growing and decaying in
time Andreev bound states. For $\pi/2$ and $3\pi/2$, there is a Majorana zero
mode penetrating through the junction in only one direction forming a
quasiparticle supercurrent.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:18:09 GMT""},{""version"":""v2"",""created"":""Mon, 11 Jul 2022 10:16:22 GMT""},{""version"":""v3"",""created"":""Tue, 16 Aug 2022 12:46:40 GMT""}]","2022-09-13"
"2205.07786","Eric Laloy","Eric Laloy, Bart Rogiers, An Bielen, Alessandro Borella, Sven Boden","Improving Bayesian radiological profiling of waste drums using Dirichlet
  priors, Gaussian process priors, and hierarchical modeling","arXiv admin note: text overlap with arXiv:2101.02112",,,,"physics.data-an physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  We present three methodological improvements of the ""SCK CEN approach"" for
Bayesian inference of the radionuclide inventory in radioactive waste drums,
from radiological measurements. First we resort to the Dirichlet distribution
for the prior distribution of the isotopic vector. The Dirichlet distribution
possesses the attractive property that the elements of its vector samples sum
up to 1. Second, we demonstrate that such Dirichlet priors can be incorporated
within an hierarchical modeling of the prior uncertainty in the isotopic
vector, when prior information about isotopic composition is available. Our
used Bayesian hierarchical modeling framework makes use of this available
information but also acknowledges its uncertainty by letting to a controlled
extent the information content of the indirect measurement data (i.e., gamma
and neutron counts) shape the actual prior distribution of the isotopic vector.
Third, we propose to regularize the Bayesian inversion by using Gaussian
process (GP) prior modeling when inferring 1D spatially-distributed quantities.
As of uncertainty in the efficiencies, we keep using the same stylized drum
modeling approach as proposed in our previous work to account for the source
distribution uncertainty across the vertical direction of the drum. A series of
synthetic tests followed by application to a real waste drum show that
combining hierarchical modeling of the prior isotopic composition uncertainty
together with GP prior modeling of the vertical Pu profile across the drum
works well. We also find that our GP prior can handles both cases with and
without spatial correlation. The computational times involved by our proposed
approach are on the order of a few hours, say about 2, to provide uncertainty
estimates for all variables of interest in the considered inverse problem. This
warrants further investigations to speed up the inference.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:18:46 GMT""},{""version"":""v2"",""created"":""Wed, 19 Oct 2022 12:29:55 GMT""},{""version"":""v3"",""created"":""Tue, 6 Dec 2022 15:10:27 GMT""},{""version"":""v4"",""created"":""Wed, 7 Dec 2022 09:54:46 GMT""}]","2022-12-08"
"2205.07787","Sunny Vagnozzi","Sunny Vagnozzi, Rittick Roy, Yu-Dai Tsai, Luca Visinelli, Misba Afrin,
  Alireza Allahyari, Parth Bambhaniya, Dipanjan Dey, Sushant G. Ghosh, Pankaj
  S. Joshi, Kimet Jusufi, Mohsen Khodadi, Rahul Kumar Walia, Ali \""Ovg\""un,
  Cosimo Bambi","Horizon-scale tests of gravity theories and fundamental physics from the
  Event Horizon Telescope image of Sagittarius A$^*$","82 pages, 47 figures, 50+ models tested. v3: fixed a few figures,
  clarified several points, included various analytical expressions for shadow
  sizes within the different models, added a few references, included a summary
  table (Table II). Version accepted for publication in Classical and Quantum
  Gravity",,"10.1088/1361-6382/acd97b",,"gr-qc astro-ph.HE hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Horizon-scale images of black holes (BHs) and their shadows have opened an
unprecedented window onto tests of gravity and fundamental physics in the
strong-field regime. We consider a wide range of well-motivated deviations from
classical General Relativity (GR) BH solutions, and constrain them using the
Event Horizon Telescope (EHT) observations of Sagittarius A$^*$ (Sgr A$^*$),
connecting the size of the bright ring of emission to that of the underlying BH
shadow and exploiting high-precision measurements of Sgr A$^*$'s
mass-to-distance ratio. The scenarios we consider, and whose fundamental
parameters we constrain, include various regular BHs, string-inspired
space-times, violations of the no-hair theorem driven by additional fields,
alternative theories of gravity, novel fundamental physics frameworks, and BH
mimickers including well-motivated wormhole and naked singularity space-times.
We demonstrate that the EHT image of Sgr A$^*$ places particularly stringent
constraints on models predicting a shadow size larger than that of a
Schwarzschild BH of a given mass, with the resulting limits in some cases
surpassing cosmological ones. Our results are among the first tests of
fundamental physics from the shadow of Sgr A$^*$ and, while the latter appears
to be in excellent agreement with the predictions of GR, we have shown that a
number of well motivated alternative scenarios, including BH mimickers, are far
from being ruled out at present.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:22:56 GMT""},{""version"":""v2"",""created"":""Fri, 19 Aug 2022 12:49:36 GMT""},{""version"":""v3"",""created"":""Fri, 26 May 2023 11:55:37 GMT""}]","2023-05-30"
"2205.07788","Naoya Shimamoto","Naoya Shimamoto","Configuration of five points in $\mathbb P^3$ and their limits",,,,,"math.RT math.AG","http://creativecommons.org/licenses/by/4.0/","  We give a classification of ordered five points in $\mathbb P^3$ under the
diagonal action of $GL_4$ over an algebraically closed field of characteristic
$0$, by an explicit description of the diagonal action of $GL_4$ on the
quintuple of the projective varieties $\mathbb P^3$. This is the second
simplest setting, where a reductive subgroup of $H$ of $G$ has an open orbit in
a (generalised) flag variety $X$ of $G$ but $\#(H\backslash X)=\infty$. The
closure relations among infinitely many orbits are also given.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:23:58 GMT""}]","2022-05-17"
"2205.07789","Michele Pernice","Guglielmo Nocera and Michele Pernice","The derived Brauer map via twisted sheaves","23 pages",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $X$ be a quasicompact quasiseparated scheme. The collection of derived
Azumaya algebras in the sense of To\""en forms a group ${\rm Br}_{{\rm Az}}(X)$,
admitting a surjective map ${\rm Br}_{{\rm Az}}(X)\to {\rm H}^2(X,\mathbb{G}m)$
(which we call derived Brauer map) with a section. Let ${\rm Br}(X)$ be the
image of this section. There is therefore an isomorphism ${\rm Br}(X)\simeq
{\rm H}^2(X,\mathbb{G}m)$. Using the theory of prestable $\infty$-categories,
Jacob Lurie was able to lift this isomorphism of abelian groups to an
equivalence of $\infty$-categories between the Brauer space of invertible
presentable prestable $\mathcal{O}_X$-linear categories and the space ${\rm
Map}(X,{\rm K}(\mathbb{G}m,2))$. We offer an alternative proof of this
equivalence of $\infty$-categories, characterizing the functor from the left to
the right via gerbes of positive trivializations, and its inverse via
connective twisted sheaves. We also emphasize that this equivalence carries a
symmetric monoidal structure.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:24:43 GMT""}]","2022-05-17"
"2205.07790","Rahul Gupta","M.D. Caballero-Garc\'ia, Rahul Gupta, S. B. Pandey, S. R. Oates, M.
  Marisaldi, A. Ramsli, Y.-D. Hu, A. J. Castro-Tirado, R. S\'anchez-Ram\'irez,
  P. H. Connell, F. Christiansen, A. Kumar Ror, A. Aryan, J.-M. Bai, M. A.
  Castro-Tirado, Y.-F. Fan, E. Fern\'andez-Garc\'ia, A. Kumar, A. Lindanger, A.
  Mezentsev, J. Navarro-Gonz\'alez, T. Neubert, N. {\O}stgaard, I.
  P\'erez-Garc\'ia, V. Reglero, D. Sarria, T. R. Sun, D.-R. Xiong, J. Yang,
  Y.-H. Yang, and B.-B. Zhang","Multi-wavelength study of the luminous GRB 210619B observed with Fermi
  and ASIM","24 pages, 18 figures, 10 tables, accepted for publication in MNRAS",,"10.1093/mnras/stac3629",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on detailed multi-wavelength observations and analysis of the very
bright and long GRB 210619B, detected by the Atmosphere-Space Interactions
Monitor (ASIM) installed on the International Space Station (ISS) and the
Gamma-ray Burst Monitor (GBM) on-board the Fermi mission. Our main goal is to
understand the radiation mechanisms and jet composition of GRB 210619B. With a
measured redshift of $z$ = 1.937, we find that GRB 210619B falls within the 10
most luminous bursts observed by Fermi so far. The energy-resolved prompt
emission light curve of GRB 210619B exhibits an extremely bright hard emission
pulse followed by softer/longer emission pulses. The low-energy photon indices
($\alpha_{\rm pt}$) values obtained using the time-resolved spectral analysis
of the burst suggest a transition between the thermal (during harder pulse) to
non-thermal (during softer pulse) outflow. We examine the correlation between
spectral parameters and find that both peak energy and $\alpha_{\rm pt}$
exhibit the flux tracking pattern. The late time broadband photometric dataset
can be explained within the framework of the external forward shock model with
$\nu_m$ $< \nu_c$ $< \nu_{x}$ (where $\nu_m$, $\nu_c$, and $\nu_{x}$ are the
synchrotron peak, cooling-break, and X-ray frequencies, respectively) spectral
regime supporting a rarely observed hard electron energy index ($p<$ 2). We
find moderate values of host extinction of E(B-V) = 0.14 $\pm$ 0.01 mag for the
Small Magellanic Cloud (SMC) extinction law. In addition, we also report
late-time optical observations with the 10.4 m GTC placing deep upper limits
for the host galaxy ($z$=1.937), favouring a faint, dwarf host for the burst.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:28:06 GMT""},{""version"":""v2"",""created"":""Mon, 5 Dec 2022 19:36:02 GMT""}]","2022-12-21"
"2205.07791","Philip M\""oller","Philip M\""oller","A note on almost negative matrices and Gromov-hyperbolic Coxeter groups","12 Pages, 5 Figures. Comments are welcome!",,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note we revisit Moussong's Characterization of Gromov-hyperbolic
Coxeter groups. A Coxeter group is Gromov-hyperbolic if and only if it does not
contain a subgroup isomorphic to $\mathbb{Z}^2$ which can be read off directly
from the defining graph. We show that there is a small gap in the original
argument and provide a workaround.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:28:30 GMT""}]","2022-05-17"
"2205.07792","Rohit Chikkaraddy","Rohit Chikkaraddy, Rakesh Arul, Lukas A. Jakob, and Jeremy J. Baumberg","Single-molecule mid-IR detection through vibrationally-assisted
  luminescence","12 pages, 3 figures",,,,"physics.app-ph cond-mat.mes-hall physics.optics","http://creativecommons.org/licenses/by/4.0/","  Room temperature detection of molecular vibrations in the mid-infrared (MIR,
$\lambda$ =3-30$\mu$m) has numerous applications including real-time gas
sensing, chemical reactivity, medical imaging, astronomical surveys, and
quantum communication [1,2]. However, MIR detection is severely hindered by
thermal noise, hence current technologies rely on energy-intensive cooled
semiconductor detectors (mercury cadmium telluride, MCT) [3,4,5]. One way to
overcome this challenge is to upconvert the low-energy MIR light into
high-energy visible wavelengths ($\lambda$ =500-800nm) where detection of
single photons is easily achieved using silicon technologies [6,7]. This
process suffers from weak cross sections and the mismatch between MIR and
visible wavelengths, limiting its efficiency. Here, we exploit molecular
emitters possessing both MIR and visible transitions from molecular vibrations
and electronic states, coupled through Frank-Condon factors. By assembling
molecules into a nanoscale cavity and continuously optically pumping them below
the electronic absorption band, we show the transduction of MIR light absorbed
by the molecular vibrations. The upconverted signal is observed as enhanced
high-energy luminescence. Combining Purcell-enhanced visible luminescence with
enhanced rates of vibrational pumping gives transduction efficiencies exceeding
10%. By down-scaling the cavity volume below $1nm^3$, we show MIR detection of
single-molecular bonds, inaccessible to any previous detector.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:29:58 GMT""}]","2022-05-17"
"2205.07793","Dalton Sakthivadivel","Dalton A R Sakthivadivel","Regarding Flows Under the Free Energy Principle: A Comment on ""How
  Particular is the Physics of the Free Energy Principle?"" by Aguilera,
  Millidge, Tschantz, and Buckley","Five pages. Invited comment","Physics of Life Reviews, volume 42, 2022","10.1016/j.plrev.2022.05.009",,"cond-mat.stat-mech nlin.AO physics.hist-ph","http://creativecommons.org/licenses/by/4.0/","  In a recent technical critique of the free energy principle (FEP) due to
Aguilera-Millidge-Tschantz-Buckley, it is argued that there are a number of
instances where the FEP$\unicode{x2014}$as conventionally written, in terms of
densities over states$\unicode{x2014}$is uninformative about the dynamics of
many physical systems, and by extension, many 'things.' In this informal
comment on their critique, I highlight two points of interest where their
derivations are largely correct, but where their arguments are not fatal to the
FEP. I go on to conjecture that a path-based formulation of the FEP has key
features which restore its explanatory power in broad physical regimes.
Correspondingly, this piece takes the position that the application of a
state-based formulation of the FEP is inappropriate for certain simple systems,
but, that the FEP can be expected to hold regardless.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:30:18 GMT""},{""version"":""v2"",""created"":""Wed, 1 Jun 2022 12:38:28 GMT""}]","2022-06-02"
"2205.07794","Evgeny Skvortsov D","Alexey Sharapov, Evgeny Skvortsov, Arseny Sukhanov and Richard Van
  Dongen","Minimal model of Chiral Higher Spin Gravity","funding info corrected",,"10.1007/JHEP09(2022)134",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A unique class of local Higher Spin Gravities with propagating massless
fields in $4d$ - Chiral Higher Spin Gravity - was first found in the light-cone
gauge. We construct a covariant form of the corresponding field equations in
all orders, thus completing the previous analysis of arXiv:2204.10285. This
result is equivalent to taking the minimal model (in the sense of
$L_\infty$-algebras) of the jet-space BV-BRST formulation of Chiral Higher Spin
Gravity, thereby, containing also information about counterterms, anomalies,
etc.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:35:00 GMT""},{""version"":""v2"",""created"":""Mon, 6 Jun 2022 11:03:16 GMT""},{""version"":""v3"",""created"":""Mon, 6 Mar 2023 10:00:54 GMT""}]","2023-03-07"
"2205.07795","Hieu Le","Hieu Le, Taufiq Daryanto, Fabian Zhafransyah, Derry Wijaya, Elizabeth
  Coppock, Sang Chin","Referring Expressions with Rational Speech Act Framework: A
  Probabilistic Approach",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  This paper focuses on a referring expression generation (REG) task in which
the aim is to pick out an object in a complex visual scene. One common
theoretical approach to this problem is to model the task as a two-agent
cooperative scheme in which a `speaker' agent would generate the expression
that best describes a targeted area and a `listener' agent would identify the
target. Several recent REG systems have used deep learning approaches to
represent the speaker/listener agents. The Rational Speech Act framework (RSA),
a Bayesian approach to pragmatics that can predict human linguistic behavior
quite accurately, has been shown to generate high quality and explainable
expressions on toy datasets involving simple visual scenes. Its application to
large scale problems, however, remains largely unexplored. This paper applies a
combination of the probabilistic RSA framework and deep learning approaches to
larger datasets involving complex visual scenes in a multi-step process with
the aim of generating better-explained expressions. We carry out experiments on
the RefCOCO and RefCOCO+ datasets and compare our approach with other
end-to-end deep learning approaches as well as a variation of RSA to highlight
our key contribution. Experimental results show that while achieving lower
accuracy than SOTA deep learning methods, our approach outperforms similar RSA
approach in human comprehension and has an advantage over end-to-end deep
learning under limited data scenario. Lastly, we provide a detailed analysis on
the expression generation process with concrete examples, thus providing a
systematic view on error types and deficiencies in the generation process and
identifying possible areas for future improvements.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:37:50 GMT""}]","2022-05-17"
"2205.07796","Rapha\""el Ruimy","Rapha\""el Ruimy","Artin perverse sheaves","64 pages, no figures, comments welcome",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the perverse t-structure induces a t-structure on the category
$\mathcal{D}^A(S,\mathbb{Z}_\ell)$ of Artin $\ell$-adic complexes when $S$ is
an excellent scheme of dimension less than $2$ and provide a counter-example in
dimension $3$. The heart $\mathrm{Perv}^A(S,\mathbb{Z}_\ell)$ of this
t-structure can be described explicitly in terms of representations in the case
of $1$-dimensional schemes.
  When $S$ is of finite type over a finite field, we also construct a perverse
homotopy t-structure over $\mathcal{D}^A(S,\mathbb{Q}_\ell)$ and show that it
is the best possible approximation of the perverse t-structure. We describe the
simple objects of its heart $\mathrm{Perv}^A(S,\mathbb{Q}_\ell)^\#$ and show
that the weightless truncation functor $\omega^0$ is t-exact. We also show that
the weightless intersection complex $EC_S=\omega^0 IC_S$ is a simple Artin
homotopy perverse sheaf. If $S$ is a surface, it is also a perverse sheaf but
it need not be simple in the category of perverse sheaves.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:38:27 GMT""},{""version"":""v2"",""created"":""Tue, 21 Mar 2023 22:41:26 GMT""}]","2023-03-23"
"2205.07797","Ruoyuan Liu","Ruoyuan Liu","On the probabilistic well-posedness of the two-dimensional periodic
  nonlinear Schr\""odinger equation with the quadratic nonlinearity $|u|^2$","28 pages. To appear in J. Math. Pures Appl",,,,"math.AP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the two-dimensional periodic nonlinear Schr\""odinger equation (NLS)
with the quadratic nonlinearity $|u|^2$. In particular, we study the quadratic
NLS with random initial data distributed according to a fractional derivative
(of order $\alpha \geq 0$) of the Gaussian free field. After removing the
singularity at the zeroth frequency, we prove that the quadratic NLS is almost
surely locally well-posed for $\alpha < \frac{1}{2}$ and is probabilistically
ill-posed for $\alpha \geq \frac{3}{4}$ in a suitable sense. These results show
that in the case of rough random initial data and a quadratic nonlinearity, the
standard probabilistic well-posedness theory for NLS breaks down before
reaching the critical value $\alpha = 1$ predicted by the scaling analysis due
to Deng, Nahmod, and Yue (2019), and thus this paper is a continuation of the
work by Oh and Okamoto (2021) on stochastic nonlinear wave and heat equations
by building an analogue for NLS.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:40:33 GMT""},{""version"":""v2"",""created"":""Sat, 2 Jul 2022 15:48:25 GMT""},{""version"":""v3"",""created"":""Thu, 27 Oct 2022 09:08:45 GMT""}]","2022-10-28"
"2205.07798","Songbo Hou","Songbo Hou","Multiple solutions of a nonlinear biharmonic equation on graphs","7 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider a biharmonic equation with respect to the
Dirichlet problem on a domain of a locally finite graph. Using the variation
method, we prove that the equation has two distinct solutions under certain
conditions.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:41:54 GMT""}]","2022-05-17"
"2205.07799","Fred C. Adams","Fred C Adams and Kevin J Napier","Transfer of Rocks between Planetary Systems: Panspermia Revisited","18 pages, 3 figures, to appear in Astrobiology",,"10.1089/ast.2021.0187",,"astro-ph.EP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Motivated by the recent discovery of interstellar objects passing through the
solar system, and by recent developments in dynamical simulations, this paper
reconsiders the likelihood for life bearing rocks to be transferred from one
planetary system to another. The astronomical aspects of this lithopanspermia
process can now be estimated, including the cross sections for rock capture,
the velocity distributions of rocky ejecta, the survival times for captured
objects, and the dynamics of the solar system in both its birth cluster and in
the field. The remaining uncertainties are primarily biological, i.e., the
probability of life developing on a planet, the time required for such an
event, and the efficiency with which life becomes seeded in a new environment.
Using current estimates for the input quantities, we find that the transfer
rates are enhanced in the birth cluster, but the resulting odds for success are
too low for panspermia to be a likely occurrence. In contrast, the expected
inventory of alien rocks in the solar system is predicted to be substantial
(where the vast majority of such bodies are not biologically active and do not
interact with Earth).
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:44:49 GMT""}]","2022-12-14"
"2205.07800","Zenan Zhu","Zenan Zhu, Seyed Mostafa Rezayat Sorkhabadi, Yan Gu, Wenlong Zhang","Design and Evaluation of an Invariant Extended Kalman Filter for Trunk
  Motion Estimation with Sensor Misalignment","9 pages, 4 figures, submitted to TMECH/AIM 2022",,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  Understanding human motion is of critical importance for health monitoring
and control of assistive robots, yet many human kinematic variables cannot be
directly or accurately measured by wearable sensors. In recent years, invariant
extended Kalman filtering (InEKF) has shown a great potential in nonlinear
state estimation, but its applications to human poses new challenges, including
imperfect placement of wearable sensors and inaccurate measurement models. To
address these challenges, this paper proposes an augmented InEKF design which
considers the misalignment of the inertial sensor at the trunk as part of the
states and preserves the group affine property for the process model.
Personalized lower-extremity forward kinematic models are built and employed as
the measurement model for the augmented InEKF. Observability analysis for the
new InEKF design is presented. The filter is evaluated with three subjects in
squatting, rolling-foot walking, and ladder-climbing motions. Experimental
results validate the superior performance of the proposed InEKF over the
state-of-the-art InEKF. Improved accuracy and faster convergence in estimating
the velocity and orientation of human, in all three motions, are achieved
despite the significant initial estimation errors and the uncertainties
associated with the forward kinematic measurement model.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:45:22 GMT""}]","2022-05-17"
"2205.07801","Cecilia Salgado","Renato Dias Costa and Cec\'ilia Salgado","Large rank jumps on elliptic surfaces and the Hilbert property",,,,,"math.NT math.AG","http://creativecommons.org/licenses/by/4.0/","  Given a rational elliptic surface over a number field, we study the
collection of fibers whose Mordell--Weil rank is greater than the generic rank.
We give conditions on the singular fibers to assure that the collection of
fibers for which the rank jumps of at least 3 is not thin.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:47:20 GMT""}]","2022-05-17"
"2205.07802","Evgenii Nikishin","Evgenii Nikishin, Max Schwarzer, Pierluca D'Oro, Pierre-Luc Bacon,
  Aaron Courville","The Primacy Bias in Deep Reinforcement Learning","ICML 2022; code at https://github.com/evgenii-nikishin/rl_with_resets",,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work identifies a common flaw of deep reinforcement learning (RL)
algorithms: a tendency to rely on early interactions and ignore useful evidence
encountered later. Because of training on progressively growing datasets, deep
RL agents incur a risk of overfitting to earlier experiences, negatively
affecting the rest of the learning process. Inspired by cognitive science, we
refer to this effect as the primacy bias. Through a series of experiments, we
dissect the algorithmic aspects of deep RL that exacerbate this bias. We then
propose a simple yet generally-applicable mechanism that tackles the primacy
bias by periodically resetting a part of the agent. We apply this mechanism to
algorithms in both discrete (Atari 100k) and continuous action (DeepMind
Control Suite) domains, consistently improving their performance.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:48:36 GMT""}]","2022-05-17"
"2205.07803","Hunter Monroe","Hunter Monroe","Average-Case Hardness of Proving Tautologies and Theorems",,,,,"cs.CC math.LO","http://creativecommons.org/licenses/by/4.0/","  We consolidate two widely believed conjectures about tautologies -- no
optimal proof system exists, and most require superpolynomial size proofs in
any system -- into a $p$-isomorphism-invariant condition satisfied by all
paddable $\textbf{coNP}$-complete languages or none. The condition is: for any
Turing machine (TM) $M$ accepting the language, $\textbf{P}$-uniform input
families requiring superpolynomial time by $M$ exist (equivalent to the first
conjecture) and appear with positive upper density in an enumeration of input
families (implies the second). In that case, no such language is easy on
average (in $\textbf{AvgP}$) for a distribution applying non-negligible weight
to the hard families.
  The hardness of proving tautologies and theorems is likely related. Motivated
by the fact that arithmetic sentences encoding ""string $x$ is Kolmogorov
random"" are true but unprovable with positive density in a finitely axiomatized
theory $\mathcal{T}$ (Calude and J{\""u}rgensen), we conjecture that any
propositional proof system requires superpolynomial size proofs for a dense set
of $\textbf{P}$-uniform families of tautologies encoding ""there is no
$\mathcal{T}$ proof of size $\leq t$ showing that string $x$ is Kolmogorov
random"". This implies the above condition.
  The conjecture suggests that there is no optimal proof system because
undecidable theories help prove tautologies and do so more efficiently as
axioms are added, and that constructing hard tautologies seems difficult
because it is impossible to construct Kolmogorov random strings. Similar
conjectures that computational blind spots are manifestations of
noncomputability would resolve other open problems.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:49:59 GMT""},{""version"":""v2"",""created"":""Fri, 8 Jul 2022 15:24:32 GMT""},{""version"":""v3"",""created"":""Wed, 20 Jul 2022 15:14:25 GMT""}]","2022-07-21"
"2205.07804","Ayon Roy","Ayon Roy, Tausif Al Zubayer, Nafisa Tabassum, Muhammad Nazrul Islam,
  Md. Abdus Sattar","CurFi: An automated tool to find the best regression analysis model
  using curve fitting",,,"10.1002/eng2.12522",,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Regression analysis is a well known quantitative research method that
primarily explores the relationship between one or more independent variables
and a dependent variable. Conducting regression analysis manually on large
datasets with multiple independent variables can be tedious. An automated
system for regression analysis will be of great help for researchers as well as
non-expert users. Thus, the objective of this research is to design and develop
an automated curve fitting system. As outcome, a curve fitting system named
""CurFi"" was developed that uses linear regression models to fit a curve to a
dataset and to find out the best fit model. The system facilitates to upload a
dataset, split the dataset into training set and test set, select relevant
features and label from the dataset; and the system will return the best fit
linear regression model after training is completed. The developed tool would
be a great resource for the users having limited technical knowledge who will
also be able to find the best fit regression model for a dataset using the
developed ""CurFi"" system.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:52:10 GMT""}]","2022-05-17"
"2205.07805","Arielle Carr","Stephen Thomas, Erin Carson, Miro Rozlo\v{z}n\'ik, Arielle Carr, Kasia
  \'Swirydowicz","Iterated Gauss-Seidel GMRES","Updates to funding",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The GMRES algorithm of Saad and Schultz (1986) is an iterative method for
approximately solving linear systems $A{\bf x}={\bf b}$, with initial guess
${\bf x}_0$ and residual ${\bf r}_0 = {\bf b} - A{\bf x}_0$. The algorithm
employs the Arnoldi process to generate the Krylov basis vectors (the columns
of $V_k$). It is well known that this process can be viewed as a $QR$
factorization of the matrix $B_k = [\: {\bf r}_0, AV_k\:]$ at each iteration.
Despite an ${O}(\epsilon)\kappa(B_k)$ loss of orthogonality, for unit roundoff
$\epsilon$ and condition number $\kappa$, the modified Gram-Schmidt formulation
was shown to be backward stable in the seminal paper by Paige et al. (2006). We
present an iterated Gauss-Seidel formulation of the GMRES algorithm (IGS-GMRES)
based on the ideas of Ruhe (1983) and \'{S}wirydowicz et al. (2020). IGS-GMRES
maintains orthogonality to the level ${O}(\epsilon)\kappa(B_k)$ or
${O}(\epsilon)$, depending on the choice of one or two iterations; for two
Gauss-Seidel iterations, the computed Krylov basis vectors remain orthogonal to
working precision and the smallest singular value of $V_k$ remains close to
one. The resulting GMRES method is thus backward stable. We show that IGS-GMRES
can be implemented with only a single synchronization point per iteration,
making it relevant to large-scale parallel computing environments. We also
demonstrate that, unlike MGS-GMRES, in IGS-GMRES the relative Arnoldi residual
corresponding to the computed approximate solution no longer stagnates above
machine precision even for highly non-normal systems.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:54:29 GMT""},{""version"":""v2"",""created"":""Mon, 12 Sep 2022 01:52:43 GMT""},{""version"":""v3"",""created"":""Mon, 24 Oct 2022 23:43:22 GMT""},{""version"":""v4"",""created"":""Thu, 23 Feb 2023 02:31:15 GMT""},{""version"":""v5"",""created"":""Mon, 20 Mar 2023 21:24:39 GMT""}]","2023-03-22"
"2205.07806","Bing Shen","Bin Wang, Enkui Yi, Leyi Li, Jianwei Qin, Bing-Feng Hu, Bing Shen, and
  Meng Wang","Magneto-Transport Properties of Kagome Magnet TmMn$_6$Sn$_6$",,"Physical Review B 106.125107 (2022)","10.1103/PhysRevB.106.125107",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Kagome magnet usually hosts nontrivial electronic or magnetic states drawing
great interests in condensed matter physics. In this paper, we report a
systematic study on transport properties of kagome magnet TmMn$_6$Sn$_6$. The
prominent topological Hall effect (THE) has been observed in a wide temperature
region spanning over several magnetic phases and exhibits strong temperature
and field dependence. This novel phenomenon due to non-zero spin chirality
indicates possible appearance of nontrival magnetic states accompanying with
strong fluctuations. The planar applied field drives planar Hall effect(PHE)
and anistropic magnetoresisitivity(PAMR) exhibiting sharp disconnections in
angular dependent planar resistivity violating the empirical law. By using an
effective field, we identify a magnetic transition separating the PAMR into two
groups belonging to various magnetic states. We extended the empirical formula
to scale the field and temperature dependent planar magnetoresistivity and
provide the understandings for planar transport behaviors with the crossover
between various magnetic states. Our results shed lights on the novel transport
effects in presence of multiple nontrivial magnetic states for the kagome
lattice with complicated magnetic structures.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:56:38 GMT""},{""version"":""v2"",""created"":""Tue, 17 May 2022 02:23:42 GMT""}]","2022-11-21"
"2205.07807","Bethan Andrea Williams","Bethan A. Williams, Daniel L. Walker, Steven N. Longmore, A. T.
  Barnes, Cara Battersby, Guido Garay, Adam Ginsburg, Laura Gomez, Jonathan D.
  Henshaw, Luis C. Ho, J. M. Diederik Kruijssen, Xing Lu, Elisabeth A. C.
  Mills, Maya A. Petkova and Qizhou Zhang","The initial conditions for young massive cluster formation in the
  Galactic Centre: convergence of large-scale gas flows",,,"10.1093/mnras/stac1378",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Young massive clusters (YMCs) are compact ($\lesssim$1 pc), high-mass
(>10${}^4$ M${}_{\odot}$) stellar systems of significant scientific interest.
Due to their rarity and rapid formation, we have very few examples of YMC
progenitor gas clouds before star formation has begun. As a result, the initial
conditions required for YMC formation are uncertain. We present high-resolution
(0.13$^{\prime\prime}$, $\sim$1000 au) ALMA observations and Mopra single-dish
data, showing that Galactic Centre dust ridge `Cloud d' (G0.412$+$0.052,
mass$\sim 7.6 \times 10^4$ M$_{\odot}$, radius$\sim 3.2$ pc) has the potential
to become an Arches-like YMC (10$^4$ M$_{\odot}$, r$\sim$1 pc), but is not yet
forming stars. This would mean it is the youngest known pre-star forming
massive cluster and therefore could be an ideal laboratory for studying the
initial conditions of YMC formation. We find 96 sources in the dust continuum,
with masses $\lesssim$3 M$_{\odot}$ and radii of $\sim$10${}^3$ au. The source
masses and separations are more consistent with thermal rather than turbulent
fragmentation. It is not possible to unambiguously determine the dynamical
state of most of the sources, as the uncertainty on virial parameter estimates
is large. We find evidence for large-scale ($\sim$1 pc) converging gas flows,
which could cause the cloud to grow rapidly, gaining 10$^4$ M$_{\odot}$ within
10$^5$ yr. The highest density gas is found at the convergent point of the
large-scale flows. We expect this cloud to form many high-mass stars, but find
no high-mass starless cores. If the sources represent the initial conditions
for star formation, the resulting IMF will be bottom-heavy.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:58:52 GMT""}]","2022-05-25"
"2205.07808","Qiao Xiang","Qiao Xiang, Ridi Wen, Chenyang Huang, Yuxin Wang, Franck Le","Switch as a Verifier: Toward Scalable Data Plane Checking via
  Distributed, On-Device Verification",,,,,"eess.SY cs.NI cs.PL cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data plane verification (DPV) is important for finding network errors.
Current DPV tools employ a centralized architecture, where a server collects
the data planes of all devices and verifies them. Despite substantial efforts
on accelerating DPV, this centralized architecture is inherently unscalable. In
this paper, to tackle the scalability challenge of DPV, we circumvent the
scalability bottleneck of centralized design and design Coral, a distributed,
on-device DPV framework. The key insight of Coral is that DPV can be
transformed into a counting problem on a directed acyclic graph, which can be
naturally decomposed into lightweight tasks executed at network devices,
enabling scalability. Coral consists of (1) a declarative requirement
specification language, (2) a planner that employs a novel data structure DVNet
to systematically decompose global verification into on-device counting tasks,
and (3) a distributed verification (DV) protocol that specifies how on-device
verifiers communicate task results efficiently to collaboratively verify the
requirements. We implement a prototype of Coral. Extensive experiments with
real-world datasets (WAN/LAN/DC) show that Coral consistently achieves scalable
DPV under various networks and DPV scenarios, i.e., up to 1250 times speed up
in the scenario of burst update, and up to 202 times speed up on 80% quantile
of incremental verification, than state-of-the-art DPV tools, with little
overhead on commodity network devices.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:00:49 GMT""},{""version"":""v2"",""created"":""Thu, 23 Jun 2022 06:41:48 GMT""},{""version"":""v3"",""created"":""Fri, 30 Sep 2022 08:37:23 GMT""}]","2022-10-03"
"2205.07809","Eliot Finch","Eliot Finch, Christopher J. Moore","Searching for a Ringdown Overtone in GW150914","12 pages, 9 figures, plus appendices (accepted in Physical Review D
  on 19 July 2022)","Phys. Rev. D 106, 043005 (2022)","10.1103/PhysRevD.106.043005","LIGO document number P2200149","gr-qc astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We reanalyze the GW150914 post-merger data searching for quasinormal modes
beyond the fundamental, quadrupolar mode. There is currently an ongoing
disagreement in the literature about whether, and to what extent, the data
contains evidence for a quasinormal mode overtone. We use a frequency-domain
approach to ringdown data analysis that was recently proposed by the authors.
Our analysis has several advantages compared to other analyses performed mainly
in the time domain; in particular, the source sky position and the ringdown
start time are marginalized over (as opposed to simply being fixed) as part of
a Bayesian ringdown analysis. We find tentative evidence for an overtone in
GW150914, but at a lower significance than reported elsewhere. Our preferred
analysis, marginalizing over the uncertainty in the time of peak strain
amplitude, gives a posterior on the overtone amplitude peaked away from zero at
$\sim 1.8\sigma$.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:03:31 GMT""},{""version"":""v2"",""created"":""Mon, 8 Aug 2022 17:24:45 GMT""}]","2022-08-09"
"2205.07810","Chao Chen","Chao Chen, Atsuhisa Ota","Induced gravitational waves from statistically anisotropic scalar
  perturbations",,,"10.1103/PhysRevD.106.063507",,"astro-ph.CO gr-qc","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Scalar-induced gravitational waves (SIGWs) are attracting growing attention
for probing extremely short-scale scalar perturbations via gravitational wave
measurements. In this paper, we investigate the SIGWs from statistically
anisotropic scalar perturbations, which are motivated in inflationary scenarios
in the presence of, e.g., a vector field. While the ensemble average of the
SIGW energy spectrum is isotropic for the standard statistically isotropic
scalar perturbations, the statistical anisotropy in the source introduces the
multipole moments of the differential SIGW energy spectrum. We consider
quadrupole anisotropy in the scalar power spectrum and show that the SIGW
spectrum has anisotropies up to $\ell=4$. We present generic formulas of the
multipole moments and then apply them to the delta-function-like and log-normal
source spectra. We find analytic expressions for the former case and show that
the infrared scalings of the multipole moments are the same as the isotropic
SIGWs. Interestingly, the monopole has an additional local minimum in the
high-$k$ tail, a key feature to distinguish from the isotropic SIGWs. The
latter log-normal case is analytic for the narrow-peak source, and we perform
the numerical calculation for the broad peak. As one expects, the multipole
moments become broader with increasing source width. Our results are helpful to
test the isotropy of primordial density perturbations at extremely small scales
through SIGWs.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:04:37 GMT""},{""version"":""v2"",""created"":""Wed, 7 Sep 2022 16:16:13 GMT""}]","2022-09-08"
"2205.07811","Colin Gordon","Colin S. Gordon, Sergey Matskevich","Natural Language Specifications in Proof Assistants",,,,,"cs.PL cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Interactive proof assistants are computer programs carefully constructed to
check a human-designed proof of a mathematical claim with high confidence in
the implementation. However, this only validates truth of a formal claim, which
may have been mistranslated from a claim made in natural language. This is
especially problematic when using proof assistants to formally verify the
correctness of software with respect to a natural language specification. The
translation from informal to formal remains a challenging, time-consuming
process that is difficult to audit for correctness. This paper argues that it
is possible to build support for natural language specifications within
existing proof assistants, in a way that complements the principles used to
establish trust and auditability in proof assistants themselves.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:05:45 GMT""}]","2022-05-17"
"2205.07812","Jialiang Sun","Jialiang Sun and Xiaohu Zheng and Wen Yao and Xiaoya Zhang and Weien
  Zhou and Xiaoqian Chen","Heat Source Layout Optimization Using Automatic Deep Learning Surrogate
  and Multimodal Neighborhood Search Algorithm",,,,,"cs.NE","http://creativecommons.org/publicdomain/zero/1.0/","  In satellite layout design, heat source layout optimization (HSLO) is an
effective technique to decrease the maximum temperature and improve the heat
management of the whole system. Recently, deep learning surrogate assisted HSLO
has been proposed, which learns the mapping from layout to its corresponding
temperature field, so as to substitute the simulation during optimization to
decrease the computational cost largely. However, it faces two main challenges:
1) the neural network surrogate for the certain task is often manually designed
to be complex and requires rich debugging experience, which is challenging for
the designers in the engineering field; 2) existing algorithms for HSLO could
only obtain a near optimal solution in single optimization and are easily
trapped in local optimum. To address the first challenge, considering reducing
the total parameter numbers and ensuring the similar accuracy as well as, a
neural architecture search (NAS) method combined with Feature Pyramid Network
(FPN) framework is developed to realize the purpose of automatically searching
for a small deep learning surrogate model for HSLO. To address the second
challenge, a multimodal neighborhood search based layout optimization algorithm
(MNSLO) is proposed, which could obtain more and better approximate optimal
design schemes simultaneously in single optimization. Finally, two typical
two-dimensional heat conduction optimization problems are utilized to
demonstrate the effectiveness of the proposed method. With the similar
accuracy, NAS finds models with 80% fewer parameters, 64% fewer FLOPs and 36%
faster inference time than the original FPN. Besides, with the assistance of
deep learning surrogate by automatic search, MNSLO could achieve multiple near
optimal design schemes simultaneously to provide more design diversities for
designers.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:08:03 GMT""},{""version"":""v2"",""created"":""Mon, 4 Jul 2022 07:15:36 GMT""}]","2022-07-05"
"2205.07813","Niklas Dexheimer","Niklas Dexheimer and Claudia Strauch","On Lasso and Slope drift estimators for L\'evy-driven
  Ornstein--Uhlenbeck processes",,,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the problem of estimating the drift parameter of a
high-dimensional L\'evy-driven Ornstein--Uhlenbeck process under sparsity
constraints. It is shown that both Lasso and Slope estimators achieve the
minimax optimal rate of convergence (up to numerical constants), for tuning
parameters chosen independently of the confidence level, which improves the
previously obtained results for standard Ornstein--Uhlenbeck processes. The
results are nonasymptotic and hold both in probability and conditional
expectation with respect to an event resembling the restricted eigenvalue
condition.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:12:58 GMT""}]","2022-05-17"
"2205.07814","Ankur Das","Ankur Das, Eyal Cornfeld, and Sumiran Pujari","Punctured-Chern topological invariants for semi-metallic bandstructures","Significant revision compared to the previous version with additional
  results on a fragile topological model. Previous results are unaffected.
  Codes are available at
  https://www.dropbox.com/s/wgy3ugj7nfk0c5w/Nexus_2d_3d.nb?dl=0 on how to
  calculate the punctured-Chern numbers in both the 2D and 3D applications
  shown in the paper. 6 pages of main text with 3 figures, 4 pages of
  supplementary text","Phys. Rev. Lett. 130, 186202 (2023)","10.1103/PhysRevLett.130.186202",,"cond-mat.mes-hall cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  Topological insulator-based methods underpin the topological classification
of gapped bands, including those surrounding semi-metallic nodal defects.
However, multiple bands with gap-closing points can also possess non-trivial
topology. We construct a general wavefunction-based ``punctured-Chern""
invariant to capture such topology. To show its general applicability, we
analyze two systems with disparate gapless topology: 1) a recent
two-dimensional fragile topological model to capture the various
band-topological transitions and 2) a three-dimensional model with a
triple-point nodal defect to characterize its semi-metallic topology with
\emph{half-integers} that govern physical observables such as anomalous
transport. This invariant also gives the classification for Nexus triple-points
($\mathbb{Z}\times\mathbb{Z}$) with certain symmetry restrictions, which is
re-confirmed by abstract algebra.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:13:20 GMT""},{""version"":""v2"",""created"":""Tue, 14 Jun 2022 16:17:17 GMT""},{""version"":""v3"",""created"":""Mon, 7 Nov 2022 12:55:55 GMT""}]","2023-05-09"
"2205.07815","Wardah Saleh","Shafin Talukder, SK. Tasnim Bari Ira, Aseya Khanom, Prantika Biswas
  Sneha and Wardah Saleh","Vehicle Collision Detection & Prevention Using VANET Based IoT With V2V","10 pages, 5 figures , 2 tables",,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  EMERGENCY alert in case of any accident is vitally necessitated to rescue the
victims. And so, this paper is made to present the results of a major analysis
relating to emergency alert conditions at the time of collision (automobile).
In this study, the authors have investigated modern Internet of Things (IoT)
and VANET (Vehicular Ad hoc Networks) technologies and developed a collection
of modern and specialized techniques as well as their characteristics. It has
sensors that detect unbalanced circumstances and provide with a warning to the
microcontroller if a collision occurs. Additionally, the technique can be
implemented in such a way that vehicles are alerted of possible closing
barriers. Vehicle-to-Vehicle communication (V2V) has a huge impact since it
allows vehicles to communicate with each other while in proximity and the
buzzer together with the LEDs serves as a safety feature. The primary goal of
the system is to carry out the microcontroller functions in every environment
and moreover, the concept refers to detect and prevent the collision specially
in a foggy weather as well as at night and in other odd circumstances. The
Internet of Things (IoT) and the Vehicular Ad-Hoc Network (VANET) have now been
merged as the fundamental and central components of Intelligent Transportation
System (ITS). Furthermore, while the procedure of obtaining the insurance may
be longer for certain people. On the other hand, others may avoid the law after
being involved in severe collisions which makes it difficult for the
authorities to discriminate between criminal and non-criminal evidence.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:14:23 GMT""}]","2022-05-17"
"2205.07816","Wardah Saleh","Wardah Saleh and Shahrin Chowdhury","RAN Slicing: Towards Multi-Tenancy IN 5G Radio Access Networks","9 pages, 5 figures",,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A significant purpose of 5G networks is allowing sharing resources among
different network tenants such as service providers and Mobile Virtual network
Operators. Numerous domains are taken in account regarding resource sharing
containing different infrastructure (storage, compute and networking), Radio
Access Network (RAN) and Radio Frequency (RF) spectrum. RAN and spectrum,
transport. Spectrum sharing and RAN are anticipated as the fundamental part in
multi-tenant 5G network. Nevertheless, there is a shortage of evaluation
platforms to determine the number of benefits that can be acquired from
multilevel spectrum sharing rather than single-level spectrum sharing. The work
presented in this paper intend to address this issue by presenting a modified
SimuLTE model is used for evaluating active RAN based on multi-tenant 5G
networks. The result shows an understanding into the actual advantages of RAN
slicing for multi-tenants in 5G networks.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:14:36 GMT""}]","2022-05-17"
"2205.07817","Stephen Ebert","Stephen Ebert, Christian Ferko, Hao-Yu Sun, Zhengdi Sun","$T\bar{T}$ in JT Gravity and BF Gauge Theory","92 pages","SciPost Phys. 13, 096 (2022)","10.21468/SciPostPhys.13.4.096",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  JT gravity has a first-order formulation as a two-dimensional BF theory,
which can be viewed as the dimensional reduction of the Chern-Simons
description of $3d$ gravity. We consider $T\bar{T}$-type deformations of the
$(0+1)$-dimensional dual to this $2d$ BF theory and interpret the deformation
as a modification of the BF theory boundary conditions. The fundamental
observables in this deformed BF theory, and in its $3d$ Chern-Simons lift, are
Wilson lines and loops. In the $3d$ Chern-Simons setting, we study
modifications to correlators involving boundary-anchored Wilson lines which are
induced by a $T\bar{T}$ deformation on the $2d$ boundary; results are presented
at both the classical level (using modified boundary conditions) and the
quantum-mechanical level (using conformal perturbation theory). Finally, we
calculate the analogous deformed Wilson line correlators in $2d$ BF theory
below the Hagedorn temperature where the principal series dominates over the
discrete series.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:17:07 GMT""},{""version"":""v2"",""created"":""Fri, 3 Jun 2022 07:39:28 GMT""},{""version"":""v3"",""created"":""Wed, 24 Aug 2022 09:46:07 GMT""}]","2022-10-19"
"2205.07818","Gleydson Chaves Ricarte","Junior da S. Bessa, Jo\~ao Vitor da Silva, Maria N. B. Frederico,
  Gleydson C. Ricarte","Sharp Hessian estimates for fully nonlinear elliptic equations under
  relaxed convexity assumptions, oblique boundary conditions and applications",,"Journal Differential Equations 2023","10.1016/j.jde.2023.05.006",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we derive global estimates for viscosity solutions to fully
nonlinear elliptic equations under relaxed structural assumptions on the
governing operator which are weaker than convexity and oblique boundary
conditions and under suitable assumptions on the dat. Our approach makes use of
geometric tangential methods, which consists of importing ""fine regularity
estimates"" from a limiting profile, i.e., the Recession operator, associated
with the original second order one via compactness and stability procedures. As
a result, we devote a special attention to the borderline scenario. In such a
setting, we prove that solutions enjoy BMO type estimates for their second
derivatives. In the end, as another application of our findings, we obtain
Hessian estimates to obstacle type problems under oblique boundary conditions
and no convexity assumptions, which may have their own mathematical interest. A
density result in a suitable class of viscosity solutions will be also
addressed.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:17:25 GMT""},{""version"":""v2"",""created"":""Wed, 31 May 2023 18:17:56 GMT""}]","2023-06-02"
"2205.07819","Uendert Dos Santos Andrade","Uendert Andrade, Rodrigo S. Gon\c{c}alves, Gabriela C. Carvalho,
  Carlos A. P. Bengaly, Joel C. Carvalho and Jailson Alcaniz","The angular scale of homogeneity with SDSS-IV DR16 Luminous Red Galaxies","13 pages, 4 figures, 3 tables. References updated; matches version
  published in JCAP",,,,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report measurements of the angular scale of cosmic homogeneity
($\theta_{H}$) using the recently released luminous red galaxy sample of the
sixteenth data release of the Sloan Digital Sky Survey (SDSS-IV LRG DR16). It
consists of a model-independent method, as we only use the celestial
coordinates of these objects to carry out such an analysis. The observational
data is divided into thin redshift bins, namely $0.67<z<0.68$, $0.70<z<0.71$,
and $0.73<z<0.74$, in order to avoid projection biases, and we estimate our
uncertainties through a bootstrap method and a suite of mock catalogues. We
find that the LRGs exhibit an angular scale of homogeneity consistent with the
predictions of the standard cosmology within the redshift interval studied.
Considering the bootstrap method, in which the measurements are obtained in a
model-independent way, we found at 1$\sigma$ level that $\theta_H^{boot}(0.675)
= 7.57 \pm 2.91$ deg, $\theta_H^{boot} (0.705) = 7.49 \pm 2.63$ deg and
$\theta_H^{boot} (0.735) = 8.88 \pm 2.81$ deg. Such results are in good
agreement with the ones obtained using mock catalogues built under the
assumption of the standard cosmological model.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:20:12 GMT""},{""version"":""v2"",""created"":""Wed, 26 Oct 2022 18:24:45 GMT""}]","2022-10-28"
"2205.07821","Giuseppina Battaglia","Giuseppina Battaglia and Carlo Nipoti","Stellar dynamics and dark matter in Local Group dwarf galaxies","Invited Review published on May 16, 2022 in Nature Astronomy. The
  Version of Record is available online at
  http://dx.doi.org/10.1038/s41550-022-01638-7",,,,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When interpreted within the standard framework of Newtonian gravity and
dynamics, the kinematics of stars and gas in dwarf galaxies reveals that most
of these systems are completely dominated by their dark matter halos. These
dwarf galaxies are thus among the best astrophysical laboratories to study the
structure of dark halos and the nature of dark matter. We review the properties
of the dwarf galaxies of the Local Group from the point of view of stellar
dynamics. After describing the observed kinematics of their stellar components
and providing an overview of the dynamical modelling techniques, we look into
the dark matter content and distribution of these galaxies, as inferred from
the combination of observed data and dynamical models. We also briefly touch
upon the prospects of using nearby dwarf galaxies as targets for indirect
detection of dark matter via annihilation or decay emission.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:21:40 GMT""}]","2022-05-17"
"2205.07822","Naoya Shimamoto","Naoya Shimamoto","Description of $GL_3$-orbits on the quadruple projective varieties",,,,,"math.RT math.AG","http://creativecommons.org/licenses/by/4.0/","  This article gives a description of the diagonal $GL_3$-orbits on the
quadruple projective variety $(\mathbb P^2)^4$. We give explicit
representatives of orbits, and describe the closure relations of orbits. A
distinguished feature of our setting is that it is the simplest case where
$\mathrm{diag}(GL_n)$ has infinitely many orbits but has an open orbit in the
multiple projective space $(\mathbb P^{n-1})^m$.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:22:18 GMT""}]","2022-05-17"
"2205.07823","Luis Oliver","R. Aleksan, L. Oliver","Remarks on the penguin decay $B_s \to \phi \phi$ with prospects for
  FCCee","49 pages, 12 figures",,,,"hep-ph hep-ex","http://creativecommons.org/publicdomain/zero/1.0/","  We underline the theoretical interest of the vector-vector penguin decay $B_s
\to \phi \phi$, very clean from the experimental point of view. The
CP-violation asymmetry $A_{CP}^{mix}$ comes from the interference of mixing and
decay $\lambda_{\phi \phi} = {q \over p} {\bar{A} \over A}$. In the Standard
Model (SM) and in the Naive Factorization limit, the CP phase from the mixing
${q \over p}$ exactly cancels the CP phase from the decay ratio ${\bar{A} \over
A}$. Therefore, this mode is suitable to look for possible New Physics (NP)
because $A_{CP}^{mix}$ would directly indicate the departure from the SM in
mixing. We estimate the deviation from this cancellation by analyzing possible
small effects in the SM, using in particular the QCD Factorization scheme. We
compare the theoretical expectation for $A_{CP}^{mix}$ to the measurement of
LHCb, and the implications for NP. We pay also special attention to the
transverse amplitude $h = -$, the longitudinal and transverse polarization
fractions, and the interesting helicity-dependent observables $\lambda_{\phi
\phi}^{h=0}$ and $\lambda_{\phi \phi}^{h=-}$. On the other hand, we make an
estimation of the expected sensitivity at the future FCCee experiment for the
CP phase and modulus of $\lambda_{\phi \phi}$. We find $\delta(\mid
\lambda_{\phi \phi}\mid) = 0.004$ and $\delta(\phi_{\phi \phi}) = 0.009$ rad
and, comparing to the LHCb data, we point out the expectations at FCCee in the
search of NP.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:25:47 GMT""},{""version"":""v2"",""created"":""Tue, 24 May 2022 12:02:11 GMT""}]","2022-05-25"
"2205.07824","Jordi Vila-Perez","Jordi Vila-P\'erez, R. Loek Van Heyningen, Ngoc-Cuong Nguyen, Jaume
  Peraire","Exasim: Generating Discontinuous Galerkin Codes for Numerical Solutions
  of Partial Differential Equations on Graphics Processors","19 pages, 4 figures, 3 tables",,,,"cs.MS cs.CE cs.NA math.NA physics.comp-ph physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents an overview of the functionalities and applications of
Exasim, an open-source code for generating high-order discontinuous Galerkin
codes to numerically solve parametrized partial differential equations (PDEs).
The software combines high-level and low-level languages to construct
parametrized PDE models via Julia, Python or Matlab scripts and produce
high-performance C++ codes for solving the PDE models on CPU and Nvidia GPU
processors with distributed memory. Exasim provides matrix-free discontinuous
Galerkin discretization schemes together with scalable reduced basis
preconditioners and Newton-GMRES solvers, making it suitable for accurate and
efficient approximation of wide-ranging classes of PDEs.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:28:28 GMT""}]","2022-05-17"
"2205.07825","Tin Sulejmanpasic","Nakarin Lohitsiri and Tin Sulejmanpasic","Comments on QCD$_3$ and anomalies with fundamental and adjoint matter","33 pages. Added brief comments on large N and T-broken phases in the
  conclusions and section 3.3",,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  't Hooft anomaly matching is powerful for constraining the low energy phases
of gauge theories. In 3d one common anomaly is the parity anomaly in a
$T$-symmetric theory where one cannot gauge the global symmetry group without
breaking the time-reversal symmetry. We find that a $T$-symmetric
$\text{SU}(N)$ gauge theory with either fermionic or bosonic matter in the
fundamental representation of the gauge group has a parity anomaly between the
flavor group and $T$-symmetry provided that there is also a massless Majorana
fermion in the adjoint representation of the gauge group. We then analyze the
parity anomaly in this theory, together with the more recent mod 16
time-reversal anomaly, and give some free fermion proposals as candidates for
the low energy phases consistent with the anomalies. We make brief comments
about the large $N$ limit and the $\T$-broken regimes in the conclusion as well
as related anomalies in 4d. }
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:32:36 GMT""},{""version"":""v2"",""created"":""Tue, 2 Aug 2022 12:36:49 GMT""}]","2022-08-03"
"2205.07826","Igor Nunes","Igor Nunes, Mike Heddes, Tony Givargis, Alexandru Nicolau, Alex
  Veidenbaum","GraphHD: Efficient graph classification using hyperdimensional computing",,,,,"cs.LG cs.NE","http://creativecommons.org/licenses/by/4.0/","  Hyperdimensional Computing (HDC) developed by Kanerva is a computational
model for machine learning inspired by neuroscience. HDC exploits
characteristics of biological neural systems such as high-dimensionality,
randomness and a holographic representation of information to achieve a good
balance between accuracy, efficiency and robustness. HDC models have already
been proven to be useful in different learning applications, especially in
resource-limited settings such as the increasingly popular Internet of Things
(IoT). One class of learning tasks that is missing from the current body of
work on HDC is graph classification. Graphs are among the most important forms
of information representation, yet, to this day, HDC algorithms have not been
applied to the graph learning problem in a general sense. Moreover, graph
learning in IoT and sensor networks, with limited compute capabilities,
introduce challenges to the overall design methodology. In this paper, we
present GraphHD$-$a baseline approach for graph classification with HDC. We
evaluate GraphHD on real-world graph classification problems. Our results show
that when compared to the state-of-the-art Graph Neural Networks (GNNs) the
proposed model achieves comparable accuracy, while training and inference times
are on average 14.6$\times$ and 2.0$\times$ faster, respectively.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:32:58 GMT""}]","2022-05-17"
"2205.07827","Jos\'e Gomes","Allan G.C. Freitas and Jos\'e N.V. Gomes","Compact gradient Einstein-type manifolds with boundary","The manuscript has been considerably improved. We include Proposition
  5 and we improve Theorem 5. Besides, Section 5 is new, where we prove Theorem
  6",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We deal with rigidity results for compact gradient Einstein-type manifolds
with nonempty boundaries. As a result, we obtain new characterizations for
hemispheres and geodesic balls in simply connected space forms. In dimensions
three and five, we obtain topological characterizations for the boundary and
upper bounds for its area.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:33:19 GMT""},{""version"":""v2"",""created"":""Sun, 29 May 2022 17:58:09 GMT""}]","2022-05-31"
"2205.07828","Zhusheng Wang","Zhusheng Wang, Sennur Ulukus","Digital Blind Box: Random Symmetric Private Information Retrieval",,,,,"cs.IT cs.CR cs.DB eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the problem of random symmetric private information retrieval
(RSPIR). In canonical PIR, a user downloads a message out of $K$ messages from
$N$ non-colluding and replicated databases in such a way that no database can
know which message the user has downloaded (user privacy). In SPIR, the privacy
is symmetric, in that, not only that the databases cannot know which message
the user has downloaded, the user itself cannot learn anything further than the
particular message it has downloaded (database privacy). In RSPIR, different
from SPIR, the user does not have an input to the databases, i.e., the user
does not pick a specific message to download, instead is content with any one
of the messages. In RSPIR, the databases need to send symbols to the user in
such a way that the user is guaranteed to download a message correctly (random
reliability), the databases do not know which message the user has received
(user privacy), and the user does not learn anything further than the one
message it has received (database privacy). This is the digital version of a
blind box, also known as gachapon, which implements the above specified setting
with physical objects for entertainment. This is also the blind version of
$1$-out-of-$K$ oblivious transfer (OT), an important cryptographic primitive.
We study the information-theoretic capacity of RSPIR for the case of $N=2$
databases. We determine its exact capacity for the cases of $K = 2, 3, 4$
messages. While we provide a general achievable scheme that is applicable to
any number of messages, the capacity for $K\geq 5$ remains open.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:37:53 GMT""}]","2022-05-17"
"2205.07829","Paula Silva","Paula Raissa Silva, Jo\~ao Vinagre, Jo\~ao Gama","Federated Anomaly Detection over Distributed Data Streams","DSAA'2021 Conference - PhD Track",,,,"cs.LG cs.DC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Sharing of telecommunication network data, for example, even at high
aggregation levels, is nowadays highly restricted due to privacy legislation
and regulations and other important ethical concerns. It leads to scattering
data across institutions, regions, and states, inhibiting the usage of AI
methods that could otherwise take advantage of data at scale. It creates the
need to build a platform to control such data, build models or perform
calculations. In this work, we propose an approach to building the bridge among
anomaly detection, federated learning, and data streams. The overarching goal
of the work is to detect anomalies in a federated environment over distributed
data streams. This work complements the state-of-the-art by adapting the data
stream algorithms in a federated learning setting for anomaly detection and by
delivering a robust framework and demonstrating the practical feasibility in a
real-world distributed deployment scenario.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:38:58 GMT""},{""version"":""v2"",""created"":""Tue, 17 May 2022 07:23:01 GMT""}]","2022-05-18"
"2205.07830","David Wan","David Wan, Mohit Bansal","FactPEGASUS: Factuality-Aware Pre-training and Fine-tuning for
  Abstractive Summarization","NAACL 2022 (19 pages)",,,,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present FactPEGASUS, an abstractive summarization model that addresses the
problem of factuality during pre-training and fine-tuning: (1) We augment the
sentence selection strategy of PEGASUS's (Zhang et al., 2020) pre-training
objective to create pseudo-summaries that are both important and factual; (2)
We introduce three complementary components for fine-tuning. The corrector
removes hallucinations present in the reference summary, the contrastor uses
contrastive learning to better differentiate nonfactual summaries from factual
ones, and the connector bridges the gap between the pre-training and
fine-tuning for better transfer of knowledge. Experiments on three downstream
tasks demonstrate that FactPEGASUS substantially improves factuality evaluated
by multiple automatic metrics and humans. Our thorough analysis suggests that
FactPEGASUS is more factual than using the original pre-training objective in
zero-shot and few-shot settings, retains factual behavior more robustly than
strong baselines, and does not rely entirely on becoming more extractive to
improve factuality. Our code and data are publicly available at:
https://github.com/meetdavidwan/factpegasus
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:39:14 GMT""}]","2022-05-17"
"2205.07831","Niclas Boehmer","Niclas Boehmer, Robert Bredereck, Edith Elkind, Piotr Faliszewski,
  Stanis{\l}aw Szufa","Expected Frequency Matrices of Elections: Computation, Geometry, and
  Preference Learning","Accepted to NeurIPS '22",,,,"cs.GT cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use the ``map of elections'' approach of Szufa et al. (AAMAS-2020) to
analyze several well-known vote distributions. For each of them, we give an
explicit formula or an efficient algorithm for computing its frequency matrix,
which captures the probability that a given candidate appears in a given
position in a sampled vote. We use these matrices to draw the ``skeleton map''
of distributions, evaluate its robustness, and analyze its properties. Finally,
we develop a general and unified framework for learning the distribution of
real-world preferences using the frequency matrices of established vote
distributions.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:40:22 GMT""},{""version"":""v2"",""created"":""Wed, 11 Jan 2023 12:36:30 GMT""}]","2023-01-12"
"2205.07832","Martti Holst Kunzendorf Kristiansen","Martti H. K. Kristiansen, Saul A. Rappaport, Andrew M. Vanderburg,
  Thomas L. Jacobs, Hans Martin Schwengeler, Robert Gagliano, Ivan A. Terentev,
  Daryll M. LaCourse, Mark R. Omohundro, Allan R. Schmitt, Brian P. Powell and
  Veselin B. Kostov","The Visual Survey Group: A Decade of Hunting Exoplanets and Unusual
  Stellar Events with Space-Based Telescopes","14 pages, 5 figures, 2 tables, accepted for publication in PASP",,"10.1088/1538-3873/ac6e06",,"astro-ph.EP astro-ph.IM astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article presents the history of the Visual Survey Group (VSG) - a
Professional-Amateur (Pro-Am) collaboration within the field of astronomy
working on data from several space missions (Kepler, K2 and TESS). This paper
covers the formation of the VSG, its survey-methods including the most common
tools used and its discoveries made over the past decade. So far, the group has
visually surveyed nearly 10 million light curves and authored 69 peer-reviewed
papers which mainly focus on exoplanets and discoveries involving multistellar
systems found using the transit method. The preferred manual search-method
carried out by the VSG has revealed its strength by detecting numerous
sub-stellar objects which were overlooked or discarded by automated search
programs, uncovering some of the most rare stars in our galaxy, and leading to
several serendipitous discoveries of unprecedented astrophysical phenomena. The
main purpose of the VSG is to assist in the exploration of our local Universe,
and we therefore advocate continued crowd-sourced examination of time-domain
data sets, and invite other research teams to reach out in order to establish
collaborating projects.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:42:53 GMT""}]","2022-07-27"
"2205.07833","Yuting Ye","Yuting Ye, Christine Ho, Ci-Ren Jiang, Wayne Tai Lee, Haiyan Huang","Decision Making for Hierarchical Multi-label Classification with
  Multidimensional Local Precision Rate","34 pages, 11 figures, 9 tables",,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Hierarchical multi-label classification (HMC) has drawn increasing attention
in the past few decades. It is applicable when hierarchical relationships among
classes are available and need to be incorporated along with the multi-label
classification whereby each object is assigned to one or more classes. There
are two key challenges in HMC: i) optimizing the classification accuracy, and
meanwhile ii) ensuring the given class hierarchy. To address these challenges,
in this article, we introduce a new statistic called the multidimensional local
precision rate (mLPR) for each object in each class. We show that
classification decisions made by simply sorting objects across classes in
descending order of their true mLPRs can, in theory, ensure the class hierarchy
and lead to the maximization of CATCH, an objective function we introduce that
is related to the area under a hit curve. This approach is the first of its
kind that handles both challenges in one objective function without additional
constraints, thanks to the desirable statistical properties of CATCH and mLPR.
In practice, however, true mLPRs are not available. In response, we introduce
HierRank, a new algorithm that maximizes an empirical version of CATCH using
estimated mLPRs while respecting the hierarchy. The performance of this
approach was evaluated on a synthetic data set and two real data sets; ours was
found to be superior to several comparison methods on evaluation criteria based
on metrics such as precision, recall, and $F_1$ score.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:43:35 GMT""}]","2022-05-17"
"2205.07834","Thaddeus Komacek","Thaddeus D. Komacek, Xianyu Tan, Peter Gao, Elspeth K.H. Lee","Patchy nightside clouds on ultra-hot Jupiters: General Circulation Model
  simulations with radiatively active cloud tracers","41 pages, 23 figures, 2 tables. Re-submitted to ApJ. Co-first authors","The Astrophysical Journal, 934:79, 2022 July 20","10.3847/1538-4357/ac7723",,"astro-ph.EP physics.ao-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The atmospheres of ultra-hot Jupiters have been characterized in detail
through recent phase curve and low- and high-resolution emission and
transmission spectroscopic observations. Previous numerical studies have
analyzed the effect of the localized recombination of hydrogen on the
atmospheric dynamics and heat transport of ultra-hot Jupiters, finding that
hydrogen dissociation and recombination lead to a reduction in the day-to-night
contrasts of ultra-hot Jupiters relative to previous expectations. In this
work, we add to previous efforts by also considering the localized condensation
of clouds in the atmospheres of ultra-hot Jupiters, their resulting transport
by the atmospheric circulation, and the radiative feedback of clouds on the
atmospheric dynamics. To do so, we include radiatively active cloud tracers
into the existing MITgcm framework for simulating the atmospheric dynamics of
ultra-hot Jupiters. We take cloud condensate properties appropriate for the
high-temperature condensate corundum from CARMA cloud microphysics models. We
conduct a suite of GCM simulations with varying cloud microphysical and
radiative properties, and we find that partial cloud coverage is a ubiquitous
outcome of our simulations. This patchy cloud distribution is inherently set by
atmospheric dynamics in addition to equilibrium cloud condensation, and causes
a cloud greenhouse effect that warms the atmosphere below the cloud deck.
Nightside clouds are further sequestered at depth due to a dynamically induced
high-altitude thermal inversion. We post-process our GCMs with the Monte Carlo
radiative transfer code gCMCRT and find that the patchy clouds on ultra-hot
Jupiters do not significantly impact transmission spectra but can affect their
phase-dependent emission spectra.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:43:35 GMT""}]","2022-07-28"
"2205.07835","Prashanth Ramadoss","Prashanth Ramadoss, Lorenzo Rapetti, Yeshasvi Tirupachuri, Riccardo
  Grieco, Gianluca Milani, Enrico Valli, Stefano Dafarra, Silvio Traversaro and
  Daniele Pucci","Whole-Body Human Kinematics Estimation using Dynamical Inverse
  Kinematics and Contact-Aided Lie Group Kalman Filter",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Full-body motion estimation of a human through wearable sensing technologies
is challenging in the absence of position sensors. This paper contributes to
the development of a model-based whole-body kinematics estimation algorithm
using wearable distributed inertial and force-torque sensing. This is done by
extending the existing dynamical optimization-based Inverse Kinematics (IK)
approach for joint state estimation, in cascade, to include a center of
pressure-based contact detector and a contact-aided Kalman filter on Lie groups
for floating base pose estimation. The proposed method is tested in an
experimental scenario where a human equipped with a sensorized suit and shoes
performs walking motions. The proposed method is demonstrated to obtain a
reliable reconstruction of the whole-body human motion.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:44:31 GMT""}]","2022-05-17"
"2205.07836","Henrik Sigstad","Manudeep Bhuller and Henrik Sigstad","2SLS with Multiple Treatments",,,,,"econ.EM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study what two-stage least squares (2SLS) identifies in models with
multiple treatments under treatment effect heterogeneity. Two conditions are
shown to be necessary and sufficient for the 2SLS to identify positively
weighted sums of agent-specific effects of each treatment: average conditional
monotonicity and no cross effects. Our identification analysis allows for any
number of treatments, any number of continuous or discrete instruments, and the
inclusion of covariates. We provide characterizations of choice behavior
implied by our identification conditions and discuss how the conditions can be
tested empirically.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:45:46 GMT""},{""version"":""v2"",""created"":""Tue, 8 Nov 2022 09:38:33 GMT""},{""version"":""v3"",""created"":""Fri, 17 Feb 2023 14:00:58 GMT""},{""version"":""v4"",""created"":""Thu, 20 Apr 2023 11:51:52 GMT""}]","2023-04-21"
"2205.07837","Matteo G. A. Paris","Berihu Teklu, Matteo Bina, and Matteo G. A. Paris","Noisy propagation of Gaussian states in optical media with finite
  bandwidth",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address propagation and entanglement of Gaussian states in optical media
characterised by non-trivial spectral densities. In particular, we consider
environments with a finite bandwidth and show that in the low temperature
regime: i) secular terms in the master equation may be neglected; ii)
attenuation (damping) is strongly suppressed; iii) the overall diffusion
process may be described as a Gaussian noise channel with variance depending
only on the bandwidth. We find several regimes where propagation is not much
detrimental and entanglement may be protected form decoherence.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:46:00 GMT""},{""version"":""v2"",""created"":""Wed, 15 Jun 2022 05:53:22 GMT""}]","2022-06-16"
"2205.07838","Abhilash Mathews","Abhilash Mathews","Physics-informed machine learning techniques for edge plasma turbulence
  modelling in computational theory and experiment","PhD thesis, 172 pages, 38 figures, 4 tables",,,,"physics.plasm-ph cs.LG cs.NA math.NA stat.ML","http://creativecommons.org/licenses/by/4.0/","  Edge plasma turbulence is critical to the performance of magnetic confinement
fusion devices. Towards better understanding edge turbulence in both theory and
experiment, a custom-built physics-informed deep learning framework constrained
by partial differential equations is developed to accurately learn turbulent
fields consistent with the two-fluid theory from partial observations of
electron pressure. This calculation is not otherwise possible using
conventional equilibrium models. With this technique, the first direct
quantitative comparisons of turbulent fields between electrostatic two-fluid
theory and electromagnetic gyrokinetic modelling are demonstrated with good
overall agreement found in magnetized helical plasmas at low normalized
pressure.
  To translate these computational techniques to experimental fusion plasmas, a
novel method to translate brightness measurements of HeI line radiation into
local plasma fluctuations is demonstrated via a newly created deep learning
framework that integrates neutral transport physics and collisional radiative
theory for the $3^3 D - 2^3 P$ transition in atomic helium. Using fast camera
data on the Alcator C-Mod tokamak, this thesis presents the first 2-dimensional
time-dependent experimental measurements of the turbulent electron density,
electron temperature, and neutral density in a fusion plasma using a single
spectral line. With this experimentally inferred data, initial estimates of the
2-dimensional turbulent electric field consistent with drift-reduced Braginskii
theory under the framework of an axisymmetric fusion plasma with purely
toroidal field are calculated. The inclusion of atomic helium effects on
particle and energy sources are found to strengthen correlations between the
electric field and electron pressure while broadening turbulent field
amplitudes which impact ${\bf E \times B}$ flows and shearing rates.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:46:14 GMT""}]","2022-05-17"
"2205.07839","Luke Melas-Kyriazi","Luke Melas-Kyriazi and Christian Rupprecht and Iro Laina and Andrea
  Vedaldi","Deep Spectral Methods: A Surprisingly Strong Baseline for Unsupervised
  Semantic Segmentation and Localization","Published at CVPR 2022. Project Page:
  https://lukemelas.github.io/deep-spectral-segmentation",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unsupervised localization and segmentation are long-standing computer vision
challenges that involve decomposing an image into semantically-meaningful
segments without any labeled data. These tasks are particularly interesting in
an unsupervised setting due to the difficulty and cost of obtaining dense image
annotations, but existing unsupervised approaches struggle with complex scenes
containing multiple objects. Differently from existing methods, which are
purely based on deep learning, we take inspiration from traditional spectral
segmentation methods by reframing image decomposition as a graph partitioning
problem. Specifically, we examine the eigenvectors of the Laplacian of a
feature affinity matrix from self-supervised networks. We find that these
eigenvectors already decompose an image into meaningful segments, and can be
readily used to localize objects in a scene. Furthermore, by clustering the
features associated with these segments across a dataset, we can obtain
well-delineated, nameable regions, i.e. semantic segmentations. Experiments on
complex datasets (Pascal VOC, MS-COCO) demonstrate that our simple spectral
method outperforms the state-of-the-art in unsupervised localization and
segmentation by a significant margin. Furthermore, our method can be readily
used for a variety of complex image editing tasks, such as background removal
and compositing.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:47:44 GMT""}]","2022-05-17"
"2205.07840","Matthew Kvalheim","Matthew D. Kvalheim","Obstructions to asymptotic stabilization","Accepted to SIAM J Control and Optimization",,,,"math.DS math.AT math.DG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Necessary conditions for asymptotic stability and stabilizability of subsets
for dynamical and control systems are obtained. The main necessary condition is
homotopical and is in turn used to obtain a homological one. A certain
extension is ruled out. Questions are posed.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:49:04 GMT""},{""version"":""v2"",""created"":""Tue, 31 May 2022 17:09:37 GMT""},{""version"":""v3"",""created"":""Thu, 27 Oct 2022 00:14:08 GMT""},{""version"":""v4"",""created"":""Mon, 14 Nov 2022 15:47:23 GMT""}]","2022-11-15"
"2205.07841","Hector Pasten","Hector Pasten","On the arithmetic case of Vojta's conjecture with truncated counting
  functions","Updated references",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a Diophantine approximation inequality for rational points in
varieties of any dimension, in the direction of Vojta's conjecture with
truncated counting functions. Our results also provide a bound towards the
$abc$ conjecture which in several cases is subexponential. The main theorem
gives a lower bound for the truncated counting function relative to a divisor
with sufficiently many components, in terms of the proximity to an algebraic
point. Furthermore, we show that the Lang-Waldschmidt conjecture implies a
special case of Vojta's conjecture with truncation in arbitrary dimension. Our
methods are based on the theory of linear forms in logarithms and a geometric
construction.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:50:44 GMT""},{""version"":""v2"",""created"":""Wed, 25 May 2022 00:07:33 GMT""},{""version"":""v3"",""created"":""Mon, 4 Jul 2022 12:36:26 GMT""}]","2022-07-05"
"2205.07842","Cristina Ana-Maria Anghel","Cristina Ana-Maria Anghel","A globalisation of Jones and Alexander polynomials constructed from a
  graded intersection of two Lagrangians in a configuration space","32 pages",,,,"math.GT math.AT","http://creativecommons.org/licenses/by/4.0/","  We consider two Laurent polynomials in two variables associated to a braid,
given by {\em graded intersections} between {\em fixed Lagrangians in
configuration spaces}. In order to get link invariants, we notice that we have
to quotient by a quadratic relation. Then we prove by topological tools that
this relation is sufficient and the first graded intersection gives an
invariant which is the Jones polynomial. This shows a {\em topological model
for the Jones polynomial} and a direct {\em topological proof}\hspace{0.4mm}
that it is a well-defined invariant. The other intersection model in the
quotient turns out to be an invariant globalising the Jones and Alexander
polynomials. This globalisation in the quotient ring is given by a {\em
specific interpolation between the Alexander and Jones polynomials}.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:52:22 GMT""},{""version"":""v2"",""created"":""Mon, 31 Oct 2022 22:43:13 GMT""}]","2022-11-02"
"2205.07843","Vignesh Gopakumar Mr.","Vignesh Gopakumar, Stanislas Pamela, Debasmita Samaddar","Loss Landscape Engineering via Data Regulation on PINNs","13 Pages, 10 Figures. Journal Submission",,,,"cs.LG physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  Physics-Informed Neural Networks have shown unique utility in parameterising
the solution of a well-defined partial differential equation using automatic
differentiation and residual losses. Though they provide theoretical guarantees
of convergence, in practice the required training regimes tend to be exacting
and demanding. Through the course of this paper, we take a deep dive into
understanding the loss landscapes associated with a PINN and how that offers
some insight as to why PINNs are fundamentally hard to optimise for. We
demonstrate how PINNs can be forced to converge better towards the solution, by
way of feeding in sparse or coarse data as a regulator. The data regulates and
morphs the topology of the loss landscape associated with the PINN to make it
easily traversable for the minimiser. Data regulation of PINNs helps ease the
optimisation required for convergence by invoking a hybrid
unsupervised-supervised training approach, where the labelled data pushes the
network towards the vicinity of the solution, and the unlabelled regime
fine-tunes it to the solution.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:54:54 GMT""}]","2022-05-17"
"2205.07844","Laurynas Karazija","Subhabrata Choudhury, Laurynas Karazija, Iro Laina, Andrea Vedaldi,
  Christian Rupprecht","Guess What Moves: Unsupervised Video and Image Segmentation by
  Anticipating Motion","BMVC 2022",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Motion, measured via optical flow, provides a powerful cue to discover and
learn objects in images and videos. However, compared to using appearance, it
has some blind spots, such as the fact that objects become invisible if they do
not move. In this work, we propose an approach that combines the strengths of
motion-based and appearance-based segmentation. We propose to supervise an
image segmentation network with the pretext task of predicting regions that are
likely to contain simple motion patterns, and thus likely to correspond to
objects. As the model only uses a single image as input, we can apply it in two
settings: unsupervised video segmentation, and unsupervised image segmentation.
We achieve state-of-the-art results for videos, and demonstrate the viability
of our approach on still images containing novel objects. Additionally we
experiment with different motion models and optical flow backbones and find the
method to be robust to these change. Project page and code available at
https://www.robots.ox.ac.uk/~vgg/research/gwm.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:55:34 GMT""},{""version"":""v2"",""created"":""Thu, 13 Oct 2022 18:01:37 GMT""}]","2022-10-17"
"2205.07845","Joshua Ziegler","Joshua J. Ziegler, Thomas D. P. Edwards, Anna M. Suliga, Irene
  Tamborra, Shunsaku Horiuchi, Shin'ichiro Ando, Katherine Freese","Non-Universal Stellar Initial Mass Functions: Large Uncertainties in
  Star Formation Rates at $z\approx 2-4$ and Other Astrophysical Probes","15 pages, 11 figures, 1 appendix","MNRAS 517, 2471 (2022)","10.1093/mnras/stac2748","UTTG-05-2022, N3AS-22-007, NORDITA 2022-026","astro-ph.GA astro-ph.CO astro-ph.IM astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We explore the assumption, widely used in many astrophysical calculations,
that the stellar initial mass function (IMF) is universal across all galaxies.
By considering both a canonical Salpeter-like IMF and a non-universal IMF, we
are able to compare the effect of different IMFs on multiple observables and
derived quantities in astrophysics. Specifically, we consider a non-universal
IMF which varies as a function of the local star formation rate, and explore
the effects on the star formation rate density (SFRD), the extragalactic
background light, the supernova (both core-collapse and thermonuclear) rates,
and the diffuse supernova neutrino background. Our most interesting result is
that our adopted varying IMF leads to much greater uncertainty on the SFRD at
$z \approx 2-4$ than is usually assumed. Indeed, we find a SFRD (inferred using
observed galaxy luminosity distributions) that is a factor of $\gtrsim 3$ lower
than canonical results obtained using a universal Salpeter-like IMF. Secondly,
the non-universal IMF we explore implies a reduction in the supernova
core-collapse rate of a factor of $\sim2$, compared against a universal IMF.
The other potential tracers are only slightly affected by changes to the
properties of the IMF. We find that currently available data do not provide a
clear preference for universal or non-universal IMF. However, improvements to
measurements of the star formation rate and core-collapse supernova rate at
redshifts $z \gtrsim 2$ may offer the best prospects for discernment.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:55:53 GMT""}]","2022-11-22"
"2205.07846","Zhite Yu","Jian-Wei Qiu, Zhite Yu","Exclusive production of a pair of high transverse momentum photons in
  pion-nucleon collisions for extracting generalized parton distributions","60 pages, 28 figures; extended reference and some discussions, with
  the main results unchanged",,"10.1007/JHEP08(2022)103",,"hep-ph hep-lat nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that exclusive production of a pair of high transverse momentum
photons in pion-nucleon collisions can be systematically studied in QCD
factorization approach if the photon's transverse momentum $q_T$ with respect
to the colliding pion is much greater than $\Lambda_{\rm QCD}$. We demonstrate
that the leading power non-perturbative contributions to the scattering
amplitudes of this exclusive process are process-independent and can be
systematically factorized into universal pion's distribution amplitudes (DAs)
and nucleon's generalized parton distributions (GPDs), which are convoluted
with corresponding infrared safe and perturbatively calculable short-distance
hard parts. The correction to this factorized expression is suppressed by
powers of $1/q_T$. We demonstrate quantitatively that this new type of
exclusive processes is not only complementary to existing processes for
extracting GPDs, but also capable of providing an enhanced sensitivity to the
dependence of both DAs and GPDs on the active parton's momentum fraction $x$.
We also introduce additional, but the same type of exclusive observables to
enhance our capability to explore GPDs, in particular, their $x$-dependence.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:57:06 GMT""},{""version"":""v2"",""created"":""Wed, 25 May 2022 14:05:56 GMT""}]","2022-08-24"
"2205.07847","Anderson Yoshiaki Iwazaki Anderson","Anderson Yoshiaki Iwazaki, Vinicius dos Santos, Katia Romero
  Felizardo, /'Erica Ferreira de Souza, Natasha M. C. Valentim and Elisa Yumi
  Nakagawa","Benefits and Drawbacks of a Graduate Course: An Experience Teaching
  Systematic Literature Review",,,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Graduate courses can provide specialized knowledge for Ph.D. and Master's
students and contribute to develop their hard and soft skills. At the same
time, Systematic Literature Review (SLR) has been increasingly adopted in the
computing area as a valuable technique to synthesize the state of the art of a
given research topic. However, there is still a poor understanding of the real
benefits and drawbacks of offering the SLR course for graduate students. This
paper reports an experience that examines such benefits and drawbacks, the
difficulties for professors (i.e., educators), and the essential SLR topics to
be taught as well as a way to better teach them. We also surveyed computer
science graduate students who attended the SLR course, which we have offered
for almost ten years for Ph.D. and Master's students in our institution. We
found the attendance to the SLR course is a valuable opportunity for graduate
students to conduct the required deep literature review of their research
topic, improve their research skills, and increase their formation. Hence, we
recommend that Ph.D. and Masters' programs offer the SLR course to contribute
to their academic achievement.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:58:11 GMT""}]","2022-05-17"
"2205.07848","Xin Wang","Zhan Yu, Hongshun Yao, Mujin Li, Xin Wang","Power and limitations of single-qubit native quantum neural networks","22 pages including appendix. To appear at NeurIPS 2022",,,,"quant-ph cond-mat.dis-nn cs.AI cs.LG math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  Quantum neural networks (QNNs) have emerged as a leading strategy to
establish applications in machine learning, chemistry, and optimization. While
the applications of QNN have been widely investigated, its theoretical
foundation remains less understood. In this paper, we formulate a theoretical
framework for the expressive ability of data re-uploading quantum neural
networks that consist of interleaved encoding circuit blocks and trainable
circuit blocks. First, we prove that single-qubit quantum neural networks can
approximate any univariate function by mapping the model to a partial Fourier
series. We in particular establish the exact correlations between the
parameters of the trainable gates and the Fourier coefficients, resolving an
open problem on the universal approximation property of QNN. Second, we discuss
the limitations of single-qubit native QNNs on approximating multivariate
functions by analyzing the frequency spectrum and the flexibility of Fourier
coefficients. We further demonstrate the expressivity and limitations of
single-qubit native QNNs via numerical experiments. We believe these results
would improve our understanding of QNNs and provide a helpful guideline for
designing powerful QNNs for machine learning tasks.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:58:27 GMT""},{""version"":""v2"",""created"":""Thu, 29 Sep 2022 16:25:56 GMT""}]","2022-09-30"
"2205.07849","William Giar\`e","Francesco D'Eramo, Eleonora Di Valentino, William Giar\`e, Fazlollah
  Hajkarim, Alessandro Melchiorri, Olga Mena, Fabrizio Renzi, Seokhoon Yun","Cosmological Bound on the QCD Axion Mass, Redux","22 pages, 9 figures, 5 tables. V2: updated to match the JCAP
  published version","JCAP 09 (2022) 022","10.1088/1475-7516/2022/09/022",,"astro-ph.CO hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We revisit the joint constraints in the mixed hot dark matter scenario in
which both thermally produced QCD axions and relic neutrinos are present. Upon
recomputing the cosmological axion abundance via recent advances in the
literature, we improve the state-of-the-art analyses and provide updated bounds
on axion and neutrino masses. By avoiding approximate methods, such as the
instantaneous decoupling approximation, and limitations due to the limited
validity of the perturbative approach in QCD that forced to artificially divide
the constraints from the axion-pion and the axion-gluon production channels, we
find robust and self-consistent limits. We investigate the two most popular
axion frameworks: KSVZ and DFSZ. From Big Bang Nucleosynthesis (BBN) light
element abundances data we find for the KSVZ axion $\Delta N_{\rm eff}<0.31$
and an axion mass bound $m_a < 0.53 $ eV (i.e., a bound on the axion decay
constant $f_a > 1.07 \times 10^7$ GeV) both at $95\%$ CL. These BBN bounds are
improved to $\Delta N_{\rm eff}<0.14$ and $m_a< 0.16$ eV ($f_a > 3.56 \times
10^7$ GeV) if a prior on the baryon energy density from Cosmic Microwave
Background (CMB) data is assumed. When instead considering cosmological
observations from the CMB temperature, polarization and lensing from the Planck
satellite combined with large scale structure data we find $\Delta N_{\rm
eff}<0.23$, $m_a< 0.28$ eV ($f_a > 2.02 \times 10^7$ GeV) and $\sum m_\nu <
0.16$ eV at $95\%$ CL. This corresponds approximately to a factor of $5$
improvement in the axion mass bound with respect to the existing limits. Very
similar results are obtained for the DFSZ axion. We also forecast upcoming
observations from future CMB and galaxy surveys, showing that they could reach
percent level errors for $m_a\sim 1$ eV.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:58:56 GMT""},{""version"":""v2"",""created"":""Sun, 11 Sep 2022 15:57:57 GMT""}]","2022-09-13"
"2205.07850","Mike Heddes","Mike Heddes, Igor Nunes, Tony Givargis, Alexandru Nicolau, Alex
  Veidenbaum","Hyperdimensional Hashing: A Robust and Efficient Dynamic Hash Table",,,,,"cs.DS cs.DC cs.NI","http://creativecommons.org/licenses/by/4.0/","  Most cloud services and distributed applications rely on hashing algorithms
that allow dynamic scaling of a robust and efficient hash table. Examples
include AWS, Google Cloud and BitTorrent. Consistent and rendezvous hashing are
algorithms that minimize key remapping as the hash table resizes. While memory
errors in large-scale cloud deployments are common, neither algorithm offers
both efficiency and robustness. Hyperdimensional Computing is an emerging
computational model that has inherent efficiency, robustness and is well suited
for vector or hardware acceleration. We propose Hyperdimensional (HD) hashing
and show that it has the efficiency to be deployed in large systems. Moreover,
a realistic level of memory errors causes more than 20% mismatches for
consistent hashing while HD hashing remains unaffected.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:58:56 GMT""}]","2022-05-17"
"2205.07887","Chia Wei Hsu","Ho-Chun Lin, Zeyu Wang, Chia Wei Hsu","Fast multi-source nanophotonic simulations using augmented partial
  factorization",,"Nature Computational Science 2, 815 (2022)","10.1038/s43588-022-00370-6",,"physics.optics cond-mat.dis-nn physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Full-wave simulations are indispensable for nanophotonics and
electromagnetics but are severely constrained on large systems, especially
multi-channel ones such as disordered media, aperiodic metasurfaces, and
densely packed photonic circuits where each input requires a large-scale
simulation. Here we bypass the computationally demanding solution of Maxwell's
equations and directly evaluate the full-wave multi-input response, with no
approximation. We augment the Maxwell operator with all input source profiles
and output projection profiles, followed by a single partial factorization that
directly yields the entire multi-input scattering matrix via the Schur
complement. This method is simple to implement and applies to any linear
partial differential equation. Its advantage grows with size, being 1,000 to
30,000,000 times faster than existing methods for systems with about ten
million variables. We use it to realize the first full-wave simulations of
entangled-photon backscattering from disorder and all-angle characterizations
of high-numerical-aperture metalenses that are thousands of wavelengths wide.
This work reveals the significant efficiency gain when we rethink what to
compute and enables the exploration of diverse multi-channel systems.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 21:23:33 GMT""},{""version"":""v2"",""created"":""Wed, 29 Jun 2022 16:46:39 GMT""}]","2022-12-21"
"2205.07889","Mohamed Jakha","S. Mouslih, M. Jakha, S. El Asri, S. Taj, B. Manaut, R. Benbrik and E
  Siher","Laser-assisted charged Higgs boson decay in Two Higgs Doublet Model --
  type II","17 pages, 7 figures, 1 table",,"10.1016/j.physletb.2022.137339",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  In this paper, we investigate the charged Higgs boson decay in the context of
the type-II two-Higgs-doublet model in the presence of a circularly polarized
electromagnetic field of laser radiation. The calculations are performed by
adopting the Furry picture approach of non-perturbative interactions with the
external electromagnetic field. Using the method of exact solutions for charged
particles states in the presence of a circularly polarized electromagnetic wave
field and evaluating the $S$-matrix elements, an exact analytic expression is
derived for the decay width of leptonic, hadronic and bosonic decay modes. The
branching ratios of different decay modes with multiple photon emission and
absorption from the laser beam are analyzed and found to be dramatically
modified in the region of superstrong fields. The dependencies of the decay
width on the laser field strength and frequency are also examined. The results
obtained may be interesting for future experimental and theoretical
investigations.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 16:58:37 GMT""}]","2022-09-14"
"2205.07890","Adam Dziedzic","Adam Dziedzic, Nikita Dhawan, Muhammad Ahmad Kaleem, Jonas Guan,
  Nicolas Papernot","On the Difficulty of Defending Self-Supervised Learning against Model
  Extraction","Accepted at ICML 2022",,,,"cs.LG cs.AI cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Self-Supervised Learning (SSL) is an increasingly popular ML paradigm that
trains models to transform complex inputs into representations without relying
on explicit labels. These representations encode similarity structures that
enable efficient learning of multiple downstream tasks. Recently,
ML-as-a-Service providers have commenced offering trained SSL models over
inference APIs, which transform user inputs into useful representations for a
fee. However, the high cost involved to train these models and their exposure
over APIs both make black-box extraction a realistic security threat. We thus
explore model stealing attacks against SSL. Unlike traditional model extraction
on classifiers that output labels, the victim models here output
representations; these representations are of significantly higher
dimensionality compared to the low-dimensional prediction scores output by
classifiers. We construct several novel attacks and find that approaches that
train directly on a victim's stolen representations are query efficient and
enable high accuracy for downstream models. We then show that existing defenses
against model extraction are inadequate and not easily retrofitted to the
specificities of SSL.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:20:44 GMT""},{""version"":""v2"",""created"":""Thu, 2 Jun 2022 17:14:02 GMT""},{""version"":""v3"",""created"":""Wed, 29 Jun 2022 15:13:23 GMT""}]","2022-06-30"
"2205.07891","Kensuke Gallock-Yoshimura","Kendra Bueley, Luosi Huang, Kensuke Gallock-Yoshimura, Robert B. Mann","Harvesting mutual information from BTZ black hole spacetime","10 pages, 4 figures; v2: fixed typos","Phys. Rev. D 106, 025010 (2022)","10.1103/PhysRevD.106.025010",,"quant-ph gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the correlation harvesting protocol for mutual information
between two Unruh-DeWitt detectors in a static BTZ black hole spacetime. Here,
the effects coming from communication and change in proper separation of the
detectors are set to be negligible so that only a black hole affects the
extracted mutual information. We find that, unlike the entanglement harvesting
scenario, harvested mutual information is zero only when a detector reaches an
event horizon, and that although the Hawking effect and gravitational redshift
both affect the extraction of mutual information, it is extreme Hawking
radiation that inhibits the detectors from harvesting.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:00:00 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jul 2022 18:25:04 GMT""}]","2022-07-25"
"2205.07892","Tianqing Zhang","Tianqing Zhang, Husni Almoubayyed, Rachel Mandelbaum, Joshua E.
  Meyers, Mike Jarvis, Arun Kannawadi, Morgan A. Schmitz, Axel Guinot, The LSST
  Dark Energy Science Collaboration","Impact of Point Spread Function Higher Moments Error on Weak
  Gravitational Lensing II: A Comprehensive Study","24 pages, 17 figures, 3 tables; Accepted by MNRAS; Comments welcome!","MNRAS, 520, 2328 - 2350 (2023)","10.1093/mnras/stac3350",,"astro-ph.CO astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  Weak gravitational lensing, or weak lensing, is one of the most powerful
probes for dark matter and dark energy science, although it faces increasing
challenges in controlling systematic uncertainties as \edit{the statistical
errors become smaller}. The Point Spread Function (PSF) needs to be precisely
modeled to avoid systematic error on the weak lensing measurements. The weak
lensing biases induced by errors in the PSF model second moments, i.e., its
size and shape, are well-studied. However, Zhang et al. (2021) showed that
errors in the higher moments of the PSF may also be a significant source of
systematics for upcoming weak lensing surveys. Therefore, the goal of this work
is to comprehensively investigate the modeling quality of PSF moments from the
$3^{\text{rd}}$ to $6^{\text{th}}$ order, and estimate their impact on
cosmological parameter inference. We propagate the \textsc{PSFEx} higher
moments modeling error in the HSC survey dataset to the weak lensing
\edit{shear-shear correlation functions} and their cosmological analyses. We
find that the overall multiplicative shear bias associated with errors in PSF
higher moments can cause a $\sim 0.1 \sigma$ shift on the cosmological
parameters for LSST Y10. PSF higher moment errors also cause additive biases in
the weak lensing shear, which, if not accounted for in the cosmological
parameter analysis, can induce cosmological parameter biases comparable to
their $1\sigma$ uncertainties for LSST Y10. We compare the \textsc{PSFEx} model
with PSF in Full FOV (\textsc{Piff}), and find similar performance in modeling
the PSF higher moments. We conclude that PSF higher moment errors of the future
PSF models should be reduced from those in current methods to avoid a need to
explicitly model these effects in the weak lensing analysis.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:00:00 GMT""},{""version"":""v2"",""created"":""Tue, 18 Apr 2023 18:56:13 GMT""}]","2023-04-20"
"2205.07893","Andrea Antonelli","Jonathan R. Gair, Andrea Antonelli and Riccardo Barbieri","A Fisher matrix for gravitational-wave population inference","14 pages, 4 figures; the results can be reproduced using codes at
  https://github.com/aantonelli94/PopFisher. v2: published version, new
  sections and appendices added during the peer-review process",,"10.1093/mnras/stac3560",,"gr-qc astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We derive a Fisher matrix for the parameters characterising a population of
gravitational-wave events. This provides a guide to the precision with which
population parameters can be estimated with multiple observations, which
becomes increasingly accurate as the number of events and the signal-to-noise
ratio of the sampled events increases. The formalism takes into account
individual event measurement uncertainties and selection effects, and can be
applied to arbitrary population models. We illustrate the framework with two
examples: an analytical calculation of the Fisher matrix for the mean and
variance of a Gaussian model describing a population affected by selection
effects, and an estimation of the precision with which the slope of a power law
distribution of supermassive black-hole masses can be measured using
extreme-mass-ratio inspiral observations. We compare the Fisher predictions to
results from Monte Carlo analyses, finding very good agreement.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:00:00 GMT""},{""version"":""v2"",""created"":""Thu, 8 Dec 2022 11:10:32 GMT""}]","2022-12-14"
"2205.07894","Craig Pellegrino","C. Pellegrino, D. A. Howell, G. Terreran, I. Arcavi, K. A. Bostroem,
  P. J. Brown, J. Burke, Y. Dong, A. Gilkis, D. Hiramatsu, G. Hosseinzadeh, C.
  McCully, M. Modjaz, M. Newsome, E. Padilla Gonzalez, T. A. Pritchard, D. J.
  Sand, S. Valenti, and M. Williamson","The Diverse Properties of Type Icn Supernovae Point to Multiple
  Progenitor Channels","25 pages, 11 figures, published in ApJ","The Astrophysical Journal, Volume 938, page 73, 2020","10.3847/1538-4357/ac8ff6",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a sample of Type Icn supernovae (SNe Icn), a newly-discovered
class of transients characterized by their interaction with H- and He-poor
circumstellar material (CSM). This sample is the largest collection of SNe Icn
to date and includes observations of two published objects (SN 2019hgp and SN
2021csp) as well as two objects (SN 2019jc and SN 2021ckj) not yet published in
the literature. The SNe Icn display a range of peak luminosities, rise times,
and decline rates, as well as diverse late-time spectral features. To
investigate their explosion and progenitor properties we fit their bolometric
light curves to a semi-analytical model consisting of luminosity inputs from
circumstellar interaction and radioactive decay of $^{56}$Ni. We infer low
ejecta masses ($\lesssim$ 2 M$_\odot$) and $^{56}$Ni masses ($\lesssim$ 0.04
M$_\odot$) from the light curves, suggesting that normal stripped-envelope
supernova (SESN) explosions within a dense CSM cannot be the underlying
mechanism powering SNe Icn. Additionally, we find that an upper limit on the
star formation rate density at the location of SN 2019jc lies at the lower end
of a distribution of SESNe, in conflict with a massive star progenitor of this
object. Based on the estimated ejecta masses, $^{56}$Ni masses, and explosion
site properties, we favor a low-mass, ultra-stripped star as the progenitor of
some SNe Icn. For others, we suggest that a Wolf-Rayet star progenitor may
better explain their observed properties. This study demonstrates that multiple
progenitor channels may produce SNe Icn and other interaction-powered
transients.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 17 Oct 2022 18:14:35 GMT""}]","2022-10-19"
"2205.07895","Richard Parker","Emma C. Daffern-Powell (1), Richard J. Parker (1) and Sascha P. Quanz
  (2) (1. University of Sheffield, UK, 2. ETH Zurich, Switzerland)","The Great Planetary Heist: Theft and capture in star-forming regions","15 pages, 10 figures, 1 appendix, accepted for publication in MNRAS",,"10.1093/mnras/stac1392",,"astro-ph.EP astro-ph.GA astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Gravitational interactions in star-forming regions are capable of disrupting
and destroying planetary systems, as well as creating new ones. In particular,
a planet can be stolen, where it is directly exchanged between passing stars
during an interaction; or captured, where a planet is first ejected from its
birth system and is free-floating for a period of time, before being captured
by a passing star. We perform sets of direct N-body simulations of young,
substructured star-forming regions, and follow their evolution for 10 Myr in
order to determine how many planets are stolen and captured, and their
respective orbital properties. We show that in high density star-forming
regions, stolen and captured planets have distinct properties. The semimajor
axis distribution of captured planets is significantly skewed to wider orbits
compared to the semimajor axis distribution of stolen planets and planets that
are still orbiting their parent star (preserved planets). However, the
eccentricity and inclination distributions of captured and stolen planets are
similar, but in turn very different to the inclination and eccentricity
distributions of preserved planets. In low-density star-forming regions these
differences are not as distinct but could still, in principle, be used to
determine whether observed exoplanets have likely formed in situ or have been
stolen or captured. We find that the initial degree of spatial and kinematic
substructure in a star-forming region is as important a factor as the stellar
density in determining whether a planetary system will be altered, disrupted,
captured or stolen.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:00:01 GMT""}]","2022-06-01"
"2205.07896","Eike M\""uller","Ricardo Z. Ferreira, M.C. David Marsh, Eike M\""uller","Strong supernovae bounds on ALPs from quantum loops","36 pages, 10 figures. Changes in v2: gravitational redshift taken
  into account, small corrections. This is an author-created, un-copyedited
  version of an article published in JCAP. IOP Publishing Ltd is not
  responsible for any errors or omissions in this version of the manuscript or
  any version derived from it","JCAP11(2022)057","10.1088/1475-7516/2022/11/057",,"hep-ph astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We show that in theories of axionlike particles (ALPs) coupled to electrons
at tree-level, the one-loop effective coupling to photons is process dependent:
the effective coupling relevant for decay processes,
$g_{a\gamma}^{\text{(D)}}$, differs significantly from the coupling appearing
in the phenomenologically important Primakoff process,
$g_{a\gamma}^{\text{(P)}}$. We show that this has important implications for
the physics of massive ALPs in hot and dense environments, such as supernovae.
We derive, as a consequence, new limits on the ALP-electron coupling,
$\hat{g}_{ae}$, from SN 1987A by accounting for all relevant production
processes, including one-loop processes, and considering bounds from excess
cooling as well as the absence of an associated gamma-ray burst from ALP
decays. Our limits are among the strongest to date for ALP masses in the range
$0.03 \, \text{MeV} \, < m_a< 240 \, \text{MeV}$. Moreover, we also show how
cosmological bounds on the ALP-photon coupling translate into new, strong
limits on $\hat{g}_{ae}$ at one loop. Our analysis emphasises that large
hierarchies between ALP effective couplings are difficult to realise once
quantum loops are taken into account.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:00:01 GMT""},{""version"":""v2"",""created"":""Fri, 25 Nov 2022 09:52:18 GMT""}]","2022-11-29"
"2205.07897","Zheng Zhou","Zheng Zhou and Yin-Chen He","Slightly broken higher-spin current in bosonic and fermionic QED in the
  large-$N$ limit","25 pages",,,,"hep-th cond-mat.stat-mech cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the slightly broken higher-spin currents in various CFTs with
$\mathrm{U}(1)$ gauge field, including the tricritical QED, scalar QED,
fermionic QED and QED-Gross-Neveu-Yukawa theory. We calculate their anomalous
dimension by making use of the classical non-conservation equation and the
equations of motion. We find a logarithmic asymptotic behaviour ($\gamma_s\sim
16/(N\pi^2) \log s $) of the anomalous dimension at large spin $s$, which is
different from other interacting CFTs without gauge fields and may indicate
certain unique features of gauge theories. We also study slightly broken
higher-spin currents of the $\mathrm{SU}(N)_1$ WZW model at $d=2+\epsilon$
dimensions by formulating them as the QED theory, and we again find its
anomalous dimension has a logarithmic asymptotic behaviour with respect to
spin. This result resolves the mystery regarding the mechanism of breaking
higher spin currents of Virasoro symmetry at $d=2+\epsilon$ dimensions, and may
be applicable to other interesting problems such as the $2+\epsilon$ expansion
of Ising CFT.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:00:01 GMT""},{""version"":""v2"",""created"":""Wed, 31 May 2023 16:28:35 GMT""}]","2023-06-01"
"2205.07898","Davide Piras","Davide Piras, Benjamin Joachimi, Francisco Villaescusa-Navarro","Fast and realistic large-scale structure from machine-learning-augmented
  random field simulations","16 pages, 11 figures. Matches MNRAS published version, which includes
  more tests with e.g. varying cosmological parameters","Monthly Notices of the Royal Astronomical Society, Volume 520,
  Issue 1, March 2023, Pages 668-683","10.1093/mnras/stad052",,"astro-ph.CO astro-ph.IM cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Producing thousands of simulations of the dark matter distribution in the
Universe with increasing precision is a challenging but critical task to
facilitate the exploitation of current and forthcoming cosmological surveys.
Many inexpensive substitutes to full $N$-body simulations have been proposed,
even though they often fail to reproduce the statistics of the smaller,
non-linear scales. Among these alternatives, a common approximation is
represented by the lognormal distribution, which comes with its own limitations
as well, while being extremely fast to compute even for high-resolution density
fields. In this work, we train a generative deep learning model, mainly made of
convolutional layers, to transform projected lognormal dark matter density
fields to more realistic dark matter maps, as obtained from full $N$-body
simulations. We detail the procedure that we follow to generate highly
correlated pairs of lognormal and simulated maps, which we use as our training
data, exploiting the information of the Fourier phases. We demonstrate the
performance of our model comparing various statistical tests with different
field resolutions, redshifts and cosmological parameters, proving its
robustness and explaining its current limitations. When evaluated on 100 test
maps, the augmented lognormal random fields reproduce the power spectrum up to
wavenumbers of $1 \ h \ \rm{Mpc}^{-1}$, and the bispectrum within 10%, and
always within the error bars, of the fiducial target simulations. Finally, we
describe how we plan to integrate our proposed model with existing tools to
yield more accurate spherical random fields for weak lensing analysis.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:00:01 GMT""},{""version"":""v2"",""created"":""Wed, 1 Feb 2023 16:33:32 GMT""}]","2023-02-02"
"2205.07899","Alberto Masini","Alberto Masini, J. V. Wijesekera, Annalisa Celotti, Peter G. Boorman","A comprehensive X-ray view of the active nucleus in NGC 4258","Accepted for publication in A&A. 14 pages, 6 figures, 3 tables","A&A 663, A87 (2022)","10.1051/0004-6361/202243231",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  (Abridged) We present a detailed broadband X-ray spectrum of NGC 4258, with
the goal of precisely measuring the coronal luminosity and accretion flow
properties of the AGN, and track any possible variation across two decades of
observations. We collect archival XMM-Newton, Chandra, Swift/BAT and NuSTAR
spectroscopic observations spanning 15 years, and fit them with a suite of
state of the art models, including a warped disk model which is suspected to
provide the well known obscuration observed in the X-rays. We complement this
information with archival results from the literature. Clear spectral
variability is observed among the different epochs. The obscuring column
density shows possibly periodic fluctuations on a timescale of 10 years, while
the intrinsic luminosity displays a long term decrease of a factor of three in
a time span of 15 years (from $L_{2-10~\text{keV}} \sim 10^{41}$ erg s$^{-1}$
in the early 2000s, to $L_{2-10~\text{keV}} \sim 3 \times 10^{40}$ erg s$^{-1}$
in 2016). The average absorption-corrected X-ray luminosity
$L_{2-10~\text{keV}}$, combined with archival determinations of the bolometric
luminosity, implies a bolometric correction $k_{\rm bol} \sim 20$, intriguingly
typical for Seyferts powered by accretion through geometrically thin,
radiatively efficient disks. Moreover, the X-ray photon index $\Gamma$ is
consistent with the typical value of the broader AGN population. However, the
accretion rate in Eddington units is very low, well within the expected RIAF
regime. Our results suggest that NGC 4258 is a genuinely low-luminosity Seyfert
II, with no strong indications in its X-ray emission for a hot, RIAF-like
accretion flow.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:00:02 GMT""}]","2022-07-20"
"2205.07900","Johannes Mitscherling","Bruno Mera and Johannes Mitscherling","Nontrivial quantum geometry of degenerate flat bands","6+15 pages (including Supplemental Material), 2+2 figures; closer to
  published version","Phys. Rev. B 106, 165133 (2022)","10.1103/PhysRevB.106.165133",,"cond-mat.mes-hall cond-mat.mtrl-sci cond-mat.quant-gas math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The importance of the quantum metric in flat-band systems has been noticed
recently in many contexts such as the superfluid stiffness, the dc electrical
conductivity, and ideal Chern insulators. Both the quantum metric of degenerate
and nondegenerate bands can be naturally described via the geometry of
different Grassmannian manifolds, specific to the band degeneracies. Contrary
to the (Abelian) Berry curvature, the quantum metric of a degenerate band
resulting from the collapse of a collection of bands is not simply the sum of
the individual quantum metrics. We provide a physical interpretation of this
phenomenon in terms of transition dipole matrix elements between two bands. By
considering a toy model, we show that the quantum metric gets enhanced,
reduced, or remains unaffected depending on which bands collapse. The dc
longitudinal conductivity and the superfluid stiffness are known to be
proportional to the quantum metric for flat-band systems, which makes them
suitable candidates for the observation of this phenomenon.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:00:02 GMT""},{""version"":""v2"",""created"":""Tue, 8 Nov 2022 22:33:22 GMT""}]","2022-11-10"
"2205.07901","Johannes Feldmeier","Johannes Feldmeier, William Witczak-Krempa, Michael Knap","Emergent tracer dynamics in constrained quantum systems","17 pages, 10 figures","Phys. Rev. B 106, 094303 (2022)","10.1103/PhysRevB.106.094303",,"cond-mat.str-el cond-mat.stat-mech quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show how the tracer motion of tagged, distinguishable particles can
effectively describe transport in various homogeneous quantum many-body systems
with constraints. We consider systems of spinful particles on a one-dimensional
lattice subjected to constrained spin interactions, such that some or even all
multipole moments of the effective spin pattern formed by the particles are
conserved. On the one hand, when all moments - and thus the entire spin pattern
- are conserved, dynamical spin correlations reduce to tracer motion
identically, generically yielding a subdiffusive dynamical exponent $z=4$. This
provides a common framework to understand the dynamics of several constrained
lattice models, including models with XNOR or $tJ_z$ - constraints. We consider
random unitary circuit dynamics with such a conserved spin pattern and use the
tracer picture to obtain exact expressions for their late-time dynamical
correlations. Our results can also be extended to integrable quantum many-body
systems that feature a conserved spin pattern but whose dynamics is insensitive
to the pattern, which includes for example the folded XXZ spin chain. On the
other hand, when only a finite number of moments of the pattern are conserved,
the dynamics is described by a convolution of the internal hydrodynamics of the
spin pattern with a tracer distribution function. As a consequence, we find
that the tracer universality is robust in generic systems if at least the
quadrupole moment of the pattern remains conserved. In cases where only total
magnetization and dipole moment of the pattern are constant, we uncover an
intriguing coexistence of two processes with equal dynamical exponent but
different scaling functions, which we relate to phase coexistence at a first
order transition.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:00:02 GMT""}]","2022-10-20"
"2205.07902","Xiaojun Yao","Xiaojun Yao","Quantum Simulation of Light-Front QCD for Jet Quenching in Nuclear
  Environments","56 pages, 9 figures; v2: add a section on the simulation of the LPM
  effect in gluon radiation; v3: added more discussions in introduction,
  modified discussions of simulation results",,,"MIT-CTP 5435, IQuS@UW-21-037","hep-ph hep-lat nucl-th quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a framework to simulate jet quenching in nuclear environments on a
quantum computer. The formulation is based on the light-front Hamiltonian
dynamics of QCD. The Hamiltonian consists of three parts relevant for jet
quenching studies: kinetic, diffusion and splitting terms. In the basis made up
of $n$-particle states in momentum space, the kinetic Hamiltonian is diagonal.
Matrices representing the diffusion and splitting parts are sparse. The
diffusion part of the Hamiltonian depends on classical background gauge fields,
which need to be sampled classically before constructing quantum circuits for
the time evolution. The cost of the sampling scales linearly with the time
length of the evolution and the momentum grid volume. The framework
automatically keeps track of quantum interference and thus it can be applied to
study the Landau-Pomeranchuk-Migdal effect in cases with more than two coherent
splittings, which is beyond the scope of state-of-the-art analyses, no matter
whether the medium is static or expanding, thin or thick, hot or cold. We apply
this framework to study a toy model and gluon in-medium radiation on a small
lattice. The essence of the Landau-Pomeranchuk-Migdal effect is observed in the
quantum simulation results of both the toy model and the gluon case, which is
quantum decoherence caused by medium interactions that suppresses the total
radiation probability.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:00:02 GMT""},{""version"":""v2"",""created"":""Tue, 8 Nov 2022 23:26:09 GMT""},{""version"":""v3"",""created"":""Tue, 27 Dec 2022 07:54:36 GMT""}]","2022-12-29"
"2205.07903","Mir Afrasiar","Mir Afrasiar, Jaydeep Kumar Basak, Ashish Chandra and Gautam Sengupta","Islands for Entanglement Negativity in Communicating Black Holes","72 pages, 32 figures and 1 appendix, v2: Citations added, Minor
  modifications",,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We obtain the holographic entanglement negativity for bipartite mixed states
at a finite temperature in baths described by conformal field theories dual to
configurations involving two communicating black holes in braneworld
geometries. In this context we analyze the mixed state entanglement structure
characterized by the information transfer between the black holes for two
separate models. The first model involves communicating black holes in a
Karch-Randall braneworld and $BCFT_2$s with two boundaries describing common
bath systems for the radiation flux. The second model corresponds to a
configuration of two dimensional eternal JT black holes in a braneworld
geometry involving two Planck branes coupled through shared bath systems
described by $CFT_2$s. For both the models our results reproduce analogue of
the Page curves for the entanglement negativity obtained earlier in the context
of random matrix theory and from geometric evaporation in JT black hole
configurations.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:00:03 GMT""},{""version"":""v2"",""created"":""Fri, 3 Jun 2022 13:37:17 GMT""}]","2022-06-06"
"2205.07904","Riccardo Middei","R. Middei, A. Marinucci, V. Braito, S. Bianchi, B. De Marco, A.
  Luminari, G. Matt, E. Nardini, M. Perri, J. N. Reeves, F. Vagnetti","The lively accretion disk in NGC 2992. II. The 2019/2021 X-ray
  monitoring campaigns","21 pages, 17 figures. Accepted for publication in MNRAS",,"10.1093/mnras/stac1381",,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on the short and long term X-ray properties of the bright nearby
Seyfert 2 galaxy NGC 2992, which was extensively observed with Swift,
XMM-Newton and NuSTAR. Swift targeted the source more than 100 times between
2019 and 2021 in the context of two monitoring campaigns. Both time-averaged
and time-resolved analyses are performed, and we find that the short-to-long
term spectral properties of NGC 2992 are dominated by a highly variable nuclear
continuum. The source varied in the 2-10 keV energy band from 0.6 to 12
$\times$ 10$^{-11}$ erg cm$^{-2}$ s$^{-1}$ during the two year long Swift
monitoring. The fastest 2-10 keV flux change (by a factor of $\sim60\%$)
occurred on a timescale of a few hours. The overall emission spectrum of the
source is consistent with a power law-like continuum ($\Gamma=1.69\pm0.01$)
absorbed by a constant line-of-sight column density N$_{H}=(7.8\pm0.1)\times$
10$^{21}$ $\rm cm^{-2}$. The reflected emission is likely due to matter with an
average column density N$_{\rm H}=(9.6\pm2.7)\times$ 10$^{22}$ $\rm cm^{-2}$,
thus NGC 2992 appears to have a globally Compton-thin circumnuclear medium.
This scenario is fully supported by an independent analysis of the fractional
variability and by XMM-Newton multi-year spectra.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:00:03 GMT""}]","2022-05-25"
"2205.07905","Vinayak Raj","Debarshi Basu, Himanshu Parihar, Vinayak Raj and Gautam Sengupta","Defect extremal surfaces for entanglement negativity","45 pages, 25 figures",,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a doubly holographic version of the semi-classical island formula
for the entanglement negativity in the framework of the defect AdS/BCFT
correspondence where the AdS bulk contains a defect conformal matter theory. In
this context, we propose a defect extremal surface (DES) formula for computing
the entanglement negativity modified by the contribution from the defect matter
theory on the end-of-the-world brane. The equivalence of the DES proposal and
the semi-classical island formula for the entanglement negativity is
demonstrated in AdS$_3$/BCFT$_2$ framework. Furthermore, in the time-dependent
AdS$_3$/BCFT$_2$ scenarios involving eternal black holes in the lower
dimensional effective description, we investigate the time evolution of the
entanglement negativity through the DES and the island formulae and obtain the
analogues of the Page curves.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:00:04 GMT""}]","2022-05-18"
"2205.07906","Aseem Paranjape","Aseem Paranjape (IUCAA)","A simulated annealing approach to parameter inference with expensive
  likelihoods","14 pages, 6 figures; submitted to MNRAS; comments welcome! PICASA is
  publicly available at https://bitbucket.org/aparanjape/picasa/",,,,"astro-ph.CO astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new approach to parameter inference targeted on generic
situations where the evaluation of the likelihood $\mathcal{L}$ (i.e., the
probability to observe the data given a fixed model configuration) is
numerically expensive. Inspired by ideas underlying simulated annealing, the
method first evaluates $\chi^2=-2\ln\mathcal{L}$ on a sparse sequence of Latin
hypercubes of increasing density in parameter (eigen)space. The semi-stochastic
choice of sampling points accounts for anisotropic gradients of $\chi^2$ and
rapidly zooms in on the minimum of $\chi^2$. The sampled $\chi^2$ values are
then used to train an interpolator which is further used in a standard Markov
Chain Monte Carlo (MCMC) algorithm to inexpensively explore the parameter space
with high density, similarly to emulator-based approaches now popular in
cosmological studies. Comparisons with example linear and non-linear problems
show gains in the number of likelihood evaluations of factors of 10 to 100 or
more, as compared to standard MCMC algorithms. As a specific implementation, we
publicly release the code PICASA: Parameter Inference using Cobaya with
Anisotropic Simulated Annealing, which combines the minimizer (of a
user-defined $\chi^2$) with Gaussian Process Regression for training the
interpolator and a subsequent MCMC implementation using the COBAYA framework.
Being agnostic to the nature of the observable data and the theoretical model,
our implementation is potentially useful for a number of emerging problems in
cosmology, astrophysics and beyond.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:00:04 GMT""}]","2022-05-18"
"2205.07907","Matthias Steinhauser","Marvin Gerlach, Ulrich Nierste, Vladyslav Shtabovenko, Matthias
  Steinhauser","The width difference in the $B-\bar{B}$ system at
  next-to-next-to-leading order of QCD","7 pages, 4 figures",,"10.1103/PhysRevLett.129.102001","TTP22-030, P3H-22-051","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We extend the theoretical prediction for the width difference $\Delta
\Gamma_q$ in the mixing of neutral $B$ mesons in the Standard Model to
next-to-next-to-leading order in $\alpha_s$. To this aim we calculate
three-loop diagrams with two $|\Delta B|=1$ current-current operators
analytically. In the matching between $|\Delta B|=1$ and $|\Delta B|=2$
effective theories we regularize the infrared divergences dimensionally and
take into account all relevant evanescent operators. Further elements of the
calculation are the two-loop renormalization matrix $Z_{ij}$ for the $|\Delta
B|=2$ operators and the $\mathcal{O}(\alpha_s^2)$ corrections to the finite
renormalization that ensures the $1/m_b$ suppression of the operator $R_0$ at
two-loop order. Our theoretical prediction reads $\Delta\Gamma_s/\Delta M_s =
{(4.33\pm 0.93)\cdot 10^{-3}}$ if expressed in terms of the bottom mass in the
$\overline{\rm MS}$ scheme and $\Delta\Gamma_s/\Delta M_s = {(4.20\pm
0.95)\cdot 10^{-3}}$ for the use of the potential-subtracted mass. While the
controversy on $|V_{cb}|$ affects both $\Delta\Gamma_s$ and $\Delta M_s$, the
ratio $\Delta\Gamma_s/\Delta M_s$ is not affected by the uncertainty in
$|V_{cb}|$ .
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:00:04 GMT""}]","2022-09-14"
"2205.07908","Albert Sneppen Mr.","Albert Sneppen","The Power Spectrum of Climate Change","8 pages (with 6 figures) with 6 pages appendix","Published in European Physical Journal Plus, 2022","10.1140/epjp/s13360-022-02773-w",,"physics.ao-ph","http://creativecommons.org/licenses/by/4.0/","  Both global, intermediate and local scales of Climate Change have been
studied extensively, but a unified diagnostic framework for examining all
spatial scales concurrently has remained elusive. Here we present a new
tool-set using spherical harmonics to examine climate change through surface
temperature anomalies from 1850 to 2021 on spatial scales ranging from
planetary to $50$ km scales. We show that the observed temperature anomalies
are accurately decomposed in spherical harmonics typically within 0.05 K. This
decomposition displays a remarkably simple dependence on spatial scale with a
universal shape across seasons and decades. The decomposition separates two
distinct regimes by a characteristic turnover-length of approximately $3000$
km. The largest scales confirm established trends, while local fluctuations are
consistent with 2-dimensional turbulence. We observe a downward cascade, from
which it follows that climate change feeds increasing volatility on all spatial
scales from $2.000$ to $50$ km. This increase is primarily driven by growing
volatility along longitudes.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:00:04 GMT""}]","2022-05-19"
"2205.07909","Mengyuan Xiao","Mengyuan Xiao, Tao Wang, David Elbaz, Daisuke Iono, Xing Lu, Longji
  Bing, Emanuele Daddi, Benjamin Magnelli, Carlos G\'omez-Guijarro, Frederic
  Bournaud, Qiusheng Gu, Shuowen Jin, Francesco Valentino, Anita Zanella,
  Raphael Gobat, Sergio Martin, Gabriel Brammer, Kotaro Kohno, Corentin
  Schreiber, Laure Ciesla, Xiaoling Yu, Koryo Okumura","Starbursts with suppressed velocity dispersion revealed in a forming
  cluster at z=2.51","19 pages, 14 figures, 3 tables. Accepted for publication in A&A","A&A 664, A63 (2022)","10.1051/0004-6361/202142843",,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  One of the most prominent features of galaxy clusters is the presence of a
dominant population of massive ellipticals in their cores. Stellar archaeology
suggests that these gigantic beasts assembled most of their stars in the early
Universe via starbursts. However, the role of dense environments and their
detailed physical mechanisms in triggering starburst activities remain unknown.
Here we report spatially resolved Atacama Large Millimeter/submillimeter Array
(ALMA) observations of the CO $J= 3-2$ emission line, with a resolution of
about 2.5 kiloparsecs, toward a forming galaxy cluster core with starburst
galaxies at $z=2.51$. In contrast to starburst galaxies in the field often
associated with galaxy mergers or highly turbulent gaseous disks, our
observations show that the two starbursts in the cluster exhibit dynamically
cold (rotation-dominated) gas-rich disks. Their gas disks have extremely low
velocity dispersion ($\sigma_{\mathrm{0}} \sim 20-30$ km s$^{-1}$), which is
three times lower than their field counterparts at similar redshifts. The high
gas fraction and suppressed velocity dispersion yield gravitationally unstable
gas disks, which enables highly efficient star formation. The suppressed
velocity dispersion, likely induced by the accretion of corotating and coplanar
cold gas, might serve as an essential avenue to trigger starbursts in massive
halos at high redshifts.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:00:06 GMT""}]","2022-08-10"
"2205.07910","Muwei Wu","Muwei Wu, Shou-Shu Gong, Dao-Xin Yao, Han-Qing Wu","Phase diagram and magnetic excitations of $J_1$-$J_3$ Heisenberg model
  on the square lattice","14 pages, 14 figures","Phys. Rev. B 106, 125129 (2022)","10.1103/PhysRevB.106.125129",,"cond-mat.str-el cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the phase diagram and the dynamical spin structure factor of the
spin-1/2 J1-J3 Heisenberg model on the square lattice using density matrix
renormalization group, exact diagonalization (ED), and cluster perturbation
theory (CPT). By extrapolating the order parameters and studying the level
crossings of the low-lying energy and entanglement spectra, we obtain the phase
diagram of this model and identify a narrow region of quantum spin liquid (QSL)
phase followed by a plaquette valence-bond solid (PVBS) state in the
intermediate region, whose nature has been controversial for many years. More
importantly, we use CPT and ED to study the dynamical spin structure factor in
the QSL and the PVBS phase. In the QSL phase, the high-energy magnon mode
completely turns into some dispersive weak excitations around the X and M
points. For the PVBS phase, the low-energy spectrum is characterized by a
gapped triplet excitation, and at the high energy, we find another branch of
dispersive excitation with broad continua, which is unlike the plaquette phase
in the 2x2 checkerboard model. In the latter case, the second branch of
excitation is nearly flat due to the weak effective interactions between the
local excitations of the plaquettes. And in the J1-J3 Heisenberg model, the
uniform interactions and the spontaneously translational symmetry breaking of
the PVBS phase make the difference in the excitation spectra.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:00:11 GMT""},{""version"":""v2"",""created"":""Mon, 19 Sep 2022 16:56:11 GMT""}]","2022-09-20"
"2205.07911","Massimo Ricotti","Massimo Ricotti, Emil Polisensky and Emily Cleland","Ghostly Stellar Haloes and their Relationship to Ultra-faint Dwarfs","18 pages, 17 figures, published on MNRAS. Movie of Fig.7 available on
  the online published version and at
  https://www.astro.umd.edu/~ricotti/NEWWEB/group.html","2022MNRAS.515..302R","10.1093/mnras/stac1485",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ghostly stellar haloes are extended haloes of stars composed solely of debris
of pre-reionization fossil galaxies and should exist in dwarf galaxies with
total masses $<10^{10}$ M$_\odot$. Fossil galaxies are even smaller mass dwarf
galaxies that stopped forming stars after the epoch of reionization and have
been identified in the Local Group as the ultra-faint dwarf satellites. Using
cosmological N-body simulations we present an empirical model for the shapes
and masses of ghostly stellar haloes. We compare the model to available
observations of stellar haloes in six isolated dwarf galaxies in the Local
Group (Leo T, Leo A, IC 10, WLM, IC 1613, NGC 6822) to infer the star formation
efficiency in dwarf galaxies at the epoch of reionization. We find an
efficiency of star formation in dark matter haloes with masses $10^6 - 10^8$
M$_\odot$ at $z\sim7$ in rough agreement with independent methods using data on
the luminosity function of ultra-faint dwarf galaxies but systematically higher
by a factor of 3-5. The systematic uncertainty of our results is still large,
mainly because available observations of stellar halo profiles do not extend
over a sufficiently large distance from the center of the host dwarf galaxy.
Additional observations, easily within reach of current telescopes, can
significantly improve the accuracy of this method and can also be used to
constrain the present day dark matter masses of dwarf galaxies in the Local
Group. Our method is based on a set of observations never used before, hence it
is a new independent test of models of hierarchical galaxy formation.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:00:18 GMT""},{""version"":""v2"",""created"":""Tue, 6 Sep 2022 17:43:47 GMT""}]","2022-09-07"
"2205.07912","Rahool Kumar Barman","Rahool Kumar Barman and Ahmed Ismail","Constraining the top electroweak sector of the SMEFT through $Z$
  associated top pair and single top production at the HL-LHC","19 pages, 9 figures, 8 tables",,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We study the processes $pp \to t\bar{t}Z$ and $pp \to tZj$ in the framework
of Standard Model Effective Field Theory (SMEFT), employing conventional
cut-and-count as well as machine learning techniques to take advantage of
kinematic information in complex final states involving multiple leptons and
$b$ jets. We explore the projected sensitivity for two SMEFT operators,
$\mathcal{O}_{tZ}$ and $\mathcal{O}_{tW}$, that induce electroweak dipole
moment interactions for top quarks, through direct searches in these
electroweak top production processes at the HL-LHC. New physics modifications
to dominant backgrounds are also considered. We show that the new physics
sensitivity can be enhanced through a combination of differential distributions
for relevant kinematic observables and machine learning techniques. Searches in
$t\bar{t}Z$ and $tZj$ production result in stronger constraints on
$\mathcal{C}_{tZ}$ and $\mathcal{C}_{tW}$, respectively. At the HL-LHC,
$\mathcal{C}_{tZ}$ can be probed up to $-0.41 \lesssim \mathcal{C}_{tZ}
\lesssim 0.47$ through searches in the $pp \to t\bar{t}Z + tWZ \to 3\ell + 2b\
+ \geq 2j$ channel while $\mathcal{C}_{tW}$ can be probed up to $-0.14 \lesssim
\mathcal{C}_{tW} < 0.11$ from searches in the $pp \to tZj + t\bar{t}Z + tWZ \to
3\ell + 1b + 1/2j$ channel, at $95\%$ CL.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:01:06 GMT""}]","2022-05-18"
"2205.07913","Vivian Yun Yan Tan","Vivian Yun Yan Tan, Adam Muzzin, Z. Cemile Marsan, Visal Sok, Leo Y.
  Alcorn, Jasleen Matharu, Heath Shipley, Danilo Marchesini, Kalina V. Nedkova,
  Nicholas Martis, Arjen van der Wel, Katherine E. Whitaker","Resolved Stellar Mass Maps of Galaxies in the Hubble Frontier Fields:
  Evidence for Mass Dependency in Environmental Quenching","25 pages, 14 figures, accepted for publication in ApJ Revision ver.
  1: Replaced title, fixed link to section 3",,"10.3847/1538-4357/ac7051",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the challenges in understanding the quenching processes for galaxies
is connecting progenitor star-forming populations to their descendant quiescent
populations over cosmic time. Here we attempt a novel approach to this
challenge by assuming that the underlying stellar mass distribution of galaxies
is not significantly altered during environmental quenching processes that
solely affect the gas content of cluster galaxies, such as strangulation and
ram-pressure stripping. Using the deep, high-resolution photometry of the
Hubble Frontier Fields, we create resolved stellar mass maps for both cluster
and field galaxies, from which we determine 2D S\'ersic profiles, and obtain
S\'ersic indices and half-mass radii. We classify the quiescent cluster
galaxies into disk-like and bulge-like populations based on their S\'ersic
indices, and find that bulge-like quiescent galaxies dominate the quiescent
population at higher masses ($M_\star > 10^{9.5}M_\odot$), whereas disk-like
quiescent galaxies dominate at lower masses ($10^{8.5}M_\odot< M_\star <
10^{9.5}M_\odot$). Using both the S\'ersic indices and half-mass radii, we
identify a population of quiescent galaxies in clusters that are ""morphological
analogues"" of field star-forming galaxies. These analogues are interpreted to
be star-forming galaxies that had been environmentally quenched. We use these
morphological analogues to compute the environmental-quenching efficiency, and
we find that the efficiency decreases with increasing stellar mass. This
demonstrates that environmental quenching is more effective on less massive
galaxies and that the effect of environment on quenching galaxies is not
completely separable from the effect of mass on quenching galaxies.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:01:06 GMT""},{""version"":""v2"",""created"":""Thu, 19 May 2022 17:48:10 GMT""}]","2022-08-17"
"2205.07914","Natalia Perkins","Kexin Feng, Aysel Shiralieva and Natalia B. Perkins","Sound attenuation in the hyperhoneycomb Kitaev spin liquid","16 pages, 7 figures",,,,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, it has been shown that the phonon dynamics may serve as an
indirect probe of fractionalization of spin degrees of freedom. Here we propose
that the sound attenuation measurements allows for the characterization and
identification of the Kitaev quantum spin liquid on the hyperhoneycomb lattice,
which is particularly interesting since the strong Kitaev interaction was
observed in the the hyperhoneycomb magnet $\beta$-Li$_2$IrO$_3$. To this end we
consider the low-temperature scattering between acoustic phonons and gapless
Majorana fermions with nodal-line band structure. We find that the sound
attenuation has a characteristic angular dependence, which is explicitly shown
for the high-symmetry planes at temperatures below the flux gap energy.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:01:09 GMT""}]","2022-05-18"
"2205.07915","Sergi Terradas-Brians\'o","Sergi Terradas-Brians\'o, Carlos A. Gonz\'alez-Guti\'errez, Franco
  Nori, Luis Mart\'in-Moreno and David Zueco","Ultrastrong waveguide QED with giant atoms","12 pages, 6 figures",,"10.1103/PhysRevA.106.063717",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Quantum optics with giant emitters has shown a new route for the observation
and manipulation of non-Markovian properties in waveguide-QED. In this paper we
extend the theory of giant atoms, hitherto restricted to the perturbative
light-matter regime, to deal with the ultrastrong coupling regime. Using static
and dynamical polaron methods we address the low energy subspace of a giant
atom coupled to an Ohmic waveguide beyond the standard rotating wave
approximation. We analyze the equilibrium properties of the system by computing
the atomic frequency renormalization as a function of the coupling
characterizing the localization-delocalization quantum phase transition for a
giant atom. We show that virtual photons dressing the ground state are
non-exponentially localized around the contact points but decay as a power-law.
Dynamics of an initially excited giant atom are studied, pointing out the
effects of ultrastrong coupling on the Lamb shift and the spontaneous emission
decay rate. Finally we comment on the existence of the so-called oscillating
bound states beyond the rotating wave approximation.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:01:13 GMT""}]","2023-01-04"
"2205.07916","Oliver Zier","Oliver Zier and Volker Springel","Simulating cold shear flows on a moving mesh","18 pages, 16 figures, submitted to MNRAS",,"10.1093/mnras/stac1783",,"astro-ph.IM astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Rotationally supported, cold, gaseous disks are ubiquitous in astrophysics
and appear in a diverse set of systems, such as protoplanetary disks, accretion
disks around black holes, or large spiral galaxies. Capturing the gas dynamics
accurately in these systems is challenging in numerical simulations due to the
low sound speed compared to the bulk velocity of the gas, the resolution
limitations of full disk models, and the fact that numerical noise can easily
source spurious growth of fluid instabilities if not suppressed sufficiently
well, negatively interfering with real physical instabilities present in such
disks (like the magneto-rotational instability). Here we implement the
so-called shearing-box approximation in the moving-mesh code ${\small AREPO}$
in order to facilitate achieving high resolution in local regions of
differentially rotating disks and to address these problems. While our new
approach offers manifest translational invariance across the shearing-box
boundaries and offers continuous local adaptivity, we demonstrate that the
unstructured mesh of ${\small AREPO}$ introduces unwanted levels of
""grid-noise"" in the default version of the code. We show that this can be
rectified by high-order integrations of the flux over mesh boundaries. With our
new techniques we obtain highly accurate results for shearing-box calculations
of the magneto-rotational instability that are superior to other Lagrangian
techniques. These improvements are also of value for other applications of the
code that feature strong shear flows.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:01:16 GMT""}]","2022-07-06"
"2205.07917","Dongzi Li","Dongzi Li, Anna Bilous, Scott Ransom, Robert Main and Yuan-Pei Yang","A Highly Variable Magnetized Environment in a Pulsar Binary resembling
  Fast Radio Bursts",,,,,"astro-ph.HE astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Fast radio bursts (FRBs) are short, intense extragalactic radio bursts of
unknown origin. Recent polarimetric studies have shown that a noticeable
fraction of the repeating FRBs display irregular, short-time variations of the
Faraday rotation measure (RM). Moreover, evidence for rare propagation effects
such as Faraday conversion and polarized attenuation is seen in at least one
FRB repeater. Together, they suggest a highly variable magneto-active
circum-burst environment. In this paper, we report similar behavior in a
globular cluster pulsar binary system PSR B1744-24A. We observe irregular fast
changes of RM with both signs at random orbital phases as well as profile
changes of the circular polarization when the pulsar emission passes close to
the companion. The latter provides strong evidence for Faraday conversion and
circularly polarized attenuation. These similarities between PSR B1744-24A and
some FRB repeaters, as well as the possible binary-produced long-term
periodicity of two active repeaters, and the discovery of a nearby FRB in a
globular cluster, where pulsar binaries are common, all suggest that some
fraction of FRBs have binary companions.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:02:28 GMT""}]","2022-05-18"
"2205.07918","Feynman Liang","Feynman Liang, Liam Hodgkinson, Michael W. Mahoney","Fat-Tailed Variational Inference with Anisotropic Tail Adaptive Flows",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While fat-tailed densities commonly arise as posterior and marginal
distributions in robust models and scale mixtures, they present challenges when
Gaussian-based variational inference fails to capture tail decay accurately. We
first improve previous theory on tails of Lipschitz flows by quantifying how
the tails affect the rate of tail decay and by expanding the theory to
non-Lipschitz polynomial flows. Then, we develop an alternative theory for
multivariate tail parameters which is sensitive to tail-anisotropy. In doing
so, we unveil a fundamental problem which plagues many existing flow-based
methods: they can only model tail-isotropic distributions (i.e., distributions
having the same tail parameter in every direction). To mitigate this and enable
modeling of tail-anisotropic targets, we propose anisotropic tail-adaptive
flows (ATAF). Experimental results on both synthetic and real-world targets
confirm that ATAF is competitive with prior work while also exhibiting
appropriate tail-anisotropy.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:03:41 GMT""}]","2022-05-18"
"2205.07919","Biao Huang","Biao Huang, Tsz-Him Leung, Dan Stamper-Kurn, W. Vincent Liu","Discrete time crystals enforced by Floquet-Bloch scars","6+11 pages","Phys. Rev. Lett. 129, 133001 (2022)","10.1103/PhysRevLett.129.133001",,"cond-mat.quant-gas cond-mat.other cond-mat.stat-mech quant-ph","http://creativecommons.org/licenses/by/4.0/","  We analytically identify a new class of quantum scars protected by
spatiotemporal translation symmetries, dubbed Floquet-Bloch scars. They
distinguish from previous (quasi-)static scars by a rigid spectral pairing only
possible in Floquet systems, where strong interaction and drivings equalize the
quasienergy corrections to all scars and maintain their spectral spacings
against generic bilinear perturbations. Scars then enforce the spatial
localization and rigid discrete time crystal (DTC) oscillations as verified
numerically in a trimerized kagome lattice model relevant to recent cold atom
experiments. Our analytical solutions offer a potential scheme to understand
the mechanisms for more generic translation-invariant DTCs.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:04:28 GMT""},{""version"":""v2"",""created"":""Tue, 30 Aug 2022 04:33:57 GMT""}]","2022-09-20"
"2205.07920","Igor Nunes","Igor Nunes, Mike Heddes, Tony Givargis, Alexandru Nicolau","An Extension to Basis-Hypervectors for Learning from Circular Data in
  Hyperdimensional Computing",,,,,"cs.LG cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  Hyperdimensional Computing (HDC) is a computation framework based on
properties of high-dimensional random spaces. It is particularly useful for
machine learning in resource-constrained environments, such as embedded systems
and IoT, as it achieves a good balance between accuracy, efficiency and
robustness. The mapping of information to the hyperspace, named encoding, is
the most important stage in HDC. At its heart are basis-hypervectors,
responsible for representing the smallest units of meaningful information. In
this work we present a detailed study on basis-hypervector sets, which leads to
practical contributions to HDC in general: 1) we propose an improvement for
level-hypervectors, used to encode real numbers; 2) we introduce a method to
learn from circular data, an important type of information never before
addressed in machine learning with HDC. Empirical results indicate that these
contributions lead to considerably more accurate models for both classification
and regression with circular data.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:04:55 GMT""}]","2022-05-18"
"2205.07921","Harrison Smith","Harrison B. Smith and Cole Mathis","The Futility of Exoplanet Biosignatures","15 pages, 2 figures, 1 box",,,,"astro-ph.EP astro-ph.IM q-bio.OT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The ultimate goal of astrobiology is to determine the distribution and
diversity of life in the universe. But as the word ""biosignature"" suggests,
what will be detected is not life itself, but an observation implicating a
particular process associated with living systems. Technical constraints and
our limited access to other worlds suggest we are more likely to detect an
out-of-equilibrium suite of gasses than a writhing octopus. Yet, anything short
of a writhing octopus will raise skepticism among astrobiologists about what
has been detected. Resolving that skepticism requires a theory to delineate
processes due to life and those due solely to abiotic mechanisms. This poses an
existential question for the endeavor of life detection: How do astrobiologists
plan to detect life via features shared between non-living and living systems?
We argue that you cannot without an underlying theory of life. We illustrate
this by analyzing the hypothetical detection of an ""Earth 2.0"" exoplanet. In
the absence of a theory of life, we argue the community should focus on
identifying unambiguous features of life via four areas of active research:
understanding the principles of life on Earth, building life in the lab,
detecting life in the solar system and searching for technosignatures.
Ultimately, we ask, what exactly do astrobiologists hope to learn by searching
for life?
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:11:44 GMT""}]","2022-05-18"
"2205.07922","Zofia Kaczmarek","Zofia Kaczmarek (1 and 2), Peter McGill (3), N. Wyn Evans (1), Leigh
  C. Smith (1), {\L}ukasz Wyrzykowski (2), Kornel Howil (2) and Maja
  Jab{\l}o\'nska (2) ((1) Institute of Astronomy, University of Cambridge, (2)
  Warsaw University Astronomical Observatory, (3) Department of Astronomy and
  Astrophysics, University of California, Santa Cruz)","Dark lenses through the dust: parallax microlensing events in the VVV","16 pages, 8 figures, submitted to MNRAS",,"10.1093/mnras/stac1507",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We use near-infrared photometry and astrometry from the VISTA Variables in
the Via Lactea (VVV) survey to analyse microlensing events containing annual
microlensing parallax information. These events are located in highly extincted
and low-latitude regions of the Galactic bulge typically off-limits to optical
microlensing surveys. We fit a catalog of $1959$ events previously found in the
VVV and extract $21$ microlensing parallax candidates. The fitting is done
using nested sampling to automatically characterise the multi-modal and
degenerate posterior distributions of the annual microlensing parallax signal.
We compute the probability density in lens mass-distance using the source
proper motion and a Galactic model of disc and bulge deflectors. By comparing
the expected flux from a main sequence lens to the baseline magnitude and
blending parameter, we identify 4 candidates which have probability $> 50$%
that the lens is dark. The strongest candidate corresponds to a nearby
($\approx0.78$ kpc), medium-mass ($1.46^{+1.13}_{-0.71} \ M_{\odot}$) dark
remnant as lens. In the next strongest, the lens is located at heliocentric
distance $\approx5.3$ kpc. It is a dark remnant with a mass of
$1.63^{+1.15}_{-0.70} \ M_{\odot}$. Both of those candidates are most likely
neutron stars, though possibly high-mass white dwarfs. The last two events may
also be caused by dark remnants, though we are unable to rule out other
possibilities because of limitations in the data.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:12:27 GMT""}]","2022-06-08"
"2205.07923","Sangmin Choi","Ratindranath Akhoury, Sangmin Choi, Malcolm J. Perry","Holography from Singular Supertranslations on a Black Hole Horizon","13 pages, matches the published version","Phys.Rev.Lett. 129 (2022) 22, 221603","10.1103/PhysRevLett.129.221603","CPHT-RR034.052022","hep-th gr-qc","http://creativecommons.org/licenses/by/4.0/","  We investigate the standard and dual Bondi-Metzner-Sachs (BMS)
supertranslation generators on a black hole horizon and draw some conclusions
about black hole physics. Recently, it has been shown that in addition to
conventional BMS supertranslation symmetries, there exists an additional
infinite set of magnetic asymptotic symmetries, dual BMS supertranslations,
again parametrized by a function on the two-sphere. We show that the Dirac
bracket between these generators exhibits an anomalous central term when one
parameter function exhibits a singularity in the complex stereographical
coordinates on the sphere. In order to preserve general coordinate invariance,
we demonstrate that this central term can be removed by postulating a
holographic gravitational Chern-Simons theory on the horizon. This indicates
that for an anomaly-free theory of quantum gravity in the presence of a black
hole, one should include a boundary theory on the horizon.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:18:24 GMT""},{""version"":""v2"",""created"":""Wed, 15 Jun 2022 16:07:34 GMT""},{""version"":""v3"",""created"":""Thu, 8 Sep 2022 11:36:13 GMT""},{""version"":""v4"",""created"":""Wed, 30 Nov 2022 21:01:06 GMT""}]","2022-12-02"
"2205.07924","Joseph Tindall","Joseph Tindall, Amy Searle, Abdulla Alhajri and Dieter Jaksch","Quantum Physics in Connected Worlds","Published Version","Quantum physics in connected worlds. Nat Commun 13, 7445 (2022)","10.1038/s41467-022-35090-y",,"quant-ph physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Theoretical research into many-body quantum systems has mostly focused on
regular structures which have a small, simple unit cell and where a vanishingly
small number of pairs of the constituents directly interact. Motivated by
advances in control over the pairwise interactions in many-body simulators, we
determine the fate of spin systems on more general, arbitrary graphs. Placing
the minimum possible constraints on the underlying graph, we prove how, with
certainty in the thermodynamic limit, such systems behave like a single
collective spin. We thus understand the emergence of complex many-body physics
as dependent on `exceptional', geometrically constrained structures such as the
low-dimensional, regular ones found in nature. Within the space of dense graphs
we identify hitherto unknown exceptions via their inhomogeneity and observe how
complexity is heralded in these systems by entanglement and highly non-uniform
correlation functions. Our work paves the way for the discovery and
exploitation of a whole class of geometries which can host uniquely complex
phases of matter.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:18:48 GMT""},{""version"":""v2"",""created"":""Fri, 2 Dec 2022 20:30:18 GMT""}]","2022-12-06"
"2205.07925","Cristiano Ciuti","Zejian Li, Valentin Heyraud, Kaelan Donatella, Zakari Denis, and
  Cristiano Ciuti","Machine learning via relativity-inspired quantum dynamics","Article (2 figures) + Suppl. Mat. (2 figures)",,"10.1103/PhysRevA.106.032413",,"quant-ph cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a machine-learning scheme based on the relativistic dynamics of a
quantum system, namely a quantum detector inside a cavity resonator. An
equivalent analog model can be realized for example in a circuit QED platform
subject to properly modulated driving fields. We consider a reservoir-computing
scheme where the input data are embedded in the modulation of the system
(equivalent to the acceleration of the relativistic object) and the output data
are obtained by linear combinations of measured observables. As an illustrative
example, we have simulated such a relativistic quantum machine for a
challenging classification task, showing a very large enhancement of the
accuracy in the relativistic regime. Using kernel-machine theory, we show that
in the relativistic regime the task-independent expressivity is dramatically
magnified with respect to the Newtonian regime.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:21:34 GMT""}]","2022-10-05"
"2205.07926","Thais Lemos","Thais Lemos, Rodrigo S. Gon\c{c}alves, Joel C. Carvalho, Jailson S.
  Alcaniz","Cosmological model-independent constraints on the baryon fraction in the
  IGM from fast radio bursts and supernovae data","8 pages, 3 figures","Eur. Phys. J. C 83 (2023) 138","10.1140/epjc/s10052-023-11275-7",,"astro-ph.CO astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fast Radio Bursts (FRBs) are millisecond-duration radio transients with an
observed dispersion measure ($DM$) greater than the expected Milky Way
contribution, which suggests that such events are of extragalactic origin.
Although some models have been proposed to explain the physics of the pulse,
the mechanism behind the FRBs emission is still unknown. From FRBs data with
known host galaxies, the redshift is directly measured and can be combined with
estimates of the $DM$ to constrain the cosmological parameters, such as the
baryon number density and the Hubble constant. However, the poor knowledge of
the fraction of baryonic mass in the intergalactic medium ($f_{IGM}$) and its
degeneracy with the cosmological parameters impose limits on the cosmological
application of FRBs. In this work we present a cosmological model-independent
method to determine the evolution of $f_{IGM}$ combining the latest FRBs
observations with localized host galaxy and current supernovae data. We
consider constant and time-dependent $f_{IGM}$ parameterizations and show,
through a Bayesian model selection analysis, that a conclusive answer about the
time-evolution of $f_{IGM}$ depend strongly on the $DM$ fluctuations due to the
spatial variation in cosmic electron density ($\delta$). In particular, our
analysis show that the evidence varies from strong (in favor of a growing
evolution of $f_{IGM}$ with redshift) to inconclusive, as larger values of
$\delta$ are considered.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:24:08 GMT""},{""version"":""v2"",""created"":""Wed, 29 Mar 2023 17:20:28 GMT""}]","2023-03-30"
"2205.07927","Xiaoyu Zheng","Obeng Appiagyei Addai, Ruilin Xiao, Xiaoyu Zheng, Peter Palffy-Muhoray","Optical characterization of dyed liquid crystal cells","16 pages, 9 figures",,,,"cond-mat.soft physics.optics","http://creativecommons.org/licenses/by/4.0/","  The guest-host liquid crystal display, first proposed in 1968, relies on
controlling the orientation of dichroic dyes dissolved in a nematic liquid
crystal host. Controlling the orientation of the liquid crystal and of the
dissolved dye with an electric field allows control of the transmittance of the
cell. Knowing the dielectric properties at optical frequencies of the dye and
liquid crystal mixtures is crucial for the optimal design of guest-host liquid
crystal devices. In this work, the dielectric functions of various layers in
liquid crystal cells are described by models obeying the Kramers-Kronig
relations: the Sellmeier equation for transparent layers and causal Gaussian
oscillator model for absorbing layers. We propose a systematic way to
accurately model the dielectric response of each layer by minimizing the sum of
squared differences between the measured transmittance spectrum of a guest-host
cell in the near-UV/vis range and the prediction of the transmittance of the
modeled multilayer structure. By measuring the transmittance for incident light
polarized parallel and perpendicular to the nematic director allows us to
separately characterize the two principal dielectric functions of the uniaxial
sample. Our results show that the causal Gaussian oscillator model can
accurately characterize the dielectric functions of dyes in liquid crystals.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:24:20 GMT""},{""version"":""v2"",""created"":""Tue, 30 Aug 2022 01:25:37 GMT""}]","2022-08-31"
"2205.07928","Marcos Celi","Marcos Osvaldo Celi, Mauro Mariani, Milva Gabriela Orsaria, Lucas
  Tonetto","Oscillating Magnetized Color Superconducting Quark Stars",,"Universe 2022, 8(5), 272","10.3390/universe8050272",,"astro-ph.HE cond-mat.supr-con nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The main objective of this work is to study the structure, composition, and
oscillation modes of color superconducting quark stars with intense magnetic
fields. We adopted the MIT bag model within the color superconductivity CFL
framework, and we included the effects of strong magnetic fields to construct
the equation of state of stable quark matter. We calculated observable
quantities, such as the mass, radius, frequency, and damping time of the
oscillation fundamental $f$ mode of quark stars, taking into account current
astrophysical constraints. The results obtained show that color superconducting
magnetized quark stars satisfy the constraints imposed by the observations of
massive pulsars and gravitational wave events. Furthermore, the quantities
associated with the oscillation $f$ mode of these objects fit the universal
relationships for compact objects. In the context of the new multi-messenger
gravitational wave astronomy era and the future asteroseismology of neutron
stars, we hope that our results contribute to the understanding of the behavior
of dense matter and compact objects.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:27:20 GMT""}]","2022-05-18"
"2205.07929","Morgan MacLeod","Morgan MacLeod, Kishalay De, Abraham Loeb","Dusty, Self-obscured Transients from Stellar Coalescence","v2, published in AAS Journals","The Astrophysical Journal, Volume 937, Issue 2, id.96, 11 pp. 2022","10.3847/1538-4357/ac8c31",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss the central role that dust condensation plays in shaping the
observational appearance of outflows from coalescing binary systems. As
binaries begin to coalesce, they shock-heat and expel material into their
surroundings. Depending on the properties of the merging system, this material
can expand to the point where molecules and dust form, dramatically increasing
the gas opacity. We use the existing population of Luminous Red Novae (LRNe) to
constrain the thermodynamics of these ejecta, then apply our findings to the
progressive obscuration of merging systems in the lead in to their coalescence.
Compact progenitor stars near the main sequence or in the Hertzsprung gap along
with massive progenitor stars have sufficiently hot circumstellar material to
remain unobscured by dust. By contrast, more extended, low-mass giants should
become completely optically obscured by dust formation in the circumbinary
environment. We predict that 30--50\% of stellar coalescence transients for
solar-mass stars will be dusty, infrared-luminous sources. Of these, the
optical transients may selectively trace complete merger outcomes while the
infrared transients trace common envelope ejection outcomes.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:27:56 GMT""},{""version"":""v2"",""created"":""Tue, 18 Apr 2023 10:11:35 GMT""}]","2023-04-19"
"2205.07930","Matthew Buican","Chinmaya Bhargava, Matthew Buican, and Hongliang Jiang","On the Protected Spectrum of the Minimal Argyres-Douglas Theory","34 pages and 2 appendices; v2: references added and typos corrected",,"10.1007/JHEP08(2022)132","QMUL-PH-22-17","hep-th","http://creativecommons.org/licenses/by/4.0/","  Despite the power of supersymmetry, finding exact closed-form expressions for
the protected operator spectra of interacting superconformal field theories
(SCFTs) is difficult. In this paper, we take a step towards a solution for the
""simplest"" interacting 4D $\mathcal{N}=2$ SCFT: the minimal Argyres-Douglas
(MAD) theory. We present two results that go beyond the well-understood Coulomb
branch and Schur sectors. First, we find the exact closed-form spectrum of
multiplets containing operators that are chiral with respect to any
$\mathcal{N}=1\subset\mathcal{N}=2$ superconformal subalgebra. We argue that
this ""full"" chiral sector (FCS) is as simple as allowed by unitarity for a
theory with a Coulomb branch and that, up to a rescaling of $U(1)_r$ quantum
numbers and the vanishing of a finite number of states, the MAD FCS is
isospectral to the FCS of the free $\mathcal{N}=2$ Abelian gauge theory. In the
language of superconformal representation theory, this leaves only the spectrum
of the poorly understood $\bar{\mathcal{C}}_{R,r(j,\bar j)}$ multiplets to be
determined. Our second result sheds light on these observables: we find an
exact closed-form answer for the number of $\bar{\mathcal{C}}_{0,r(j,0)}$
multiplets, for any $r$ and $j$, in the MAD theory. We argue that this
sub-sector is also as simple as allowed by unitarity for a theory with a
Coulomb branch and that there is a natural map to the corresponding sector of
the free $\mathcal{N}=2$ Abelian gauge theory. These results motivate a
conjecture on the full local operator algebra of the MAD theory.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:29:44 GMT""},{""version"":""v2"",""created"":""Thu, 16 Jun 2022 13:31:52 GMT""}]","2022-09-07"
"2205.07931","Damanvir Binner","Damanvir Singh Binner and Amarpreet Rattan","A Comparison of Integer Partitions Based on Smallest Part",,,,,"math.CO math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For positive integers $n, L$ and $s$, consider the following two sets that
both contain partitions of $n$ with the difference between the largest and
smallest parts bounded by $L$: the first set contains partitions with smallest
part $s$, while the second set contains partitions with smallest part at least
$s+1$. Let $G_{L,s}(q)$ be the generating series whose coefficient of $q^n$ is
difference between the sizes of the above two sets of partitions. This
generating series was introduced by Berkovich and Uncu in 2019. Previous
results concentrated on the nonnegativity of $G_{L,s}(q)$ in the cases $s=1$
and $s=2$. In the present paper, we show the eventual positivity of
$G_{L,s}(q)$ for general s and also find a precise nonnegativity result for the
case $s=3$.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:30:48 GMT""}]","2022-05-18"
"2205.07932","Yang Feng","Yifan He and Yong Zhou and Yang Feng","Distributed Feature Selection for High-dimensional Additive Models","40 pages, 2 figures",,,,"cs.LG math.ST stat.AP stat.CO stat.ML stat.TH","http://creativecommons.org/licenses/by/4.0/","  Distributed statistical learning is a common strategy for handling massive
data where we divide the learning task into multiple local machines and
aggregate the results afterward. However, most existing work considers the case
where the samples are divided. In this work, we propose a new algorithm,
DDAC-SpAM, that divides features under the high-dimensional sparse additive
model. The new algorithm contains three steps: divide, decorrelate, and
conquer. We show that after the decorrelation operation, every local estimator
can recover the sparsity pattern for each additive component consistently
without imposing strict constraints to the correlation structure among
variables. Theoretical analysis of the aggregated estimator and empirical
results on synthetic and real data illustrate that the DDAC-SpAM algorithm is
effective and competitive in fitting sparse additive models.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:31:03 GMT""}]","2022-05-18"
"2205.07933","Reyk B\""orner","Reyk B\""orner, Jan O. Haerter and Romain Fi\'evet","Modeling wind-responsive diurnal sea surface temperature for
  cloud-resolving simulations","Submitted to the Journal of Advances in Modeling Earth Systems
  (JAMES)",,,,"physics.ao-ph physics.flu-dyn physics.geo-ph","http://creativecommons.org/licenses/by-sa/4.0/","  The diurnal variability of sea surface temperature (SST) may play an
important role for cloud organization above the tropical ocean, with
implications for precipitation extremes, storminess, and climate sensitivity.
Recent cloud-resolving simulations demonstrate how imposed diurnal SST
oscillations can strongly, and delicately, impact mesoscale convective
organization. In spite of this nuanced interaction, many idealized modeling
studies of tropical convection either assume a constant, homogeneous SST or, in
case of a responsive sea surface, represent the upper ocean by a slab with
fixed thickness. Here we show that slab ocean models with constant heat
capacity fail to capture the wind-dependence of observed diurnal sea surface
warming. To alleviate this shortcoming, we present a simple one-dimensional
model of upper-ocean temperature dynamics under atmospheric forcing. The model
describes turbulent mixing as diffusion with a wind-dependent diffusivity, in
addition to a bulk mixing term and heat fluxes entering as sources and sinks.
Using observational data, we apply Bayesian inference to calibrate the model.
In contrast with a slab model, our model captures the exponential reduction of
the diurnal warming amplitude with increasing wind speed. Formulated as a
single partial differential equation with three key tuning parameters, the
model is suitable as an interactive numerical boundary condition for
cloud-resolving simulations.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:31:50 GMT""},{""version"":""v2"",""created"":""Wed, 13 Jul 2022 09:47:46 GMT""}]","2022-07-14"
"2205.07934","Denis Basko","D. B. Karki, R. S. Whitney, D. M. Basko","Local bistability under microwave heating for spatially mapping
  disordered superconductors",,"Phys. Rev. B 106, 155419 (2022)","10.1103/PhysRevB.106.155419",,"cond-mat.mes-hall cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We theoretically study a strongly disordered superconducting layer heated by
near-field microwave radiation from a nanometric metallic tip. The microwaves
heat up the quasiparticles, which cool by phonon emission and conduction away
from the heated area. Due to a bistability with two stable states of the
electron temperature under the tip, the heating can be tuned to induce a
submicrometer-sized normal region bounded by a sharp domain wall between high-
and low-temperature states. We propose this as a local probe to access
different physics from existing methods, for example, to map out inhomogeneous
superfluid flow in the layer. The bistability-induced domain wall can
significantly improve its spatial resolution.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:36:34 GMT""},{""version"":""v2"",""created"":""Tue, 18 Oct 2022 11:57:31 GMT""},{""version"":""v3"",""created"":""Fri, 21 Oct 2022 14:31:43 GMT""}]","2022-10-24"
"2205.07935","Isabella Trierweiler","Isabella L Trierweiler, Alexandra E Doyle, Carl Melis, Kevin J Walsh,
  Edward D Young","Exomoons as sources of white dwarf pollution","Submitted to AAS journals, comments welcome",,"10.3847/1538-4357/ac86d5",,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Polluted white dwarfs offer a unique way to study the bulk compositions of
exoplanetary material, but it is not always clear if this material originates
from comets, asteroids, moons, or planets. We combine N-body simulations with
an analytical model to assess the prevalence of extrasolar moons as white dwarf
(WD) polluters. Using a sample of observed polluted white dwarfs we find that
the extrapolated parent body masses of the polluters are often more consistent
with those of many solar system moons, rather than solar-like asteroids. We
provide a framework for estimating the fraction of white dwarfs currently
undergoing observable moon accretion based on results from simulated white
dwarf planetary and moon systems. Focusing on a three-planet white dwarf system
of Super-Earth to Neptune-mass bodies, we find that we could expect about one
percent of such systems to be currently undergoing moon accretions as opposed
to asteroid accretion.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:36:53 GMT""},{""version"":""v2"",""created"":""Wed, 18 May 2022 18:24:38 GMT""}]","2022-09-07"
"2205.07936","Abril Sahade","A. Sahade, M. C\'ecere, M.V. Sieyra, G. Krause, H. Cremades, A. Costa","Pseudostreamer influence on flux rope evolution",,"A&A 662, A113 (2022)","10.1051/0004-6361/202243618",,"astro-ph.SR physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  A critical aspect of solar activity is the coupling between eruptions and the
surrounding coronal magnetic field, which determines the trajectory and
morphology of the eruptive event. Pseudostreamers (PSs) are coronal magnetic
structures formed by arcs of twin loops capped by magnetic field lines from
coronal holes of the same polarity that meet at a central spine. They contain a
single magnetic null point in the spine, potentially influencing the evolution
of nearby flux ropes (FRs). To understand the net effect of the PS on FR
eruptions is first necessary to study diverse and isolated FR-PS scenarios,
which are not influenced by other magnetic structures. We performed numerical
simulations in which a FR structure is in the vicinity of a PS magnetic
configuration. The combined magnetic field of the PS and the FR results in the
formation of two magnetic null points. We evolve this scenario by numerically
solving the magnetohydrodynamic equations in 2.5D. The simulations consider a
fully ionised compressible ideal plasma in the presence of a gravitational
field and a stratified atmosphere. We find that the dynamic behaviour of the FR
can be categorised into three different classes based on the FR trajectories
and whether it is eruptive or confined. Our analysis indicates that the
magnetic null points are decisive in the direction and intensity of the FR
deflection and their hierarchy depends on the topological arrangement of the
scenario. Moreover, the PS lobe acts as a magnetic cage enclosing the FR. We
report that the total unsigned magnetic flux of the cage is a key parameter
defining whether the FR is ejected or not.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:37:57 GMT""}]","2022-06-29"
"2205.07937","Rentian Yao","Rentian Yao, Xiaohui Chen and Yun Yang","Mean-Field Nonparametric Estimation of Interacting Particle Systems",,,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper concerns the nonparametric estimation problem of the
distribution-state dependent drift vector field in an interacting $N$-particle
system. Observing single-trajectory data for each particle, we derive the
mean-field rate of convergence for the maximum likelihood estimator (MLE),
which depends on both Gaussian complexity and Rademacher complexity of the
function class. In particular, when the function class contains $\alpha$-smooth
H{\""o}lder functions, our rate of convergence is minimax optimal on the order
of $N^{-\frac{\alpha}{d+2\alpha}}$. Combining with a Fourier analytical
deconvolution argument, we derive the consistency of MLE for the external force
and interaction kernel in the McKean-Vlasov equation.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:39:09 GMT""},{""version"":""v2"",""created"":""Mon, 27 Jun 2022 02:57:05 GMT""}]","2022-06-28"
"2205.07938","Simon DeDeo","Robin W. Na and Simon DeDeo","The Diversity of Argument-Making in the Wild: from Assumptions and
  Definitions to Causation and Anecdote in Reddit's ""Change My View""","7 pages, 5 tables. Accepted as paper with oral presentation to CogSci
  2022, Toronto. Proceedings of the Annual Meeting of the Cognitive Science
  Society, 44",,,,"cs.CL cs.SI q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  What kinds of arguments do people make, and what effect do they have on
others? Normative constraints on argument-making are as old as philosophy
itself, but little is known about the diversity of arguments made in practice.
We use NLP tools to extract patterns of argument-making from the Reddit site
""Change My View"" (r/CMV). This reveals six distinct argument patterns: not just
the familiar deductive and inductive forms, but also arguments about
definitions, relevance, possibility and cause, and personal experience. Data
from r/CMV also reveal differences in efficacy: personal experience and, to a
lesser extent, arguments about causation and examples, are most likely to shift
a person's view, while arguments about relevance are the least. Finally, our
methods reveal a gradient of argument-making preferences among users: a
two-axis model, of ""personal--impersonal"" and ""concrete--abstract"", can account
for nearly 80% of the strategy variance between individuals.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:39:21 GMT""}]","2022-12-12"
"2205.07939","Xiaoxiong Zhong","Xinghan Wang, Xiaoxiong Zhong, Jiahong Ning, Hangfan Li, Tingting
  Yang, Yuanyuan Yang","Two-Stage Coded Federated Edge Learning: A Dynamic Partial Gradient
  Coding Perspective","improve some simulations",,,,"cs.NI","http://creativecommons.org/publicdomain/zero/1.0/","  Federated edge learning (FEL) can training a global model from terminal
nodes' local dataset, which can make full use of the computing resources of
terminal nodes and performs more extensive and efficient machine learning on
terminal nodes with protecting user information requirements. Performance of
FEL will be suffered from long delay or fault decision as the master collects
partial gradients from stragglers which cannot return correct results within a
deadline. Inspired by this, in this paper, we propose a novel coded FEL to
mitigate stragglers for synchronous gradient with a two-stage dynamic scheme,
where we start with part of workers for a duration of before starting the
second stage, and on completion of at the first stage, we start remaining
workers in the second stage. In particular, the computation latency and
transmission latency is essential and should be quantitatively analyzed. Then
the dynamically coded coefficients scheme is proposed which is based on
historical information including worker completion time. For performance
optimization of FEL, a Lyapunov function is designed to maximize admission data
balancing fairness and two stage dynamic coding scheme is designed to maximize
arrival data among workers. Experimental evidence verifies the derived
properties and demonstrates that our proposed solution achieves a better
performance for practical network parameters and benchmark datasets in terms of
accuracy and resource utilization in the FEL system.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:44:28 GMT""},{""version"":""v2"",""created"":""Wed, 25 Jan 2023 15:18:31 GMT""}]","2023-01-26"
"2205.07940","Samyobrata Mukherjee","Samyobrata Mukherjee, David Artigas and Lluis Torner","Surface Bound States in the Continuum in Dyakonov Structures",,"Phys. Rev. B 105, L201406 (2022)","10.1103/PhysRevB.105.L201406",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Surface bound states in the continuum (SBICs) have been found to occur in
diverse settings, but so far always at the interface of non-homogeneous media,
such as discrete lattices or periodic systems. Here we show that they can also
exist at the interface of homogeneous media, resulting in unique SBICs.
Specifically, we found that, contrary to general belief, leaky Dyakonov states
exist at the interface between materials that exhibit opposite signs of
anisotropy. In addition, properly breaking the anisotropy-symmetry leads to the
formation of both guided states and also SBICs embedded within the continuum. A
direct implication of our finding is the possibility to create SBICs and
Dyakonov states in a whole new class of materials and metamaterials.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:49:13 GMT""}]","2022-05-24"
"2205.07941","Daniya Seitova","Daniya Seitova, Jonathan C. Pober","The Optical Depth of Foregrounds for the Highest Redshift 21 cm Signals","9 pages, 3 figures, MNRAS",,"10.1093/mnras/stac1237",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Foreground emission makes it difficult to detect the highly-redshifted
cosmological 21 cm signal at any frequency. However, at low frequencies
foregrounds are likely to become optically thick, which would make it
completely impossible to see a 21 cm signal behind them. To find out which
regions of the sky might be optically thick for the highest redshifts of the 21
cm signal, we fit the measurements from LWA1 and the Haslam 408 MHz map with a
two-component spectral model and calculate the frequency-dependent foreground
optical depth point-by-point across the sky. Limitations of the current data
prevent us from making any strong conclusions at high statistical significance,
but there is suggestive evidence ($\sim1\sigma$) that as much as 25% of the sky
could be obscured for the highest redshift 21 cm signals.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:54:24 GMT""}]","2022-05-18"
"2205.07942","Talal Ahmed Chowdhury","Talal Ahmed Chowdhury, Shaaban Khalil and Ernest Ma","Nested Radiative Seesaw Masses for Dark Matter and Neutrinos","11 pages, 6 figures",,"10.1103/PhysRevD.106.095020",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  The scotogenic model of neutrino mass is modified so that the dark Majorana
fermion singlet $S$ which makes the neutrino massive is itself generated in one
loop. This is accomplished by having $Z_6$ lepton symmetry softly broken to
$Z_2$ in the scalar sector by a unique quadratic term. It is shown that $S$ is
a viable freeze-in dark-matter candidate through Higgs decay.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:58:31 GMT""}]","2022-11-30"
"2205.07943","Rob Fine","MicroBooNE collaboration: P. Abratenko, J. Anthony, L. Arellano, J.
  Asaadi, A. Ashkenazi, S. Balasubramanian, B. Baller, C. Barnes, G. Barr, J.
  Barrow, V. Basque, L. Bathe-Peters, O. Benevides Rodrigues, S. Berkman, A.
  Bhanderi, A. Bhat, M. Bhattacharya, M. Bishai, A. Blake, T. Bolton, J. Y.
  Book, L. Camilleri, D. Caratelli, I. Caro Terrazas, F. Cavanna, G. Cerati, Y.
  Chen, D. Cianci, J. M. Conrad, M. Convery, L. Cooper-Troendle, J. I.
  Crespo-Anadon, M. Del Tutto, S. R. Dennis, P. Detje, A. Devitt, R. Diurba, R.
  Dorrill, K. Duffy, S. Dytman, B. Eberly, A. Ereditato, J. J. Evans, R. Fine,
  O. G. Finnerud, G. A. Fiorentini Aguirre, R. S. Fitzpatrick, B. T. Fleming,
  N. Foppiani, D. Franco, A. P. Furmanski, D. Garcia-Gamez, S. Gardiner, G. Ge,
  S. Gollapinni, O. Goodwin, E. Gramellini, P. Green, H. Greenlee, W. Gu, R.
  Guenette, P. Guzowski, L. Hagaman, O. Hen, R. Hicks, C. Hilgenberg, G. A.
  Horton-Smith, R. Itay, C. James, X. Ji, L. Jiang, J. H. Jo, R. A. Johnson, Y.
  J. Jwa, D. Kalra, N. Kamp, N. Kaneshige, G. Karagiorgi, W. Ketchum, M. Kirby,
  T. Kobilarcik, I. Kreslo, M. B. Leibovitch, I. Lepetic, J.-Y. Li, K. Li, Y.
  Li, K. Lin, B. R. Littlejohn, W. C. Louis, X. Luo, K. Manivannan, C. Mariani,
  D. Marsden, J. Marshall, D. A. Martinez Caicedo, K. Mason, A. Mastbaum, N.
  McConkey, V. Meddage, T. Mettler, K. Miller, J. Mills, K. Mistry, T. Mohayai,
  A. Mogan, M. Mooney, A. F. Moor, C. D. Moore, L. Mora Lepin, J. Mousseau, S.
  Mulleria Babu, D. Naples, A. Navrer-Agasson, N. Nayak, M. Nebot-Guinot, R. K.
  Neely, D. A. Newmark, J. Nowak, M. Nunes, N. Oza, O. Palamara, V. Paolone, A.
  Papadopoulou, V. Papavassiliou, H. Parkinson, S. F. Pate, N. Patel, A.
  Paudel, Z. Pavlovic, E. Piasetzky, I. Ponce-Pinto, S. Prince, X. Qian, J.L.
  Raaf, V. Radeka, A. Rafique, M. Reggiani-Guzzo, L. Ren, L. C. J. Rice, L.
  Rochester, J. Rodriguez Rondon, M. Rosenberg, M. Ross-Lonergan, C. Rudolph
  von Rohr, G. Scanavini, D. W. Schmitz, A. Schukraft, W. Seligman, M. H.
  Shaevitz, R. Sharankova, J. Shi, J. Sinclair, A. Smith, E.L. Snider, M.
  Soderberg, S. Soldner-Rembold, P. Spentzouris, J. Spitz, M. Stancari, J. St.
  John, T. Strauss, K. Sutton, S. Sword-Fehlberg, A. M. Szelc, W. Tang, N.
  Taniuchi, K. Terao, C.Thorpe, D. Torbunov, D. Totani, M. Toups, Y. -T. Tsai,
  M. A. Uchida, T. Usher, B. Viren, M. Weber, H. Wei, A. J. White, Z. Williams,
  S. Wolbers, T. Wongjirad, M. Wospakrik, K. Wresilo, N. Wright, W. Wu, E.
  Yandel, T. Yang, G. Yarbrough, L. E. Yates, H. W. Yu, G. P. Zeller, J.
  Zennamo, C. Zhang","Measurement of neutral current single $\pi^0$ production on argon with
  the MicroBooNE detector","16 pages, 14 figures, 2 tables",,,"FERMILAB-PUB-22-412-ND-SCD","hep-ex","http://creativecommons.org/licenses/by/4.0/","  We report the first measurement of $\pi^0$ production in neutral current (NC)
interactions on argon with average neutrino energy of $\lesssim1$~GeV. We use
data from the MicroBooNE detector's 85-tonne active volume liquid argon time
projection chamber situated in Fermilab's Booster Neutrino Beam and exposed to
$5.89\times10^{20}$ protons on target for this measurement. Measurements of NC
$\pi^0$ events are reported for two exclusive event topologies without charged
pions. Those include a topology with two photons from the decay of the $\pi^0$
and one proton and a topology with two photons and zero protons. Flux-averaged
cross-sections for each exclusive topology and for their semi-inclusive
combination are extracted (efficiency-correcting for two-plus proton final
states), and the results are compared to predictions from the \textsc{genie},
\textsc{neut}, and \textsc{NuWro} neutrino event generators. We measure cross
sections of $1.243\pm0.185$ (syst) $\pm0.076$ (stat), $0.444\pm0.098\pm0.047$,
and $0.624\pm0.131\pm0.075$ $[10^{-38}\textrm{cm}^2/\textrm{Ar}]$ for the
semi-inclusive NC$\pi^0$, exclusive NC$\pi^0$+1p, and exclusive NC$\pi^0$+0p
processes, respectively.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:59:26 GMT""},{""version"":""v2"",""created"":""Thu, 29 Sep 2022 18:38:09 GMT""},{""version"":""v3"",""created"":""Thu, 8 Dec 2022 17:28:10 GMT""}]","2022-12-09"
"2205.07944","Zhaofeng Tian","Zhaofeng Tian, Weisong Shi","Design and Implement an Enhanced Simulator for Autonomous Delivery Robot",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As autonomous driving technology is getting more and more mature today,
autonomous delivery companies like Starship, Marble, and Nuro has been making
progress in the tests of their autonomous delivery robots. While simulations
and simulators are very important for the final product landing of the
autonomous delivery robots since the autonomous delivery robots need to
navigate on the sidewalk, campus, and other urban scenarios, where the
simulations can avoid real damage to pedestrians and properties in the real
world caused by any algorithm failures and programming errors and thus
accelerate the whole developing procedure and cut down the cost. In this case,
this study proposes an open-source simulator based on our autonomous delivery
robot ZebraT to accelerate the research on autonomous delivery. The simulator
developing procedure is illustrated step by step. What is more, the
applications on the simulator that we are working on are also introduced, which
includes autonomous navigation in the simulated urban environment, cooperation
between an autonomous vehicle and an autonomous delivery robot, and
reinforcement learning practice on the task training in the simulator. We have
published the proposed simulator in Github.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 19:05:27 GMT""}]","2022-05-18"
"2205.07946","Tom\'a\v{s} Mrkvi\v{c}ka","Ji\v{r}\'i Dvo\v{r}\'ak, Radim Reme\v{s}, Ladislav Ber\'anek and
  Tom\'a\v{s} Mrkvi\v{c}ka","binspp: An R Package for Bayesian Inference for Neyman-Scott Point
  Processes with Complex Inhomogeneity Structure",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  The Neyman-Scott point process is a widely used point process model which is
easily interpretable and easily extendable to include various types of
inhomogeneity. The inference for such complex models is then complicated and
fast methods, such as minimum contrast method or composite likelihood approach
do not provide accurate estimates or fail completely. Therefore, we introduce
Bayesian MCMC approach for the inference of Neymann-Scott point process models
with inhomogeneity in any or all of the following model components: process of
cluster centers, mean number of points in a cluster, spread of the clusters. We
also extend the Neyman-Scott point process to the case of overdispersed or
underdispersed cluster sizes and provide a Bayesian MCMC algorithm for its
inference. The R package binspp provides these estimation methods in an easy to
handle implementation, with detailed graphical output including traceplots for
all model parameters and further diagnostic plots. All inhomogeneities are
modelled by spatial covariates and the Bayesian inference for the corresponding
regression parameters is provided.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 19:07:53 GMT""}]","2022-05-18"
"2205.07947","Yotam Gershon","Yotam Gershon, Yuval Cassuto","Genomic Compression with Read Alignment at the Decoder",,,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  We propose a new compression scheme for genomic data given as sequence
fragments called reads. The scheme uses a reference genome at the decoder side
only, freeing the encoder from the burdens of storing references and performing
computationally costly alignment operations. The main ingredient of the scheme
is a multi-layer code construction, delivering to the decoder sufficient
information to align the reads, correct their differences from the reference,
validate their reconstruction, and correct reconstruction errors. The core of
the method is the well-known concept of distributed source coding with decoder
side information, fortified by a generalized-concatenation code construction
enabling efficient embedding of all the information needed for reliable
reconstruction. We first present the scheme for the case of substitution errors
only between the reads and the reference, and then extend it to support reads
with a single deletion and multiple substitutions. A central tool in this
extension is a new distance metric that is shown analytically to improve
alignment performance over existing distance metrics.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 19:10:13 GMT""},{""version"":""v2"",""created"":""Thu, 9 Feb 2023 17:09:39 GMT""}]","2023-02-10"
"2205.07948","Ravneet S. Bedi","Ravneet S. Bedi, Tony Gherghetta and Maxim Pospelov","Enhanced EDMs from Small Instantons","21 pages, 4 figures; v2: version published in PRD","Phys. Rev. D 106 (2022) 1, 015030","10.1103/PhysRevD.106.015030","UMN-TH-4122/22, FTPI-MINN-22/13","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that models in which the strong $CP$ problem is solved by introducing
an axion field with a mass enhanced by non-QCD UV dynamics at a scale
$\Lambda_{\rm SI}$ exhibit enhanced sensitivity to external sources of $CP$
violation. In the presence of higher-dimensional $CP$-odd sources at a scale
$\Lambda_{\rm CP}$, the same mechanisms that enhance the axion mass also modify
the axion potential, shifting the potential minimum by a factor
$\propto\Lambda^2_{\rm SI}/\Lambda^2_{\rm CP}$. This phenomenon of
$CP$-violation enhancement, which puts stringent constraints on the scale of
new physics, is explicitly demonstrated within a broad class of ""small
instanton"" models with $CP$-odd sources arising from the dimension-six Weinberg
gluonic and four-fermion operators. We find that for heavy axion masses
$\gtrsim 100$MeV, arising from new dynamics at $\Lambda_{\rm SI}\lesssim
10^{10}$GeV, $CP$ violation generated up to the Planck scale can be probed by
future electric dipole moment experiments.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 19:12:21 GMT""},{""version"":""v2"",""created"":""Thu, 4 Aug 2022 17:47:30 GMT""}]","2022-08-05"
"2205.07949","Dhandeep Challagundla","Dhandeep Challagundla, Mehedi Galib, Ignatius Bezzam and Riadul Islam","Power and Skew Reduction Using Resonant Energy Recycling in 14-nm FinFET
  Clocks",,,,,"eess.SY cs.AR cs.SY","http://creativecommons.org/licenses/by/4.0/","  As the demand for high-performance microprocessors increases, the circuit
complexity and the rate of data transfer increases resulting in higher power
consumption. We propose a clocking architecture that uses a series LC resonance
and inductor matching technique to address this bottleneck. By employing pulsed
resonance, the switching power dissipated is recycled back. The inductor
matching technique aids in reducing the skew, increasing the robustness of the
clock network. This new resonant architecture saves over 43% power and 91% skew
clocking a range of 1--5 GHz, compared to a conventional primary-secondary
flip-flop-based CMOS architecture.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 19:17:52 GMT""}]","2022-05-18"
"2205.07950","Nikolay Kudrin","Graham Elliott, Nikolay Kudrin, Kaspar W\""uthrich","(When) Can We Detect $p$-Hacking?","Some parts of this paper are based on material in earlier versions of
  our arXiv working paper ""Detecting p-hacking"" (arXiv:1906.06711), which were
  not included in the final published version (Elliott et al., 2022,
  Econometrica)",,,,"econ.EM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  $p$-Hacking can undermine the validity of empirical studies. A flourishing
empirical literature investigates the prevalence of $p$-hacking based on the
empirical distribution of reported $p$-values across studies. Interpreting
results in this literature requires a careful understanding of the power of
methods used to detect different types of $p$-hacking. We theoretically study
the implications of likely forms of $p$-hacking on the distribution of reported
$p$-values and the power of existing methods for detecting it. Power can be
quite low, depending crucially on the particular $p$-hacking strategy and the
distribution of actual effects tested by the studies. We relate the power of
the tests to the costs of $p$-hacking and show that power tends to be larger
when $p$-hacking is very costly. Monte Carlo simulations support our
theoretical results.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 19:18:55 GMT""}]","2022-05-18"
"2205.07951","Xi Long","Xi Long, Daniel J. Patnaude, Paul P. Plucinsky and Terrance J. Gaetz","The Proper Motion of the Pulsar J1124-5916 in the Galactic Supernova
  Remnant G292.0+1.8","Accepted for publication in ApJ, 15 pages, 12 figures, 6 tables",,"10.3847/1538-4357/ac704b",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We present the first direct measurement of the proper motion of pulsar
J1124-5916 in the young, oxygen-rich supernova remnant G292.0+1.8. Using deep
Chandra ACIS-I observations from 2006 and 2016, we measure a positional change
of $0.^{\prime\prime}21$ $\pm$ $0.^{\prime\prime}05$ over the $\sim$ 10 year
baseline, or $\sim$ $0.^{\prime\prime}02$ yr$^{-1}$. At a distance of 6.2 $\pm$
0.9 kpc, this corresponds to a kick velocity in the plane of the sky of
$\mathrm{612\pm 152\,km \, s^{-1}}$. We compare this direct measurement against
the velocity inferred from estimates based on the center of mass of the ejecta.
Additionally, we use this new proper motion measurement to compare the motion
of the neutron star to the center of expansion of the optically emitting
ejecta. We derive an age estimate for the supernova remnant of $\gtrsim$ 2000
years. The high measured kick velocity is in line with recent studies of high
proper motion neutron stars in other Galactic supernova remnants, and
consistent with a hydrodynamic origin to the neutron star kick.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 19:20:53 GMT""}]","2022-06-29"
"2205.07952","Damien Tourret","Thomas Isensee and Damien Tourret","Convective effects on columnar dendritic solidification -- A multiscale
  dendritic needle network study",,"Acta Materialia 234 (2022) 118035","10.1016/j.actamat.2022.118035",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Gravity-induced buoyancy, inevitable in most solidification processes,
substantially alters the dynamics of crystal growth, such that incorporating
fluid flow in solidification models is crucial to understand and predict key
aspects of microstructure selection. Here, we present a multi-scale Dendritic
Needle Network (DNN) model for directional solidification that includes buoyant
flow in the liquid, and apply it to a range of alloys and growth conditions.
After a brief presentation of the model, we study the selection of stable
primary dendrite arm spacings in Al-4at.%Cu and in Ti-45at.%Al alloys under
different gravity levels, comparing both applications to published phase-field
results and experimental measurements. Then, we simulate the oscillatory growth
behavior recently reported via X-ray in situ imaging of directional
solidification of nickel-based superalloy CMSX-4. In this last application, the
DNN simulations manage to reproduce the oscillatory growth behavior, and hence
permit identifying the fundamental mechanisms behind the oscillatory growth
regime. In particular, we show that sustained oscillations occur when the
average liquid flow velocity is close to the crystal growth velocity, and that
primary dendritic spacings also play a crucial role in the oscillatory
behavior.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 19:24:07 GMT""},{""version"":""v2"",""created"":""Mon, 8 Aug 2022 18:44:19 GMT""}]","2022-08-10"
"2205.07953","Derya Soydaner","H\""useyin Bahtiyar, Derya Soydaner, Esra Y\""uksel","Application of multilayer perceptron with data augmentation in nuclear
  physics",,,"10.1016/j.asoc.2022.109470",,"cs.LG nucl-th","http://creativecommons.org/licenses/by/4.0/","  Neural networks have become popular in many fields of science since they
serve as promising, reliable and powerful tools. In this work, we study the
effect of data augmentation on the predictive power of neural network models
for nuclear physics data. We present two different data augmentation
techniques, and we conduct a detailed analysis in terms of different depths,
optimizers, activation functions and random seed values to show the success and
robustness of the model. Using the experimental uncertainties for data
augmentation for the first time, the size of the training data set is
artificially boosted and the changes in the root-mean-square error between the
model predictions on the test set and the experimental data are investigated.
Our results show that the data augmentation decreases the prediction errors,
stabilizes the model and prevents overfitting. The extrapolation capabilities
of the MLP models are also tested for newly measured nuclei in AME2020 mass
table, and it is shown that the predictions are significantly improved by using
data augmentation.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 19:29:37 GMT""},{""version"":""v2"",""created"":""Tue, 5 Jul 2022 12:47:09 GMT""}]","2022-09-29"
"2205.07954","Nina Voronova","A. M. Grudinina and N. S. Voronova","Dark and thermal reservoir contributions to polariton sound velocity","6 pages, 4 figures","Phys. Rev. B 106, L121301 (2022)","10.1103/PhysRevB.106.L121301",,"cond-mat.mes-hall cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Exciton-polaritons in an optical microcavity can form a macroscopically
coherent state despite being an inherently driven-dissipative system. In
comparison with equilibrium bosonic fluids, polaritonic condensates possess
multiple peculiarities that make them behave differently from well-known
textbook examples. One such peculiarity is the presence of dark excitons which
are created by the pump together with optically-active particles. They can
considerably affect the spectrum of elementary excitations of the condensate
and hence change its superfluid properties. Here, we theoretically analyze the
influence of the bright and dark ``reservoir'' populations on the sound
velocity $c_s$ of incoherently-driven polaritons. Both pulsed and
continuous-wave pumping schemes characterized by essentially different
condensate-to-reservoir ratio are considered. We show that the dark exciton
contribution leads to considerable lowering of $c_s$ and to its deviation from
the square-root-like behavior on the system's chemical potential (measurable
condensate blueshift). Importantly, our model allows to unambiguously define
the density of dark excitons in the system by experimentally tracking $c_s$
against the condensate blueshift and fitting the dependence at a given
temperature.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 19:29:45 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jul 2022 15:56:24 GMT""}]","2022-09-16"
"2205.07955","Antonella Meninno","Antonella Meninno and Ion Errea","Absence of sizable superconductivity in hydrogen boride: A first
  principles study",,,"10.1103/PhysRevB.106.214508",,"cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  The recently synthesized hydrogen boride monolayer in the Cmmm phase is a
promising super-conductor due to its similarity to MgB2 and the large hydrogen
content in its structure. Making use of first-principles calculations based on
density functional theory, we study its electronic, vibrational,and
superconducting properties and conclude that, despite the expectations,
hydrogen boride does not have a sizable superconducting critical temperature.
The presence of hydrogen in the system alters the boron-boron bonding,
weakening the electron-phonon interaction. We have studied the effect of
enhancing the critical temperature by doping the system, but the inclusion of
electrons or holes reveals ineffective. We attribute the small critical
temperature of this system to the vanishing hydrogen character of the states at
the Fermi level, which are dominated by boron p states. Our results determine
that a large proportion of hydrogen-like states are needed at the Fermi level
to attain a large superconducting critical temperature in hydrogenated
monolayers.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 19:40:31 GMT""}]","2022-12-21"
"2205.07956","Fernando de Melo","Ra\'ul O. Vallejos, Pedro Silva Correia, Paola Concha Obando, Nina
  Machado O'Neill, Alexandre Baron Tacla, Fernando de Melo","Quantum state inference from coarse-grained descriptions: analysis and
  an application to quantum thermodynamics","14+5 pages, 9+2 figures. Comments are welcome",,"10.1103/PhysRevA.106.012219",,"quant-ph cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  The characterization of physical systems relies on the observable properties
which are measured, and how such measurements are performed. Here we analyze
two ways of assigning a description to a quantum system assuming that we only
have access to coarse-grained properties. More specifically, we compare the
Maximum Entropy Principle method, with the Bayesian-inspired recently proposed
Average Assignment Map method [P. S. Correia et al, Phys. Rev. A 103, 052210
(2021)]. Despite the fact that the assigned descriptions by both methods
respect the measured constraints, and that they share the same conceptual
foundations, the descriptions differ in scenarios that go beyond the
traditional system-environment structure. The Average Assignment Map is thus
shown to be a more sensible choice for the ever more prevalent scenario of
complex quantum systems. We discuss the physics behind such a difference, and
further exploit it in a quantum thermodynamics process.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 19:42:24 GMT""}]","2022-08-10"
"2205.07957","Mohammed Alser","Mohammed Alser, Joel Lindegger, Can Firtina, Nour Almadhoun, Haiyu
  Mao, Gagandeep Singh, Juan Gomez-Luna, Onur Mutlu","Going From Molecules to Genomic Variations to Scientific Discovery:
  Intelligent Algorithms and Architectures for Intelligent Genome Analysis","arXiv admin note: text overlap with arXiv:2008.00961",,,,"q-bio.GN cs.AR q-bio.QM","http://creativecommons.org/licenses/by/4.0/","  We now need more than ever to make genome analysis more intelligent. We need
to read, analyze, and interpret our genomes not only quickly, but also
accurately and efficiently enough to scale the analysis to population level.
There currently exist major computational bottlenecks and inefficiencies
throughout the entire genome analysis pipeline, because state-of-the-art genome
sequencing technologies are still not able to read a genome in its entirety. We
describe the ongoing journey in significantly improving the performance,
accuracy, and efficiency of genome analysis using intelligent algorithms and
hardware architectures. We explain state-of-the-art algorithmic methods and
hardware-based acceleration approaches for each step of the genome analysis
pipeline and provide experimental evaluations. Algorithmic approaches exploit
the structure of the genome as well as the structure of the underlying
hardware. Hardware-based acceleration approaches exploit specialized
microarchitectures or various execution paradigms (e.g., processing inside or
near memory) along with algorithmic changes, leading to new hardware/software
co-designed systems. We conclude with a foreshadowing of future challenges,
benefits, and research directions triggered by the development of both very low
cost yet highly error prone new sequencing technologies and specialized
hardware chips for genomics. We hope that these efforts and the challenges we
discuss provide a foundation for future work in making genome analysis more
intelligent. The analysis script and data used in our experimental evaluation
are available at: https://github.com/CMU-SAFARI/Molecules2Variations
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 19:43:13 GMT""}]","2022-05-18"
"2205.07958","Ekaterina Amerik","Ekaterina Amerik and Fr\'ed\'eric Campana","On algebraically coisotropic submanifolds of holomorphic symplectic
  manifolds","17 pages. v2: an improvement following a recent work of B. Taji
  (results valid for fibers with good minimal models rather than semiample
  canonical bundle). V3: minor corrections, a remark added",,,,"math.AG math.CV","http://creativecommons.org/licenses/by/4.0/","  We investigate algebraically coisotropic submanifolds $X$ in a holomorphic
symplectic projective manifold $M$. Motivated by our results in the
hypersurface case, we raise the following question: when $X$ is not uniruled,
is it true that up to a finite \'etale cover, the pair $(X,M)$ is a product
$(Z\times Y, N\times Y)$ where $N, Y$ are holomorphic symplectic and $Z\subset
N$ is Lagrangian? We prove that this is indeed the case when $M$ is an abelian
variety, and give some partial answer when the canonical bundle $K_X$ is
semi-ample. In particular, when $K_X$ is nef and big, $X$ is Lagrangian in $M$
(in fact this also holds without nefness assumption). We also remark that
Lagrangian submanifolds do not exist on a sufficiently general Abelian variety,
in contrast to the case when $M$ is irreducible hyperk\""ahler.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 19:46:00 GMT""},{""version"":""v2"",""created"":""Mon, 4 Jul 2022 22:09:24 GMT""},{""version"":""v3"",""created"":""Thu, 15 Dec 2022 15:51:49 GMT""}]","2022-12-16"
"2205.07959","Dejan Markovikj","Dejan Markovikj","Deep Apprenticeship Learning for Playing Games","A dissertation submitted in partial fulfillment of the requirements
  for the degree of Master of Science in Computer Science at University of
  Oxford",,,,"cs.LG cs.AI cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In the last decade, deep learning has achieved great success in machine
learning tasks where the input data is represented with different levels of
abstractions. Driven by the recent research in reinforcement learning using
deep neural networks, we explore the feasibility of designing a learning model
based on expert behaviour for complex, multidimensional tasks where reward
function is not available. We propose a novel method for apprenticeship
learning based on the previous research on supervised learning techniques in
reinforcement learning. Our method is applied to video frames from Atari games
in order to teach an artificial agent to play those games. Even though the
reported results are not comparable with the state-of-the-art results in
reinforcement learning, we demonstrate that such an approach has the potential
to achieve strong performance in the future and is worthwhile for further
research.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 19:52:45 GMT""}]","2022-05-18"
"2205.07960","Badr AlKhamissi","Badr AlKhamissi, Mona Diab","Meta AI at Arabic Hate Speech 2022: MultiTask Learning with
  Self-Correction for Hate Speech Classification","Accepted at the 5th Workshop on Open-Source Arabic Corpora and
  Processing Tools (OSACT5/LREC 2022)",,,,"cs.CL","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, we tackle the Arabic Fine-Grained Hate Speech Detection shared
task and demonstrate significant improvements over reported baselines for its
three subtasks. The tasks are to predict if a tweet contains (1) Offensive
language; and whether it is considered (2) Hate Speech or not and if so, then
predict the (3) Fine-Grained Hate Speech label from one of six categories. Our
final solution is an ensemble of models that employs multitask learning and a
self-consistency correction method yielding 82.7% on the hate speech subtask --
reflecting a 3.4% relative improvement compared to previous work.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 19:53:16 GMT""}]","2022-05-18"
"2205.07961","Daniel Galicer","Tom\'as Fernandez Vidal, Daniel Galicer and Pablo Sevilla-Peris","Multipliers for Hardy spaces of Dirichlet series","29 pages",,,,"math.CV math.FA","http://creativecommons.org/licenses/by/4.0/","  We characterize the space of multipliers from the Hardy space of Dirichlet
series $\mathcal H_p$ into $\mathcal H_q$ for every $1 \leq p,q \leq \infty$.
For a fixed Dirichlet series, we also investigate some structural properties of
its associated multiplication operator. In particular, we study the norm, the
essential norm, and the spectrum for an operator of this kind. We exploit the
existing natural identification of spaces of Dirichlet series with spaces of
holomorphic functions in infinitely many variables and apply several methods
from complex and harmonic analysis to obtain our results. As a byproduct we get
analogous statements on such Hardy spaces of holomorphic functions.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 19:58:45 GMT""}]","2022-05-18"
"2205.07962","Yijun Wang","Yijun Wang, Kris Pardo, Tzu-Ching Chang, Olivier Dor\'e","Constraining the Stochastic Gravitational Wave Background with
  Photometric Surveys","7 pages, 2 figures; updated with minor text changes","Phys. Rev. D 106, 084006 (2022)","10.1103/PhysRevD.106.084006",,"gr-qc astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The detection of the Stochastic Gravitational Wave Background (SGWB) is
essential for understanding black hole populations, especially for supermassive
black hole binaries. The recent promising results from various Pulsar Timing
Array (PTA) collaborations allude to an imminent detection. In this paper, we
investigate the relative astrometric gravitational wave detection method, which
can contribute to SGWB studies in the microhertz range. We consider the Roman
Space Telescope and Gaia as candidates and quantitatively discuss the survey
sensitivity in both the frequency and spatial domains. We emphasize the
importance of survey specific constraints on performance estimates by
considering mean field of view (FoV) signal subtraction and angular power
spectrum binning. We conclude that if the SGWB is at a similar level as in PTA
estimates, both Roman and Gaia have the potential to detect this
frequency-domain power excess. However, both Roman and Gaia are subject to FoV
limitations, and are unlikely to be sensitive to the spatial pattern of the
SGWB.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 19:59:19 GMT""},{""version"":""v2"",""created"":""Wed, 12 Oct 2022 18:13:39 GMT""}]","2022-10-14"
"2205.07963","Kong Ooi Tan","Yifan Quan, Jakob Steiner, Yifu Ouyang, Kong Ooi Tan, W. Thomas
  Wenckebach, Patrick Hautle, and Robert G. Griffin","Integrated, stretched, and adiabatic solid effects",,,,,"physics.chem-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper presents a theory describing the dynamic nuclear polarization
(DNP) process associated with an arbitrary frequency swept microwave pulse. The
theory is utilized to explain the integrated solid effect (ISE) as well as the
newly discovered stretched solid effect (SSE) and adiabatic solid effect (ASE).
It is verified with experiments performed at 9.4 GHz (0.34 T) on single
crystals of naphthalene doped with pentacene-d14. It is shown that SSE and ASE
can be more efficient than ISE. Furthermore, the theory predicts that the
efficiency of the SSE improves at high magnetic fields, where the EPR linewidth
is small compared to the nuclear Larmor frequency. In addition, we show that
ISE, SSE, and ASE are based on similar physical principles and we suggest
definitions to distinguish among them.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 20:01:28 GMT""}]","2022-05-18"
"2205.07964","Meridith Joyce","Meridith Joyce, Christian I. Johnson, Tommaso Marchetti, R. Michael
  Rich, Iulia Simion and John Bourke","The Ages of Galactic Bulge Stars with Realistic Uncertainties","accepted to ApJ; revisions complete",,"10.3847/1538-4357/acb692",,"astro-ph.SR astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Using modern isochrones with customized physics and carefully considered
statistical techniques, we recompute the age distribution for a sample of 91
micro-lensed dwarfs in the Galactic bulge presented by Bensby et al. (2017) and
do not produce an age distribution consistent with their results. In
particular, our analysis finds that only 15 of 91 stars have ages younger than
7 Gyr, compared to their finding of 42 young stars in the same sample. While we
do not find a constituency of very young stars, our results do suggest the
presence of an $\sim8$ Gyr population at the highest metallicities, thus
contributing to long-standing debate about the age--metallicity distribution of
the Galactic bulge. We supplement this with attempts at independent age
determinations from two sources of photometry, BDBS and \textit{Gaia}, but find
that the imprecision of photometric measurements prevents reliable age and age
uncertainty determinations. Lastly, we present age uncertainties derived using
a first-order consideration of global modeling uncertainties in addition to
standard observational uncertainties. The theoretical uncertainties are based
on the known variance of free parameters in the 1D stellar evolution models
used to generate isochrones, and when included, result in age uncertainties of
$2$--$5$ Gyr for this spectroscopically well-constrained sample. These error
bars, which are roughly twice as large as typical literature values, constitute
realistic lower limits on the true age uncertainties.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 20:02:01 GMT""},{""version"":""v2"",""created"":""Sat, 18 Feb 2023 00:47:24 GMT""}]","2023-03-29"
"2205.07965","Umar Hashmi Md","Md Umar Hashmi, Arpan Koirala, Hakan Ergun, Dirk Van Hertem","Flexible and curtailable resource activation in three-phase unbalanced
  distribution networks",,,,,"eess.SY cs.SY math.OC","http://creativecommons.org/licenses/by/4.0/","  The need for flexibility and curtailable resources is crucial for ensuring
the healthy operation of future distribution networks (DN). In this work, we
propose a network-state driven framework that distribution system operators
(DSOs) can utilize for activating flexible and curtailable resources for
alleviating network voltage and thermal issues, while accounting for network
voltage and current imbalances. This approach assumes the availability of
dynamic network state information and uses nodal sensitivities for calculating
a flexibility activation signal (FAS). The signal design is motivated by
volt-Var and volt-watt inverter control, and thus bounded. The FAS also
considers network voltage and current imbalances and incentivizes activation of
active and reactive power flexibilities for reducing imbalance in addition to
mitigating voltage and thermal imbalances in a three-phase unbalanced
distribution network. The FAS design resembles optimal power flow duals, often
used as locational marginal prices. The gains associated with the imbalance
component of the objective function of three-phase unbalanced resource
activation (TPU-RA) is performed using Pareto optimality. A numerical case
study is presented showing the efficacy of the proposed framework in avoiding
network issues while reducing voltage unbalance factor by more than 80\%.
Further, DN's flexibility needs are quantified for location and time of day.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 20:02:37 GMT""}]","2022-05-18"
"2205.07966","Mainak Mukhopadhyay","Mainak Mukhopadhyay","Searching for supernova neutrinos with GW memory triggers","6 pages, 3 figures. Contribution to the 2022 Electroweak session of
  the 56th Rencontres de Moriond",,,,"astro-ph.HE gr-qc hep-ph","http://creativecommons.org/licenses/by/4.0/","  Anisotropic neutrino emission from a core-collapse supernova (CCSN) causes a
permanent change in the local space-time metric, called the gravitational wave
(GW) memory. Long considered unobservable, this effect will be detectable in
the near future, at deci-Hertz GW interferometers. I will present a novel idea,
where observations of the neutrino GW memory from CCSNe will enable
time-triggered searches of supernova neutrinos at megaton (Mt) scale detectors,
which will open a new avenue to studying supernova neutrinos.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 20:03:53 GMT""}]","2022-05-18"
"2205.07967","Nancy Remage Evans","Nancy Remage Evans, Scott Engle, Ignazio Pillitteri, Edward Guinan, H.
  Moritz G\""unther, Scott Wolk, Hilding Neilson, Massimo Marengo, Lynn D.
  Matthews, Sofia Moschou, Jeremy J. Drake, Elaine M. Winston, Maxwell Moe,
  Pierre Kervella, and Louise Breuval","X-rays in Cepheids: Identifying Low-Mass Companions of Intermediate-Mass
  Stars","Accepted by ApJ",,,,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  X-ray observations have been made of a sample of 20 classical Cepheids,
including two new observations (Polaris and {\it l} Car) reported here. The
occurrence of X-ray flux around the pulsation cycle is discussed. Three
Cepheids are detected ($\delta$ Cep, $\beta$ Dor, and Polaris). X-rays have
also been detected from the low--mass F, G, and K companions of 4 Cepheids
(V473 Lyr, R Cru, V659 Cen, and W Sgr), and one hot companion (S Mus). Upper
limits on the X-ray flux of the remaining Cepheids provide an estimate that
28\% have low mass companions. This fraction of low--mass companions in
intermediate mass Cepheids is significantly lower than expected from random
pairing with the field IMF. Combining the companion fraction from X-rays with
that from ultraviolet observations results in a binary/multiple fraction of
57\% $\pm$12\% for Cepheids with the ratios q $>$ 0.1 and separations a $>$ 1
au. This is a lower limit since M stars are not included. X-ray observations
detect less massive companions than other existing studies of intermediate mass
stars. Our measured occurrence rate of unresolved, low-mass companions to
Cepheids suggests that intermediate-period binaries derive from a combination
of disk and core fragmentation and accretion. This yields a hybrid mass-ratio
distribution that is skewed toward small values compared to a uniform
distribution but is still top-heavy compared to random pairings drawn from the
IMF.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 20:06:41 GMT""}]","2022-05-18"
"2205.07968","Kenny \v{S}torgel","Hoang La and Kenny \v{S}torgel","$2$-distance, injective, and exact square list-coloring of planar graphs
  with maximum degree 4",,,"10.1016/j.disc.2023.113405",,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the past various distance based colorings on planar graphs were
introduced. We turn our focus to three of them, namely $2$-distance coloring,
injective coloring, and exact square coloring. A $2$-distance coloring is a
proper coloring of the vertices in which no two vertices at distance $2$
receive the same color, an injective coloring is a coloring of the vertices in
which no two vertices with a common neighbor receive the same color, and an
exact square coloring is a coloring of the vertices in which no two vertices at
distance exactly $2$ receive the same color. We prove that planar graphs with
maximum degree $\Delta = 4$ and girth at least $4$ are $2$-distance list
$(\Delta + 7)$-colorable and injectively list $(\Delta + 5)$-colorable.
Additionally, we prove that planar graphs with $\Delta = 4$ are injectively
list $(\Delta + 7)$-colorable and exact square list $(\Delta + 6)$-colorable.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 20:09:55 GMT""}]","2023-03-20"
"2205.07969","Jose Fontanari","Henrique A. T\'ortura and Jos\'e F. Fontanari","The synergy between two threats: disinformation and Covid-19",,"Mathematical Models and Methods in Applied Sciences 32 (2022)
  2077-2097","10.1142/S021820252250049X",,"physics.soc-ph physics.bio-ph q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The breakdown of trusted sources of information is probably one of the most
serious problems today, since in the absence of a common ground, it will be
impossible to address the problems that trouble our contemporary world. The
Covid-19 pandemic is just a recent situation where the lack of agreed stances
has led to failure and hopelessness. In fact, disinformation surrounding the
Covid-19 has been a distinctive feature of this pandemic since its very
beginning and has hampered what is perhaps the most important initiative to
prevent the spread of the coronavirus, viz., an effective communication between
scientifically-minded health authorities and the general public. To investigate
how disinformation threatens epistemic security, here we propose and solve
analytically an evolutionary game-theoretic model where the individuals must
accurately estimate some property of their hazardous environment. They can
either explore the environment or copy the estimate from another individual,
who may display a distorted version of its estimate. We find that the
exploration-only strategy is optimal when the environment is relatively safe
and the individuals are not reliable. In this doomsday scenario, disinformation
erodes trust and suppresses the ability of the individuals to share information
with one another.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 20:10:25 GMT""},{""version"":""v2"",""created"":""Thu, 16 Jun 2022 19:10:41 GMT""},{""version"":""v3"",""created"":""Sat, 24 Sep 2022 14:25:12 GMT""}]","2023-01-03"
"2205.07970","Maur\'icio Gruppi","Maur\'icio Gruppi, Panayiotis Smeros, Sibel Adal{\i}, Carlos Castillo,
  Karl Aberer","SciLander: Mapping the Scientific News Landscape",,,,,"cs.CY cs.SI physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  The COVID-19 pandemic has fueled the spread of misinformation on social media
and the Web as a whole. The phenomenon dubbed `infodemic' has taken the
challenges of information veracity and trust to new heights by massively
introducing seemingly scientific and technical elements into misleading
content. Despite the existing body of work on modeling and predicting
misinformation, the coverage of very complex scientific topics with inherent
uncertainty and an evolving set of findings, such as COVID-19, provides many
new challenges that are not easily solved by existing tools. To address these
issues, we introduce SciLander, a method for learning representations of news
sources reporting on science-based topics. SciLander extracts four
heterogeneous indicators for the news sources; two generic indicators that
capture (1) the copying of news stories between sources, and (2) the use of the
same terms to mean different things (i.e., the semantic shift of terms), and
two scientific indicators that capture (1) the usage of jargon and (2) the
stance towards specific citations. We use these indicators as signals of source
agreement, sampling pairs of positive (similar) and negative (dissimilar)
samples, and combine them in a unified framework to train unsupervised news
source embeddings with a triplet margin loss objective. We evaluate our method
on a novel COVID-19 dataset containing nearly 1M news articles from 500 sources
spanning a period of 18 months since the beginning of the pandemic in 2020. Our
results show that the features learned by our model outperform state-of-the-art
baseline methods on the task of news veracity classification. Furthermore, a
clustering analysis suggests that the learned representations encode
information about the reliability, political leaning, and partisanship bias of
these sources.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 20:20:43 GMT""}]","2022-05-18"
"2205.07971","Evgeny Panov","Evgeny Yu. Panov","On entropy solutions of scalar conservation laws with discontinuous flux",,,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We introduce the notion of entropy solutions (e.s.) to a conservation law
with an arbitrary jump continuous flux vector and prove existence of the
largest and the smallest e.s. to the Cauchy problem. The monotonicity and
stability properties of these solutions are also established. In the case of a
periodic initial function we derive the uniqueness of e.s. Generally, the
uniqueness property can be violated, which is confirmed by an example. Finally,
we proved that in the case of single space variable a weak limit of a sequence
of spatially periodic e.s. is an e.s. as well.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 20:22:57 GMT""}]","2022-05-18"
"2205.07972","Valentyn Boreiko","Valentyn Boreiko, Maximilian Augustin, Francesco Croce, Philipp
  Berens, Matthias Hein","Sparse Visual Counterfactual Explanations in Image Space",,"GCPR 2022","10.1007/978-3-031-16788-1_9",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Visual counterfactual explanations (VCEs) in image space are an important
tool to understand decisions of image classifiers as they show under which
changes of the image the decision of the classifier would change. Their
generation in image space is challenging and requires robust models due to the
problem of adversarial examples. Existing techniques to generate VCEs in image
space suffer from spurious changes in the background. Our novel perturbation
model for VCEs together with its efficient optimization via our novel
Auto-Frank-Wolfe scheme yields sparse VCEs which lead to subtle changes
specific for the target class. Moreover, we show that VCEs can be used to
detect undesired behavior of ImageNet classifiers due to spurious features in
the ImageNet dataset.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 20:23:11 GMT""},{""version"":""v2"",""created"":""Thu, 29 Sep 2022 10:36:18 GMT""}]","2022-10-25"
"2205.07973","Hasibul Jamil","Hasibul Jamil, Ning Yang and Ning Weng","Many Field Packet Classification with Decomposition and Reinforcement
  Learning","13 pages, published in IET Netw. arXiv admin note: substantial text
  overlap with arXiv:1902.10319 by other authors","IET Netw 2022 1-16","10.1049/ntw2.12038",,"cs.NI cs.AI cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Scalable packet classification is a key requirement to support scalable
network applications like firewalls, intrusion detection, and differentiated
services. With ever increasing in the line-rate in core networks, it becomes a
great challenge to design a scalable packet classification solution using
hand-tuned heuristics approaches. In this paper, we present a scalable
learning-based packet classification engine by building an efficient data
structure for different ruleset with many fields. Our method consists of the
decomposition of fields into subsets and building separate decision trees on
those subsets using a deep reinforcement learning procedure. To decompose given
fields of a ruleset, we consider different grouping metrics like standard
deviation of individual fields and introduce a novel metric called diversity
index (DI). We examine different decomposition schemes and construct decision
trees for each scheme using deep reinforcement learning and compare the
results. The results show that the SD decomposition metrics results in 11.5%
faster than DI metrics, 25% faster than random 2 and 40% faster than random 1.
Furthermore, our learning-based selection method can be applied to varying
rulesets due to its ruleset independence.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 20:24:37 GMT""}]","2022-05-18"
"2205.07974","Rahul Gupta Mr.","R. Gupta, F. Cosco, R. S. Malik, X. Chen, S. Saha, A. Ghosh, T.
  Pohlmann, J. R. L. Mardegan, S. Francoual, R. Stefanuik, J. Soderstrom, B.
  Sanyal, O. Karis, P. Svedlindh, P. M. Oppeneer, and R. Knut","Element resolved evidence of superdiffusive terahertz spin current
  arising from ultrafast demagnetization process","7 pages, 5 figures",,,,"cond-mat.mtrl-sci cond-mat.mes-hall cond-mat.other physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Using element-specific measurements of the ultrafast demagnetization of
Ru/Fe$_{65}$Co$_{35}$ heterostructures, we show that Ru can exhibit a
significant magnetic contrast (3% asymmetry) resulting from ultrafast spin
currents emanating from the demagnetization process of the FeCo layer. We use
this magnetic contrast to investigate how superdiffusive spin currents are
affected by the doping of heavy elements in the FeCo layer. We find that the
spin currents are strongly suppressed, and that the recovery process in Ru
slows down, by Re doping. This is in accordance with a change in interface
reflectivity of spin currents as found by the superdiffusive spin transport
model.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 20:26:05 GMT""},{""version"":""v2"",""created"":""Wed, 3 May 2023 10:30:44 GMT""}]","2023-05-04"
"2205.07976","Felix Wittwer","Felix Wittwer (1), Nicholas K. Sauter (2), Derek Mendez (2), Billy K.
  Poon (2), Aaron S. Brewster (2), James M. Holton (2), Michael E. Wall (3),
  William E. Hart (4), Deborah J. Bard (1), Johannes P. Blaschke (1) ((1)
  National Energy Research Scientific Computing Center, Lawrence Berkeley
  National Laboratory, USA, (2) Molecular Biophysics and Integrated Bioimaging
  Division, Lawrence Berkeley National Laboratory, USA, (3) Computer,
  Computational, and Statistical Sciences Division, Los Alamos National
  Laboratory, USA, (4) Sandia National Laboratories, USA)","Accelerating X-Ray Tracing for Exascale Systems using Kokkos",,,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The upcoming exascale computing systems Frontier and Aurora will draw much of
their computing power from GPU accelerators. The hardware for these systems
will be provided by AMD and Intel, respectively, each supporting their own GPU
programming model. The challenge for applications that harness one of these
exascale systems will be to avoid lock-in and to preserve performance
portability.
  We report here on our results of using Kokkos to accelerate a real-world
application on NERSC's Perlmutter Phase 1 (using NVIDIA A100 accelerators) and
the testbed system for OLCF's Frontier (using AMD MI250X). By porting to
Kokkos, we were able to successfully run the same X-ray tracing code on both
systems and achieved speed-ups between 13% and 66% compared to the original
CUDA code. These results are a highly encouraging demonstration of using Kokkos
to accelerate production science code.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 20:27:03 GMT""}]","2022-05-18"
"2205.07978","Maciej Dunajski","Peter Cameron, Maciej Dunajski, Paul Tod","Conformal Geodesics Cannot Spiral",,,,,"math.DG gr-qc hep-th math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  We show that conformal geodesics on a Riemannian manifold cannot spiral:
there does not exist a conformal geodesic which becomes trapped in every
neighbourhood of a point.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 20:34:59 GMT""}]","2022-05-20"
"2205.07979","Boro Sitnikovski","Boro Sitnikovski","Budge: a programming language and a theorem prover",,,,,"cs.PL cs.CL cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a simple programming language based on G\""odel numbering and prime
factorization, enhanced with explicit, scoped loops, allowing for easy program
composition. Further, we will present a theorem prover that allows expressing
and working with formal systems. The theorem prover is simple as it relies
merely on a substitution rule and set equality to derive theorems. Finally, we
will represent the programming language in the theorem prover. We will show the
syntax and semantics of both, and then provide a few example programs and their
evaluation.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 20:35:25 GMT""},{""version"":""v2"",""created"":""Thu, 19 May 2022 12:25:22 GMT""},{""version"":""v3"",""created"":""Tue, 24 May 2022 13:15:24 GMT""},{""version"":""v4"",""created"":""Thu, 4 Aug 2022 11:47:22 GMT""},{""version"":""v5"",""created"":""Tue, 23 Aug 2022 23:23:12 GMT""},{""version"":""v6"",""created"":""Tue, 6 Dec 2022 11:48:21 GMT""}]","2022-12-07"
"2205.07980","Simone Assali","Simone Assali, Sebastian Koelling, Zeinab Abboud, J\'er\^ome Nicolas,
  Anis Attiaoui, and Oussama Moutanabbir","500-period epitaxial Ge/Si0.18Ge0.82 multi-quantum wells on silicon",,,"10.1063/5.0119624",,"cond-mat.mtrl-sci physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ge/SiGe multi-quantum well heterostructures are highly sought-after for
silicon-integrated optoelectronic devices operating in the broad range of the
electromagnetic spectrum covering infrared to terahertz wavelengths. However,
the epitaxial growth of these heterostructures at a thickness of a few microns
has been a challenging task due the lattice mismatch and its associated
instabilities resulting from the formation of growth defects. To elucidates
these limits, we outline herein a process for the strain-balanced growth on
silicon of 11.1 nm/21.5 nm Ge/Si0.18Ge0.82 superlattices (SLs) with a total
thickness of 16 {\mu}m corresponding to 500 periods. Composition, thickness,
and interface width are preserved across the entire SL heterostructure, which
is an indication of limited Si-Ge intermixing. High crystallinity and low
defect density are obtained in the Ge/Si0.18Ge0.82 layers, however, the
dislocation pile up at the interface with the growth substate induces
micrometer-longs cracks on the surface. This eventually leads to significant
layer tilt in the strain-balanced SL and in the formation of millimeter-long,
free-standing flakes. These results confirm the local uniformity of structural
properties and highlight the critical importance of threading dislocations in
shaping the wafer-level stability of thick multi-quantum well heterostructures
required to implement effective silicon-compatible Ge/SiGe photonic devices.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 20:36:56 GMT""}]","2022-11-08"
"2205.07981","Jack Singal","V. Petrosian, J. Singal, S. Mutchnick","Can the Distance-Redshift Relation Be Determined from Correlations
  Between Luminosities?","6 pages, 2 figures, updated to version accepted to ApJL, typos and
  misformattings removed",,"10.3847/2041-8213/ac85ac",,"astro-ph.CO astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore whether an independent determination of the distance-redshift
relation, and hence cosmological model parameters, can be obtained from the
apparent correlations between two different waveband luminosities or fluxes, as
has been claimed in recent works using the X-ray and ultraviolet luminosities
and fluxes of quasars. We show that such an independent determination is
possible only if the correlation between luminosities is obtained independent
of the cosmological model, and measured fluxes and redshifts; for example,
being based on sound theoretical models or unrelated observations. In
particular, we show that if the correlation is determined empirically from two
luminosities obtained from fluxes and redshifts, then the method suffers from
circularity. In case, as claimed in recent works, the observed correlation
between fluxes in very narrow redshift bins are used as proxy for the
luminosity correlation, then we show that one is dealing with a pure tautology
with no information on distances and cosmological model. We argue that the
problem arises because of the incomplete treatment of the correlation and we
use numerical methods with a joint X-ray and ultraviolet quasar data set to
demonstrate this shortcoming.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 20:41:32 GMT""},{""version"":""v2"",""created"":""Wed, 18 May 2022 20:30:49 GMT""},{""version"":""v3"",""created"":""Wed, 15 Jun 2022 16:47:15 GMT""},{""version"":""v4"",""created"":""Mon, 15 Aug 2022 00:23:25 GMT""},{""version"":""v5"",""created"":""Sat, 15 Oct 2022 22:47:39 GMT""}]","2022-10-18"
"2205.07982","Keyang Zhou","Keyang Zhou, Bharat Lal Bhatnagar, Jan Eric Lenssen, Gerard Pons-Moll","TOCH: Spatio-Temporal Object-to-Hand Correspondence for Motion
  Refinement",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  We present TOCH, a method for refining incorrect 3D hand-object interaction
sequences using a data prior. Existing hand trackers, especially those that
rely on very few cameras, often produce visually unrealistic results with
hand-object intersection or missing contacts. Although correcting such errors
requires reasoning about temporal aspects of interaction, most previous works
focus on static grasps and contacts. The core of our method are TOCH fields, a
novel spatio-temporal representation for modeling correspondences between hands
and objects during interaction. TOCH fields are a point-wise, object-centric
representation, which encode the hand position relative to the object.
Leveraging this novel representation, we learn a latent manifold of plausible
TOCH fields with a temporal denoising auto-encoder. Experiments demonstrate
that TOCH outperforms state-of-the-art 3D hand-object interaction models, which
are limited to static grasps and contacts. More importantly, our method
produces smooth interactions even before and after contact. Using a single
trained TOCH model, we quantitatively and qualitatively demonstrate its
usefulness for correcting erroneous sequences from off-the-shelf RGB/RGB-D
hand-object reconstruction methods and transferring grasps across objects.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 20:41:45 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jul 2022 10:12:23 GMT""}]","2022-07-22"
"2205.07983","Mathilde Bateson","Mathilde Bateson, Herv\'e Lombaert, Ismail Ben Ayed","Test-Time Adaptation with Shape Moments for Image Segmentation","Early Accept at International Conference on Medical Image Computing
  and Computer Assisted Intervention (MICCAI) 2022",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Supervised learning is well-known to fail at generalization under
distribution shifts. In typical clinical settings, the source data is
inaccessible and the target distribution is represented with a handful of
samples: adaptation can only happen at test time on a few or even a single
subject(s). We investigate test-time single-subject adaptation for
segmentation, and propose a Shape-guided Entropy Minimization objective for
tackling this task. During inference for a single testing subject, our loss is
minimized with respect to the batch normalization's scale and bias parameters.
We show the potential of integrating various shape priors to guide adaptation
to plausible solutions, and validate our method in two challenging scenarios:
MRI-to-CT adaptation of cardiac segmentation and cross-site adaptation of
prostate segmentation. Our approach exhibits substantially better performances
than the existing test-time adaptation methods. Even more surprisingly, it
fares better than state-of-the-art domain adaptation methods, although it
forgoes training on additional target data during adaptation. Our results
question the usefulness of training on target data in segmentation adaptation,
and points to the substantial effect of shape priors on test-time inference.
Our framework can be readily used for integrating various priors and for
adapting any segmentation network, and our code is available.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 20:47:13 GMT""}]","2022-05-18"
"2205.07984","Hans Boehringer","Hans Boehringer, Gayoung Chon","The Cosmic Large-Scale Structure in X-rays (CLASSIX) cluster survey IV:
  Superclusters in the local Universe at z <= 0.03","Published in Astronomy and Astrophysics, 31 pages, 28 figures","Astronomy and Astrophysics, 656, A144 (2021)","10.1051/0004-6361/202141341",,"astro-ph.CO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  It is important to map the large-scale matter distribution in the local
Universe for cosmological studies, such as the tracing of the large-scale
peculiar velocity flow, the characterisation of the environment for different
astronomical objects, and for precision measurements of cosmological
parameters. We used X-ray luminous clusters to map this matter distribution and
find that about 51% of the groups and clusters are members of superclusters
which occupy only a few percent of the volume. In this paper we provide a
detailed description of these large-scale structures. With a friends-to-friends
algorithm, we find eight superclusters with a cluster overdensity ratio of at
least two with five or more galaxy group and cluster members in the cosmic
volume out to z = 0.03. The four most prominent ones are the Perseus-Pisces,
the Centaurus, the Coma, and the Hercules supercluster, with lengths from about
40 to over 100 Mpc and estimated masses of 0.6 - 2.2 10^16 Msun. The largest of
these structures is the Perseus-Pisces supercluster. The four smaller
superclusters include the Local and the Abell 400 supercluster and two
superclusters in the constellations Sagittarius and Lacerta. We provide
detailed maps, member catalogues, and physical descriptions of the eight
superclusters. By constructing superclusters with a range of cluster
sub-samples with different lower X-ray luminosity limits, we show that the main
structures are always reliably recovered.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 20:52:02 GMT""}]","2022-05-25"
"2205.07985","Maik G\""unther","F. Lorenz, M. G\""unther","Expert Systems with Logic#. A Novel Modeling Framework for Logic
  Programming in an Object-Oriented Context of C#","23 pages, 4 figures, 4 tables, 7 appendices",,,,"cs.AI cs.PL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a novel approach how logic programming for expert systems can be
declared directly in an object-oriented language.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 20:52:27 GMT""}]","2022-05-18"
"2205.07986","Xin Zhao","Guangbin Ren, Xin Zhao","The twisted group algebra structure of the Cayley-Dickson algebra",,,,,"math.RA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Cayley-Dickson algebra has long been a challenge due to the lack of an
explicit multiplication table. Despite being constructible through inductive
construction, its explicit structure has remained elusive until now. In this
article, we propose a solution to this long-standing problem by revealing the
Cayley-Dickson algebra as a twisted group algebra with an explicit twist
function $\sigma(A,B)$. We show that this function satisfies the equation
$$e_Ae_B=(-1)^{\sigma(A,B)}e_{A\oplus B}$$ and provide a formula for the
relationship between the Cayley-Dickson algebra and split Cayley-Dickson
algebra, thereby giving an explicit expression for the twist function of the
split Cayley-Dickson algebra. Our approach not only resolves the lack of
explicit structure for the Cayley-Dickson algebra and split Cayley-Dickson
algebra but also sheds light on the algebraic structure underlying this
fundamental mathematical object.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 20:54:41 GMT""},{""version"":""v2"",""created"":""Mon, 13 Mar 2023 10:40:28 GMT""}]","2023-03-14"
"2205.07987","Karl Daningburg","Karl Daningburg and Richard O'Shaughnessy","Cost Minimization in Acquisition for Gravitational Wave Surrogate
  Modeling","8 pages, 4 figures",,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gravitational wave science is dependent upon expensive numerical simulations,
which provide the foundational understanding of binary merger radiation needed
to interpret observations of massive binary black holes. The high cost of these
simulations limits large-scale campaigns to explore the binary black hole
parameter space. Surrogate models have been developed to efficiently
interpolate between simulation results, but these models require a sufficiently
comprehensive sample to train on. Acquisition functions can be used to identify
points in the domain for simulation. We develop a new acquisition function
which accounts for the cost of simulating new points. We show that when applied
to a 3D domain of binary mass ratio and dimensionless spins, the accumulated
cost of simulation is reduced by a factor of about 10.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 20:57:59 GMT""}]","2022-05-18"
"2205.07988","Brianna Cantrall","Brianna Cantrall, Solomon Quinn, Emory F. Bunn","Optimal method for reconstructing polychromatic maps from broadband
  observations with an asymmetric antenna pattern",,"Phys. Rev. D 107, 123002 (2023)","10.1103/PhysRevD.107.123002",,"astro-ph.IM astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Broadband time-ordered data obtained from telescopes with a
wavelength-dependent, asymmetric beam pattern can be used to extract maps at
multiple wavelengths from a single scan. This technique is especially useful
when collecting data on cosmic phenomena such as the Cosmic Microwave
Background (CMB) radiation, as it provides the ability to separate the CMB
signal from foreground contaminants. We develop a method to determine the
optimal linear combinations of wavelengths (``colors'') that can be
reconstructed for a given telescope design and the number of colors that are
measurable with high signal-to-noise ratio. The optimal colors are found as
eigenvectors of a matrix derived from the inverse noise covariance matrix. When
the telescope is able to scan the sky isotropically, it is useful to transform
to a spherical harmonic basis, in which this matrix has a particularly simple
form. We propose using the optimal colors determined from the isotropic case
even when the actual scanning pattern is not isotropic (e.g., covers only part
of the sky). We perform simulations showing that maps in multiple colors can be
reconstructed accurately from both full-sky and partial-sky scans. Although the
original motivation for this research comes from mapping the CMB, this method
of polychromatic map-making will have broader applications throughout
astrophysics.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 21:01:04 GMT""},{""version"":""v2"",""created"":""Fri, 2 Jun 2023 18:25:32 GMT""}]","2023-06-06"
"2205.07989","Serafim Grubas","Serafim Grubas, Anton Duchkov and Georgy Loginov","Neural Eikonal Solver: improving accuracy of physics-informed neural
  networks for solving eikonal equation in case of caustics","The paper has 14 pages and 6 figures. Source code is available at
  https://github.com/sgrubas/NES",,"10.1016/j.jcp.2022.111789",,"physics.geo-ph physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  The concept of physics-informed neural networks has become a useful tool for
solving differential equations due to its flexibility. There are a few
approaches using this concept to solve the eikonal equation which describes the
first-arrival traveltimes of acoustic and elastic waves in smooth heterogeneous
velocity models. However, the challenge of the eikonal is exacerbated by the
velocity models producing caustics, resulting in instabilities and
deterioration of accuracy due to the non-smooth solution behaviour. In this
paper, we revisit the problem of solving the eikonal equation using neural
networks to tackle the caustic pathologies. We introduce the novel Neural
Eikonal Solver (NES) for solving the isotropic eikonal equation in two
formulations: the one-point problem is for a fixed source location; the
two-point problem is for an arbitrary source-receiver pair. We present several
techniques which provide stability in velocity models producing caustics:
improved factorization; non-symmetric loss function based on Hamiltonian;
gaussian activation; symmetrization. In our tests, NES showed the
relative-mean-absolute error of about 0.2-0.4% from the second-order factored
Fast Marching Method, and outperformed existing neural-network solvers giving
10-60 times lower errors and 2-30 times faster training. The inference time of
NES is comparable with the Fast Marching. The one-point NES provides the most
accurate solution, whereas the two-point NES provides slightly lower accuracy
but gives an extremely compact representation. It can be useful in various
seismic applications where massive computations are required (millions of
source-receiver pairs): ray modeling, traveltime tomography, hypocenter
localization, and Kirchhoff migration.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 21:11:08 GMT""}]","2022-12-14"
"2205.07990","Jiequn Han","Weinan E, Jiequn Han, Jihao Long","Empowering Optimal Control with Machine Learning: A Perspective from
  Model Predictive Control",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Solving complex optimal control problems have confronted computational
challenges for a long time. Recent advances in machine learning have provided
us with new opportunities to address these challenges. This paper takes model
predictive control, a popular optimal control method, as the primary example to
survey recent progress that leverages machine learning techniques to empower
optimal control solvers. We also discuss some of the main challenges
encountered when applying machine learning to develop more robust optimal
control algorithms.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 21:14:21 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jul 2022 13:50:19 GMT""}]","2022-07-21"
"2205.07991","Weikang Qiao","Weikang Qiao and Licheng Guo and Zhenman Fang and Mau-Chung Frank
  Chang and Jason Cong","TopSort: A High-Performance Two-Phase Sorting Accelerator Optimized on
  HBM-based FPGAs",,,,,"cs.AR cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The emergence of high-bandwidth memory (HBM) brings new opportunities to
boost the performance of sorting acceleration on FPGAs, which was
conventionally bounded by the available off-chip memory bandwidth. However, it
is nontrivial for designers to fully utilize this immense bandwidth. First, the
existing sorter designs cannot be directly scaled at the increasing rate of
available off-chip bandwidth, as the required on-chip resource usage grows at a
much faster rate and would bound the sorting performance in turn. Second,
designers need an in-depth understanding of HBM characteristics to effectively
utilize the HBM bandwidth. To tackle these challenges, we present TopSort, a
novel two-phase sorting solution optimized for HBM-based FPGAs. In the first
phase, 16 merge trees work in parallel to fully utilize 32 HBM channels. In the
second phase, TopSort reuses the logic from phase one to form a wider merge
tree to merge the partially sorted results from phase one. TopSort also adopts
HBM-specific optimizations to reduce resource overhead and improve bandwidth
utilization. TopSort can sort up to 4 GB data using all 32 HBM channels, with
an overall sorting performance of 15.6 GB/s. TopSort is 6.7x and 2.2x faster
than state-of-the-art CPU and FPGA sorters.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 21:15:43 GMT""}]","2022-05-18"
"2205.07992","Xhek Turkeshi","Xhek Turkeshi, Lorenzo Piroli, Marco Schir\`o","Enhanced entanglement negativity in boundary driven monitored fermionic
  chains","10 pages, comments are welcome","Phys. Rev. B 106, 024304 (2022)","10.1103/PhysRevB.106.024304",,"cond-mat.stat-mech cond-mat.str-el quant-ph","http://creativecommons.org/licenses/by/4.0/","  We investigate entanglement dynamics in continuously monitored open quantum
systems featuring current-carrying non-equilibrium states. We focus on a
prototypical one-dimensional model of boundary-driven non-interacting fermions
with monitoring of the local density, whose average Lindblad dynamics features
a well-studied ballistic to diffusive crossover in transport. Here we analyze
the dynamics of the fermionic negativity, mutual information, and purity along
different quantum trajectories. We show that monitoring this boundary-driven
system enhances its entanglement negativity at long times, which otherwise
decays to zero in absence of measurements. This result is in contrast with the
case of unitary evolution where monitoring suppresses entanglement production.
For small values of $\gamma$, the stationary-state negativity shows a
logarithmic scaling with system size, transitioning to an area-law scaling as
$\gamma$ is increased beyond a critical value. Similar critical behavior is
found in the mutual information, while the late-time purity shows no apparent
signature of a transition, being $O(1)$ for all values of $\gamma$. Our work
unveils the double role of weak monitoring in current-driven open quantum
systems, simultaneously damping transport and enhancing entanglement.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 21:16:53 GMT""}]","2022-07-12"
"2205.07993","Chen Wang","Chen Wang, Danfei Xu, Li Fei-Fei","Generalizable Task Planning through Representation Pretraining",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ability to plan for multi-step manipulation tasks in unseen situations is
crucial for future home robots. But collecting sufficient experience data for
end-to-end learning is often infeasible in the real world, as deploying robots
in many environments can be prohibitively expensive. On the other hand,
large-scale scene understanding datasets contain diverse and rich semantic and
geometric information. But how to leverage such information for manipulation
remains an open problem. In this paper, we propose a learning-to-plan method
that can generalize to new object instances by leveraging object-level
representations extracted from a synthetic scene understanding dataset. We
evaluate our method with a suite of challenging multi-step manipulation tasks
inspired by household activities and show that our model achieves measurably
better success rate than state-of-the-art end-to-end approaches. Additional
information can be found at https://sites.google.com/view/gentp
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 21:19:07 GMT""}]","2022-05-18"
"2205.07994","Qing Zou","Qing Zou, Mathews Jacob","Joint cardiac $T_1$ mapping and cardiac function estimation using a deep
  manifold framework",,,,,"eess.IV eess.SP","http://creativecommons.org/licenses/by/4.0/","  In this work, we proposed a continuous-acquisition strategy using a gradient
echo (GRE) inversion recovery sequence based on spiral trajectories to
simultaneously obtain the $T_1$ mapping and CINE imaging. The acquisition is
using a free-breathing and ungated fashion. An approach based on variational
auto-encoder(VAE) is used for the motion estimation from the centered k-space
data. The motion signal is then used to train a deep manifold reconstruction
algorithm for image reconstruction. Once the network is trained, we can excite
the latent vectors (the estimated motion signals and the contrast signal) in
any way as we wanted to generate the image frames in the time series. We can
estimate the $T_1$ mapping using the generated image frames where only contrast
is varying. We can also generate the breath-hold CINE in different contrast.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 21:24:34 GMT""}]","2022-05-18"
"2205.07995","Emanuele Galiffi","Emanuele Galiffi, Shixiong Yin and Andrea Al\`u","Tapered Photonic Switching",,,"10.1515/nanoph-2022-0200",,"physics.optics cond-mat.other physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  The advent of novel nonlinear materials has stirred unprecedented interest in
exploring the use of temporal inhomogeneities to achieve novel forms of wave
control, amidst the greater vision of engineering metamaterials across both
space and time. When the properties of an unbounded medium are abruptly
switched in time, propagating waves are efficiently converted to different
frequencies, and partially coupled to their back-propagating phase-conjugate
partners, through a process called time-reversal. However, in realistic
materials the switching time is necessarily finite, playing a central role in
the resulting temporal scattering features. By identifying and leveraging the
crucial role of electromagnetic momentum conservation in time-reversal
processes, here we develop a very general analytical formalism to quantify
time-reversal due to temporal inhomogeneities of arbitrary profile. Finally, we
deploy our analytic theory to develop a formalism, analogous to spatial
tapering theory, that enables the tailoring of a desired time-reversal spectral
response, demonstrating its use for the realization of broadband frequency
converters and filters.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 21:28:18 GMT""}]","2022-11-24"
"2205.07996","Hendrik Schatz","H. Schatz, A. D. Becerril Reyes, A. Best, E. F. Brown, K.
  Chatziioannou, K. A. Chipps, C. M. Deibel, R. Ezzeddine, D. K. Galloway, C.
  J. Hansen, F. Herwig, A. P. Ji, M. Lugaro, Z. Meisel, D. Norman, J. S. Read,
  L. F. Roberts, A. Spyrou, I. Tews, F. X. Timmes, C. Travaglio, N. Vassh, C.
  Abia, P. Adsley, S. Agarwal, M. Aliotta, W. Aoki, A. Arcones, A. Aryan, A.
  Bandyopadhyay, A. Banu, D. W. Bardayan, J. Barnes, A. Bauswein, T. C. Beers,
  J. Bishop, T. Boztepe, B. C\^ot\'e, M. E. Caplan, A. E. Champagne, J. A.
  Clark, M. Couder, A. Couture, S. E. de Mink, S. Debnath, R. J. deBoer, J. den
  Hartogh, P. Denissenkov, V. Dexheimer, I. Dillmann, J. E. Escher, M. A.
  Famiano, R. Farmer, R. Fisher, C. Fr\""ohlich, A. Frebel, C. Fryer, G. Fuller,
  A. K. Ganguly, S. Ghosh, B. K. Gibson, T. Gorda, K. N. Gourgouliatos, V.
  Graber, M. Gupta, W. Haxton, A. Heger, W. R. Hix, W C. G. Ho, E. M. Holmbeck,
  A. A. Hood, S. Huth, G. Imbriani, R. G. Izzard, R. Jain, H. Jayatissa, Z.
  Johnston, T. Kajino, A. Kankainen, G. G. Kiss, A. Kwiatkowski, M. La Cognata,
  A. M. Laird, L. Lamia, P. Landry, E. Laplace, K. D. Launey, D. Leahy, G.
  Leckenby, A. Lennarz, B. Longfellow, A. E. Lovell, W. G. Lynch, S. M. Lyons,
  K. Maeda, E. Masha, C. Matei, J. Merc, B. Messer, F. Montes, A. Mukherjee, M.
  Mumpower, D. Neto, B. Nevins, W. G. Newton, L. Q. Nguyen, K. Nishikawa, N.
  Nishimura, F. M. Nunes, E. O'Connor, B. W. O'Shea, W-J. Ong, S. D. Pain, M.
  A. Pajkos, M. Pignatari, R. G. Pizzone, V. M. Placco, T. Plewa, B.
  Pritychenko, A. Psaltis, D. Puentes, Y-Z. Qian, D. Radice, D. Rapagnani, B.
  M. Rebeiro, R. Reifarth, A. L. Richard, N. Rijal, I. U. Roederer, J. S. Rojo,
  J. S K, Y. Saito, A. Schwenk, M. L. Sergi, R. S. Sidhu, A. Simon, T.
  Sivarani, \'A. Sk\'ulad\'ottir, M. S. Smith, A. Spiridon, T. M. Sprouse, S.
  Starrfield, A. W. Steiner, F. Strieder, I. Sultana, R. Surman, T. Sz\""ucs, A.
  Tawfik, F. Thielemann, L. Trache, R. Trappitsch, M. B. Tsang, A. Tumino, S.
  Upadhyayula, J. O. Valle Mart\'inez, M. Van der Swaelmen, C. Viscasillas
  V\'azquez, A. Watts, B. Wehmeyer, M. Wiescher, C. Wrede, J. Yoon, R G. T.
  Zegers, M. A. Zermane, M. Zingale","Horizons: Nuclear Astrophysics in the 2020s and Beyond","96 pages. Submitted to Journal of Physics G",,"10.1088/1361-6471/ac8890","LA-UR-22-23997","nucl-ex astro-ph.HE astro-ph.SR nucl-th","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Nuclear Astrophysics is a field at the intersection of nuclear physics and
astrophysics, which seeks to understand the nuclear engines of astronomical
objects and the origin of the chemical elements. This white paper summarizes
progress and status of the field, the new open questions that have emerged, and
the tremendous scientific opportunities that have opened up with major advances
in capabilities across an ever growing number of disciplines and subfields that
need to be integrated. We take a holistic view of the field discussing the
unique challenges and opportunities in nuclear astrophysics in regards to
science, diversity, education, and the interdisciplinarity and breadth of the
field. Clearly nuclear astrophysics is a dynamic field with a bright future
that is entering a new era of discovery opportunities.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 21:29:23 GMT""}]","2022-11-30"
"2205.07997","Tina M\""uller","L. Wells, T. M\""uller, R. M. Stevenson, J. Skiba-Szymanska, D. A.
  Ritchie, and A. J. Shields","Coherent light scattering from a telecom C-band quantum dot",,,,,"quant-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum networks have the potential to transform secure communication via
quantum key distribution and enable novel concepts in distributed quantum
computing and sensing. Coherent quantum light generation at telecom wavelengths
is fundamental for fibre-based network implementations, but Fourier-limited
emission and subnatural linewidth photons have so far only been reported from
systems operating in the visible to near-infrared wavelength range. Here, we
use InAs/InP quantum dots to demonstrate photons with coherence times much
longer than the Fourier limit at telecom wavelength. Evidence of the
responsible elastic laser scattering mechanism is observed in a distinct
signature in two-photon interference measurements, and is confirmed using a
direct measurement of the emission coherence. Further, we show that even the
inelastically scattered photons have coherence times within the error bars of
the Fourier limit. Finally, we make direct use of the minimal attenuation in
fibre for these photons by measuring two-photon interference after 25 km of
fibre, thereby demonstrating indistinguishability of photons emitted about 100
000 excitation cycles apart.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 21:32:12 GMT""},{""version"":""v2"",""created"":""Wed, 1 Jun 2022 17:46:24 GMT""}]","2022-06-02"
"2205.07998","Jo\~ao Pedro Ramos","Jo\~ao P. G. Ramos and Paolo Tilli","A Faber-Krahn inequality for wavelet transforms","16 pages",,,,"math.FA math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For some special window functions $\psi_{\beta} \in H^2(\mathbb{C}^+),$ we
prove that, over all sets $\Delta \subset \mathbb{C}^+$ of fixed hyperbolic
measure $\nu(\Delta),$ the ones over which the Wavelet transform
$W_{\overline{\psi_{\beta}}}$ with window $\overline{\psi_{\beta}}$
concentrates optimally are exactly the discs with respect to the
pseudohyperbolic metric of the upper half space. This answers a question raised
by Abreu and D\""orfler.
  Our techniques make use of a framework recently developed in a previous work
by F. Nicola and the second author, but in the hyperbolic context induced by
the dilation symmetry of the Wavelet transform. This leads us naturally to use
a hyperbolic rearrangement function, as well as the hyperbolic isoperimetric
inequality, in our analysis.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 21:32:42 GMT""}]","2022-05-18"
"2205.07999","Nhat Ho","Nhat Ho and Tongzheng Ren and Sujay Sanghavi and Purnamrita Sarkar and
  Rachel Ward","An Exponentially Increasing Step-size for Parameter Estimation in
  Statistical Models","37 pages. The authors are listed in alphabetical order",,,,"stat.ML cs.LG math.OC math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using gradient descent (GD) with fixed or decaying step-size is a standard
practice in unconstrained optimization problems. However, when the loss
function is only locally convex, such a step-size schedule artificially slows
GD down as it cannot explore the flat curvature of the loss function. To
overcome that issue, we propose to exponentially increase the step-size of the
GD algorithm. Under homogeneous assumptions on the loss function, we
demonstrate that the iterates of the proposed \emph{exponential step size
gradient descent} (EGD) algorithm converge linearly to the optimal solution.
Leveraging that optimization insight, we then consider using the EGD algorithm
for solving parameter estimation under both regular and non-regular statistical
models whose loss function becomes locally convex when the sample size goes to
infinity. We demonstrate that the EGD iterates reach the final statistical
radius within the true parameter after a logarithmic number of iterations,
which is in stark contrast to a \emph{polynomial} number of iterations of the
GD algorithm in non-regular statistical models. Therefore, the total
computational complexity of the EGD algorithm is \emph{optimal} and
exponentially cheaper than that of the GD for solving parameter estimation in
non-regular statistical models while being comparable to that of the GD in
regular statistical settings. To the best of our knowledge, it resolves a
long-standing gap between statistical and algorithmic computational
complexities of parameter estimation in non-regular statistical models.
Finally, we provide targeted applications of the general theory to several
classes of statistical models, including generalized linear models with
polynomial link functions and location Gaussian mixture models.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 21:36:22 GMT""},{""version"":""v2"",""created"":""Wed, 1 Feb 2023 20:35:28 GMT""}]","2023-02-03"
"2205.08000","Iv\'an D\'iaz","Iv\'an D\'iaz","Non-agency interventions for causal mediation in the presence of
  intermediate confounding",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  Recent approaches to causal inference have focused on causal effects defined
as contrasts between the distribution of counterfactual outcomes under
hypothetical interventions on the nodes of a graphical model. In this article
we develop theory for causal effects defined with respect to a different type
of intervention, one which alters the information propagated through the edges
of the graph. These information transfer interventions may be more useful than
node interventions in settings in which causes are non-manipulable, for example
when considering race or genetics as a causal agent. Furthermore, information
transfer interventions allow us to define path-specific decompositions which
are identified in the presence of treatment-induced mediator-outcome
confounding, a practical problem whose general solution remains elusive. We
prove that the proposed effects provide valid statistical tests of mechanisms,
unlike popular methods based on randomized interventions on the mediator. We
propose efficient non-parametric estimators for a covariance version of the
proposed effects, using data-adaptive regression coupled with semi-parametric
efficiency theory to address model misspecification bias while retaining
$\sqrt{n}$-consistency and asymptotic normality. We illustrate the use of our
methods in two examples using publicly available data.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 21:46:05 GMT""},{""version"":""v2"",""created"":""Thu, 16 Mar 2023 20:39:45 GMT""},{""version"":""v3"",""created"":""Wed, 19 Apr 2023 22:07:25 GMT""},{""version"":""v4"",""created"":""Tue, 25 Apr 2023 14:33:29 GMT""}]","2023-04-26"
"2205.08001","Koel Dutta Chowdhury","Koel Dutta Chowdhury, Rricha Jalota, Cristina Espa\~na-Bonet, and
  Josef van Genabith","Towards Debiasing Translation Artifacts","Accepted to NAACL 2022, Main Conference",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Cross-lingual natural language processing relies on translation, either by
humans or machines, at different levels, from translating training data to
translating test sets. However, compared to original texts in the same
language, translations possess distinct qualities referred to as
translationese. Previous research has shown that these translation artifacts
influence the performance of a variety of cross-lingual tasks. In this work, we
propose a novel approach to reducing translationese by extending an established
bias-removal technique. We use the Iterative Null-space Projection (INLP)
algorithm, and show by measuring classification accuracy before and after
debiasing, that translationese is reduced at both sentence and word level. We
evaluate the utility of debiasing translationese on a natural language
inference (NLI) task, and show that by reducing this bias, NLI accuracy
improves. To the best of our knowledge, this is the first study to debias
translationese as represented in latent embedding space.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 21:46:51 GMT""}]","2022-05-18"
"2205.08002","Neelanjan Bhowmik","Neelanjan Bhowmik, Jack W. Barker, Yona Falinie A. Gaus, Toby P.
  Breckon","Lost in Compression: the Impact of Lossy Image Compression on Variable
  Size Object Detection within Infrared Imagery",,,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lossy image compression strategies allow for more efficient storage and
transmission of data by encoding data to a reduced form. This is essential
enable training with larger datasets on less storage-equipped environments.
However, such compression can cause severe decline in performance of deep
Convolution Neural Network (CNN) architectures even when mild compression is
applied and the resulting compressed imagery is visually identical. In this
work, we apply the lossy JPEG compression method with six discrete levels of
increasing compression {95, 75, 50, 15, 10, 5} to infrared band (thermal)
imagery. Our study quantitatively evaluates the affect that increasing levels
of lossy compression has upon the performance of characteristically diverse
object detection architectures (Cascade-RCNN, FSAF and Deformable DETR) with
respect to varying sizes of objects present in the dataset. When training and
evaluating on uncompressed data as a baseline, we achieve maximal mean Average
Precision (mAP) of 0.823 with Cascade R-CNN across the FLIR dataset,
outperforming prior work. The impact of the lossy compression is more extreme
at higher compression levels (15, 10, 5) across all three CNN architectures.
However, re-training models on lossy compressed imagery notably ameliorated
performances for all three CNN models with an average increment of ~76% (at
higher compression level 5). Additionally, we demonstrate the relative
sensitivity of differing object areas {tiny, small, medium, large} with respect
to the compression level. We show that tiny and small objects are more
sensitive to compression than medium and large objects. Overall, Cascade R-CNN
attains the maximal mAP across most of the object area categories.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 21:54:32 GMT""}]","2022-05-18"
"2205.08003","Sheng-Lun Xie","Sheng-Lun Xie, Ce Cai, Shao-Lin Xiong, Yun-Wei Yu, Yan-Qiu Zhang, Lin
  Lin, Zhen Zhang, Wang-Chen Xue, Jia-Cong Liu, Yi Zhao, Shuo Xiao, Chao Zheng,
  Qi-Bin Yi, Peng Zhang, Ping Wang, Rui Qiao, Wen-Xi Peng, Yue Huang, Xiang Ma,
  Xiao-Yun Zhao, Xiao-Bo Li, Shi-Jie Zheng, Ming-Yu Ge, Cheng-Kui Li, Xin-Qiao
  Li, Xiang-Yang Wen, Fan Zhang, Li-Ming Song, Shuang-Nan Zhang, Zhi-Wei Guo,
  Xiao-Lu Zhang, Guo-Ying Zhao, Chao-Yang Li","Revisit the periodicity of SGR J1935+2154 bursts with updated sample",,,"10.1093/mnras/stac2918",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Since FRB 200428 has been found to be associated with an X-ray burst from the
Galactic magnetar SGR J1935+2154, it is interesting to explore whether the
magnetar bursts also follow the similar active periodic behavior as some
repeating FRBs. Previous studies show that there is possible period about 230
day in SGR J1935+2154 bursts. Here, we collected an updated burst sample from
SGR J1935+2154, including all bursts reported by Fermi/GBM and GECAM till 2022
January. We also developed a targeted search pipeline to reveal more bursts
from SGR J1935+2154 in the Fermi/GBM data from 2008 August to 2014 December
(i.e. before the first burst detected by Swift/BAT). With this burst sample, we
re-analyzed the possible periodicity of SGR J1935+2154 bursts using the Period
Folding and Lomb-Scargle Periodogram methods. Our results show that the
periodicity $\sim$238 day reported in literature is probably fake and the
observation effects may introduce false periods (i.e. 55 day) according to
simulation tests. We find that, for the current burst sample, the most probable
period is 126.88$\pm$2.05 day, which could be interpreted as the precession of
the magnetar. However, we note that the whole burst history is very complicated
and difficult to be perfectly accommodated with any period reported thus far,
therefore more monitoring observations of SGR J1935+2154 are required to test
any periodicity hypothesis.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 22:14:34 GMT""},{""version"":""v2"",""created"":""Mon, 10 Oct 2022 09:37:13 GMT""}]","2022-10-26"
"2205.08004","Satoru Hayami","Satoru Hayami","Multifarious skyrmion phases on a trilayer triangular lattice","22 pages, 14 figures, 1 table, accepted for publication in PRB","Phys. Rev. B 105, 184426 (2022)","10.1103/PhysRevB.105.184426",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The instability toward a magnetic skyrmion crystal in centrosymmetric
trilayer magnets is investigated based on a spin model with layer-dependent
Dzayloshinskii-Moriya interaction. We find various types of skyrmion crystal
phases with different skyrmion numbers in a low-temperature phase diagram by
performing the simulated annealing. In addition to the N\'eel skyrmion crystal
phase that is expected to emerge in the presence of the polar-type
Dzayloshinskii-Moriya interaction, we obtain the skyrmion crystal phases
characteristics of the layered system: the twisted surface skyrmion crystal,
anti-skyrmion crystal, and high-topological-number skyrmion crystal phases. The
rich magnetic phases are brought about by the synergy among the layer-dependent
Dzayloshinskii-Moriya interaction, interlayer exchange interaction, and an
external magnetic field. Our results indicate that the layer degree of freedom
at the surface and heterostructures provides a good platform to engineer and
design the topological spin textures.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 22:20:43 GMT""}]","2022-06-10"
"2205.08005","Peichun Amy Tsai","Alban Pouplard and Peichun Amy Tsai","Controlling Viscous Fingering Instabilities of Complex Fluids","Submitted for publication",,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The process of one fluid pushing another is universally common while
involving complex interfacial instabilities. Particularly, occurring in a
myriad of natural and industrial processes, wavy fingering patterns frequently
emerge when a less viscous fluid pushes another more viscous one, such as water
invading oil, in a porous medium. Such finger-shaped interfaces producing
partial displacement significantly affect the efficiency of numerous
applications, for example, chromatography, printing devices, coating flows,
oil-well cementing, as well as large-scale technologies of groundwater and
enhanced oil recovery (EOR). This classical viscous fingering instability is
notoriously difficult to control because the two fluids' viscosity or mobility
ratio is often fixed and yet the predominant drive of the instability. Although
some strategies have been recently revealed for simple fluids of constant
viscosity, the feasibility of controlling the fundamental viscous fingering
instability for omnipresent complex fluids has not been established. Here, we
demonstrate how to control a common complex fluid (of a power-law fluid with a
yield-stress) using a narrow tapered cell theoretically and experimentally.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 22:22:22 GMT""}]","2022-05-18"
"2205.08006","Tao Lu","Shahin Honari and Saeed Farajollahi and Tao Lu","A Novel Buckle-Free Large Rib Microdisk with Sub-Micron Thickness",,,"10.1002/adpr.202200178",,"physics.optics","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Thin large microdisks, that are key for dense spectral microcomb generation
at visible to UV wavelengths, face challenges in fabrication. One of the most
difficult issues is the buckling effect that significantly reduces the cavity
optical quality factor. This work introduces a novel rib disk structure that
significantly mitigates the buckling effects. Using this approach, we obtained
millimeter size buckle-free microdisks with sub-micron thickness and high
optical quality factor exceeding $10^7$.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 22:27:54 GMT""}]","2022-10-24"
"2205.08007","Randy Frans Fela","Randy F Fela, Andr\'eas Pastor, Patrick Le Callet, Nick Zacharov,
  Toinon Vigier, S{\o}ren Forchhammer","Perceptual Evaluation on Audio-visual Dataset of 360 Content","6 pages, 5 figures, International Conference on Multimedia and Expo
  2022",,,,"cs.MM cs.SD eess.AS eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To open up new possibilities to assess the multimodal perceptual quality of
omnidirectional media formats, we proposed a novel open source 360 audiovisual
(AV) quality dataset. The dataset consists of high-quality 360 video clips in
equirectangular (ERP) format and higher-order ambisonic (4th order) along with
the subjective scores. Three subjective quality experiments were conducted for
audio, video, and AV with the procedures detailed in this paper. Using the data
from subjective tests, we demonstrated that this dataset can be used to
quantify perceived audio, video, and audiovisual quality. The diversity and
discriminability of subjective scores were also analyzed. Finally, we
investigated how our dataset correlates with various objective quality metrics
of audio and video. Evidence from the results of this study implies that the
proposed dataset can benefit future studies on multimodal quality evaluation of
360 content.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 22:31:29 GMT""}]","2022-05-18"
"2205.08008","Peichun Amy Tsai","Alban Pouplard and Peichun Amy Tsai","Control of Viscous Fingering Instability for Complex Yield-Stress Fluids
  using a Tapered Cell","Submitted for publication",,,,"physics.flu-dyn physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Being a major limiting factor for the efficiency of various technologies,
such as Enhanced Oil Recovery, the viscous fingering (or Saffman--Taylor)
instability has been extensively studied, especially for simple Newtonian
fluids. Here, we experimentally and theoretically demonstrate a vital control
of inhibiting the viscous fingering instability for complex (yield-stress)
fluids to generate a complete sweep with a flat interface. Using a rectangular
tapered cell, we first experimentally show the feasibility of controlling the
primary fingering instability of a complex yield-stress fluid when pushed by
another less viscous one. We further develop a theoretical linear stability
analysis generalized for complex fluids with a yield stress and a power-law
form of viscosity to provide insights. With three complex solutions yielding
different viscosity contrasts, we observe stable flat and unstable wavy
interfaces depending on the gap gradient ($\alpha$) and injection flow rate
($Q$). Finally, the comparison reveals an agreeable theoretical stability
criterion capable of predicting stable vs. unstable displacements for
yield-stress fluids under various $\alpha$.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 22:34:56 GMT""}]","2022-05-18"
"2205.08009","Andr\'es del Pino Molina Dr.","Andr\'es del Pino, Mattia Libralato, Roeland P. van der Marel, Paul
  Bennet, Mark A. Fardal, Jay Anderson, Andrea Bellini, Sangmo Tony Sohn, and
  Laura L. Watkins","GaiaHub: A method for combining data from the Gaia and Hubble space
  telescopes to derive improved proper motions for faint stars","24 pages, 18 figures. Accepted for publication in ApJ",,"10.3847/1538-4357/ac70cf",,"astro-ph.GA astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  We present GaiaHub, a publicly available tool that combines $Gaia$
measurements with $Hubble$ $Space$ $Telescope$ ($HST$) archival images to
derive proper motions (PMs). It increases the scientific impact of both
observatories beyond their individual capabilities. $Gaia$ provides PMs across
the whole sky, but the limited mirror size and time baseline restrict the best
PM performance to relatively bright stars. $HST$ can measure accurate PMs for
much fainter stars over a small field, but this requires two epochs of
observation which are not always available. GaiaHub yields considerably
improved PM accuracy compared to $Gaia$-only measurements, especially for faint
sources $(G \gtrsim 18)$, requiring only a single epoch of $HST$ data observed
more than $\sim 7$ years ago (before 2012). This provides considerable
scientific value especially for dynamical studies of stellar systems or
structures in and beyond the Milky Way (MW) halo, for which the member stars
are generally faint. To illustrate the capabilities and demonstrate the
accuracy of GaiaHub, we apply it to samples of MW globular clusters (GCs) and
classical dwarf spheroidal (dSph) satellite galaxies. This allows us, e.g., to
measure the velocity dispersions in the plane of the sky for objects out to and
beyond $\sim 100$ kpc. We find, on average, mild radial velocity anisotropy in
GCs, consistent with existing results for more nearby samples. We observe a
correlation between the internal kinematics of the clusters and their
ellipticity, with more isotropic clusters being, on average, more round. Our
results also support previous findings that Draco and Sculptor dSph galaxies
appear to be radially anisotropic systems.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 22:35:29 GMT""}]","2022-07-20"
"2205.08010","Julio Stern","Julio Michael Stern, Carlos Alberto de Braganca Pereira, Marcelo de
  Souza Lauretto, Luis Gustavo Esteves, Rafael Izbicki, Rafael Bassi Stern,
  Marcio Alves Diniz","The e-value and the Full Bayesian Significance Test: Logical Properties
  and Philosophical Consequences",,,,,"math.ST stat.TH","http://creativecommons.org/licenses/by-sa/4.0/","  This article gives a conceptual review of the e-value, ev(H|X) -- the
epistemic value of hypothesis H given observations X. This statistical
significance measure was developed in order to allow logically coherent and
consistent tests of hypotheses, including sharp or precise hypotheses, via the
Full Bayesian Significance Test (FBST). Arguments of analysis allow a full
characterization of this statistical test by its logical or compositional
properties, showing a mutual complementarity between results of mathematical
statistics and the logical desiderata lying at the foundations of this theory.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 22:43:31 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jul 2022 12:54:37 GMT""},{""version"":""v3"",""created"":""Tue, 9 Aug 2022 23:22:53 GMT""},{""version"":""v4"",""created"":""Sun, 14 Aug 2022 01:58:08 GMT""}]","2022-08-16"
"2205.08011","Digvijay Boob","Digvijay Boob, Qi Deng, Guanghui Lan","Level Constrained First Order Methods for Function Constrained
  Optimization",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new feasible proximal gradient method for constrained
optimization where both the objective and constraint functions are given by
summation of a smooth, possibly nonconvex function and a convex simple
function. The algorithm converts the original problem into a sequence of convex
subproblems. Either exact or approximate solutions of convex subproblems can be
computed efficiently in many cases. For the inexact case, computing the
solution of the subproblem requires evaluation of at most one
gradient/function-value of the original objective and constraint functions. An
important feature of the algorithm is the constraint level parameter. By
carefully increasing this level for each subproblem, we provide a simple
solution to overcome the challenge of bounding the Lagrangian multipliers, and
show that the algorithm follows a strictly feasible solution path till
convergence to the stationary point. Finally, we develop a simple, proximal
gradient descent type analysis, showing that the complexity bound of this new
algorithm is comparable to gradient descent for the unconstrained setting which
is new in the literature. Exploiting this new design and analysis technique, we
extend our algorithms to some more challenging constrained optimization
problems where 1) the objective is a stochastic or finite-sum function, and 2)
structured nonsmooth functions replace smooth components of both objective and
constraint functions. Complexity results for these problems also seem to be new
in the literature. We also show that our method can be applied for convex
function constrained problems where we show complexities similar to the
proximal gradient method.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 22:46:43 GMT""}]","2022-05-18"
"2205.08012","Tara Safavi","Tara Safavi, Doug Downey, Tom Hope","CascadER: Cross-Modal Cascading for Knowledge Graph Link Prediction","AKBC 2022",,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Knowledge graph (KG) link prediction is a fundamental task in artificial
intelligence, with applications in natural language processing, information
retrieval, and biomedicine. Recently, promising results have been achieved by
leveraging cross-modal information in KGs, using ensembles that combine
knowledge graph embeddings (KGEs) and contextual language models (LMs).
However, existing ensembles are either (1) not consistently effective in terms
of ranking accuracy gains or (2) impractically inefficient on larger datasets
due to the combinatorial explosion problem of pairwise ranking with deep
language models. In this paper, we propose a novel tiered ranking architecture
CascadER to maintain the ranking accuracy of full ensembling while improving
efficiency considerably. CascadER uses LMs to rerank the outputs of more
efficient base KGEs, relying on an adaptive subset selection scheme aimed at
invoking the LMs minimally while maximizing accuracy gain over the KGE.
Extensive experiments demonstrate that CascadER improves MRR by up to 9 points
over KGE baselines, setting new state-of-the-art performance on four benchmarks
while improving efficiency by one or more orders of magnitude over competitive
cross-modal baselines. Our empirical analyses reveal that diversity of models
across modalities and preservation of individual models' confidence signals
help explain the effectiveness of CascadER, and suggest promising directions
for cross-modal cascaded architectures. Code and pretrained models are
available at https://github.com/tsafavi/cascader.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 22:55:45 GMT""},{""version"":""v2"",""created"":""Fri, 23 Sep 2022 16:45:34 GMT""}]","2022-09-26"
"2205.08013","Maciej Zamorski","Maciej Zamorski, Micha{\l} Stypu{\l}kowski, Konrad Karanowski, Tomasz
  Trzci\'nski, Maciej Zi\k{e}ba","Continual learning on 3D point clouds with random compressed rehearsal","10 pages, 3 figures",,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  Contemporary deep neural networks offer state-of-the-art results when applied
to visual reasoning, e.g., in the context of 3D point cloud data. Point clouds
are important datatype for precise modeling of three-dimensional environments,
but effective processing of this type of data proves to be challenging. In the
world of large, heavily-parameterized network architectures and
continuously-streamed data, there is an increasing need for machine learning
models that can be trained on additional data. Unfortunately, currently
available models cannot fully leverage training on additional data without
losing their past knowledge. Combating this phenomenon, called catastrophic
forgetting, is one of the main objectives of continual learning. Continual
learning for deep neural networks has been an active field of research,
primarily in 2D computer vision, natural language processing, reinforcement
learning, and robotics. However, in 3D computer vision, there are hardly any
continual learning solutions specifically designed to take advantage of point
cloud structure. This work proposes a novel neural network architecture capable
of continual learning on 3D point cloud data. We utilize point cloud structure
properties for preserving a heavily compressed set of past data. By using
rehearsal and reconstruction as regularization methods of the learning process,
our approach achieves a significant decrease of catastrophic forgetting
compared to the existing solutions on several most popular point cloud datasets
considering two continual learning settings: when a task is known beforehand,
and in the challenging scenario of when task information is unknown to the
model.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 22:59:52 GMT""},{""version"":""v2"",""created"":""Fri, 20 May 2022 12:09:47 GMT""}]","2022-05-23"
"2205.08014","Alena Aksenova","Al\""ena Aks\""enova, Zhehuai Chen, Chung-Cheng Chiu, Daan van Esch,
  Pavel Golik, Wei Han, Levi King, Bhuvana Ramabhadran, Andrew Rosenberg, Suzan
  Schwartz, Gary Wang","Accented Speech Recognition: Benchmarking, Pre-training, and Diverse
  Data","5 pages, 3 tables",,,,"eess.AS cs.SD","http://creativecommons.org/licenses/by/4.0/","  Building inclusive speech recognition systems is a crucial step towards
developing technologies that speakers of all language varieties can use.
Therefore, ASR systems must work for everybody independently of the way they
speak. To accomplish this goal, there should be available data sets
representing language varieties, and also an understanding of model
configuration that is the most helpful in achieving robust understanding of all
types of speech. However, there are not enough data sets for accented speech,
and for the ones that are already available, more training approaches need to
be explored to improve the quality of accented speech recognition. In this
paper, we discuss recent progress towards developing more inclusive ASR
systems, namely, the importance of building new data sets representing
linguistic diversity, and exploring novel training approaches to improve
performance for all users. We address recent directions within benchmarking ASR
systems for accented speech, measure the effects of wav2vec 2.0 pre-training on
accented speech recognition, and highlight corpora relevant for diverse ASR
evaluations.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 23:01:17 GMT""}]","2022-05-18"
"2205.08015","Alexander Strang","Christopher Cebra, and Alexander Strang","Similarity Suppresses Cyclicity: Why Similar Competitors Form
  Hierarchies","37 pages, 9 figures",,,,"q-bio.PE math.PR","http://creativecommons.org/licenses/by/4.0/","  Competitive systems can exhibit both hierarchical (transitive) and cyclic
(intransitive) structures. Despite theoretical interest in cyclic competition,
which offers richer dynamics, and occupies a larger subset of the space of
possible competitive systems, most real-world systems are predominantly
transitive. Why? Here, we introduce a generic mechanism which promotes
transitivity, even when there is ample room for cyclicity. Consider a
competitive system where outcomes are mediated by competitor attributes via a
performance function. We demonstrate that, if competitive outcomes depend
smoothly on competitor attributes, then similar competitors compete
transitively. We quantify the rate of convergence to transitivity given the
similarity of the competitors and the smoothness of the performance function.
Thus, we prove the adage regarding apples and oranges. Similar objects admit
well ordered comparisons. Diverse objects may not. To test that theory, we run
a series of evolution experiments designed to mimic genetic training
algorithms. We consider a series of canonical bimatrix games and an ensemble of
random performance functions that demonstrate the generality of our mechanism,
even when faced with highly cyclic games. We vary the training parameters
controlling the evolution process, and the shape parameters controlling the
performance function, to evaluate the robustness of our results. These
experiments illustrate that, if competitors evolve to optimize performance,
then their traits may converge, leading to transitivity.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 23:09:59 GMT""}]","2022-05-18"
"2205.08016","Georgios Tzimpragos","Jennifer Volk, Alex Wynn, Evan Golden, Timothy Sherwood, Georgios
  Tzimpragos","Pulsar: A Superconducting Delay-Line Memory","12 pages, 6 figures, 1 table, under submission",,,,"cs.ET cs.AR","http://creativecommons.org/licenses/by/4.0/","  Recent advances in logic schemes and fabrication processes have renewed
interest in using superconductor electronics for energy-efficient computing and
quantum control processors. However, scalable superconducting memory still
poses a challenge. To address this issue, we present an alternative to
approaches that solely emphasize storage cell miniaturization by exploiting the
minimal attenuation and dispersion properties of superconducting passive
transmission lines to develop a delay-line memory system. This fully
superconducting design operates at speeds between 20 GHz and 100 GHz, with
$\pm$24\% and $\pm$13\% bias margins, respectively, and demonstrates data
densities in the 10s of Mbit/cm$^2$ with the MIT Lincoln Laboratory SC2
fabrication process. Additionally, the circulating nature of this design allows
for minimal control circuitry, eliminates the need for data splitting and
merging, and enables inexpensive implementations of sequential-access and
content-addressable memories. Further advances in fabrication processes suggest
data densities of 100s of Mbit/cm$^2$ and beyond.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 23:10:10 GMT""},{""version"":""v2"",""created"":""Sat, 20 May 2023 00:25:08 GMT""}]","2023-05-23"
"2205.08017","Yutao Zhong","Pranjal Awasthi, Anqi Mao, Mehryar Mohri, Yutao Zhong","$\mathscr{H}$-Consistency Estimation Error of Surrogate Loss Minimizers","ICML 2022 (long presentation)",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a detailed study of estimation errors in terms of surrogate loss
estimation errors. We refer to such guarantees as $\mathscr{H}$-consistency
estimation error bounds, since they account for the hypothesis set
$\mathscr{H}$ adopted. These guarantees are significantly stronger than
$\mathscr{H}$-calibration or $\mathscr{H}$-consistency. They are also more
informative than similar excess error bounds derived in the literature, when
$\mathscr{H}$ is the family of all measurable functions. We prove general
theorems providing such guarantees, for both the distribution-dependent and
distribution-independent settings. We show that our bounds are tight, modulo a
convexity assumption. We also show that previous excess error bounds can be
recovered as special cases of our general results.
  We then present a series of explicit bounds in the case of the zero-one loss,
with multiple choices of the surrogate loss and for both the family of linear
functions and neural networks with one hidden-layer. We further prove more
favorable distribution-dependent guarantees in that case. We also present a
series of explicit bounds in the case of the adversarial loss, with surrogate
losses based on the supremum of the $\rho$-margin, hinge or sigmoid loss and
for the same two general hypothesis sets. Here too, we prove several
enhancements of these guarantees under natural distributional assumptions.
Finally, we report the results of simulations illustrating our bounds and their
tightness.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 23:13:36 GMT""}]","2022-05-18"
"2205.08018","Udayan Khurana","Udayan Khurana and Kavitha Srinivas and Horst Samulowitz","A Survey on Semantics in Automated Data Science",,,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data Scientists leverage common sense reasoning and domain knowledge to
understand and enrich data for building predictive models. In recent years, we
have witnessed a surge in tools and techniques for {\em automated machine
learning}. While data scientists can employ various such tools to help with
model building, many other aspects such as {\em feature engineering} that
require semantic understanding of concepts, remain manual to a large extent. In
this paper we discuss important shortcomings of current automated data science
solutions and machine learning. We discuss how leveraging basic semantic
reasoning on data in combination with novel tools for data science automation
can help with consistent and explainable data augmentation and transformation.
Moreover, semantics can assist data scientists in a new manner by helping with
challenges related to {\em trust}, {\em bias}, and {\em explainability}.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 23:16:09 GMT""}]","2022-05-18"
"2205.08019","Peichun Amy Tsai","Alban Pouplard and Peichun Amy Tsai","Viscous Fingering Instability of Complex Fluids in a Tapered Geometry","Submitted for publication",,,,"physics.flu-dyn cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Viscous fingering (VF) is an interfacial instability that occurs in a narrow
confinement or porous medium when a less-viscous fluid pushes a more viscous
one, producing finger-like patterns. Controlling the VF instability is
essential to enhance the efficiency of various technological applications.
However, the control of VF instability has been challenging and so far focused
on simple Newtonian fluids of constant viscosity. Here, we extend to complex
yield-stress fluids and examine the controlling feasibility by carrying out a
linear stability analysis using a radial cell with a converging gap gradient.
We avoid making the major assumption of a small Bingham number, Bn << 1, i.e.,
a negligible ratio of the yield to shear stress, and instead provide a new
stability criterion predicting apparent complex VF. This criterion depends on
not only the complex fluid's rheology, interfacial tension, and contact angle
to the wetting wall, but also the gap gradient, the radius, gap-thickness, and
velocity at the fluid-fluid interface. Finally, we compare this theoretical
criterion to our experimental data with nitrogen pushing a complex yield-stress
fluid in a taper and find good agreement.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 23:17:50 GMT""}]","2022-05-18"
"2205.08020","Polina Binder","Polina Binder, Meghan Lawler, LaShadric Grady, Neil Carlson, Sumudu
  Leelananda, Svetlana Belyanskaya, Joe Franklin, Nicolas Tilmans, Henri
  Palacci","Partial Product Aware Machine Learning on DNA-Encoded Libraries","8 pages, 5 figures; Published at the MLDD workshop, ICLR 2022",,,,"cs.LG q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  DNA encoded libraries (DELs) are used for rapid large-scale screening of
small molecules against a protein target. These combinatorial libraries are
built through several cycles of chemistry and DNA ligation, producing large
sets of DNA-tagged molecules. Training machine learning models on DEL data has
been shown to be effective at predicting molecules of interest dissimilar from
those in the original DEL. Machine learning chemical property prediction
approaches rely on the assumption that the property of interest is linked to a
single chemical structure. In the context of DNA-encoded libraries, this is
equivalent to assuming that every chemical reaction fully yields the desired
product. However, in practice, multi-step chemical synthesis sometimes
generates partial molecules. Each unique DNA tag in a DEL therefore corresponds
to a set of possible molecules. Here, we leverage reaction yield data to
enumerate the set of possible molecules corresponding to a given DNA tag. This
paper demonstrates that training a custom GNN on this richer dataset improves
accuracy and generalization performance.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 23:18:02 GMT""}]","2022-05-18"
"2205.08021","Marco Schlichting","Marco Schlichting","On the Homology stability range for symplectic groups",,,,,"math.KT math.AT","http://creativecommons.org/licenses/by/4.0/","  We improve, by a factor of 2, known homology stability ranges for the
integral homology of symplectic groups over commutative local rings with
infinite residue field and show that the obstruction to further stability is
bounded below by Milnor-Witt K-theory. In particular our stability range is
optimal in many cases.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 23:23:04 GMT""}]","2022-05-18"
"2205.08022","David Harris","David G. Harris, N. S. Narayanaswamy","A faster algorithm for Vertex Cover parameterized by solution size",,,,,"cs.DS math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe a new algorithm for vertex cover with runtime $O^*(1.25284^k)$,
where $k$ is the size of the desired solution and $O^*$ hides polynomial
factors in the input size. This improves over previous runtime of
$O^*(1.2738^k)$ due to Chen, Kanj, & Xia (2010) standing for more than a
decade. The key to our algorithm is to use a potential function which
simultaneously tracks $k$ as well as the optimal value $\lambda$ of the vertex
cover LP relaxation. This approach also allows us to make use of prior
algorithms for Maximum Independent Set in bounded-degree graphs and
Above-Guarantee Vertex Cover.
  The main step in the algorithm is to branch on high-degree vertices, while
ensuring that both $k$ and $\mu = k - \lambda$ are decreased at each step.
There can be local obstructions in the graph that prevent $\mu$ from decreasing
in this process; we develop a number of novel branching steps to handle these
situations.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 23:23:09 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jul 2022 03:34:24 GMT""},{""version"":""v3"",""created"":""Sun, 6 Nov 2022 17:19:00 GMT""},{""version"":""v4"",""created"":""Sun, 30 Apr 2023 14:10:01 GMT""}]","2023-05-02"
"2205.08023","Guillaume Barraquand","Guillaume Barraquand and Pierre Le Doussal","A stationary model of non-intersecting directed polymers","30 pages, 8 figures","Journal of Physics A: Mathematical and Theoretical, Volume 56,
  Number 4, 2023","10.1088/1751-8121/acb6c8",,"cond-mat.stat-mech math-ph math.MP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the partition function $Z_{\ell}(\vec x,0\vert \vec y,t)$ of
$\ell$ non-intersecting continuous directed polymers of length $t$ in dimension
$1+1$, in a white noise environment, starting from positions $\vec x$ and
terminating at positions $\vec y$. When $\ell=1$, it is well known that for
fixed $x$, the field $\log Z_1(x,0\vert y,t)$ solves the Kardar-Parisi-Zhang
equation and admits the Brownian motion as a stationary measure. In particular,
as $t$ goes to infinity, $Z_1(x,0\vert y,t)/Z_1(x,0\vert 0,t) $ converges to
the exponential of a Brownian motion $B(y)$. In this article, we show an
analogue of this result for any $\ell$. We show that $Z_{\ell}(\vec x,0\vert
\vec y,t)/Z_{\ell}(\vec x,0\vert \vec 0,t) $ converges as $t$ goes to infinity
to an explicit functional $Z_{\ell}^{\rm stat}(\vec y)$ of $\ell$ independent
Brownian motions. This functional $Z_{\ell}^{\rm stat}(\vec y)$ admits a simple
description as the partition sum for $\ell$ non-intersecting semi-discrete
polymers on $\ell$ lines. We discuss applications to the endpoints and
midpoints distribution for long non-crossing polymers and derive explicit
formulas in the case of two polymers. To obtain these results, we show that the
stationary measure of the O'Connell-Warren multilayer stochastic heat equation
is given by a collection of independent Brownian motions. This in turn is shown
via analogous results in a discrete setup for the so-called log-gamma polymer
and exploit the connection between non-intersecting log-gamma polymers and the
geometric RSK correspondence found in arXiv:1110.3489.
  .
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 23:27:40 GMT""},{""version"":""v2"",""created"":""Mon, 20 Feb 2023 19:07:55 GMT""}]","2023-02-22"
"2205.08024","Mika H\""am\""al\""ainen","Khalid Alnajjar and Mika H\""am\""al\""ainen","Harnessing Multilingual Resources to Question Answering in Arabic",,,,,"cs.CL","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The goal of the paper is to predict answers to questions given a passage of
Qur'an. The answers are always found in the passage, so the task of the model
is to predict where an answer starts and where it ends. As the initial data set
is rather small for training, we make use of multilingual BERT so that we can
augment the training data by using data available for languages other than
Arabic. Furthermore, we crawl a large Arabic corpus that is domain specific to
religious discourse. Our approach consists of two steps, first we train a BERT
model to predict a set of possible answers in a passage. Finally, we use
another BERT based model to rank the candidate answers produced by the first
BERT model.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 23:28:01 GMT""}]","2022-05-18"
"2205.08025","Rahnuma Islam Nishat","Rahnuma Islam Nishat, Venkatesh Srinivasan, and Sue Whitesides","The Hamiltonian Path Graph is Connected for Simple $s,t$ Paths in
  Rectangular Grid Graphs",,,,,"cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A \emph{simple} $s,t$ path $P$ in a rectangular grid graph $\mathbb{G}$ is a
Hamiltonian path from the top-left corner $s$ to the bottom-right corner $t$
such that each \emph{internal} subpath of $P$ with both endpoints $a$ and $b$
on the boundary of $\mathbb{G}$ has the minimum number of bends needed to
travel from $a$ to $b$ (i.e., $0$, $1$, or $2$ bends, depending on whether $a$
and $b$ are on opposite, adjacent, or the same side of the bounding rectangle).
Here, we show that $P$ can be reconfigured to any other simple $s,t$ path of
$\mathbb{G}$ by \emph{switching $2\times 2$ squares}, where at most
${5}|\mathbb{G}|/{4}$ such operations are required. Furthermore, each
\emph{square-switch} is done in $O(1)$ time and keeps the resulting path in the
same family of simple $s,t$ paths. Our reconfiguration result proves that the
\emph{Hamiltonian path graph} $\cal{G}$ for simple $s,t$ paths is connected and
has diameter at most ${5}|\mathbb{G}|/{4}$ which is asymptotically tight.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 23:34:07 GMT""}]","2022-05-18"
"2205.08026","Deng Wang","Deng Wang","Shaving the Hair of Black Hole with Sagittarius A$^*$ from Event Horizon
  Telescope","4.5 pages, 1 figure",,,,"gr-qc hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, the Event Horizon Telescope collaboration has reported the first
image of the supermassive black hole Sagittarius in the Galactic Center. We
attempt to test the validity of the no-hair theorem of black holes using this
new shadow observation. Considering the Einstein-Maxwell-klein-Gordon theory
with a minimally-coupled scalar field, we find that our numerical result is
consistent with the prediction of the no-hair theorem. However, we can not rule
out the possibility that black holes with scalar hair may exist in some special
cases.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 23:56:30 GMT""}]","2022-05-18"
"2205.08027","Buang Ann Tay","B. A. Tay","Energy transfer in quantum molecular chain -- two models of
  inhomogeneity","To appear in AIP Proceedings (2022)",,,,"cond-mat.stat-mech quant-ph","http://creativecommons.org/licenses/by/4.0/","  We study a linear chain of oscillators with inhomogeneity in their
interactions with phonon bath. In a previous work on the Markovian master
equation of the system, we investigated a model in which the difference in the
site-phonon coupling between adjacent oscillators is the same throughout the
chain. Here we look into another model in which the oscillators are coupled to
the phonon bath with alternating strength at successive sites. Whereas in the
first model all exciton modes are connected, in the second model they are
coupled in pairs that are not connected to each other. Owing to this special
structure in the coupling, the excitation numbers of different modes can be
solved exactly in the steady state. In the first model, the minima of the
excitation profile in the site basis occur at the edges of the chain, whereas
in the second model the maxima occur at the edges. The energy transfer
efficiency in the first model is affected by the source power whereas in the
second model the efficiency is independent of it. A distinct feature in the
second model is that a sink placed at the middle of the chain is able to
distinguish between chains with even and odd number of sites. The energy
transfer efficiency in a chain with even number of sites is higher than a chain
with odd number of sites. Therefore, it reveals the discrete nature of the
chain. In the limit of very long chain when the discreteness of the chain is
less evident, the efficiencies approach each other.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 23:57:17 GMT""}]","2022-05-18"
"2205.08028","Jacob Miller","Jacob Miller, Stephen Kobourov, Vahan Huroyan","Browser-based Hyperbolic Visualization of Graphs","To appear in IEEE PacificVis 2022",,,,"cs.GR cs.SI","http://creativecommons.org/licenses/by/4.0/","  Hyperbolic geometry offers a natural focus + context for data visualization
and has been shown to underlie real-world complex networks. However, current
hyperbolic network visualization approaches are limited to special types of
networks and do not scale to large datasets. With this in mind, we designed,
implemented, and analyzed three methods for hyperbolic visualization of
networks in the browser based on inverse projections, generalized
force-directed algorithms, and hyperbolic multi-dimensional scaling (H-MDS). A
comparison with Euclidean MDS shows that H-MDS produces embeddings with lower
distortion for several types of networks. All three methods can handle
node-link representations and are available in fully functional web-based
systems.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 23:58:01 GMT""}]","2022-05-18"
"2205.08029","Neetha Jambigi","Neetha Jambigi, Thomas Bach, Felix Schabernack, Michael Felderer","Automatic Error Classification and Root Cause Determination while
  Replaying Recorded Workload Data at SAP HANA","10 pages",,,,"cs.SE cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Capturing customer workloads of database systems to replay these workloads
during internal testing can be beneficial for software quality assurance.
However, we experienced that such replays can produce a large amount of false
positive alerts that make the results unreliable or time consuming to analyze.
Therefore, we design a machine learning based approach that attributes root
causes to the alerts. This provides several benefits for quality assurance and
allows for example to classify whether an alert is true positive or false
positive. Our approach considerably reduces manual effort and improves the
overall quality assurance for the database system SAP HANA. We discuss the
problem, the design and result of our approach, and we present practical
limitations that may require further research.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 23:58:34 GMT""}]","2022-05-18"
"2205.08030","Mingrui Zhang","Mingrui Zhang and Peng Ding","Interpretable sensitivity analysis for the Baron-Kenny approach to
  mediation with unmeasured confounding",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  Mediation analysis assesses the extent to which the treatment affects the
outcome indirectly through a mediator and the extent to which it operates
directly through other pathways. As the most popular method in empirical
mediation analysis, the Baron-Kenny approach estimates the indirect and direct
effects of the treatment on the outcome based on linear structural equation
models. However, when the treatment and the mediator are not randomized, the
estimates may be biased due to unmeasured confounding among the treatment,
mediator, and outcome. Building on Cinelli and Hazlett (2020), we propose a
sharp and interpretable sensitivity analysis method for the Baron-Kenny
approach to mediation in the presence of unmeasured confounding. We first
modify their omitted-variable bias formula to facilitate the discussion with
heteroskedasticity and model misspecification. We then apply the result to
develop a sensitivity analysis method for the Baron-Kenny approach. To ensure
interpretability, we express the sensitivity parameters in terms of the partial
$R^2$'s that correspond to the natural factorization of the joint distribution
of the direct acyclic graph for mediation analysis. They measure the
proportions of variability explained by unmeasured confounding given the
observed variables. Moreover, we extend the method to deal with multiple
mediators, based on a novel matrix version of the partial $R^2$ and a general
form of the omitted-variable bias formula. Importantly, we prove that all our
sensitivity bounds are attainable and thus sharp.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 00:05:36 GMT""},{""version"":""v2"",""created"":""Sun, 12 Jun 2022 04:33:59 GMT""}]","2022-06-14"
"2205.08031","Kagan Yanik","Kagan Yanik, Bibek Bhandari, Sreenath K. Manikandan, and Andrew N.
  Jordan","Thermodynamics of Quantum Measurement and the Demon's Arrow of Time","9 pages, 7 figures",,"10.1103/PhysRevA.106.042221",,"quant-ph cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  We discuss the thermodynamic aspects of a single qubit based device, powered
by weak quantum measurements, and feedback controlled by a quantum Maxwell's
demon. We discuss both discrete and time-continuous operation of the
measurement based device at finite temperature of the reservoir. In the
discrete example where a demon acquires information via discrete weak
measurements, we find that the thermodynamic variables including the heat
exchanged, extractable work, and the entropy produced are completely determined
by an information theoretic measure of the demon's perceived arrow of time. We
also discuss a realistic time-continuous operation of the device where the
feedback is applied after a sequence of weak measurements. In the
time-continuous limit, we derive the exact finite-time statistics of work, heat
and entropy changes along individual quantum trajectories of the quantum
measurement process, and relate them to the demon's arrow of time.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 00:09:01 GMT""},{""version"":""v2"",""created"":""Fri, 30 Sep 2022 17:26:21 GMT""}]","2022-11-09"
"2205.08032","Kordag Kilic","Kordag Mehmet Kilic, Jin Sima and Jehoshua Bruck","On Algebraic Constructions of Neural Networks with Small Weights",,,,,"cs.CC cs.DM cs.IT cs.LG cs.NE math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural gates compute functions based on weighted sums of the input variables.
The expressive power of neural gates (number of distinct functions it can
compute) depends on the weight sizes and, in general, large weights
(exponential in the number of inputs) are required. Studying the trade-offs
among the weight sizes, circuit size and depth is a well-studied topic both in
circuit complexity theory and the practice of neural computation. We propose a
new approach for studying these complexity trade-offs by considering a related
algebraic framework. Specifically, given a single linear equation with
arbitrary coefficients, we would like to express it using a system of linear
equations with smaller (even constant) coefficients. The techniques we
developed are based on Siegel's Lemma for the bounds, anti-concentration
inequalities for the existential results and extensions of Sylvester-type
Hadamard matrices for the constructions.
  We explicitly construct a constant weight, optimal size matrix to compute the
EQUALITY function (checking if two integers expressed in binary are equal).
Computing EQUALITY with a single linear equation requires exponentially large
weights. In addition, we prove the existence of the best-known weight size
(linear) matrices to compute the COMPARISON function (comparing between two
integers expressed in binary). In the context of the circuit complexity theory,
our results improve the upper bounds on the weight sizes for the best-known
circuit sizes for EQUALITY and COMPARISON.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 00:09:23 GMT""}]","2022-05-18"
"2205.08033","Irina Cristali","Irina Cristali and Victor Veitch","Using Embeddings for Causal Estimation of Peer Influence in Social
  Networks","17 pages, 1 figure, 4 tables",,,,"cs.SI cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  We address the problem of using observational data to estimate peer contagion
effects, the influence of treatments applied to individuals in a network on the
outcomes of their neighbors. A main challenge to such estimation is that
homophily - the tendency of connected units to share similar latent traits -
acts as an unobserved confounder for contagion effects. Informally, it's hard
to tell whether your friends have similar outcomes because they were influenced
by your treatment, or whether it's due to some common trait that caused you to
be friends in the first place. Because these common causes are not usually
directly observed, they cannot be simply adjusted for. We describe an approach
to perform the required adjustment using node embeddings learned from the
network itself. The main aim is to perform this adjustment nonparametrically,
without functional form assumptions on either the process that generated the
network or the treatment assignment and outcome processes. The key
contributions are to nonparametrically formalize the causal effect in a way
that accounts for homophily, and to show how embedding methods can be used to
identify and estimate this effect. Code is available at
https://github.com/IrinaCristali/Peer-Contagion-on-Networks.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 00:22:56 GMT""}]","2022-05-18"
"2205.08034","Woong Gyu La","Woong Gyu La, Lingjie Kong, Sunil Muralidhara, Pratik Nichat","DeepSim: A Reinforcement Learning Environment Build Toolkit for ROS and
  Gazebo",,,,,"cs.LG cs.AI cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose DeepSim, a reinforcement learning environment build toolkit for
ROS and Gazebo. It allows machine learning or reinforcement learning
researchers to access the robotics domain and create complex and challenging
custom tasks in ROS and Gazebo simulation environments. This toolkit provides
building blocks of advanced features such as collision detection, behaviour
control, domain randomization, spawner, and many more. DeepSim is designed to
reduce the boundary between robotics and machine learning communities by
providing Python interface. In this paper, we discuss the components and design
decisions of DeepSim Toolkit.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 00:31:40 GMT""}]","2022-05-18"
"2205.08035","Thibaud Taillefumier","Lorenzo Sadun and Thibaud Taillefumier","Global solutions with infinitely many blowups in a mean-field neural
  network",,,,,"math.PR q-bio.NC","http://creativecommons.org/licenses/by/4.0/","  We recently introduced idealized mean-field models for networks of
integrate-and-fire neurons with impulse-like interactions -- the so-called
delayed Poissonian mean-field models. Such models are prone to blowups: for a
strong enough interaction coupling, the mean-field rate of interaction diverges
in finite time with a finite fraction of neurons spiking simultaneously. Due to
the reset mechanism of integrate-and-fire neurons, these blowups can happen
repeatedly, at least in principle. A benefit of considering Poissonian
mean-field models is that one can resolve blowups analytically by mapping the
original singular dynamics onto uniformly regular dynamics via a time change.
Resolving a blowup then amounts to solving the fixed-point problem that
implicitly defines the time change, which can be done consistently for a single
blowup and for nonzero delays. Here we extend this time-change analysis in two
ways: First, we exhibit the existence and uniqueness of explosive solutions
with a countable infinity of blowups in the large interaction regime. Second,
we show that these delayed solutions specify ""physical"" explosive solutions in
the limit of vanishing delays, which in turn can be explicitly constructed. The
first result relies on the fact that blowups are self-sustaining but
nonoverlapping in the time-changed picture. The second result follows from the
continuity of blowups in the time-changed picture and incidentally implies the
existence of periodic solutions. These results are useful to study the
emergence of synchrony in neural network models.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 00:31:53 GMT""}]","2022-05-18"
"2205.08036","Jinyuan Liu","Jinyuan Liu, Tuo Lin, Tian Chen, Xinlian Zhang, Xin M. Tu","On Semiparametric Efficiency of an Emerging Class of Regression Models
  for Between-subject Attributes",,,,,"stat.ME math.ST stat.TH","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The semiparametric regression models have attracted increasing attention
owing to their robustness compared to their parametric counterparts. This paper
discusses the efficiency bound for functional response models (FRM), an
emerging class of semiparametric regression that serves as a timely solution
for research questions involving pairwise observations. This new paradigm is
especially appealing to reduce astronomical data dimensions for those arising
from wearable devices and high-throughput technology, such as microbiome
Beta-diversity, viral genetic linkage, single-cell RNA sequencing, etc. Despite
the growing applications, the efficiency of their estimators has not been
investigated carefully due to the extreme difficulty to address the inherent
correlations among pairs. Leveraging the Hilbert-space-based semiparametric
efficiency theory for classical within-subject attributes, this manuscript
extends such asymptotic efficiency into the broader regression involving
between-subject attributes and pinpoints the most efficient estimator, which
leads to a sensitive signal-detection in practice. With pairwise outcomes
burgeoning immensely as effective dimension-reduction summaries, the
established theory will not only fill the critical gap in identifying the most
efficient semiparametric estimator but also propel wide-ranging implementations
of this new paradigm for between-subject attributes.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 00:42:06 GMT""}]","2022-05-18"
"2205.08037","Xiujuan Zhang","Xiujuan Zhang, Tian Zhang, Ming-Hui Lu, and Yan-Feng Chen","A review on non-Hermitian skin effect",,,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  The past decades have witnessed the flourishing of non-Hermitian physics in
non-conservative systems, leading to unprecedented phenomena of unidirectional
invisibility, enhanced sensitivity and more recently the novel topological
features such as bulk Fermi arcs. Among them, growing efforts have been
invested to an intriguing phenomenon, known as the non-Hermitian skin effect
(NHSE). Here, we review the recent progress in this emerging field. By starting
from the one-dimensional (1D) case, the fundamental concepts of NHSE, its
minimal model, the physical meanings and consequences are elaborated in
details. In particular, we discuss the NHSE enriched by lattice symmetries,
which gives rise to unique non-Hermitian topological properties with revised
bulk-boundary correspondence (BBC) and new definitions of topological
invariants. Then we extend the discussions to two and higher dimensions, where
dimensional surprises enable even more versatile NHSE phenomena. Extensions of
NHSE assisted with extra degrees of freedom such as long-range coupling,
pseudospins, magnetism, non-linearity and crystal defects are also reviewed.
This is followed by the contemporary experimental progress for NHSE. Finally,
we provide the outlooks to possible future directions and developments.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 00:55:51 GMT""}]","2022-05-18"
"2205.08038","Raphael Chinchilla","Raphael Chinchilla, Guosong Yang, Joao P. Hespanha","Newton and interior-point methods for (constrained) nonconvex-nonconcave
  minmax optimization with stability and instability guarantees","Submitted for Journal publication",,,,"math.OC cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  We address the problem of finding a local solution to a nonconvex-nonconcave
minmax optimization using Newton type methods, including interior-point ones.
We modify the Hessian matrix of these methods such that, at each step, the
modified Newton update direction can be seen as the solution to a quadratic
program that locally approximates the minmax problem. Moreover, we show that by
selecting the modification in an appropriate way, the only stable equilibrium
points of the algorithm's iterations are local minmax points. As a consequence,
the algorithm can only converge towards an equilibrium point if such point is a
local minmax, and it will escape if the point is not a local minmax. Using
numerical examples, we show that the computation time of our algorithm scales
roughly linearly with the number of nonzero elements in the Hessian.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 01:02:05 GMT""},{""version"":""v2"",""created"":""Tue, 7 Mar 2023 01:37:41 GMT""}]","2023-03-08"
"2205.08039","Sanefumi Moriyama","Tomohiro Furukawa, Sanefumi Moriyama, Hikaru Sasaki","Duality Cascades and Parallelotopes","37 pages, 9 eps figures; v2: section 2.2 added, four figures added",,"10.1088/1751-8121/acc2fb","NITEP 136, OCU-PHYS 561","hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Duality cascades are a series of duality transformations in field theories,
which can be realized as the Hanany-Witten transitions in brane configurations
on a circle. In the setup of the ABJM theory and its generalizations, from the
physical requirement that duality cascades always end and the final destination
depends only on the initial brane configuration, we propose that the
fundamental domain of supersymmetric brane configurations in duality cascades
can tile the whole parameter space of relative ranks by translations, hence is
a parallelotope. We provide our arguments for the proposal.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 01:03:56 GMT""},{""version"":""v2"",""created"":""Wed, 17 Aug 2022 06:17:23 GMT""}]","2023-04-12"
"2205.08040","Carmen Galaz-Garc\'ia","Carmen Galaz-Garc\'ia","Zariski dense surface subgroups in $SL(n,\mathbb{Q})$ with odd $n$",,,,,"math.GT","http://creativecommons.org/licenses/by-sa/4.0/","  For odd $n$ we construct a path $\rho_t\colon \pi_1(S) \to SL(n,\mathbb{R})$
of discrete, faithful and Zariski dense representations of a surface group such
that $\rho_t(\pi_1(S)) \subset SL(n,\mathbb{Q})$ for every $t\in \mathbb{Q}$.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 01:10:04 GMT""}]","2022-05-18"
"2205.08041","Azarakhsh Keipour","Azarakhsh Keipour, Mohammadreza Mousaei, Maryam Bandari, Stefan
  Schaal, Sebastian Scherer","Detection and Physical Interaction with Deformable Linear Objects","Presented at ICRA 2022 2nd Workshop on Representing and Manipulating
  Deformable Objects (https://deformable-workshop.github.io/icra2022/)",,,,"cs.RO cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deformable linear objects (e.g., cables, ropes, and threads) commonly appear
in our everyday lives. However, perception of these objects and the study of
physical interaction with them is still a growing area. There have already been
successful methods to model and track deformable linear objects. However, the
number of methods that can automatically extract the initial conditions in
non-trivial situations for these methods has been limited, and they have been
introduced to the community only recently. On the other hand, while physical
interaction with these objects has been done with ground manipulators, there
have not been any studies on physical interaction and manipulation of the
deformable linear object with aerial robots.
  This workshop describes our recent work on detecting deformable linear
objects, which uses the segmentation output of the existing methods to provide
the initialization required by the tracking methods automatically. It works
with crossings and can fill the gaps and occlusions in the segmentation and
output the model desirable for physical interaction and simulation. Then we
present our work on using the method for tasks such as routing and manipulation
with the ground and aerial robots. We discuss our feasibility analysis on
extending the physical interaction with these objects to aerial manipulation
applications.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 01:17:21 GMT""},{""version"":""v2"",""created"":""Sat, 8 Apr 2023 21:18:38 GMT""}]","2023-04-11"
"2205.08042","Hirokuni Iiboshi","Hirokuni Iiboshi and Daisuke Ozaki","The Impact of the Social Security Reforms on Welfare: Who benefits and
  Who loses across Generations, Gender, and Employment Type?",,,,,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We quantitatively explore the impact of social security reforms in Japan,
which is facing rapid aging and the highest government debt among developed
countries, using an overlapping generations model with four types of agents
distinguished by gender and employment type. We find that introducing social
security reforms without extending the retirement age raises the welfare of
future generations, while reforms with rising copayment rates for medical and
long-term care expenditures, in particular, significantly lowers the welfare of
low-income groups (females and part-timers) of the current retired and working
generations. In contrast, reforms reducing the pension replacement rate lead to
a greater decline in the welfare of full-timers. The combination of these
reforms and the extension of the retirement age is expected to improve the
welfare of the current working generations by 2--9 % over the level without
reforms.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 01:17:55 GMT""},{""version"":""v2"",""created"":""Sat, 11 Jun 2022 03:30:36 GMT""},{""version"":""v3"",""created"":""Sun, 19 Jun 2022 02:49:59 GMT""},{""version"":""v4"",""created"":""Wed, 26 Oct 2022 02:21:24 GMT""}]","2022-10-27"
"2205.08043","Shaleeza Sohail Dr","Shaleeza Sohail, Zongwen Fan, Xin Gu and Fariza Sabrina","Explainable and Optimally Configured Artificial Neural Networks for
  Attack Detection in Smart Homes",,,,,"cs.CR cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In recent years cybersecurity has become a major concern in adaptation of
smart applications. Specially, in smart homes where a large number of IoT
devices are used having a secure and trusted mechanisms can provide peace of
mind for users. Accurate detection of cyber attacks is crucial, however precise
identification of the type of attacks plays a huge role if devising the
countermeasure for protecting the system. Artificial Neural Networks (ANN) have
provided promising results for detecting any security attacks for smart
applications. However, due to complex nature of the model used for this
technique it is not easy for normal users to trust ANN based security
solutions. Also, selection of right hyperparameters for ANN architecture plays
a crucial role in the accurate detection of security attacks, especially when
it come to identifying the subcategories of attacks. In this paper, we propose
a model that considers both the issues of explainability of ANN model and the
hyperparameter selection for this approach to be easily trusted and adapted by
users of smart home applications. Also, our approach considers a subset of the
dataset for optimal selection of hyperparamters to reduce the overhead of the
process of ANN architecture design. Distinctively this paper focuses on
configuration, performance and evaluation of ANN architecture for
identification of five categorical attacks and nine subcategorical attacks.
Using a very recent IoT dataset our approach showed high performance for
intrusion detection with 99.9%, 99.7%, and 97.7% accuracy for Binary, Category,
and Subcategory level classification of attacks.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 01:25:32 GMT""}]","2022-05-18"
"2205.08044","Qi'an Guan","Shijie Bao, Qi'an Guan","Modules at boundary points, fiberwise Bergman kernels, and
  log-subharmonicity II -- on Stein manifolds","21 pages, some typos are corrected. An appendix is add to show an
  example for explaining the results we obtain in the present paper",,,,"math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we consider Bergman kernels related to modules at boundary
points on Stein manifolds, and obtain a log-subharmonicity property of the
Bergman kernels. As applications, we obtain a lower estimate of weighted $L^2$
integrals on Stein manifolds, and reprove an effectiveness result of strong
openness property of modules at boundary points on Stein manifolds.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 01:29:11 GMT""},{""version"":""v2"",""created"":""Sat, 31 Dec 2022 02:30:18 GMT""}]","2023-01-03"
"2205.08045","Kohei Yamagami","K. Yamagami, Y. Fujisawa, M. Pardo-Almanza, B. R. M. Smith, K. Sumida,
  Y. Takeda, and Y. Okada","Enhanced $d$-$p$ hybridization intertwined with anomalous ground state
  formation in van der Waals-coupled magnetic metal Fe$_5$GeTe$_2$","12 pages, 4 figures",,"10.1103/PhysRevB.106.045137",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  Fe$_5$GeTe$_2$ is a van der Waals (vdW)-coupled unconventional ferromagnetic
metal with a high Curie temperature ($T_C$) exceeding 300 K. The formation of
an anomalous ground state significantly below $T_C$ has received considerable
attention, resulting in increased interest in understanding the spin-polarized
electronic state evolution near the Fermi energy ($E_F$) as a function of
temperature. Despite recent extensive studies, a microscopic understanding of
the spin-polarized electronic structure around $E_F$ has not yet been
established owing to the intrinsic complexity of both the crystal and band
structures. In this study, we investigate the temperature dependence of
element-specific soft X-ray magnetic circular dichroism (XMCD). A systematic
temperature evolution in the XMCD signal from both magnetic Fe and its ligand
Te is clearly observed. More importantly, the enhancement in the hybridization
between the Fe 3$d$ and Te 5$p$ states in the zero-magnetic field limit is
revealed, and we discuss its implications on the possible emergence of an
exotic magnetic ground state in Fe$_5$GeTe$_2$.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 01:30:09 GMT""}]","2022-08-10"
"2205.08046","Valmir C. Barbosa","Eduardo J. Aguilar, Valmir C. Barbosa","Shape complexity in cluster analysis","Minor improvements and fixes in this version","PLoS One 18 (2023), e0286312","10.1371/journal.pone.0286312",,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In cluster analysis, a common first step is to scale the data aiming to
better partition them into clusters. Even though many different techniques have
throughout many years been introduced to this end, it is probably fair to say
that the workhorse in this preprocessing phase has been to divide the data by
the standard deviation along each dimension. Like division by the standard
deviation, the great majority of scaling techniques can be said to have roots
in some sort of statistical take on the data. Here we explore the use of
multidimensional shapes of data, aiming to obtain scaling factors for use prior
to clustering by some method, like k-means, that makes explicit use of
distances between samples. We borrow from the field of cosmology and related
areas the recently introduced notion of shape complexity, which in the variant
we use is a relatively simple, data-dependent nonlinear function that we show
can be used to help with the determination of appropriate scaling factors.
Focusing on what might be called ""midrange"" distances, we formulate a
constrained nonlinear programming problem and use it to produce candidate
scaling-factor sets that can be sifted on the basis of further considerations
of the data, say via expert knowledge. We give results on some iconic data
sets, highlighting the strengths and potential weaknesses of the new approach.
These results are generally positive across all the data sets used.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 01:33:15 GMT""},{""version"":""v2"",""created"":""Wed, 18 May 2022 10:59:59 GMT""},{""version"":""v3"",""created"":""Mon, 5 Sep 2022 19:08:44 GMT""}]","2023-05-30"
"2205.08047","Jonathan Hehir","Jonathan Hehir, Xiaoyue Niu, Aleksandra Slavkovic","Perfect Spectral Clustering with Discrete Covariates","23 pages, 1 figure",,,,"stat.ML cs.LG cs.SI math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Among community detection methods, spectral clustering enjoys two desirable
properties: computational efficiency and theoretical guarantees of consistency.
Most studies of spectral clustering consider only the edges of a network as
input to the algorithm. Here we consider the problem of performing community
detection in the presence of discrete node covariates, where network structure
is determined by a combination of a latent block model structure and homophily
on the observed covariates. We propose a spectral algorithm that we prove
achieves perfect clustering with high probability on a class of large, sparse
networks with discrete covariates, effectively separating latent network
structure from homophily on observed covariates. To our knowledge, our method
is the first to offer a guarantee of consistent latent structure recovery using
spectral clustering in the setting where edge formation is dependent on both
latent and observed factors.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 01:41:06 GMT""}]","2022-05-18"
"2205.08048","Bassam Bamieh","Bassam Bamieh","A Short Introduction to the Koopman Representation of Dynamical Systems",,,,,"eess.SY cs.SY math.DS","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Koopman representation is an infinite dimensional linear representation
of linear or nonlinear dynamical systems. It represents the dynamics of output
maps (aka observables), which are functions on the state space whose evaluation
is interpreted as an output. Conceptually simple derivations and commentary on
the Koopman representation are given. We emphasize an important duality between
initial conditions and output maps of the original system, and those of the
Koopman representation. This duality is an important consideration when this
representation is used in data-driven applications such as the Dynamic Mode
Decomposition (DMD) and its variants. The adjoint relation between the Koopman
representation and the transfer operator of mass transport is also shown.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 01:44:42 GMT""}]","2022-05-18"
"2205.08049","Qianqian Hou","Qianqian Hou","Boundary layer problem on chemotaxis-Navier-Stokes system with Robin
  boundary conditions",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is concerned with the boundary layer problem on a
chemotaxis-Navier-Stokes system modelling boundary layer formation of aerobic
bacteria in fluid. Completing the system with physical Robin-type boundary
conditions for oxygen, no-flux and Dirichlet boundary conditions for bacteria
and fluid velocity, we show that the gradients of its radial solutions in a
region between two concentric spheres possessing boundary layer effects as the
oxygen diffusion rate $\varepsilon$ goes to zero and the boundary-layer
thickness is of order $\mathcal{O}(\varepsilon^\alpha)$ with
$0<\alpha<\frac{1}{2}$.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 01:48:10 GMT""}]","2022-05-18"
"2205.08050","Alessandro Monti","Alessandro Monti, Shane Nicholas, Mohammad Omidyeganeh, Alfredo
  Pinelli, and Marco E. Rosti","On the solidity parameter in canopy flows",,,"10.1017/jfm.2022.551",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have performed high-fidelity simulations of turbulent open-channel flows
over submerged rigid canopies made of cylindrical filaments of fixed length
$l=0.25H$ ($H$ being the domain depth) mounted on the wall with an angle of
inclination $\theta$. The inclination is the free parameter that sets the
density of the canopy by varying its frontal area. The density of the canopy,
based on the solidity parameter $\lambda$, is a widely accepted criterion
defining the ongoing canopy flow regime, with low values ($\lambda \ll 0.1$)
indicating the sparse regime, and higher values ($\lambda > 0.1$) the dense
regime. All the numerical predictions have been obtained considering the same
nominal bulk Reynolds number (i.e. $Re_b=U_b H/\nu = 6000$). We consider nine
configurations of canopies, with $\theta$ varying symmetrically around
$0{\deg}$ in the range $\theta\in [\pm 78.5{\deg}]$, where positive angles
define canopies inclined in the flow direction (with the grain) and
$\theta=0{\deg}$ corresponds to the wall-normally mounted canopy. The study
compares canopies with identical solidity obtained inclining the filaments in
opposite angles and assesses the efficacy of the solidity as a representative
parameter. It is found that when the canopy is inclined, the actual flow regime
differs substantially from the one of a straight canopy that shares the same
solidity indicating that criteria solely based on this parameter are not
robust. Finally, a new phenomenological model describing the interaction
between the coherent structures populating the canopy region and the outer flow
is given.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 01:52:34 GMT""},{""version"":""v2"",""created"":""Wed, 29 Jun 2022 00:39:32 GMT""}]","2022-08-10"
"2205.08051","Zheng Cao","Zheng Cao, Koichi Hattori, Masaru Hongo, Xu-Guang Huang, Hidetoshi
  Taya","Gyrohydrodynamics: Relativistic spinful fluid with strong vorticity",,"PTEP 2022 (2022) 7, 071D01","10.1093/ptep/ptac091","RIKEN-iTHEMS-Report-22","hep-th hep-ph nucl-th","http://creativecommons.org/licenses/by/4.0/","  We develop a relativistic (quasi-)hydrodynamic framework, dubbed the
gyrohydrodynamics, to describe fluid dynamics of many-body systems with spin
under strong vorticity based on entropy-current analysis. This framework
generalizes the recently-developed spin hydrodynamics to the regime where the
spin density is at the leading order in derivatives but suppressed by another
small parameter, the Planck constant $\hbar$, due to its quantum nature. Our
analysis shows that the complete first-order constitutive relations of
gyrohydrodynamics involve seventeen transport coefficients and are highly
anisotropic.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 01:53:10 GMT""},{""version"":""v2"",""created"":""Tue, 21 Jun 2022 06:22:17 GMT""}]","2022-10-04"
"2205.08052","Youfei Yu","Youfei Yu, Min Zhang, Bhramar Mukherjee","An Inverse Probability Weighted Regression Method that Accounts for
  Right-censoring for Causal Inference with Multiple Treatments and a Binary
  Outcome",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  Comparative effectiveness research often involves evaluating the differences
in the risks of an event of interest between two or more treatments using
observational data. Often, the post-treatment outcome of interest is whether
the event happens within a pre-specified time window, which leads to a binary
outcome. One source of bias for estimating the causal treatment effect is the
presence of confounders, which are usually controlled using propensity
score-based methods. An additional source of bias is right-censoring, which
occurs when the information on the outcome of interest is not completely
available due to dropout, study termination, or treatment switch before the
event of interest. We propose an inverse probability weighted regression-based
estimator that can simultaneously handle both confounding and right-censoring,
calling the method CIPWR, with the letter C highlighting the censoring
component. CIPWR estimates the average treatment effects by averaging the
predicted outcomes obtained from a logistic regression model that is fitted
using a weighted score function. The CIPWR estimator has a double robustness
property such that estimation consistency can be achieved when either the model
for the outcome or the models for both treatment and censoring are correctly
specified. We establish the asymptotic properties of the CIPWR estimator for
conducting inference, and compare its finite sample performance with that of
several alternatives through simulation studies. The methods under comparison
are applied to a cohort of prostate cancer patients from an insurance claims
database for comparing the adverse effects of four candidate drugs for advanced
stage prostate cancer.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 01:53:51 GMT""}]","2022-05-18"
"2205.08053","Edward Taylor","Edward Taylor, Richard P. Hill, Daniel Letourneau","Modeling the impact of spatial oxygen heterogeneity on radiolytic oxygen
  depletion during FLASH radiotherapy","Published version","Physics in Medicine and Biology, 2022","10.1088/1361-6560/ac702c",,"physics.med-ph","http://creativecommons.org/licenses/by/4.0/","  It has been postulated that the delivery of radiotherapy at ultra-high dose
rates (""FLASH"") reduces normal tissue toxicities by depleting them of oxygen.
The fraction of normal tissue and cancer cells surviving radiotherapy depends
on dose and oxygen levels in an exponential manner and even a very small
fraction of tissue at low oxygen levels can determine radiotherapy response.
The effect of FLASH on radiation-induced normal and tumour tissue cell killing
was studied by simulating oxygen diffusion, metabolism, and radiolytic oxygen
depletion over domains with simulated capillary architectures. Two
architectural models were used: 1.) randomly distributed capillaries and 2.)
capillaries forming a regular square lattice array. The resulting oxygen
partial pressure distribution histograms were used to simulate normal and
tumour tissue cell survival using the linear quadratic model of cell survival,
modified to incorporate oxygen-enhancement ratio (OER) effects. Tumour cell
survival was found to be increased by FLASH as compared to conventional
radiotherapy, with a 0-1 order of magnitude increase for expected levels of
tumour hypoxia, depending on the relative magnitudes of radiolytic oxygen
depletion and tissue oxygen metabolism. Interestingly, for the random capillary
model, the impact of FLASH on well-oxygenated (normal) tissues was found to be
much greater, with an estimated increase in cell survival by up to 10 orders of
magnitude, even though reductions in mean tissue partial pressure were modest,
less than 7 mmHg for the parameter values studied. The presence of very small
nearly hypoxic regions in otherwise well-perfused normal tissues with high mean
oxygen levels resulted in a greater proportional sparing of normal tissue than
tumour cells during FLASH irradiation, possibly explaining empirical normal
tissue sparing and iso-tumour control results.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 01:57:38 GMT""}]","2022-05-18"
"2205.08054","Yoichi Watanabe","Yoichi Watanabe, A. Biswas, K. Rangarajan, G. Rath, and N. Gopishankar","Classification of anatomic structures in head and neck by CT-based
  radiomics",,,,,"q-bio.QM eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Background and Purpose: Radiomics features are used to identify disease types
and predict therapy outcomes. However, how the radiomics features are different
among different anatomical structures has never been investigated. Hence, we
analyzed the radiomics features of 22 anatomical structures in the head and
neck area in CT images. Furthermore, we studied whether CT radiomics can
classify anatomical structures of the head and neck using unsupervised
machine-learning techniques. Materials and methods: We obtained IMRT/VMAT
treatment planning data from 36 patients treated for head and neck cancers in a
single institution. There were 1357 contours of more than 22 anatomical
structures drawn on planning CTs. We calculated 174 radiomics features using
the SIBEX program. First, we tested whether the radiomics features of
anatomical structures were unique enough to classify all contours into 22
groups. We then developed a two-stage clustering technique to classify 22
anatomic structures into sub-groups with similar physiological or biological
characteristics. Results: The heatmap of 174 radiomics features of 22
anatomical structures showed a distinct difference among tumors and other
healthy structures. Radiomics features have allowed us to identify the eyes,
lens, submandibular, pituitary glands, and thyroids with over 90% accuracy. The
two-stage clustering of 22 structures resulted in six subgroups, which shared
common characteristics such as fatty and bony tissues. Conclusions: We have
shown that anatomical structures in head and neck tumors have distinguishable
radiomics features. We could observe similarities of features among subgroups
of the structures. The results suggest that CT radiomics can help distinguish
the biological characteristics of head and neck lesions.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 01:59:23 GMT""}]","2022-05-18"
"2205.08055","Xiaomin Fang","Shanzhuo Zhang, Zhiyuan Yan, Yueyang Huang, Lihang Liu, Donglong He,
  Wei Wang, Xiaomin Fang, Xiaonan Zhang, Fan Wang, Hua Wu, Haifeng Wang","HelixADMET: a robust and endpoint extensible ADMET system incorporating
  self-supervised knowledge transfer",,"Bioinformatics, 2022","10.1093/bioinformatics/btac342",,"q-bio.BM cs.AI cs.LG q-bio.QM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Accurate ADMET (an abbreviation for ""absorption, distribution, metabolism,
excretion, and toxicity"") predictions can efficiently screen out undesirable
drug candidates in the early stage of drug discovery. In recent years, multiple
comprehensive ADMET systems that adopt advanced machine learning models have
been developed, providing services to estimate multiple endpoints. However,
those ADMET systems usually suffer from weak extrapolation ability. First, due
to the lack of labelled data for each endpoint, typical machine learning models
perform frail for the molecules with unobserved scaffolds. Second, most systems
only provide fixed built-in endpoints and cannot be customised to satisfy
various research requirements. To this end, we develop a robust and endpoint
extensible ADMET system, HelixADMET (H-ADMET). H-ADMET incorporates the concept
of self-supervised learning to produce a robust pre-trained model. The model is
then fine-tuned with a multi-task and multi-stage framework to transfer
knowledge between ADMET endpoints, auxiliary tasks, and self-supervised tasks.
Our results demonstrate that H-ADMET achieves an overall improvement of 4%,
compared with existing ADMET systems on comparable endpoints. Additionally, the
pre-trained model provided by H-ADMET can be fine-tuned to generate new and
customised ADMET endpoints, meeting various demands of drug research and
development requirements.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 02:04:22 GMT""}]","2022-05-25"
"2205.08056","Debanjan Ghosh","Lingyu Gao, Debanjan Ghosh, Kevin Gimpel","""What makes a question inquisitive?"" A Study on Type-Controlled
  Inquisitive Question Generation","Accepted at the 11th Joint Conference on Lexical and Computational
  Semantics (*SEM) Conference, NAACL 2022",,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  We propose a type-controlled framework for inquisitive question generation.
We annotate an inquisitive question dataset with question types, train question
type classifiers, and finetune models for type-controlled question generation.
Empirical results demonstrate that we can generate a variety of questions that
adhere to specific types while drawing from the source texts. We also
investigate strategies for selecting a single question from a generated set,
considering both an informative vs.~inquisitive question classifier and a
pairwise ranker trained from a small set of expert annotations. Question
selection using the pairwise ranker yields strong results in automatic and
manual evaluation. Our human evaluation assesses multiple aspects of the
generated questions, finding that the ranker chooses questions with the best
syntax (4.59), semantics (4.37), and inquisitiveness (3.92) on a scale of 1-5,
even rivaling the performance of human-written questions.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 02:05:50 GMT""},{""version"":""v2"",""created"":""Wed, 18 May 2022 16:31:52 GMT""},{""version"":""v3"",""created"":""Thu, 19 May 2022 12:33:35 GMT""}]","2022-05-20"
"2205.08057","Zachary Vendeiro","Zachary Vendeiro, Joshua Ramette, Alyssa Rudelis, Michelle Chong,
  Josiah Sinclair, Luke Stewart, Alban Urvoy, Vladan Vuleti\'c","Machine-learning-accelerated Bose-Einstein condensation","9 pages, 5 figures + supplemental material",,"10.1103/PhysRevResearch.4.043216",,"physics.atom-ph cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine learning is emerging as a technology that can enhance physics
experiment execution and data analysis. Here, we apply machine learning to
accelerate the production of a Bose-Einstein condensate (BEC) of
$^{87}\mathrm{Rb}$ atoms by Bayesian optimization of up to 55 control
parameters. This approach enables us to prepare BECs of $2.8 \times 10^3$
optically trapped $^{87}\mathrm{Rb}$ atoms from a room-temperature gas in 575
ms. The algorithm achieves the fast BEC preparation by applying highly
efficient Raman cooling to near quantum degeneracy, followed by a brief final
evaporation. We anticipate that many other physics experiments with complex
nonlinear system dynamics can be significantly enhanced by a similar
machine-learning approach.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 02:09:23 GMT""},{""version"":""v2"",""created"":""Thu, 6 Oct 2022 05:25:40 GMT""},{""version"":""v3"",""created"":""Mon, 19 Dec 2022 00:25:54 GMT""}]","2022-12-29"
"2205.08058","Jiajia Zhou","Jiajia Zhou and Masao Doi","Derivation of Two-fluid Model Based on Onsager Principle","11 pages, submitted to Entropy","Entropy 24, 716 (2022)","10.3390/e24050716",,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using Onsager variational principle, we study the dynamic coupling between
the stress and the composition in polymer solution. In the original derivation
of the two-fluid model [Doi and Onuki, J. Phys. II France {\bf 2}, 1631
(1992)], the polymer stress was introduced \emph{a priopri}, therefore a
constitutive equation is required to close the equations. Based on our previous
study of viscoelastic fluids with homogeneous composition [Phys. Rev. Fluids
{\bf 3}, 084004 (2018)], we start with a dumbbell model for the polymer, and
derive all dynamic equations using the Onsager variational principle.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 02:11:26 GMT""}]","2023-03-14"
"2205.08059","Jonas Maziero","Lucas Friedrich and Jonas Maziero","Evolution strategies: Application in hybrid quantum-classical neural
  networks",,"Quantum Inf. Process. 22, 132 (2023)","10.1007/s11128-023-03876-8",,"quant-ph cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the rapid development of quantum computers, several applications are
being proposed for them. Quantum simulations, simulation of chemical reactions,
solution of optimization problems and quantum neural networks (QNNs) are some
examples. However, problems such as noise, limited number of qubits and circuit
depth, and gradient vanishing must be resolved before we can use them to their
full potential. In the field of quantum machine learning, several models have
been proposed. In general, in order to train these different models, we use the
gradient of a cost function with respect to the model parameters. In order to
obtain this gradient, we must compute the derivative of this function with
respect to the model parameters. One of the most used methods in the literature
to perform this task is the parameter-shift rule method. This method consists
of evaluating the cost function twice for each parameter of the QNN. A problem
with this method is that the number of evaluations grows linearly with the
number of parameters. In this work we study an alternative method, called
Evolution Strategies (ES), which are a family of black box optimization
algorithms which iteratively update the parameters using a search gradient. An
advantage of the ES method is that in using it one can control the number of
times the cost function will be evaluated. We apply the ES method to the binary
classification task, showing that this method is a viable alternative for
training QNNs. However, we observe that its performance will be strongly
dependent on the hyperparameters used. Furthermore, we also observe that this
method, alike the parameter shift rule method, suffers from the problem of
gradient vanishing.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 02:14:44 GMT""},{""version"":""v2"",""created"":""Tue, 28 Feb 2023 20:39:51 GMT""}]","2023-03-02"
"2205.08060","Feng Yuan","Yoshitaka Hatta, Bo-Wen Xiao, Feng Yuan","Semi-inclusive Diffractive Deep Inelastic Scattering at Small-$x$","Added appendices, 10 pages, 5 figures",,"10.1103/PhysRevD.106.094015",,"hep-ph hep-ex nucl-ex nucl-th","http://creativecommons.org/licenses/by/4.0/","  Inspired by a recent study of Iancu, Mueller and Triantafyllopoulos [1] and
earlier papers by Golec-Biernat and Wusthoff [2,3], we propose semi-inclusive
diffractive deep inelastic scattering (SIDDIS) to investigate the gluon
tomography in the nucleon and nuclei at small-$x$. The relevant diffractive
quark and gluon parton distribution functions (DPDF) can be computed in terms
of the color dipole S-matrices in the fundamental and adjoint representations,
respectively. Novel correlations from the gluon tomography in the dipole
S-matrix can be experimentally studied through the DPDFs in these processes at
the future electron-ion collider (EIC).
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 02:26:33 GMT""},{""version"":""v2"",""created"":""Mon, 7 Nov 2022 18:46:53 GMT""}]","2022-11-23"
"2205.08061","Jonathan Jiang","Philip E. Rosen, Dan Zhang, Jonathan H. Jiang, Leopold Van Ijzendoorn,
  Kristen A. Fahy, Zong-Hong Zhu","Impact of Economic Constraints on the Projected Timeframe for
  Human-Crewed Deep Space Exploration","10 pages, 5 figures",,"10.3390/galaxies10040088",,"physics.pop-ph astro-ph.EP astro-ph.IM physics.soc-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Deep space exploration offers the most profound opportunity for the expansion
of humanity and our understanding of the Universe, but remains extremely
challenging. Progress will continue to be paced by uncrewed missions followed
up by crewed missions to ever further destinations. Major space powers continue
to invest in crewed deep space exploration as an important national strategy.
An improved model based on previous work is developed, which projects the
earliest possible launch dates for human-crewed missions from cis-lunar space
to selected destinations in the Solar System and beyond based on NASA's
historic budget trend and overall development trends of deep space exploration
research. The purpose of the analysis is to provide a projected timeframe for
crewed missions beyond Mars. Our findings suggest the first human missions from
a spacefaring nation or international collaboration to the Asteroid Belt and
Jovian System could be scheduled as soon as ~2071 to ~2087 and ~2101 to ~2121,
respectively, while a launch to the Saturn System may occur by the year ~2132,
with an uncertainty window of ~2129 to ~2153.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 02:28:29 GMT""}]","2022-08-16"
"2205.08062","Zhiyi Huang","Ziyun Chen and Zhiyi Huang and Dorsa Majdi and Zipeng Yan","Strong Revenue (Non-)Monotonicity of Single-parameter Auctions",,,,,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consider Myerson's optimal auction with respect to an inaccurate prior, e.g.,
estimated from data, which is an underestimation of the true value
distribution. Can the auctioneer expect getting at least the optimal revenue
w.r.t. the inaccurate prior since the true value distribution is larger? This
so-called strong revenue monotonicity is known to be true for single-parameter
auctions when the feasible allocations form a matroid. We find that strong
revenue monotonicity fails to generalize beyond the matroid setting, and
further show that auctions in the matroid setting are the only downward-closed
auctions that satisfy strong revenue monotonicity. On the flip side, we recover
an approximate version of strong revenue monotonicity that holds for all
single-parameter auctions, even without downward-closedness. As applications,
we get sample complexity upper bounds for single-parameter auctions under
matroid constraints, downward-closed constraints, and general constraints. They
improve the state-of-the-art upper bounds and are tight up to logarithmic
factors.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 02:29:36 GMT""},{""version"":""v2"",""created"":""Wed, 9 Nov 2022 02:52:45 GMT""}]","2022-11-10"
"2205.08063","Jing-Wen Yi","Jiahao Dai, Jing-Wen Yi, Li Chai","Fast consensus of high-order multi-agent systems","9 pages",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, the fast consensus problem of high-order multi-agent systems
under undirected topologies is considered. The direct link between the
consensus convergence rate and the control gains is established. An accelerated
consensus algorithm based on gradient descent is proposed to optimize the
convergence rate. By applying the Routh-Hurwitz stability criterion, the lower
bound on the convergence rate is derived, and explicit control gains are
derived as the necessary condition to achieve the optimal convergence rate.
Moreover, a protocol with time-varying control gains is designed to achieve the
finite-time consensus. Explicit formulas for the time-varying control gains and
the final consensus state are given. Numerical examples and simulation results
are presented to illustrate the obtained theoretical results.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 02:29:37 GMT""}]","2022-05-18"
"2205.08064","Ryosuke Nishide","Ryosuke Nishide, Shuji Ishihara","Pattern Propagation Driven by Surface Curvature","Accepted by PRL
  (https://journals.aps.org/prl/accepted/9e070Yd7Ce41e478502d7524db41ca3ec89bef83d)",,"10.1103/PhysRevLett.128.224101",,"nlin.PS physics.bio-ph","http://creativecommons.org/licenses/by/4.0/","  Pattern dynamics on curved surfaces are found everywhere in nature. The
geometry of surfaces have been shown to influence dynamics and play a
functional role, yet a comprehensive understanding is still elusive. Here, we
report for the first time that a static Turing pattern on a flat surface can
propagate on a curved surface, as opposed to previous studies, where the
pattern is presupposed to be static irrespective of the surface geometry. To
understand such significant changes on curved surfaces, we investigate
reaction-diffusion systems on axisymmetric curved surfaces. Numerical and
theoretical analyses reveal that both the symmetries of the surface and pattern
participate in the initiation of pattern propagation. This study provides a
novel and generic mechanism of pattern propagation that is caused by surface
curvature, as well as insights into the general role of surface geometry.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 02:54:29 GMT""}]","2022-06-15"
"2205.08065","Yuta Ozawa","Yuta Ozawa, Takayuki Nagata and Taku Nonomura","Spatiotemporal Superresolution Measurement based on POD and Sparse
  Regression applied to a Supersonic Jet measured by PIV and Near-field
  Microphone",,,"10.1007/s12650-022-00855-6",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The present study proposed the framework of the spatiotemporal
superresolution measurement based on the sparse regression with dimensionality
reduction using the proper orthogonal decomposition (POD). The
non-time-resolved particle image velocimetry (PIV) and the time-resolved
near-field acoustic measurements using microphones were simultaneously
performed for a Mach 1.35 supersonic jet. POD is applied to PIV and microphone
data matrices and the sparse linear regression model of the reduced-order data
is calculated using the least absolute shrinkage and selection operator
regression. The effects of the hyperparameters of the superresolution
measurement were quantitatively evaluated through randomized cross-validation.
The superresolved velocity field indicated the smooth convection of the
velocity fluctuations associated with the screech tone, while the convection of
the large-scale structures at the downstream side was not observed. The
proposed framework can reconstruct the unsteady fluctuation with multiple
frequency phenomena, although the reconstruction is limited to the phenomena
that are associated with the microphone output.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 02:57:43 GMT""}]","2022-07-27"
"2205.08066","Ning Zhou","Ying Yuan, Abdusalam Abdukerim, Zihao Bo, Wei Chen, Xun Chen, Yunhua
  Chen, Chen Cheng, Xiangyi Cui, Yingjie Fan, Deqing Fang, Changbo Fu, Mengting
  Fu, Lisheng Geng, Karl Giboni, Linhui Gu, Xuyuan Guo, Ke Han, Changda He,
  Jinrong He, Di Huang, Yanlin Huang, Zhou Huang, Ruquan Hou, Xiangdong Ji,
  Yonglin Ju, Chenxiang Li, Mingchuan Li, Shu Li, Shuaijie Li, Qing Lin,
  Jianglai Liu, Xiaoying Lu, Lingyin Luo, Wenbo Ma, Yugang Ma, Yajun Mao, Yue
  Meng, Nasir Shaheed, Xuyang Ning, Ningchun Qi, Zhicheng Qian, Xiangxiang Ren,
  Changsong Shang, Guofang Shen, Lin Si, Wenliang Sun, Andi Tan, Yi Tao, Anqing
  Wang, Meng Wang, Qiuhong Wang, Shaobo Wang, Siguang Wang, Wei Wang, Xiuli
  Wang, Zhou Wang, Mengmeng Wu, Weihao Wu, Jingkai Xia, Mengjiao Xiao, Xiang
  Xiao, Pengwei Xie, Binbin Yan, Xiyu Yan, Jijun Yang, Yong Yang, Chunxu Yu,
  Jumin Yuan, Dan Zhang, Minzhen Zhang, Peng Zhang, Tao Zhang, Li Zhao, Qibin
  Zheng, Jifang Zhou, Ning Zhou, Xiaopeng Zhou, and Yong Zhou (for the PandaX
  Collaboration)","A search for two-component Majorana dark matter in a simplified model
  using the full exposure data of PandaX-II experiment",,,"10.1016/j.physletb.2022.137254",,"hep-ex hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the two-component Majorana dark matter model, one dark matter particle can
scatter off the target nuclei, and turn into a slightly heavier component. In
the framework of a simplified model with a vector boson mediator, both the
tree-level and loop-level processes contribute to the signal in direct
detection experiment. In this paper, we report the search results for such dark
matter from PandaX-II experiment, using total data of the full 100.7
tonne$\cdot$day exposure. No significant excess is observed, so strong
constraints on the combined parameter space of mediator mass and dark matter
mass are derived. With the complementary search results from collider
experiments, a large range of parameter space can be excluded.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 02:59:49 GMT""}]","2022-06-29"
"2205.08067","Sudeep Pasricha","Joydeep Dey, Sudeep Pasricha","Robust Perception Architecture Design for Automotive Cyber-Physical
  Systems",,,,,"cs.LG cs.RO cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In emerging automotive cyber-physical systems (CPS), accurate environmental
perception is critical to achieving safety and performance goals. Enabling
robust perception for vehicles requires solving multiple complex problems
related to sensor selection/ placement, object detection, and sensor fusion.
Current methods address these problems in isolation, which leads to inefficient
solutions. We present PASTA, a novel framework for global co-optimization of
deep learning and sensing for dependable vehicle perception. Experimental
results with the Audi-TT and BMW-Minicooper vehicles show how PASTA can find
robust, vehicle-specific perception architecture solutions.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 03:02:07 GMT""}]","2022-05-18"
"2205.08068","Sudeep Pasricha","Liping Wang, Sudeep Pasricha","A Framework for CSI-Based Indoor Localization with 1D Convolutional
  Neural Networks",,,,,"eess.SP cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Modern indoor localization techniques are essential to overcome the weak GPS
coverage in indoor environments. Recently, considerable progress has been made
in Channel State Information (CSI) based indoor localization with signal
fingerprints. However, CSI signal patterns can be complicated in the large and
highly dynamic indoor spaces with complex interiors, thus a solution for
solving this issue is urgently needed to expand the applications of CSI to a
broader indoor space. In this paper, we propose an end-to-end solution
including data collection, pattern clustering, denoising, calibration and a
lightweight one-dimensional convolutional neural network (1D CNN) model with
CSI fingerprinting to tackle this problem. We have also created and plan to
open source a CSI dataset with a large amount of data collected across complex
indoor environments at Colorado State University. Experiments indicate that our
approach achieves up to 68.5% improved performance (mean distance error) with
minimal number of parameters, compared to the best-known deep machine learning
and CSI-based indoor localization works.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 03:04:47 GMT""}]","2022-05-18"
"2205.08069","Sudeep Pasricha","Saideep Tiku, Danish Gufran, Sudeep Pasricha","Multi-Head Attention Neural Network for Smartphone Invariant Indoor
  Localization",,,,,"eess.SP cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Smartphones together with RSSI fingerprinting serve as an efficient approach
for delivering a low-cost and high-accuracy indoor localization solution.
However, a few critical challenges have prevented the wide-spread proliferation
of this technology in the public domain. One such critical challenge is device
heterogeneity, i.e., the variation in the RSSI signal characteristics captured
across different smartphone devices. In the real-world, the smartphones or IoT
devices used to capture RSSI fingerprints typically vary across users of an
indoor localization service. Conventional indoor localization solutions may not
be able to cope with device-induced variations which can degrade their
localization accuracy. We propose a multi-head attention neural network-based
indoor localization framework that is resilient to device heterogeneity. An
in-depth analysis of our proposed framework across a variety of indoor
environments demonstrates up to 35% accuracy improvement compared to
state-of-the-art indoor localization techniques.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 03:08:09 GMT""}]","2022-05-18"
"2205.08070","Zhihuan Zhou","Zhihuan Zhou, Gang Liu, Yuhao Mu, Lixin Xu","Limit on the dark matter mass from its interaction with photons","14 pages, 9 figures","Phys. Rev. D 105, 103509 (2022)","10.1103/PhysRevD.105.103509",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  In this work, we explore the phenomenology of generalized dark matter (GDM)
which interacts with photons ($\gamma$). We assume that DM establishes elastic
scattering with $\gamma$ when it has already become nonrelativistic, otherwise
the abundance of DM today is disfavored by current observations. Within this
scenario, the equation of state (EoS) of DM is determined by its mass
($m_\chi$) and the DM-$\gamma$ scattering cross-section. The distinctive
imprints of a nonzero EoS of DM on CMB angular power spectrum allow us to set a
lower limit on $m_\chi$ with Planck 2018 data alone, i.e., $m_{\chi} > 8.7$ keV
at $95\%$ C.L. In the study of cosmic concordance problems, we find that the
GDM scenario preserves the sound horizon ($r_s(z_*)$) predicted in the fiducial
$\Lambda$CDM model, and thus does not solve the $H_0$ tension. When performing
the joint analysis of Planck+LSS datasets, the best-fit $S_8= 0.785\pm 0.017$
closely matches the given $S_8$ prior. This suggests that the GDM scenario can
be counted as a viable candidate to restore the $S_8$ ($\sigma_{8}$) tension.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 03:08:18 GMT""}]","2022-05-18"
"2205.08071","Michal Kepkowski","Michal Kepkowski, Lucjan Hanzlik, Ian Wood, and Mohamed Ali Kaafar","How Not to Handle Keys: Timing Attacks on FIDO Authenticator Privacy","to be published in the 22nd Privacy Enhancing Technologies Symposium
  (PETS 2022)",,,,"cs.CR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper presents a timing attack on the FIDO2 (Fast IDentity Online)
authentication protocol that allows attackers to link user accounts stored in
vulnerable authenticators, a serious privacy concern. FIDO2 is a new standard
specified by the FIDO industry alliance for secure token online authentication.
It complements the W3C WebAuthn specification by providing means to use a USB
token or other authenticator as a second factor during the authentication
process. From a cryptographic perspective, the protocol is a simple
challenge-response where the elliptic curve digital signature algorithm is used
to sign challenges. To protect the privacy of the user the token uses unique
key pairs per service. To accommodate for small memory, tokens use various
techniques that make use of a special parameter called a key handle sent by the
service to the token. We identify and analyse a vulnerability in the way the
processing of key handles is implemented that allows attackers to remotely link
user accounts on multiple services. We show that for vulnerable authenticators
there is a difference between the time it takes to process a key handle for a
different service but correct authenticator, and for a different authenticator
but correct service. This difference can be used to perform a timing attack
allowing an adversary to link user's accounts across services. We present
several real world examples of adversaries that are in a position to execute
our attack and can benefit from linking accounts. We found that two of the
eight hardware authenticators we tested were vulnerable despite FIDO level 1
certification. This vulnerability cannot be easily mitigated on authenticators
because, for security reasons, they usually do not allow firmware updates. In
addition, we show that due to the way existing browsers implement the WebAuthn
standard, the attack can be executed remotely.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 03:11:12 GMT""}]","2022-05-18"
"2205.08072","Sudeep Pasricha","Ninad Hogade, Sudeep Pasricha","A Survey on Machine Learning for Geo-Distributed Cloud Data Center
  Management",,,,,"cs.DC cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Cloud workloads today are typically managed in a distributed environment and
processed across geographically distributed data centers. Cloud service
providers have been distributing data centers globally to reduce operating
costs while also improving quality of service by using intelligent workload and
resource management strategies. Such large scale and complex orchestration of
software workload and hardware resources remains a difficult problem to solve
efficiently. Researchers and practitioners have been trying to address this
problem by proposing a variety of cloud management techniques. Mathematical
optimization techniques have historically been used to address cloud management
issues. But these techniques are difficult to scale to geo-distributed problem
sizes and have limited applicability in dynamic heterogeneous system
environments, forcing cloud service providers to explore intelligent
data-driven and Machine Learning (ML) based alternatives. The characterization,
prediction, control, and optimization of complex, heterogeneous, and
ever-changing distributed cloud resources and workloads employing ML
methodologies have received much attention in recent years. In this article, we
review the state-of-the-art ML techniques for the cloud data center management
problem. We examine the challenges and the issues in current research focused
on ML for cloud management and explore strategies for addressing these issues.
We also discuss advantages and disadvantages of ML techniques presented in the
recent literature and make recommendations for future research directions.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 03:14:54 GMT""}]","2022-05-18"
"2205.08073","Jahrul Alam","Jahrul Alam","Interaction of vortex stretching with wind power fluctuations","29 pages, 10 Figures;",,"10.1063/5.0099347",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The transfer of turbulence kinetic energy from large to small scales occurs
through vortex stretching. Also, statistical properties of the subgrid-scale
energy fluxes depend on the alignment of the vorticity vector with the
principal strain axis. A heuristic analysis of the present study indicates that
vortex-stretching and the second invariant of the velocity gradient tensor
provide a scale-adaptive parameterization of the subgrid-scale stresses and the
local energy fluxes in the wakes of wind turbines. The scale-adaptivity
underlies the restricted Euler dynamics of the filtered motion that
vortex-stretching plays in the growth of the second invariant of filtered
velocity gradient and the local energy transfer. We have analyzed wind power
fluctuations in a utility-scale wind farm with $41$ actuator disks. The
numerical results show that the spectrum of the wind power fluctuations follows
a power law with a logarithmic slope of $-5/3$. Furthermore, POD analysis
indicates that the wind power fluctuations depend on the incoming turbulence
and its modulation by the wake interactions in wind farms.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 03:17:37 GMT""}]","2022-07-08"
"2205.08074","Alexander Fix","A.Fix and I.Dementjev","Discrete ambiguities in a partial-wave analysis of pseudoscalar
  photoproduction with truncation in total angular momentum",,,"10.1088/1361-6471/acc67a",,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The discrete ambiguities appearing in the complete experiment problem for
single pseudoscalar meson photoproduction within truncated partial-wave
analysis are discussed. It is shown that, in addition to the double ambiguity
known from previous works, it is always necessary to take into account another
ambiguity arising when truncation in total angular momentum is employed.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 03:19:50 GMT""},{""version"":""v2"",""created"":""Tue, 6 Sep 2022 05:07:28 GMT""}]","2023-04-26"
"2205.08075","Junli Zha","Zhixing Huang, Junli Zha, Fei Xie, Yuwei Zheng, Yuandong Zhong,
  Jinpeng Tang","Collaborative Attention Memory Network for Video Object Segmentation","Technical Report. Proposed systems attain 6th in YouTube-VOS
  challenge 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Semi-supervised video object segmentation is a fundamental yet Challenging
task in computer vision. Embedding matching based CFBI series networks have
achieved promising results by foreground-background integration approach.
Despite its superior performance, these works exhibit distinct shortcomings,
especially the false predictions caused by little appearance instances in first
frame, even they could easily be recognized by previous frame. Moreover, they
suffer from object's occlusion and error drifts. In order to overcome the
shortcomings , we propose Collaborative Attention Memory Network with an
enhanced segmentation head. We introduce a object context scheme that
explicitly enhances the object information, which aims at only gathering the
pixels that belong to the same category as a given pixel as its context.
Additionally, a segmentation head with Feature Pyramid Attention(FPA) module is
adopted to perform spatial pyramid attention structure on high-level output.
Furthermore, we propose an ensemble network to combine STM network with all
these new refined CFBI network. Finally, we evaluated our approach on the 2021
Youtube-VOS challenge where we obtain 6th place with an overall score of
83.5\%.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 03:40:11 GMT""},{""version"":""v2"",""created"":""Mon, 23 May 2022 03:16:40 GMT""}]","2022-05-24"
"2205.08076","Jaeyoun You","Jaeyoun You, Daemin Park, Joo-yeong Song, Bongwon Suh","A Labeling Task Design for Supporting Algorithmic Needs: Facilitating
  Worker Diversity and Reducing AI Bias","45 pages, 4 figures",,"10.1109/BigData55660.2022.10020415",,"cs.HC","http://creativecommons.org/licenses/by/4.0/","  Studies on supervised machine learning (ML) recommend involving workers from
various backgrounds in training dataset labeling to reduce algorithmic bias.
Moreover, sophisticated tasks for categorizing objects in images are necessary
to improve ML performance, further complicating micro-tasks. This study aims to
develop a task design incorporating the fair participation of people,
regardless of their specific backgrounds or task's difficulty. By collaborating
with 75 labelers from diverse backgrounds for 3 months, we analyzed workers'
log-data and relevant narratives to identify the task's hurdles and helpers.
The findings revealed that workers' decision-making tendencies varied depending
on their backgrounds. We found that the community that positively helps workers
and the machine's feedback perceived by workers could make people easily
engaged in works. Hence, ML's bias could be expectedly mitigated. Based on
these findings, we suggest an extended human-in-the-loop approach that connects
labelers, machines, and communities rather than isolating individual workers.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 03:41:09 GMT""}]","2023-04-07"
"2205.08077","Minghan Chen","Minghan Chen, Yiting Li, Timothy D. Brandt, Trent J. Dupuy, C\'atia V.
  Cardoso, Mark J. McCaughrean","Precise Dynamical Masses of Epsilon Indi Ba and Bb: Evidence of Slowed
  Cooling at the L/T Transition","21 pages, 14 figures, to be published in the Astronomical Journal",,"10.3847/1538-3881/ac66d2",,"astro-ph.SR astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report individual dynamical masses of $66.92 \pm 0.36 \; M_{Jup}$ and
$53.25 \pm 0.29 \; M_{Jup}$ for the binary brown dwarfs $\varepsilon$ Indi Ba
and Bb, measured from long term ($\approx 10$ yr) relative orbit monitoring and
absolute astrometry monitoring data on the VLT. Relative astrometry with NACO
fully constrains the Keplerian orbit of the binary pair, while absolute
astrometry with FORS2 measures the system's parallax and mass ratio. We find a
parallax consistent with the Hipparcos and Gaia values for $\varepsilon$ Indi
A, and a mass ratio for $\varepsilon$ Indi Ba to Bb precise to better than
$0.2\%$. $\varepsilon$ Indi Ba and Bb have spectral types T1-1.5 and T6,
respectively. With an age of $3.5^{+0.8}_{-1.0}$ Gyr from $\varepsilon$ Indi
A's activity, these brown dwarfs provide some of the most precise benchmarks
for substellar cooling models. Assuming coevality, the very different
luminosities of the two brown dwarfs and our moderate mass ratio imply a steep
mass-luminosity relationship $L \propto M^{5.37 \pm 0.08}$ that can be
explained by a slowed cooling rate in the L/T transition, as previously
observed for other L/T binaries. Finally, we present a periodogram analysis of
the near-infrared photometric data, but find no definitive evidence of periodic
signals with a coherent phase.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 04:00:13 GMT""}]","2022-06-01"
"2205.08078","Arda Sahiner","Arda Sahiner, Tolga Ergen, Batu Ozturkler, John Pauly, Morteza
  Mardani, Mert Pilanci","Unraveling Attention via Convex Duality: Analysis and Interpretations of
  Vision Transformers","38 pages, 2 figures. To appear in ICML 2022",,,,"cs.LG cs.CV math.OC","http://creativecommons.org/licenses/by/4.0/","  Vision transformers using self-attention or its proposed alternatives have
demonstrated promising results in many image related tasks. However, the
underpinning inductive bias of attention is not well understood. To address
this issue, this paper analyzes attention through the lens of convex duality.
For the non-linear dot-product self-attention, and alternative mechanisms such
as MLP-mixer and Fourier Neural Operator (FNO), we derive equivalent
finite-dimensional convex problems that are interpretable and solvable to
global optimality. The convex programs lead to {\it block nuclear-norm
regularization} that promotes low rank in the latent feature and token
dimensions. In particular, we show how self-attention networks implicitly
clusters the tokens, based on their latent similarity. We conduct experiments
for transferring a pre-trained transformer backbone for CIFAR-100
classification by fine-tuning a variety of convex attention heads. The results
indicate the merits of the bias induced by attention compared with the existing
MLP or linear heads.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 04:01:15 GMT""},{""version"":""v2"",""created"":""Fri, 20 May 2022 17:26:35 GMT""}]","2022-05-23"
"2205.08079","Hidemasa Ishii","Hidemasa Ishii, Nariaki Nishino","Asymptotically stable matchings and evolutionary dynamics of preference
  revelation games in marriage problems",,,,,"econ.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The literature on centralized matching markets often assumes that a true
preference of each player is known to herself and fixed, but empirical evidence
casts doubt on its plausibility. To circumvent the problem, we consider
evolutionary dynamics of preference revelation games in marriage problems. We
formulate the asymptotic stability of a matching, indicating the dynamical
robustness against sufficiently small changes in players' preference reporting
strategies, and show that asymptotically stable matchings are stable when they
exist. The simulation results of replicator dynamics are presented to
demonstrate the asymptotic stability. We contribute a practical insight for
market designers that a stable matching may be realized by introducing a
learning period in which participants find appropriate reporting strategies
through trial and error. We also open doors to a novel area of research by
demonstrating ways to employ evolutionary game theory in studies on centralized
markets.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 04:06:08 GMT""}]","2022-05-18"
"2205.08080","Chan-Ho Kim","Chan-Ho Kim, Matteo Longo","An explicit comparison of anticyclotomic $p$-adic $L$-functions for Hida
  families","This version may be slightly different from the final version which
  will appear in IJNT",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  The aim of this note is to compare several anticyclotomic $p$-adic
$L$-functions for modular forms and $p$-adic families of ordinary modular
forms, which have been defined and studied from different perspectives by
Skinner-Urban, Hida, Perin-Riou, Bertolini-Darmon, Vatsal, Chida-Hsieh,
Longo-Vigni, Castella-Longo and Castella-Kim-Longo. The main result of this
paper is a comparison between the central critical twist of the two-variable
anticyclotomic $p$-adic $L$-function obtained as specialisation of the
three-variable $p$-adic $L$-function of Skinner-Urban and the two-variable
$p$-adic $L$-function introduced by one of the authors on collaboration with
Vigni by means of $p$-adic families of Gross points.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 04:06:36 GMT""},{""version"":""v2"",""created"":""Mon, 28 Nov 2022 08:38:51 GMT""},{""version"":""v3"",""created"":""Fri, 14 Apr 2023 03:38:16 GMT""}]","2023-04-17"
"2205.08081","Chan-Ho Kim","Chan-Ho Kim, Matteo Longo","Anticyclotomic main conjecture and the non-triviality of Rankin-Selberg
  $L$-values in Hida families","Title changed. This version may be slightly different from the final
  version which will appear in JNT",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  The aim of this paper is to prove the two-variable anticyclotomic Iwasawa
main conjecture for Hida families and a definite version of the horizontal
non-vanishing conjecture, which are formulated in Longo-Vigni. Our approach is
based on the two-variable anticyclotomic control theorem for Selmer groups for
Hida families and the relation between the two-variable anticyclotomic
$L$-function for Hida families built out of $p$-adic families of Gross points
on definite Shimura curves studied in Castella-Longo and Castella-Kim-Longo and
the self-dual twist of the specialisation to the anticyclotomic line of the
three-variable $p$-adic $L$-function of Skinner-Urban.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 04:11:13 GMT""},{""version"":""v2"",""created"":""Fri, 14 Apr 2023 03:36:44 GMT""}]","2023-04-17"
"2205.08082","Satoshi Takashima","Satoshi Takashima, Hirokazu Odaka, Hiroki Yoneda, Yuto Ichinohe, Aya
  Bamba, Tsuguo Aramaki, Yoshiyuki Inoue","Event reconstruction of Compton telescopes using a multi-task neural
  network","26 pages, 13 figures, 3 tables, accepted for publication in NIM A",,"10.1016/j.nima.2022.166897","RIKEN-iTHEMS-Report-22","astro-ph.IM hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have developed a neural network model to perform event reconstruction of
Compton telescopes. This model reconstructs events that consist of three or
more interactions in a detector. It is essential for Compton telescopes to
determine the time order of the gamma-ray interactions and whether the incident
photon deposits all energy in a detector or it escapes from the detector. Our
model simultaneously predicts these two essential factors using a multi-task
neural network with three hidden layers of fully connected nodes. For
verification, we have conducted numerical experiments using Monte Carlo
simulation, assuming a large-area Compton telescope using liquid argon to
measure gamma rays with energies up to $3.0\,\mathrm{MeV}$. The reconstruction
model shows excellent performance of event reconstruction for multiple
scattering events that consist of up to eight hits. The accuracies of hit order
prediction are around $60\%$ while those of escape flags are higher than $70\%$
for up to eight-hit events of $4\pi$ isotropic photons. Compared with two other
algorithms, a classical model and a physics-based probabilistic one, the
present neural network method shows high performance in estimation accuracy
particularly when the number of scattering is small, 3 or 4. Since simulation
data easily optimize the network model, the model can be flexibly applied to a
wide variety of Compton telescopes.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 04:11:21 GMT""}]","2022-06-22"
"2205.08083","Zifan Chen","Hexin Dong, Zifan Chen, Mingze Yuan, Yutong Xie, Jie Zhao, Fei Yu, Bin
  Dong, Li Zhang","Region-Aware Metric Learning for Open World Semantic Segmentation via
  Meta-Channel Aggregation","Accepted at IJCAI 2022",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As one of the most challenging and practical segmentation tasks, open-world
semantic segmentation requires the model to segment the anomaly regions in the
images and incrementally learn to segment out-of-distribution (OOD) objects,
especially under a few-shot condition. The current state-of-the-art (SOTA)
method, Deep Metric Learning Network (DMLNet), relies on pixel-level metric
learning, with which the identification of similar regions having different
semantics is difficult. Therefore, we propose a method called region-aware
metric learning (RAML), which first separates the regions of the images and
generates region-aware features for further metric learning. RAML improves the
integrity of the segmented anomaly regions. Moreover, we propose a novel
meta-channel aggregation (MCA) module to further separate anomaly regions,
forming high-quality sub-region candidates and thereby improving the model
performance for OOD objects. To evaluate the proposed RAML, we have conducted
extensive experiments and ablation studies on Lost And Found and Road Anomaly
datasets for anomaly segmentation and the CityScapes dataset for incremental
few-shot learning. The results show that the proposed RAML achieves SOTA
performance in both stages of open world segmentation. Our code and appendix
are available at https://github.com/czifan/RAML.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 04:12:47 GMT""}]","2022-05-18"
"2205.08084","Zeyu Cui","Zeyu Cui, Jianxin Ma, Chang Zhou, Jingren Zhou, Hongxia Yang","M6-Rec: Generative Pretrained Language Models are Open-Ended Recommender
  Systems","10 pages, 8 figures, proudly rejected by KDD 2022",,,,"cs.IR","http://creativecommons.org/publicdomain/zero/1.0/","  Industrial recommender systems have been growing increasingly complex, may
involve \emph{diverse domains} such as e-commerce products and user-generated
contents, and can comprise \emph{a myriad of tasks} such as retrieval, ranking,
explanation generation, and even AI-assisted content production. The mainstream
approach so far is to develop individual algorithms for each domain and each
task. In this paper, we explore the possibility of developing a unified
foundation model to support \emph{open-ended domains and tasks} in an
industrial recommender system, which may reduce the demand on downstream
settings' data and can minimize the carbon footprint by avoiding training a
separate model from scratch for every task. Deriving a unified foundation is
challenging due to (i) the potentially unlimited set of downstream domains and
tasks, and (ii) the real-world systems' emphasis on computational efficiency.
We thus build our foundation upon M6, an existing large-scale industrial
pretrained language model similar to GPT-3 and T5, and leverage M6's pretrained
ability for sample-efficient downstream adaptation, by representing user
behavior data as plain texts and converting the tasks to either language
understanding or generation. To deal with a tight hardware budget, we propose
an improved version of prompt tuning that outperforms fine-tuning with
negligible 1\% task-specific parameters, and employ techniques such as late
interaction, early exiting, parameter sharing, and pruning to further reduce
the inference time and the model size. We demonstrate the foundation model's
versatility on a wide range of tasks such as retrieval, ranking, zero-shot
recommendation, explanation generation, personalized content creation, and
conversational recommendation, and manage to deploy it on both cloud servers
and mobile devices.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 04:13:42 GMT""},{""version"":""v2"",""created"":""Thu, 19 May 2022 06:50:31 GMT""}]","2022-05-20"
"2205.08085","Md Sarowar Morshed","Md Sarowar Morshed","Penalty & Augmented Kaczmarz Methods For Linear Systems & Linear
  Feasibility Problems",,,,,"math.OC cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we shed light on the so-called Kaczmarz method for solving
Linear System (LS) and Linear Feasibility (LF) problems from a optimization
point of view. We introduce well-known optimization approaches such as
Lagrangian penalty and Augmented Lagrangian in the Randomized Kaczmarz (RK)
method. In doing so, we propose two variants of the RK method namely the
Randomized Penalty Kacmarz (RPK) method and Randomized Augmented Kacmarz (RAK)
method. We carry out convergence analysis of the proposed methods and obtain
linear convergence results.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 04:14:42 GMT""},{""version"":""v2"",""created"":""Wed, 18 May 2022 15:01:30 GMT""},{""version"":""v3"",""created"":""Fri, 12 Aug 2022 07:22:40 GMT""}]","2022-08-15"
"2205.08086","Huang Zonghao Mr.","Huang Zonghao, Quinn Wu, David Howard, Cynthia Sung","EvoRobogami: Co-designing with Humans in Evolutionary Robotics
  Experiments","To be published in GECCO 2022",,"10.1145/3512290.3528867",,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  We study the effects of injecting human-generated designs into the initial
population of an evolutionary robotics experiment, where subsequent population
of robots are optimised via a Genetic Algorithm and MAP-Elites. First, human
participants interact via a graphical front-end to explore a
directly-parameterised legged robot design space and attempt to produce robots
via a combination of intuition and trial-and-error that perform well in a range
of environments. Environments are generated whose corresponding
high-performance robot designs range from intuitive to complex and hard to
grasp. Once the human designs have been collected, their impact on the
evolutionary process is assessed by replacing a varying number of designs in
the initial population with human designs and subsequently running the
evolutionary algorithm. Our results suggest that a balance of random and
hand-designed initial solutions provides the best performance for the problems
considered, and that human designs are most valuable when the problem is
intuitive. The influence of human design in an evolutionary algorithm is a
highly understudied area, and the insights in this paper may be valuable to the
area of AI-based design more generally.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 04:18:20 GMT""}]","2022-05-18"
"2205.08087","Ajoy Das","Ajoy Das, Gias Uddin, Guenther Ruhe","An Empirical Study of Blockchain Repositories in GitHub","The International Conference on Evaluation and Assessment in Software
  Engineering 2022 (EASE 2022)",,"10.1145/3530019.3530041",,"cs.CR cs.SE","http://creativecommons.org/licenses/by/4.0/","  Blockchain is a distributed ledger technique that guarantees the traceability
of transactions. Blockchain is adopted in multiple domains like finance (e.g.,
cryptocurrency), healthcare, security, and supply chain. In the open-source
software (OSS) portal GitHub, we observe a growing adoption of Blockchain-based
solutions. Given the rapid emergence of Blockchain-based solutions in our daily
life and the evolving cryptocurrency market, it is important to know the status
quo, how developers generally interact in those repos, and how much freedom
they have in applying code changes. We report an empirical study of 3,664
Blockchain software repositories from GitHub. We divide the Blockchain
repositories into two categories: Tool (e.g., SDKs) and Applications (e.g.,
service/solutions developed using SDKs). The Application category is further
divided into two sub-categories: Crypto and Non-Crypto applications. In all
Blockchain repository categories, the contribution interactions on commits are
the most common interaction type. We found that more organizations contributing
to the Blockchain repos than individual users. The median numbers of internal
and external users in tools are higher than the application repos. We observed
a higher degree of collaboration (e.g., for maintenance efforts) among users in
Blockchain tools than those in the application repos. Among the artifacts,
issues have a greater number of interactions than commits and pull requests.
Related to autonomy we found that less than half of total project contributions
are autonomous. Our findings offer implications to Blockchain stakeholders,
like developers to stay aware of OSS practices around Blockchain software.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 04:21:06 GMT""}]","2022-05-18"
"2205.08088","Dan Kondo","Dan Kondo, Robert McGehee, Tom Melia and Hitoshi Murayama","Linear Sigma Dark Matter","30 pages, 13 figures; v2: minor revisions to match published version","JHEP09(2022)041","10.1007/JHEP09(2022)041",,"hep-ph astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  We present a model of self-interacting dark matter based on QCD-like theories
and inspired by the proximity of $a_0(980\pm 20)$ to the $K\bar{K}(990)$
threshold. Dark matter is comprised of dark pions which self-scatter via the
$\sigma$ resonance close to the $\pi\pi$ threshold. While the linear sigma
model serves as a qualitative guide, a fully unitary description of the
scattering in the strongly coupled regime is given by effective range theory.
The introduction of a kinetically mixed dark photon allows the dark pion to
either freeze-out or -in. We study the viable parameter space which explains
the observed relic abundance while evading all current constraints. Searches
for dark matter self interactions at different scales, (in)direct detection
signals, and (in)visibly-decaying dark photons will test this model in the near
future.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 04:31:29 GMT""},{""version"":""v2"",""created"":""Sun, 11 Sep 2022 05:29:03 GMT""}]","2022-09-13"
"2205.08089","Xianke Lin","Sabir Hossain, Xianke Lin","Efficient Stereo Depth Estimation for Pseudo LiDAR: A Self-Supervised
  Approach Based on Multi-Input ResNet Encoder","9 pages, 5 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Perception and localization are essential for autonomous delivery vehicles,
mostly estimated from 3D LiDAR sensors due to their precise distance
measurement capability. This paper presents a strategy to obtain the real-time
pseudo point cloud instead of the laser sensor from the image sensor. We
propose an approach to use different depth estimators to obtain pseudo point
clouds like LiDAR to obtain better performance. Moreover, the training and
validating strategy of the depth estimator has adopted stereo imagery data to
estimate more accurate depth estimation as well as point cloud results. Our
approach to generating depth maps outperforms on KITTI benchmark while yielding
point clouds significantly faster than other approaches.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 04:42:13 GMT""}]","2022-05-18"
"2205.08090","Ziwei Wang","Ziwei Wang, Dingran Yuan, Yonhon Ng and Robert Mahony","A Linear Comb Filter for Event Flicker Removal","10 pages, 7 figures, published in IEEE International Conference on
  Robotics and Automation (ICRA), 2022",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Event cameras are bio-inspired sensors that capture per-pixel asynchronous
intensity change rather than the synchronous absolute intensity frames captured
by a classical camera sensor. Such cameras are ideal for robotics applications
since they have high temporal resolution, high dynamic range and low latency.
However, due to their high temporal resolution, event cameras are particularly
sensitive to flicker such as from fluorescent or LED lights. During every cycle
from bright to dark, pixels that image a flickering light source generate many
events that provide little or no useful information for a robot, swamping the
useful data in the scene. In this paper, we propose a novel linear filter to
preprocess event data to remove unwanted flicker events from an event stream.
The proposed algorithm achieves over 4.6 times relative improvement in the
signal-to-noise ratio when compared to the raw event stream due to the
effective removal of flicker from fluorescent lighting. Thus, it is ideally
suited to robotics applications that operate in indoor settings or scenes
illuminated by flickering light sources.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 04:47:26 GMT""}]","2022-05-18"
"2205.08091","Somnath Roy","Somnath Roy, Debapriya Das and Dhruba Banerjee","Hopf Bifurcation in vibrational resonance through modulation of fast
  frequency","6 pages, 6 figures",,,,"nlin.CD math.DS physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this Letter we explore the possibility of a supercritical Hopf bifurcation
in a typical parametric nonlinear oscillator which has been excited by two
frequencies, one slow and the other fast, through the variation of the
frequency of the rapidly oscillating driving force. Studies of nonlinear
responses and bifurcations of such driven nonlinear systems are usually done by
treating the strength of the fast drive as the control parameter. Here we show
that, beyond its role in allowing one to study the dynamics with the slow and
fast components nicely separated, the fast frequency can also be used as an
independent control parameter for studying Hopf bifurcation.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 05:00:31 GMT""}]","2022-05-18"
"2205.08092","Amitesh Omar","Amitesh Omar (Aryabhatta Research Institute of observational sciences,
  India)","Yet another Odd Radio Circle?","5 pages, 1 figure, Accepted in RNAAS",,"10.3847/2515-5172/ac7044",,"astro-ph.HE astro-ph.CO astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  The Odd Radio Circles are newly identified diffuse radio sources at ~1 GHz
frequency, with edge-brightened nearly circular morphology, which is remarkably
similar to supernova remnants although a physical association with previous
population of Galactic supernova remnants is challenging due to detections of
the Odd Radio Circles at high Galactic latitudes. Here, a serendipitous
identification of a new source in a LOFAR 144 MHz image with similar morphology
as that of Odd Radio Circles is reported. This is the first reported
identification of an Odd Radio Circle at a very low frequency and with the
LOFAR.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 05:06:23 GMT""}]","2022-05-20"
"2205.08093","Yi-Jun Chang","Yi-Jun Chang and Hsin-Hao Su","Narrowing the LOCAL$\unicode{x2013}$CONGEST Gaps in Sparse Networks via
  Expander Decompositions",,,,,"cs.DS cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many combinatorial optimization problems can be approximated within $(1 \pm
\epsilon)$ factors in $\text{poly}(\log n, 1/\epsilon)$ rounds in the LOCAL
model via network decompositions [Ghaffari, Kuhn, and Maus, STOC 2018]. These
approaches require sending messages of unlimited size, so they do not extend to
the CONGEST model, which restricts the message size to be $O(\log n)$ bits.
  In this paper, we develop a generic framework for obtaining $\text{poly}(\log
n, 1/\epsilon)$-round $(1\pm \epsilon)$-approximation algorithms for many
combinatorial optimization problems, including maximum weighted matching,
maximum independent set, and correlation clustering, in graphs excluding a
fixed minor in the CONGEST model. This class of graphs covers many sparse
network classes that have been studied in the literature, including planar
graphs, bounded-genus graphs, and bounded-treewidth graphs.
  Furthermore, we show that our framework can be applied to give an efficient
distributed property testing algorithm for an arbitrary minor-closed graph
property that is closed under taking disjoint union, significantly generalizing
the previous distributed property testing algorithm for planarity in [Levi,
Medina, and Ron, PODC 2018 & Distributed Computing 2021].
  Our framework uses distributed expander decomposition algorithms [Chang and
Saranurak, FOCS 2020] to decompose the graph into clusters of high conductance.
We show that any graph excluding a fixed minor admits small edge separators.
Using this result, we show the existence of a high-degree vertex in each
cluster in an expander decomposition, which allows the entire graph topology of
the cluster to be routed to a vertex. Similar to the use of network
decompositions in the LOCAL model, the vertex will be able to perform any local
computation on the subgraph induced by the cluster and broadcast the result
over the cluster.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 05:06:24 GMT""}]","2022-05-18"
"2205.08094","Edouard Belval","Thomas Delteil, Edouard Belval, Lei Chen, Luis Goncalves and Vijay
  Mahadevan","MATrIX -- Modality-Aware Transformer for Information eXtraction",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  We present MATrIX - a Modality-Aware Transformer for Information eXtraction
in the Visual Document Understanding (VDU) domain. VDU covers information
extraction from visually rich documents such as forms, invoices, receipts,
tables, graphs, presentations, or advertisements. In these, text semantics and
visual information supplement each other to provide a global understanding of
the document. MATrIX is pre-trained in an unsupervised way with specifically
designed tasks that require the use of multi-modal information (spatial,
visual, or textual). We consider the spatial and text modalities all at once in
a single token set. To make the attention more flexible, we use a learned
modality-aware relative bias in the attention mechanism to modulate the
attention between the tokens of different modalities. We evaluate MATrIX on 3
different datasets each with strong baselines.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 05:06:59 GMT""}]","2022-05-18"
"2205.08095","Ying Sheng","Ying Sheng, Andres N\""otzli, Andrew Reynolds, Yoni Zohar, David Dill,
  Wolfgang Grieskamp, Junkil Park, Shaz Qadeer, Clark Barrett, and Cesare
  Tinelli","Reasoning About Vectors using an SMT Theory of Sequences","IJCAR 2022",,,,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dynamic arrays, also referred to as vectors, are fundamental data structures
used in many programs. Modeling their semantics efficiently is crucial when
reasoning about such programs. The theory of arrays is widely supported but is
not ideal, because the number of elements is fixed (determined by its index
sort) and cannot be adjusted, which is a problem, given that the length of
vectors often plays an important role when reasoning about vector programs. In
this paper, we propose reasoning about vectors using a theory of sequences. We
introduce the theory, propose a basic calculus adapted from one for the theory
of strings, and extend it to efficiently handle common vector operations. We
prove that our calculus is sound and show how to construct a model when it
terminates with a saturated configuration. Finally, we describe an
implementation of the calculus in cvc5 and demonstrate its efficacy by
evaluating it on verification conditions for smart contracts and benchmarks
derived from existing array benchmarks.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 05:12:40 GMT""},{""version"":""v2"",""created"":""Sat, 21 May 2022 08:25:25 GMT""}]","2022-05-24"
"2205.08096","Murari Mandal","Vikram S Chundawat, Ayush K Tarun, Murari Mandal, Mohan Kankanhalli","Can Bad Teaching Induce Forgetting? Unlearning in Deep Networks using an
  Incompetent Teacher","Accepted in AAAI 2023",,,,"cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Machine unlearning has become an important area of research due to an
increasing need for machine learning (ML) applications to comply with the
emerging data privacy regulations. It facilitates the provision for removal of
certain set or class of data from an already trained ML model without requiring
retraining from scratch. Recently, several efforts have been put in to make
unlearning to be effective and efficient. We propose a novel machine unlearning
method by exploring the utility of competent and incompetent teachers in a
student-teacher framework to induce forgetfulness. The knowledge from the
competent and incompetent teachers is selectively transferred to the student to
obtain a model that doesn't contain any information about the forget data. We
experimentally show that this method generalizes well, is fast and effective.
Furthermore, we introduce the zero retrain forgetting (ZRF) metric to evaluate
any unlearning method. Unlike the existing unlearning metrics, the ZRF score
does not depend on the availability of the expensive retrained model. This
makes it useful for analysis of the unlearned model after deployment as well.
We present results of experiments conducted for random subset forgetting and
class forgetting on various deep networks and across different application
domains.~Source code is at:
https://github.com/vikram2000b/bad-teaching-unlearning
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 05:13:17 GMT""},{""version"":""v2"",""created"":""Wed, 31 May 2023 11:53:38 GMT""}]","2023-06-01"
"2205.08097","Linh Truong","Linh Truong","A note on knot Floer thickness and the dealternating number","5 pages, 1 figure",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note, we give a short proof that knot Floer thickness is a lower
bound on the dealternating number of a knot. The result is originally due to
work of Abe and Kishimoto, Lowrance, and Turaev. Our proof is a modification of
the Stipsicz-Szabo approach using Kauffman states to show that thickness bounds
the minimal number of bad domains in a knot diagram.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 05:20:20 GMT""}]","2022-05-18"
"2205.08098","Xin Tong Thomson","Yi Chen, Jing Dong, Xin T. Tong","Can We Do Better Than Random Start? The Power of Data Outsourcing","22 pages, 5 figures",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many organizations have access to abundant data but lack the computational
power to process the data. While they can outsource the computational task to
other facilities, there are various constraints on the amount of data that can
be shared. It is natural to ask what can data outsourcing accomplish under such
constraints. We address this question from a machine learning perspective. When
training a model with optimization algorithms, the quality of the results often
relies heavily on the points where the algorithms are initialized. Random start
is one of the most popular methods to tackle this issue, but it can be
computationally expensive and not feasible for organizations lacking computing
resources. Based on three different scenarios, we propose simulation-based
algorithms that can utilize a small amount of outsourced data to find good
initial points accordingly. Under suitable regularity conditions, we provide
theoretical guarantees showing the algorithms can find good initial points with
high probability. We also conduct numerical experiments to demonstrate that our
algorithms perform significantly better than the random start approach.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 05:34:36 GMT""}]","2022-05-18"
"2205.08099","Paul Wimmer","Paul Wimmer, Jens Mehnert, Alexandru Paul Condurache","Dimensionality Reduced Training by Pruning and Freezing Parts of a Deep
  Neural Network, a Survey","This preprint has not undergone peer review or any post-submission
  improvements or corrections. The Version of Record of this article is
  published in Artificial Intelligence Review (2023), and is available online
  at https://doi.org/10.1007/s10462-023-10489-1","Artif Intell Rev 2023","10.1007/s10462-023-10489-1",,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  State-of-the-art deep learning models have a parameter count that reaches
into the billions. Training, storing and transferring such models is energy and
time consuming, thus costly. A big part of these costs is caused by training
the network. Model compression lowers storage and transfer costs, and can
further make training more efficient by decreasing the number of computations
in the forward and/or backward pass. Thus, compressing networks also at
training time while maintaining a high performance is an important research
topic. This work is a survey on methods which reduce the number of trained
weights in deep learning models throughout the training. Most of the introduced
methods set network parameters to zero which is called pruning. The presented
pruning approaches are categorized into pruning at initialization, lottery
tickets and dynamic sparse training. Moreover, we discuss methods that freeze
parts of a network at its random initialization. By freezing weights, the
number of trainable parameters is shrunken which reduces gradient computations
and the dimensionality of the model's optimization space. In this survey we
first propose dimensionality reduced training as an underlying mathematical
model that covers pruning and freezing during training. Afterwards, we present
and discuss different dimensionality reduced training methods.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 05:37:08 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 05:59:41 GMT""}]","2023-05-26"
"2205.08100","Andreas Malmendier","Adrian Clingher, Thomas Hill, Andreas Malmendier","The duality between F-theory and the Heterotic String in $D=8$ with two
  Wilson lines","22 pages. arXiv admin note: substantial text overlap with
  arXiv:1908.09578, arXiv:1806.07460","Lett. Math. Phys. 110 (2020), no. 11, 3081-3104","10.1007/s11005-020-01323-8",,"math.AG hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct non-geometric string compactifications by using the F-theory
dual of the heterotic string compactified on a two-torus with two Wilson line
parameters, together with a close connection between modular forms and the
equations for certain K3 surfaces of Picard rank $16$. We construct explicit
Weierstrass models for all inequivalent Jacobian elliptic fibrations supported
on this family of K3 surfaces and express their parameters in terms of modular
forms generalizing Siegel modular forms. In this way, we find a complete list
of all dual non-geometric compactifications obtained by the partial higgsing of
the heterotic string gauge algebra using two Wilson line parameters.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 05:38:01 GMT""}]","2022-05-18"
"2205.08101","Shuo Kong","Shuo Kong (1) ((1) University of Arizona)","Dense Gas Formation via Collision-induced Magnetic Reconnection in a
  Disk Galaxy with a BiSymmetric Spiral Magnetic Field","21 pages, 11 figures, 1 table, accepted by ApJ",,"10.3847/1538-4357/ac70cd",,"astro-ph.GA physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  Recently, a collision-induced magnetic reconnection (CMR) mechanism was
proposed to explain a dense filament formation in the Orion A giant molecular
cloud. A natural question is that whether CMR works elsewhere in the Galaxy. As
an initial attempt to answer the question, this paper investigates the
triggering of CMR and the production of dense gas in a flat-rotating disk with
a modified BiSymmetric Spiral (BSS) magnetic field. Cloud-cloud collisions at
field reversals in the disk are modeled with the Athena++ code. Under the
condition that is representative of the warm neutral medium, the cloud-cloud
collision successfully triggers CMR at different disk radii. However, dense gas
formation is hindered by the dominating thermal pressure, unless a moderately
stronger initial field $\gtrsim5\mu$G is present. The strong-field model,
having a larger Lundquist number $S_L$ and lower plasma $\beta$, activates the
plasmoid instability in the collision midplane, which is otherwise suppressed
by the disk rotation. We speculate that CMR can be common if more clouds
collide along field reversals. However, to witness the CMR process in numerical
simulations, we need to significantly resolve the collision midplane with a
spatial dynamic range $\gtrsim10^6$. If Milky Way spiral arms indeed coincide
with field reversals in BSS, it is possible that CMR creates or maintains dense
gas in the arms. High-resolution, high-sensitivity Zeeman/Faraday-Rotation
observations are crucial for finding CMR candidates that have helical fields.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 05:39:07 GMT""}]","2022-07-20"
"2205.08102","Saugata Chatterjee","Saugata Chatterjee","Can Galileons cause violation of the second law of black hole
  thermodynamics?",,,,,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  Galileons are stable null energy condition (NEC) violating perturbations. If
these NEC violating modes are coupled to Einstein gravity, they can cause
violation of the second law of black hole thermodynamics. We demonstrate that
galileons can only be coupled to quadratic gravity since they are generated by
consistent Kaluza-Klein reduction of the Einstein-Hilbert-Gauss-Bonnet action
from 10-dimensions to 4-dimensions. As a result, the NEC violation of galileons
can no longer be the source of the violation of the second law of black hole
thermodynamics.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 05:40:58 GMT""}]","2022-05-18"
"2205.08103","Zhiyi Huang","Zhiyi Huang and Hanwen Zhang","Deterministic 3-Server on a Circle and the Limitation of Canonical
  Potentials",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The deterministic $k$-server conjecture states that there is a
$k$-competitive deterministic algorithm for the $k$-server problem for any
metric space. We show that the work function algorithm is $3$-competitive for
the $3$-server problem on circle metrics, a case left open by Coester and
Koutsoupias (2021). Our analysis follows the existing framework but introduces
a new potential function which may be viewed as a relaxation of the counterpart
by Coester and Koutsoupias (2021). We further notice that the new potential
function and many existing ones can be rewritten in a canonical form. Through a
computer-aided verification, however, we find that no such canonical potential
function can resolve the deterministic $3$-server conjecture for general metric
spaces under the current analysis framework.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 05:49:46 GMT""}]","2022-05-18"
"2205.08104","Chiwei Yan","Fupeng Sun, Yanwei Sun, Chiwei Yan, Li Jin","Sequential Elimination Contests with All-Pay Auctions",,,,,"cs.GT econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a sequential elimination contest where players are filtered prior to
the round of competing for prizes. This is motivated by the practice that many
crowdsourcing contests have very limited resources of reviewers and want to
improve the overall quality of the submissions. We first consider a setting
where the designer knows the ranking of the abilities (types) of all $n_1$
registered players, and admit the top $n_2$ players with $2\leq n_2 \leq n_1$
into the contest. The players admitted into the contest update their beliefs
about their opponents based on the signal that their abilities are among the
top $n_2$. We find that their posterior beliefs, even with IID priors, are
correlated and depend on players' private abilities.
  We explicitly characterize the symmetric and unique Bayesian equilibrium
strategy. We find that each admitted player's equilibrium effort is increasing
in $n_2$ when $n_2 \in [\lfloor{(n_1+1)/2}\rfloor+1,n_1]$, but not monotone in
general when $n_2 \in [2,\lfloor{(n_1+1)/2}\rfloor+1]$. Surprisingly, despite
this non-monotonicity, all players exert their highest efforts when $n_2=n_1$.
As a sequence, if the designer has sufficient capacity, he should admit all
players to maximize their equilibrium efforts. This result holds generally --
it is true under any ranking-based reward structure, ability distribution, and
cost function. We also discuss the situation where the designer can only admit
$c<n_1$ players. Our numerical results show that, in terms of the expected
highest or total efforts, the optimal $n_2$ is either $2$ or $c$.
  Finally, we extend our model to a two-stage setting, where players with top
first-stage efforts can proceed to the second stage competing for prizes. We
establish an intriguing negative result in this setting: there does not exist a
symmetric and monotone Perfect Bayesian equilibrium.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 05:59:52 GMT""},{""version"":""v2"",""created"":""Tue, 18 Apr 2023 01:06:54 GMT""},{""version"":""v3"",""created"":""Wed, 19 Apr 2023 17:36:29 GMT""}]","2023-04-20"
"2205.08105","Volker Mehrmann","Peter Kunkel and Volker Mehrmann","Discretization of inherent ODEs and the geometric integration of DAEs
  with symmetries",,,,,"math.NA cs.NA math.OC","http://creativecommons.org/licenses/by/4.0/","  Discretization methods for differential-algebraic equations (DAEs) are
considered that are based on the integration of an associated inherent ordinary
differential equation (ODE). This allows to make use of any discretization
scheme suitable for the numerical integration of ODEs. For DAEs with symmetries
it is shown that the inherent ODE can be constructed in such a way that it
inherits the symmetry properties of the given DAE and geometric properties of
its flow. This in particular allows the use of geometric integration schemes
with a numerical flow that has analogous geometric properties.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:01:20 GMT""}]","2022-05-18"
"2205.08106","Yun-Chien Cheng","Chia-Hung Yang, Yun-Chien Cheng, Chin Kuo","Computerized Tomography Pulmonary Angiography Image Simulation using
  Cycle Generative Adversarial Network from Chest CT imaging in Pulmonary
  Embolism Patients","23 pages, 14 figures, 6 tables",,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The purpose of this research is to develop a system that generates simulated
computed tomography pulmonary angiography (CTPA) images clinically for
pulmonary embolism diagnoses. Nowadays, CTPA images are the gold standard
computerized detection method to determine and identify the symptoms of
pulmonary embolism (PE), although performing CTPA is harmful for patients and
also expensive. Therefore, we aim to detect possible PE patients through CT
images. The system will simulate CTPA images with deep learning models for the
identification of PE patients' symptoms, providing physicians with another
reference for determining PE patients. In this study, the simulated CTPA image
generation system uses a generative antagonistic network to enhance the
features of pulmonary vessels in the CT images to strengthen the reference
value of the images and provide a basis for hospitals to judge PE patients. We
used the CT images of 22 patients from National Cheng Kung University Hospital
and the corresponding CTPA images as the training data for the task of
simulating CTPA images and generated them using two sets of generative
countermeasure networks. This study is expected to propose a new approach to
the clinical diagnosis of pulmonary embolism, in which a deep learning network
is used to assist in the complex screening process and to review the generated
simulated CTPA images, allowing physicians to assess whether a patient needs to
undergo detailed testing for CTPA, improving the speed of detection of
pulmonary embolism and significantly reducing the number of undetected
patients.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:02:33 GMT""}]","2022-05-18"
"2205.08107","Matti Vuorinen","Dimitrios Betsakos, Alexander Solynin and Matti Vuorinen","Conformal capacity of hedgehogs","44 pages, 6 figures",,,,"math.CV","http://creativecommons.org/licenses/by/4.0/","  In this paper we discuss problems concerning the conformal condenser capacity
of ""hedgehogs"", which are compact sets $E$ in the unit disk
$\mathbb{D}=\{z:\,|z|<1\}$ consisting of a central body $E_0$ that is typically
a smaller disk $\overline{\mathbb{D}}_r=\{z:\,|z|\le r\}$, $0<r<1$, and several
spikes $E_k$ that are compact sets lying on radial intervals
$I(\alpha_k)=\{te^{i\alpha_k}:\,0\le t<1\}$. The main questions we are
concerned with are the following: (1) How does the conformal capacity ${\rm
cap}(E)$ of $E=\cup_{k=0}^n E_k$ behave when the spikes $E_k$, $k=1,\ldots,n$,
move along the intervals $I(\alpha_k)$ toward the central body if their
hyperbolic lengths are preserved during the motion? (2) How does the capacity
${\rm cap}(E)$ depend on the distribution of angles between the spikes $E_k$?
We prove several results related to these questions and discuss methods of
applying symmetrization type transformations to study the capacity of
hedgehogs. Several open problems, including problems on the capacity of
hedgehogs in the three-dimensional hyperbolic space, also will be suggested.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:06:55 GMT""},{""version"":""v2"",""created"":""Fri, 9 Sep 2022 08:34:56 GMT""}]","2022-09-12"
"2205.08108","Zhicheng Yang","Zhicheng Yang, Jinghui Qin, Jiaqi Chen, and Xiaodan Liang","Unbiased Math Word Problems Benchmark for Mitigating Solving Bias",,"Findings of NAACL 2022","10.18653/v1/2022.findings-naacl.104",,"cs.AI cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this paper, we revisit the solving bias when evaluating models on current
Math Word Problem (MWP) benchmarks. However, current solvers exist solving bias
which consists of data bias and learning bias due to biased dataset and
improper training strategy. Our experiments verify MWP solvers are easy to be
biased by the biased training datasets which do not cover diverse questions for
each problem narrative of all MWPs, thus a solver can only learn shallow
heuristics rather than deep semantics for understanding problems. Besides, an
MWP can be naturally solved by multiple equivalent equations while current
datasets take only one of the equivalent equations as ground truth, forcing the
model to match the labeled ground truth and ignoring other equivalent
equations. Here, we first introduce a novel MWP dataset named UnbiasedMWP which
is constructed by varying the grounded expressions in our collected data and
annotating them with corresponding multiple new questions manually. Then, to
further mitigate learning bias, we propose a Dynamic Target Selection (DTS)
Strategy to dynamically select more suitable target expressions according to
the longest prefix match between the current model output and candidate
equivalent equations which are obtained by applying commutative law during
training. The results show that our UnbiasedMWP has significantly fewer biases
than its original data and other datasets, posing a promising benchmark for
fairly evaluating the solvers' reasoning skills rather than matching nearest
neighbors. And the solvers trained with our DTS achieve higher accuracies on
multiple MWP benchmarks. The source code is available at
https://github.com/yangzhch6/UnbiasedMWP.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:07:04 GMT""}]","2022-10-10"
"2205.08109","Hardik Patel","Soham Vyas, Yuvraj Goyal, Neel Bhatt, Sanskar Bhuwania, Hardik Patel,
  Shakti Mishra, Brijesh Tripathi","Forecasting Solar Power Generation on the basis of Predictive and
  Corrective Maintenance Activities",,,,,"cs.LG cs.AI eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Solar energy forecasting has seen tremendous growth in the last decade using
historical time series collected from a weather station, such as weather
variables wind speed and direction, solar radiance, and temperature. It helps
in the overall management of solar power plants. However, the solar power plant
regularly requires preventive and corrective maintenance activities that
further impact energy production. This paper presents a novel work for
forecasting solar power energy production based on maintenance activities,
problems observed at a power plant, and weather data. The results accomplished
on the datasets obtained from the 1MW solar power plant of PDEU (our
university) that has generated data set with 13 columns as daily entries from
2012 to 2020. There are 12 structured columns and one unstructured column with
manual text entries about different maintenance activities, problems observed,
and weather conditions daily. The unstructured column is used to create a new
feature column vector using Hash Map, flag words, and stop words. The final
dataset comprises five important feature vector columns based on correlation
and causality analysis.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:11:57 GMT""}]","2022-05-18"
"2205.08110","Jack Engdahl","Jack N. Engdahl, Aydin Cem Keser and Oleg P. Sushkov","Micromagnets dramatically enhance effects of viscous hydrodynamic flow
  in two-dimensional electron fluid","9 pages, 8 figures","Phys. Rev. Research 4, 043175, 2022","10.1103/PhysRevResearch.4.043175",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  The hydrodynamic behavior of electron fluids in a certain range of
temperatures and densities is well established in graphene and in 2D
semiconductor heterostructures. The hydrodynamic regime is intrinsically based
on electron-electron interactions, and therefore it provides a unique
opportunity to study electron correlations. Unfortunately, in all existing
measurements, the relative contribution of hydrodynamic effects to transport is
rather small. Viscous hydrodynamic effects are masked by impurities,
interaction with phonons, uncontrolled boundaries and ballistic effects. This
essentially limits the accuracy of measurements of electron viscosity.
Fundamentally, what causes viscous friction in the electron fluid is the
property of the flow called vorticity. In this paper, we propose to use
micromagnets to increase the vorticity by orders of magnitude. Experimental
realization of this proposal will bring electron hydrodynamics to a
qualitatively new precision level, as well as opening a new way to characterize
and externally control the electron fluid.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:14:15 GMT""}]","2022-12-13"
"2205.08111","Miho Yanagisawa","Daisuke Shimamoto and Miho Yanagisawa","Common Packing Patterns for Jammed Particles of Different Power Size
  Distributions","8 pages, 5 figures",,,,"cond-mat.soft cond-mat.stat-mech","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We introduce a model for particles that are extremely polydisperse in size
compared to monodisperse and bidisperse systems. In two dimensions (2D), size
polydispersity inhibits crystallization and increases packing fraction at
jamming points. However, no packing pattern common to diverse polydisperse
particles has been reported. We focused on polydisperse particles with a power
size distribution $r^{-a}$ as a ubiquitous system that can be expected to be
scale-invariant. We experimentally and numerically constructed 2D random
packing for various polydisperse particles with different size exponents, $a$.
Analysis of the packing pattern revealed a common contact number distribution
for $a<3$ and a higher jamming point in $2<a<3$ than monodisperse systems.
These findings demonstrate that the ambiguity of the characteristic length
provides the common properties that leads to a novel classification scheme for
polydisperse particles.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:14:22 GMT""},{""version"":""v2"",""created"":""Thu, 20 Oct 2022 06:38:11 GMT""}]","2022-10-21"
"2205.08112","Arthur Charpentier","Laurence Barry and Arthur Charpentier","The Fairness of Machine Learning in Insurance: New Rags for an Old Man?",,,,,"econ.GN cs.CY q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  Since the beginning of their history, insurers have been known to use data to
classify and price risks. As such, they were confronted early on with the
problem of fairness and discrimination associated with data. This issue is
becoming increasingly important with access to more granular and behavioural
data, and is evolving to reflect current technologies and societal concerns. By
looking into earlier debates on discrimination, we show that some algorithmic
biases are a renewed version of older ones, while others show a reversal of the
previous order. Paradoxically, while the insurance practice has not deeply
changed nor are most of these biases new, the machine learning era still deeply
shakes the conception of insurance fairness.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:22:00 GMT""}]","2022-05-18"
"2205.08113","Mehdi Shafiei Aporvari","Mehdi Shaffei Aporvari, Agnese Callegari, Emine Ulku Saritas","Effect of colloidal weight at different planar interfaces","10 pages, 8 figures",,,,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  In many physical and biological systems, particles and microorganisms move in
the proximity of an interface. Understanding the dynamics of a particle
suspended close to an interface is not only important conceptually but is
crucial for practical applications ranging from the treatment of waste waters
to industrial applications of self-assemblies. In this work, we experimentally
investigate the effects of colloidal weight on its dynamics while moving in the
close proximity of a variety of liquid-solid and liquid-air interfaces. Using
an upward magnetic force, we change the effective weight of a superparamagnetic
colloid. At water-glass interfaces, we observe the expected decrease of the
diffusion coefficients with increasing effective weight. At liquid-air
interfaces, while for a pure water-air interface there is a negligible
dependency between the diffusivity and the effective weight, we find that in
semi-dilute polymer solution at the solution-air interface the diffusivity of
the particle shows similar behavior as those at liquid-solid interfaces. We
implement a Brownian dynamics simulation to support our results and show how
the interplay between hydrodynamic interactions and electrostatic interface
repulsion explains the experimental results.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:22:30 GMT""}]","2022-05-18"
"2205.08114","Wei-Min Zhang","Wei-Ming Huang and Wei-Min Zhang","Nonperturbative renormalization of quantum thermodynamics from weak to
  strong couplings","24 pages, 7 figures, a huge extension version of arXiv:2010.01828","Phys. Rev. Research 4, 023141 (2022)",,,"quant-ph cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  By solving the exact master equation of open quantum systems, we formulate
the quantum thermodynamics from weak to strong couplings. The open quantum
systems exchange matters, energies and information with their reservoirs
through quantum particles tunnelings that are described by the generalized
Fano-Anderson Hamiltonians. We find that the exact solution of the reduced
density matrix of these systems approaches a Gibbs-type state in the
steady-state limit for both the weak and strong system-reservoir coupling
strengths. When the couplings become strong, thermodynamic quantities of the
system must be renormalized. The renormalization effects are obtained
nonperturbatively after exactly traced over all reservoir states through the
coherent state path integrals. The renormalized system Hamiltonian is
characterized by the renormalized system energy levels and interactions,
corresponding to the quantum work done by the system. The renormalized
temperature is introduced to characterize the entropy production counting the
heat transfer between the system and the reservoir. We further find that only
with the renormalized system Hamiltonian and other renormalized thermodynamic
quantities, can the exact steady state of the system be expressed as the
standard Gibbs state. Consequently, the corresponding exact steady-state
particle occupations in the renormalized system energy levels obey the
Bose-Einstein and the Fermi-Dirac distributions for bosonic and fermionic
systems, respectively. Thus, the conventional statistical mechanics and
thermodynamics are thereby rigorously deduced from quantum dynamical evolution.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:25:03 GMT""}]","2022-06-07"
"2205.08115","Jiajin Li","Jiajin Li, Jianheng Tang, Lemin Kong, Huikang Liu, Jia Li, Anthony
  Man-Cho So, Jose Blanchet","Fast and Provably Convergent Algorithms for Gromov-Wasserstein in Graph
  Data",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the design and analysis of a class of efficient
algorithms for computing the Gromov-Wasserstein (GW) distance tailored to
large-scale graph learning tasks. Armed with the Luo-Tseng error bound
condition~\citep{luo1992error}, two proposed algorithms, called Bregman
Alternating Projected Gradient (BAPG) and hybrid Bregman Proximal Gradient
(hBPG) enjoy the convergence guarantees. Upon task-specific properties, our
analysis further provides novel theoretical insights to guide how to select the
best-fit method. As a result, we are able to provide comprehensive experiments
to validate the effectiveness of our methods on a host of tasks, including
graph alignment, graph partition, and shape matching. In terms of both
wall-clock time and modeling performance, the proposed methods achieve
state-of-the-art results.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:26:54 GMT""},{""version"":""v2"",""created"":""Wed, 14 Dec 2022 11:38:47 GMT""}]","2022-12-15"
"2205.08116","Raula Gaikovina Kula Dr","Ayano Ikegami, Raula Gaikovina Kula, Bodin Chinthanet, Vittunyuta
  Maeprasart, Ali Ouni, Takashi Ishio, Kenichi Matsumoto","On the Use of Refactoring in Security Vulnerability Fixes: An
  Exploratory Study on Maven Libraries","Accepted as ERA paper to EASE2022",,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Third-party library dependencies are commonplace in today's software
development. With the growing threat of security vulnerabilities, applying
security fixes in a timely manner is important to protect software systems. As
such, the community developed a list of software and hardware weakness known as
Common Weakness Enumeration (CWE) to assess vulnerabilities. Prior work has
revealed that maintenance activities such as refactoring code potentially
correlate with security-related aspects in the source code. In this work, we
explore the relationship between refactoring and security by analyzing
refactoring actions performed jointly with vulnerability fixes in practice. We
conducted a case study to analyze 143 maven libraries in which 351 known
vulnerabilities had been detected and fixed. Surprisingly, our exploratory
results show that developers incorporate refactoring operations in their fixes,
with 31.9% (112 out of 351) of the vulnerabilities paired with refactoring
actions. We envision this short paper to open up potential new directions to
motivate automated tool support, allowing developers to deliver fixes faster,
while maintaining their code.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:31:06 GMT""}]","2022-05-18"
"2205.08117","Michel Brion","Michel Brion and Stefan Schr\""oer","The inverse Galois problem for connected algebraic groups","21 pages",,,,"math.AG","http://creativecommons.org/licenses/by/4.0/","  We show that each connected group scheme of finite type over an arbitrary
ground field is isomorphic to the component of the identity inside the
automorphism group scheme of some projective, geometrically integral scheme.
The main ingredients are embeddings into smooth group schemes, equivariant
completions, blow-ups of orbit closures, Fitting ideals for K\""ahler
differentials, and Blanchard's Lemma.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:36:45 GMT""}]","2022-05-18"
"2205.08118","Ruiqi Li","Xinze Qiu, Tianli Gao, Yu Yang, Ankang Luo, Fan Shang, Ruiqi Li","Understanding urban congestion with biking traffic and routing detour
  ratio",,,,,"physics.soc-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Bike-sharing systems have been regarded as a critical component of solutions
towards the transition to greener and more sustainable transportation, with the
benefits of reducing carbon emissions, improving public health, and mitigating
congestion by replacing short-distance motorized trips. Due to better
accessibility and usage flexibility, newly emergent dockless sharing bikes have
become quite popular and are reviving the fashion of cycling in cities. Urban
congestion is simultaneously influenced by heterogeneous saptio-temporal travel
demands, topology and spatial characteristics of road networks, and the
interplay between travel modes. In this paper, by considering aforementioned
factors, we discover a robust sublinear scaling relation between the level of
congestion for vehicles and the detour ratio weighted by biking traffic, which
is intriguing given the fact that congestion and detour ratio is linearly
independent. Such a scaling relation implies a strong interplay between vehicle
traffic and cycling activities and can be applied in predictions for congestion
or aggregated to more sophisticated traffic models. In addition,
biking-traffic-weighted detour ratio can be applied to detect inefficient
routes, which would help alleviate urban congestion, make better urban
planning, and improve transportation efficiency and equity in cities.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:39:14 GMT""}]","2022-05-18"
"2205.08119","Haoran You","Haoran You, Baopu Li, Huihong Shi, Yonggan Fu, Yingyan Lin","ShiftAddNAS: Hardware-Inspired Search for More Accurate and Efficient
  Neural Networks","Accepted by ICML 2022",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Neural networks (NNs) with intensive multiplications (e.g., convolutions and
transformers) are capable yet power hungry, impeding their more extensive
deployment into resource-constrained devices. As such, multiplication-free
networks, which follow a common practice in energy-efficient hardware
implementation to parameterize NNs with more efficient operators (e.g., bitwise
shifts and additions), have gained growing attention. However,
multiplication-free networks usually under-perform their vanilla counterparts
in terms of the achieved accuracy. To this end, this work advocates hybrid NNs
that consist of both powerful yet costly multiplications and efficient yet less
powerful operators for marrying the best of both worlds, and proposes
ShiftAddNAS, which can automatically search for more accurate and more
efficient NNs. Our ShiftAddNAS highlights two enablers. Specifically, it
integrates (1) the first hybrid search space that incorporates both
multiplication-based and multiplication-free operators for facilitating the
development of both accurate and efficient hybrid NNs; and (2) a novel weight
sharing strategy that enables effective weight sharing among different
operators that follow heterogeneous distributions (e.g., Gaussian for
convolutions vs. Laplacian for add operators) and simultaneously leads to a
largely reduced supernet size and much better searched networks. Extensive
experiments and ablation studies on various models, datasets, and tasks
consistently validate the efficacy of ShiftAddNAS, e.g., achieving up to a
+7.7% higher accuracy or a +4.9 better BLEU score compared to state-of-the-art
NN, while leading to up to 93% or 69% energy and latency savings, respectively.
Codes and pretrained models are available at
https://github.com/RICE-EIC/ShiftAddNAS.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:40:13 GMT""},{""version"":""v2"",""created"":""Wed, 27 Jul 2022 07:18:29 GMT""},{""version"":""v3"",""created"":""Thu, 18 Aug 2022 22:46:35 GMT""}]","2022-08-22"
"2205.08120","Mehdi Abdi","M. Rezaei, K. Javidan, and M. Abdi","Accelerated Gaussian quantum state transfer between two remote
  mechanical resonators","12 pages, 6 figures. A substantially enhanced work based on our
  previous preprint arXiv:2003.01175","New J. Phys. (2022)","10.1088/1367-2630/ac6dfc",,"quant-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The main challenge in deterministic quantum state transfer between remote
mechanical resonators is the local decoherence and the transmission losses in
the communication channel. In the path of overcoming this limitation, here we
employ a shortcut to adiabatic passage protocol to devise a fast and reliable
evolution path between two remote mechanical modes in separate optomechanical
systems. A quantum state transfer between the two nodes is conceived by
engineering their coupling to an intermediate fiber optical channel. The
coupling pulses are operated such that the dark eigenmode of the system is
decoupled from the fiber modes and transitions to the bright modes are
compensated for by counterdiabatic drives. We show that one obtains a quantum
state transfer with high fidelity for various Gaussian states. The efficiency
is compared to that of adiabatic passage protocol in the presence of losses and
noises. Our results show that while the adiabatic passage protocol is very
sensitive to the decoherence, the shortcut to adiabaticity provides a robust
and fast quantum state transfer even for small values of the coupling strength.
The performance of both protocols are also investigated for the case of
multimode fiber through numerical and an effective single-model model which is
found by the elimination of off-resonant fiber modes. Our findings may pave the
way for using optomechanical systems in the realization of continuous-variable
Gaussian quantum state transfer.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:41:26 GMT""}]","2022-05-18"
"2205.08121","Francis Lau C.M.","Jia Zhan and Francis C.M. Lau","Design of Joint Source-Channel Codes Based on a Generic Protograph","26 pages, 15 figures, 5 tables",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, we propose using a generic protograph to design joint
source-channel codes (JSCCs). We present a generalized algorithm, called
protograph extrinsic information transfer for JSCC algorithm (PEXIT-JSCC
algorithm), for analyzing the channel threshold of the proposed JSCC. We also
propose a source generic protograph EXIT (SGP-EXIT) algorithm, which is more
appropriate than the generalized source protograph extrinsic information
transfer (GSP-EXIT) algorithm, for evaluating the source threshold of a generic
protograph. Moreover, a collaborative optimization method based on the SGP-EXIT
and PEXIT-JSCC algorithms is proposed to construct generic-protograph JSCCs
with good source and channel thresholds. Finally, we construct
generic-protograph JSCCs, analyze their decoding thresholds, and compare their
theoretical and error performance with JSCC systems based on optimized
double-protographs. Results show that our proposed codes can attain channel
thresholds within 1 dB from the Shannon limit and outperform
double-protograph-based JSCCs.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:42:13 GMT""},{""version"":""v2"",""created"":""Sat, 15 Oct 2022 14:38:21 GMT""},{""version"":""v3"",""created"":""Tue, 18 Oct 2022 08:00:59 GMT""}]","2022-10-19"
"2205.08122","Lucien Besombes","V. Tiwari, M. Morita T. Inoue, S. Ando S. Kuroda, H. Boukari, L.
  Besombes","Spin dynamics of positively charged excitons in Cr$^+$-doped quantum
  dots probed by resonant photoluminescence",,,"10.1103/PhysRevB.106.045308",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the dynamics of the spin system that consist of a positively charged
II-VI semiconductor quantum dot doped with a single Cr$^+$ ion. The resonant
photoluminescence (PL) of the positively charged exciton coupled with the
Cr$^+$ spin is used to analyze the main spin relaxation channels. The intensity
of the resonant PL is reduced by an optical pumping of the spin of the resident
hole-Cr$^+$ complex that can be seen as a nano-magnet. The spin memory can be
partially erased by a non-resonant optical excitation. This leads to an
increase of the resonant PL signal. The resonant PL is co-circularly polarized
and corresponds to relaxation channels that conserve the Cr$^+$ spin $\vert S_z
\vert$. The observation in the resonant-PL excitation spectra of optical
transitions with a change of the Cr$^+$ spin permits to determine the magnetic
anisotropy of the magnetic atom. Optical pumping, auto-correlation measurements
and the power dependence of the PL intensity distribution show that the
effective temperature of the hole-Cr$^+$ spin system is affected by the optical
excitation through the local generation of phonons.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:47:33 GMT""}]","2022-08-17"
"2205.08123","Tommi Keski-Filppula","Tommi Keski-Filppula, Marko Nikki, Marianne Haapea, Naglis
  Ramanauskas, Osmo Tervonen","Using artificial intelligence to detect chest X-rays with no significant
  findings in a primary health care setting in Oulu, Finland","Abstract #21318 - ECR 2022 oral presentations",,,,"eess.IV cs.CV physics.med-ph","http://creativecommons.org/licenses/by/4.0/","  Objectives: To assess the use of artificial intelligence-based software in
ruling out chest X-ray cases, with no significant findings in a primary health
care setting.
  Methods: In this retrospective study, a commercially available artificial
intelligence (AI) software was used to analyse 10 000 chest X-rays of Finnish
primary health care patients. In studies with a mismatch between an AI normal
report and the original radiologist report, a consensus read by two
board-certified radiologists was conducted to make the final diagnosis.
  Results: After the exclusion of cases not meeting the study criteria, 9579
cases were analysed by AI. Of these cases, 4451 were considered normal in the
original radiologist report and 4644 after the consensus reading. The number of
cases correctly found nonsignificant by AI was 1692 (17.7% of all studies and
36.4% of studies with no significant findings). After the consensus read, there
were nine confirmed false-negative studies. These studies included four cases
of slightly enlarged heart size, four cases of slightly increased pulmonary
opacification and one case with a small unilateral pleural effusion. This gives
the AI a sensitivity of 99.8% (95% CI= 99.65-99.92) and specificity of 36.4 %
(95% CI= 35.05-37.84) for recognising significant pathology on a chest X-ray.
  Conclusions: AI was able to correctly rule out 36.4% of chest X-rays with no
significant findings of primary health care patients, with a minimal number of
false negatives that would lead to effectively no compromise on patient safety.
No critical findings were missed by the software.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:48:01 GMT""}]","2022-05-18"
"2205.08124","Orion Weller","Orion Weller, Kevin Seppi, Matt Gardner","When to Use Multi-Task Learning vs Intermediate Fine-Tuning for
  Pre-Trained Encoder Transfer Learning","ACL 2022",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Transfer learning (TL) in natural language processing (NLP) has seen a surge
of interest in recent years, as pre-trained models have shown an impressive
ability to transfer to novel tasks. Three main strategies have emerged for
making use of multiple supervised datasets during fine-tuning: training on an
intermediate task before training on the target task (STILTs), using multi-task
learning (MTL) to train jointly on a supplementary task and the target task
(pairwise MTL), or simply using MTL to train jointly on all available datasets
(MTL-ALL). In this work, we compare all three TL methods in a comprehensive
analysis on the GLUE dataset suite. We find that there is a simple heuristic
for when to use one of these techniques over the other: pairwise MTL is better
than STILTs when the target task has fewer instances than the supporting task
and vice versa. We show that this holds true in more than 92% of applicable
cases on the GLUE dataset and validate this hypothesis with experiments varying
dataset size. The simplicity and effectiveness of this heuristic is surprising
and warrants additional exploration by the TL community. Furthermore, we find
that MTL-ALL is worse than the pairwise methods in almost every case. We hope
this study will aid others as they choose between TL methods for NLP tasks.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:48:45 GMT""}]","2022-05-18"
"2205.08125","Spiros Cotsakis","Ignatios Antoniadis, Spiros Cotsakis, John Miritzis","Localizing branes with bifurcating bulks","29 pages, 10 figures, 1 table, matches published version","Eur. Phys. J. C82 (2022) 785","10.1140/epjc/s10052-022-10758-3",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of evolution of bulk 5-fluids having an embedded
braneworld with a flat, de Sitter, or anti-de Sitter geometry. We introduce new
variables to express the Einstein equations as a dynamical system that depends
on the equation of state parameter $\gamma$ and exponent $\lambda$. For linear
fluids (i.e., $\lambda=1$), our formulation leads to a partial decoupling of
the equations and thus to an exact solution. We find that such a fluid develops
a transcritical bifurcation around the value $\gamma=-1/2$, and study how this
behaviour affects to stability of the solutions. For nonlinear fluids, the
situation is more diverse. We find an overall attractor at $\lambda=1/2$ and
draw enough phase portraits to exhibit in detail the overall dynamics. We show
that the value $\lambda =3/2$ is structurally unstable and typical for other
forms of $\lambda$. Consequently, we observe a noticeable dependence of the
qualitative behaviour of the solutions on different `polytropic' forms of the
fluid bulk. In addition, we prove the existence of a Dulac function for
nonlinear fluids, signifying the impossibility of closed orbits in certain
subsets of the phase space. We also provide ample numerical evidence of gravity
localizing solutions on the brane which satisfy all energy conditions.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:51:55 GMT""},{""version"":""v2"",""created"":""Fri, 7 Oct 2022 14:38:46 GMT""}]","2022-10-10"
"2205.08126","Torsten M\""utze","Petr Gregor, Arturo Merino, Torsten M\""utze","The Hamilton compression of highly symmetric graphs",,,,,"math.CO cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We say that a Hamilton cycle $C=(x_1,\ldots,x_n)$ in a graph $G$ is
$k$-symmetric, if the mapping $x_i\mapsto x_{i+n/k}$ for all $i=1,\ldots,n$,
where indices are considered modulo $n$, is an automorphism of $G$. In other
words, if we lay out the vertices $x_1,\ldots,x_n$ equidistantly on a circle
and draw the edges of $G$ as straight lines, then the drawing of $G$ has
$k$-fold rotational symmetry, i.e., all information about the graph is
compressed into a $360^\circ/k$ wedge of the drawing. We refer to the maximum
$k$ for which there exists a $k$-symmetric Hamilton cycle in $G$ as the
Hamilton compression of $G$. We investigate the Hamilton compression of four
different families of vertex-transitive graphs, namely hypercubes, Johnson
graphs, permutahedra and Cayley graphs of abelian groups. In several cases we
determine their Hamilton compression exactly, and in other cases we provide
close lower and upper bounds. The cycles we construct have a much higher
compression than several classical Gray codes known from the literature. Our
constructions also yield Gray codes for bitstrings, combinations and
permutations that have few tracks and/or that are balanced.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:52:21 GMT""}]","2022-05-18"
"2205.08127","Francesco Ballarin","Simona Perotto, Gloria Bellini, Francesco Ballarin, Karol Cal\`o,
  Valentina Mazzi, Umberto Morbiducci","Isogeometric Hierarchical Model Reduction for advection-diffusion
  process simulation in microchannels","17 pages",,,,"physics.flu-dyn cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Microfluidics proved to be a key technology in various applications, allowing
to reproduce large-scale laboratory settings at a more sustainable small-scale.
The current effort is focused on enhancing the mixing process of different
passive species at the micro-scale, where a laminar flow regime damps
turbulence effects. Chaotic advection is often used to improve mixing effects
also at very low Reynolds numbers. In particular, we focus on passive
micromixers, where chaotic advection is mainly achieved by properly selecting
the geometry of microchannels. In such a context, reduced order modeling can
play a role, especially in the design of new geometries. In this chapter, we
verify the reliability and the computational benefits lead by a Hierarchical
Model (HiMod) reduction when modeling the transport of a passive scalar in an
S-shaped microchannel. Such a geometric configuration provides an ideal setting
where to apply a HiMod approximation, which exploits the presence of a leading
dynamics to commute the original three-dimensional model into a system of
one-dimensional coupled problems. It can be proved that HiMod reduction
guarantees a very good accuracy when compared with a high-fidelity model,
despite a drastic reduction in terms of number of unknowns.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:54:31 GMT""}]","2022-05-18"
"2205.08128","Francesco Ranzato","Marco Milanese and Francesco Ranzato","Local Completeness Logic on Kleene Algebra with Tests",,,,,"cs.LO cs.PL","http://creativecommons.org/licenses/by-sa/4.0/","  Local Completeness Logic (LCL) has been put forward as a program logic for
proving both the correctness and incorrectness of program specifications. LCL
is an abstract logic, parameterized by an abstract domain that allows combining
over- and under-approximations of program behaviors. It turns out that LCL
instantiated to the trivial singleton abstraction boils down to O'Hearn
incorrectness logic, which allows us to prove the presence of program bugs. It
has been recently proved that suitable extensions of Kleene algebra with tests
(KAT) allow representing both O'Hearn incorrectness and Hoare correctness
program logics within the same equational framework. In this work, we
generalize this result by showing how KATs extended either with a modal diamond
operator or with a top element are able to represent the local completeness
logic LCL. This is achieved by studying how these extended KATs can be endowed
with an abstract domain so as to define the validity of
correctness/incorrectness LCL triples and to show that the LCL proof system is
logically sound and, under some hypotheses, complete.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:58:07 GMT""},{""version"":""v2"",""created"":""Thu, 25 Aug 2022 08:15:36 GMT""}]","2022-08-26"
"2205.08129","Kuan Fang","Kuan Fang, Patrick Yin, Ashvin Nair, Sergey Levine","Planning to Practice: Efficient Online Fine-Tuning by Composing Goals in
  Latent Space",,,,,"cs.RO cs.AI cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  General-purpose robots require diverse repertoires of behaviors to complete
challenging tasks in real-world unstructured environments. To address this
issue, goal-conditioned reinforcement learning aims to acquire policies that
can reach configurable goals for a wide range of tasks on command. However,
such goal-conditioned policies are notoriously difficult and time-consuming to
train from scratch. In this paper, we propose Planning to Practice (PTP), a
method that makes it practical to train goal-conditioned policies for
long-horizon tasks that require multiple distinct types of interactions to
solve. Our approach is based on two key ideas. First, we decompose the
goal-reaching problem hierarchically, with a high-level planner that sets
intermediate subgoals using conditional subgoal generators in the latent space
for a low-level model-free policy. Second, we propose a hybrid approach which
first pre-trains both the conditional subgoal generator and the policy on
previously collected data through offline reinforcement learning, and then
fine-tunes the policy via online exploration. This fine-tuning process is
itself facilitated by the planned subgoals, which breaks down the original
target task into short-horizon goal-reaching tasks that are significantly
easier to learn. We conduct experiments in both the simulation and real world,
in which the policy is pre-trained on demonstrations of short primitive
behaviors and fine-tuned for temporally extended tasks that are unseen in the
offline data. Our experimental results show that PTP can generate feasible
sequences of subgoals that enable the policy to efficiently solve the target
tasks.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:58:17 GMT""},{""version"":""v2"",""created"":""Tue, 18 Apr 2023 07:06:50 GMT""}]","2023-04-19"
"2205.08130","Stephan Rosswog","S. Rosswog, P. Diener, F. Torsello","Thinking outside the box: Numerical Relativity with particles","36 pages, accepted for publication in Symmetry",,,,"gr-qc astro-ph.HE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  To date, essentially all simulation codes that solve the full set of
Einstein's equations are performed in the framework of Eulerian hydrodynamics.
The exception is our recently developed Numerical Relativity code SPHINCS_BSSN
which solves the commonly used BSSN formulation of the Einstein equations on a
structured mesh and the matter equations via Lagrangian particles. We show
here, for the first time, SPHINCS_BSSN neutron star merger simulations with
piecewise polytropic approximations to four nuclear matter equations of state.
In this set of neutron star merger simulations we focus on perfectly symmetric
binary systems that are irrotational and have 1.3 $M_\odot$ masses. We
introduce some further methodological refinements (a new way of steering
dissipation, an improved particle-mesh mapping) and we explore the impact of
the exponent that enters in the calculation of the thermal pressure
contribution. We find that it leaves a noticeable imprint on the gravitational
wave amplitude (calculated via both quadrupole approximation and the
$\Psi_4$-formalism) and has a noticeable impact on the amount of dynamic
ejecta. Consistent with earlier findings, we only find a few times $10^{-3}$
\Msun as dynamic ejecta in the studied equal mass binary systems, with softer
equations of state (which are more prone to shock formation) ejecting larger
amounts of matter. In all of the cases, we see a credible high-velocity
($\sim0.5 .. 0.7c$) ejecta component of $\sim 10^{-4}$ \Msun that is launched
at contact from the interface between the two neutron stars. Such a
high-velocity component has been suggested to produce an early, blue precursor
to the main kilonova emission and it could also potentially cause a kilonova
afterglow.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:58:35 GMT""},{""version"":""v2"",""created"":""Wed, 15 Jun 2022 21:49:15 GMT""}]","2022-06-17"
"2205.08131","Salaheddin Zarrin","S. Zarrin and S. Dadfar (Department of Physics, University of Sistan
  and Baluchestan, Zahedan, Iran)","Nonlinear corrections to the single differential cross section for
  neutral current e-p scattering at the NLO approximation",,,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the effects of nonlinear corrections to the single differential
cross section d\sigma/dQ^2 and the reduced cross section \sigma_r (x,Q^2) for
the neutral current (NC) e-p scattering at the leading order (LO) and the
next-to-leading order (NLO) approximations in perturbative quantum chromo
dynamics (QCD). Technically, based on the double Laplace transform method, we
first derive the effects of the nonlinear corrections to the proton structure
functions F2(x,Q^2) and FL(x,Q^2) and consequently obtain the corresponding
single differential and reduced cross sections. Our results clearly indicate
the consistency of the nonlinear behavior of the quark and gluon distributions
at low x values. Our numerical results ( obtained in a range of the virtuality
8.5 < Q2 < 5000 GeV ^2 and the Bjorken scale 10^(-5)< x < 1) show that the
effects of these nonlinear corrections to the proton structure functions are
more noticeable at x < 0.001 and, to some extent, control the incremental trend
of these functions at low x values. Moreover, a comparison of our numerical
results of the single differential and reduced cross sections at the NLO
approximations with those of H1 collaboration data shows that the nonlinear
corrections increase the accuracy of calculations rather than the linear
calculations at low to moderate Q^2 values for low x values.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:00:42 GMT""}]","2022-05-18"
"2205.08132","Joachim Schaeffer","Joachim Schaeffer and Richard Braatz","Latent Variable Method Demonstrator -- Software for Understanding
  Multivariate Data Analytics Algorithms","18 pages, 14 figures, code available:
  https://github.com/JoachimSchaeffer/LAVADE, preprint submitted to Computers &
  Chemical Engineering",,"10.1016/j.compchemeng.2022.108014",,"stat.ML cs.CY cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The ever-increasing quantity of multivariate process data is driving a need
for skilled engineers to analyze, interpret, and build models from such data.
Multivariate data analytics relies heavily on linear algebra, optimization, and
statistics and can be challenging for students to understand given that most
curricula do not have strong coverage in the latter three topics. This article
describes interactive software - the Latent Variable Demonstrator (LAVADE) -
for teaching, learning, and understanding latent variable methods. In this
software, users can interactively compare latent variable methods such as
Partial Least Squares (PLS), and Principal Component Regression (PCR) with
other regression methods such as Least Absolute Shrinkage and Selection
Operator (lasso), Ridge Regression (RR), and Elastic Net (EN). LAVADE helps to
build intuition on choosing appropriate methods, hyperparameter tuning, and
model coefficient interpretation, fostering a conceptual understanding of the
algorithms' differences. The software contains a data generation method and
three chemical process datasets, allowing for comparing results of datasets
with different levels of complexity. LAVADE is released as open-source software
so that others can apply and advance the tool for use in teaching or research.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:02:41 GMT""},{""version"":""v2"",""created"":""Mon, 26 Sep 2022 15:56:52 GMT""}]","2022-11-08"
"2205.08133","Hossein Teimoori Faal","Hossein Teimoori Faal","On Clique Incidence Matrices and Derivatives of Clique Polynomials",,,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  The ordinary generating function of the number of complete subgraphs
(cliques) of $G$, denoted by $C(G,x)$, is called the The clique polynomial of
the graph $G$. In this paper, we first introduce some \emph{clique} incidence
matrices associated by a simple graph $G$ as a generalization of the classical
vertex-edge incidence matrix of $G$. Then, using these clique incidence
matrices, we obtain two clique-counting identities that can be used for
deriving two combinatorial formulas for the first and the second derivatives of
clique polynomials. Finally, we conclude the paper with several open questions
and conjectures about possible extensions of our main results for higher
derivatives of clique polynomials.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:03:56 GMT""}]","2022-05-18"
"2205.08134","Sibel Baskal","Sibel Baskal, Sinan Celik","Compatibility of the Dimensional Reduction and Variation Procedures for
  a Quadratic Curvature Model with a Kaluza-Klein Ansatz","v2 has an overall sign change in Eq.(102), Eq.(104) and some other
  minor corrections elsewhere, without any effect on the subsequent expressions
  and results. All versions contain more detailed calculations and are longer
  than the published version",,"10.1007/s10714-022-03029-9",,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  The introduction of extra dimensions is an invaluable strategy for the
unification of gravity with other physical fields. Nevertheless, the matter in
hand is to be eventually reduced to the actual 4D spacetime. The Kaluza-Klein
theory is no exception to this well-known scheme. There are two procedures to
obtain the field equations from a higher dimensional action. One can either
take the variation of the effective action in that higher dimension and then
reduce the resulting equations or reduce the higher dimensional action to the
actual 4D and henceforward take the variations with respect to the constituent
fields of the theory. Here, for the case of a quadratic curvature model with a
Kaluza-Klein ansatz the field equations are obtained from the reduced action
and compatibility of these two procedures is discussed in detail.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:04:51 GMT""},{""version"":""v2"",""created"":""Mon, 26 Dec 2022 07:12:14 GMT""}]","2022-12-27"
"2205.08135","Hai-Han Sun","Hai-Han Sun, Weixia Cheng, and Zheng Fan","Learning to Remove Clutter in Real-World GPR Images Using Hybrid Data",,,"10.1109/TGRS.2022.3176029",,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The clutter in the ground-penetrating radar (GPR) radargram disguises or
distorts subsurface target responses, which severely affects the accuracy of
target detection and identification. Existing clutter removal methods either
leave residual clutter or deform target responses when facing complex and
irregular clutter in the real-world radargram. To tackle the challenge of
clutter removal in real scenarios, a clutter-removal neural network (CR-Net)
trained on a large-scale hybrid dataset is presented in this study. The CR-Net
integrates residual dense blocks into the U-Net architecture to enhance its
capability in clutter suppression and target reflection restoration. The
combination of the mean absolute error (MAE) loss and the multi-scale
structural similarity (MS-SSIM) loss is used to effectively drive the
optimization of the network. To train the proposed CR-Net to remove complex and
diverse clutter in real-world radargrams, the first large-scale hybrid dataset
named CLT-GPR dataset containing clutter collected by different GPR systems in
multiple scenarios is built. The CLT-GPR dataset significantly improves the
generalizability of the network to remove clutter in real-world GPR radargrams.
Extensive experimental results demonstrate that the CR-Net achieves superior
performance over existing methods in removing clutter and restoring target
responses in diverse real-world scenarios. Moreover, the CR-Net with its
end-to-end design does not require manual parameter tuning, making it highly
suitable for automatically producing clutter-free radargrams in GPR
applications. The CLT-GPR dataset and the code implemented in the paper can be
found at https://haihan-sun.github.io/GPR.html.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:05:02 GMT""}]","2022-06-15"
"2205.08136","Qianqian Yu","Qianqian Yu, Siqi Liu, Chunqi Yuan, and Dong Sheng","Light-shift-free and dead-zone-free atomic orientation based scalar
  magnetometry using a single amplitude-modulated beam","Accepted by Physical Review Applied",,,,"physics.atom-ph physics.ins-det physics.optics","http://creativecommons.org/licenses/by/4.0/","  Detection dead zones and heading errors induced by light shifts are two
important problems in optically pumped scalar magnetometry. We introduce an
atomic orientation based single-beam magnetometry scheme to simultaneously
solve these problems, using a polarization-reversing and path-bending Herriott
cavity. Here, a reflection mirror is inserted into the cavity to bend the
optical paths in the middle, and divide them into two separated orthogonal
regions to avoid the detection dead zone. Moreover, half-wave plates are added
in the center of each optical region, so that the light polarization is flipped
each time it passes the wave plates and the light shift effects are spatially
averaged out. This operation is demonstrated to eliminate the unnoticed heading
errors induced by ac light shifts. The methods developed in this paper are
robust to use, and easy to be applied in other atomic devices.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:07:36 GMT""}]","2022-05-18"
"2205.08137","Cong Wang","Xiaoliang Li and Cong Wang","On the exterior Dirichlet problem for Hessian type fully nonlinear
  elliptic equations","24 pages",,"10.1142/S0219199722500821",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We treat the exterior Dirichlet problem for a class of fully nonlinear
elliptic equations of the form $$f(\lambda(D^2u))=g(x),$$ with prescribed
asymptotic behavior at infinity. The equations of this type had been studied
extensively by Caffarelli--Nirenberg--Spruck \cite{Caffarelli1985}, Trudinger
\cite{Trudinger1995} and many others, and there had been significant
discussions on the solvability of the classical Dirichlet problem via the
continuity method, under the assumption that $f$ is a concave function. In this
paper, based on the Perron's method, we establish an exterior existence and
uniqueness result for viscosity solutions of the equations by assuming $f$ to
satisfy certain structure conditions as in \cite{Caffarelli1985,Trudinger1995},
which may embrace the well-known Monge--Amp\`ere equations, Hessian equations
and Hessian quotient equations as special cases but do not require the
concavity.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:08:55 GMT""},{""version"":""v2"",""created"":""Fri, 13 Jan 2023 14:14:09 GMT""}]","2023-01-16"
"2205.08138","Daisuke Niizumi","Daisuke Niizumi, Daiki Takeuchi, Yasunori Ohishi, Noboru Harada, and
  Kunio Kashino","Composing General Audio Representation by Fusing Multilayer Features of
  a Pre-trained Model","5 pages, 4 figures and 4 tables. Accepted by EUSIPCO 2022",,,,"eess.AS cs.SD","http://creativecommons.org/licenses/by/4.0/","  Many application studies rely on audio DNN models pre-trained on a
large-scale dataset as essential feature extractors, and they extract features
from the last layers. In this study, we focus on our finding that the middle
layer features of existing supervised pre-trained models are more effective
than the late layer features for some tasks. We propose a simple approach to
compose features effective for general-purpose applications, consisting of two
steps: (1) calculating feature vectors along the time frame from middle/late
layer outputs, and (2) fusing them. This approach improves the utility of
frequency and channel information in downstream processes, and combines the
effectiveness of middle and late layer features for different tasks. As a
result, the feature vectors become effective for general purposes. In the
experiments using VGGish, PANNs' CNN14, and AST on nine downstream tasks, we
first show that each layer output of these models serves different tasks. Then,
we demonstrate that the proposed approach significantly improves their
performance and brings it to a level comparable to that of the
state-of-the-art. In particular, the performance of the non-semantic speech
(NOSS) tasks greatly improves, especially on Speech commands V2 with VGGish of
+77.1 (14.3% to 91.4%).
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:10:19 GMT""}]","2022-05-18"
"2205.08139","Philippe Roncin","Peng Pan, Jaafar Najafi Rad, Philippe Roncin","A setup for grazing incidence fast atom diffraction","14 pages, 15figures","Rev. Sci. Instrum. 93, 093305 (2022)","10.1063/5.0099269",,"physics.ins-det","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We describe a UHV setup for grazing incidence fast atom diffraction (GIFAD)
experiments. The overall geometry is simply a source of keV atoms facing an
imaging detector. Therefore, It is very similar to the geometry of RHEED
experiments, reflection high energy electron diffraction used to monitor growth
at surfaces. Several custom instrumental developments are described making
GIFAD operation efficient and straightforward. The difficulties associated with
accurately measuring the small scattering angle and the related calibration are
carefully analyzed.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:13:07 GMT""}]","2022-09-23"
"2205.08140","Candy Sonveaux","Candy Sonveaux and Joseph J. Winkin","State feedback control law design for an age-dependent SIR model","Preprint submitted to Automatica",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An age-dependent SIR model is considered with the aim to develop a
state-feedback vaccination law in order to eradicate a disease. A dynamical
analysis of the system is performed using the principle of linearized stability
and shows that, if the basic reproduction number is larger than 1, the disease
free equilibrium is unstable. This result justifies the developement of a
vaccination law. Two approaches are used. The first one is based on a
dicretization of the partial integro-differential equations (PIDE) model
according to the age. In this case a linearizing feedback law is found using
Isidori's theory. Conditions guaranteeing stability and positivity are
established. The second approach yields a linearizing feedback law developed
for the PIDE model. This law is deduced from the one obtained for the ODE case.
Using semigroup theory, stability conditions are also obtained. Finally,
numerical simulations are presented to reinforce the theoretical arguments.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:13:29 GMT""}]","2022-05-18"
"2205.08141","Florian Domingo","Florian Domingo and Herbi K. Dreiner","Decays of a bino-like particle in the low-mass regime","50 pages, 5 figures","SciPost Phys. 14, 134 (2023)","10.21468/SciPostPhys.14.5.134","BONN-TH-2022-13","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the phenomenology associated with a light bino-like neutralino with
mass under the tau mass in the context of the R-parity violating Minimal
Supersymmetric Standard Model. This is a well-motivated example of scenarios
producing potentially light and long-lived exotic particles, which might be
testable in far-detector experiments, such as the FASER experiment at the Large
Hadron Collider. A quantitative assessment of the discovery potential or the
extraction of limits run through a detailed understanding of the interactions
of the light exotic fermion with Standard Model matter, in particular, the
hadronic sector. Here, we propose a systematic analysis of the decays of such a
particle and proceed to a model-independent derivation of the low-energy
effects, so that this formalism may be transposed to other UV-completions or
even stand as an independent effective field theory. We then stress the
diversity of the possible phenomenology and more specifically discuss the
features associated with the R-parity violating supersymmetric framework, for
example neutron-antineutron oscillations.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:17:49 GMT""},{""version"":""v2"",""created"":""Thu, 28 Jul 2022 13:39:07 GMT""}]","2023-05-31"
"2205.08142","Hai-Han Sun","Hai-Han Sun, Yee Hui Lee, Wenhao Luo, Lai Fern Ow, Mohamed Lokman Mohd
  Yusof, and Abdulkadir C. Yucel","Dual-Cross-Polarized GPR Measurement Method for Detection and
  Orientation Estimation of Shallowly Buried Elongated Object",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Detecting a shallowly buried and elongated object and estimating its
orientation using a commonly adopted co-polarized GPR system is challenging due
to the presence of strong ground clutter that masks the target reflection. A
cross-polarized configuration can be used to suppress ground clutter and reveal
the object reflection, but it suffers from inconsistent detection capability
which significantly varies with different object orientations. To address this
issue, we propose a dual-cross-polarized detection (DCPD) method which utilizes
two cross-polarized antennas with a special arrangement to detect the object.
The signals reflected by the object and collected by the two antennas are
combined in a rotationally invariant manner to ensure both effective ground
clutter suppression and consistent detection irrespective of the object
orientation. In addition, we present a dual-cross-polarized orientation
estimation (DCPOE) algorithm to estimate the object orientation from the two
cross-polarized data. The proposed DCPOE algorithm is less affected by
environmental noise and performs robust and accurate azimuth angle estimation.
The effectiveness of the proposed techniques in the detection and orientation
estimation and their advantages over the existing method have been demonstrated
using experimental data. Comparison results show that the maximum and average
errors are 22.3{\deg} and 10.9{\deg} for the Alford rotation algorithm, while
those are 4.9{\deg} and 1.8{\deg} for the proposed DCPOE algorithm in the
demonstrated shallowly buried object cases. The proposed techniques can be
unified in a framework to facilitate the investigation and mapping of shallowly
buried and elongated targets.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:20:49 GMT""}]","2022-05-18"
"2205.08143","Yu Wang","Yu Wang, Binbin Zhu, Lingsi Kong, Jianlin Wang, Bin Gao, Jianhua Wang,
  Dingcheng Tian, and Yudong Yao","Brachial Plexus Nerve Trunk Segmentation Using Deep Learning: A
  Comparative Study with Doctors' Manual Segmentation","9 pages",,,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ultrasound-guided nerve block anesthesia (UGNB) is a high-tech visual nerve
block anesthesia method that can observe the target nerve and its surrounding
structures, the puncture needle's advancement, and local anesthetics spread in
real-time. The key in UGNB is nerve identification. With the help of deep
learning methods, the automatic identification or segmentation of nerves can be
realized, assisting doctors in completing nerve block anesthesia accurately and
efficiently. Here, we establish a public dataset containing 320 ultrasound
images of brachial plexus (BP). Three experienced doctors jointly produce the
BP segmentation ground truth and label brachial plexus trunks. We design a
brachial plexus segmentation system (BPSegSys) based on deep learning. BPSegSys
achieves experienced-doctor-level nerve identification performance in various
experiments. We evaluate BPSegSys' performance in terms of
intersection-over-union (IoU), a commonly used performance measure for
segmentation experiments. Considering three dataset groups in our established
public dataset, the IoU of BPSegSys are 0.5238, 0.4715, and 0.5029,
respectively, which exceed the IoU 0.5205, 0.4704, and 0.4979 of experienced
doctors. In addition, we show that BPSegSys can help doctors identify brachial
plexus trunks more accurately, with IoU improvement up to 27%, which has
significant clinical application value.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:23:28 GMT""}]","2022-05-18"
"2205.08144","Mario Beraha","Mario Beraha and Bruno Guindani and Matteo Gianella and Alessandra
  Guglielmi","BayesMix: Bayesian Mixture Models in C++",,,,,"stat.CO stat.OT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe BayesMix, a C++ library for MCMC posterior simulation for general
Bayesian mixture models. The goal of BayesMix is to provide a self-contained
ecosystem to perform inference for mixture models to computer scientists,
statisticians and practitioners. The key idea of this library is extensibility,
as we wish the users to easily adapt our software to their specific Bayesian
mixture models. In addition to the several models and MCMC algorithms for
posterior inference included in the library, new users with little familiarity
on mixture models and the related MCMC algorithms can extend our library with
minimal coding effort. Our library is computationally very efficient when
compared to competitor software. Examples show that the typical code runtimes
are from two to 25 times faster than competitors for data dimension from one to
ten. Our library is publicly available on Github at
https://github.com/bayesmix-dev/bayesmix/.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:23:45 GMT""}]","2022-05-18"
"2205.08145","Lara Be{\ss}mann","Lara Be{\ss}mann","Is the right-angled building associated to a universal group unique?","8 Pages, 2 Figures, Corrected Typos",,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A universal group is a subgroup of the group of type preserving automorphisms
of a right-angled building and hence associated to this building. A question is
then if this universal group can act chamber-transitively and with compact open
stabilisers on a different right-angled building of the same type. We answer
this question and define two universal groups associated to different
right-angled buildings which are isomorphic as topological groups.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:24:41 GMT""},{""version"":""v2"",""created"":""Wed, 1 Jun 2022 12:42:37 GMT""}]","2022-06-02"
"2205.08146","Anna Stramaglia","Anna Stramaglia and Jeroen J.A. Keiren","Formal verification of an industrial UML-like model using mCRL2
  (extended version)","pre-print of a paper that is submitted to FMICS 2022",,,,"eess.SY cs.LO cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Low-code development platforms are gaining popularity. Essentially, such
platforms allow to shift from coding to graphical modeling, helping to improve
quality and reduce development time. The Cordis SUITE is a low-code development
platform that adopts the Unified Modeling Language (UML) to design complex
machine-control applications. In this paper we introduce Cordis models and
their semantics. To enable formal verification, we define an automatic
translation of Cordis models to the process algebraic specification language
mCRL2. As a proof of concept, we describe requirements of the control software
of an industrial cylinder model developed by Cordis, and show how these can be
verified using model checking. We show that our verification approach is
effective to uncover subtle issues in the industrial model and its
implementation.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:30:22 GMT""}]","2022-05-18"
"2205.08147","Yue Zhang","Zhang Yue, Zheng Xiangtao, Lu Xiaoqiang","Pairwise Comparison Network for Remote Sensing Scene Classification","6 pages, 4 figures, published to GRSL","IEEE Geoscience and Remote Sensing Letters, vol. 19, pp. 1-5, 2022","10.1109/LGRS.2021.3139695",,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Remote sensing scene classification aims to assign a specific semantic label
to a remote sensing image. Recently, convolutional neural networks have greatly
improved the performance of remote sensing scene classification. However, some
confused images may be easily recognized as the incorrect category, which
generally degrade the performance. The differences between image pairs can be
used to distinguish image categories. This paper proposed a pairwise comparison
network, which contains two main steps: pairwise selection and pairwise
representation. The proposed network first selects similar image pairs, and
then represents the image pairs with pairwise representations. The
self-representation is introduced to highlight the informative parts of each
image itself, while the mutual-representation is proposed to capture the subtle
differences between image pairs. Comprehensive experimental results on two
challenging datasets (AID, NWPU-RESISC45) demonstrate the effectiveness of the
proposed network. The codes are provided in
https://github.com/spectralpublic/PCNet.git.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:31:36 GMT""},{""version"":""v2"",""created"":""Sat, 21 May 2022 07:33:29 GMT""}]","2022-05-24"
"2205.08148","Yusuke Hirota","Yusuke Hirota, Yuta Nakashima, Noa Garcia","Gender and Racial Bias in Visual Question Answering Datasets","ACM Conference on Fairness, Accountability, and Transparency (FAccT
  2022)",,"10.1145/3531146.3533184",,"cs.CV cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Vision-and-language tasks have increasingly drawn more attention as a means
to evaluate human-like reasoning in machine learning models. A popular task in
the field is visual question answering (VQA), which aims to answer questions
about images. However, VQA models have been shown to exploit language bias by
learning the statistical correlations between questions and answers without
looking into the image content: e.g., questions about the color of a banana are
answered with yellow, even if the banana in the image is green. If societal
bias (e.g., sexism, racism, ableism, etc.) is present in the training data,
this problem may be causing VQA models to learn harmful stereotypes. For this
reason, we investigate gender and racial bias in five VQA datasets. In our
analysis, we find that the distribution of answers is highly different between
questions about women and men, as well as the existence of detrimental
gender-stereotypical samples. Likewise, we identify that specific race-related
attributes are underrepresented, whereas potentially discriminatory samples
appear in the analyzed datasets. Our findings suggest that there are dangers
associated to using VQA datasets without considering and dealing with the
potentially harmful stereotypes. We conclude the paper by proposing solutions
to alleviate the problem before, during, and after the dataset collection
process.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:33:24 GMT""},{""version"":""v2"",""created"":""Wed, 18 May 2022 08:47:20 GMT""},{""version"":""v3"",""created"":""Fri, 3 Jun 2022 06:36:16 GMT""}]","2022-06-06"
"2205.08149","Ke Lai","Ke Lai, Zilong Liu, Jing Lei, Lei Wen, Gaojie Chen, and Pei Xiao","A Novel K-Repetition Design for SCMA","6 pages, 6 figures",,,,"cs.IT eess.SP math.IT","http://creativecommons.org/publicdomain/zero/1.0/","  This work presents a novel K-Repetition based HARQ scheme for LDPC coded
uplink SCMA by employing a network coding (NC) principle to encode different
packets, where K-Repetition is an emerging technique (recommended in 3GPP
Release 15) for enhanced reliability and reduced latency in future massive
machine-type communication. Such a scheme is referred to as the NC aided
K-repetition SCMA (NCK-SCMA). We introduce a joint iterative detection
algorithm for improved detection of the data from the proposed LDPC coded
NCKSCMA systems. Simulation results demonstrate the benefits of NCK-SCMA with
higher throughput and improved reliability over the conventional K-Repetition
SCMA.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:33:58 GMT""}]","2022-05-18"
"2205.08150","Yiming Tu","Yiming Tu","UnPWC-SVDLO: Multi-SVD on PointPWC for Unsupervised Lidar Odometry",,,,,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High-precision lidar odomety is an essential part of autonomous driving. In
recent years, deep learning methods have been widely used in lidar odomety
tasks, but most of the current methods only extract the global features of the
point clouds. It is impossible to obtain more detailed point-level features in
this way. In addition, only the fully connected layer is used to estimate the
pose. The fully connected layer has achieved obvious results in the
classification task, but the changes in pose are a continuous rather than
discrete process, high-precision pose estimation can not be obtained only by
using the fully connected layer. Our method avoids problems mentioned above. We
use PointPWC as our backbone network. PointPWC is originally used for scene
flow estimation. The scene flow estimation task has a strong correlation with
lidar odomety. Traget point clouds can be obtained by adding the scene flow and
source point clouds. We can achieve the pose directly through ICP algorithm
solved by SVD, and the fully connected layer is no longer used. PointPWC
extracts point-level features from point clouds with different sampling levels,
which solves the problem of too rough feature extraction. We conduct
experiments on KITTI, Ford Campus Vision and Lidar DataSe and Apollo-SouthBay
Dataset. Our result is comparable with the state-of-the-art unsupervised deep
learing method SelfVoxeLO.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:37:21 GMT""}]","2022-05-18"
"2205.08151","Yuanyuan Yang","Yuanyuan Yang, Delin Feng and S\""oren Schwertfeger","Cluster on Wheels","8 pages, 7 figures, 2022 International Conference for Advancement in
  Technology(ICONAT). It is about the work of the mapping robot cluster
  computer platform","2022 International Conference for Advancement in Technology
  (ICONAT), 2022, pp. 1-8","10.1109/ICONAT53423.2022.9725992",,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a very compact 16-node cluster that is the core of a
future robot for collecting and storing massive amounts of sensor data for
research on Simultaneous Localization and Mapping (SLAM). To the best of our
knowledge, this is the first time that such a cluster is used in robotics. We
first present the requirements and different options for computing of such a
robot and then show the hardware and software of our solution in detail. The
cluster consists of 16 nodes of AMD Ryzen 7 5700U CPUs with a total of 128
cores. As a system that is to be used on a Clearpath Husky robot, it is very
small in size, can be operated from battery power and has all required power
and networking components integrated. Stress tests on the completed cluster
show that it performs well.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:38:42 GMT""},{""version"":""v2"",""created"":""Thu, 19 May 2022 08:41:16 GMT""}]","2022-05-20"
"2205.08152","Huan Meng","Huan Meng","Dual-mode robust MPC for the tracking control of non-holonomoic mobile
  robots","This paper exists a lot of mistakes. Therefore, I want to withdraw it",,,,"cs.RO","http://creativecommons.org/publicdomain/zero/1.0/","  In this paper, a novel dual-mode robust model predictive control (MPC)
approach is proposed for solving the tracking control problem of non-holonomoic
mobile robots with additive bounded disturbance. To reduce the negative effect
of disturbance and drive the state of real system closer to the one of nominal
system , a robust reference signal is introduced into the cost function of MPC.
In order to reduced the computation burden caused by online optimization of MPC
and further improve the tracking accuracy, a dual-mode control strucuture
consisting of the robust MPC and the local nonlinear robust control is
developed, in which the local nonlinear robust control law is applied within a
specified terminal region. Finally, simulation results on the non-holonomic
mobile robot are presented to show the validity of the proposed control
approach.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:43:20 GMT""},{""version"":""v2"",""created"":""Fri, 24 Feb 2023 09:38:55 GMT""}]","2023-02-27"
"2205.08153","Michael Voit","Michael Voit","Freezing Limits for Beta-Cauchy Ensembles",,"SIGMA 18 (2022), 069, 25 pages","10.3842/SIGMA.2022.069",,"math.PR math-ph math.CA math.MP","http://creativecommons.org/licenses/by-sa/4.0/","  Bessel processes associated with the root systems $A_{N-1}$ and $B_N$
describe interacting particle systems with $N$ particles on $\mathbb R$; they
form dynamic versions of the classical $\beta$-Hermite and Laguerre ensembles.
In this paper we study corresponding Cauchy processes constructed via some
subordination. This leads to $\beta$-Cauchy ensembles in both cases with
explicit distributions. For these distributions we derive central limit
theorems for fixed $N$ in the freezing regime, i.e., when the parameters tend
to infinity. The results are closely related to corresponding known freezing
results for $\beta$-Hermite and Laguerre ensembles and for Bessel processes.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:46:56 GMT""},{""version"":""v2"",""created"":""Wed, 28 Sep 2022 06:06:30 GMT""}]","2022-09-29"
"2205.08154","Kerstin Beer","Kerstin Beer","Quantum neural networks","PhD Thesis, Leibniz University Hannover (22.02.2022)",,"10.15488/11896",,"quant-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This PhD thesis combines two of the most exciting research areas of the last
decades: quantum computing and machine learning. We introduce dissipative
quantum neural networks (DQNNs), which are designed for fully quantum learning
tasks, are capable of universal quantum computation and have low memory
requirements while training. These networks are optimised with training data
pairs in form of input and desired output states and therefore can be used for
characterising unknown or untrusted quantum devices. We not only demonstrate
the generalisation behaviour of DQNNs using classical simulations, but also
implement them successfully on actual quantum computers. To understand the
ultimate limits for such quantum machine learning methods, we discuss the
quantum no free lunch theorem, which describes a bound on the probability that
a quantum device, which can be modelled as a unitary process and is optimised
with quantum examples, gives an incorrect output for a random input. Moreover
we expand the area of applications of DQNNs in two directions. In the first
case, we include additional information beyond just the training data pairs:
since quantum devices are always structured, the resulting data is always
structured as well. We modify the DQNN's training algorithm such that knowledge
about the graph-structure of the training data pairs is included in the
training process and show that this can lead to better generalisation
behaviour. Both the original DQNN and the DQNN including graph structure are
trained with data pairs in order to characterise an underlying relation.
However, in the second extension of the algorithm we aim to learn
characteristics of a set of quantum states in order to extend it to quantum
states which have similar properties. Therefore we build a generative
adversarial model where two DQNNs, called the generator and discriminator, are
trained in a competitive way.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:47:00 GMT""}]","2022-05-18"
"2205.08155","Aiyi Li","Aiyi Li, Masaki Ogura, Naoki Wakamiya","Communication-Free Shepherding Navigation with Multiple Steering Agents","6 pages, 2 figures, comments welcome",,,,"eess.SY cs.MA cs.SY","http://creativecommons.org/licenses/by/4.0/","  Swarm guidance addresses a challenging problem considering the navigation and
control of a group of passive agents. To solve this problem, shepherding offers
a bio-inspired technique of navigating such group of agents by using external
steering agents with appropriately designed movement law. Although most
shepherding researches are mainly based on the availability of centralized
instructions, these assumptions are not realistic enough to solve some emerging
application problems. Therefore, this paper presents a decentralized
shepherding method where each steering agent makes movements based on its own
observation without any inter-agent communication. Our numerical simulations
confirm the effectiveness of the proposed method by showing its high success
rate and low costs in various placement patterns. These advantages particularly
improve with the increase in the number of steering agents.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:47:47 GMT""}]","2022-05-18"
"2205.08156","Dimitrios Bachtis","Dimitrios Bachtis","Reducing finite-size effects in quantum field theories with the
  renormalization group",,,,,"hep-lat cond-mat.stat-mech hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish a real-space renormalization group approach for lattice field
theories that partially overcomes finite-size effects and therefore provides
accurate infinite-volume limit calculations on systems with moderately small
lattice sizes. The method, which relies on the construction of renormalization
group mappings between two systems of identical lattice size, is utilized to
extract critical exponents and to explicitly determine the renormalized
coupling parameters of the two-dimensional $\phi^{4}$ scalar field theory. We
conclude by discussing how renormalization group methods, which are capable of
providing accurate results on small lattice sizes by reducing systematic errors
pertinent to finite-size effects, can be viewed as an alternative approach to
evade the implications of the critical slowing down effect.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:47:50 GMT""}]","2022-05-18"
"2205.08157","Yuan Minglei","Minglei Yuan, Qian Xu, Chunhao Cai, Yin-Dong Zheng, Tao Wang, Tong Lu","Uncertainty-based Network for Few-shot Image Classification","Few-shot learning, Uncertainty, Mutual information",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  The transductive inference is an effective technique in the few-shot learning
task, where query sets update prototypes to improve themselves. However, these
methods optimize the model by considering only the classification scores of the
query instances as confidence while ignoring the uncertainty of these
classification scores. In this paper, we propose a novel method called
Uncertainty-Based Network, which models the uncertainty of classification
results with the help of mutual information. Specifically, we first data
augment and classify the query instance and calculate the mutual information of
these classification scores. Then, mutual information is used as uncertainty to
assign weights to classification scores, and the iterative update strategy
based on classification scores and uncertainties assigns the optimal weights to
query instances in prototype optimization. Extensive results on four benchmarks
show that Uncertainty-Based Network achieves comparable performance in
classification accuracy compared to state-of-the-art method.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:49:32 GMT""}]","2022-05-18"
"2205.08158","Chia-Wei Liu","Chia-Wei Liu and Chao-Qiang Geng","Center of mass motion in bag model","21 pages, 2 figures",,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  Despite the great success on the mass spectra, the reputation of the bag
model has been closely followed by the embarrassment from the center of mass
motion. It leads to severe theoretical inconsistencies. For instance, the
masses and the decay constants would no longer be independent of the momentum.
In this work, we provide a systematical approach to resolve this problem. The
meson decay constants as well as the baryon transition form factors can be
computed consistently in our framework. Notably, the form factors in the
neutron $\beta$ decays do not depend on any free parameters, and are determined
to be $F^V_1 =1 $ and $F^A_1 = 1.31$ or $F_1^A/F_1^V= 1.31$, which is close the
experimental value of $F^A_1/F^V_1 = 1.27$. In addition, we find that ${\cal B}
(\Lambda_b \to \Lambda \gamma) = (6.8 \pm 3.3 ) \times 10^{-6} $, which agrees
to the experimental value of $(7.1\pm 1.7)\times 10^{-6}$.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:51:38 GMT""},{""version"":""v2"",""created"":""Thu, 27 Oct 2022 15:54:30 GMT""}]","2023-01-02"
"2205.08159","Prabhav Singh","Prabhav Singh, Ridam Srivastava, K.P.S. Rana, Vineet Kumar","SEMI-FND: Stacked Ensemble Based Multimodal Inference For Faster Fake
  News Detection",,,"10.1016/j.eswa.2022.119302",,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Fake News Detection (FND) is an essential field in natural language
processing that aims to identify and check the truthfulness of major claims in
a news article to decide the news veracity. FND finds its uses in preventing
social, political and national damage caused due to misrepresentation of facts
which may harm a certain section of society. Further, with the explosive rise
in fake news dissemination over social media, including images and text, it has
become imperative to identify fake news faster and more accurately. To solve
this problem, this work investigates a novel multimodal stacked ensemble-based
approach (SEMIFND) to fake news detection. Focus is also kept on ensuring
faster performance with fewer parameters. Moreover, to improve multimodal
performance, a deep unimodal analysis is done on the image modality to identify
NasNet Mobile as the most appropriate model for the task. For text, an ensemble
of BERT and ELECTRA is used. The approach was evaluated on two datasets:
Twitter MediaEval and Weibo Corpus. The suggested framework offered accuracies
of 85.80% and 86.83% on the Twitter and Weibo datasets respectively. These
reported metrics are found to be superior when compared to similar recent
works. Further, we also report a reduction in the number of parameters used in
training when compared to recent relevant works. SEMI-FND offers an overall
parameter reduction of at least 20% with unimodal parametric reduction on text
being 60%. Therefore, based on the investigations presented, it is concluded
that the application of a stacked ensembling significantly improves FND over
other approaches while also improving speed.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:51:55 GMT""}]","2023-02-28"
"2205.08160","Aneta Wojnar","Aneta Wojnar","Stellar and substellar objects in modified gravity","20 pages, 1 figure, Invited contribution to the forthcoming book
  ""Modified and Quantum Gravity - From theory to experimental searches on all
  scales"", Springer Nature, Eds C. L\""ammerzahl and C. Pfeifer",,,,"gr-qc astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The last findings on stellar and substellar objects in modified gravity are
presented, allowing a reader to quickly jump into this topic. Early stellar
evolution of low-mass stars, cooling models of brown dwarfs and giant gaseous
exoplanets as well as internal structure of terrestrial planets are discussed.
Moreover, possible test of models of gravity with the use of the discussed
objects are proposed.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:51:57 GMT""}]","2022-05-18"
"2205.08161","Cristiano Sabiu","Jaewon Yoo, Jongwan Ko, Cristiano G. Sabiu, Jihye Shin, Kyungwon Chun,
  Ho Seong Hwang, Juhan Kim, M. James Jee, Hyowon Kim, Rory Smith","Comparison of spatial distributions of Intracluster light and Dark
  Matter","17 pages, 8 figures, accepted in ApJS",,"10.3847/1538-4365/ac7142",,"astro-ph.GA astro-ph.CO astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  In a galaxy cluster, the relative spatial distributions of dark matter,
member galaxies, gas, and intracluster light (ICL) may connote their mutual
interactions over the cluster evolution. However, it is a challenging problem
to provide a quantitative measure for the shape matching between two
multi-dimensional scalar distributions. We present a novel methodology, named
the {\em Weighted Overlap Coefficient (WOC)}, to quantify the similarity of
2-dimensional spatial distributions. We compare the WOC with a standard method
known as the Modified Hausdorff Distance (MHD). We find that our method is
robust, and performs well even with the existence of multiple sub-structures.
We apply our methodology to search for a visible component whose spatial
distribution resembled with that of dark matter. If such a component could be
found to trace the dark matter distribution with high fidelity for more relaxed
galaxy clusters, then the similarity of the distributions could also be used as
a dynamical stage estimator of the cluster. We apply the method to six galaxy
clusters at different dynamical stages simulated within the GRT simulation,
which is an N-body simulation using the galaxy replacement technique. Among the
various components (stellar particles, galaxies, ICL), the ICL+ brightest
cluster galaxy (BCG) component most faithfully trace the dark matter
distribution. Among the sample galaxy clusters, the relaxed clusters show
stronger similarity in the spatial distribution of the dark matter and ICL+BCG
than the dynamically young clusters. While the MHD results show weaker trend
with the dynamical stages.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:55:04 GMT""},{""version"":""v2"",""created"":""Wed, 18 May 2022 06:09:36 GMT""}]","2022-08-03"
"2205.08162","Stefano Pinton Mr","Fabrizio Colombo, Antonino De Martino, Stefano Pinton, and Irene
  Sabadini","Axially harmonic functions and the harmonic functional calculus on the
  S-spectrum",,,,,"math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The spectral theory on the S-spectrum was introduced to give an appropriate
mathematical setting to quaternionic quantum mechanics, but it was soon
realized that there were different applications of this theory, for example, to
fractional heat diffusion and to the spectral theory for the Dirac operator on
manifolds. In this seminal paper we introduce the harmonic functional calculus
based on the S-spectrum and on an integral representation of axially harmonic
functions. This calculus can be seen as a bridge between harmonic analysis and
the spectral theory. The resolvent operator of the harmonic functional calculus
is the commutative version of the pseudo S-resolvent operator. This new
calculus also appears, in a natural way, in the product rule for the
F-functional calculus.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:58:35 GMT""}]","2022-05-18"
"2205.08163","Arturo Nu\~nez-Casti\~neyra","A. Nu\~nez-Casti\~neyra, I. A. Grenier, F. Bournaud, Y. Dubois, F. R.
  Kamal Youssef and P. Hennebelle","Cosmic-ray diffusion and the multi-phase interstellar medium in a dwarf
  galaxy. I. Large-scale properties and $\gamma$-ray luminosities",,,,,"astro-ph.HE astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Dynamically, cosmic rays with energies above about one GeV/nucleon may be
important agents of galaxy evolution. Their pressures compare with the thermal
and magnetic ones impacting galactic gas accretion, fountains and galactic
outflows, and alter the mass cycling between the gas phases, its efficiency
depends on the properties of CR transport in the different media. We aim to
study the dynamical role of CRs in shaping the interstellar medium of a galaxy
when changing their propagation mode. We perform MHD simulations with the AMR
code RAMSES of the evolution of the same isolated galaxy (dwarf galaxy of
$10^{11}$ M$_{\odot}$ down to 9-pc resolution) and compare the impact of the
simplest cosmic-ray transport assumption of uniform diffusion. We have also
updated the observational relation seen between the $\gamma$-ray luminosities
and SFR of galaxies using the latest detection of Fermi LAT sources. We find
that the radial and vertical distributions, and mass fractions of the gas in
the different phases are marginally altered when changing CR transport. We
observe positive feedback of CR on the amplification of the magnetic field in
the inner half of the galaxy, except for fast isotropic diffusion. The increase
in CR pressure for slow or anisotropic diffusion can suppress star formation by
up to 50\%, but the dual effect of cosmic-ray pressure and magnetic
amplification can reduce star formation by a factor 2.5. The $\gamma$-ray
luminosities and SFR of the simulated galaxies are fully consistent with the
trend seen in the observations in the case of anisotropic $10^{27.5-29}$ cm$^2$
s$^{-1}$ diffusion and for isotropic diffusion slower or equal to $3 \times
10^{28}$cm$^2$ s$^{-1}$. These results, therefore, do not confirm claims of
very fast $10^{29-31}$ cm$^2$ s$^{-1}$ diffusion to match the Fermi LAT
observations.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 08:01:46 GMT""}]","2022-05-18"
"2205.08164","Benjalmin Dequ\^ene","Benjamin Dequ\^ene","Jordan recoverability of some subcategories of modules over gentle
  algebras","Modified version following reports for submission to JPAA",,,,"math.RT math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gentle algebras form a class of finite-dimensional algebras introduced by I.
Assem and A. Skowro\'{n}ski in the 1980s. Modules over such an algebra can be
described by string and band combinatorics in the associated gentle quiver from
the work of M.C.R. Butler and C.M. Ringel. Any module can be naturally
associated to a quiver representation. A nilpotent endomorphism of a quiver
representation induces linear transformations over vector spaces at each
vertex. Generically among all nilpotent endomorphisms, a well-defined Jordan
form exists for these representations. We focus on subcategories additively
generated by all the indecomposable representations of a gentle quiver,
including a fixed vertex in their support. We show a characterization of the
vertices such that the objects of this subcategory are determined up to
isomorphism by their generic Jordan form.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 08:02:04 GMT""},{""version"":""v2"",""created"":""Wed, 17 May 2023 15:00:02 GMT""}]","2023-05-18"
"2205.08165","Jie Lu","Ge Tang, Xiao-Yong Yang, Ying Yan and Jie Lu","Fast Evolution of Single Qubit Gate in Non-Adiabatic Geometric Quantum
  Computing","20 pages, 7 fugures","Physics Letters A Physics Letters A, Volume 449, 14 October 2022,
  128349","10.1016/j.physleta.2022.128349",,"quant-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We implemented arbitrary single qubit gates of geometric quantum computing
for a three-level system in a single-shot manner. The evolution time of the
gate has been minimized by considering the shortest trajectory of the state on
the Bloch sphere. The duration of gates grows from zero with the rotation angle
$\gamma$, and the tested T gate time can be reduced to $\sim$40\% of those in
the traditional orange-sliced-shaped path non-adiabatic holonomic quantum
computing (NHQC) scheme by the parametrization of Rabi frequency. We also
demonstrated that certain pulses are robust against static detuning errors and
Rabi errors. The time-dependent detuning and Rabi frequency are found to be
proportional to each other by a constant which is determined by the geometric
phase. In this way, some previous NHQC schemes can be treated as special cases
in our generalized model.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 08:08:19 GMT""},{""version"":""v2"",""created"":""Mon, 29 Aug 2022 13:31:18 GMT""}]","2022-08-30"
"2205.08166","Lorenzo Cerrone","Lorenzo Cerrone, Athul Vijayan, Tejasvinee Mody, Kay Schneitz, Fred A.
  Hamprecht","CellTypeGraph: A New Geometric Computer Vision Benchmark",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Classifying all cells in an organ is a relevant and difficult problem from
plant developmental biology. We here abstract the problem into a new benchmark
for node classification in a geo-referenced graph. Solving it requires learning
the spatial layout of the organ including symmetries. To allow the convenient
testing of new geometrical learning methods, the benchmark of Arabidopsis
thaliana ovules is made available as a PyTorch data loader, along with a large
number of precomputed features. Finally, we benchmark eight recent graph neural
network architectures, finding that DeeperGCN currently works best on this
problem.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 08:08:19 GMT""}]","2022-05-18"
"2205.08167","Tianxiang Gou","Tianxiang Gou","Blowup of cylindrically symmetric solutions for biharmonic NLS","9 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider blowup of solutions to the Cauchy problem for the
following biharmonic NLS, $$ \textnormal{i} \, \partial_t u=\Delta^2 u-\mu
\Delta u-|u|^{2 \sigma} u \quad \text{in} \,\, \R \times \R^d, $$ where $d \geq
1$, $\mu \in \R$ and $0<\sigma<\infty$ if $1 \leq d \leq 4$ and
$0<\sigma<4/(d-4)$ if $d \geq 5$. In the mass critical and supercritical cases,
we establish the existence of blowup solutions to the problem for cylindrically
symmetric data. Our result extends the one obtained in \cite{BL}, where blowup
of solutions to the problem for radially symmetric data was considered.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 08:08:42 GMT""}]","2022-05-18"
"2205.08168","Mario Fuest","Mario Fuest, Shahin Heydari, Petr Knobloch, Johannes Lankeit, Thomas
  Wick","Global existence of classical solutions and numerical simulations of a
  cancer invasion model","43 pages, 16 figures",,,,"math.NA cs.NA math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study a cancer invasion model both theoretically and
numerically. The model is a nonstationary, nonlinear system of three coupled
partial differential equations modeling the motion of cancer cells, degradation
of the extracellular matrix, and certain enzymes. We first establish existence
of global classical solutions in both two- and three-dimensional bounded
domains, despite the lack of diffusion of the matrix-degrading enzymes and
corresponding regularizing effects in the analytical treatment. Next, we give a
weak formulation and apply finite differences in time and a Galerkin finite
element scheme for spatial discretization. The overall algorithm is based on a
fixed-point iteration scheme. In order to substantiate our theory and numerical
framework, several numerical simulations are carried out in two and three
spatial dimensions.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 08:12:36 GMT""}]","2022-05-18"
"2205.08169","Mamiya Kawaguchi","Mamiya Kawaguchi and Mei Huang","Restriction on the form of quark anomalous magnetic moment from lattice
  QCD results","14 pages, 13 figures",,"10.1088/1674-1137/acc641",,"hep-ph hep-lat nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The quark anomalous magnetic moment (AMM) is dynamically generated through
the spontaneous chiral symmetry breaking. It has been revealed that even though
its exact form is still unknown, the quark AMM is essential to explore quark
matter properties and QCD phase structure under external magnetic fields. In
this study, we take three different forms of the quark AMM and investigate its
influence on the chiral phase transition under magnetic field. In general, a
negative quark AMM plays the role as magnetic catalyzer and a positive quark
AMM plays the role of magnetic inhibition. It is found that a constant quark
AMM drives an unexpected 1st order chiral phase transition; a quark AMM
proportional to the chiral condensate gives a flip of the sign on the chiral
condensate; and a quark AMM proportional to the square of chiral condensate can
produce results of chiral condensate as functions of the temperature and the
magnetic field in good agreement with the lattice result.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 08:14:17 GMT""}]","2023-05-31"
"2205.08170","Victor Peterson II","Victor Peterson II","Pessimism and Cynicism as Physical Entities",,,,,"physics.soc-ph physics.hist-ph","http://creativecommons.org/licenses/by/4.0/","  Choosing pessimism makes one cynical to and necessitates their destruction of
information.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 08:18:33 GMT""}]","2022-05-18"
"2205.08171","Weikang Lin","Weikang Lin and Tsutomu Yanagida","Confronting the Galactic 511 keV emission with $B-L$ gauge boson dark
  matter","5 pages, 2 figure; matches version published in PRD","Phys. Rev. D 106, 075012 (2022)","10.1103/PhysRevD.106.075012",,"hep-ph astro-ph.CO astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The $B-L$ gauge symmetry motivated from the successful generation of the
seesaw mechanism and leptogenesis. We show that if the $B-L$ gauge boson
constitutes a small fraction of the dark matter (DM) it can explain the
Galactic $511$ keV emission via the decay into an electron-positron pair. We
find the model parameter space that is consistent with the seesaw mechanism,
cosmologically viable, and accounting for the amplitude of the Galactic
positron line. From this parameter space we derive an upper bound of the gauge
boson mass and then an bound of the positron injection energy $\lesssim3$ MeV.
This derived energy bound is consistent with the observational upper limit of
the injection energy. The resultant model predicts the $B-L$ breaking scale to
be in a relatively narrow range, i.e., $V_{B\textrm{--}L}\sim10^{15}
\textrm{--} 10^{16} $GeV, which is consistent with a Grand Unification (GUT)
scale seesaw mechanism. The model is consistent in several phenomenologies,
suggesting their common origin from the B-L symmetry breaking.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 08:19:19 GMT""},{""version"":""v2"",""created"":""Thu, 13 Oct 2022 11:04:48 GMT""}]","2022-10-14"
"2205.08172","Vladimir Lotoreichik","David Krejcirik, Vladimir Lotoreichik","Quasi-conical domains with embedded eigenvalues",,,,,"math.SP math-ph math.AP math.MP","http://creativecommons.org/licenses/by/4.0/","  The spectrum of the Dirichlet Laplacian on any quasi-conical open set
coincides with the non-negative semi-axis. We show that there is a connected
quasi-conical open set such that the respective Dirichlet Laplacian has a
positive (embedded) eigenvalue. This open set is constructed as the tower of
cubes of growing size connected by windows of vanishing size. Moreover, we show
that the sizes of the windows in this construction can be chosen so that the
absolutely continuous spectrum of the Dirichlet Laplacian is empty.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 08:21:24 GMT""}]","2022-05-18"
"2205.08173","Iv\'an Le\'on","Iv\'an Le\'on and Diego Paz\'o","Efficient moment-based approach to the simulation of infinitely many
  heterogeneous phase oscillators","12 pages, 9 figures","Chaos 32, 063124 (2022)","10.1063/5.0093001",,"nlin.AO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The dynamics of ensembles of phase oscillators are usually described
considering their infinite-size limit. In practice, however, this limit is
fully accessible only if the Ott-Antonsen theory can be applied, and the
heterogeneity is distributed following a rational function. In this work we
demonstrate the usefulness of a moment-based scheme to reproduce the dynamics
of infinitely many oscillators. Our analysis is particularized for Gaussian
heterogeneities, leading to a FourierHermite decomposition of the oscillator
density. The Fourier-Hermite moments obey a set of hierarchical ordinary
differential equations. As a preliminary experiment, the effects of truncating
the moment system and implementing different closures are tested in the
analytically solvable Kuramoto model. The moment-based approach proves to be
much more efficient than the direct simulation of a large oscillator ensemble.
The convenience of the moment-based approach is exploited in two illustrative
examples: (i) the Kuramoto model with bimodal frequency distribution, and (ii)
the 'enlarged Kuramoto model' (endowed with nonpairwise interactions). In both
systems we obtain new results inaccessible through direct numerical integration
of populations.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 08:23:17 GMT""},{""version"":""v2"",""created"":""Wed, 18 May 2022 10:31:44 GMT""}]","2022-10-11"
"2205.08174","Matt Sampson","Matt L. Sampson, James R. Beattie, Mark R. Krumholz, Roland M.
  Crocker, Christoph Federrath and Amit Seta","Turbulent diffusion of streaming cosmic rays in compressible, partially
  ionised plasma","Accepted in MNRAS",,"10.1093/mnras/stac3207",,"astro-ph.GA astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Cosmic rays (CRs) are a dynamically important component of the interstellar
medium (ISM) of galaxies. The $\sim$GeV CRs that carry most CR energy and
pressure are likely confined by self-generated turbulence, leading them to
stream along magnetic field lines at the ion Alfv\'en speed. However, the
consequences of self-confinement for CR propagation on galaxy scales remain
highly uncertain. In this paper, we use a large ensemble of
magnetohydrodynamical turbulence simulations to quantify how the basic
parameters describing ISM turbulence -- the sonic Mach number, $\mathcal{M}$
(plasma compressibility), Alfv\'en Mach number, $\mathcal{M}_{A0}$ (strength of
the large-scale field with respect to the turbulence), and ionisation fraction
by mass, $\chi$ -- affect the transport of streaming CRs. We show that the
large-scale transport of CRs whose small-scale motion consists of streaming
along field lines is well described as a combination of streaming along the
mean field and superdiffusion both along (parallel to) and across
(perpendicular to) it; $\mathcal{M}_{A0}$ drives the level of anisotropy
between parallel and perpendicular diffusion and $\chi$ modulates the magnitude
of the diffusion coefficients, while in our choice of units, $\mathcal{M}$ is
unimportant except in the sub-Alfv\'enic ($\mathcal{M}_{A0} \lesssim 0.5$)
regime. Our finding that superdiffusion is ubiquitous potentially explains the
apparent discrepancy between CR diffusion coefficients inferred from
measurements close to individual sources compared to those measured on larger,
Galactic scales. Finally, we present empirical fits for the diffusion
coefficients as a function of plasma parameters that may be used as sub-grid
recipes for global interstellar medium, galaxy or cosmological simulations.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 08:26:16 GMT""},{""version"":""v2"",""created"":""Thu, 3 Nov 2022 17:47:45 GMT""}]","2022-11-16"
"2205.08175","Nathana\""el Fijalkow","Nathana\""el Fijalkow, Cristian Riveros, James Worrell","Probabilistic Automata of Bounded Ambiguity","Short version in CONCUR'17, Long version in Information and
  Computation (special issue on Weighted Automata)","Information and Computation, Volume 282, January 2022, 104648","10.1016/j.ic.2020.104648",,"cs.FL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Probabilistic automata are an extension of nondeterministic finite automata
in which transitions are annotated with probabilities. Despite its simplicity,
this model is very expressive and many of the associated algorithmic questions
are undecidable. In this work we focus on the emptiness problem (and its
variant the value problem), which asks whether a given probabilistic automaton
accepts some word with probability greater than a given threshold. We consider
a natural and well-studied structural restriction on automata, namely the
degree of ambiguity, which is defined as the maximum number of accepting runs
over all words. The known undecidability proofs exploits infinite ambiguity and
so we focus on the case of finitely ambiguous probabilistic automata. Our main
contributions are to construct efficient algorithms for analysing finitely
ambiguous probabilistic automata through a reduction to a multi-objective
optimisation problem called the stochastic path problem. We obtain a polynomial
time algorithm for approximating the value of probabilistic automata of fixed
ambiguity and a quasi-polynomial time algorithm for the emptiness problem for
2-ambiguous probabilistic automata. We complement these positive results by an
inapproximability result stating that the value of finitely ambiguous
probabilistic automata cannot be approximated unless PTIME = NP.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 08:37:40 GMT""},{""version"":""v2"",""created"":""Thu, 19 May 2022 12:32:59 GMT""}]","2022-05-20"
"2205.08176","Dachao Lin","Dachao Lin, Zhihua Zhang","On the Convergence of Policy in Unregularized Policy Mirror Descent",,,,,"math.OC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this short note, we give the convergence analysis of the policy in the
recent famous policy mirror descent (PMD). We mainly consider the unregularized
setting following [11] with generalized Bregman divergence. The difference is
that we directly give the convergence rates of policy under generalized Bregman
divergence. Our results are inspired by the convergence of value function in
previous works and are an extension study of policy mirror descent. Though some
results have already appeared in previous work, we further discover a large
body of Bregman divergences could give finite-step convergence to an optimal
policy, such as the classical Euclidean distance.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 08:49:41 GMT""},{""version"":""v2"",""created"":""Thu, 19 May 2022 11:59:54 GMT""}]","2022-05-20"
"2205.08177","Anton Bochkarev S","Anton Bochkarev, Yury Lysogorskiy, Christoph Ortner, G\'abor Cs\'anyi,
  Ralf Drautz","Multilayer atomic cluster expansion for semi-local interactions",,,"10.1103/PhysRevResearch.4.L042019",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Traditionally, interatomic potentials assume local bond formation
supplemented by long-range electrostatic interactions when necessary. This
ignores intermediate range multi-atom interactions that arise from the
relaxation of the electronic structure. Here, we present the multilayer atomic
cluster expansion (ml-ACE) that includes collective, semi-local multi-atom
interactions naturally within its remit. We demonstrate that ml-ACE
significantly improves fit accuracy compared to a local expansion on selected
examples and provide physical intuition to understand this improvement.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 08:55:08 GMT""}]","2022-11-07"
"2205.08178","Tue Herlau Mr","Tue Herlau","Active learning of causal probability trees",,,,,"cs.LG stat.ME","http://creativecommons.org/licenses/by/4.0/","  The past two decades have seen a growing interest in combining causal
information, commonly represented using causal graphs, with machine learning
models. Probability trees provide a simple yet powerful alternative
representation of causal information. They enable both computation of
intervention and counterfactuals, and are strictly more general, since they
allow context-dependent causal dependencies. Here we present a Bayesian method
for learning probability trees from a combination of interventional and
observational data. The method quantifies the expected information gain from an
intervention, and selects the interventions with the largest gain. We
demonstrate the efficiency of the method on simulated and real data. An
effective method for learning probability trees on a limited interventional
budget will greatly expand their applicability.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 08:56:34 GMT""}]","2022-05-18"
"2205.08179","Jyotirmoy Mukherjee Mukherjee","Jyotirmoy Mukherjee","Pseudo Entropy in $U(1)$ gauge theory","30 pages, 10 figures",,"10.1007/JHEP10(2022)016",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the properties of pseudo entropy, a new generalization of
entanglement entropy, in free Maxwell field theory in $d = 4$ dimension. We
prepare excited states by the different components of the field strengths
located at different Euclidean times acting on the vacuum. We compute the
difference between the pseudo R\'{e}nyi entropy and the R\'{e}nyi entropy of
the ground state and observe that the difference changes significantly near the
boundary of the subsystems and vanishes far away from the boundary. Near the
boundary of the subsystems, the difference between pseudo R\'{e}nyi entropy and
R\'{e}nyi entropy of the ground state depends on the ratio of the two Euclidean
times where the operators are kept. To begin with, we develop the method to
evaluate pseudo entropy of conformal scalar field in $d=4$ dimension. We
prepare two states by two operators with fixed conformal weight acting on the
vacuum and observe that the difference between pseudo R\'{e}nyi entropy and
ground state R\'{e}nyi entropy changes only near the boundary of the
subsystems. We also show that a suitable analytical continuation of pseudo
R\'{e}nyi entropy leads to the evaluation of real-time evolution of R\'{e}nyi
entropy during quenches.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 08:58:22 GMT""}]","2022-10-19"
"2205.08180","Antoine Laurent","Sameer Khurana and Antoine Laurent and James Glass","SAMU-XLSR: Semantically-Aligned Multimodal Utterance-level Cross-Lingual
  Speech Representation",,,"10.1109/JSTSP.2022.3192714",,"cs.CL cs.LG cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose the SAMU-XLSR: Semantically-Aligned Multimodal Utterance-level
Cross-Lingual Speech Representation learning framework. Unlike previous works
on speech representation learning, which learns multilingual contextual speech
embedding at the resolution of an acoustic frame (10-20ms), this work focuses
on learning multimodal (speech-text) multilingual speech embedding at the
resolution of a sentence (5-10s) such that the embedding vector space is
semantically aligned across different languages. We combine state-of-the-art
multilingual acoustic frame-level speech representation learning model XLS-R
with the Language Agnostic BERT Sentence Embedding (LaBSE) model to create an
utterance-level multimodal multilingual speech encoder SAMU-XLSR. Although we
train SAMU-XLSR with only multilingual transcribed speech data, cross-lingual
speech-text and speech-speech associations emerge in its learned representation
space. To substantiate our claims, we use SAMU-XLSR speech encoder in
combination with a pre-trained LaBSE text sentence encoder for cross-lingual
speech-to-text translation retrieval, and SAMU-XLSR alone for cross-lingual
speech-to-speech translation retrieval. We highlight these applications by
performing several cross-lingual text and speech translation retrieval tasks
across several datasets.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 08:58:48 GMT""}]","2022-11-23"
"2205.08181","Raphael Steiner","Man-Kwun Chiu, Stefan Felsner, Manfred Scheucher, Felix Schr\""oder,
  Raphael Steiner, Birgit Vogtenhuber","Coloring circle arrangements: New $4$-chromatic planar graphs","21 pages, 15 figures. An extended abstract of this work has appeared
  in the proceedings of EUROCOMB 2021",,,,"math.CO cs.CG cs.DM","http://creativecommons.org/licenses/by/4.0/","  Felsner, Hurtado, Noy and Streinu (2000) conjectured that arrangement graphs
of simple great-circle arrangements have chromatic number at most $3$.
Motivated by this conjecture, we study the colorability of arrangement graphs
for different classes of arrangements of (pseudo-)circles.
  In this paper the conjecture is verified for $\triangle$-saturated
pseudocircle arrangements, i.e., for arrangements where one color class of the
2-coloring of faces consists of triangles only, as well as for further classes
of (pseudo-)circle arrangements. These results are complemented by a
construction which maps $\triangle$-saturated arrangements with a pentagonal
face to arrangements with 4-chromatic 4-regular arrangement graphs. This
""corona"" construction has similarities with the crowning construction
introduced by Koester (1985). Based on exhaustive experiments with small
arrangements we propose three strengthenings of the original conjecture.
  We also investigate fractional colorings. It is shown that the arrangement
graph of every arrangement $\mathcal{A}$ of pairwise intersecting pseudocircles
is ""close"" to being $3$-colorable. More precisely, the fractional chromatic
number $\chi_f(\mathcal{A})$ of the arrangement graph is bounded from above by
$\chi_f(\mathcal{A}) \le 3+O(\frac{1}{n})$, where $n$ is the number of
pseudocircles of $\mathcal{A}$. Furthermore, we construct an infinite family of
$4$-edge-critical $4$-regular planar graphs which are fractionally
$3$-colorable. This disproves a conjecture of Gimbel, K\""{u}ndgen, Li, and
Thomassen (2019).
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:03:24 GMT""}]","2022-05-18"
"2205.08182","Hua-Cheng Zhou","Ze-Hao Wu, Hua-Cheng Zhou, Bao-Zhu Guo, and Feiqi Deng","On Convergence of Tracking Differentiator with Multiple Stochastic
  Disturbances",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, the convergence and noise-tolerant performance of a tracking
differentiator in the presence of multiple stochastic disturbances are
investigated for the first time. We consider a quite general case where the
input signal is corrupted by additive colored noise, and the tracking
differentiator itself is disturbed by additive colored noise and white noise.
It is shown that the tracking differentiator tracks the input signal and its
generalized derivatives in mean square and even in almost sure sense when the
stochastic noise affecting the input signal is vanishing. Some numerical
simulations are performed to validate the theoretical results.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:05:34 GMT""}]","2022-05-18"
"2205.08183","Parth Chavan","Parth Chavan","Hurwitz Zeta Functions and Ramanujan's Identity for Odd Zeta Values",,,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  Inspired by a famous formula of Ramanujan for odd zeta values, we prove an
analogous formula involving the Hurwitz zeta function. We introduce a new
integral kernel related to the Hurwitz zeta function, generalizing the integral
kernel associated to Ramanujan's identity. We also derive several infinite
families of identities analogous to Ramanujan's formula.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:10:57 GMT""}]","2022-05-18"
"2205.08184","Zhe Dong","Fedor Moiseev, Zhe Dong, Enrique Alfonseca, Martin Jaggi","SKILL: Structured Knowledge Infusion for Large Language Models","NAACL 2022",,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Large language models (LLMs) have demonstrated human-level performance on a
vast spectrum of natural language tasks. However, it is largely unexplored
whether they can better internalize knowledge from a structured data, such as a
knowledge graph, or from text. In this work, we propose a method to infuse
structured knowledge into LLMs, by directly training T5 models on factual
triples of knowledge graphs (KGs). We show that models pre-trained on Wikidata
KG with our method outperform the T5 baselines on FreebaseQA and WikiHop, as
well as the Wikidata-answerable subset of TriviaQA and NaturalQuestions. The
models pre-trained on factual triples compare competitively with the ones on
natural language sentences that contain the same knowledge. Trained on a
smaller size KG, WikiMovies, we saw 3x improvement of exact match score on
MetaQA task compared to T5 baseline. The proposed method has an advantage that
no alignment between the knowledge graph and text corpus is required in
curating training data. This makes our method particularly useful when working
with industry-scale knowledge graphs.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:12:22 GMT""}]","2022-05-18"
"2205.08185","Bin Wang","Bin Wang, Yaolin Jiang","Optimally accurate integrators with long time conservation for highly
  oscillatory second-order differential equations",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we are concerned with optimally accurate integrators for
highly oscillatory second-order differential equations
$\ddot{q}(t)+\frac{1}{\varepsilon^2}A q(t) =\frac{1}{\varepsilon^m}F(q(t))$
with large initial data, a scaling parameter $0<\varepsilon\ll 1$ and $m=0,1$.
The highly oscillatory property of this model problem corresponds to the
parameter $\varepsilon$. We propose and analyze a novel class of highly
accurate integrators which is based on some formulation approaches to the
problem, Fourier pseudo-spectral method and exponential integrators. Two
practical integrators up to order four are constructed by using the proposed
symmetric property and stiff order conditions of implicit exponential
integrators. The convergence of the obtained integrators is rigorously studied,
and it is shown that the accuracy is improved to be
$\mathcal{O}(\varepsilon^{r-rm} h^r)$ in the absolute position error for the
time stepsize $h$ and the order $r$ of the integrator. The near energy
conservation over long times is established for the multi-stage integrators by
using modulated Fourier expansions. These theoretical results are achievable
even if large stepsizes are utilized in the schemes. Numerical results on the
Duffing equation and a nonlinear relativistic Klein--Gordon equation show that
the proposed integrators used with large stepsizes have optimal uniformly high
accuracy, excellent long time energy conservation and competitive efficiency.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:12:32 GMT""},{""version"":""v2"",""created"":""Mon, 5 Dec 2022 13:43:58 GMT""},{""version"":""v3"",""created"":""Tue, 17 Jan 2023 15:55:43 GMT""}]","2023-01-18"
"2205.08186","Xiazhi Hao","Xiazhi Hao and S. Y. Lou","Multi-component decompositions, linear superpositions, and new nonlinear
  integrable coupled KdV-type systems","17 pages, 0 figures",,,,"nlin.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The existence of decompositions of the nonlinear integrable systems not only
permits us to establish so-called linear superposition solutions but also to
derive new nonlinear integrable coupled systems. Restricting our attention to
the single component decompositions of the potential BKP hierarchy, we obtain
that suitable linear superpositions of some decomposition solutions still
satisfy the same equations. In parallel, successful attempts are made by
multi-component decompositions of the potential BKP hierarchy to construct
linear superposition solutions and new nonlinear integrable coupled KdV-type
systems that a change of dependent variables cannot decouple.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:12:51 GMT""}]","2022-05-18"
"2205.08187","Hoil Lee","Hoil Lee, Fadhel Ayed, Paul Jung, Juho Lee, Hongseok Yang and
  Fran\c{c}ois Caron","Deep neural networks with dependent weights: Gaussian Process mixture
  limit, heavy tails, sparsity and compressibility","89 pages, 11 figures, 7 tables",,,,"stat.ML cs.LG math.PR math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article studies the infinite-width limit of deep feedforward neural
networks whose weights are dependent, and modelled via a mixture of Gaussian
distributions. Each hidden node of the network is assigned a nonnegative random
variable that controls the variance of the outgoing weights of that node. We
make minimal assumptions on these per-node random variables: they are iid and
their sum, in each layer, converges to some finite random variable in the
infinite-width limit. Under this model, we show that each layer of the
infinite-width neural network can be characterised by two simple quantities: a
non-negative scalar parameter and a L\'evy measure on the positive reals. If
the scalar parameters are strictly positive and the L\'evy measures are trivial
at all hidden layers, then one recovers the classical Gaussian process (GP)
limit, obtained with iid Gaussian weights. More interestingly, if the L\'evy
measure of at least one layer is non-trivial, we obtain a mixture of Gaussian
processes (MoGP) in the large-width limit. The behaviour of the neural network
in this regime is very different from the GP regime. One obtains correlated
outputs, with non-Gaussian distributions, possibly with heavy tails.
Additionally, we show that, in this regime, the weights are compressible, and
feature learning is possible. Many sparsity-promoting neural network models can
be recast as special cases of our approach, and we discuss their infinite-width
limits; we also present an asymptotic analysis of the pruning error. We
illustrate some of the benefits of the MoGP regime over the GP regime in terms
of representation learning and compressibility on simulated, MNIST and Fashion
MNIST datasets.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:14:32 GMT""}]","2022-05-18"
"2205.08188","Madjid Hadjal","Madjid Hadjal (1), Encarni Medina-L\'opez (2), Jinchang Ren (3),
  Alejandro Gallego (4), David McKee (1,5) ((1) Physics Department, University
  of Strathclyde, Glasgow, UK, (2) Institute for Infrastructure and
  Environment, School of Engineering, The University of Edinburgh, The King's
  Buildings, Edinburgh, UK, (3) Department of Computing Sciences, Robert Gordon
  University of Aberdeen, UK, (4) Marine Laboratory Aberdeen, Marine Scotland
  Science, Aberdeen, UK, (5) Department of Arctic and Marine Biology, UiT the
  Arctic University of Norway, Troms{\o}, Norway)","An Artificial Neural Network Algorithm to Retrieve Chlorophyll a for
  Northwest European Shelf Seas from Top of Atmosphere Ocean Colour Reflectance","27 pages, 12 figures",,,,"physics.ao-ph","http://creativecommons.org/licenses/by/4.0/","  Chlorophyll-a (Chl) retrieval from ocean colour remote sensing is problematic
for relatively turbid coastal waters due to the impact of non-algal materials
on atmospheric correction and standard Chl algorithm performance. Artificial
neural networks (NNs) provide an alternative approach for retrieval of Chl from
space and results in northwest European shelf seas over the 2002-2020 period
are shown. The NNs operate on 15 MODIS-Aqua visible and infrared bands and are
tested using bottom of atmosphere (BOA), top of atmosphere (TOA) and Rayleigh
corrected TOA reflectances (RC). In each case, a NN architecture consisting of
3 layers of 15 neurons improved performances and data availability compared to
current state-of-the-art algorithms used in the region. The NN operating on TOA
reflectance outperformed BOA and RC versions. By operating on TOA reflectance
data, the NN approach overcomes the common but difficult problem of atmospheric
correction in coastal waters. Moreover, the NN provides data for regions which
other algorithms often mask out for turbid water or low zenith angle flags. A
distinguishing feature of the NN approach is generation of associated product
uncertainties based on multiple resampling of the training data set to produce
a distribution of values for each pixel, and an example is shown for a coastal
time series in the North Sea. The final output of the NN approach consists of a
best-estimate image based on medians for each pixel and a second image
representing uncertainty based on standard deviation for each pixel, providing
pixel-specific estimates of uncertainty in the final product.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:15:50 GMT""}]","2022-05-18"
"2205.08189","Alex Coninx","Aur\'elien Morel, Yakumo Kunimoto, Alex Coninx and St\'ephane Doncieux","Automatic Acquisition of a Repertoire of Diverse Grasping Trajectories
  through Behavior Shaping and Novelty Search","7 pages, 9 figures, accepted at ICRA 2022. Annex video available at
  https://youtu.be/bqqQepJAOKQ",,,,"cs.RO cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Grasping a particular object may require a dedicated grasping movement that
may also be specific to the robot end-effector. No generic and autonomous
method does exist to generate these movements without making hypotheses on the
robot or on the object. Learning methods could help to autonomously discover
relevant grasping movements, but they face an important issue: grasping
movements are so rare that a learning method based on exploration has little
chance to ever observe an interesting movement, thus creating a bootstrap
issue. We introduce an approach to generate diverse grasping movements in order
to solve this problem. The movements are generated in simulation, for
particular object positions. We test it on several simulated robots: Baxter,
Pepper and a Kuka Iiwa arm. Although we show that generated movements actually
work on a real Baxter robot, the aim is to use this method to create a large
dataset to bootstrap deep learning methods.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:17:31 GMT""}]","2022-05-18"
"2205.08190","Luis Eduardo Sola Conde","Gianluca Occhetta, Eleonora A. Romano, Luis E. Sol\'a Conde,
  Jaros{\l}aw A. Wi\'sniewski","Geometric realizations of birational transformations via
  $\mathbb{C}^*$-actions",,,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study varieties admitting torus actions as geometric
realizations of birational transformations. We present an explicit construction
of these geometric realizations for a particular class of birational
transformations, and study some of their geometric properties, such as their
Mori, Nef and Movable cones.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:20:16 GMT""},{""version"":""v2"",""created"":""Wed, 31 Aug 2022 12:45:30 GMT""}]","2022-09-01"
"2205.08191","Bin Wang","Bin Wang, Yaolin Jiang","Semi-discretization and full-discretization with optimal accuracy for
  charged-particle dynamics in a strong nonuniform magnetic field",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim of this paper is to formulate and analyze numerical discretizations
of charged-particle dynamics (CPD) in a strong nonuniform magnetic field. A
strategy is firstly performed for the two dimensional CPD to construct the
semi-discretization and full-discretization which have optimal accuracy. This
accuracy is improved in the position and in the velocity when the strength of
the magnetic field becomes stronger. This is a better feature than the usual so
called ""uniformly accurate methods"". To obtain this refined accuracy, some
reformulations of the problem and two-scale exponential integrators are
incorporated, and the optimal accuracy is derived from this new procedure. Then
based on the strategy given for the two dimensional case, a new class of
uniformly accurate methods with simple scheme is formulated for the three
dimensional CPD in maximal ordering case. All the theoretical results of the
accuracy are numerically illustrated by some numerical tests.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:23:01 GMT""}]","2022-05-18"
"2205.08192","Tue Herlau Mr","Tue Herlau","Moral reinforcement learning using actual causation",,,,,"cs.LG cs.AI cs.CY","http://creativecommons.org/licenses/by/4.0/","  Reinforcement learning systems will to a greater and greater extent make
decisions that significantly impact the well-being of humans, and it is
therefore essential that these systems make decisions that conform to our
expectations of morally good behavior. The morally good is often defined in
causal terms, as in whether one's actions have in fact caused a particular
outcome, and whether the outcome could have been anticipated. We propose an
online reinforcement learning method that learns a policy under the constraint
that the agent should not be the cause of harm. This is accomplished by
defining cause using the theory of actual causation and assigning blame to the
agent when its actions are the actual cause of an undesirable outcome. We
conduct experiments on a toy ethical dilemma in which a natural choice of
reward function leads to clearly undesirable behavior, but our method learns a
policy that avoids being the cause of harmful behavior, demonstrating the
soundness of our approach. Allowing an agent to learn while observing causal
moral distinctions such as blame, opens the possibility to learning policies
that better conform to our moral judgments.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:25:51 GMT""}]","2022-05-18"
"2205.08193","Graeme Stewart","Graeme A Stewart, Peter Elmer, Elizabeth Sexton-Kennedy (for the HEP
  Software Foundation)","The HEP Software Foundation Community",,,,"HSF-DOC-2022-01","physics.comp-ph cs.SE","http://creativecommons.org/licenses/by/4.0/","  The HEP Software Foundation was founded in 2014 to tackle common problems of
software development and sustainability for high-energy physics. In this paper
we outline the motivation for the founding of the organisation and give a brief
history of its development. We describe how the organisation functions today
and what challenges remain to be faced in the future.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:28:00 GMT""}]","2022-05-18"
"2205.08194","Francesco Ferrante","Suha Shreim and Francesco Ferrante and Christophe Prieur","Design of saturated boundary control for hyperbolic systems with
  in-domain disturbances","V1 matches the printed version of the paper published in Automatica","Automatica, Volume 142, 2022","10.1016/j.automatica.2022.110346",,"math.OC cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Boundary feedback control design is studied for 1D hyperbolic systems with an
in-domain disturbance and a boundary feedback controller under the effect of
actuator saturation. Nonlinear semigroup theory is used to prove well-posedness
of mild solution pairs to the closed-loop system. Sufficient conditions in the
form of dissipation functional inequalities are derived to establish global
stability for the closed-loop system and $\mathcal{L}^2$-stability in presence
of in-domain disturbances. The control design problem is then recast as an
optimization problem over linear matrix inequality constraints. Numerical
results are shown to validate the effectiveness of the proposed control design.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:30:35 GMT""}]","2022-05-18"
"2205.08195","David Nicolas Nenning","David Nicolas Nenning, Armin Rainer, Gerhard Schindl","The Borel map in the mixed Beurling setting","33 pages; some typos corrected","Rev. R. Acad. Cienc. Exactas F\'is. Nat. Ser. A Mat. RACSAM, no.
  117, art. no. 40, 2023","10.1007/s13398-022-01372-9",,"math.FA math.CA math.CV","http://creativecommons.org/licenses/by/4.0/","  The Borel map takes a smooth function to its infinite jet of derivatives (at
zero). We study the restriction of this map to ultradifferentiable classes of
Beurling type in a very general setting which encompasses the classical
Denjoy-Carleman and Braun-Meise-Taylor classes. More precisely, we characterize
when the Borel image of one class covers the sequence space of another class in
terms of the two weights that define the classes. We present two independent
solutions to this problem, one by reduction to the Roumieu case and the other
by dualization of the involved Fr\'echet spaces, a Phragm\'en-Lindel\""of
theorem, and H\""ormander's solution of the $\bar{\partial}$-problem.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:36:33 GMT""},{""version"":""v2"",""created"":""Wed, 7 Dec 2022 12:02:24 GMT""}]","2022-12-29"
"2205.08196","Lyle Ramshaw","Lyle Ramshaw","The Bring sextic of equilateral pentagons","37 pages and 17 figures, with Mathematica appendix of 33 pages",,,,"math.MG math.DG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Consider equilateral pentagons $V_1,\ldots,V_5$ in the Euclidean plane. When
we identify pentagons that differ by translation, rotation, and magnification,
the moduli space of possible shapes that we get is an oft-studied polygon
space: a 2-manifold $E_5$ known topologically to be a quadruple torus (genus
4). We study $E_5$ geometrically, our goal being a conformal map of that
terrain of possible shapes. The differential geometry that we use is all due to
Gauss, though much of it is named after his student Riemann.
  The manifold $E_5$ inherits a Riemannian metric from the Grassmannian
approach of Hausmann and Knutson, a metric $e_5$ under which $E_5$ has 240
isometries: an optional reflection combined with any permutation of the order
in which the five edge vectors $V_{k+1}-V_k$ get assembled into a pentagon.
Giving $E_5$ the conformal structure imposed by $e_5$ yields a compact Riemann
surface of genus 4 with 120 automorphisms: the 120 isometries that preserve
orientation. But there is only one Riemann surface with those properties: the
Bring sextic. So $(E_5, e_5)$ conformally embeds in the hyperbolic plane, like
the Bring sextic, as a repeating pattern of 240 triangles, each with vertex
angles of $\frac{\pi}{2}$, $\frac{\pi}{4}$, and $\frac{\pi}{5}$. That conformal
map realizes our goal.
  To plot pentagons on our map, we compute an initial pair of isothermal
coordinates for $E_5$ by solving the Beltrami equation \`a la Gauss. We then
use a conformal mapping to convert one of those isothermal triangular regions
into a Poincar\'e projection of a $(\frac{\pi}{2},\frac{\pi}{4},\frac{\pi}{5})$
hyperbolic triangle.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:37:46 GMT""}]","2022-05-18"
"2205.08197","Song Jin Ri","Song Jin Ri","Refined and Generalized $\hat{Z}$ Invariants for Plumbed 3-Manifolds",,"SIGMA 19 (2023), 011, 27 pages","10.3842/SIGMA.2023.011",,"math.GT hep-th math-ph math.MP math.NT math.QA","http://creativecommons.org/licenses/by-sa/4.0/","  We introduce a two-variable refinement $\hat{Z}_a(q,t)$ of plumbed 3-manifold
invariants $\hat{Z}_a(q)$, which were previously defined for weakly negative
definite plumbed 3-manifolds. We also provide a number of explicit examples in
which we argue the recovering process to obtain $\hat{Z}_a(q)$ from
$\hat{Z}_a(q,t)$ by taking a limit $ t\rightarrow 1 $. For plumbed 3-manifolds
with two high-valency vertices, we analytically compute the limit by using the
explicit integer solutions of quadratic Diophantine equations in two variables.
Based on numerical computations of the recovered $\hat{Z}_a(q)$ for plumbings
with two high-valency vertices, we propose a conjecture that the recovered
$\hat{Z}_a(q)$, if exists, is an invariant for all tree plumbed 3-manifolds.
Finally, we provide a formula of the $\hat{Z}_a(q,t)$ for the connected sum of
plumbed 3-manifolds in terms of those for the components.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:39:07 GMT""},{""version"":""v2"",""created"":""Fri, 2 Sep 2022 13:19:25 GMT""},{""version"":""v3"",""created"":""Tue, 6 Dec 2022 16:20:10 GMT""},{""version"":""v4"",""created"":""Mon, 20 Feb 2023 09:50:50 GMT""},{""version"":""v5"",""created"":""Sun, 19 Mar 2023 09:50:36 GMT""}]","2023-03-21"
"2205.08198","Naveen Sisodia","Naveen Sisodia (1), Johan Pelloux-Prayer (1), Liliana D.
  Buda-Prejbeanu (1), Lorena Anghel (1), Gilles Gaudin (1), Olivier Boulle (1)
  ((1) Univ. Grenoble Alpes, CNRS, CEA, SPINTEC, Grenoble, France)","Programmable skyrmion logic gates based on skyrmion tunneling",,"Phys. Rev. Applied 17, 064035 (2022)","10.1103/PhysRevApplied.17.064035",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Magnetic skyrmions are promising candidates as elementary nanoscale bits in
logic-in-memory devices, intrinsically merging high density memory and
computing capabilities. Here we exploit the dynamics of skyrmions interacting
with anisotropy energy barriers patterned by ion irradiation to design
programmable logic gates. Using micromagnetic simulations with experimental
parameters, we show that a fine tuning of the barrier height and width allows
the selective tunneling of skyrmions between parallel nanotracks triggered by
skyrmion-skyrmion interaction. This can be leveraged to design skyrmion
De-multiplexer (DMux) logic gate which works solely using skyrmions as logic
inputs. By cascading and connecting demultiplexer gates with a specific
topology, we develop a fully programmable logic gate capable of producing any
possible logic output as a sum of all minterms generated by a given set of
inputs without requiring any complex additional electric/magnetic
interconversion. The proposed design is fully conservative and cascadable and
paves a new pathway for full skyrmionic-based logic-in-memory devices.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:41:33 GMT""}]","2022-09-07"
"2205.08199","Mohammad Hossein Amani","Mohammad Hossein Amani, Simone Bombari, Marco Mondelli, Rattana
  Pukdee, Stefano Rini","Sharp asymptotics on the compression of two-layer neural networks",,,,,"cs.IT cs.LG math.IT stat.ML","http://creativecommons.org/licenses/by/4.0/","  In this paper, we study the compression of a target two-layer neural network
with N nodes into a compressed network with M<N nodes. More precisely, we
consider the setting in which the weights of the target network are i.i.d.
sub-Gaussian, and we minimize the population L_2 loss between the outputs of
the target and of the compressed network, under the assumption of Gaussian
inputs. By using tools from high-dimensional probability, we show that this
non-convex problem can be simplified when the target network is sufficiently
over-parameterized, and provide the error rate of this approximation as a
function of the input dimension and N. In this mean-field limit, the simplified
objective, as well as the optimal weights of the compressed network, does not
depend on the realization of the target network, but only on expected scaling
factors. Furthermore, for networks with ReLU activation, we conjecture that the
optimum of the simplified optimization problem is achieved by taking weights on
the Equiangular Tight Frame (ETF), while the scaling of the weights and the
orientation of the ETF depend on the parameters of the target network.
Numerical evidence is provided to support this conjecture.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:45:23 GMT""},{""version"":""v2"",""created"":""Wed, 18 May 2022 08:57:56 GMT""},{""version"":""v3"",""created"":""Sat, 13 Aug 2022 06:48:46 GMT""},{""version"":""v4"",""created"":""Tue, 16 Aug 2022 04:53:30 GMT""}]","2022-08-17"
"2205.08200","Naveen Sisodia","Naveen Sisodia (1), Johan Pelloux-Prayer (1), Liliana D.
  Buda-Prejbeanu (1), Lorena Anghel (1), Gilles Gaudin (1), Olivier Boulle (1)
  ((1) Univ. Grenoble Alpes, CNRS, CEA, SPINTEC, Grenoble, France)","Robust and programmable logic-in-memory devices exploiting skyrmion
  confinement and channeling using local energy barriers",,"Phys. Rev. Applied 18, 014025 (2022)","10.1103/PhysRevApplied.18.014025",,"cond-mat.mes-hall physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Magnetic skyrmions are promising candidates for logic-in-memory applications,
intrinsically merging high density non-volatile data storage with computing
capabilities, owing to their nanoscale size, fast motion, and mutual
repulsions. However, concepts proposed so far suffer from reliability issues as
well as inefficient conversion of magnetic information to electrical signals.
In this paper, we propose a logic-in-memory device which exploits skyrmion
confinement and channeling using anisotropy energy barriers to achieve reliable
data storage and synchronous shift in racetracks combined with cascadable and
reprogrammable logics relying purely on magnetic interactions. The device
combines a racetrack shift register based on skyrmions confined in nanodots
with Full Adder (FA) gates. The designed FA is reprogrammable and cascadable
and can also be used to perform simple logic operations such as AND, OR, NOT,
NAND, XOR and NXOR. The monolithic design of the logic gate and the absence of
any complex electrical contacts makes the device ideal for integration with
conventional CMOS circuitry.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:46:47 GMT""}]","2022-09-07"
"2205.08201","Dennis Hendriks","Dennis Hendriks (1 and 2), Arjan van der Meer (1 and 3), Wytse
  Oortwijn (1) ((1) ESI (TNO), Eindhoven, The Netherlands, (2) Radboud
  University, Nijmegen, The Netherlands, (3) Capgemini Engineering, Eindhoven,
  The Netherlands)","A Multi-level Methodology for Behavioral Comparison of
  Software-Intensive Systems","21 pages, 13 figures, submitted to FMICS 2022",,,,"cs.SE cs.FL","http://creativecommons.org/licenses/by/4.0/","  Software-intensive systems constantly evolve. To prevent software changes
from unintentionally introducing costly system defects, it is important to
understand their impact to reduce risk. However, it is in practice nearly
impossible to foresee the full impact of software changes when dealing with
huge industrial systems with many configurations and usage scenarios. To assist
developers with change impact analysis we introduce a novel multi-level
methodology for behavioral comparison of software-intensive systems. Our fully
automated methodology is based on comparing state machine models of software
behavior. We combine existing complementary comparison methods into a novel
approach, guiding users step by step though relevant differences by gradually
zooming into more and more detail. We empirically evaluate our work through a
qualitative exploratory field study, showing its practical value using multiple
case studies at ASML, a leading company in developing lithography systems. Our
method shows great potential for preventing regressions in system behavior for
software changes.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:47:11 GMT""}]","2022-05-18"
"2205.08202","Barbara Ulrike Sch\""utt","Barbara Sch\""utt, Marc Heinrich, Sonja Marahrens, J. Marius Z\""ollner,
  Eric Sax","An Application of Scenario Exploration to Find New Scenarios for the
  Development and Testing of Automated Driving Systems in Urban Scenarios","Proceedings of the 8th International Conference on Vehicle Technology
  and Intelligent Transport Systems (VEHITS 2022)",,"10.5220/0011064600003191",,"cs.SE cs.LG cs.RO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Verification and validation are major challenges for developing automated
driving systems. A concept that gets more and more recognized for testing in
automated driving is scenario-based testing. However, it introduces the problem
of what scenarios are relevant for testing and which are not. This work aims to
find relevant, interesting, or critical parameter sets within logical scenarios
by utilizing Bayes optimization and Gaussian processes. The parameter
optimization is done by comparing and evaluating six different metrics in two
urban intersection scenarios. Finally, a list of ideas this work leads to and
should be investigated further is presented.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:47:32 GMT""}]","2022-05-18"
"2205.08203","Dominik Kaaser","Petra Berenbrink and Amin Coja-Oghlan and Oliver Gebhard and Max
  Hahn-Klimroth and Dominik Kaaser and Malin Rau","On the Hierarchy of Distributed Majority Protocols",,,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the Consensus problem among $n$ agents, defined as follows.
Initially, each agent holds one of two possible opinions. The goal is to reach
a consensus configuration in which every agent shares the same opinion. To this
end, agents randomly sample other agents and update their opinion according to
a simple update function depending on the sampled opinions.
  We consider two communication models: the gossip model and a variant of the
population model. In the gossip model, agents are activated in parallel,
synchronous rounds. In the population model, one agent is activated after the
other in a sequence of discrete time steps. For both models we analyze the
following natural family of majority processes called $j$-Majority: when
activated, every agent samples $j$ other agents uniformly at random (with
replacement) and adopts the majority opinion among the sample (breaking ties
uniformly at random). As our main result we show a hierarchy among majority
protocols: $(j+1)$-Majority (for $j > 1$) converges stochastically faster than
$j$-Majority for any initial opinion configuration. In our analysis we use
Strassen's Theorem to prove the existence of a coupling. This gives an
affirmative answer for the case of two opinions to an open question asked by
Berenbrink et al. [2017].
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:53:22 GMT""}]","2022-05-18"
"2205.08204","Huaiqiang Wang","Dinghui Wang, Huaiqiang Wang, Dingyu Xing and Haijun Zhang","Three-Dirac-fermion approach to unexpected gapless surface states of van
  der Waals magnetic topological insulators","7 pages, 4 figures",,,,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/publicdomain/zero/1.0/","  A diverse range of topological quantum phenomena and potential applications
of three-dimensional topological insulators (TIs) hinge on opening an energy
gap of Dirac-cone surface states. Layered van der Waals (vdW) topological
materials, especially the recently discovered MnBi$_2$Te$_4$-family magnetic
TIs, have aroused great attention, where the interlayer vdW gap is expected to
play a crucial role in topological surface states. However, it remains a
serious controversy whether the surface states are gapped or gapless for
magnetic TI MnBi$_2$Te$_4$, which is a crucial issue for the prospect of
various magnetic topological states. Here, a 3-Dirac-fermion approach is
developed to generally describe surface states of nonmagnetic/magnetic vdW TIs
under the interlayer vdW gap modulation. In particular, we apply this approach
to solving controversial issues in the surface states of vdW antiferromagnetic
(AFM) TIs. Remarkably, unexpected topologically protected gapless Dirac-cone
surface states are found to arise due to the interlayer vdW gap expansion on
the surface, when the surface ferromagnetic layer has a zero Chern number,
while the surface states remain gapped for all other cases. These results are
further confirmed by first-principles calculations on AFM TI MnBi$_2$Te$_4$.
The unexpected gapless Dirac-cone states are invaluable in solving the puzzle
of the observed gapless surface states in MnBi$_2$Te$_4$. This work also
provides a promising way for experiments to realize intrinsic magnetic quantum
anomalous Hall effect with a large energy gap in MnBi$_2$Te$_4$ films.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:01:21 GMT""}]","2022-05-18"
"2205.08205","Wei Liu","Wei Liu, Aigeng Yang, Hao Sun","Shedding light on the electroweak phase transition from exotic Higgs
  boson decays at the lifetime frontiers","14 pages, 7 figures, to be published in PRD",,"10.1103/PhysRevD.105.115040",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the scenarios where a strongly first-order electroweak phase
transition (EWPT) is triggered by a light singlet scalar, which has feeble
interactions to the Higgs. Since the singlet scalar is light and has weak
couplings, it can decay at a macroscopic distance away from the collision
point. Therefore, it can be regarded as a long-lived particles (LLP) in such
scenarios. We perform the searches of the LLPs from the exotic Higgs decays, at
the FASER, MAPP and CMS-Timing detectors of the 14 TeV HL-LHC, to probe the
strongly first-order EWPT. In certain scenarios, we show that the LLP searches
can help to reach the parameter space of the strongly first-order EWPT
remarkably, where the searches for promptly exotic Higgs decays are not valid.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:02:21 GMT""},{""version"":""v2"",""created"":""Thu, 23 Jun 2022 01:35:22 GMT""}]","2022-07-13"
"2205.08206","Daishi Kiyohara","Daishi Kiyohara","Lattice points on a curve via $\ell^2$ decoupling","12 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a generalization of Bombieri-Pila's inequality for lattice points on
a curve to proper generalized arithmetic progressions. The proof uses the
$\ell^2$ decoupling inequality for non-degenerate curves in $\mathbb{R}^n$. We
also review the curve-lifting method and use it to establish various estimates
of lattice points on a planar curve.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:04:56 GMT""},{""version"":""v2"",""created"":""Wed, 17 May 2023 03:55:44 GMT""}]","2023-05-18"
"2205.08207","Baosheng Zhang","Baosheng Zhang, Ya Wang, Xiaoguang Ma, Hongjun Ma and Chunbo Luo","DynPL-SVO: A New Method Using Point and Line Features for Stereo Visual
  Odometry in Dynamic Scenes",,,,,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stereo visual odometry is widely used where a robot tracks its position and
orientation using stereo cameras. Most of the approaches recovered mobile
robotics motion based on the matching and tracking of point features along a
sequence of stereo images. But in low-textured and dynamic scenes, there are no
sufficient robust static point features for motion estimation, causing lots of
previous work to fail to reconstruct the robotic motion. However, line features
can be detected in such low-textured and dynamic scenes. In this paper, we
proposed DynPL-SVO, a stereo visual odometry with the $dynamic$ $grid$
algorithm and the cost function containing both vertical and horizontal
information of the line features. Stereo camera motion was obtained through
Levenberg-Marquard minimization of re-projection error of point and line
features. The experimental results on the KITTI and EuRoC MAV datasets showed
that the DynPL-SVO had a competitive performance when compared to other
state-of-the-art systems by producing more robust and accurate motion
estimation, especially in low-textured and dynamic scenes.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:08:03 GMT""},{""version"":""v2"",""created"":""Thu, 29 Sep 2022 14:51:21 GMT""}]","2022-09-30"
"2205.08208","Mattia  Zorzi","Davide Ghion and Mattia Zorzi","Distributed Kalman filtering with event-triggered communication: a
  robust approach",,,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  We consider the problem of distributed Kalman filtering for sensor networks
in the case there is a limit in data transmission and there is model
uncertainty. More precisely, we propose a distributed filtering strategy with
event-triggered communication in which the state estimators are computed
according to the least favorable model. The latter belongs to a ball (in
Kullback-Leibler topology) about the nominal model. We also present a
preliminary numerical example in order to test the performance of the proposed
strategy.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:09:12 GMT""}]","2022-05-18"
"2205.08209","Florian Kofler","Florian Kofler, Suprosanna Shit, Ivan Ezhov, Lucas Fidon, Izabela
  Horvath, Rami Al-Maskari, Hongwei Li, Harsharan Bhatia, Timo Loehr, Marie
  Piraud, Ali Erturk, Jan Kirschke, Jan C. Peeken, Tom Vercauteren, Claus
  Zimmer, Benedikt Wiestler, Bjoern Menze","blob loss: instance imbalance aware loss functions for semantic
  segmentation","23 pages, 7 figures // corrected one mistake where it said beta
  instead of alpha in the text",,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep convolutional neural networks (CNN) have proven to be remarkably
effective in semantic segmentation tasks. Most popular loss functions were
introduced targeting improved volumetric scores, such as the Dice coefficient
(DSC). By design, DSC can tackle class imbalance, however, it does not
recognize instance imbalance within a class. As a result, a large foreground
instance can dominate minor instances and still produce a satisfactory DSC.
Nevertheless, detecting tiny instances is crucial for many applications, such
as disease monitoring. For example, it is imperative to locate and surveil
small-scale lesions in the follow-up of multiple sclerosis patients. We propose
a novel family of loss functions, \emph{blob loss}, primarily aimed at
maximizing instance-level detection metrics, such as F1 score and sensitivity.
\emph{Blob loss} is designed for semantic segmentation problems where detecting
multiple instances matters. We extensively evaluate a DSC-based \emph{blob
loss} in five complex 3D semantic segmentation tasks featuring pronounced
instance heterogeneity in terms of texture and morphology. Compared to soft
Dice loss, we achieve 5% improvement for MS lesions, 3% improvement for liver
tumor, and an average 2% improvement for microscopy segmentation tasks
considering F1 score.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:13:27 GMT""},{""version"":""v2"",""created"":""Thu, 14 Jul 2022 20:44:56 GMT""},{""version"":""v3"",""created"":""Tue, 6 Jun 2023 17:54:34 GMT""}]","2023-06-07"
"2205.08210","\'Ad\'am Wolf","\'Ad\'am Wolf, Stefan Romeder-Finger, K\'aroly Sz\'ell, P\'eter
  Galambos","Towards Robotic Laboratory Automation Plug & Play: Survey and Concept
  Proposal on Teaching-free Robot Integration with the LAPP Digital Twin",,,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  The Laboratory Automation Plug & Play (LAPP) framework is an over-arching
reference architecture concept for the integration of robots in life science
laboratories. The plug & play nature lies in the fact that manual configuration
is not required, including the teaching of the robots. In this paper a digital
twin (DT) based concept is proposed that outlines the types of information that
have to be provided for each relevant component of the system. In particular,
for the devices interfacing with the robot, the robot positions have to be
defined beforehand in a device-attached coordinate system (CS) by the vendor.
This CS has to be detectable by the vision system of the robot by means of
optical markers placed on the front side of the device. With that, the robot is
capable of tending the machine by performing the pick-and-place type
transportation of standard sample carriers. This basic use case is the primary
scope of the LAPP-DT framework. The hardware scope is limited to simple
benchtop and mobile manipulators with parallel grippers at this stage. This
paper first provides an overview of relevant literature and state-of-the-art
solutions, after which it outlines the framework on the conceptual level,
followed by the specification of the relevant DT parameters for the robot, for
the devices and for the facility. Finally, appropriate technologies and
strategies are identified for the implementation.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:14:12 GMT""},{""version"":""v2"",""created"":""Sat, 4 Jun 2022 13:01:28 GMT""},{""version"":""v3"",""created"":""Fri, 28 Oct 2022 08:18:24 GMT""},{""version"":""v4"",""created"":""Mon, 19 Dec 2022 20:32:01 GMT""}]","2022-12-21"
"2205.08211","Andrea Farina","Antonio Pifferi, Massimo Miniati, Andrea Farina, Sanathana Konugolu
  Venkata Sekar, Pranav Lanka, Alberto Dalla Mora, Paola Taroni","Initial non-invasive in vivo sensing of the lung using time domain
  diffuse optics","15 pages, 15 figures, 1 Table",,,,"physics.med-ph eess.IV physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Non-invasive in vivo sensing of the lung with light would help diagnose and
monitor pulmonary disorders (caused by e.g. COVID-19, emphysema, immature lung
tissue in infants). We investigated the possibility to probe the lung with time
domain diffuse optics, taking advantage of the increased depth (few cm) reached
by photons detected after a long (few ns) propagation time. An initial study on
5 healthy volunteers included time-resolved broadband diffuse optical
spectroscopy measurements at 3 cm source-detector distance over the 600-1100 nm
range, and long-distance (6-9 cm) measurements at 820 nm performed during a
breathing protocol. The interpretation of the in vivo data with a simplified
homogeneous model yielded a maximum probing depth of 2.6-3.9 cm, suitable to
reach the lung. Also, signal changes related to the inspiration act were
observed, especially at high photon propagation times. Yet, intra- and
inter-subject variability and inconsistencies, possibly alluring to competing
scattering and absorption effects, prevented a simple interpretation. Aspects
to be further investigated to gain a deeper insight are discussed.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:16:13 GMT""}]","2022-05-18"
"2205.08212","Jens Biele","Jens Biele, Matthias Grott, Michael E. Zolensky, Artur Benisek, Edgar
  Dachs","The specific heat of astro-materials: Review of theoretical concepts,
  materials and techniques","submitted to Special Issue for International Journal of Thermophysics
  'Thermophysics of Advanced Spacecraft Materials and Extraterrestrial Samples'
  Part II to be submitted still in 2022",,"10.1007/s10765-022-03046-5",,"astro-ph.EP cond-mat.mtrl-sci physics.class-ph physics.geo-ph","http://creativecommons.org/licenses/by/4.0/","  We provide detailed background, theoretical and practical, on the specific
heat cp of minerals and mixtures thereof, 'astro-materials', as well as
background information on common minerals and other relevant solid substances
found on the surfaces of solar system bodies. Furthermore, we demonstrate how
to use specific heat and composition data for lunar samples and meteorites as
well as a new database of endmember mineral heat capacities (the result of an
extensive literature review) to construct reference models for the isobaric
specific heat cP as a function of temperature for common solar system
materials. Using a (generally linear) mixing model for the specific heat of
minerals allows extrapolation of the available data to very low and very high
temperatures, such that models cover the temperature range between 10 and 1000
K at least (and pressures from zero up to several kbars). We describe a
procedure to estimate cp(T) for virtually any solid solar system material with
a known mineral composition, e.g., model specific heat as a function of
temperature for a number of typical meteorite classes with known mineralogical
compositions. We present, as examples, the cp(T) curves of a number of
well-described laboratory regolith analogues, as well as for planetary ices and
'tholins' in the outer solar system. Part II will review and present the heat
capacity database for minerals and compounds and part III is going to cover
applications, standard reference compositions, cp(T) curves and a comparison
with new and literature experimental data.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:16:25 GMT""}]","2022-08-24"
"2205.08213","Atila \v{C}eki","Olivera Latkovi\'c and Atila \v{C}eki","Light curve analysis of six totally eclipsing W UMa binaries",,"Publications of the Astronomical Society of Japan, 2021, Volume
  73, Issue 1, pp. 132-142","10.1093/pasj/psaa109",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze multicolor light curves of six totally eclipsing, short-period W
UMa binaries and derive, for the first time, their orbital and stellar
parameters. The mass ratios are established robustly through an automated
q-search procedure that performs a heuristic survey of the parameter space.
Five stars belong to the W and one to the A subtype. The mass ratios range from
0.23 to 0.51 and the fillouts from 10 to 15%. We estimate the ages and discuss
the evolutionary status of these objects in comparison with a sample of other
short-period W UMa binaries from the literature.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:16:32 GMT""},{""version"":""v2"",""created"":""Wed, 1 Feb 2023 07:37:43 GMT""}]","2023-02-02"
"2205.08214","Songlin Zhao","Hai-Jing Xu, Song-lin Zhao","Cauchy matrix solutions to some local and nonlocal complex equations","28 pages,62 figures,to appear in Theor. Math. Phys",,,,"nlin.SI math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we develop a Cauchy matrix reduction technique that enables us
to obtain solutions for the reduced local and nonlocal complex equations from
the Cauchy matrix solutions of the original before-reduction systems.
Specifically, by imposing local and nonlocal complex reductions on some
Ablowitz-Kaup-Newell-Segur-type equations, we study some local and nonlocal
complex equations, involving the local and nonlocal complex modified
Korteweg-de Vries equation, the local and nonlocal complex sine-Gordon
equation, the local and nonlocal potential nonlinear Schr\""{o}dinger equation
and the local and nonlocal potential complex modified Korteweg-de Vries
equation. Cauchy matrix-type soliton solutions and Jordan block solutions for
the aforesaid local and nonlocal complex equations are presented. The dynamical
behaviors of some obtained solutions are analyzed with graphical illustrations.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:18:04 GMT""}]","2022-05-18"
"2205.08215","Xiangwei Yin","Tianjun Li, Junle Pei, Xiangwei Yin, Bin Zhu","Explanations of the Tentative New Physics Anomalies and Dark Matter in
  the Simple Extension of the Standard Model (SESM)","24 pages, 6 figures, 4 tables",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We revisit the Simple Extension of the Standard Model (SESM) which can
account for various tentative new physics anomalies and dark matter (DM). We
consider a complete scalar potential which is needed to address the $W$ boson
anomaly. Interestingly, the SESM can simultaneously explain the B physics
anomaly, muon anomalous magnetic moment, $W$ mass anomaly, and dark matter,
etc. Also, we study the unitarity constraint in this model. We perform the
systematic study, and find the viable parameter spaces which can explain these
anomalies and evade all the current experimental constraints. To be complete,
we briefly comment on the neutrino masses and mixings, baryon asymmetry, and
inflation.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:20:39 GMT""}]","2022-05-18"
"2205.08216","Songbo Hou","Jia Gao, Songbo Hou","Existence theorems for a generalized Chern-Simons equation on finite
  graphs","15 pages",,,,"math.AP math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Denote by $G=(V,E)$ a finite graph. We study a generalized Chern-Simons
equation $$ \Delta u=\lambda
\mathrm{e}^u(\mathrm{e}^{bu}-1)+4\pi\sum\limits_{j=1}^{N}\delta_{p_j} $$ on
$G$, where $\lambda$ and $b$ are positive constants; $N$ is a positive integer;
$p_1, p_2, \cdot\cdot\cdot, p_N$ are distinct vertices of $V$ and
$\delta_{p_j}$ is the Dirac delta mass at $p_j$. We prove that there exists a
critical value $\lambda_c$ such that the equation has a solution if
$\lambda\geq \lambda_c$ and the equation has no solution if
$\lambda<\lambda_c$. We also prove that if $\lambda>\lambda_c$ the equation has
at least two solutions which include a local minimizer for the corresponding
functional and a mountain-pass type solution.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:22:10 GMT""}]","2022-05-18"
"2205.08217","Lanhai He","Lanhai He, Sebastian Malerz, Florian Trinter, Sebastian Trippel,
  Luk\'a\v{s} Toman\'ik, Michal Belina, Petr Slav\'i\v{c}ek, Bernd Winter,
  Jochen K\""upper","Specific versus non-specific solvent interactions of a biomolecule in
  water","13 pages, 5 figures",,,,"physics.chem-ph physics.atm-clus physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Solvent interactions and specifically hydration are of utmost importance in
chemical and biochemical systems. Model systems enable us to unravel the
microscopic details of these interactions. Here, we clearly unraveled a
specific hydrogen-bonding motif of the prototypical biomolecular building block
indole (C8H7N), the chromophore of tryptophan, in water: The system exhibits a
strong localized N-H...OH2 hydrogen bond, but otherwise unstructured
interactions of the molecule with the solvent. This surprising segmentation of
the solvent interaction was obtained from a combined experimental and
theoretical investigation of the electronic structure of indole in aqueous
solution. We recorded the complete x-ray photoemission and Auger spectrum of
aqueous-phase indole and quantitatively explained all peaks with the aid of
extensive ab initio modeling. The combination of the maximum-overlap method
with the non-equilibrium polarizable-continuum model was demonstrated as an
efficient and accurate technique for a modeling of both the valence and core
photoemission spectra. A two-hole electron-population analysis shows a
quantitative theoretical description of Auger spectra. Especially the
core-electron binding energies for nitrogen and carbon demonstrated the
distinct specific interaction of the one hydrogen-bound water molecule with the
N-H group and the otherwise unspecific solvent interactions. The valence
photoemission data provided the reorganization energy of aqueous-phase indole
associated with its ionization, which we could directly connect to is
electrochemical redox potential.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:24:26 GMT""},{""version"":""v2"",""created"":""Wed, 22 Jun 2022 12:31:06 GMT""}]","2022-06-23"
"2205.08218","Hao-Ning Wu","Congpei An, Hao-Ning Wu","Is hyperinterpolation efficient in the approximation of singular and
  oscillatory functions?","A new theorem, Theorem 2.1, is presented",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Singular and oscillatory functions feature in numerous applications. The
high-accuracy approximation of such functions shall greatly help us develop
high-order methods for solving applied mathematics problems. This paper
demonstrates that hyperinterpolation, a discrete projection method with
coefficients obtained by evaluating the $L^2$ orthogonal projection
coefficients using some numerical integration methods, may be inefficient for
approximating singular and oscillatory functions. A relatively large amount of
numerical integration points are necessary for satisfactory accuracy. Moreover,
in the spirit of product-integration, we propose an efficient modification of
hyperinterpolation for such approximation. The proposed approximation scheme,
called efficient hyperinterpolation, achieves satisfactory accuracy with fewer
numerical integration points than the original scheme. The implementation of
the new approximation scheme is relatively easy. Theorems are also given to
explain the outperformance of efficient hyperinterpolation over the original
scheme in such approximation, with the functions assumed to belong to
$L^1(\Omega)$, $L^2(\Omega)$, and $\mathcal{C}(\Omega)$ spaces, respectively.
These theorems, as well as numerical experiments on the interval and the
sphere, show that efficient hyperinterpolation has better accuracy in such
approximation than the original one when the amount of numerical integration
points is limited.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:26:56 GMT""},{""version"":""v2"",""created"":""Thu, 19 May 2022 10:51:13 GMT""}]","2022-05-20"
"2205.08219","Holger Grosshans","Holger Grosshans, Simon Jantac","Review on CFD modeling of electrostatic powder charging during pneumatic
  conveying",,,,,"physics.flu-dyn","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Thus far, Computational Fluid Dynamics (CFD) simulations fail to reliably
predict the electrostatic charging of powder during pneumatic conveying. The
lack of a predictive tool is one reason for unwanted discharges and growing
deposits that make a plant a prime candidate for an explosion. This paper
reviews the numerical models' state-of-the-art, limitations, and progress in
recent years. In particular, the discussion includes the condenser model, which
is up to today most popular in CFD simulations of powder flow electrification
but fails to predict most of its features. New experiments led to advanced
models, such as the non-uniform charge model, which resolves the local
distribution of charge on non-conductive particle surfaces. Further, models
relying on the surface state theory predicted bipolar charging of polydisperse
particles made of the same material. Whereas these models were usually
implemented in CFD tools using an Eulerian-Lagrangian strategy, powder charging
was recently successfully described in an Eulerian framework. The Eulerian
framework is computationally efficient when handling complete powders; thus,
this research can pave the way from academic studies to simulating powder
processing units. Overall, even though CFD models for powder flow charging
improved, major hurdles toward a predictive tool remain.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:27:53 GMT""}]","2022-05-18"
"2205.08220","Zhuoyin Dai","Zhuoyin Dai, Ruoguang Li, Jingran Xu, Yong Zeng, and Shi Jin","Rate-Region Characterization and Channel Estimation for Cell-Free
  Symbiotic Radio Communications","arXiv admin note: substantial text overlap with arXiv:2106.06148",,,,"eess.SY cs.SY eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cell-free massive MIMO and symbiotic radio communication have been recently
proposed as the promising beyond fifth-generation (B5G) networking architecture
and transmission technology, respectively. To reap the benefits of both, this
paper studies cell-free symbiotic radio communication systems, where a number
of cell-free access points (APs) cooperatively send primary information to a
receiver, and simultaneously support the passive backscattering communication
of the secondary backscatter device (BD). We first derive the achievable
communication rates of the active primary user and passive secondary user under
the assumption of perfect channel state information (CSI), based on which the
transmit beamforming of the cellfree APs is optimized to characterize the
achievable rate-region of cell-free symbiotic communication systems.
Furthermore, to practically acquire the CSI of the active and passive channels,
we propose an efficient channel estimation method based on two-phase
uplink-training, and the achievable rate-region taking into account CSI
estimation errors are further characterized. Simulation results are provided to
show the effectiveness of our proposed beamforming and channel estimation
methods.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:33:03 GMT""}]","2022-05-18"
"2205.08221","Demian Gholipour Ghalandari","Demian Gholipour Ghalandari, Chris Hokamp, Georgiana Ifrim","Efficient Unsupervised Sentence Compression by Fine-tuning Transformers
  with Reinforcement Learning",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sentence compression reduces the length of text by removing non-essential
content while preserving important facts and grammaticality. Unsupervised
objective driven methods for sentence compression can be used to create
customized models without the need for ground-truth training data, while
allowing flexibility in the objective function(s) that are used for learning
and inference. Recent unsupervised sentence compression approaches use custom
objectives to guide discrete search; however, guided search is expensive at
inference time. In this work, we explore the use of reinforcement learning to
train effective sentence compression models that are also fast when generating
predictions. In particular, we cast the task as binary sequence labelling and
fine-tune a pre-trained transformer using a simple policy gradient approach.
Our approach outperforms other unsupervised models while also being more
efficient at inference time.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:34:28 GMT""}]","2022-05-18"
"2205.08222","Yasushi Nagano","Yasushi Nagano, Koji Hukushima","Phase transition in compressed sensing with horseshoe prior","9pages, 5figures",,"10.1103/PhysRevE.107.034126",,"cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In Bayesian statistics, horseshoe prior has attracted increasing attention as
an approach to the sparse estimation. The estimation accuracy of compressed
sensing with the horseshoe prior is evaluated by statistical mechanical method.
It is found that there exists a phase transition in signal recoverability in
the plane of the number of observations and the number of nonzero signals and
that the recoverability phase is more extended than that using the well-known
$l_1$ norm regularization.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:48:33 GMT""}]","2023-03-29"
"2205.08223","Fujun Hou","Fujun Hou","Conditions for Social Preference Transitivity When Cycle Involved and A
  $\hat{O}\mbox{-}\hat{I}$ Framework","we present some conditions for the individual preferences to yield a
  transitive social ordering when cycles are included. We outline a conceptual
  $\hat{O}\mbox{-}\hat{I}$ framework for social transitivity, whose axioms were
  found effective for some existent conditions, and prospective for formulating
  new transitivity conditions. arXiv admin note: text overlap with
  arXiv:2205.02040",,,,"econ.TH","http://creativecommons.org/licenses/by/4.0/","  We present some conditions for social preference transitivity under the
majority rule when the individual preferences include cycles. First, our
concern is with the restriction on the preference orderings of individuals
except those (called cycle members) whose preferences constitute the cycles,
but the considered transitivity is, of course, of the society as a whole. In
our discussion, the individual preferences are assumed concerned and the cycle
members' preferences are assumed as strict orderings. Particularly, for an
alternative triple when one cycle is involved and the society is sufficient
large (at least 5 individuals in the society), we present a sufficient
condition for social transitivity; when two antagonistic cycles are involved
and the society has at least 9 individuals, necessary and sufficient conditions
are presented which are merely restricted on the preferences of those
individuals except the cycle members. Based on the work due to Slutsky (1977)
and Gaertner \& Heinecke (1978), we then outline a conceptual
$\hat{O}\mbox{-}\hat{I}$ framework of social transitivity in an axiomatic
manner. Connections between some already identified conditions and the
$\hat{O}\mbox{-}\hat{I}$ framework is examined.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:50:15 GMT""},{""version"":""v2"",""created"":""Tue, 31 May 2022 22:33:10 GMT""}]","2022-06-02"
"2205.08224","Vinayak Shantaram Bhat","Vinayak Shantaram Bhat, Sho Watanabe, Florian Kronast, Korbinian
  Baumgaertl, and Dirk Grundler","Spin Dynamics, Loop Formation and Cooperative Reversal in Artificial
  Quasicrystals with Tailored Exchange Coupling","12 pages, 6 figures",,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Aperiodicity and un-conventional rotational symmetries allow quasicrystalline
structures to exhibit unprecedented physical and functional properties. In
magnetism, artificial ferromagnetic quasicrystals exhibited knee anomalies
suggesting reprogrammable magnetic properties via nonstochastic switching.
However, the decisive roles of short-range exchange and long-range dipolar
interactions have not yet been clarified for optimized reconfigurable
functionality. We report broadband spin-wave spectroscopy and X-ray
photoemission electron microscopy on different quasicrystal lattices consisting
of ferromagnetic Ni81Fe19 nanobars arranged on aperiodic Penrose and Ammann
tilings with different exchange and dipolar interactions. We imaged the
magnetic states of partially reversed quasicrystals and analyzed their
configurations in terms of the charge model, geometrical frustration and the
formation of flux-closure loops. Only the exchange-coupled lattices are found
to show aperiodicity-specific collective phenomena and non-stochastic
switching. Both, exchange and dipolarly coupled quasicrystals show magnonic
excitations with narrow linewidths in minor loop measurements. Thereby
reconfigurable functionalities in spintronics and magnonics become realistic.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:52:47 GMT""}]","2022-05-18"
"2205.08225","Laurent Jacques","R\'emi Delogne, Vincent Schellekens, and Laurent Jacques","ROP inception: signal estimation with quadratic random sketching","9 pages, 3 figures; part of this work has been submitted to the ESANN
  2022 conference; this version contains additional proofs",,,,"eess.SP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Rank-one projections (ROP) of matrices and quadratic random sketching of
signals support several data processing and machine learning methods, as well
as recent imaging applications, such as phase retrieval or optical processing
units. In this paper, we demonstrate how signal estimation can be operated
directly through such quadratic sketches--equivalent to the ROPs of the ""lifted
signal"" obtained as its outer product with itself--without explicitly
reconstructing that signal. Our analysis relies on showing that, up to a minor
debiasing trick, the ROP measurement operator satisfies a generalised sign
product embedding (SPE) property. In a nutshell, the SPE shows that the scalar
product of a signal sketch with the ""sign"" of the sketch of a given pattern
approximates the square of the projection of that signal on this pattern. This
thus amounts to an insertion (an ""inception"") of a ROP model inside a ROP
sketch. The effectiveness of our approach is evaluated in several synthetic
experiments.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:55:48 GMT""}]","2022-05-18"
"2205.08226","Martin Raum","Martin Raum","The Bernstein-Gelfand Tensor Product Functor and the Weight-2 Eisenstein
  Series",,,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Bernstein-Gelfand tensor product functors are endofunctors of the
category of Harish-Chandra modules provided by tensor products with finite
dimensional modules. We provide an automorphic analogue of these tensor product
functors, implemented by vector-valued automorphic representations that are
trivial at all finite places. They naturally explain the role of vector-valued
modular forms in recent work by Bringmann-Kudla on Harish-Chandra modules
associated with harmonic weak Maa\ss{} forms. We give a detailed account of the
image $\mathrm{sym}^1 \otimes \varpi(E_2)$ of the automorphic representation
$\varpi(E_2)$ generated by the Eisenstein series of weight $2$ under one of
those tensor product functors. This builds upon work by Roy-Schmidt-Yi, who
recently determined the structure of $\varpi(E_2)$. They found that
$\varpi(E_2)$ does not decompose as a restricted tensor product over all places
of $\mathbb{Q}$, while we discover that $\mathrm{sym}^1 \otimes \varpi(E_2)$
has a direct summand that does. This summand corresponds to a holomorphic and
modular, vector-valued analogue of $E_2$. The complement in $\mathrm{sym}^1
\otimes \varpi(E_2)$ arises from one of the vector-valued examples in the work
of Bringmann-Kudla. Our approach allows us to determine its structure at the
finite places.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:55:49 GMT""}]","2022-05-18"
"2205.08227","Jiachen Jiang","Jiachen Jiang, Douglas J. K. Buisson, Thomas Dauser, Andrew C. Fabian,
  Felix F\""urst, Luigi C. Gallo, Fiona A. Harrison, Michael L. Parker, James F.
  Steiner, John A. Tomsick, Santiago Ubach and Dominic J. Walton","A NuSTAR and Swift View of the Hard State of MAXI J1813-095","9 pages, 12 figures, accepted for publication in MNRAS",,"10.1093/mnras/stac1401",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We present an analysis of the NuSTAR and Swift spectra of the black hole
candidate MAXI J1813-095 in a failed-transition outburst in 2018. The NuSTAR
observations show evidence of reflected emission from the inner region of the
accretion disc. By modelling the reflection component in the spectra, we find a
disc inner radius of $R_{\rm in}<7$ $r_{\rm g}$. This result suggests that
either a slightly truncated disc or a non-truncated disc forms at a few percent
of the Eddington limit in MAXI J1813-095. Our best-fit reflection models
indicate that the geometry of the innermost accretion remains consistent during
the period of NuSTAR observations. The spectral variability of MAXI J1813-095
from multi-epoch observations is dominated by the variable photon index of the
Comptonisation emission.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:56:03 GMT""}]","2022-06-01"
"2205.08228","Alexander Manashov","V.M. Braun, K.G. Chetyrkin, A.N. Manashov","NNLO anomalous dimension matrix for twist-two flavor-singlet operators","6 pages, 2 ancillary files + README.pdf",,"10.1016/j.physletb.2022.137409","DESY-22-078, TTP22-032","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conformal symmetry of QCD is restored at the Wilson-Fisher critical point in
noninteger $4-2\epsilon$ space-time dimensions. Correlation functions of
multiplicatively renormalizable operators with different anomalous dimensions
at the critical point vanish identically. We show that this property allows one
to calculate off-diagonal parts of the anomalous dimension matrices for
leading-twist operators from a set of two-point correlation functions of
gauge-invariant operators which can be evaluated using standard computer
algebra techniques. As an illustration, we present the results for the NNLO
anomalous dimension matrix for flavor-singlet QCD operators for spin $N\le 8$.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:57:54 GMT""}]","2022-09-07"
"2205.08229","Stuart Russell","Stuart Russell, John F. Rudge, Jessica C. E. Irving and Sanne Cottaar","A Re-examination of Ellipticity Corrections for Seismic Phases","Main paper of 11 pages, 4 figures and 1 table plus a supplement of 12
  pages and 1 table",,"10.1093/gji/ggac315",,"physics.geo-ph","http://creativecommons.org/licenses/by/4.0/","  The Earth's ellipticity of figure has an effect on the travel times of
seismic waves over teleseismic distances. Tables of ellipticity corrections and
coefficients have been used by seismologists for several decades, however due
to the increasing variety and complexity of seismic phases in use, current
tables of ellipticity coefficients are now outmoded and incomplete. We present
a Python package, EllipticiPy, for the calculation of ellipticity corrections
that removes the dependence on pre-calculated coefficients at discrete source
depths and epicentral distances. EllipticiPy also facilitates the calculation
of ellipticity corrections on other planetary bodies. When applied to both
Earth and Mars, the magnitudes of ellipticity corrections are on the order of
single seconds and are significant for some seismic studies on Earth but remain
negligible on Mars due to other greater sources of uncertainty.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:59:09 GMT""},{""version"":""v2"",""created"":""Thu, 11 Aug 2022 11:57:32 GMT""}]","2022-09-07"
"2205.08230","Nick Wright","Graham A. Niblo, Roger Plymen and Nick Wright","Centralisers, complex reflection groups and actions in the Weyl group
  $E_6$",,,,,"math.GR math.KT math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The compact, connected Lie group $E_6$ admits two forms: simply connected and
adjoint type. As we previously established, the Baum-Connes isomorphism relates
the two Langlands dual forms, giving a duality between the equivariant K-theory
of the Weyl group acting on the corresponding maximal tori. Our study of the
$A_n$ case showed that this duality persists at the level of homotopy, not just
homology. In this paper we compute the extended quotients of maximal tori for
the two forms of $E_6$, showing that the homotopy equivalences of sectors
established in the $A_n$ case also exist here, leading to a conjecture that the
homotopy equivalences always exist for Langlands dual pairs. In computing these
sectors we show that centralisers in the $E_6$ Weyl group decompose as direct
products of reflection groups, generalising Springer's results for regular
elements, and we develop a pairing between the component groups of fixed sets
generalising Reeder's results. As a further application we compute the
$K$-theory of the reduced Iwahori-spherical $C^*$-algebra of the p-adic group
$E_6$, which may be of adjoint type or simply connected.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:59:56 GMT""},{""version"":""v2"",""created"":""Thu, 14 Jul 2022 16:28:10 GMT""},{""version"":""v3"",""created"":""Mon, 17 Apr 2023 12:12:03 GMT""}]","2023-04-18"
"2205.08231","Calum Robert MacLellan","Calum Robert MacLellan and Feng Dong","Hyper-Learning for Gradient-Based Batch Size Adaptation",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Scheduling the batch size to increase is an effective strategy to control
gradient noise when training deep neural networks. Current approaches implement
scheduling heuristics that neglect structure within the optimization procedure,
limiting their flexibility to the training dynamics and capacity to discern the
impact of their adaptations on generalization. We introduce Arbiter as a new
hyperparameter optimization algorithm to perform batch size adaptations for
learnable scheduling heuristics using gradients from a meta-objective function,
which overcomes previous heuristic constraints by enforcing a novel learning
process called hyper-learning. With hyper-learning, Arbiter formulates a neural
network agent to generate optimal batch size samples for an inner deep network
by learning an adaptive heuristic through observing concomitant responses over
T inner descent steps. Arbiter avoids unrolled optimization, and does not
require hypernetworks to facilitate gradients, making it reasonably cheap,
simple to implement, and versatile to different tasks. We demonstrate Arbiter's
effectiveness in several illustrative experiments: to act as a stand-alone
batch size scheduler; to complement fixed batch size schedules with greater
flexibility; and to promote variance reduction during stochastic
meta-optimization of the learning rate.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:01:14 GMT""}]","2022-05-18"
"2205.08232","Zhicheng Yang","Zhicheng Yang, Jinghui Qin, Jiaqi Chen, Liang Lin and Xiaodan Liang","LogicSolver: Towards Interpretable Math Word Problem Solving with
  Logical Prompt-enhanced Learning",,"Findings of EMNLP 2022",,,"cs.AI cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Recently, deep learning models have made great progress in MWP solving on
answer accuracy. However, they are uninterpretable since they mainly rely on
shallow heuristics to achieve high performance without understanding and
reasoning the grounded math logic. To address this issue and make a step
towards interpretable MWP solving, we first construct a high-quality MWP
dataset named InterMWP which consists of 11,495 MWPs and annotates
interpretable logical formulas based on algebraic knowledge as the grounded
linguistic logic of each solution equation. Different from existing MWP
datasets, our InterMWP benchmark asks for a solver to not only output the
solution expressions but also predict the corresponding logical formulas. We
further propose a novel approach with logical prompt and interpretation
generation, called LogicSolver. For each MWP, our LogicSolver first retrieves
some highly-correlated algebraic knowledge and then passes them to the backbone
model as prompts to improve the semantic representations of MWPs. With these
improved semantic representations, our LogicSolver generates corresponding
solution expressions and interpretable knowledge formulas in accord with the
generated solution expressions, simultaneously. Experimental results show that
our LogicSolver has stronger logical formula-based interpretability than
baselines while achieving higher answer accuracy with the help of logical
prompts, simultaneously. The source code and dataset is available at
https://github.com/yangzhch6/InterMWP.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:01:52 GMT""},{""version"":""v2"",""created"":""Fri, 21 Oct 2022 09:52:08 GMT""},{""version"":""v3"",""created"":""Mon, 24 Oct 2022 10:30:56 GMT""}]","2022-10-25"
"2205.08233","Zolt\'an Kov\'acs","Zolt\'an Kov\'acs, Alexander Thaller","Towards understanding the central limit theorem by learning Python
  basics","16 pages, 13 figures",,,,"math.HO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on a first experiment about an email based course that connects
learning Python basics and introductory probability theory. In the experiment 7
short sequences of homework were sent out to prospective mathematics teachers
who did not have any programming background formerly, but already had some
minor knowledge on probability theory. The experiment was about to decide if
learning basics of programming can promote understanding main concepts of
probability theory.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:08:24 GMT""}]","2022-05-18"
"2205.08234","Naresh Manwani","Naresh Manwani, Mudit Agarwal","Delaytron: Efficient Learning of Multiclass Classifiers with Delayed
  Bandit Feedbacks",,,,,"cs.LG cs.AI stat.ML","http://creativecommons.org/licenses/by/4.0/","  In this paper, we present online algorithm called {\it Delaytron} for
learning multi class classifiers using delayed bandit feedbacks. The sequence
of feedback delays $\{d_t\}_{t=1}^T$ is unknown to the algorithm. At the $t$-th
round, the algorithm observes an example $\mathbf{x}_t$ and predicts a label
$\tilde{y}_t$ and receives the bandit feedback $\mathbb{I}[\tilde{y}_t=y_t]$
only $d_t$ rounds later. When $t+d_t>T$, we consider that the feedback for the
$t$-th round is missing. We show that the proposed algorithm achieves regret of
$\mathcal{O}\left(\sqrt{\frac{2
K}{\gamma}\left[\frac{T}{2}+\left(2+\frac{L^2}{R^2\Vert
\W\Vert_F^2}\right)\sum_{t=1}^Td_t\right]}\right)$ when the loss for each
missing sample is upper bounded by $L$. In the case when the loss for missing
samples is not upper bounded, the regret achieved by Delaytron is
$\mathcal{O}\left(\sqrt{\frac{2
K}{\gamma}\left[\frac{T}{2}+2\sum_{t=1}^Td_t+\vert \mathcal{M}\vert
T\right]}\right)$ where $\mathcal{M}$ is the set of missing samples in $T$
rounds. These bounds were achieved with a constant step size which requires the
knowledge of $T$ and $\sum_{t=1}^Td_t$. For the case when $T$ and
$\sum_{t=1}^Td_t$ are unknown, we use a doubling trick for online learning and
proposed Adaptive Delaytron. We show that Adaptive Delaytron achieves a regret
bound of $\mathcal{O}\left(\sqrt{T+\sum_{t=1}^Td_t}\right)$. We show the
effectiveness of our approach by experimenting on various datasets and
comparing with state-of-the-art approaches.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:12:20 GMT""}]","2022-05-18"
"2205.08235","Sooyeong Kim","Jane Breen, Emanuele Crisostomi, and Sooyeong Kim","Kemeny's constant for a graph with bridges","21 pages and 3 figures",,,,"math.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, we determine a formula for Kemeny's constant for a graph with
multiple bridges, in terms of quantities that are inherent to the subgraphs
obtained upon removal of all bridges and that can be computed independently.
With the formula, we consider several optimization problems for Kemeny's
constant for graphs with bridges, and we remark on the computational benefit of
this formula for the computation of Kemeny's constant. Finally, we discuss some
potential applications.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:15:23 GMT""}]","2022-05-18"
"2205.08236","Jiachen Jiang","Jiachen Jiang, Luigi C. Gallo, Andrew C. Fabian, Michael L. Parker and
  Christopher S. Reynolds","A Disc Reflection Model for Ultra-Soft Narrow-Line Seyfert 1 Galaxies","16 pages, 11 figures; published in MNRAS, Volume 498, Issue 3,
  November 2020. The Reflionx model used in this work is available for download
  at https://www.michaelparker.space/reflionx-models",,,,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We present a detailed analysis of the XMM-Newton observations of five
narrow-line Seyfert 1 galaxies (NLS1s). They all show very soft continuum
emission in the X-ray band with a photon index of $\Gamma\gtrsim 2.5$.
Therefore, they are referred to as `ultra-soft' NLS1s in this paper. By
modeling their optical/UV-X-ray spectral energy distribution (SED) with a
reflection-based model, we find indications that the disc surface in these
ultra-soft NLS1s is in a higher ionisation state than other typical Seyfert 1
AGN. Our best-fit SED models suggest that these five ultra-soft NLS1s have an
Eddington ratio of $\lambda_{\rm Edd}=1-20$ assuming available black hole mass
measurements. In addition, our models infer that a significant fraction of the
disc energy in these ultra-soft NLS1s is radiated away in the form of
non-thermal emission instead of the thermal emission from the disc. Due to
their extreme properties, X-ray observations of these sources in the iron band
are particularly challenging. Future observations, e.g. from Athena, will
enable us to have a clearer view of the spectral shape in the iron band and
thus distinguish the reflection model from other interpretations of their
broadband spectra.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:16:22 GMT""}]","2022-05-18"
"2205.08237","Giuseppe D'Onofrio","Giuseppe D'Onofrio, Pierre Patie, Laura Sacerdote","Jacobi processes with jumps as neuronal models: a first passage time
  analysis","20 pages, 8 figures",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To overcome some limits of classical neuronal models, we propose a Markovian
generalization of the classical model based on Jacobi processes by introducing
downwards jumps to describe the activity of a single neuron. The statistical
analysis of inter-spike intervals is performed by studying the first-passage
times of the proposed Markovian Jacobi process with jumps through a constant
boundary. In particular, we characterize its Laplace transform which is
expressed in terms of some generalization of hypergeometric functions that we
introduce, and, deduce a closed-form expression for its expectation. Our
approach, which is original in the context of first passage time problems,
relies on intertwining relations between the semigroups of the classical Jacobi
process and its generalization which have been recently established in [10]. A
numerical investigation of the firing rate of the considered neuron is
performed for some choices of the involved parameters and of the jumps
distributions.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:17:06 GMT""}]","2022-05-18"
"2205.08238","Jeremy Siegert","Jeremy Siegert","Relating asymptotic dimension to Ponomarev's cofinal dimension via
  coarse proximities","41 pages",,,,"math.MG math.GN math.GT","http://creativecommons.org/licenses/by/4.0/","  In this paper we show that the asymptotic dimension of an unbounded proper
metric space is bounded above by a coarse analog of Ponomarev's cofinal
dimension of topological spaces, which we call the coarse cofinal dimension. We
also show that asymptotic dimension is bounded below by the cofinal dimension
of the Higson corona by existing results of Miyata, Austin, and Virk. We do
this by introducing several constructions in the theory of coarse proximity
spaces. In particular we introduce the inverse limit of coarse proximity
spaces. We end with some open problems.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:19:54 GMT""}]","2022-05-18"
"2205.08239","Liu Li","Liu Li, Qiang Ma, Matthew Sinclair, Antonios Makropoulos, Joseph
  Hajnal, A. David Edwards, Bernhard Kainz, Daniel Rueckert, Amir Alansary","CAS-Net: Conditional Atlas Generation and Brain Segmentation for Fetal
  MRI",,,,,"eess.IV cs.CV","http://creativecommons.org/publicdomain/zero/1.0/","  Fetal Magnetic Resonance Imaging (MRI) is used in prenatal diagnosis and to
assess early brain development. Accurate segmentation of the different brain
tissues is a vital step in several brain analysis tasks, such as cortical
surface reconstruction and tissue thickness measurements. Fetal MRI scans,
however, are prone to motion artifacts that can affect the correctness of both
manual and automatic segmentation techniques. In this paper, we propose a novel
network structure that can simultaneously generate conditional atlases and
predict brain tissue segmentation, called CAS-Net. The conditional atlases
provide anatomical priors that can constrain the segmentation connectivity,
despite the heterogeneity of intensity values caused by motion or partial
volume effects. The proposed method is trained and evaluated on 253 subjects
from the developing Human Connectome Project (dHCP). The results demonstrate
that the proposed method can generate conditional age-specific atlas with sharp
boundary and shape variance. It also segment multi-category brain tissues for
fetal MRI with a high overall Dice similarity coefficient (DSC) of $85.2\%$ for
the selected 9 tissue labels.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:23:02 GMT""}]","2022-05-18"
"2205.08240","Karthik Gvb","Karthik GVB, Vivek S. Borkar, Gaurav S. Kasbekar","Scheduling in Wireless Networks using Whittle Index Theory","6 pages, 9 figures. arXiv admin note: substantial text overlap with
  arXiv:1910.04402",,,,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  We consider the problem of scheduling packet transmissions in a wireless
network of users while minimizing the energy consumed and the transmission
delay. A challenge is that transmissions of users that are close to each other
mutually interfere, while users that are far apart can transmit simultaneously
without much interference. Each user has a queue of packets that are
transmitted on a single channel and mutually non interfering users reuse the
spectrum. Using the theory of Whittle index for cost minimizing restless
bandits, we design four index-based policies and compare their performance with
that of the well-known policies: Slotted ALOHA, maximum weight scheduling,
quadratic Lyapunov drift, Cella and Cesa Bianchi algorithm, and two Whittle
index based policies from a recently published paper. We make the code used to
perform our simulations publicly available, so that it can be used for future
work by the research community at large.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:23:24 GMT""}]","2022-05-18"
"2205.08241","Nicholas Boardman","Nicholas F. Boardman, Gail Zasowski, Jeffrey A. Newman, Sebastian F.
  Sanchez, Brett Andrews, Jorge K. Barrera-Ballesteros, Jianhui Lian, Rog\'erio
  Riffel, Rogemar A. Riffel, Adam Schaefer, Kevin Bundy","How well do local relations predict gas-phase metallicity gradients?
  Results from SDSS-IV MaNGA","21 pages, 23 figures. Accepted by MNRAS; some minor corrections made
  following receipt of journal proofs",,"10.1093/mnras/stac1475",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Gas-phase metallicity gradients in galaxies provide important clues to those
galaxies' formation histories. Using SDSS-IV MaNGA data, we previously
demonstrated that gas metallicity gradients vary systematically and
significantly across the galaxy mass--size plane: at stellar masses beyond
approximately $10^{10}$ $\mathrm{M_\odot}$, more extended galaxies display
steeper gradients (in units of $\mathrm{dex/R_e}$) at a given stellar mass.
Here, we set out to develop a physical interpretation of these findings by
examining the ability of local $\sim$kpc-scale relations to predict the
gradient behaviour along the mass--size plane. We find that local stellar mass
surface density, when combined with total stellar mass, is sufficient to
reproduce the overall mass--size trend in a qualitative sense. We further find
that we can improve the predictions by correcting for residual trends relating
to the recent star formation histories of star-forming regions. However, we
find as well that the most extended galaxies display steeper average gradients
than predicted, even after correcting for residual metallicity trends with
other local parameters. From these results, we argue that gas-phase metallicity
gradients can largely be understood in terms of known local relations, but we
also discuss some possible physical causes of discrepant gradients.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:34:27 GMT""},{""version"":""v2"",""created"":""Wed, 25 May 2022 13:29:39 GMT""},{""version"":""v3"",""created"":""Tue, 14 Jun 2022 11:03:14 GMT""}]","2022-06-15"
"2205.08242","Shahid Shah","Aaqib Bulla and Shahid M Shah","Outage Analysis of Energy Efficiency in a Finite-Element-IRS Aided
  Communication System","18 Pages, 6 Figures, 2 Tables",,,,"cs.IT eess.SP math.IT math.PR","http://creativecommons.org/licenses/by/4.0/","  In this paper, we study the performance of an energy efficient wireless
communication system, assisted by a finite-element-intelligent reflecting
surface (IRS). With no instantaneous channel state information (CSI) at the
transmitter, we characterize the system performance in terms of the outage
probability (OP) of energy efficiency (EE). Depending upon the availability of
line-of-sight (LOS) paths, we analyze the system for two different channel
models, viz. Rician and Rayleigh. For an arbitrary number of IRS elements
$(N)$, we derive the approximate closed-form solutions for the OP of EE, using
Laguerre series and moment matching methods. The analytical results are
validated using the Monte-Carlo simulations. Moreover, we also quantify the
rate of convergence of the derived expressions to the central limit theorem
(CLT) approximations using the \textit{Berry-Esseen} inequality. Further, we
prove that the OP of EE is a strict pseudo-convex function of the transmit
power and hence, has a unique global minimum. To obtain the optimal transmit
power, we solve the OP of EE as a constrained optimization problem. To the best
of our knowledge, the OP of EE as a performance metric, has never been
previously studied in IRS-assisted wireless communication systems.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:35:55 GMT""}]","2022-05-18"
"2205.08243","Changgang Zheng","Changgang Zheng, Zhaoqi Xiong, Thanh T Bui, Siim Kaupmees, Riyad
  Bensoussane, Antoine Bernabeu, Shay Vargaftik, Yaniv Ben-Itzhak, Noa
  Zilberman","IIsy: Practical In-Network Classification","(14 pages body, 19 pages total, 19 figures)",,,,"cs.NI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The rat race between user-generated data and data-processing systems is
currently won by data. The increased use of machine learning leads to further
increase in processing requirements, while data volume keeps growing. To win
the race, machine learning needs to be applied to the data as it goes through
the network. In-network classification of data can reduce the load on servers,
reduce response time and increase scalability. In this paper, we introduce
IIsy, implementing machine learning classification models in a hybrid fashion
using off-the-shelf network devices. IIsy targets three main challenges of
in-network classification: (i) mapping classification models to network devices
(ii) extracting the required features and (iii) addressing resource and
functionality constraints. IIsy supports a range of traditional and ensemble
machine learning models, scaling independently of the number of stages in a
switch pipeline. Moreover, we demonstrate the use of IIsy for hybrid
classification, where a small model is implemented on a switch and a large
model at the backend, achieving near optimal classification results, while
significantly reducing latency and load on the servers.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:37:15 GMT""},{""version"":""v2"",""created"":""Sun, 19 Jun 2022 22:57:41 GMT""}]","2022-06-22"
"2205.08244","Mikhail Dubashinskiy","Mikhail Dubashinskiy","Growth and nodal current of complexified horocycle eigenfunctions","v.2: supplemented with explicit calculation of growth of functions",,,,"math.SP math-ph math.AP math.CV math.MP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study horocycle eigenfunctions at Lobachevsky plane. These are functions
$u\colon \mathbb H=\mathbb C^+=\{z\in\mathbb C\colon \Im z>0\}\to\mathbb C$
such that $\left(-y^2\left(\frac{\partial^2}{\partial
x^2}+\frac{\partial^2}{\partial y^2}\right)+ 2i\tau y\frac{\partial}{\partial
x}\right)u(x+iy)=s^2 u(x+iy)$, $x+iy\in\mathbb C^+$, with $\tau,s\in\mathbb R$,
$\tau$ large and $s/\tau$ small. In other words, we study eigenfunctions of
\emph{magnetic} quantum Hamiltonian on hyperbolic plane. By semiclassical
correspondence principle, asymptotic behavior of such functions is related to
horocycle flow on $T\mathbb H$. If a sequence of horocycle functions possesses
microlocal quantum unique ergodicity at the admissible energy level (with
$\hbar=1/\tau$) then we may find asymptotic distribution of divisor of $u$
analytically continued to the complexified Lobachevsky plane $\mathbb H^\mathbb
C$. This is done by establishing the asymptotic estimates on $|u|$ in $\mathbb
H^\mathbb C$. The growth of functions $u$ as $\tau\to\infty$ turns to be
governed by the growth of complexified \emph{gauge factor} occurring in
$\tau$-automorphic kernels for functions on $\mathbb H$.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:37:52 GMT""},{""version"":""v2"",""created"":""Thu, 15 Sep 2022 21:07:54 GMT""}]","2022-09-19"
"2205.08245","Tobias Kallehauge MSc","Tobias Kallehauge","Bayesian Inference for Non-Parametric Extreme Value Theory",,,,,"stat.ME math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Statistical inference for extreme values of random events is difficult in
practice due to low sample sizes and inaccurate models for the studied rare
events. If prior knowledge for extreme values is available, Bayesian statistics
can be applied to reduce the sample complexity, but this requires a known
probability distribution. By working with the quantiles for extremely low
probabilities (in the order of $10^{-2}$ or lower) and relying on their
asymptotic normality, inference can be carried out without assuming any
distributions. Despite relying on asymptotic results, it is shown that a
Bayesian framework that incorporates prior information can reduce the number of
observations required to estimate a particular quantile to some level of
accuracy.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:40:46 GMT""}]","2022-05-18"
"2205.08246","Run-Qiu Yang","Run-Qiu Yang, Li Li and Rong-Gen Cai","When null energy condition meets ADM mass","7 pages, no figure","Commun. Theor. Phys. 74, 095403, 2022","10.1088/1572-9494/ac84cd",,"gr-qc hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a conjecture on the lower bound of the ADM mass $M$ by using the null
energy condition. The conjecture includes a Penrose-like inequality
$3M\geq\kappa\mathcal{A}/(4\pi)+\sqrt{\mathcal{A}/4\pi}$ and the Penrose
inequality $ 2M\geq\sqrt{{\mathcal{A}}/{4\pi}}$ with $\mathcal{A}$ the event
horizon area and $\kappa$ the surface gravity. Both the conjecture in the
static spherically symmetric case and the Penrose inequality for a dynamical
spacetime with spherical symmetry are proved by imposing the null energy
condition. We then generalize the conjecture to a general dynamical spacetime.
Our results raise a new challenge for the famous unsettled question in general
relativity: in what general case can the null energy condition replace other
energy conditions to ensure the Penrose inequality?
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:42:03 GMT""}]","2022-09-02"
"2205.08247","Joao Monteiro","Joao Monteiro, Mohamed Osama Ahmed, Hossein Hajimirsadeghi, Greg Mori","Monotonicity Regularization: Improved Penalties and Novel Applications
  to Disentangled Representation Learning and Robust Classification","Accepted to UAI 2022",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study settings where gradient penalties are used alongside risk
minimization with the goal of obtaining predictors satisfying different notions
of monotonicity. Specifically, we present two sets of contributions. In the
first part of the paper, we show that different choices of penalties define the
regions of the input space where the property is observed. As such, previous
methods result in models that are monotonic only in a small volume of the input
space. We thus propose an approach that uses mixtures of training instances and
random points to populate the space and enforce the penalty in a much larger
region. As a second set of contributions, we introduce regularization
strategies that enforce other notions of monotonicity in different settings. In
this case, we consider applications, such as image classification and
generative modeling, where monotonicity is not a hard constraint but can help
improve some aspects of the model. Namely, we show that inducing monotonicity
can be beneficial in applications such as: (1) allowing for controllable data
generation, (2) defining strategies to detect anomalous data, and (3)
generating explanations for predictions. Our proposed approaches do not
introduce relevant computational overhead while leading to efficient procedures
that provide extra benefits over baseline models.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:42:45 GMT""}]","2022-05-18"
"2205.08248","Melanie M\""uller","Natalia Mart\'in Saban\'es, Faruk Krecinic, Takashi Kumagai, Fabian
  Schulz, Martin Wolf and Melanie M\""uller","Femtosecond Thermal and Nonthermal Hot Electron Tunneling inside a
  Photoexcited Tunnel Junction","32 pages, 5 figures, supporting information",,"10.1021/acsnano.2c04846",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Efficient operation of electronic nanodevices at ultrafast speeds requires
understanding and control of the currents generated by femtosecond bursts of
light. Ultrafast laser-induced currents in metallic nanojunctions can originate
from photo-assisted hot electron tunneling or lightwave-induced tunneling. Both
processes can drive localized photocurrents inside a scanning tunneling
microscope (STM) on femto- to attosecond time scales, enabling ultrafast STM
with atomic spatial resolution. Femtosecond laser excitation of a metallic
nanojunction, however, also leads to the formation of a transient thermalized
electron distribution, but the tunneling of thermalized hot electrons on time
scales faster than electron-lattice equilibration is not well understood. Here,
we investigate ultrafast electronic heating and transient thermionic tunneling
inside a metallic photoexcited tunnel junction and its role in the generation
of ultrafast photocurrents in STM. Phase-resolved sampling of broadband THz
pulses via the THz-field-induced modulation of ultrafast photocurrents allows
us to probe the electronic temperature evolution inside the STM tip, and to
observe the competition between instantaneous and delayed tunneling due to
nonthermal and thermal hot electron distributions in real time. Our results
reveal the pronounced nonthermal character of photo-induced hot electron
tunneling, and provide a detailed microscopic understanding of hot electron
dynamics inside a laser-excited tunnel junction.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:43:43 GMT""}]","2022-11-16"
"2205.08249","Daniel Rotman","Daniel Rotman, Yevgeny Yaroker, Elad Amrani, Udi Barzelay, Rami
  Ben-Ari","Learnable Optimal Sequential Grouping for Video Scene Detection",,"In Proceedings of the 28th ACM International Conference on
  Multimedia, pp. 1958-1966. 2020","10.1145/3394171.3413612",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Video scene detection is the task of dividing videos into temporal semantic
chapters. This is an important preliminary step before attempting to analyze
heterogeneous video content. Recently, Optimal Sequential Grouping (OSG) was
proposed as a powerful unsupervised solution to solve a formulation of the
video scene detection problem. In this work, we extend the capabilities of OSG
to the learning regime. By giving the capability to both learn from examples
and leverage a robust optimization formulation, we can boost performance and
enhance the versatility of the technology. We present a comprehensive analysis
of incorporating OSG into deep learning neural networks under various
configurations. These configurations include learning an embedding in a
straight-forward manner, a tailored loss designed to guide the solution of OSG,
and an integrated model where the learning is performed through the OSG
pipeline. With thorough evaluation and analysis, we assess the benefits and
behavior of the various configurations, and show that our learnable OSG
approach exhibits desirable behavior and enhanced performance compared to the
state of the art.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:45:03 GMT""}]","2022-06-10"
"2205.08250","Georgios Daskalopoulos","Georgios Daskalopoulos and Karen Uhlenbeck","Analytic properties of Stretch maps and geodesic laminations",,,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a 1995 preprint, William Thurston outlined a Teichmueller theory for
hyperbolic surfaces based on maps between surfaces which minimize the Lipschitz
constant. In this paper we continue the analytic investigation into best
Lipschitz maps which we began in our previous paper. In the spirit of the
construction of infinity harmonic functions, we obtain best Lipschitz maps u as
limits of minimizers of Schatten-von Neumann integrals in a fixed homotopy
class of maps between two hyperbolic surfaces. We construct Lie algebra valued
dual functions which minimize a dual Schatten von-Neumann integral and limit on
a Lie algebra valued function v of bounded variation with least gradient
properties. The main result of the paper is that the support of the measure
which is a derivative of v lies on the canonical geodesic lamination
constructed by Thurston and further studied by Gueritaud-Kassel. In the sequel
paper we will use these results to investigate the dependence on the hyperbolic
structures and construct a variety of transverse measures. This should provide
information about the geometry and make contact with results of the Thurston
school.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:50:03 GMT""}]","2022-05-18"
"2205.08251","Francesco Navarra","Carmelo Cisto, Francesco Navarra and Rosanna Utano","On Gr\""obner bases and Cohen-Macaulay property of closed path
  polyominoes","18 pages, 20 figures","The Electronic Journal of Combinatorics, 29 (2022)","10.37236/11122",,"math.AC math.CO","http://creativecommons.org/licenses/by/4.0/","  In this paper we introduce some monomial orders for the class of closed path
polyominoes and we prove that the set of the generators of the polyomino ideal
attached to a closed path forms the reduced Gr\""obner basis with respect to
these monomial orders. It is known that the polyomino ideal attached to a
closed path containing an L-configuration or a ladder of at least three steps,
equivalently having no zig-zag walks, is prime. As a consequence, we obtain
that the coordinate ring of a closed path having no zig-zag walks is a normal
Cohen-Macaulay domain.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:50:14 GMT""}]","2022-09-13"
"2205.08252","Nazar Waheed","Nazar Waheed, Muhammad Ikram, Saad Sajid Hashmi, Xiangjian He,
  Priyadarsi Nanda","An Empirical Assessment of Security and Privacy Risks of Web
  based-Chatbots","Submitted to WISE 2020 Conference",,,,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  Web-based chatbots provide website owners with the benefits of increased
sales, immediate response to their customers, and insight into customer
behaviour. While Web-based chatbots are getting popular, they have not received
much scrutiny from security researchers. The benefits to owners come at the
cost of users' privacy and security. Vulnerabilities, such as tracking cookies
and third-party domains, can be hidden in the chatbot's iFrame script. This
paper presents a large-scale analysis of five Web-based chatbots among the top
1-million Alexa websites. Through our crawler tool, we identify the presence of
chatbots in these 1-million websites. We discover that 13,515 out of the top
1-million Alexa websites (1.59%) use one of the five analysed chatbots. Our
analysis reveals that the top 300k Alexa ranking websites are dominated by
Intercom chatbots that embed the least number of third-party domains. LiveChat
chatbots dominate the remaining websites and embed the highest samples of
third-party domains. We also find that 850 (6.29%) of the chatbots use insecure
protocols to transfer users' chats in plain text. Furthermore, some chatbots
heavily rely on cookies for tracking and advertisement purposes. More than
two-thirds (68.92%) of the identified cookies in chatbot iFrames are used for
ads and tracking users. Our results show that, despite the promises for
privacy, security, and anonymity given by the majority of the websites,
millions of users may unknowingly be subject to poor security guarantees by
chatbot service providers
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:55:36 GMT""}]","2022-05-18"
"2205.08253","Saber Salehkaleybar","Saber Salehkaleybar, Sadegh Khorasani, Negar Kiyavash, Niao He,
  Patrick Thiran","Momentum-Based Policy Gradient with Second-Order Information",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Variance-reduced gradient estimators for policy gradient methods have been
one of the main focus of research in the reinforcement learning in recent years
as they allow acceleration of the estimation process. We propose a
variance-reduced policy-gradient method, called SHARP, which incorporates
second-order information into stochastic gradient descent (SGD) using momentum
with a time-varying learning rate. SHARP algorithm is parameter-free, achieving
$\epsilon$-approximate first-order stationary point with $O(\epsilon^{-3})$
number of trajectories, while using a batch size of $O(1)$ at each iteration.
Unlike most previous work, our proposed algorithm does not require importance
sampling which can compromise the advantage of variance reduction process.
Moreover, the variance of estimation error decays with the fast rate of
$O(1/t^{2/3})$ where $t$ is the number of iterations. Our extensive
experimental evaluations show the effectiveness of the proposed algorithm on
various control tasks and its advantage over the state of the art in practice.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:56:50 GMT""},{""version"":""v2"",""created"":""Thu, 18 Aug 2022 09:01:16 GMT""}]","2022-08-19"
"2205.08256","Patrizia Paggio","Sidsel Boldsen and Patrizia Paggio","Letters From the Past: Modeling Historical Sound Change Through
  Diachronic Character Embeddings","Accepted as long paper at ACL 2022",,,,"cs.CL","http://creativecommons.org/licenses/by-nc-nd/4.0/","  While a great deal of work has been done on NLP approaches to lexical
semantic change detection, other aspects of language change have received less
attention from the NLP community. In this paper, we address the detection of
sound change through historical spelling. We propose that a sound change can be
captured by comparing the relative distance through time between their
distributions using PPMI character embeddings. We verify this hypothesis in
synthetic data and then test the method's ability to trace the well-known
historical change of lenition of plosives in Danish historical sources. We show
that the models are able to identify several of the changes under consideration
and to uncover meaningful contexts in which they appeared. The methodology has
the potential to contribute to the study of open questions such as the relative
chronology of sound shifts and their geographical distribution.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:57:17 GMT""}]","2022-05-18"
"2205.08257","Daniel Rotman","Daniel Rotman, Ophir Azulai, Inbar Shapira, Yevgeny Burshtein, Udi
  Barzelay","Detection Masking for Improved OCR on Noisy Documents",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Optical Character Recognition (OCR), the task of extracting textual
information from scanned documents is a vital and broadly used technology for
digitizing and indexing physical documents. Existing technologies perform well
for clean documents, but when the document is visually degraded, or when there
are non-textual elements, OCR quality can be greatly impacted, specifically due
to erroneous detections. In this paper we present an improved detection network
with a masking system to improve the quality of OCR performed on documents. By
filtering non-textual elements from the image we can utilize document-level OCR
to incorporate contextual information to improve OCR results. We perform a
unified evaluation on a publicly available dataset demonstrating the usefulness
and broad applicability of our method. Additionally, we present and make
publicly available our synthetic dataset with a unique hard-negative component
specifically tuned to improve detection results, and evaluate the benefits that
can be gained from its usage
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:59:18 GMT""}]","2022-05-18"
"2205.08258","Kyoungsik Kim","Monu Nath Baitha and Kyoungsik Kim","Polarization manipulation of giant photonic spin Hall effect using
  wave-guiding effect","26 Pages, 17 Figures",,"10.1063/5.0100554",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In plasmonic systems, the enhanced photonic spin Hall effect (PSHE) was
previously possible only for horizontal polarization. By employing the
wave-guiding surface plasmon resonance (WG-SPR) effect, we report a giant
photonic spin Hall effect (G-PSHE) of reflected light for both horizontal and
vertical polarization waves. We investigated the polarization-manipulated
G-PSHE in the Kretschmann configuration with an additional glass dielectric
layer. This additional dielectric layer allowed us to achieve millimeter-scale
(more than 2 mm to sub-millimeter) G-PSHE. We achieved polarization
manipulation by designing novel structures employing wave-guiding and SPR
theory. Using a simulation study, we investigated the impact of an additional
thin dielectric layer on G-PSHE. This study enables the potential application
of both horizontal and vertical polarization-based quantum devices and sensors
for which light spin plays a pivotal role.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:59:35 GMT""}]","2022-08-10"
"2205.08259","Jianda Wu","Yunjing Gao, Jiahao Yang, Zhenyu Zhu, Yosuke Mizuno, and Jianda Wu","A Proposal for Detecting Superfluidity in Neutron Stars","5 pages, 5 figures",,,,"gr-qc astro-ph.HE cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  Based on the GW dispersion relation raised in [1], we investigate the
possible reflection of gravitational wave (GW) by superfluidity (SF) in the
neutron star, provided its high density and dissipationless properties.
Following this scenario, an experimental proposal is raised to probe the
expected SF in neutron star by means of GW detection. Two types of binary
systems are considered, neutron star-black hole and binary neutron star
systems, with weak gravitational field condition imposed. Non-negligible
modulation on the total signal caused by the GW reflection is found, which
contributes amplitude and phase variations distinguishable from the primitive
sine signal. Furthermore, we show that it is possible for such modulations to
be detected by the Cosmic Explorer and Einstein Telescope at $100\,\mbox{Mpc}$.
Identification of those signals can evince the existence of the long-sought SF
in neutron stars as well as the exotic superfluidity-induced GW reflection.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:59:50 GMT""},{""version"":""v2"",""created"":""Wed, 19 Oct 2022 05:14:43 GMT""}]","2022-10-20"
"2205.08260","Mayank Goswami","Ankur Kumar and Mayank Goswami","LabVIEW is faster and C is economical interfacing tool for UCT
  automation","15 pages, 9 figures, 2 tables, 23 references",,,,"cs.PL cs.RO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  An in-house developed 2D ultrasound computerized Tomography system is fully
automated. Performance analysis of instrument and software interfacing soft
tools, namely the LabVIEW, MATLAB, C, and Python, is presented. The instrument
interfacing algorithms, hardware control algorithms, signal processing, and
analysis codes are written using above mentioned soft tool platforms. Total of
eight performance indices are used to compare the ease of (a) realtime control
of electromechanical assembly, (b) sensors, instruments integration, (c)
synchronized data acquisition, and (d) simultaneous raw data processing. It is
found that C utilizes the least processing power and performs a lower number of
processes to perform the same task. In runtime analysis (data acquisition and
realtime control), LabVIEW performs best, taking 365.69s in comparison to
MATLAB (623.83s), Python ( 1505.54s), and C (1252.03s) to complete the
experiment. Python performs better in establishing faster interfacing and
minimum RAM usage. LabVIEW is recommended for its fast process execution. C is
recommended for the most economical implementation. Python is recommended for
complex system automation having a very large number of components involved.
This article provides a methodology to select optimal soft tools for instrument
automation-related aspects.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:00:25 GMT""}]","2022-05-18"
"2205.08261","Yorgo Senikoglu","Tekin Dereli, Ozay Gurtug, Mustafa Halilsoy, Yorgo Senikoglu","Neutrino Fields in a Sandwich Gravitational Wave Background","Accepted Version to appear in Class.Quant.Grav",,"10.1088/1361-6382/ac9bc6",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sandwich gravitational waves are given globally in terms of step functions at
the boundaries. Linearized Einstein-Weyl equations are solved exactly in this
background in Rosen coordinates. Depending on the geometry and composition of
the sandwich wave, the neutrino's energy-momentum redistributes itself. At the
test field level, since the background will not change, the neutrino's energy
density in particular will show variations between positive and negative
extrema when crossing the sandwich wave. This may reveal facts about the weakly
interacting neutrinos in cosmology.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:02:14 GMT""},{""version"":""v2"",""created"":""Wed, 19 Oct 2022 13:40:29 GMT""}]","2022-11-23"
"2205.08262","Tao Guo","Deheng Yuan, Tao Guo, Bo Bai, and Wei Han","Lossy Computing with Side Information via Multi-Hypergraphs",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a problem of coding for computing, where the decoder wishes to
estimate a function of its local message and the source message at the encoder
within a given distortion. We show that the rate-distortion function can be
characterized through a characteristic multi-hypergraph, which simplifies the
evaluation of the rate-distortion function.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:02:34 GMT""}]","2022-05-18"
"2205.08263","Ali Kariminezhad","Ali Kariminezhad, Soheil Gherekhloo, and Aydin Sezgin","Contact-less Material Probing with Distributed Sensors: Joint Sensing
  and Communication Optimization","arXiv admin note: text overlap with arXiv:1902.11117",,,,"cs.IT eess.SP math.IT","http://creativecommons.org/licenses/by/4.0/","  The utilization of RF signals to probe material properties of objects is of
huge interest both in academia as well as industry. To this end, a setup is
investigated, in which a transmitter equipped with a two-dimensional
multi-antenna array dispatches a signal, which hits objects in the environment
and the reflections from the objects are captured by distributed sensors. The
received signal at those sensors are then amplified and forwarded to a multiple
antenna fusion center, which performs space-time post-processing in order to
optimize the information extraction. In this process, optimal design of power
allocation per object alongside sensors amplifications is of crucial
importance. Here, the power allocation and sensors amplifications is jointly
optimized, given maximum-ratio combining (MRC) at the fusion center. We
formulate this challenge as a sum-power minimization under per-object SINR
constraints, a sum-power constraint at the transmitter and individual power
constraints at the sensors. Moreover, the advantage of deploying zero-forcing
(ZF) and minimum mean-squared error (MMSE) at the fusion center is discussed.
Asymptotic analysis is also provided for the case that large number of sensors
are deployed in the sensing environment.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:03:15 GMT""}]","2022-05-18"
"2205.08264","Lachlan Urquhart Ph.D","Lachlan Urquhart, Alex Laffer and Diana Miranda","Working with Affective Computing: Exploring UK Public Perceptions of AI
  enabled Workplace Surveillance",,,,,"cs.HC cs.CY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper explores public perceptions around the role of affective computing
in the workplace. It uses a series of design fictions with 46 UK based
participants, unpacking their perspectives on the advantages and disadvantages
of tracking the emotional state of workers. The scenario focuses on mundane
uses of biometric sensing in a sales environment, and how this could shape
management approaches with workers. The paper structure is as follows: section
1 provides a brief introduction; section 2 provides an overview of the
innovative design fiction methodology; section 3 explores wider shifts around
IT in the workplace; section 4 provides some legal analysis exploring emergence
of AI in the workplace; and section 5 presents themes from the study data. The
latter section includes discussion on concerns around functionality and
accuracy of affective computing systems, and their impacts on surveillance,
human agency, and worker/management interactions.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:03:20 GMT""}]","2022-05-18"
"2205.08265","Nadia Daoudi Ms","Nadia Daoudi, Kevin Allix, Tegawend\'e F. Bissyand\'e and Jacques
  Klein","A two-steps approach to improve the performance of Android malware
  detectors",,,,,"cs.CR cs.AI","http://creativecommons.org/licenses/by/4.0/","  The popularity of Android OS has made it an appealing target to malware
developers. To evade detection, including by ML-based techniques, attackers
invest in creating malware that closely resemble legitimate apps. In this
paper, we propose GUIDED RETRAINING, a supervised representation learning-based
method that boosts the performance of a malware detector. First, the dataset is
split into ""easy"" and ""difficult"" samples, where difficulty is associated to
the prediction probabilities yielded by a malware detector: for difficult
samples, the probabilities are such that the classifier is not confident on the
predictions, which have high error rates. Then, we apply our GUIDED RETRAINING
method on the difficult samples to improve their classification. For the subset
of ""easy"" samples, the base malware detector is used to make the final
predictions since the error rate on that subset is low by construction. For the
subset of ""difficult"" samples, we rely on GUIDED RETRAINING, which leverages
the correct predictions and the errors made by the base malware detector to
guide the retraining process. GUIDED RETRAINING focuses on the difficult
samples: it learns new embeddings of these samples using Supervised Contrastive
Learning and trains an auxiliary classifier for the final predictions. We
validate our method on four state-of-the-art Android malware detection
approaches using over 265k malware and benign apps, and we demonstrate that
GUIDED RETRAINING can reduce up to 40.41% prediction errors made by the malware
detectors. Our method is generic and designed to enhance the classification
performance on a binary classification task. Consequently, it can be applied to
other classification problems beyond Android malware detection.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:04:17 GMT""}]","2022-05-18"
"2205.08266","Xin Zhong","Yang Liu, Xin Zhong","Entropy-bounded solutions to the 3D compressible heat-conducting
  magnetohydrodynamic equations with vacuum at infinity","33 pages. arXiv admin note: text overlap with arXiv:2111.14057 by
  other authors","Journal of Differential Equations, 358 (2023), 295-338","10.1016/j.jde.2023.02.020",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The mathematical analysis on the behavior of the entropy for viscous,
compressible, and heat conducting magnetohydrodynamic flows near the vacuum
region is a challenging problem as the governing equation for entropy is highly
degenerate and singular in the vacuum region. In particular, it is unknown
whether the entropy remains its boundedness. In the present paper, we
investigate the Cauchy problem to the three-dimensional (3D) compressible
heat-conducting magnetohydrodynamic equations with vacuum at infinity only. We
show that the uniform boundedness of the entropy and the $L^2$ regularities of
the velocity and temperature can be propagated provided that the initial
density decays suitably slow at infinity. The main tools are based on
singularly weighted energy estimates and De Giorgi type iteration techniques
developed by Li and Xin (arXiv:2111.14057) for the 3D full compressible
Navier-Stokes system. Some new mathematical techniques and useful estimates are
developed to deduce the lower and upper bounds on the entropy.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:04:50 GMT""}]","2023-02-23"
"2205.08267","Pierre Bouvier","Pierre Bouvier, Alireza Sasani, Eric Bousquet, Mael Guennou, Joaquim
  Agostinho Moreira","Lattice dynamics and Raman spectrum of supertetragonal PbVO3","11 pages, 8 figures, 6 Tables, Supplemental Information 3 figures and
  6 Tables, under review",,"10.1016/j.jpcs.2022.111092",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Lead vanadate PbVO3 is a polar crystal with a P4mm space group at ambient
conditions. It is isostructural with the model soft-mode driven ferroelectric
PbTiO3, but differs from it by the so-called 'supertetragonal' elongation of
its unit cell. In this paper, we report a combined study of the lattice
dynamics of PbVO3 by Raman spectroscopy at room temperature and first-principle
calculations. All zone-center transverse optical (TO) phonon modes are
identified by polarized, angle-dependent Raman spectroscopy and assigned as
follows: E modes at 136, 269, 374 and 508 cm-1, A1 modes at 188, 429 and 874
cm-1 and B1 mode at 319 cm-1. The calculations confirm the experimental
symmetry assignment and allow to obtain the longitudinal (LO) phonons
wavenumbers. Besides, we analyze the mode eigenvectors in detail, in order to
identify the atomic displacements associated with each mode and compare them
with PbTiO3. In spite of their differences in chemistry and strain, the phonon
eigenvectors are found to be remarkably comparable in both compounds. We
discuss the position of the ferroelectric soft mode in PbVO3 as compared to
PbTiO3. A sizeable splitting of the B1+E modes appears as a characteristic
feature of supertetragonal phases. The peculiarity of the vanadyl V-O bond
frequency in PbVO3 is also addressed.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:07:29 GMT""},{""version"":""v2"",""created"":""Fri, 16 Sep 2022 07:23:58 GMT""}]","2022-11-30"
"2205.08268","Gen Chiaki","Gen Chiaki and John H. Wise","Triggered Population III star formation: the effect of H$_2$
  self-shielding","14 pages, 7 figures, 3 tables, accepted to MNRAS",,"10.1093/mnras/stad433",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The multiplicity of metal-free (Population III) stars may influence their
feedback efficiency within their host dark matter halos, affecting subsequent
metal enrichment and the transition to galaxy formation. Radiative feedback
from massive stars can trigger nearby star formation in dense self-shielded
clouds. In model radiation self-shielding, the H$_2$ column density must be
accurately computed. In this study, we compare two local approximations based
on the density gradient and Jeans length with a direct integration of column
density along rays. After the primary massive star forms, we find that no
secondary stars form for both the direct integration and density gradient
approaches. The approximate method reduces the computation time by a factor of
2. The Jeans length approximation overestimates the H$_2$ column density by a
factor of 10, leading to five numerically enhanced self-shielded, star-forming
clumps. We conclude that the density gradient approximation is sufficiently
accurate for larger volume galaxy simulations, although one must still caution
that the approximation cannot fully reproduce the result of direct integration.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:08:14 GMT""},{""version"":""v2"",""created"":""Sat, 4 Feb 2023 00:24:10 GMT""}]","2023-02-15"
"2205.08269","Jongkuk Kim","Dong Woo Kang, Jongkuk Kim, Takaaki Nomura, Hiroshi Okada","Natural mass hierarchy among three heavy Majorana neutrinos for resonant
  leptogenesis under modular $A_4$ symmetry","20 pages, 2 tables, 6 figures",,,"KIAS-P22026, APCTP Pre2022 - 005","hep-ph","http://creativecommons.org/licenses/by/4.0/","  It is clear that matter is dominant in the Universe compared to antimatter.
We call this problem baryon asymmetry. The baryon asymmetry is experimentally
determined by both cosmic microwave background and big bang nucleosynthesis
measurements. To resolve the baryon number asymmetry of the Universe as well as
neutrino oscillations, we study a radiative seesaw model in a modular $A_4$
symmetry. Degenerate heavy Majorana neutrino masses can be naturally realized
in an appropriate assignments under modular $A_4$ with large imaginary part of
modulus $\tau$, and it can induce measured baryon number via resonant
leptogenesis that is valid in around TeV scale energy theory. We also find that
the dominant contribution to the CP asymmetry arises from Re[$\tau$] through
our numerical analysis satisfying the neutrino oscillation data.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:08:56 GMT""}]","2022-05-18"
"2205.08270","Rose Bohrer","Rose Bohrer","Chemical Case Studies in KeYmaera X","17 pages. Preprint of submission to FMICS 2022",,,,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Safety-critical chemical processes are the backbone of multi-billion-dollar
industries, thus society deserves the strongest possible guarantees that they
are safe. To that end, models of chemical processes are well-studied in the
formal methods literature, including hybrid systems models which combine
discrete and continuous dynamics. This paper is the first to use the KeYmaera X
theorem-prover to verify chemical models with differential dynamic logic. Our
case studies are novel in combining the following: we provide strong
general-case correctness theorems, use particularly rich hybrid dynamics, and
have particularly rigorous proofs. This novel combination is made possible by
KeYmaera X.
  Simultaneously, we tell a general story about KeYmaera X: recent advances in
automated reasoning about safety and liveness for differential equations have
enabled elegant proofs about reaction dynamics.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:09:20 GMT""}]","2022-05-18"
"2205.08271","Liang-Jun Zhai","Liang-Jun Zhai, Guang-Yao Huang and Shuai Yin","Nonequilibrium dynamics of the localization-delocalization transition in
  the non-Hermitian Aubry-Andr\'{e} model",,,"10.1103/PhysRevB.106.014204",,"cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we investigate the driven dynamics of the localization
transition in the non-Hermitian Aubry-Andr\'{e} model with the periodic
boundary condition. Depending on the strength of the quasi-periodic potential
$\lambda$, this model undergoes a localization-delocalization phase transition.
We find that the localization length $\xi$ satisfies $\xi\sim
\varepsilon^{-\nu}$ with $\varepsilon$ being the distance from the critical
point and $\nu=1$ being a universal critical exponent independent of the
non-Hermitian parameter. In addition, from the finite-size scaling of the
energy gap between the ground state and the first excited state, we determine
the dynamic exponent $z$ as $z=2$. The critical exponent of the inverse
participation ratio (IPR) for the $n$th eigenstate is also determined as
$s=0.1197$. By changing $\varepsilon$ linearly to cross the critical point, we
find that the driven dynamics can be described by the Kibble-Zurek scaling
(KZS). Moreover, we show that the KZS with the same set of the exponents can be
generalized to the localization phase transitions in the excited states.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:12:39 GMT""},{""version"":""v2"",""created"":""Wed, 25 May 2022 13:41:27 GMT""},{""version"":""v3"",""created"":""Sat, 30 Jul 2022 03:18:46 GMT""}]","2022-08-02"
"2205.08272","Zhaolin Wang","Zhaolin Wang, Xidong Mu, Yuanwei Liu, Xiaodong Xu, Ping Zhang","NOMA-aided Joint Communication, Sensing, and Multi-tier Computing
  Systems","30 pages, 8 figures",,"10.1109/JSAC.2022.3229447",,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A non-orthogonal multiple access (NOMA)-aided joint communication, sensing,
and multi-tier computing (JCSMC) framework is proposed. In this framework, a
multi-functional base station (BS) carries out target sensing, while providing
edge computing services to the nearby users. To enhance the computation
efficiency, the multi-tier computing structure is exploited, where the BS can
further offload the computation tasks to a powerful Cloud server (CS). The
potential benefits of employing NOMA in the proposed JCSMC framework are
investigated, which can maximize the computation offloading capacity and
suppress the inter-function interference. Based on the proposed framework, the
transmit beamformer of the BS and computation resource allocation at the BS and
the CS are jointly optimized to maximize the computation rate subject to the
communication-computation causality and the sensing quality constraints. Both
partial and binary computation offloading modes are considered: 1) For the
partial offloading mode, a weighted minimum mean square error based alternating
optimization algorithm is proposed to solve the corresponding non-convex
optimization problem. It is proved that a KKT optimal solution can be obtained;
2) For the binary offloading mode, the resultant highly-coupled mixed-integer
optimization problem is first transformed to an equivalent but more tractable
form. Then, the reformulated problem is solved by utilizing the alternating
direction method of multipliers approach to obtain a nearly optimal solution.
Finally, numerical results verify the effectiveness of the proposed algorithms
and the proposed NOMA-aided JCSMC framework
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:13:05 GMT""},{""version"":""v2"",""created"":""Tue, 27 Dec 2022 16:05:55 GMT""}]","2022-12-29"
"2205.08273","Sebastian Zuniga Alterman","Stanis{\l}aw Kasjan, Mariusz Lema\'nczyk, Sebastian Zuniga Alterman","Dynamics of $\mathscr{B}$-free systems generated by Behrend sets. I",,"Acta Arithmetica 2023",,,"math.DS math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the complexity of $\mathscr{B}$-free subshifts which are proximal
and of zero entropy. Such subshifts are generated by Behrend sets. The
complexity is shown to achieve any subexponential growth and is estimated for
some classical subshifts (prime and semiprime subshifts). We also show that
$\mathscr{B}$-admissible subshifts are transitive only for coprime sets
$\mathscr{B}$ which allows one to characterize dynamically the subshifts
generated by the Erd\""os sets.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:13:09 GMT""}]","2023-01-23"
"2205.08274","Ailisi Li","Ailisi Li, Xueyao Jiang, Bang Liu, Jiaqing Liang, Yanghua Xiao","Tackling Math Word Problems with Fine-to-Coarse Abstracting and
  Reasoning",,,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Math Word Problems (MWP) is an important task that requires the ability of
understanding and reasoning over mathematical text. Existing approaches mostly
formalize it as a generation task by adopting Seq2Seq or Seq2Tree models to
encode an input math problem in natural language as a global representation and
generate the output mathematical expression. Such approaches only learn shallow
heuristics and fail to capture fine-grained variations in inputs. In this
paper, we propose to model a math word problem in a fine-to-coarse manner to
capture both the local fine-grained information and the global logical
structure of it. Instead of generating a complete equation sequence or
expression tree from the global features, we iteratively combine low-level
operands to predict a higher-level operator, abstracting the problem and
reasoning about the solving operators from bottom to up. Our model is naturally
more sensitive to local variations and can better generalize to unseen problem
types. Extensive evaluations on Math23k and SVAMP datasets demonstrate the
accuracy and robustness of our method.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:14:44 GMT""}]","2022-05-18"
"2205.08275","Richard D. Gill","R.J.F. Ypma, P.A. Maaskant-van Wijk, R.D. Gill, M. Sjerps, M. van den
  Berge","Calculating LRs for presence of body fluids from mRNA assay data in
  mixtures","24 pages. This is a pre-publication version. Latest version: now in
  LaTeX after mainly automatic conversion from Word using ""pandoc""","Forensic Science International: Genetics, Volume 52, 2021, 102455.
  https://www.sciencedirect.com/science/article/pii/S1872497320302271","10.1016/j.fsigen.2020.102455",,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Messenger RNA (mRNA) profiling can identify body fluids present in a stain,
yielding information on what activities could have taken place at a crime
scene. To account for uncertainty in such identifications, recent work has
focused on devising statistical models to allow for probabilistic statements on
the presence of body fluids. A major hurdle for practical adoption is that
evidentiary stains are likely to contain more than one body fluid and current
models are ill-suited to analyse such mixtures. Here, we construct a likelihood
ratio (LR) system that can handle mixtures, considering the hypotheses H1: the
sample contains at least one of the body fluids of interest (and possibly other
body fluids); H2: the sample contains none of the body fluids of interest (but
possibly other body fluids). Thus, the LR-system outputs an LR-value for any
combination of mRNA profile and set of body fluids of interest that are given
as input. The calculation is based on an augmented dataset obtained by in
silico mixing of real single body fluid mRNA profiles. These digital mixtures
are used to construct a probabilistic classification method (a 'multi-label
classifier'). The probabilities produced are subsequently used to calculate an
LR, via calibration. We test a range of different classification methods from
the field of machine learning, ways to preprocess the data and multi-label
strategies for their performance on in silico mixed test data. Furthermore, we
study their robustness to different assumptions on background levels of the
body fluids. We find logistic regression works as well as more flexible
classifiers, but shows higher robustness and better explainability. We test the
system's performance on lab-generated mixture samples, and discuss practical
usage in case work.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:17:40 GMT""},{""version"":""v2"",""created"":""Fri, 20 May 2022 09:15:57 GMT""}]","2022-05-23"
"2205.08276","Aleksandr Konovalov","Aleksandr Yu. Konovalov","Generalized Realizability and Intuitionistic Logic","arXiv admin note: substantial text overlap with arXiv:2001.08989",,,,"math.LO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Let V be a set of number-theoretical functions. We define a notion of V
-realizability for predicate formulas in such a way that the indices of
functions in V are used for interpreting the implication and the universal
quantifier. In this paper we prove that Intuitionistic Predicate Calculus is
sound with respect to the semantics of V -realizability if and only if some
natural conditions for V hold.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:20:10 GMT""}]","2022-05-18"
"2205.08282","Stanislaw Mrowczynski","Sylwia Bazak and Stanislaw Mrowczynski","Stability of Classical Chromodynamic Fields -- Addendum","10 pages, no figures, Physical Review D in print",,,,"hep-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A system of chromodynamic fields, which can be treated as classical, is
generated at the earliest stage of relativistic heavy-ion collisions. Numerical
simulations show that the system is unstable but the nature of the instability
is not well understood. We study the problem systematically. In the first
paper, we have performed a linear stability analysis of space-time uniform
chromoelectric and chromomagnetic fields. There they have been considered the
Abelian configurations of single-color potentials linearly depending on
coordinates and nonAbelian ones where the fields are generated by the
multi-color non-commuting uniform potentials. Here we extend and supplement the
analysis. We discuss the parallel chromoelectric and chromomagnetic fields
which occur simultaneously. We also consider a general nonAbelian
configurations of the uniform fields. Finally, we discuss the gauge dependence
of our results.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:27:24 GMT""},{""version"":""v2"",""created"":""Thu, 18 Aug 2022 08:36:34 GMT""}]","2022-08-19"
"2205.08283","Jean Letang","Fran\c{c}ois Smekens, Nicolas Freud, Bruno Sixou, Guillaume Beslon and
  Jean M L\'etang","Towards the optimization of ballistics in proton therapy using genetic
  algorithms: implementation issues","18 pages, 4 figures",,,,"physics.med-ph cs.NE","http://creativecommons.org/licenses/by/4.0/","  The dose delivered to the planning target volume by proton beams is highly
conformal, sparing organs at risk and normal tissues. New treatment planning
systems adapted to spot scanning techniques have been recently proposed to
simultaneously optimize several fields and thus improve dose delivery. In this
paper, we investigate a new optimization framework based on a genetic algorithm
approach. This tool is intended to make it possible to explore new schemes of
treatment delivery, possibly with future enhanced technologies. The
optimization framework is designed to be versatile and to account for many
degrees of freedom, without any {\it a priori} technological constraint. To
test the behavior of our algorithm, we propose in this paper, as an example, to
optimize beam fluences, target points and irradiation directions at the same
time.
  The proposed optimization routine takes typically into account several
thousands of spots of fixed size. The evolution is carried out by the three
standard genetic operators: mutation, crossover and selection. The
figure-of-merit (or fitness) is based on an objective function relative to the
dose prescription to the tumor and to the limits set for organs at risk and
normal tissues. Fluence optimization is carried out via a specific scheme based
on a plain gradient with analytical solution. Several specific genetic
algorithm issues are addressed: (i) the mutation rate is tuned to balance the
search and selection forces, (ii) the initial population is selected using a
bootstrap technique and (iii) to scale down the computation time, dose
calculations are carried out with a fast analytical ray tracing method and are
multi-threaded.
  In this paper implementation issues of the optimization framework are
thoroughly described. The behavior of the proposed genetic algorithm is
illustrated in both elementary and clinically-realistic test cases.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:31:14 GMT""}]","2022-05-18"
"2205.08284","Alan Cornell","Alan S. Cornell, Anele Ncube and Gerhard Harmsen","Using physics-informed neural networks to compute quasinormal modes","43 pages, 12 figures",,"10.1103/PhysRevD.106.124047",,"physics.comp-ph gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years there has been an increased interest in neural networks,
particularly with regard to their ability to approximate partial differential
equations. In this regard, research has begun on so-called physics-informed
neural networks (PINNs) which incorporate into their loss function the boundary
conditions of the functions they are attempting to approximate. In this paper,
we investigate the viability of obtaining the quasi-normal modes (QNMs) of
non-rotating black holes in 4-dimensional space-time using PINNs, and we find
that it is achievable using a standard approach that is capable of solving
eigenvalue problems (dubbed the eigenvalue solver here). In comparison to the
QNMs obtained via more established methods (namely, the continued fraction
method and the 6th-order Wentzel, Kramer, Brillouin method) the PINN
computations share the same degree of accuracy as these counterparts. In other
words, our PINN approximations had percentage deviations as low as
$(\delta\omega_{_{Re}}, \delta\omega_{_{Im}}) = (<0.01\%, <0.01\%)$. In terms
of the time taken to compute QNMs to this accuracy, however, the PINN approach
falls short, leading to our conclusion that the method is currently not to be
recommended when considering overall performance.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:31:42 GMT""},{""version"":""v2"",""created"":""Mon, 24 Oct 2022 18:43:18 GMT""}]","2023-01-11"
"2205.08285","Binbin Hu","Binbin Hu, Zhiyang Hu, Zhiqiang Zhang, Jun Zhou, Chuan Shi","KGNN: Distributed Framework for Graph Neural Knowledge Representation",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Knowledge representation learning has been commonly adopted to incorporate
knowledge graph (KG) into various online services. Although existing knowledge
representation learning methods have achieved considerable performance
improvement, they ignore high-order structure and abundant attribute
information, resulting unsatisfactory performance on semantics-rich KGs.
Moreover, they fail to make prediction in an inductive manner and cannot scale
to large industrial graphs. To address these issues, we develop a novel
framework called KGNN to take full advantage of knowledge data for
representation learning in the distributed learning system. KGNN is equipped
with GNN based encoder and knowledge aware decoder, which aim to jointly
explore high-order structure and attribute information together in a
fine-grained fashion and preserve the relation patterns in KGs, respectively.
Extensive experiments on three datasets for link prediction and triplet
classification task demonstrate the effectiveness and scalability of KGNN
framework.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:32:02 GMT""}]","2022-05-18"
"2205.08286","Fabian Germ","Fabian Germ and Istv\'an Gy\""ongy","On partially observed jump diffusions I. The filtering equations","27 pages",,,,"math.PR math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is the first part of a series of papers on filtering for partially
observed jump diffusions satisfying a stochastic differential equation driven
by Wiener processes and Poisson martingale measures. The coefficients of the
equation only satisfy appropriate growth conditions. Some results in filtering
theory of diffusion processes are extended to jump diffusions and equations for
the time evolution of the conditional distribution and the unnormalised
conditional distribution of the unobserved process at time $t$, given the
observations until $t$, are presented.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:33:19 GMT""}]","2022-05-18"
"2205.08287","Maxwell Young","Trisha Chakraborty, Abir Islam, Valerie King, Daniel Rayborn, Jared
  Saia, Maxwell Young","Bankrupting DoS Attackers Despite Uncertainty",,,,,"cs.CR cs.DC cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  On-demand provisioning in the cloud allows for services to remain available
despite massive denial-of-service (DoS) attacks. Unfortunately, on-demand
provisioning is expensive and must be weighed against the costs incurred by an
adversary. This leads to a recent threat known as {\it economic
denial-of-sustainability (EDoS)}, where the cost for defending a service is
higher than that of attacking.
  A natural tool for combating EDoS is to impose costs via resource burning
(RB). Here, a client must verifiably consume resources -- for example, by
solving a computational challenge -- before service is rendered. However, prior
RB-based defenses with security guarantees do not account for the cost of
on-demand provisioning.
  Another common approach is the use of heuristics -- such as a client's
reputation score or the geographical location -- to identify and discard
spurious job requests. However, these heuristics may err and existing
approaches do not provide security guarantees when this occurs.
  Here, we propose an EDoS defense, LCharge, that uses resource burning while
accounting for on-demand provisioning. LCharge leverages an estimate of the
number of job requests from honest clients (i.e., good jobs) in any set $S$ of
requests to within an $O(\alpha)$-factor, for any unknown $\alpha>0$, but
retains a strong security guarantee despite the uncertainty of this estimate.
Specifically, against an adversary that expends $B$ resources to attack, the
total cost for defending is $O( \alpha^{5/2}\sqrt{B\,(g+1)} +
\alpha^3(g+\alpha))$ where $g$ is the number of good jobs. Notably, for large
$B$ relative to $g$ and $\alpha$, the adversary has higher cost, implying that
the algorithm has an economic advantage. Finally, we prove a lower bound for
our problem of $\Omega(\sqrt{\alpha B g})$, showing that the cost of LCharge is
asymptotically tight for $\alpha=\Theta(1)$.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:34:56 GMT""},{""version"":""v2"",""created"":""Sat, 10 Sep 2022 17:42:05 GMT""}]","2022-09-13"
"2205.08288","Davide Locatelli","Davide Locatelli and Ariadna Quattoni","Measuring Alignment Bias in Neural Seq2Seq Semantic Parsers","5 pages, 3 figures. In Proceedings of the 11th Joint Conference on
  Lexical and Computational Semantics. 2022",,"10.18653/v1/2022.starsem-1.17",,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  Prior to deep learning the semantic parsing community has been interested in
understanding and modeling the range of possible word alignments between
natural language sentences and their corresponding meaning representations.
Sequence-to-sequence models changed the research landscape suggesting that we
no longer need to worry about alignments since they can be learned
automatically by means of an attention mechanism. More recently, researchers
have started to question such premise. In this work we investigate whether
seq2seq models can handle both simple and complex alignments. To answer this
question we augment the popular Geo semantic parsing dataset with alignment
annotations and create Geo-Aligned. We then study the performance of standard
seq2seq models on the examples that can be aligned monotonically versus
examples that require more complex alignments. Our empirical study shows that
performance is significantly better over monotonic alignments.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:35:52 GMT""},{""version"":""v2"",""created"":""Fri, 11 Nov 2022 22:04:27 GMT""}]","2022-11-15"
"2205.08289","Hossein A. Rahmani","Hossein A. Rahmani, Mohammadmehdi Naghiaei, Mahdi Dehghan, Mohammad
  Aliannejadi","Experiments on Generalizability of User-Oriented Fairness in Recommender
  Systems","SIGIR 2022",,,,"cs.IR cs.AI","http://creativecommons.org/licenses/by/4.0/","  Recent work in recommender systems mainly focuses on fairness in
recommendations as an important aspect of measuring recommendations quality. A
fairness-aware recommender system aims to treat different user groups
similarly. Relevant work on user-oriented fairness highlights the
discriminative behavior of fairness-unaware recommendation algorithms towards a
certain user group, defined based on users' activity level. Typical solutions
include proposing a user-centered fairness re-ranking framework applied on top
of a base ranking model to mitigate its unfair behavior towards a certain user
group i.e., disadvantaged group. In this paper, we re-produce a user-oriented
fairness study and provide extensive experiments to analyze the dependency of
their proposed method on various fairness and recommendation aspects, including
the recommendation domain, nature of the base ranking model, and user grouping
method. Moreover, we evaluate the final recommendations provided by the
re-ranking framework from both user- (e.g., NDCG, user-fairness) and item-side
(e.g., novelty, item-fairness) metrics. We discover interesting trends and
trade-offs between the model's performance in terms of different evaluation
metrics. For instance, we see that the definition of the
advantaged/disadvantaged user groups plays a crucial role in the effectiveness
of the fairness algorithm and how it improves the performance of specific base
ranking models. Finally, we highlight some important open challenges and future
directions in this field. We release the data, evaluation pipeline, and the
trained models publicly on https://github.com/rahmanidashti/FairRecSys.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:36:30 GMT""}]","2022-05-18"
"2205.08290","Young-Min Baek","Young-Min Baek (1), Esther Cho (1), Donghwan Shin (2), Doo-Hwan Bae
  (1) ((1) Korea Advanced Institute of Science and Technology (KAIST), (2)
  University of Luxembourg)","Literature Review to Collect Conceptual Variables of Scenario Methods
  for Establishing a Conceptual Scenario Framework","22 pages, 7 figures",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Over recent decades, scenarios and scenario-based software/system engineering
have been actively employed as essential tools to handle intricate problems,
validate requirements, and support stakeholders' communication. However,
despite the widespread use of scenarios, there have been several challenges for
engineers to more willingly utilize scenario-based engineering approaches
(i.e., scenario methods) in their projects. First, the term scenario has
numerous published definitions, thus lacking in a well-established shared
understanding of scenarios and scenario methods. Second, the conceptual basis
for engineers developing or employing scenarios is missing. To establish shared
understanding and to find common denominators of scenario methods, this study
leverages well-defined metamodeling and conceptualization that systematically
investigate the concepts under analysis and define core entities and their
relations. By conducting a semi-systematic literature review, conceptual
variables are collected and conceptualized as a conceptual meta-model. As a
result, this study introduces scenario variables (SVs) that represent
constructs/semantics of scenario descriptions, according to 4 levels of
constructs of a scenario method. To evaluate the comprehensibility and
applicability of the defined variables, we analyze five existing scenario
methods and their instances in automated driving system (ADS) domains. The
results showed that our conceptual model and its constituent scenario variables
adequately support the understanding of a scenario method and provide a means
for comparative analysis between different scenario methods.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:44:12 GMT""}]","2022-05-18"
"2205.08291","Yian Xu Dr.","Wei Dong, Baogang Xu, Yian Xu","A tight linear bound to the chromatic number of $(P_5, K_1+(K_1\cup
  K_3))$-free graphs","arXiv admin note: text overlap with arXiv:2202.13177",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $F_1$ and $F_2$ be two disjoint graphs. The union $F_1\cup F_2$ is a
graph with vertex set $V(F_1)\cup V(F_2)$ and edge set $E(F_1)\cup E(F_2)$, and
the join $F_1+F_2$ is a graph with vertex set $V(F_1)\cup V(F_2)$ and edge set
$E(F_1)\cup E(F_2)\cup \{xy\;|\; x\in V(F_1)\mbox{ and } y\in V(F_2)\}$. In
this paper, we present a characterization to $(P_5, K_1\cup K_3)$-free graphs,
prove that $\chi(G)\le 2\omega(G)-1$ if $G$ is $(P_5, K_1\cup K_3)$-free. Based
on this result, we further prove that $\chi(G)\le $max$\{2\omega(G),15\}$ if
$G$ is a $(P_5,K_1+( K_1\cup K_3))$-free graph, and construct an infinite
family of $(P_5, K_1+( K_1\cup K_3))$-free graphs such that every graph $G$ in
the family satisfies $\chi(G)=2\omega(G)$.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:44:52 GMT""},{""version"":""v2"",""created"":""Fri, 29 Jul 2022 10:32:45 GMT""}]","2022-08-01"
"2205.08292","Cheng Xin","Xin Cheng, Tingting Liu, Feng Shu, Chuan Ma, Jun Li, and Jiangzhou
  Wang","Providing Location Information at Edge Networks: A Federated
  Learning-Based Approach",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, the development of mobile edge computing has enabled exhilarating
edge artificial intelligence (AI) with fast response and low communication
cost. The location information of edge devices is essential to support the edge
AI in many scenarios, like smart home, intelligent transportation systems and
integrated health care. Taking advantages of deep learning intelligence, the
centralized machine learning (ML)-based positioning technique has received
heated attention from both academia and industry. However, some potential
issues, such as location information leakage and huge data traffic, limit its
application. Fortunately, a newly emerging privacy-preserving distributed ML
mechanism, named federated learning (FL), is expected to alleviate these
concerns. In this article, we illustrate a framework of FL-based localization
system as well as the involved entities at edge networks. Moreover, the
advantages of such system are elaborated. On practical implementation of it, we
investigate the field-specific issues associated with system-level solutions,
which are further demonstrated over a real-word database. Moreover, future
challenging open problems in this field are outlined.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:44:54 GMT""},{""version"":""v2"",""created"":""Tue, 12 Jul 2022 03:09:15 GMT""},{""version"":""v3"",""created"":""Wed, 24 Aug 2022 08:47:00 GMT""}]","2022-08-25"
"2205.08293","Arnaud Marsiglietti","Arnaud Marsiglietti and James Melbourne","Moments, Concentration, and Entropy of Log-Concave Distributions","19 pages",,,,"math.PR cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We utilize and extend a simple and classical mechanism, combining
log-concavity and majorization in the convex order to derive moments,
concentration, and entropy inequalities for certain classes of log-concave
distributions.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:45:11 GMT""},{""version"":""v2"",""created"":""Thu, 1 Sep 2022 21:15:20 GMT""}]","2022-09-05"
"2205.08294","Risto Raitio Dr","Risto Raitio","A Stringy Model of Pointlike Particles","arXiv admin note: substantial text overlap with arXiv:1509.07153 by
  other authors","Nuclear Physics B980 (2022) 115826","10.1016/j.nuclphysb.2022.115826",,"hep-ph hep-th","http://creativecommons.org/licenses/by/4.0/","  A previous supersymmetric preon scenario for visible matter particles is
extended to the dark sector. In addition, the scenario is reformulated as a
Double Field Theory (DFT) with four extra dimensions, to avoid a singular Big
Bang in cosmology. T-duality and doubled local Lorentz symmetry of the model
are genuine stringy properties. It is proposed that DFT preons may be an
approximate pointlike projection of string theory.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:48:17 GMT""}]","2022-05-18"
"2205.08295","Young-Geun Choi","Young-Geun Choi, Gi-Soo Kim, Seunghoon Paik and Myunghee Cho Paik","Semi-Parametric Contextual Bandits with Graph-Laplacian Regularization",,,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Non-stationarity is ubiquitous in human behavior and addressing it in the
contextual bandits is challenging. Several works have addressed the problem by
investigating semi-parametric contextual bandits and warned that ignoring
non-stationarity could harm performances. Another prevalent human behavior is
social interaction which has become available in a form of a social network or
graph structure. As a result, graph-based contextual bandits have received much
attention. In this paper, we propose ""SemiGraphTS,"" a novel contextual
Thompson-sampling algorithm for a graph-based semi-parametric reward model. Our
algorithm is the first to be proposed in this setting. We derive an upper bound
of the cumulative regret that can be expressed as a multiple of a factor
depending on the graph structure and the order for the semi-parametric model
without a graph. We evaluate the proposed and existing algorithms via
simulation and real data example.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:51:54 GMT""}]","2022-05-18"
"2205.08296","Shiqi Zhou","S. Q. Zhou, E. G\""ugercino\u{g}lu, J. P. Yuan, M. Y. Ge, C. Yu, C. M.
  Zhang, J. Zhang, Z. W. Feng, C. Q. Ye","New pulse profile variability associated with a glitch of PSR J0738-4042","13 pages, 6 figures. Accepted for publication in MNRAS. Comments
  Welcome",,"10.1093/mnras/stac3355",,"astro-ph.HE astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  The close correlation observed between emission state and spin-down rate
change of pulsars has many implications both for the magnetospheric physics and
the neutron star interior. The middle-aged pulsar PSR J0738$-$4042, which had
been observed to display variations in the pulse profile associated with its
spin-down rate change due to external effects, is a remarkable example. In this
study, based on the 12.5-yr combined public timing data from UTMOST and Parkes,
we have detected a new emission-rotation correlation in PSR J0738$-$4042
concurrent with a glitch. A glitch that occurred at MJD 57359(5) (December 3,
2015) with $\Delta\nu/\nu \sim 0.36(4)\times 10^{-9}$ is the first glitch event
observed in this pulsar and is probably the underlying cause of the
emission-rotation correlation. Unlike the usual post-glitch behaviours, the
braking torque on the pulsar has continued to increase over 1380 d,
corresponding to a significant decrease in $\ddot{\nu}$. As for changes in the
pulse profile after the glitch, the relative amplitude of the leading component
weakens drastically, while the middle component becomes stronger. A combined
model of crustquake induced platelet movement and vortex creep response is
invoked to account for this rare correlation. In this scenario, magnetospheric
state-change is naturally linked to the pulsar-intrinsic processes that give
rise to a glitch.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:52:00 GMT""},{""version"":""v2"",""created"":""Tue, 22 Nov 2022 11:42:16 GMT""}]","2022-11-23"
"2205.08297","Christoph Weidenbach","Hendrik Leidinger and Christoph Weidenbach","SCL(EQ): SCL for First-Order Logic with Equality",,,,,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new calculus SCL(EQ) for first-order logic with equality that
only learns non-redundant clauses. Following the idea of CDCL (Conflict Driven
Clause Learning) and SCL (Clause Learning from Simple Models) a ground literal
model assumption is used to guide inferences that are then guaranteed to be
non-redundant. Redundancy is defined with respect to a dynamically changing
ordering derived from the ground literal model assumption. We prove SCL(EQ)
sound and complete and provide examples where our calculus improves on
superposition.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:52:26 GMT""}]","2022-05-18"
"2205.08298","Timo Kuschel","Maik Gaerner, Robin Silber, Tobias Peters, Jaroslav Hamrle, Timo
  Kuschel","Cubic magneto-optic Kerr effect in Ni(111) thin films with and without
  twinning","6 pages, 3 figures, supplemental pdf",,,,"physics.optics cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  In most studies utilizing the magneto-optic Kerr effect (MOKE), the detected
change of polarized light upon reflection from a magnetized sample is supposed
to be proportional to the magnetization $\boldsymbol{M}$. However, MOKE
signatures quadratic in $\boldsymbol{M}$ have also been identified and
utilized, e.g., to sense the structural order in Heusler compounds, to detect
spin-orbit torques or to image antiferromagnetic domains. In our study, we
observe a strong anisotropic MOKE contribution of third order in
$\boldsymbol{M}$ in Ni(111) thin films, attributed to a cubic magneto-optic
tensor $\propto $ $\boldsymbol{M}^3$. We further show that the angular
dependence of cubic MOKE (CMOKE) is affected by the amount of structural domain
twinning in the sample. Our detailed study on CMOKE for two selected photon
energies will open up new opportunities for CMOKE applications with sensitivity
to twinning properties of thin films, e.g. CMOKE spectroscopy and microscopy or
time-resolved CMOKE.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:54:42 GMT""}]","2022-05-18"
"2205.08299","Wang Gao","Xin Li, Wang Gao, and Qing Jiang","A Rule of Solute Segregation at Grain Boundaries",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The control of solute segregation at grain boundaries (GBs) is essential in
engineering alloy properties, however the structure-activity relationship of
the key parameter-the segregation energies-still remains elusive. Here we
propose the electronic and geometric descriptors of GB segregation based on the
valence, electronegativity and size of solutes and the non-local coordination
number of free surfaces, with which we build a predictive framework to
determine the segregation energies across different solutes, matrices, GB
structures and segregation sites. This framework uncovers not only the coupling
rule of solutes and matrices in GB segregation, but also the origin of
solute-segregation determinants. The contribution of solutes essentially stems
from their d- and s-state coupling in alloying, whereas that of matrix GB
interfaces is determined by matrix free surfaces. Our scheme builds a novel
picture for the solute segregation at GBs and provides a useful tool for the
design of advanced alloys.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:56:10 GMT""},{""version"":""v2"",""created"":""Wed, 19 Oct 2022 13:31:18 GMT""}]","2022-10-20"
"2205.08300","Thom Badings","Thom S. Badings, Nils Jansen, Sebastian Junges, Marielle Stoelinga,
  Matthias Volk","Sampling-Based Verification of CTMCs with Uncertain Rates",,"Computed Aided Verification (CAV) 2022","10.1007/978-3-031-13188-2_2",,"cs.LO math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We employ uncertain parametric CTMCs with parametric transition rates and a
prior on the parameter values. The prior encodes uncertainty about the actual
transition rates, while the parameters allow dependencies between transition
rates. Sampling the parameter values from the prior distribution then yields a
standard CTMC, for which we may compute relevant reachability probabilities. We
provide a principled solution, based on a technique called
scenario-optimization, to the following problem: From a finite set of parameter
samples and a user-specified confidence level, compute prediction regions on
the reachability probabilities. The prediction regions should (with high
probability) contain the reachability probabilities of a CTMC induced by any
additional sample. To boost the scalability of the approach, we employ standard
abstraction techniques and adapt our methodology to support approximate
reachability probabilities. Experiments with various well-known benchmarks show
the applicability of the approach.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:56:51 GMT""},{""version"":""v2"",""created"":""Fri, 20 May 2022 14:20:56 GMT""},{""version"":""v3"",""created"":""Tue, 21 Jun 2022 20:48:50 GMT""}]","2022-12-08"
"2205.08301","Antonello Paolino","Tong Hui (1 and 2), Antonello Paolino (1 and 4), Gabriele Nava (1),
  Giuseppe L'Erario (1 and 3), Fabio Di Natale (1), Fabio Bergonti (1 and 3),
  Francesco Braghin (2) and Daniele Pucci (1 and 3) ((1) Istituto Italiano di
  Tecnologia, (2) Politecnico di Milano, (3) University of Manchester, (4)
  Universit\`a degli Studi di Napoli Federico II)","Centroidal Aerodynamic Modeling and Control of Flying Multibody Robots","7 pages, 6 figures, to be published in IEEE ICRA 2022. Presentation
  video: https://youtu.be/WDb-OVlh5XA",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a modeling and control framework for multibody flying
robots subject to non-negligible aerodynamic forces acting on the centroidal
dynamics. First, aerodynamic forces are calculated during robot flight in
different operating conditions by means of Computational Fluid Dynamics (CFD)
analysis. Then, analytical models of the aerodynamics coefficients are
generated from the dataset collected with CFD analysis. The obtained simplified
aerodynamic model is also used to improve the flying robot control design. We
present two control strategies: compensating for the aerodynamic effects via
feedback linearization and enforcing the controller robustness with
gain-scheduling. Simulation results on the jet-powered humanoid robot iRonCub
validate the proposed approach.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:58:18 GMT""}]","2022-05-18"
"2205.08302","Felipe Espreafico Guelerman Ramos","Felipe Espreafico","Gauss-Manin connection in disguise: Open Gromov-Witten invariants","21 pages. No figures. Comments and corrections are welcome! In the
  new version I added a subsection reviewing GMCD for Elliptic Curves as
  motivation and made some other minor corrections",,,,"math.AG math-ph math.MP","http://creativecommons.org/licenses/by-sa/4.0/","  In mirror symmetry, after the work by J. Walcher, the number of holomorphic
disks with boundary on the real quintic lagrangian in a general quintic
threefold is related to the periods of the mirror quintic family with boundary
on two homologous rational curves. Following the ideias of H.Movasati, we
construct a quasi-affine space parametrizing such objects enhanced with a frame
for the relative de Rham cohomology with boundary at the curves compatible with
the mixed Hodge structure. We also compute a modular vector field attached to
such a parametrization.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 12:59:19 GMT""},{""version"":""v2"",""created"":""Sun, 19 Jun 2022 22:56:18 GMT""}]","2022-06-22"
"2205.08303","Deblina Bhattacharjee","Deblina Bhattacharjee, Tong Zhang, Sabine S\""usstrunk and Mathieu
  Salzmann","MulT: An End-to-End Multitask Learning Transformer","Accepted to CVPR 2022",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We propose an end-to-end Multitask Learning Transformer framework, named
MulT, to simultaneously learn multiple high-level vision tasks, including depth
estimation, semantic segmentation, reshading, surface normal estimation, 2D
keypoint detection, and edge detection. Based on the Swin transformer model,
our framework encodes the input image into a shared representation and makes
predictions for each vision task using task-specific transformer-based decoder
heads. At the heart of our approach is a shared attention mechanism modeling
the dependencies across the tasks. We evaluate our model on several multitask
benchmarks, showing that our MulT framework outperforms both the state-of-the
art multitask convolutional neural network models and all the respective single
task transformer models. Our experiments further highlight the benefits of
sharing attention across all the tasks, and demonstrate that our MulT model is
robust and generalizes well to new domains. Our project website is at
https://ivrl.github.io/MulT/.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:03:18 GMT""}]","2022-05-18"
"2205.08306","Oliver T. Unke","Oliver T. Unke, Martin St\""ohr, Stefan Ganscha, Thomas Unterthiner,
  Hartmut Maennel, Sergii Kashubin, Daniel Ahlin, Michael Gastegger, Leonardo
  Medrano Sandonas, Alexandre Tkatchenko, Klaus-Robert M\""uller","Accurate Machine Learned Quantum-Mechanical Force Fields for
  Biomolecular Simulations",,,,,"physics.chem-ph cs.LG q-bio.BM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Molecular dynamics (MD) simulations allow atomistic insights into chemical
and biological processes. Accurate MD simulations require computationally
demanding quantum-mechanical calculations, being practically limited to short
timescales and few atoms. For larger systems, efficient, but much less reliable
empirical force fields are used. Recently, machine learned force fields (MLFFs)
emerged as an alternative means to execute MD simulations, offering similar
accuracy as ab initio methods at orders-of-magnitude speedup. Until now, MLFFs
mainly capture short-range interactions in small molecules or periodic
materials, due to the increased complexity of constructing models and obtaining
reliable reference data for large molecules, where long-ranged many-body
effects become important. This work proposes a general approach to constructing
accurate MLFFs for large-scale molecular simulations (GEMS) by training on
""bottom-up"" and ""top-down"" molecular fragments of varying size, from which the
relevant physicochemical interactions can be learned. GEMS is applied to study
the dynamics of alanine-based peptides and the 46-residue protein crambin in
aqueous solution, allowing nanosecond-scale MD simulations of >25k atoms at
essentially ab initio quality. Our findings suggest that structural motifs in
peptides and proteins are more flexible than previously thought, indicating
that simulations at ab initio accuracy might be necessary to understand dynamic
biomolecular processes such as protein (mis)folding, drug-protein binding, or
allosteric regulation.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:08:28 GMT""}]","2022-05-18"
"2205.08307","Muhammad Farooq","Muhammad Farooq, Tung T. Vu, Hien Quoc Ngo, Le-Nam Tran","Serving Federated Learning and Non-Federated Learning Users: A Massive
  MIMO Approach","IEEE SPAWC 2022",,"10.1109/SPAWC51304.2022.9833955",,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Federated learning (FL) with its data privacy protection and communication
efficiency has been considered as a promising learning framework for
beyond-5G/6G systems. We consider a scenario where a group of downlink non-FL
users are jointly served with a group of FL users using massive multiple-input
multiple-output technology. The main challenge is how to utilise the resource
to optimally serve both FL and non-FL users. We propose a communication scheme
that serves the downlink of the non-FL users (UEs) and the uplink of FL UEs in
each half of the frequency band. We formulate an optimization problem for
optimizing transmit power to maximize the minimum effective data rates for
non-FL users, while guaranteeing a quality-of-service time of each FL
communication round for FL users. Then, a successive convex approximation-based
algorithm is proposed to solve the formulated problem. Numerical results
confirm that our proposed scheme significantly outperforms the baseline scheme.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:09:25 GMT""},{""version"":""v2"",""created"":""Sat, 21 May 2022 19:45:46 GMT""}]","2023-01-11"
"2205.08310","Rubens Augusto Amaro Junior","Cezar Augusto Bellezi, Liang-Yee Cheng, Rubens Augusto Amaro Junior,
  Marcio Michiharu Tsukamoto","Border mapping multi-resolution (BMMR) technique for incompressible
  projection-based particle methods","58 pages, 21 figures","Computer Methods in Applied Mechanics and Engineering 396 (2022)","10.1016/j.cma.2022.115013",,"physics.flu-dyn","http://creativecommons.org/licenses/by-nc-nd/4.0/","  A novel multi-resolution technique called border mapping multi-resolution
(BMMR) is proposed for projection-based particle methods. The BMMR aims to
obtain background equivalent particle distributions in the two sides of a
border between sub-domains with a 2:1 resolution ratio so that a single
resolution framework is adopted to near-border particles calculations. The
novelty of the BMMR is that it obtains the background grid from the mapping of
the actual particle distribution in the border and, as a result, the location
of the particles in the background grid exactly matches the location of the
actual particles. In this way, such technique aims to reduce the error from the
interpolation of the physical quantities in the background grid and to avoid
sudden changes in the particle distribution that may lead to unstable local
pressure calculation. In the coarse side of the border, the refinement is made
by a triangulation and by placing fictitious particles in the midpoints of the
triangles. In the fine side of the border, the derefinement is made by defining
a set of fine particles that result in a particle distribution that best
resembles a coarse one. The accuracy and computational performance of the BMMR
implemented in a moving particle semi-implicit (MPS) simulation system are
verified by using benchmark test cases of 2D free surface flows.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:11:00 GMT""},{""version"":""v2"",""created"":""Mon, 3 Apr 2023 19:42:05 GMT""}]","2023-04-05"
"2205.08312","Taro Kimura","Taro Kimura","Higgsing $qq$-character and irreducibility","27 pages",,,,"math.QA hep-th math.RT","http://creativecommons.org/licenses/by/4.0/","  We show that the $qq$-character of the irreducible highest weight module for
finite-type and affine quivers is obtained by Higgsing, specialization of the
equivariant parameters of the associated framing space in the quiver variety.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:11:50 GMT""}]","2022-05-18"
"2205.08313","Sergio Giardino","Sergio Giardino","Quaternionic scalar field in the real Hilbert space","accept by Int. J. Mod. Phys. A",,"10.1142/S0217751X22501019",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using the complex Klein-Gordon field as a model, we quantize the quaternionic
scalar field in the real Hilbert space. The lagrangian formulation has
accordingly been obtained, as well as the hamiltonian formulation, and the
energy and charge operators. Conversely to the complex case, the quaternionic
quantization admits two quantization schemes, concerning either two or four
components. Therefore, the quaternionic field permits a richer structure of
states, if compared to the complex scalar field case. Moreover, the
quaternionic theory admits as a further novel feature a non-associative
algebraic structure in their complex components, something not observed in the
complex case.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:12:04 GMT""}]","2022-07-13"
"2205.08314","Yepeng Ding","Yepeng Ding and Hiroyuki Sato","Self-Sovereign Identity as a Service: Architecture in Practice",,,"10.1109/COMPSAC54236.2022.00244",,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Self-sovereign identity (SSI) has gained a large amount of interest. It
enables physical entities to retain ownership and control of their digital
identities, which naturally forms a conceptual decentralized architecture. With
the support of the distributed ledger technology (DLT), it is possible to
implement this conceptual decentralized architecture in practice and further
bring technical advantages such as privacy protection, security enhancement,
high availability. However, developing such a relatively new identity model has
high costs and risks with uncertainty. To facilitate the use of the DLT-based
SSI in practice, we formulate Self-Sovereign Identity as a Service (SSIaaS), a
concept that enables a system, especially a system cluster, to readily adopt
SSI as its identity model for identification, authentication, and
authorization. We propose a practical architecture by elaborating the service
concept, SSI, and DLT to implement SSIaaS platforms and SSI services. Besides,
we present an architecture for constructing and customizing SSI services with a
set of architectural patterns and provide corresponding evaluations.
Furthermore, we demonstrate the feasibility of our proposed architecture in
practice with Selfid, an SSIaaS platform based on our proposed architecture.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:13:06 GMT""},{""version"":""v2"",""created"":""Thu, 2 Jun 2022 08:37:33 GMT""}]","2023-01-10"
"2205.08315","Kowsar Al MousaviTaha","Kowsar. Al Mousavitaha, \""Ozg\""ur E. M\""ustecapl{\i}oglu, and
  Esfandyar Faizi","Quantum Coherent Route to Bath Induced Entanglement","6 pages, to appear in Physical Review A",,,,"quant-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The micromaser is an archetype experimental setting where a beam of excited
two-level atoms is injected into a high-finesse cavity. It has played a pivotal
role as a testbed for predictions of quantum optics. We consider a generalized
micromaser setting consisting of high-quality cavity pumped by a beam of
three-level atoms. The atoms are assumed to be prepared to carry quantum
coherence between their excited state doublet. Our objective is to produce
quantum entanglement between the right-handed circular (RHC) and left-handed
circular (LHC) polarized photons in the cavity, exploiting the quantum
coherence in the pump atoms. For that aim, we derive the generalized micromaser
master equation for our system. We find that the dynamics of the micromaser
field driven by the pump beam is equivalent to two non-interacting RHC and LHC
photonis systems sharing a common non-equilibrium environment. The effect of
the shared bath is to mediate an incoherent interaction between the otherwise
non-interacting cavity photons, which emerges only if the atoms carry quantum
coherence. We take into account cavity losses as a source of quantum
decoherence and characterize the quantum entanglement between the LHC and RHC
polarized photons in terms of logarithmic negativity, calculated using the
dynamical solution of the master equation. Our reseults reveal that while there
is no steady-state entanglement, LHC and RHC polarzied photons can be entangled
in the transient regime.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:14:56 GMT""},{""version"":""v2"",""created"":""Sun, 19 Jun 2022 12:08:16 GMT""}]","2022-06-22"
"2205.08316","Jan Ole von Hartz","Jan Ole von Hartz, Eugenio Chisari, Tim Welschehold and Abhinav Valada","Self-Supervised Learning of Multi-Object Keypoints for Robotic
  Manipulation","Presented at IEEE ICRA 2022 Workshop 'Reinforcement Learning for
  Contact-Rich Manipulation'",,,,"cs.RO cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, policy learning methods using either reinforcement or
imitation have made significant progress. However, both techniques still suffer
from being computationally expensive and requiring large amounts of training
data. This problem is especially prevalent in real-world robotic manipulation
tasks, where access to ground truth scene features is not available and
policies are instead learned from raw camera observations. In this paper, we
demonstrate the efficacy of learning image keypoints via the Dense
Correspondence pretext task for downstream policy learning. Extending prior
work to challenging multi-object scenes, we show that our model can be trained
to deal with important problems in representation learning, primarily
scale-invariance and occlusion. We evaluate our approach on diverse robot
manipulation tasks, compare it to other visual representation learning
approaches, and demonstrate its flexibility and effectiveness for
sample-efficient policy learning.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:15:07 GMT""},{""version"":""v2"",""created"":""Tue, 11 Oct 2022 09:06:57 GMT""}]","2022-10-12"
"2205.08320","Pisin Chen","Pisin Chen, Misao Sasaki, Dong-han Yeom, Junggi Yoon","Resolving information loss paradox with Euclidean path integral","12 pages, 3 figures",,"10.1142/S0218271822420019",,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  The information loss paradox remains unresolved ever since Hawking's seminal
discovery of black hole evaporation. In this essay, we revisit the entanglement
entropy via Euclidean path integral (EPI) and allow for the branching of
semi-classical histories during the Lorentzian evolution. We posit that there
exist two histories that contribute to EPI, where one is information-losing
that dominates at early times, while the other is information-preserving that
dominates at late times. By so doing we recover the Page curve and preserve the
unitarity, albeit with the Page time shifted significantly towards the late
time. One implication is that the entropy bound may thus be violated. We
compare our approach with string-based islands and replica wormholes concepts.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:15:37 GMT""}]","2022-09-16"
"2205.08321","Rishith Ellath Meethal","Rishith Ellath Meethal, Birgit Obst, Mohamed Khalil, Aditya
  Ghantasala, Anoop Kodakkal, Kai-Uwe Bletzinger, Roland W\""uchner","Finite Element Method-enhanced Neural Network for Forward and Inverse
  Problems",,,,,"cs.CE cs.LG cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a novel hybrid methodology combining classical finite element
methods (FEM) with neural networks to create a well-performing and
generalizable surrogate model for forward and inverse problems. The residual
from finite element methods and custom loss functions from neural networks are
merged to form the algorithm. The Finite Element Method-enhanced Neural Network
hybrid model (FEM-NN hybrid) is data-efficient and physics conforming. The
proposed methodology can be used for surrogate models in real-time simulation,
uncertainty quantification, and optimization in the case of forward problems.
It can be used for updating the models in the case of inverse problems. The
method is demonstrated with examples, and the accuracy of the results and
performance is compared against the conventional way of network training and
the classical finite element method. An application of the forward-solving
algorithm is demonstrated for the uncertainty quantification of wind effects on
a high-rise buildings. The inverse algorithm is demonstrated in the
speed-dependent bearing coefficient identification of fluid bearings. The
hybrid methodology of this kind will serve as a paradigm shift in the
simulation methods currently used.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:18:14 GMT""}]","2022-05-18"
"2205.08322","Ralph Bohlin","Ralph C. Bohlin, Jessica E. Krick, Karl D. Gordon, Ivan Hubeny","How do Spitzer IRAC Fluxes Compare to HST CALSPEC","7 Figures, AJ in press",,"10.3847/1538-3881/ac6fe1",,"astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  An accurate tabulation of stellar brightness in physical units is essential
for a multitude of scientific endeavors. The HST/CALSPEC database of flux
standards contains many stars with spectral coverage in the 0.115--1 \micron\
range with some extensions to longer wavelengths of 1.7 or 2.5 \micron. Modeled
flux distributions to 32 \micron\ for calibration of JWST complement the
shorter wavelength HST measurements. Understanding the differences between IRAC
observations and CALSPEC models is important for science that uses IR fluxes
from multiple instruments, including JWST. The absolute flux of Spitzer IRAC
photometry at 3.6--8 \micron\ agrees with CALSPEC synthetic photometry to 1\%
for the three prime HST standards G191B2B, GD153, and GD71. For a set of 17--22
A-star standards, the average IRAC difference rises from agreement at 3.6
\micron\ to 3.4 $\pm$0.1\% brighter than CALSPEC at 8 \micron. For a smaller
set of G-stars, the average of the IRAC photometry falls below CALSPEC by as
much as 3.7 $\pm$0.3\% for IRAC1, while one G-star, P330E, is consistent with
the A-star ensemble of IRAC/CALSPEC ratios.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:18:56 GMT""}]","2022-06-22"
"2205.08323","Jan Gregorovi\v{c}","Jan Gregorovi\v{c} and Lenka Zalabov\'a","First BGG operators on homogeneous conformal geometries","40 pages, comments welcomed, several typos corrected",,"10.1088/1361-6382/acbc05",,"math.DG gr-qc math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study first BGG operators and their solutions on homogeneous conformal
geometries. We focus on conformal Killing tensors, conformal Killing--Yano
forms and twistor spinors in particular. We develop an invariant calculus that
allows us to find solutions explicitly using only algebraic computations. We
also discuss applications to holonomy reductions and conserved quantities of
conformal circles. We demonstrate our result on examples of homogeneous
conformal geometries coming mostly from general relativity.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:19:29 GMT""},{""version"":""v2"",""created"":""Mon, 8 Aug 2022 08:52:57 GMT""}]","2023-03-08"
"2205.08324","Stephen D.H. Yang","Stephen D.H. Yang, Bin Wang, Weijia Li, YiQi Lin, Conghui He","Unified Interactive Image Matting",,,,,"cs.CV cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent image matting studies are developing towards proposing trimap-free or
interactive methods for complete complex image matting tasks. Although avoiding
the extensive labors of trimap annotation, existing methods still suffer from
two limitations: (1) For the single image with multiple objects, it is
essential to provide extra interaction information to help determining the
matting target; (2) For transparent objects, the accurate regression of alpha
matte from RGB image is much more difficult compared with the opaque ones. In
this work, we propose a Unified Interactive image Matting method, named UIM,
which solves the limitations and achieves satisfying matting results for any
scenario. Specifically, UIM leverages multiple types of user interaction to
avoid the ambiguity of multiple matting targets, and we compare the pros and
cons of different annotation types in detail. To unify the matting performance
for transparent and opaque objects, we decouple image matting into two stages,
i.e., foreground segmentation and transparency prediction. Moreover, we design
a multi-scale attentive fusion module to alleviate the vagueness in the
boundary region. Experimental results demonstrate that UIM achieves
state-of-the-art performance on the Composition-1K test set and a synthetic
unified dataset. Our code and models will be released soon.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:20:30 GMT""},{""version"":""v2"",""created"":""Mon, 23 May 2022 02:20:05 GMT""}]","2022-05-24"
"2205.08325","Niluthpol Chowdhury Mithun","Zachary Seymour, Niluthpol Chowdhury Mithun, Han-Pang Chiu, Supun
  Samarasekera, Rakesh Kumar","GraphMapper: Efficient Visual Navigation by Scene Graph Generation","ICPR 2022",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Understanding the geometric relationships between objects in a scene is a
core capability in enabling both humans and autonomous agents to navigate in
new environments. A sparse, unified representation of the scene topology will
allow agents to act efficiently to move through their environment, communicate
the environment state with others, and utilize the representation for diverse
downstream tasks. To this end, we propose a method to train an autonomous agent
to learn to accumulate a 3D scene graph representation of its environment by
simultaneously learning to navigate through said environment. We demonstrate
that our approach, GraphMapper, enables the learning of effective navigation
policies through fewer interactions with the environment than vision-based
systems alone. Further, we show that GraphMapper can act as a modular scene
encoder to operate alongside existing Learning-based solutions to not only
increase navigational efficiency but also generate intermediate scene
representations that are useful for other future tasks.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:21:20 GMT""}]","2022-05-18"
"2205.08327","Saroj Dash Prof. Dr.","Anamul Md. Hoque, Bing Zhao, Dmitrii Khokhriakov, Prasanta Muduli,
  Saroj P. Dash1","Charge to Spin Conversion in van der Waals Metal NbSe2",,,"10.1063/5.0121577",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Quantum materials with a large charge current-induced spin polarization are
promising for next-generation all-electrical spintronic science and technology.
Van der Waals metals with high spin-orbit coupling and novel spin textures have
attracted significant attention for an efficient charge to spin conversion
process. Here, we demonstrate the electrical generation of spin polarization in
NbSe2 up to room temperature. To probe the current-induced spin polarization in
NbSe2, we used a graphene-based non-local spin-valve device, where the
spin-polarization in NbSe2 is efficiently injected and detected using non-local
spin-switch and Hanle spin precession measurements. A significantly higher
charge-spin conversion in NbSe2 is observed at a lower temperature, below the
superconducting transition temperature Tc ~ 7 K of NbSe2. However, the
charge-spin conversion signal could only be observed with a higher bias current
above the superconducting critical current, limiting the observation of the
signal only to the non-superconducting state of NbSe2. Systematic measurements
provide the possible origins of the spin polarization to be predominantly due
to the spin Hall effect or Rashba-Edelstein effect in NbSe2, considering
different symmetry allowed charge-spin conversion processes.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:21:55 GMT""}]","2022-12-28"
"2205.08328","Muhammad Farooq","Muhammad Farooq, Tung Thanh Vu, Hien Quoc Ngo, and Le-Nam Tran","Massive MIMO for Serving Federated Learning and Non-Federated Learning
  Users",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With its privacy preservation and communication efficiency, federated
learning (FL) has emerged as a promising learning framework for beyond 5G
wireless networks. It is anticipated that future wireless networks will jointly
serve both FL and downlink non-FL user groups in the same time-frequency
resource. While in the downlink of each FL iteration, both groups jointly
receive data from the base station in the same time-frequency resource, the
uplink of each FL iteration requires bidirectional communication to support
uplink transmission for FL users and downlink transmission for non-FL users. To
overcome this challenge, we present half-duplex (HD) and full-duplex (FD)
communication schemes to serve both groups. More specifically, we adopt the
massive multiple-input multiple-output technology and aim to maximize the
minimum effective rate of non-FL users under a quality of service (QoS) latency
constraint for FL users. Since the formulated problem is highly nonconvex, we
propose a power control algorithm based on successive convex approximation to
find a stationary solution. Numerical results show that the proposed solutions
perform significantly better than the considered baselines schemes. Moreover,
the FD-based scheme outperforms the HD-based scheme in scenarios where the
self-interference is small or moderate and/or the size of FL model updates is
large.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:22:28 GMT""},{""version"":""v2"",""created"":""Sat, 21 May 2022 19:49:05 GMT""}]","2022-05-24"
"2205.08329","Sandra Lagen","Sandra Lag\'en, Xavier Gelabert, Andreas Hansson, Manuel Requena,
  Lorenza Giupponi","Fronthaul Compression Control for shared Fronthaul Access Networks","paper to appear in IEEE Communications Magazine",,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There is a widely held belief that future Radio Access Network (RAN)
architectures will be characterized by increased levels of virtualization,
whereby base station functionalities, traditionally residing at a single
location, will be scattered across different logical entities while being
interfaced via high-speed fronthaul (FH) links. For the deployment of such FH
links, operators are faced with the challenge of maintaining acceptable radio
access performance while at the same time keeping deployment costs low. A
common practice is to exploit statistical multiplexing by allowing several
cells to utilize the same FH link. As a result, in order to cope with the
resulting aggregated traffic, different techniques can be used to reduce the
required FH data rates. Herein, we focus on FH compression control strategies
for multiple-cell/multiple-user scenarios sharing a common FH link. We propose
various methods for sounding reference signal (SRS) handling and analyze
different FH-aware modulation data compression and scheduling strategies.
Considering a full system setup, including the radio and FH access networks,
numerical evaluation is conducted using a 5G NR system-level simulator
implemented in ns-3. Simulation results show that, under stringent FH capacity
constraints, optimized modulation compression strategies provide significant
user-perceived throughput gains over baseline strategies (between 5.2x and
6.9x). On top of them, SRS handling methods achieve additional 2% to 41% gains.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:23:21 GMT""}]","2022-05-18"
"2205.08330","Affaf Junaid Ahamad Momin","Affaf Junaid Ahamad Momin, Gabriele Nava, Giuseppe LErario, Hosameldin
  Awadalla Omer Mohamed, Fabio Bergonti, Punith Reddy Vanteddu, Francesco
  Braghin, and Daniele Pucci","Nonlinear Model Identification and Observer Design for Thrust Estimation
  of Small-scale Turbojet Engines","6+1 pages",,,,"cs.RO cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Jet-powered vertical takeoff and landing (VTOL) drones require precise thrust
estimation to ensure adequate stability margins and robust maneuvering.
Small-scale turbojets have become good candidates for powering heavy aerial
drones. However, due to limited instrumentation available in these turbojets,
estimating the precise thrust using classical techniques is not
straightforward. In this paper, we present a methodology to accurately estimate
the online thrust for the small-scale turbojets used on the iRonCub - an aerial
humanoid robot. We use a grey-box method to capture the turbojet system
dynamics with a nonlinear state-space model based on the data acquired from a
custom engine test bench. This model is then used to design an extended Kalman
filter that estimates the turbojet thrust only from the angular speed
measurements. We exploited the parameter estimation algorithm to ensure that
the EKF gives smooth and accurate estimates even at engine failures. The
designed EKF was validated on the test bench where the mean absolute error in
estimated thrust was found to be within 2% of rated peak thrust.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:23:33 GMT""}]","2022-05-18"
"2205.08331","Xinkai Chen","Xinkai Chen, Jing Wang, Xu Kong","The Role of Inner HI Mass in Regulating the Scatter of the
  Mass-Metallicity Relation","14 pages, 8 figures; accepted for publication in ApJ",,"10.3847/1538-4357/ac70d0",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use 789 disk-like, star-forming galaxies (with 596 HI detections) from HI
follow-up observations for the SDSS-IV MaNGA survey to study the possible role
of inner HI gas in causing secondary dependences in the mass-gas-phase
metallicity relation. We use the gas-phase metallicity derived at the effective
radii of the galaxies. We derive the inner HI mass witHIn the optical radius,
but also use the total HI mass and star formation rate (SFR) for a comparison.
We confirm the anticorrelation between the total HI mass and gas-phase
metallicity at fixed stellar mass, but the anticorrelation is significantly
strengthened when the total HI mass is replaced by the inner HI mass.
Introducing a secondary relation with the inner HI mass can produce a small but
noticeable decrease (16%) in the scatter of the mass-gas-phase metallicity
relation, in contrast to the negligible effect with the SFR. The correlation
with the inner HI mass is robust when using different diagnostics of
metallicity, but the correlation with SFR is not. The correlation with the
inner HI mass becomes much weaker when the gas-phase metallicity is derived in
the central region instead of at the effective radius. These results support
the idea that the scatter in the mass-metallicity relation is regulated by gas
accretion, and not directly by the SFR, and stress the importance of deriving
the gas mass and the metallicity from roughly the same region. The new relation
between inner HI mass and gas-phase metallicity will provide new constraints
for chemical and galaxy evolution models.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:27:26 GMT""},{""version"":""v2"",""created"":""Wed, 8 Jun 2022 08:19:38 GMT""}]","2022-07-04"
"2205.08333","Ettore Vicari","Francesco Tarantelli and Ettore Vicari","Out-of-equilibrium dynamics arising from slow round-trip variations of
  Hamiltonian parameters across quantum and classical critical points","24 pages, Phys. Rev. B in press",,"10.1103/PhysRevB.105.235124",,"cond-mat.stat-mech quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address the out-of-equilibrium dynamics of many-body systems subject to
slow time-dependent round-trip protocols across quantum and classical (thermal)
phase transitions. We consider protocols where one relevant parameter w is
slowly changed across its critical point wc = 0, linearly in time with a large
time scale ts, from wi < 0 to wf > 0 and then back to wi < 0, thus entailing
multiple passages through the critical point. Analogously to the one-way
Kibble-Zurek protocols across a critical point, round-trip protocols develop
dynamic scaling behaviors at both classical and quantum transitions, put
forward within renormalization-group frameworks. The scaling scenario is
analyzed within some paradigmatic models undergoing quantum and classical
transitions belonging to the two-dimensional Ising universality class, such as
one-dimensional quantum Ising models and fermionic wires, and two-dimensional
classical Ising models (supplemented with a purely relaxational dynamics).
While the dynamic scaling frameworks are similar for classical and quantum
systems, substantial differences emerge due to the different nature of their
dynamics, which is purely relaxational for classical systems (implying
thermalization in the large-time limit at fixed model parameters), and unitary
in the case of quantum systems. In particular, when the critical point
separates two gapped (short-ranged) phases and the extreme value wf > 0 is kept
fixed in the large-ts limit of the round-trip protocol, we observe
hysteresis-like scenarios in classical systems, while quantum systems do not
apparently develop a sufficiently robust scaling limit along the return way,
due to the presence of rapidly oscillating relative phases among the relevant
quantum states.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:27:32 GMT""},{""version"":""v2"",""created"":""Sun, 12 Jun 2022 21:10:52 GMT""}]","2022-06-29"
"2205.08334","Songqi Li","Songqi Li and Wenpeng Li and Bernd R. Noack","Machine-learned control-oriented flow estimation for multiactuator
  multi-sensor systems exemplified for the fluidic pinball","34 pages, 27 figures, 4 tables",,"10.1017/jfm.2022.908",,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  We propose the first machine-learned control-oriented flow estimation for
multiple-input multiple-output plants. Starting point is constant actuation
with open-loop actuation commands leading to a database with simultaneously
recorded actuation commands, sensor signals and flow fields. A key enabler is
an estimator input vector comprising sensor signals and actuation commands. The
mapping from the sensor signals and actuation commands to the flow fields is
realized in an analytically simple, data-centric and general nonlinear
approach. The analytically simple estimator generalizes Linear Stochastic
Estimation (LSE) for actuation commands. The data-centric approach yields flow
fields from estimator inputs by interpolating from the database -- similar to
Loiseau et al. (2018) for unforced flow. The interpolation is performed with k
Nearest Neighbors (kNN). The general global nonlinear mapping from inputs to
flow fields is obtained from a Deep Neural Network (DNN) via an iterative
training approach. The estimator comparison is performed for the fluidic
pinball plant, which is a multiple-input, multiple-output wake control
benchmark (Deng et al. 2020) featuring rich dynamics under steady controls. We
conclude that the machine learning methods clearly outperform the linear model.
The performance of kNN and DNN estimators are comparable for periodic dynamics.
Yet, DNN performs consistently better when the flow is chaotic. Moreover, a
thorough comparison regarding to the complexity, computational cost, and
prediction accuracy is presented to demonstrate the relative merits of each
estimator. The proposed method can be generalized for closed-loop flow control
plants.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:27:53 GMT""},{""version"":""v2"",""created"":""Fri, 26 Aug 2022 06:49:06 GMT""},{""version"":""v3"",""created"":""Sat, 1 Oct 2022 14:06:46 GMT""}]","2022-12-14"
"2205.08336","Lirong Cui","Lirong Cui, Xiangchen Li, Narayanaswamy Balakrishnan","On Uncertainty of Dynamic Systems via State Aggregation Coarse-Graining
  and State Decomposition Fine-Graining Ways","13 pages are for the paper, 16 pages for supplemental material",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  Uncertainty is an important feature of dynamic systems, and entropy has been
widely used to measure this attribute. In this Letter, we prove that state
aggregation and decomposition can decrease and increase the entropy,
respectively, of dynamic systems. More than 20 popular entropies in the
literature are summarized and analyzed, and it is noted that none of them
breaks this property. Finally, pertinent proofs are given for four cases.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:30:02 GMT""}]","2022-05-18"
"2205.08337","Deyou Chen","Deyou Chen, Chuanhong Gao","Angular momentum and chaos bound of charged particles around
  Einstein-Euler-Heisenberg AdS black holes","22 pages","New J. Phys. 24 (2022) 123014","10.1088/1367-2630/aca820",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  In this paper, we investigate influences of the charge and angular momentum
of a particle around a charged Einstein-Euler-Heisenberg AdS black hole on a
Lyapunov exponent, and find spatial regions where the chaos bound is violated.
Positions of circular orbits are gotten by fixing the charge and angular
momentum of the particle, respectively. The positions gradually move away from
the event horizon with the increase of the angular momentum when the charge is
fixed and with the decrease of the charge when the angular momentum is fixed.
For certain values of the charge, angular momentum and Euler-Heisenberg
parameter, the spatial regions where the bound is violated are found. When the
charge is fixed and the Euler-Heisenberg parameter is large, a small angular
momentum causes the violation. Although the angular momentum is small, the
corresponding spatial region is not small. An interesting discovery is that the
bound is violated by the black hole when the particle's charge is less than 1
and $\Lambda =0$, but this requires the black hole's charge to be large enough.
This violation may be related to the dynamical stability of the black hole. The
backreaction of the particle on the background spacetime isn't considered in
the investigation.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:30:22 GMT""},{""version"":""v2"",""created"":""Wed, 29 Jun 2022 03:25:15 GMT""},{""version"":""v3"",""created"":""Mon, 8 Aug 2022 13:00:34 GMT""},{""version"":""v4"",""created"":""Thu, 15 Dec 2022 15:07:54 GMT""}]","2022-12-16"
"2205.08338","Xiangdong Zhang","Ling-Jun Kong, Weixuan Zhang, Peng, Li, Xuyue Guo, Jingfeng Zhang,
  Furong Zhang, Jianlin Zhao and Xiangdong Zhang","High capacity topological coding based on nested vortex knots and links","18 pages 4 figures","Nature Communications 13, 2705 (2022)","10.1038/s41467-022-30381-w",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Optical knots and links have attracted great attention because of their
exotic topological characteristics. Recent investigations have shown that the
information encoding based on optical knots could possess robust features
against external perturbations. However, as a superior coding scheme, it is
also necessary to achieve a high capacity, which is hard to be fulfilled by
existing knot-carriers owing to the limit number of associated topological
invariants. Thus, how to realize the knot-based information coding with a high
capacity is a key problem to be solved. Here, we create a type of nested vortex
knot, and show that it can be used to fulfill the robust information coding
with a high capacity assisted by a large number of intrinsic topological
invariants. In experiments, we design and fabricate metasurface holograms to
generate light fields sustaining different kinds of nested vortex links.
Furthermore, we verify the feasibility of the high-capacity coding scheme based
on those topological optical knots. Our work opens another way to realize the
robust and high capacity optical coding, which may have useful impacts on the
field of information transfer and storage.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:32:17 GMT""}]","2022-06-01"
"2205.08339","Yangyang Wang","Yangyang Wang and Jeffrey P. Gill and Hillel J. Chiel and Peter J.
  Thomas","Variational and phase response analysis for limit cycles with hard
  boundaries, with applications to neuromechanical control problems","26 pages, 13 figures",,,,"q-bio.NC math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motor systems show an overall robustness, but because they are highly
nonlinear, understanding how they achieve robustness is difficult. In many
rhythmic systems, robustness against perturbations involves response of both
the shape and the timing of the trajectory. This makes the study of robustness
even more challenging.
  To understand how a motor system produces robust behaviors in a variable
environment, we consider a neuromechanical model of motor patterns in the
feeding apparatus of the marine mollusk \textit{Aplysia californica}
\citep{shaw2015,lyttle2017}. We established in \citep{WGCT2021} the tools for
studying combined shape and timing responses of limit cycle systems under
sustained perturbations and here apply them to study robustness of the
neuromechanical model against increased mechanical load during swallowing.
Interestingly, we discover that nonlinear biomechanical properties confer
resilience by immediately increasing resistance to applied loads. In contrast,
the effect of changed sensory feedback signal is significantly delayed by the
firing rates' hard boundary properties. Our analysis suggests that sensory
feedback contributes to robustness in swallowing primarily by shifting the
timing of neural activation involved in the power stroke of the motor cycle
(retraction). This effect enables the system to generate stronger retractor
muscle forces to compensate for the increased load, and hence achieve strong
robustness.
  The approaches that we are applying to understanding a neuromechanical model
in \textit{Aplysia}, and the results that we have obtained, are likely to
provide insights into the function of other motor systems that encounter
changing mechanical loads and hard boundaries, both due to mechanical and
neuronal firing properties.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:33:40 GMT""}]","2022-05-18"
"2205.08340","Felipe Maia Polo","Felipe Maia Polo, Rafael Izbicki, Evanildo Gomes Lacerda Jr, Juan
  Pablo Ibieta-Jimenez, Renato Vicente","A unified framework for dataset shift diagnostics",,,,,"stat.ML cs.AI cs.LG stat.ME","http://creativecommons.org/licenses/by/4.0/","  Most supervised learning methods assume that the data used in the training
phase comes from the target population. However, in practice, one often faces
dataset shift, which, if not adequately taken into account, may decrease the
performance of their predictors. In this work, we propose a novel and flexible
framework called DetectShift that enables quantification and testing of various
types of dataset shifts, including shifts in the distributions of $(X, Y)$,
$X$, $Y$, $X|Y$, and $Y|X$. DetectShift provides practitioners with insights
about changes in their data, allowing them to leverage source and target data
to retrain or adapt their predictors. That is particularly valuable in
scenarios where labeled samples from the target domain are scarce. The
framework utilizes test statistics with the same nature to quantify the
magnitude of the various shifts, making results more interpretable. Moreover,
it can be applied in both regression and classification tasks, as well as to
different types of data such as tabular, text, and image data. Experimental
results demonstrate the effectiveness of DetectShift in detecting dataset
shifts even in higher dimensions. Our implementation for DetectShift can be
found in https://github.com/felipemaiapolo/detectshift.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:34:45 GMT""},{""version"":""v2"",""created"":""Mon, 26 Sep 2022 03:03:02 GMT""},{""version"":""v3"",""created"":""Fri, 12 May 2023 02:25:37 GMT""}]","2023-05-15"
"2205.08341","Abdenacer Makhlouf","K. Abdaoui, R. Gharbi, S. Mabrouk, A. Makhlouf","Cohomology and formal deformations of n-Hom-Lie color algebras",,,,,"math.RA math-ph math.MP math.RT","http://creativecommons.org/licenses/by/4.0/","  The aim of this paper is to provide a cohomology of $n$-Hom-Lie color
algebras governing one parameter formal deformations. Then, we study formal
deformations of a $n$-Hom-Lie color algebra and introduce the notion of
Nijenhuis operator on an $n$-Hom-Lie color algebra, which could give rise to
infinitesimally trivial $(n-1)$-order deformations. Furthermore, in connection
with Nijenhuis operators we introduce and discuss the notion of a product
structure on $n$-Hom-Lie color algebras.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:39:35 GMT""}]","2022-05-18"
"2205.08342","Kiryl Asheichyk","Kiryl Asheichyk and Matthias Kr\""uger","Radiative heat transfer with a cylindrical waveguide decays
  logarithmically slow","Main text: 6 pages, 4 figures; supplemental material: 10 pages, 6
  figures. Changes compared to v1: Figs. 4 and S6 are added (together with the
  corresponding two new sections in the SM); the inset of Fig. 2 is changed;
  one more inset is added to Fig. 3; additional information regarding the
  system parameters is added","Phys. Rev. Lett. 129, 170605 (2022)","10.1103/PhysRevLett.129.170605",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Radiative heat transfer between two far-field-separated nanoparticles placed
close to a perfectly conducting nanowire decays logarithmically slow with the
interparticle distance. This makes a cylinder an excellent waveguide which can
transfer thermal electromagnetic energy to arbitrary large distances with
almost no loss. It leads to a dramatic increase of the heat transfer, so that,
for almost any (large) separation, the transferred energy can be as large as
for isolated particles separated by a few hundred nanometers. A
phenomenologically found analytical formula accurately describes the numerical
results over a wide range of parameters.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:39:45 GMT""},{""version"":""v2"",""created"":""Wed, 26 Oct 2022 14:43:38 GMT""}]","2022-10-27"
"2205.08343","Arthur Barbosa C\^amara","Arthur C\^amara, Claudia Hauff","Moving Stuff Around: A study on efficiency of moving documents into
  memory for Neural IR models","7 pages, 2 figures. Accepted to the ReNeuIR workshop at SIGIR 2022",,,,"cs.IR","http://creativecommons.org/licenses/by/4.0/","  When training neural rankers using Large Language Models, it's expected that
a practitioner would make use of multiple GPUs to accelerate the training time.
By using more devices, deep learning frameworks, like PyTorch, allow the user
to drastically increase the available VRAM pool, making larger batches possible
when training, therefore shrinking training time. At the same time, one of the
most critical processes, that is generally overlooked when running data-hungry
models, is how data is managed between disk, main memory and VRAM. Most open
source research implementations overlook this memory hierarchy, and instead
resort to loading all documents from disk to main memory and then allowing the
framework (e.g., PyTorch) to handle moving data into VRAM. Therefore, with the
increasing sizes of datasets dedicated to IR research, a natural question
arises: s this the optimal solution for optimizing training time? We here study
how three different popular approaches to handling documents for IR datasets
behave and how they scale with multiple GPUs. Namely, loading documents
directly into memory, reading documents directly from text files with a lookup
table and using a library for handling IR datasets (ir_datasets) differ, both
in performance (i.e. samples processed per second) and memory footprint. We
show that, when using the most popular libraries for neural ranker research
(i.e. PyTorch and Hugging Face's Transformers), the practice of loading all
documents into main memory is not always the fastest option and is not feasible
for setups with more than a couple GPUs. Meanwhile, a good implementation of
data streaming from disk can be faster, while being considerably more scalable.
We also show how popular techniques for improving loading times, like memory
pining, multiple workers, and RAMDISK usage, can reduce the training time
further with minor memory overhead.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:40:18 GMT""},{""version"":""v2"",""created"":""Thu, 23 Jun 2022 12:19:29 GMT""}]","2022-06-24"
"2205.08344","Roberto Ribeiro","Marcelo V. Flamarion and Roberto Ribeiro-Jr","Solitary waves on flows with an exponentially sheared current and
  stagnation points",,,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While several articles have been written on water waves on flows with
constant vorticity, little is known about the extent to which a nonconstant
vorticity affects the flow structure, such as the appearance of stagnation
points. In order to shed light on this topic, we investigate in detail the flow
beneath solitary waves propagating on an exponentially decaying sheared
current. Our focus is to analyse numerically the emergence of stagnation
points. For this purpose, we approximate the velocity field within the fluid
bulk through the classical Korteweg-de Vries asymptotic expansion and use the
Matlab language to evaluate the resulting streamfunction. Our findings suggest
that the flow beneath the waves can have zero, one or two stagnation points in
the fluid body. We also study the bifurcation between these flows. Our
simulations indicate that the stagnation points emerge from a streamline with a
sharp corner.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:41:16 GMT""}]","2022-05-18"
"2205.08345","Eva Primo","D. Aleja, G. Contreras-Aso, K. Alfaro-Bittner, E. Primo, R. Criado, M.
  Romance, S. Boccaletti","A compartmental model for cyber-epidemics","6 pages, 5 figures",,"10.1016/j.chaos.2022.112310",,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  In our more and more interconnected world, a specific risk is that of a
cyber-epidemic (or cyber-pandemic), produced either accidentally or
intentionally, where a cyber virus propagates from device to device up to
undermining the global Internet system with devastating consequences in terms
of economic costs and societal harms related to the shutdown of essential
services. We introduce a compartmental model for studying the spreading of a
malware and of the awareness of its incidence through different waves which are
evolving on top of the same graph structure (the global network of connected
devices). This is realized by considering vectorial compartments made of two
components, the first being descriptive of the state of the device with respect
to the new malware's propagation, and the second accounting for the awareness
of the device's user about the presence of the cyber threat. By introducing
suitable transition rates between such compartments, one can then follow the
evolution of a cyber-epidemic from the moment at which a new virus is seeded in
the network, up to when a given user realizes that his/her device has suffered
a damage and consequently starts a wave of awareness which eventually ends up
with the development of a proper antivirus software. We then compare the
overall damage that a malware is able to produce in Erd\H{o}s-R\'enyi and
scale-free network architectures for both the case in which the virus is
causing a fixed damage on each device and the case where, instead, the virus is
engineered to mutate while replicating from device to device. Our result
constitute actually the attempt to build a specific compartmental model whose
variables and parameters are entirely customized for describing
cyber-epidemics.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:43:34 GMT""}]","2022-07-13"
"2205.08352","Arkaprabha Sarangi","Arkaprabha Sarangi and Jonathan Slavin","Dust Production in a Thin Dense Shell in Supernovae with Early
  Circumstellar Interactions","Accepted for publication in The Astrophysical Journal",,"10.3847/1538-4357/ac713d",,"astro-ph.SR astro-ph.GA astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  In supernovae (SNe), where the light curves show evidence of strong and early
interaction between the ejecta and the circumstellar matter (CSM), the
formation of new dust is estimated to take place in a dense shell of gas
between the forward (FS) and the reverse shock (RS). For the first time, in
this study, the mechanism of dust formation in this dense shell is modeled. A
set of 9 cases, considering variations of the ejecta mass, and the
pre-explosion mass-loss rates is considered, accounting for the diverse nature
of interactions reported in such SNe. For a single main sequence mass, the
variation of ejecta mass was manifested as a variation of the H-shell mass of
the star, lost due to pre-explosion mass-loss. We find that the dust masses in
the dense shell range between 10$^{-3}$ M$_{\odot}$ and 0.8 M$_{\odot}$,
composed of O-rich and C-rich grains, whose relative proportions are determined
by the nature of interaction. Dust formation in the post-shock gas is
characterized by a gradual production rate, mostly ranging from 10$^{-6}$ to
10$^{-3}$ M$_{\odot}$ day$^{-1}$, which may continue for a decade,
post-explosion. A higher mass-loss rate leads to a larger mass of dust, while a
smaller ejecta mass (smaller left-over H-shell) increases the efficiency of
dust production in such SNe. Dust formed behind the RS, as in our calculations,
is not subject to destruction by either the FS or RS and is thus likely to
survive in larger proportion than dust formed in the ejecta.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:46:29 GMT""}]","2022-07-20"
"2205.08353","Adrian Vetta","Arash Abizadeh and Adrian Vetta","A General Framework for a Class of Quarrels: The Quarrelling Paradox
  Revisited",,,,,"econ.TH cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  If a measure of voting power assigns greater voting power to a player because
it no longer effectively cooperates with another, then the measure displays the
quarrelling paradox and violates the quarrel postulate. We provide formal
criteria by which to judge whether a given conception of quarrelling is (a)
reasonable and (b) fit to serve as the basis for a reasonable quarrel
postulate. To achieve this, we formalize a general framework distinguishing
between three degrees of quarrelling (weak, strong, cataclysmic), symmetric vs.
asymmetrical quarrels, and reciprocal vs. non-reciprocal quarrels, and which
thereby yields twelve conceptions of quarrelling, which encompasses the two
conceptions proposed by Felsenthal and Machover and by Laruelle and Valenciano,
respectively. We argue that the two existing formulations of the quarrel
postulate based on these conceptions are unreasonable. In contrast, we prove
that the symmetric, weak conception of quarrelling identified by our framework
-- whether reciprocal or not -- is fit to serve as the basis for a reasonable
quarrel postulate. Furthermore, the classic Shapley-Shubik index and
Penrose-Banzhaf measure both satisfy the quarrel postulate based on a symmetric
weak quarrel.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:47:36 GMT""}]","2022-05-18"
"2205.08357","Hans Simon","Hans Ulrich Simon","Minimum Tournaments with the Strong $S_k$-Property and Implications for
  Teaching","9 pages, 0 figures",,,,"cs.DM","http://creativecommons.org/licenses/by/4.0/","  A tournament is said to have the $S_k$-property if, for any set of $k$
players, there is another player who beats them all. Minimum tournaments having
this property have been explored very well in the 1960's and the early 1970's.
In this paper, we define a strengthening of the $S_k$-property that we name
""strong $S_k$-property"". We show, first, that several basic results on the
weaker notion remain valid for the stronger notion (and the corresponding
modification of the proofs requires only little extra-effort). Second, it is
demonstrated that the stronger notion has applications in the area of Teaching.
Specifically, we present an infinite family of concept classes all of which can
be taught with a single example in the No-Clash model of teaching while, in
order to teach a class $\cC$ of this family in the recursive model of teaching,
order of $\log|\cC|$ many examples are required. This is the first paper that
presents a concrete and easily constructible family of concept classes which
separates the No-Clash from the recursive model of teaching by more than a
constant factor. The separation by a logarithmic factor is remarkable because
the recursive teaching dimension is known to be bounded by $\log |\cC|$ for any
concept class $\cC$.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:50:47 GMT""}]","2022-05-18"
"2205.08358","Manar Samad","Manar Samad and Sakib Abrar","Perturbation of Deep Autoencoder Weights for Model Compression and
  Classification of Tabular Data",,,,,"cs.LG cs.AI cs.NE","http://creativecommons.org/licenses/by-sa/4.0/","  Fully connected deep neural networks (DNN) often include redundant weights
leading to overfitting and high memory requirements. Additionally, the
performance of DNN is often challenged by traditional machine learning models
in tabular data classification. In this paper, we propose periodical
perturbations (prune and regrow) of DNN weights, especially at the
self-supervised pre-training stage of deep autoencoders. The proposed weight
perturbation strategy outperforms dropout learning in four out of six tabular
data sets in downstream classification tasks. The L1 or L2 regularization of
weights at the same pretraining stage results in inferior classification
performance compared to dropout or our weight perturbation routine. Unlike
dropout learning, the proposed weight perturbation routine additionally
achieves 15% to 40% sparsity across six tabular data sets for the compression
of deep pretrained models. Our experiments reveal that a pretrained deep
autoencoder with weight perturbation or dropout can outperform traditional
machine learning in tabular data classification when fully connected DNN fails
miserably. However, traditional machine learning models appear superior to any
deep models when a tabular data set contains uncorrelated variables. Therefore,
the success of deep models can be attributed to the inevitable presence of
correlated variables in real-world data sets.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:51:31 GMT""}]","2022-05-18"
"2205.08359","Maryna Raievska Iuriivna","Iryna Raievska, Maryna Raievska","Lower bounds for the number of local nearrings on groups of order $p^3$",,,,,"math.RA math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lower bounds for the number of local nearrings on groups of order $p^3$ are
obtained. On each non-metacyclic non-abelian or metacyclic abelian groups of
order $p^3$ there exist at least $p+1$ non-isomorphic local nearrings
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:52:51 GMT""}]","2022-05-18"
"2205.08360","Arno F\""orster","Arno F\""orster, Lucas Visscher","Quasiparticle Self-Consistent $GW$-Bethe-Salpeter equation calculations
  for large chromophoric systems",,,,,"physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  The $GW$-Bethe-Salpeter Equation (BSE) method is promising for calculating
the low-lying excited states of molecular systems. So far, it has only been
applied to rather small molecules, and in the commonly implemented diagonal
approximations to the electronic self-energy it depends on a mean-field
starting point. We describe here an implementation of the self-consistent and
starting-point independent quasiparticle self-consistent (qs$GW$)-BSE approach
which is suitable for calculations on large molecules. We herein show that
eigenvalue-only self-consistency leads to an unfaithful description of certain
excitonic states for Chlorophyll dimers while the qs$GW$-BSE vertical
excitation energies (VEE) are in excellent agreement with spectroscopic
experiments for Chlorophyll monomers and dimers measured in the gas phase. On
the other hand, VEEs from time-dependent density functional theory calculations
tend to disagree with experimental values and using different range-separated
hybrid (RSH) kernels changes the VEEs by up to 0.5 eV. We use the new
qs$GW$-BSE implementation to calculate the lowest excitation energies of the
six chromophores of the photosystem II (PSII) reaction center (RC) with nearly
2000 correlated electrons. Using more than 11000 (6000) basis functions, the
calculation could be completed in less than 5 (2) days one a single modern
compute node. In agreement with previous TD-DFT calculations using RSH kernels
on models that do also not include environment effects, our qs$GW$-BSE
calculations only yield states with local character in the low-energy spectrum
of the hexameric complex. Earlier work with RSH kernels has demonstrated that
the protein environment facilitates the experimentally observed
interchromophoric charge transfer. Therefore, future research will need to
combine correlation effects beyond TD-DFT with an explicit treatment of
environment electrostatics.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:53:02 GMT""},{""version"":""v2"",""created"":""Tue, 9 Aug 2022 14:58:00 GMT""}]","2022-08-10"
"2205.08361","Francesco Bonacci","Francesco Bonacci, Brato Chakrabarti, David Saintillan, Olivia du
  Roure, Anke Lindner","Dynamics of flexible filaments in oscillatory shear flows","18 pages, 9 figures",,"10.1017/jfm.2022.1040",,"physics.flu-dyn cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  The fluid-structure interactions between flexible fibers and viscous flows
play an essential role in various biological phenomena, medical problems, and
industrial processes. Of particular interest is the case of particles freely
transported in time-dependent flows. This work elucidates the dynamics and
morphologies of actin filaments under oscillatory shear flows by combining
microfluidic experiments, numerical simulations, and theoretical modeling. Our
work reveals that, in contrast to steady shear flows, in which small
orientational fluctuations from a flow-aligned state initiate tumbling and
deformations, the periodic flow reversal allows the filament to explore many
different configurations at the beginning of each cycle. Investigation of
filament motion during half time periods of oscillation highlights the critical
role of the initial filament orientation on the emergent dynamics. This strong
coupling between orientation and deformation results in new deformation regimes
and novel higher-order buckling modes absent in steady shear flows. The primary
outcome of our analysis is the possibility of suppression of buckling
instabilities for certain combinations of the oscillation frequency and initial
filament orientation, even in very strong flows. We explain this unusual
behavior through a weakly nonlinear Landau theory of buckling, in which we
treat the filaments as inextensible Brownian Euler-Bernoulli rods whose
hydrodynamics are described by local slender-body theory.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:54:02 GMT""}]","2023-02-01"
"2205.08366","Kamal Choudhary","Kamal Choudhary, Bobby G. Sumpter","A Deep-learning Model for Fast Prediction of Vacancy Formation in
  Diverse Materials",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The presence of point defects such as vacancies plays an important role in
material design. Here, we demonstrate that a graph neural network (GNN) model
trained only on perfect materials can also be used to predict vacancy formation
energies ($E_{vac}$) of defect structures without the need for additional
training data. Such GNN-based predictions are considerably faster than density
functional theory (DFT) calculations with reasonable accuracy and show the
potential that GNNs are able to capture a functional form for energy
predictions. To test this strategy, we developed a DFT dataset of 508 $E_{vac}$
consisting of 3D elemental solids, alloys, oxides, nitrides, and 2D monolayer
materials. We analyzed and discussed the applicability of such direct and fast
predictions. We applied the model to predict 192494 $E_{vac}$ for 55723
materials in the JARVIS-DFT database.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:56:43 GMT""}]","2022-05-18"
"2205.08367","Emanuele Costa","Emanuele Costa, Giuseppe Scriva, Rosario Fazio, Sebastiano Pilati","Deep learning density functionals for gradient descent optimization","9 pages, 10 figures","Phys. Rev. E 106, 045309 (2022)","10.1103/PhysRevE.106.045309",,"physics.comp-ph cond-mat.dis-nn cond-mat.mtrl-sci cond-mat.other cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine-learned regression models represent a promising tool to implement
accurate and computationally affordable energy-density functionals to solve
quantum many-body problems via density functional theory. However, while they
can easily be trained to accurately map ground-state density profiles to the
corresponding energies, their functional derivatives often turn out to be too
noisy, leading to instabilities in self-consistent iterations and in
gradient-based searches of the ground-state density profile. We investigate how
these instabilities occur when standard deep neural networks are adopted as
regression models, and we show how to avoid it using an ad-hoc convolutional
architecture featuring an inter-channel averaging layer. The testbed we
consider is a realistic model for noninteracting atoms in optical speckle
disorder. With the inter-channel average, accurate and systematically
improvable ground-state energies and density profiles are obtained via
gradient-descent optimization, without instabilities nor violations of the
variational principle.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:57:08 GMT""},{""version"":""v2"",""created"":""Mon, 7 Nov 2022 12:14:42 GMT""}]","2022-11-08"
"2205.08368","Adrian Vetta","Arash Abizadeh and Adrian Vetta","The Blocker Postulates for Measures of Voting Power",,,,,"econ.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A proposed measure of voting power should satisfy two conditions to be
plausible: first, it must be conceptually justified, capturing the intuitive
meaning of what voting power is; second, it must satisfy reasonable postulates.
This paper studies a set of postulates, appropriate for a priori voting power,
concerning blockers (or vetoers) in a binary voting game. We specify and
motivate five such postulates, namely, two subadditivity blocker postulates,
two minimum-power blocker postulates, each in weak and strong versions, and the
added-blocker postulate. We then test whether three measures of voting power,
namely the classic Penrose-Banzhaf measure, the classic Shapley-Shubik index,
and the newly proposed Recursive Measure, satisfy these postulates. We find
that the first measure fails four of the postulates, the second fails two,
while the third alone satisfies all five postulates. This work consequently
adds to the plausibility of the Recursive Measure as a reasonable measure of
voting power.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:57:15 GMT""}]","2022-05-18"
"2205.08374","Lucas Rovige","Lucas Rovige, Jos\'ephine Monzac, Julius Huijts, Igor A. Andriyash,
  Aline Vernier, Jaismeen Kaur, Marie Ouill\'e, Zhao Cheng, Vidmantas Tomkus,
  Valdas Girdauskas, Gediminas Ra\v{c}iukaits, Juozas Dudutis, Valdemar
  Stankevi\v{c}, Paulius Ge\v{c}ys, Rodrigo Lopez-Martens, J\'er\^ome Faure","Carrier-envelope phase controlled dynamics of relativistic electron
  beams in a laser-wakefield accelerator",,"Eur. Phys. J. Spec. Top. (2022)","10.1140/epjs/s11734-022-00675-7",,"physics.plasm-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In laser-wakefield acceleration, an ultra-intense laser pulse is focused into
an underdense plasma in order to accelerate electrons to relativistic
velocities. In most cases, the pulses consist of multiple optical cycles and
the interaction is well described in the framework of the ponderomotive force
where only the envelope of the laser has to be considered. But when using
single-cycle pulses, the ponderomotive approximation breaks down, and the
actual waveform of the laser has to be taken into account. In this paper, we
use near-single cycle laser pulses to drive a laser-wakefield accelerator. We
observe variations of the electron beam pointing on the order of 10 mrad in the
polarisation direction, as well as 30% variations of the beam charge, locked to
the value of the controlled laser carrier-envelope phase, in both nitrogen and
helium plasma. Those findings are explained through particle-in-cell
simulations indicating that low-emittance, ultra-short electron bunches are
periodically injected off-axis by the transversally oscillating bubble
associated with the slipping carrier-envelope phase.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:00:30 GMT""},{""version"":""v2"",""created"":""Fri, 7 Oct 2022 13:31:44 GMT""}]","2022-10-10"
"2205.08375","Francesco Navarra","Carmelo Cisto, Francesco Navarra and Rosanna Utano","Hilbert-Poincar\'e series and Gorenstein property for some non-simple
  polyominoes","21 pages, 8 figures","Bulletin of the Iranian Mathematical Society, \textbf{49}, 22
  (2023)","10.1007/s41980-023-00769-5",,"math.AC math.CO","http://creativecommons.org/licenses/by/4.0/","  Let $\mathcal{P}$ be a closed path having no zig-zag walks, a kind of
non-simple thin polyomino. In this paper we give a combinatorial interpretation
of the $h$-polynomial of $K[\mathcal{P}]$, showing that it is the rook
polynomial of $\mathcal{P}$. It is known by Rinaldo and Romeo (2021), that if
$\mathcal{P}$ is a simple thin polyomino then the $h$-polynomial is equal to
the rook polynomial of $\mathcal{P}$ and it is conjectured that this property
characterizes all thin polyominoes. Our main demonstrative strategy is to
compute the reduced Hilbert-Poincar\'e series of the coordinate ring attached
to a closed path $\mathcal{P}$ having no zig-zag walks, as a combination of the
Hilbert-Poincar\'e series of convenient simple thin polyominoes. As a
consequence we prove that the Krull dimension is equal to $\vert
V(\mathcal{P})\vert -\mathrm{rank}\, \mathcal{P}$ and the regularity of
$K[\mathcal{P}]$ is the rook number of $\mathcal{P}$. Finally we characterize
the Gorenstein prime closed paths, proving that $K[\mathcal{P}]$ is Gorenstein
if and only if $\mathcal{P}$ consists of maximal blocks of length three.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:00:50 GMT""},{""version"":""v2"",""created"":""Wed, 4 Jan 2023 16:14:44 GMT""}]","2023-04-05"
"2205.08376","Musa Furkan Keskin","Musa Furkan Keskin, Henk Wymeersch, Visa Koivunen","Monostatic Sensing with OFDM under Phase Noise: From Mitigation to
  Exploitation",,,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  We consider the problem of monostatic radar sensing with orthogonal
frequency-division multiplexing (OFDM) joint radar-communications (JRC) systems
in the presence of phase noise (PN) caused by oscillator imperfections. We
begin by providing a rigorous statistical characterization of PN in the radar
receiver over multiple OFDM symbols for free-running oscillators (FROs) and
phase-locked loops (PLLs). Based on the delay-dependent PN covariance matrix,
we derive the hybrid maximum-likelihood (ML)/maximum a-posteriori (MAP)
estimator of the deterministic delay-Doppler parameters and the random PN,
resulting in a challenging high-dimensional nonlinear optimization problem. To
circumvent the nonlinearity of PN, we then develop an iterated small angle
approximation (ISAA) algorithm that progressively refines delay-Doppler-PN
estimates via closed-form updates of PN as a function of delay-Doppler at each
iteration. Moreover, unlike existing approaches where PN is considered to be
purely an impairment that has to be mitigated, we propose to exploit PN for
resolving range ambiguity by capitalizing on its delay-dependent statistics
(i.e., the range correlation effect), through the formulation of a parametric
Toeplitz-block Toeplitz covariance matrix reconstruction problem. Simulation
results indicate quick convergence of ISAA to the hybrid Cram\'{e}r-Rao bound
(CRB), as well as its remarkable performance gains over state-of-the-art
benchmarks, for both FROs and PLLs under various operating conditions, while
showing that the detrimental effect of PN can be turned into an advantage for
sensing.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:01:08 GMT""},{""version"":""v2"",""created"":""Wed, 28 Sep 2022 15:05:43 GMT""}]","2022-09-29"
"2205.08379","Andrea Mifsud","Andrea Mifsud, Jiawei Shen, Peilong Feng, Lijie Xie, Chaohan Wang,
  Yihan Pan, Sachin Maheshwari, Shady Agwa, Spyros Stathopoulos, Shiwei Wang,
  Alexander Serb, Christos Papavassiliou, Themis Prodromakis, Timothy G.
  Constandinou","A CMOS-based Characterisation Platform for Emerging RRAM Technologies","5 pages. To be published in ISCAS 2022 and made available on IEEE
  Xplore",,,,"cs.ET cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Mass characterisation of emerging memory devices is an essential step in
modelling their behaviour for integration within a standard design flow for
existing integrated circuit designers. This work develops a novel
characterisation platform for emerging resistive devices with a capacity of up
to 1 million devices on-chip. Split into four independent sub-arrays, it
contains on-chip column-parallel DACs for fast voltage programming of the DUT.
On-chip readout circuits with ADCs are also available for fast read operations
covering 5-decades of input current (20nA to 2mA). This allows a device's
resistance range to be between 1k$\Omega$ and 10M$\Omega$ with a minimum
voltage range of $\pm$1.5V on the device.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:02:14 GMT""}]","2022-05-18"
"2205.08380","BoQiang Lu","Bo-Qiang Lu, Cheng-Wei Chiang, and Da Huang","Probing WIMPs in space-based gravitational wave experiments","11 pages, 2 figures, 2 tables","Physics Letters B 833 (2022) 137308","10.1016/j.physletb.2022.137308",,"hep-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Although searches for dark matter have lasted for decades, no convincing
signal has been found without ambiguity in underground detections, cosmic ray
observations, and collider experiments. We show by example that gravitational
wave (GW) observations can be a supplement to dark matter detections if the
production of dark matter follows a strong first-order cosmological phase
transition. We explore this possibility in a complex singlet extension of the
standard model with CP symmetry. We demonstrate three benchmarks in which the
GW signals from the first-order phase transition are loud enough for future
space-based GW observations, for example, BBO, U-DECIGO, LISA, Taiji, and
TianQin. While satisfying the constraints from the XENON1T experiment and the
Fermi-LAT gamma-ray observations, the dark matter candidate with its mass
around $\sim 1$~TeV in these scenarios has a correct relic abundance obtained
by the Planck observations of the cosmic microwave background radiation.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:02:58 GMT""},{""version"":""v2"",""created"":""Sun, 24 Jul 2022 15:15:56 GMT""}]","2022-07-26"
"2205.08381","Andrea Mifsud","Lijie Xie, Jiawei Shen, Andrea Mifsud, Chaohan Wang, Abdulaziz
  Alshaya, Christos Papavassiliou","A Wide Dynamic Range Read-out System For Resistive Switching Technology","5 pages, To be published in ISCAS 2022 and made available on IEEE
  Xplore",,,,"cs.ET cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The memristor, because of its controllability over a wide dynamic range of
resistance, has emerged as a promising device for data storage and analog
computation. A major challenge is the accurate measurement of memristance over
a wide dynamic range. In this paper, a novel read-out circuit with feedback
adjustment is proposed to measure and digitise input current in the range
between 20nA and 2mA. The magnitude of the input currents is estimated by a
5-stage logarithmic current-to-voltage amplifier which scales a linear
analog-to-digital converter. This way the least significant bit tracks the
absolute input magnitude. This circuit is applicable to reading single
memristor conductance, and is also preferable in analog computing where
read-out accuracy is particularly critical. The circuits have been realized in
Bipolar-CMOS-DMOS (BCD) Gen2 technology.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:03:36 GMT""}]","2022-05-18"
"2205.08386","S. B. F. Dorch","O. Ellegaard and S. B. F. Dorch","Astronomical observatory publications: information exchange before the
  Internet era","8 pages, 3 figures,","Journal of Astronomical History and Heritage (2022), 25(1), 91",,,"astro-ph.IM physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For decades, perhaps even centuries, the exchange of publications between
observatories was the most important source of information on new astronomical
results, either in the form of observational data or new scientific theories.
In particular, small observatories or institutions used this method. The
exchange of physical material between observatories has now been replaced by
the exchange of information via the Internet. Yet much of the ancient material
has never been digitized and can only be found in the few existing collections
of observatory publications. A recent donation of such a collection from the
University of Copenhagen to our own library at the University of Southern
Denmark has led us to investigate the uniqueness of such collections: Which
observatories and publications are represented in the collections that still
exist today? We also examine the availability of the material in the
collections.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:07:31 GMT""}]","2022-05-18"
"2205.08387","Carlos Pe\~na-Monferrer","Carlos Pe\~na-Monferrer and Carmen D\'iaz-Mar\'in","rom.js/cfd.xyz: An open-source framework for generating and visualizing
  parametric CFD results","This article has been published in the OpenFOAM Journal","OpenFOAM Journal 2 (2022) 143-148","10.51560/ofj.v2.83",,"physics.flu-dyn cs.NA math.NA","http://creativecommons.org/licenses/by-sa/4.0/","  We present in this technical note an open-source web framework for the
generation and visualization of parametric OpenFOAM simulations from surrogate
models. It consists of a JavaScript module (rom.js) and a web app (cfd.xyz) to
explore fluid dynamics problems efficiently and easily for a wide range of
parameters. rom.js is a JavaScript port of a set of open-source packages
(Eigen, Splinter, VTK/C++ and ITHACA-FV) to solve the online stage of
reduced-order models (ROM) generated by the ITHACA-FV tool. It can be executed
outside a web browser within a backend JavaScript runtime environment, or in a
given web solution. This methodology can also be extended to methods using
machine learning. The rom.js module was used in cfd.xyz, an open-source web
service to deliver a collection of interactive CFD cases in a parametric space.
The framework includes some tutorials, showing the whole process from the
generation of the surrogate model to the web browser. It also includes a
standalone web tool for visualizing users' ROMs by directly dragging and
dropping the output folder of the offline stage. Beyond the current proof of
technology, this enables a collaborative effort for the implementation of
OpenFOAM surrogate models in applications demanding real-time solutions such as
digital twins and other digital transformation technologies.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:09:29 GMT""},{""version"":""v2"",""created"":""Thu, 13 Oct 2022 09:18:17 GMT""}]","2022-10-14"
"2205.08388","Raphael Wagner","Raphael Wagner, Emil Wiedemann","Statistical solutions of the incompressible Euler equations",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study statistical solutions of the incompressible Euler equations in two
dimensions with vorticity in $L^p$, $1\leq p \leq \infty$, and in the class of
vortex-sheets with a distinguished sign. Our notion of statistical solution is
based on the framework due to Bronzi, Mondaini and Rosa. Existence in this
setting is shown by approximation with discrete measures, concentrated on
deterministic solutions of the Euler equations. Additionally, we provide
arguments to show that the statistical solutions of the Euler equations may be
obtained in the inviscid limit of statistical solutions of the incompressible
Navier-Stokes equations. Uniqueness of trajectory statistical solutions is
shown in the Yudovich class.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:10:01 GMT""}]","2022-05-18"
"2205.08389","Giuseppe Vecchio","Giuseppe Vecchio, Simone Palazzo, Dario C. Guastella, Ignacio
  Carlucho, Stefano V. Albrecht, Giovanni Muscato and Concetto Spampinato","MIDGARD: A Simulation Platform for Autonomous Navigation in Unstructured
  Environments",,,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  We present MIDGARD, an open-source simulation platform for autonomous robot
navigation in outdoor unstructured environments. MIDGARD is designed to enable
the training of autonomous agents (e.g., unmanned ground vehicles) in
photorealistic 3D environments, and to support the generalization skills of
learning-based agents through the variability in training scenarios. MIDGARD's
main features include a configurable, extensible, and difficulty-driven
procedural landscape generation pipeline, with fast and photorealistic scene
rendering based on Unreal Engine. Additionally, MIDGARD has built-in support
for OpenAI Gym, a programming interface for feature extension (e.g.,
integrating new types of sensors, customizing exposing internal simulation
variables), and a variety of simulated agent sensors (e.g., RGB, depth and
instance/semantic segmentation). We evaluate MIDGARD's capabilities as a
benchmarking tool for robot navigation utilizing a set of state-of-the-art
reinforcement learning algorithms. The results demonstrate MIDGARD's
suitability as a simulation and training environment, as well as the
effectiveness of our procedural generation approach in controlling scene
difficulty, which directly reflects on accuracy metrics. MIDGARD build, source
code and documentation are available at https://midgardsim.org/.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:10:21 GMT""},{""version"":""v2"",""created"":""Tue, 20 Sep 2022 10:10:11 GMT""}]","2022-09-21"
"2205.08390","Chu Han","Yuhao Mo, Chu Han, Yu Liu, Min Liu, Zhenwei Shi, Jiatai Lin, Bingchao
  Zhao, Chunwang Huang, Bingjiang Qiu, Yanfen Cui, Lei Wu, Xipeng Pan, Zeyan
  Xu, Xiaomei Huang, Zaiyi Liu, Ying Wang, Changhong Liang","HoVer-Trans: Anatomy-aware HoVer-Transformer for ROI-free Breast Cancer
  Diagnosis in Ultrasound Images",,,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Ultrasonography is an important routine examination for breast cancer
diagnosis, due to its non-invasive, radiation-free and low-cost properties.
However, the diagnostic accuracy of breast cancer is still limited due to its
inherent limitations. It would be a tremendous success if we can precisely
diagnose breast cancer by breast ultrasound images (BUS). Many learning-based
computer-aided diagnostic methods have been proposed to achieve breast cancer
diagnosis/lesion classification. However, most of them require a pre-define ROI
and then classify the lesion inside the ROI. Conventional classification
backbones, such as VGG16 and ResNet50, can achieve promising classification
results with no ROI requirement. But these models lack interpretability, thus
restricting their use in clinical practice. In this study, we propose a novel
ROI-free model for breast cancer diagnosis in ultrasound images with
interpretable feature representations. We leverage the anatomical prior
knowledge that malignant and benign tumors have different spatial relationships
between different tissue layers, and propose a HoVer-Transformer to formulate
this prior knowledge. The proposed HoVer-Trans block extracts the inter- and
intra-layer spatial information horizontally and vertically. We conduct and
release an open dataset GDPH&SYSUCC for breast cancer diagnosis in BUS. The
proposed model is evaluated in three datasets by comparing with four CNN-based
models and two vision transformer models via five-fold cross validation. It
achieves state-of-the-art classification performance with the best model
interpretability. In the meanwhile, our proposed model outperforms two senior
sonographers on the breast cancer diagnosis when only one BUS image is given.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:11:07 GMT""},{""version"":""v2"",""created"":""Fri, 15 Jul 2022 05:09:37 GMT""}]","2022-07-18"
"2205.08391","Andrea Mifsud","Jiawei Shen, Andrea Mifsud, Lijie Xie, Abdulaziz Alshaya, Christos
  Papavassiliou","A High-Voltage Characterisation Platform For Emerging Resistive
  Switching Technologies","5 pages. To be published in ISCAS 2022 and made available on
  IEEEXplore",,,,"cs.ET cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Emerging memristor-based array architectures have been effectively employed
in non-volatile memories and neuromorphic computing systems due to their
density, scalability and capability of storing information. Nonetheless, to
demonstrate a practical on-chip memristor-based system, it is essential to have
the ability to apply large programming voltage ranges during the
characterisation procedures for various memristor technologies. This work
presents a 16x16 high voltage memristor characterisation array employing high
voltage CMOS circuitry. The proposed system has a maximum programming range of
$\pm22V$ to allow on-chip electroforming and I-V sweep. In addition, a Kelvin
voltage sensing system is implemented to improve the readout accuracy for low
memristance measurements. This work addresses the limitation of conventional
CMOS-memristor platforms which can only operate at low voltages, thus limiting
the characterisation range and integration options of memristor technologies.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:15:19 GMT""}]","2022-05-18"
"2205.08392","Olivier Rahavandrainy","Olivier Rahavandrainy","All bi-unitary perfect polynomials over $\mathbb{F}_2$ with at most four
  irreducible factors","15 pages. arXiv admin note: text overlap with arXiv:1810.09697,
  arXiv:2204.13337",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give, in this paper, all bi-unitary perfect polynomials over the prime
field $\mathbb{F}_2$, with at most four irreducible factors.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:15:26 GMT""},{""version"":""v2"",""created"":""Mon, 23 May 2022 17:22:52 GMT""}]","2022-05-24"
"2205.08393","Md Atiqul Islam","George C. Alexandropoulos, Md Atiqul Islam, and Besma Smida","Full Duplex Massive MIMO Architectures: Recent Advances, Applications,
  and Future Directions","7 pages, 5 figure. Under review for publication in IEEE Vehicular
  Technology Magazine, 2022",,,,"cs.IT eess.SP math.IT","http://creativecommons.org/licenses/by/4.0/","  The increasingly demanding objectives for next generation wireless
communications have spurred recent research activities on multi-antenna
transceiver hardware architectures and relevant intelligent communication
schemes. Among them belong the Full Duplex (FD) Multiple-Input Multiple-Output
(MIMO) architectures, which offer the potential for simultaneous uplink and
downlink operations in the entire frequency band. However, as the number of
antenna elements increases, the interference signal leaking from the
transmitter of the FD radio to its receiver becomes more severe. In this
article, we present a unified FD massive MIMO architecture comprising analog
and digital transmit and receive BeamForming (BF), as well as analog and
digital SI cancellation, which can be jointly optimized for various performance
objectives and complexity requirements. Performance evaluation results for
applications of the proposed architecture to fully digital and hybrid analog
and digital BF operations using recent algorithmic designs, as well as
simultaneous communication of data and control signals are presented. It is
shown that the proposed architecture, for both small and large numbers of
antennas, enables improved spectral efficiency FD communications with fewer
analog cancellation elements compared to various benchmark schemes. The article
is concluded with a list of open challenges and research directions for future
FD massive MIMO communication systems and their promising applications.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:17:37 GMT""}]","2022-05-18"
"2205.08394","Adam Kesner","Ida H\""aggstr\""om, Lukas M. Carter, Thomas J. Fuchs and Adam L. Kesner","Depth resolved pencil beam radiography using AI -- a proof of principle
  study","10 pages, 6 figures. To be published in Journal of Instrumentation",,"10.1088/1748-0221/17/06/P06012",,"physics.med-ph physics.app-ph physics.ins-det","http://creativecommons.org/licenses/by-nc-nd/4.0/","  AIMS: Clinical radiographic imaging is seated upon the principle of
differential keV photon transmission through an object. At clinical x-ray
energies the scattering of photons causes signal noise and is utilized solely
for transmission measurements. However, scatter - particularly Compton scatter,
is characterizable. In this work we hypothesized that modern radiation sources
and detectors paired with deep learning techniques can use scattered photon
information constructively to resolve superimposed attenuators in planar x-ray
imaging. METHODS: We simulated a monoenergetic x-ray imaging system consisting
of a pencil beam x-ray source directed at an imaging target positioned in front
of a high spatial- and energy-resolution detector array. The signal was
analyzed by a convolutional neural network, and a description of scattering
material along the axis of the beam was derived. The system was virtually
designed/tested using Monte Carlo processing of simple phantoms consisting of
10 pseudo-randomly stacked air/bone/water materials, and the network was
trained by solving a classification problem. RESULTS: The average accuracy of
the material identification along the beam was 0.91 +- 0.01, with slightly
higher accuracy towards the entrance/exit peripheral surfaces of the object.
The average sensitivity and specificity was 0.91 and 0.95, respectively.
CONCLUSIONS: Our work provides proof of principle that deep learning techniques
can be used to analyze scattered photon patterns which can constructively
contribute to the information content in radiography, here used to infer depth
information in a traditional 2D planar setup. This principle, and our results,
demonstrate that the information in Compton scattered photons may provide a
basis for further development. The ability to scale performance to the clinic
remains unexplored and requires further study.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:17:39 GMT""}]","2022-06-22"
"2205.08395","Sara Lafia","Sara Lafia, Lizhou Fan, Andrea Thomer, Libby Hemphill","Subdivisions and Crossroads: Identifying Hidden Community Structures in
  a Data Archive's Citation Network","30 pages, 7 tables, 4 figures",,"10.1162/qss_a_00209",,"cs.DL cs.CY","http://creativecommons.org/licenses/by/4.0/","  Data archives are an important source of high quality data in many fields,
making them ideal sites to study data reuse. By studying data reuse through
citation networks, we are able to learn how hidden research communities - those
that use the same scientific datasets - are organized. This paper analyzes the
community structure of an authoritative network of datasets cited in academic
publications, which have been collected by a large, social science data
archive: the Interuniversity Consortium for Political and Social Research
(ICPSR). Through network analysis, we identified communities of social science
datasets and fields of research connected through shared data use. We argue
that communities of exclusive data reuse form subdivisions that contain
valuable disciplinary resources, while datasets at a ""crossroads"" broadly
connect research communities. Our research reveals the hidden structure of data
reuse and demonstrates how interdisciplinary research communities organize
around datasets as shared scientific inputs. These findings contribute new ways
of describing scientific communities in order to understand the impacts of
research data reuse.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:18:49 GMT""}]","2022-10-21"
"2205.08396","Andrzej Rozkosz","Andrzej Rozkosz and Leszek Slominski","On approximation of a Dirichlet problem for divergence form operator by
  Robin problems",,,,,"math.AP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that under natural assumptions solution of Dirichlet problems for
uniformly elliptic divergence form operator can be approximated pointwise by
solutions of some versions of Robin problems. The proof is based on stochastic
representation of solutions and properties of reflected diffusions
corresponding to divergence form operators.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:28:00 GMT""}]","2022-05-18"
"2205.08397","Rasmus Pagh","Rasmus Pagh, Mikkel Thorup","Improved Utility Analysis of Private CountSketch","To appear at NeurIPS 2022",,,,"cs.DS cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sketching is an important tool for dealing with high-dimensional vectors that
are sparse (or well-approximated by a sparse vector), especially useful in
distributed, parallel, and streaming settings. It is known that sketches can be
made differentially private by adding noise according to the sensitivity of the
sketch, and this has been used in private analytics and federated learning
settings. The post-processing property of differential privacy implies that all
estimates computed from the sketch can be released within the given privacy
budget.
  In this paper we consider the classical CountSketch, made differentially
private with the Gaussian mechanism, and give an improved analysis of its
estimation error. Perhaps surprisingly, the privacy-utility trade-off is
essentially the best one could hope for, independent of the number of
repetitions in CountSketch: The error is almost identical to the error from
non-private CountSketch plus the noise needed to make the vector private in the
original, high-dimensional domain.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:29:23 GMT""},{""version"":""v2"",""created"":""Wed, 12 Oct 2022 07:52:10 GMT""}]","2022-10-13"
"2205.08398","Jean Letang","Fran\c{c}ois Smekens, Nicolas Freud, Bruno Sixou, Guillaume Beslon and
  Jean M L\'etang","Variable length genetic algorithm with continuous parameters
  optimization of beam layout in proton therapy","16 pages, 8 figures",,,,"physics.med-ph cs.NE","http://creativecommons.org/licenses/by/4.0/","  Proton therapy is a modality in fast development. Characterized by a maximum
dose deposition at the end of the proton trajectory followed by a sharp
fall-off, proton beams can deliver a highly conformal dose to the tumor while
sparing organs at risk and surrounding healthy tissues. New treatment planning
systems based on spot scanning techniques can now propose multi-field
optimization. However, in most cases, this optimization only processes the
field fluences whereas the choice of ballistics (field geometry) is left to the
oncologist and medical physicist.
  In this work, we investigate a new optimization framework based on a genetic
approach. This tool is intended to explore new irradiation schemes and to
evaluate the potential of actual or future irradiation systems. We propose to
optimize simultaneously the target points and beam incidence angles in a
continuous manner and with a variable number of beams. No \textit{a priori}
technological constraints are taken into account, \textit{i.e.}~the beam energy
values, incidence directions and target points are free parameters.
  The proposed algorithm is based on a modified version of classical genetic
operators: mutation, crossover and selection. We use the real coding associated
with random perturbations of the parameters to obtain a continuous variation of
the potential solutions. We also introduce a perturbation in the exchange
points of the crossover to allow variations of the number of beams. These
variations are controlled by introducing a beam fluence lower limit.
  In this paper, we present a complete description of the algorithm and of its
behaviour in an elementary test case. The proposed method is finally assessed
in a clinically-realistic test case.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:31:33 GMT""}]","2022-05-18"
"2205.08399","Lisa Bonheme","Lisa Bonheme and Marek Grzes","How do Variational Autoencoders Learn? Insights from Representational
  Similarity",,,,,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The ability of Variational Autoencoders (VAEs) to learn disentangled
representations has made them popular for practical applications. However,
their behaviour is not yet fully understood. For example, the questions of when
they can provide disentangled representations, or suffer from posterior
collapse are still areas of active research. Despite this, there are no
layerwise comparisons of the representations learned by VAEs, which would
further our understanding of these models. In this paper, we thus look into the
internal behaviour of VAEs using representational similarity techniques.
Specifically, using the CKA and Procrustes similarities, we found that the
encoders' representations are learned long before the decoders', and this
behaviour is independent of hyperparameters, learning objectives, and datasets.
Moreover, the encoders' representations in all but the mean and variance layers
are similar across hyperparameters and learning objectives.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:31:57 GMT""},{""version"":""v2"",""created"":""Fri, 5 Aug 2022 14:06:39 GMT""},{""version"":""v3"",""created"":""Mon, 26 Sep 2022 15:40:26 GMT""}]","2022-09-27"
"2205.08400","Guillemin Rodary","K. Badiane, G. Rodary, M. Amato, A. Gloter, C. David, H. Aubin, and
  J.-C. Girard","Atomic scale visualization of the p-d hybridization in III-V
  semiconductors doped with transition metal impurities",,,"10.1103/PhysRevB.105.235443",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-sa/4.0/","  p-d hybridization of transition metal impurities in a semiconductor host is
the mechanism that couples valence-band electrons and localized spins. We use
scanning tunneling microscopy and spectroscopy combined with density functional
theory to probe at the atomic scale hybridization of Cr single impurities with
GaAs host. Combining spatial density of states mapping and in-gap states
spectroscopy of the Cr substituted at the surface of the semiconductor, we give
a detailed picture of the spatial extension and the electronic structure of the
strongly anisotropic wave function of Cr on GaAs(110). First principles
calculations allow to identify electronic character and origin of each states
and show that the main resonance peaks and the wave function with ""drop-eyes""
lobes experimentally observed for 3d metal impurities in III-V semiconductor
are direct local evidences of the p-d hybridization.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:34:43 GMT""}]","2022-07-13"
"2205.08401","Niles Johnson","Niles Johnson, Donald Yau","Multifunctorial $K$-Theory is an Equivalence of Homotopy Theories","20 pages. Final version. To appear in Journal of Homotopy and Related
  Structures","Journal of Homotopy and Related Structures 17 (2022), 569-592","10.1007/s40062-022-00317-8",,"math.AT math.CT math.KT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that each of the three $K$-theory multifunctors from small
permutative categories to $\mathcal{G}_*$-categories,
$\mathcal{G}_*$-simplicial sets, and connective spectra, is an equivalence of
homotopy theories. For each of these $K$-theory multifunctors, we describe an
explicit homotopy inverse functor. As a separate application of our general
results about pointed diagram categories, we observe that the right-induced
homotopy theory of Bohmann-Osorno $\mathcal{E}_*$-categories is equivalent to
the homotopy theory of pointed simplicial categories.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:34:54 GMT""},{""version"":""v2"",""created"":""Mon, 23 May 2022 11:05:19 GMT""},{""version"":""v3"",""created"":""Tue, 4 Oct 2022 14:09:12 GMT""}]","2022-12-12"
"2205.08402","Md Atiqul Islam","Md Atiqul Islam, George C. Alexandropoulos, and Besma Smida","Simultaneous Multi-User MIMO Communications and Multi-Target Tracking
  with Full Duplex Radios","6 pages, 5 figures. Submitted for publication in the Proceedings of
  IEEE Global Communications Conference (GLOBECOM), 2022",,,,"cs.IT eess.SP math.IT","http://creativecommons.org/licenses/by/4.0/","  In this paper, we present an Integrated Sensing and Communications (ISAC)
system enabled by in-band Full Duplex (FD) radios, where a massive
Multiple-Input Multiple-Output (MIMO) base station equipped with hybrid Analog
and Digital (A/D) beamformers is communicating with multiple DownLink (DL)
users, and simultaneously estimates via the same signaling waveforms the
Direction of Arrival (DoA) as well as the range of radar targets randomly
distributed within its coverage area. Capitalizing on a recent
reduced-complexity FD hybrid A/D beamforming architecture, we devise a joint
radar target tracking and DL data transmission protocol. An optimization
framework for the joint design of the massive A/D beamformers and the
Self-Interference (SI) cancellation unit, with the dual objective of maximizing
the radar tracking accuracy and DL communication performance, is presented. Our
simulation results at millimeter wave frequencies using 5G NR wideband
waveforms, showcase the accuracy of the radar target tracking performance of
the proposed system, which simultaneously offers increased sum rate compared
with benchmark schemes.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:37:17 GMT""}]","2022-05-18"
"2205.08403","Kengo Shimada","Yoshimasa Hidaka, Satoshi Iso and Kengo Shimada","Complementarity and causal propagation of decoherence by measurement in
  relativistic quantum field theories","Version published in PRD",,"10.1103/PhysRevD.106.076018","KEK-TH-2426, RIKEN-iTHEMS-Report-22","quant-ph gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Entanglement generation by Newtonian gravitational potential between objects
has been widely discussed to reveal the quantum nature of gravity. In this
paper, we perform a quantum field theoretical analysis of a slightly modified
version of the gedanken experiment by Mari and co-workers. We show that
decoherence due to the presence of a detector propagates with the speed of
light in terms of a retarded Green's function, as it should be consistent with
causality of relativistic field theories. The quantum nature of fields, such as
quantum fluctuations or emission of gravitons expressed in terms of the Keldysh
Green's function also play important roles in the mechanism of decoherence due
to on-shell particle creation. We also discuss the trade-off relation between
the visibility of the interference and the distinguishability of the
measurement, known as the wave particle duality, in our setup.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:37:43 GMT""},{""version"":""v2"",""created"":""Mon, 23 May 2022 12:50:28 GMT""},{""version"":""v3"",""created"":""Mon, 26 Sep 2022 07:48:27 GMT""},{""version"":""v4"",""created"":""Mon, 7 Nov 2022 11:40:02 GMT""}]","2022-11-09"
"2205.08404","Alberto Yukinobu Hata","Rafia Inam, Alberto Yukinobu Hata, Vlasjov Prifti and Sara Abbaspour
  Asadollah","A Comprehensive Study on Artificial Intelligence Algorithms to Implement
  Safety Using Communication Technologies",,,,,"cs.AI cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recent development of artificial intelligence (AI) has increased the
interest of researchers and practitioners towards applying its techniques into
multiple domains like automotive, health care and air space to achieve
automation. Combined to these applications, the attempt to use AI techniques
into carrying out safety issues is momentarily at a progressive state. As AI
problems are getting even more complex, large processing power is demanded for
safety-critical systems to fulfill real-time requirements. These challenges can
be solved through edge or cloud computing, which makes the communication an
integral part of the solution. This study aims at providing a comprehensive
picture of the state of the art AI based safety solutions that uses different
communication technologies in diverse application domains. To achieve this, a
systematic mapping study is conducted and 565 relevant papers are shortlisted
through a multistage selection process, which are then analyzed according to a
systematically defined classification framework. The results of the study are
based on these main objectives: to clarify current research gaps in the field,
to identify the possibility of increased usage of cellular communication in
multiple domains, to identify the mostly used AI algorithms and to summarize
the emerging future research trends on the topic. The results demonstrate that
automotive domain is the one applying AI and communication the most to
implement safety and the most used AI in this domain is neural networks,
clustering and computer vision; applying cellular communication to automotive
domain is highest; the use of non-cellular communication technologies is
dominant however a clear trend of a rapid increase in the use of cellular
communication is observed specially from 2020 with the roll-out of 5G
technology.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:38:38 GMT""}]","2022-05-18"
"2205.08405","Saswati Ganguly","Florian Miserez, Saswati Ganguly, Rudolf Haussmann, Matthias Fuchs","Continuum mechanics for the elastic properties of crystals: Microscopic
  approach based on projection-operator formalism",,,"10.1103/PhysRevE.106.054125",,"cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  We present a microscopic derivation of the laws of continuum mechanics of
nonideal ordered solids including dissipation, defect diffusion, and heat
transport. Starting point is the classical many-body Hamiltonian. The approach
relies on the Zwanzig-Mori projection operator formalism to connect microscopic
fluctuations to thermodynamic derivatives and transport coefficients.
Conservation laws and spontaneous symmetry breaking, implemented via
Bogoliubov's inequality, determine the selection of the slow variables. Density
fluctuations in reciprocal space encode the displacement field and the defect
concentration. Isothermal and adiabatic elastic constants are obtained from
equilibrium correlations, while transport coefficients are given as Green-Kubo
formulae, providing the basis for their measurement in atomistic simulations or
colloidal experiments. The approach and results are compared to others from the
literature.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:39:30 GMT""}]","2022-11-23"
"2205.08406","Ali Kariminezhad","Ravi Kothari, Ali Kariminezhad, Christian Mayr, Haoming Zhang","Raw Radar data based Object Detection and Heading estimation using Cross
  Attention",,,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  Radar is an inevitable part of the perception sensor set for autonomous
driving functions. It plays a gap-filling role to complement the shortcomings
of other sensors in diverse scenarios and weather conditions. In this paper, we
propose a Deep Neural Network (DNN) based end-to-end object detection and
heading estimation framework using raw radar data. To this end, we approach the
problem in both a Data-centric and model-centric manner. We refine the publicly
available CARRADA dataset and introduce Bivariate norm annotations. Besides,
the baseline model is improved by a transformer inspired cross-attention fusion
and further center-offset maps are added to reduce localisation error. Our
proposed model improves the detection mean Average Precision (mAP) by 5%, while
reducing the model complexity by almost 23%. For comprehensive scene
understanding purposes, we extend our model for heading estimation. The
improved ground truth and proposed model is available at Github
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:42:13 GMT""},{""version"":""v2"",""created"":""Fri, 17 Feb 2023 13:51:50 GMT""}]","2023-02-20"
"2205.08407","Philip Lazos","Georgios Amanatidis, Georgios Birmpas, Philip Lazos, Francisco J.
  Marmolejo-Coss\'io","Decentralised Update Selection with Semi-Strategic Experts",,,,,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by governance models adopted in blockchain applications, we study
the problem of selecting appropriate system updates in a decentralised way.
Contrary to most existing voting approaches, we use the input of a set of
motivated experts of varying levels of expertise. In particular, we develop an
approval voting inspired selection mechanism through which the experts approve
or disapprove the different updates according to their perception of the
quality of each alternative. Given their opinions, and weighted by their
expertise level, a single update is then implemented and evaluated, and the
experts receive rewards based on their choices. We show that this mechanism
always has approximate pure Nash equilibria and that these achieve a constant
factor approximation with respect to the quality benchmark of the optimal
alternative. Finally, we study the repeated version of the problem, where the
weights of the experts are adjusted after each update, according to their
performance. Under mild assumptions about the weights, the extension of our
mechanism still has approximate pure Nash equilibria in this setting.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:42:59 GMT""}]","2022-05-18"
"2205.08408","Qin Yu","Q. Yu","Tight focusing proton beam with radius in nanometer scale generation
  based on channeled solid target",,,,,"physics.acc-ph physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An efficient scheme of generating ultra-tightly focused proton bunch with
radius in nanometer scale is proposed. A needlelike proton filament of
transverse size in nanometer scale with the density of and charge quantity is
obtained based on multi-dimension Particle-in-Cell (PIC) simulations. The
regime is achieved via laser irradiating on a solid target with pre-channeled
density profile. The theoretical analysis mentions that the transverse electric
field dramatically transits from a defocusing dipole to double dipoles
structure with the change of the initial target density distribution from
uniform to pre-channeled. The inner dipole of the electric field tightly
focuses the proton beam into the order of magnitude of nanometer. 3D
simulations verify the scheme in the realistic condition. Various pre-channeled
density profiles including linear, parabolic and arbitrary steeped prove to
work well for the regime, which declares the robustness and the performability
of the scheme in experiment.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:14:11 GMT""}]","2022-05-18"
"2205.08410","Kurando Baba","Kurando Baba and Osamu Ikawa","Double Satake diagrams and canonical forms in compact symmetric triads","34 pages",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we first introduce the notion of double Satake diagrams for
compact symmetric triads. In terms of this notion, we give an alternative proof
for the classification theorem for compact symmetric triads, which was
originally given by Toshihiko Matsuki. Secondly, we introduce the notion of
canonical forms for compact symmetric triads, and prove the existence of
canonical forms for compact simple symmetric triads. We also give some
properties for canonical forms.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:44:20 GMT""}]","2022-05-18"
"2205.08411","Michael Benzaquen","Quentin Da Cruz Lopes, Sophie Ramananarivo, Caroline Cohen and Michael
  Benzaquen","Paragliders' Launch Trajectory is Universal","7 pages, 5 figures",,"10.1119/5.0101359",,"physics.pop-ph physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We designed and built a reduced-scale model experiment to study the
paragliding inflation and launching phase at given traction force. We show that
the launch trajectory of a single skin glider is universal, that is,
independent of the exerted force. As a consequence, the length of the take-off
run required for the glider to reach its ""ready to launch"" vertical position is
also universal. We successfully compare our results to full-scale experiments,
and show that such universality can be understood through a simple theoretical
model.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:47:18 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 14:37:46 GMT""}]","2023-05-03"
"2205.08412","Valentina Pansanella","Valentina Pansanella, Giulio Rossetti and Letizia Milli","From mean-field to complex topologies: network effects on the
  algorithmic bias model","11 pages, 4 figures, Complex Networks & Their Applications X",,"10.1007/978-3-030-93413-2_28",,"cs.SI physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  Nowadays, we live in a society where people often form their opinion by
accessing and discussing contents shared on social networking websites. While
these platforms have fostered information access and diffusion, they represent
optimal environments for the proliferation of polluted contents, which is
argued to be one of the co-causes of polarization/radicalization. Moreover,
recommendation algorithms - intended to enhance platform usage - are likely to
augment such phenomena, generating the so called Algorithmic Bias. In this
work, we study the impact that different network topologies have on the
formation and evolution of opinion in the context of a recent opinion dynamic
model which includes bounded confidence and algorithmic bias. Mean-field,
scale-free and random topologies, as well as networks generated by the
Lancichinetti-Fortunato-Radicchi benchmark, are compared in terms of opinion
fragmentation/polarization and time to convergence.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:50:08 GMT""}]","2022-05-18"
"2205.08413","Max Dabagia","Max Dabagia, Konrad P Kording, Eva L Dyer","Comparing high-dimensional neural recordings by aligning their
  low-dimensional latent representations",,,,,"q-bio.NC","http://creativecommons.org/licenses/by-sa/4.0/","  Many questions in neuroscience involve understanding of the responses of
large populations of neurons. However, when dealing with large-scale neural
activity, interpretation becomes difficult, and comparisons between two
animals, or across different time points becomes challenging. One major
challenge that we face in modern neuroscience is that of correspondence, e.g.
we do not record the exact same neurons at the exact same times. Without some
way to link two or more datasets, comparing different collections of neural
activity patterns becomes impossible. Here, we describe approaches for
leveraging shared latent structure across neural recordings to tackle this
correspondence challenge. We review algorithms that map two datasets into a
shared space where they can be directly compared, and argue that alignment is
key for comparing high-dimensional neural activities across times, subsets of
neurons, and individuals.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:52:09 GMT""}]","2022-05-18"
"2205.08414","Ruby Wright","Ruby J. Wright, Claudia del P. Lagos, Chris Power, Adam R. H. Stevens,
  Luca Cortese, Rhys J. J. Poulton","An orbital perspective on the starvation, stripping, and quenching of
  satellite galaxies in the EAGLE simulations","Accepted for publication in MNRAS",,"10.1093/mnras/stac2042",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Using the EAGLE suite of simulations, we demonstrate that both cold gas
stripping {\it and} starvation of gas inflow play an important role in
quenching satellite galaxies across a range of stellar and halo masses,
$M_{\star}$ and $M_{200}$. By quantifying the balance between gas inflows,
outflows, and star formation rates, we show that even at $z=2$, only
$\approx30\%$ of satellite galaxies are able to maintain equilibrium or grow
their reservoir of cool gas - compared to $\approx50\%$ of central galaxies at
this redshift. We find that the number of orbits completed by a satellite is a
very good predictor of its quenching, even more so than the time since infall.
On average, we show that intermediate-mass satellites with $M_{\star}$ between
$10^{9}{\rm M}_{\odot}-10^{10}{\rm M}_{\odot}$ will be quenched at first
pericenter in massive group environments, $M_{200}>10^{13.5}{\rm M}_{\odot}$;
and will be quenched at second pericenter in less massive group environments,
$M_{200}<10^{13.5}{\rm M}_{\odot}$. On average, more massive satellites
($M_{\star}>10^{10}{\rm M}_{\odot}$) experience longer depletion time-scales,
being quenched between first and second pericenters in massive groups; while in
smaller group environments, just $\approx30\%$ will be quenched even after two
orbits. Our results suggest that while starvation alone may be enough to slowly
quench satellite galaxies, direct gas stripping, particularly at pericenters,
is required to produce the short quenching time-scales exhibited in the
simulation.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:52:48 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jul 2022 02:44:47 GMT""}]","2022-08-03"
"2205.08415","Xiang Li","Xiang Li, Jing Hao, Jiguang Bao","Entire solutions of the generalized Hessian inequality",,,,,"math.DG math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we discuss the more general Hessian inequality
$\sigma_{k}^{\frac{1}{k}}(\lambda (D_i (A\left(|Du|\right) D_j u)))\geq f(u)$
including the Laplacian, p-Laplacian, mean curvature, Hessian, k-mean curvature
operators, and provide a necessary and sufficient condition on the global
solvability, which can be regarded as generalized Keller-Osserman conditions.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:55:10 GMT""}]","2022-05-18"
"2205.08416","Qingyu Li","Qingyu Li, Yilei Shi, Xiao Xiang Zhu","Semi-Supervised Building Footprint Generation with Feature and Output
  Consistency Training",,,"10.1109/TGRS.2022.3174636",,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Accurate and reliable building footprint maps are vital to urban planning and
monitoring, and most existing approaches fall back on convolutional neural
networks (CNNs) for building footprint generation. However, one limitation of
these methods is that they require strong supervisory information from massive
annotated samples for network learning. State-of-the-art semi-supervised
semantic segmentation networks with consistency training can help to deal with
this issue by leveraging a large amount of unlabeled data, which encourages the
consistency of model output on data perturbation. Considering that rich
information is also encoded in feature maps, we propose to integrate the
consistency of both features and outputs in the end-to-end network training of
unlabeled samples, enabling to impose additional constraints. Prior
semi-supervised semantic segmentation networks have established the cluster
assumption, in which the decision boundary should lie in the vicinity of low
sample density. In this work, we observe that for building footprint
generation, the low-density regions are more apparent at the intermediate
feature representations within the encoder than the encoder's input or output.
Therefore, we propose an instruction to assign the perturbation to the
intermediate feature representations within the encoder, which considers the
spatial resolution of input remote sensing imagery and the mean size of
individual buildings in the study area. The proposed method is evaluated on
three datasets with different resolutions: Planet dataset (3 m/pixel),
Massachusetts dataset (1 m/pixel), and Inria dataset (0.3 m/pixel).
Experimental results show that the proposed approach can well extract more
complete building structures and alleviate omission errors.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:55:13 GMT""}]","2022-06-15"
"2205.08421","Xiang-Bin Wang","Cong Jiang, Zong-Wen Yu, Xiao-Long Hu and Xiang-Bin Wang","Side-channel-free quantum key distribution with practical devices",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Based on the idea that there is no side channel in the vacuum state, the
side-channel-free quantum key distribution (SCFQKD) protocol was proposed,
which is immune to all attacks in the source side-channel space and all attacks
in the detectors. In the original SCFQKD protocol, an important assumption is
that Alice and Bob can produce the perfect vacuum pulses. But due to the finite
extinction ratio of the intensity modulators, the perfect vacuum pulse is
impossible in practice. In this paper, we solve this problem and make the
quantum key distribution side-channel secure with real source device which does
not emit perfect vacuum pulses. Our conclusion only depends on the upper bounds
of the intensities of the sources. No other assumptions such as stable sources
and stable side channels are needed. The numerical results show that, comparing
with the results of SCFQKD protocol with perfect vacuum sources, the key rates
and secure distance are only slightly decreased if the upper bound of the
intensity of the imperfect vacuum source is less than $10^{-8}$ which can be
achieved in experiment by two-stage intensity modulator. We also show that the
two-way classical communication can be used to the data post-processing of
SCFQKD protocol to improve the key rate. Specially, the active odd-parity
pairing method can improve the key rates in all distances by about two times
and the secure distance by about 40 km. Give that the side channel security
based on imperfect vacuum, this work makes it possible to realize side channel
secure QKD with real devices.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:57:38 GMT""},{""version"":""v2"",""created"":""Wed, 18 May 2022 13:58:01 GMT""},{""version"":""v3"",""created"":""Thu, 19 May 2022 01:27:50 GMT""}]","2022-05-20"
"2205.08424","Stijn Debackere","Stijn N.B. Debackere, Henk Hoekstra, Joop Schaye","Galaxy cluster aperture masses are more robust to baryonic effects than
  3D halo masses","9 pages, 6 figures, updated to accepted version from MNRAS",,"10.1093/mnras/stac2077",,"astro-ph.CO","http://creativecommons.org/licenses/by-sa/4.0/","  Systematic uncertainties in the mass measurement of galaxy clusters limit the
cosmological constraining power of future surveys that will detect more than
$10^5$ clusters. Previously, we argued that aperture masses can be inferred
more accurately and precisely than 3D masses without loss of cosmological
constraining power. Here, we use the Baryons and Haloes of Massive Systems
(BAHAMAS) cosmological, hydrodynamical simulations to show that aperture masses
are also less sensitive to changes in mass caused by galaxy formation
processes. For haloes with $m_\mathrm{200m,dmo} > 10^{14} \, h^{-1} \,
\mathrm{M}_\odot$, binned by their 3D halo mass, baryonic physics affects
aperture masses and 3D halo masses similarly when measured within apertures
similar to the halo virial radius, reaching a maximum reduction of $\approx 3
\, \%$. For lower-mass haloes, $10^{13.5} < m_\mathrm{200m,dmo} / (h^{-1} \,
\mathrm{M}_\odot) < 10^{14}$, and aperture sizes $\sim 1 \, h^{-1} \,
\mathrm{cMpc}$, representative of weak lensing observations, the aperture mass
is consistently reduced less ($\lesssim 5 \, \%$) than the 3D halo mass
($\lesssim 10 \, \%$ for $m_\mathrm{200m}$). The halo mass reduction evolves
only slightly, by up to $2$ percentage points, between redshift 0.25 and 1 for
both the aperture mass and $m_\mathrm{200m}$. Varying the strength of the
simulated feedback so the mean simulated hot gas fraction covers the observed
scatter inferred from X-ray observations, we find that the aperture mass is
consistently less biased than the 3D halo mass, by up to $2 \, $ percentage
points at $m_\mathrm{200m,dmo} = 10^{14} \, h^{-1} \, \mathrm{M}_\odot$.
Therefore, cluster aperture mass calibrations provide a fruitful path forward
for future cluster surveys to reduce their sensitivity to systematic
uncertainties.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:00:39 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jul 2022 11:57:31 GMT""}]","2022-08-03"
"2205.08425","Abdelhakim Hannousse","Abdelhakim Hannousse and Salima Yahiouche and Mohamed Cherif
  Nait-Hamoud","Twenty-two years since revealing cross-site scripting attacks: a
  systematic mapping and a comprehensive survey",,,,,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  Cross-site scripting (XSS) is one of the major threats menacing the privacy
of data and the navigation of trusted web applications. Since its reveal in
late 1999 by Microsoft security engineers, several techniques have been
developed in the aim to secure web navigation and protect web applications
against XSS attacks. The problem became worse with the emergence of advanced
web technologies such as Web services and APIs and new programming styles such
as AJAX, CSS3 and HTML5. While new technologies enable complex interactions and
data exchanges between clients and servers in the network, new programming
styles introduce new and complicate injection flaws to web applications. XSS
has been and still in the TOP 10 list of web vulnerabilities reported by the
Open Web Applications Security Project (OWASP). Consequently, handling XSS
attacks became one of the major concerns of several web security communities.
In this paper, we contribute by conducting a systematic mapping and a
comprehensive survey. We summarize and categorize existent endeavors that aim
to protect against XSS attacks and develop XSS-free web applications. The
present review covers 147 high quality published studies since 1999 including
early publications of 2022. A comprehensive taxonomy is drawn out describing
the different techniques used to prevent, detect, protect and defend against
XSS attacks. Although the diversity of XSS attack types and the scripting
languages that can be used to state them, the systematic mapping revealed a
remarkable bias toward basic and JavaScript XSS attacks and a dearth of
vulnerability repair mechanisms. The survey highlighted the limitations,
discussed the potentials of existing XSS attack defense mechanisms and
identified potential gaps.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:00:58 GMT""},{""version"":""v2"",""created"":""Thu, 19 May 2022 09:18:45 GMT""}]","2022-05-20"
"2205.08426","Ryan Shah","Ryan Shah, Chuadhry Mujeeb Ahmed, Shishir Nagaraja","Can You Still See Me?: Reconstructing Robot Operations Over End-to-End
  Encrypted Channels","13 pages, 7 figures, 9 tables, Poster presented at wisec'22",,,,"cs.CR cs.LG cs.RO","http://creativecommons.org/licenses/by/4.0/","  Connected robots play a key role in Industry 4.0, providing automation and
higher efficiency for many industrial workflows. Unfortunately, these robots
can leak sensitive information regarding these operational workflows to remote
adversaries. While there exists mandates for the use of end-to-end encryption
for data transmission in such settings, it is entirely possible for passive
adversaries to fingerprint and reconstruct entire workflows being carried out
-- establishing an understanding of how facilities operate. In this paper, we
investigate whether a remote attacker can accurately fingerprint robot
movements and ultimately reconstruct operational workflows. Using a neural
network approach to traffic analysis, we find that one can predict
TLS-encrypted movements with around ~60% accuracy, increasing to near-perfect
accuracy under realistic network conditions. Further, we also find that
attackers can reconstruct warehousing workflows with similar success.
Ultimately, simply adopting best cybersecurity practices is clearly not enough
to stop even weak (passive) adversaries.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:01:32 GMT""},{""version"":""v2"",""created"":""Wed, 21 Sep 2022 10:13:21 GMT""}]","2022-09-22"
"2205.08427","Yun Wang","Yun Wang, Tian-Ci Zheng, Zhi-Ping Jin","GRB 220426A: A Thermal Radiation-Dominated Gamma-Ray Burst","14 pages, 6 figures, 2 tables; Accepted for publication in ApJ",,"10.3847/1538-4357/aca017",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The physical composition of the ejecta of gamma-ray bursts (GRBs) remains an
open question. The radiation mechanism of the prompt gamma rays is also in
debate. This problem can be solved for the bursts hosting distinct thermal
radiation. However, the events with dominant thermal spectral components are
still rare. In this work, we focus on GRB 220426A, a recent event detected by
Fermi-GBM. The time-resolved and time-integrated data analyses yield very hard
low-energy spectral indices and rather soft high-energy spectral indices. This
means that the spectra of GRB 220426A are narrowly distributed. And the
Bayesian inference results are in favor of the multicolor blackbody (mBB)
model. The physical properties of the relativistic outflow are calculated.
Assuming a redshift $z= 1.4$, the bulk Lorentz factors $\Gamma$ of the shells
are found to be between $274_{-18}^{+24}$ and $827_{-71}^{+100}$, and the
corresponding photosphere radii $R_{\rm ph}$ are in the range of
$1.83_{-0.50}^{+0.52} \times 10^{11}$ and $2.97_{-0.15}^{+0.14} \times 10^{12}$
cm. Similar to GRB 090902B, the time-resolved properties of GRB 220426A satisfy
the observed $\Gamma-L$ and $E_p-L$ correlations, where $L$ is the luminosity
of the prompt emission and $E_{p}$ is the spectral peak energy.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:07:19 GMT""},{""version"":""v2"",""created"":""Wed, 18 May 2022 15:33:48 GMT""},{""version"":""v3"",""created"":""Thu, 26 May 2022 05:43:20 GMT""},{""version"":""v4"",""created"":""Tue, 6 Dec 2022 02:36:02 GMT""}]","2022-12-07"
"2205.08428","Yuguang Shi","Yuhao Hu, Peng Liu, Yuguang Shi","Rigidity of 3D spherical caps via $\mu$-bubbles","20 pages, 1 figure, All comments are welcome",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  By using Gromov's $\mu$-bubble technique, we show that the $3$-dimensional
spherical caps are rigid under perturbations that do not reduce the metric, the
scalar curvature, and the mean curvature along its boundary. Several
generalizations of this result will be discussed.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:07:31 GMT""},{""version"":""v2"",""created"":""Sat, 28 May 2022 06:09:48 GMT""},{""version"":""v3"",""created"":""Sat, 25 Jun 2022 00:15:58 GMT""}]","2022-06-28"
"2205.08429","Zhengfang Wang","Xiao-Wu Chen and Zhengfang Wang","The singular Yoneda category and the stabilization functor","28 pages, comments welcome",,,,"math.RT math.KT math.RA","http://creativecommons.org/licenses/by/4.0/","  For a noetherian ring $\Lambda$, the stabilization functor in the sense of
Krause yields an embedding of the singularity category of $\Lambda$ into the
homotopy category of acyclic complexes of injective $\Lambda$-modules. When
$\Lambda$ contains a semisimple artinian subring $E$, we give an explicit
description of the stabilization functor using the Hom complexes in the
$E$-relative singular Yoneda dg category of $\Lambda$.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:14:55 GMT""}]","2022-05-18"
"2205.08430","Chia-Hung Lin","Lin Shih-Chun, Lin Chia-Hung, Chu Liang C. and Lien Shao-Yu","Towards Resilient Access Equality for 6G Serverless p-LEO Satellite
  Networks","Submitted for possible publication to the IEEE Communication magazine",,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Low earth orbit (LEO) mega-constellations, integrating government space
systems and commercial practices, have emerged as enabling technologies for the
sixth generation (6G) networks due to their good merits of global coverage and
ubiquitous services for military and civilian use cases. However, convergent
LEO-based satellite networking infrastructures still lack leveraging the
synergy of space and terrestrial systems. This paper, therefore, extends
conventional serverless cloud platforms with serverless edge learning
architectures for 6G proliferated LEO (p-LEO) satellite ecosystems and provides
a new distributed training design from a networking perspective. The proposed
design dynamically orchestrates communications and computation functionalities
and resources among heterogeneous physical units to efficiently fulfill
multi-agent deep reinforcement learning for service-level agreements.
Innovative ecosystem enhancements, including ultrabroadband access, anti-jammed
transmissions, resilient networking, and related open challenges, are also
investigated for end-to-end connectivity, communications, and learning
performance.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:16:48 GMT""}]","2022-05-18"
"2205.08431","Pablo Mart\'inez-Mirav\'e","Guo-yuan Huang, Manfred Lindner, Pablo Mart\'inez-Mirav\'e, Manibrata
  Sen","Cosmology-friendly time-varying neutrino masses via the sterile neutrino
  portal","20 pages, 9 figures, updated, new references, change in notation",,"10.1103/PhysRevD.106.033004",,"hep-ph astro-ph.CO hep-ex","http://creativecommons.org/licenses/by/4.0/","  We investigate a consistent scenario of time-varying neutrino masses, and
discuss its impact on cosmology, beta decay, and neutrino oscillation
experiments. Such time-varying masses are assumed to be generated by the
coupling between a sterile neutrino and an ultralight scalar field, which in
turn affects the light neutrinos by mixing. Besides, the scalar could act as an
ultralight dark matter candidate. We demonstrate how various cosmological
bounds, such as those coming from Big Bang nucleosynthesis, the cosmic
microwave background, as well as large scale structures, can be evaded in this
model. This scenario can be further constrained using multiple terrestrial
experiments. In particular, for beta-decay experiments like KATRIN, non-trivial
distortions to the electron spectrum can be induced, even when time-variation
is fast and gets averaged out. Furthermore, the presence of time-varying masses
of sterile neutrinos will alter the interpretation of light sterile neutrino
parameter space in the context of the reactor and gallium anomalies. In
addition, we also study the impact of such time-varying neutrino masses on
results from the BEST collaboration, which have recently strengthened the
gallium anomaly. If confirmed, we find that the time-varying neutrino mass
hypothesis could give a better fit to the recent BEST data.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:19:40 GMT""},{""version"":""v2"",""created"":""Thu, 26 Jan 2023 13:25:50 GMT""}]","2023-01-27"
"2205.08432","Juan Carlos Bilbao-Ludena","Juan Carlos Bilbao-Ludena, George Papadakis","On the structure of Vorticity and Turbulence Fields in a separated flow
  around a finite wing; analysis using Direct Numerical Simulation",,,,,"physics.flu-dyn","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We investigate the spatial distributions and production mechanisms of
vorticity and turbulent kinetic energy around a finite NACA 0018 wing with
square wingtip profile at $Re_c=10^4$ and $10^{\circ}$ angle of attack with the
aid of Direct Numerical Simulation (DNS). The analysis focuses on the highly
inhomogeneous region around the tip and the near wake; this region is highly
convoluted, strongly three-dimensional, and far from being self-similar. The
flow separates close to the leading edge creating a large, open recirculation
zone around the central part of the wing. In the proximity of the tip, the flow
remains attached but another smaller recirculation zone forms closer to the
trailing edge; this zone strongly affects the development of main wing tip
vortex. The early formation mechanisms of three vortices close to the leading
edge are elucidated and discussed. More specifically, we analyse the role of
vortex stretching/compression and tilting, and how it affects the strength of
each vortex as it approaches the trailing edge. We find that the
three-dimensional flow separation at the sharp tip close to the leading edge
plays an important role on the subsequent vortical flow development on the
suction side. The production of turbulent kinetic energy and Reynolds stresses
is also investigated and discussed in conjunction with the identified vortex
patterns. The detailed analysis of the mechanisms that sustain vorticity and
turbulent kinetic energy improves our understanding of these highly three
dimensional, non-equilibrium flows and can lead to better actuation methods to
manipulate these flows.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:21:48 GMT""}]","2022-05-18"
"2205.08433","Kayue Wong","Dan Barbasch, Kayue Daniel Wong","Admissible modules and normality of classical nilpotent orbits II","17 pages, preliminary version. This work is a sequel to
  arXiv:1801.06909",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we compute the character formula of the Brylinski model for
all classical nilpotent varieties $\overline{\mathcal{O}}$. As a consequence,
one can compute the multiplicities of all $K-$types of the ring of regular
functions $R(\overline{\mathcal{O}})$ for all classical nilpotent varieties.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:22:21 GMT""}]","2022-05-18"
"2205.08434","Youssef Nader","Youssef Nader, Leon Sixt, Tim Landgraf","DNNR: Differential Nearest Neighbors Regression","published at ICML 2022",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  K-nearest neighbors (KNN) is one of the earliest and most established
algorithms in machine learning. For regression tasks, KNN averages the targets
within a neighborhood which poses a number of challenges: the neighborhood
definition is crucial for the predictive performance as neighbors might be
selected based on uninformative features, and averaging does not account for
how the function changes locally. We propose a novel method called Differential
Nearest Neighbors Regression (DNNR) that addresses both issues simultaneously:
during training, DNNR estimates local gradients to scale the features; during
inference, it performs an n-th order Taylor approximation using estimated
gradients. In a large-scale evaluation on over 250 datasets, we find that DNNR
performs comparably to state-of-the-art gradient boosting methods and MLPs
while maintaining the simplicity and transparency of KNN. This allows us to
derive theoretical error bounds and inspect failures. In times that call for
transparency of ML models, DNNR provides a good balance between performance and
interpretability.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:22:53 GMT""}]","2022-05-18"
"2205.08435","Linfeng Zhang","Wing Fung Chong, Runhuan Feng, Hins Hu, Linfeng Zhang","Cyber Risk Assessment for Capital Management","This paper was first presented on July 5, 2021, at the 24th
  International Congress on Insurance: Mathematics and Economics",,,,"q-fin.RM cs.CR math.OC","http://creativecommons.org/licenses/by/4.0/","  Cyber risk is an omnipresent risk in the increasingly digitized world that is
known to be difficult to quantify and assess. Despite the fact that cyber risk
shows distinct characteristics from conventional risks, most existing models
for cyber risk in the insurance literature have been purely based on
frequency-severity analysis, which was developed for classical property and
casualty risks. In contrast, the cybersecurity engineering literature employs
different approaches, under which cyber incidents are viewed as threats or
hacker attacks acting on a particular set of vulnerabilities. There appears a
gap in cyber risk modeling between engineering and insurance literature. This
paper presents a novel model to capture these unique dynamics of cyber risk
known from engineering and to model loss distributions based on industry loss
data and a particular company's cybersecurity profile. The analysis leads to a
new tool for allocating resources of the company between cybersecurity
investments and loss-absorbing reserves.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:25:23 GMT""},{""version"":""v2"",""created"":""Sat, 6 Aug 2022 04:13:56 GMT""}]","2022-08-09"
"2205.08436","Daniela De Silva","Daniela De Silva and Ovidiu Savin","Uniform density estimates and $\Gamma$-convergence for the Alt-Phillips
  functional of negative powers",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We obtain density estimates for the free boundaries of minimizers $u \ge 0$
of the Alt-Phillips functional involving negative power potentials
  $$\int_\Omega \left(|\nabla u|^2 + u^{-\gamma} \chi_{\{u>0\}}\right) \, dx,
\quad \quad \gamma \in (0,2).$$
  These estimates remain uniform as the parameter $\gamma \to 2$. As a
consequence we establish the uniform convergence of the corresponding free
boundaries to a minimal surface as $\gamma \to 2$.
  The results are based on the $\Gamma$-convergence of these energies (properly
rescaled) to the Dirichlet-perimeter functional
  $$\int_\Omega |\nabla u|^2 dx + Per_{\Omega}(\{ u=0\}),$$
  considered by Athanasopoulous, Caffarelli, Kenig, and Salsa.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:26:03 GMT""}]","2022-05-18"
"2205.08437","Raffaello Potestio","Margherita Mele, Roberto Covino and Raffaello Potestio","Information-theoretical measures identify accurate low-resolution
  representations of protein configurational space",,,,,"cond-mat.soft cond-mat.stat-mech q-bio.BM q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A steadily growing computational power is employed to perform molecular
dynamics simulations of biological macromolecules, which represents at the same
time an immense opportunity and a formidable challenge. In fact, large amounts
of data are produced, from which useful, synthetic, and intelligible
information has to be extracted to make the crucial step from knowing to
understanding. Here we tackled the problem of coarsening the conformational
space sampled by proteins in the course of molecular dynamics simulations. We
applied different schemes to cluster the frames of a dataset of protein
simulations; we then employed an information-theoretical framework, based on
the notion of resolution and relevance, to gauge how well the various
clustering methods accomplish this simplification of the configurational space.
Our approach allowed us to identify the level of resolution that optimally
balances simplicity and informativeness; furthermore, we found that the most
physically accurate clustering procedures are those that induce an ultrametric
structure of the low-resolution space, consistently with the hypothesis that
the protein conformational landscape has a self-similar organisation. The
proposed strategy is general and its applicability extends beyond that of
computational biophysics, making it a valuable tool to extract useful
information from large datasets.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:27:29 GMT""}]","2022-05-18"
"2205.08438","Alexander Brownlee Dr","Alexander Brownlee, Martin Pelikan, John McCall, and Andrei Petrovski","An Application of a Multivariate Estimation of Distribution Algorithm to
  Cancer Chemotherapy","Tech report, originally published at Missouri EDA Lab, in support of
  extended abstract (poster) with same title presented at GECCO 2008",,,,"cs.AI q-bio.QM","http://creativecommons.org/licenses/by/4.0/","  Chemotherapy treatment for cancer is a complex optimisation problem with a
large number of interacting variables and constraints. A number of different
probabilistic algorithms have been applied to it with varying success. In this
paper we expand on this by applying two estimation of distribution algorithms
to the problem. One is UMDA, which uses a univariate probabilistic model
similar to previously applied EDAs. The other is hBOA, the first EDA using a
multivariate probabilistic model to be applied to the chemotherapy problem.
While instinct would lead us to predict that the more sophisticated algorithm
would yield better performance on a complex problem like this, we show that it
is outperformed by the algorithms using the simpler univariate model. We
hypothesise that this is caused by the more sophisticated algorithm being
impeded by the large number of interactions in the problem which are
unnecessary for its solution.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:28:46 GMT""}]","2022-05-18"
"2205.08439","Irina Gaynanova","Renat Sergazinov, Andrew Leroux, Erjia Cui, Ciprian Crainiceanu, R.
  Nisha Aurora, Naresh M. Punjabi, Irina Gaynanova","A case study of glucose levels during sleep using fast function on
  scalar regression inference",,,,,"stat.AP stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Continuous glucose monitors (CGMs) are increasingly used to measure blood
glucose levels and provide information about the treatment and management of
diabetes. Our motivating study contains CGM data during sleep for 174 study
participants with type II diabetes mellitus measured at a 5-minute frequency
for an average of 10 nights. We aim to quantify the effects of diabetes
medications and sleep apnea severity on glucose levels. Statistically, this is
an inference question about the association between scalar covariates and
functional responses. However, many characteristics of the data make analyses
difficult, including (1) non-stationary within-day patterns; (2) substantial
between-day heterogeneity, non-Gaussianity, and outliers; 3) large
dimensionality due to the number of study participants, sleep periods, and time
points. We evaluate and compare two methods: fast univariate inference (FUI)
and functional additive mixed models (FAMM). We introduce a new approach for
calculating p-values for testing a global null effect of covariates using FUI,
and provide practical guidelines for speeding up FAMM computations, making it
feasible for our data. While FUI and FAMM are philosophically different, they
lead to similar point estimators in our study. In contrast to FAMM, FUI is
fast, accounts for within-day correlations, and enables the construction of
joint confidence intervals. Our analyses reveal that: (1) biguanide medication
and sleep apnea severity significantly affect glucose trajectories during
sleep, and (2) the estimated effects are time-invariant.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:31:20 GMT""}]","2022-05-18"
"2205.08440","Shashank Tripathi","Simon Tschirner, Shashank Shekher Tripathi, Mathias Roeper, Markus M.
  Becker and Volker Skwarek","Moving Smart Contracts -- A Privacy Preserving Method for Off-Chain Data
  Trust","10 pages, 6 figures",,,,"cs.CR cs.DC cs.MA cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Blockchains provide environments where parties can interact transparently and
securely peer-to-peer without needing a trusted third party. Parties can trust
the integrity and correctness of transactions and the verifiable execution of
binary code on the blockchain (smart contracts) inside the system. Including
information from outside of the blockchain remains challenging. A challenge is
data privacy. In a public system, shared data becomes public and, coming from a
single source, often lacks credibility. A private system gives the parties
control over their data and sources but trades in positive aspects as
transparency. Often, not the data itself is the most critical information but
the result of a computation performed on it.
  An example is research data certification. To keep data private but still
prove data provenance, researchers can store a hash value of that data on the
blockchain. This hash value is either calculated locally on private data
without the chance for validation or is calculated on the blockchain, meaning
that data must be published and stored on the blockchain -- a problem of the
overall data amount stored on and distributed with the ledger. A system we
called moving smart contracts bypasses this problem: Data remain local, but
trusted nodes can access them and execute trusted smart contract code stored on
the blockchain. This method avoids the system-wide distribution of research
data and makes it accessible and verifiable with trusted software.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:32:33 GMT""},{""version"":""v2"",""created"":""Wed, 18 May 2022 12:22:09 GMT""}]","2023-03-02"
"2205.08441","Max Argus","Sergio Izquierdo, Max Argus, Thomas Brox","Conditional Visual Servoing for Multi-Step Tasks",,,,,"cs.RO cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Visual Servoing has been effectively used to move a robot into specific
target locations or to track a recorded demonstration. It does not require
manual programming, but it is typically limited to settings where one
demonstration maps to one environment state. We propose a modular approach to
extend visual servoing to scenarios with multiple demonstration sequences. We
call this conditional servoing, as we choose the next demonstration conditioned
on the observation of the robot. This method presents an appealing strategy to
tackle multi-step problems, as individual demonstrations can be combined
flexibly into a control policy. We propose different selection functions and
compare them on a shape-sorting task in simulation. With the reprojection error
yielding the best overall results, we implement this selection function on a
real robot and show the efficacy of the proposed conditional servoing. For
videos of our experiments, please check out our project page:
https://lmb.informatik.uni-freiburg.de/projects/conditional_servoing/
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:34:54 GMT""}]","2022-05-18"
"2205.08442","Tim Hoheisel","Tim Hoheisel and Elliot Paquette","Flatness of the nuclear norm sphere, simultaneous polarization, and
  uniqueness in nuclear norm minimization",,,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  In this paper we establish necessary and sufficient conditions for the
existence of line segments (or flats) in the sphere of the nuclear norm via the
notion of simultaneous polarization and a refined expression for the
subdifferential of the nuclear norm. This is then leveraged to provide
(point-based) necessary and sufficient conditions for uniqueness of solutions
for minimizing the nuclear norm over an affine manifold. We further establish
an alternative set of sufficient conditions for uniqueness, based on the
interplay of the subdifferential of the nuclear norm and the range of the
problem-defining linear operator. Finally, using convex duality, we show how to
transfer the uniqueness results for the original problem to a whole class of
nuclear norm-regularized minimization problems with a strictly convex fidelity
term.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:36:49 GMT""}]","2022-05-18"
"2205.08443","Dario Pasquini","Dario Pasquini, Mathilde Raynal and Carmela Troncoso","On the (In)security of Peer-to-Peer Decentralized Machine Learning","IEEE S&P'23 (Previous title: ""On the Privacy of Decentralized Machine
  Learning"")",,,,"cs.CR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we carry out the first, in-depth, privacy analysis of
Decentralized Learning -- a collaborative machine learning framework aimed at
addressing the main limitations of federated learning. We introduce a suite of
novel attacks for both passive and active decentralized adversaries. We
demonstrate that, contrary to what is claimed by decentralized learning
proposers, decentralized learning does not offer any security advantage over
federated learning. Rather, it increases the attack surface enabling any user
in the system to perform privacy attacks such as gradient inversion, and even
gain full control over honest users' local model. We also show that, given the
state of the art in protections, privacy-preserving configurations of
decentralized learning require fully connected networks, losing any practical
advantage over the federated setup and therefore completely defeating the
objective of the decentralized approach.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:36:50 GMT""},{""version"":""v2"",""created"":""Thu, 27 Apr 2023 16:50:14 GMT""}]","2023-04-28"
"2205.08444","Wentao Jin Prof.","Chuandi Zhang, Qianhui Xu, Xu-Tao Zeng, Chao Lyu, Zhengwang Lin,
  Jiazheng Hao, Sihao Deng, Lunhua He, Yinguo Xiao, Yu Ye, Ziyu Chen, Xian-Lei
  Sheng, and Wentao Jin","Doping-induced structural transformation in the spin-1/2
  triangular-lattice antiferromagnet
  Na$_{2}$Ba$_{1-x}$Sr$_{x}$Co(PO$_{4}$)$_{2}$","26 pages, 7 figures","Journal of Alloys and Compounds 905, 164147 (2022)","10.1016/j.jallcom.2022.164147",,"cond-mat.str-el cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The effects of Sr doping on the structural properties of
Na$_{2}$BaCo(PO$_{4}$)$_{2}$, a spin-1/2 triangular-lattice antiferromagnet as
a quantum spin liquid candidate, are investigated by complementary x-ray and
neutron powder diffraction measurements. It is found that in
Na$_{2}$Ba$_{1-x}$Sr$_{x}$Co(PO$_{4}$)$_{2}$ (NBSCPO), the trigonal phase
(space group $\mathit{P}$$\bar{3}$$\mathit{m}$1) with a perfect triangular
lattice of Co$^{2+}$ ions is structurally stable when the doping level of Sr is
below 30% ($\mathit{x}$ $\le$ 0.3), while a pure monoclinic phase (space group
$\mathit{P}$2$_{1}$/$\mathit{a}$) with slight rotations of CoO$_{6}$ octahedra
and displacements of Ba$^{2+}$/Sr$^{2+}$ ions will be established when the Sr
doping level is above 60% ($\mathit{x}$ $\ge$ 0.6). Such a doping-induced
structural transformation in NBSCPO is supported by first-principles
calculations and Raman spectroscopy. Na$_{2}$SrCo(PO$_{4}$)$_{2}$, a novel
spin-1/2 triangular-lattice antiferromagnet with glaserite-type structure,
although monoclinically distorted, exhibits no long-range magnetic order down
to 2 K and a similar negative Curie-Weiss temperature as
Na$_{2}$BaCo(PO$_{4}$)$_{2}$ with a perfect triangular lattice, suggesting the
robustness of magnetic exchange interaction against the Ba/Sr substitutions.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:37:01 GMT""}]","2022-05-18"
"2205.08445","Shobhit Gupta","Olivia Jacome, Shobhit Gupta, Stephanie Stockar, Marcello Canova","Data-driven Driver Model for Speed Advisory Systems in Partially
  Automated Vehicles","6 pages, 9 figures",,,,"cs.RO cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Vehicle control algorithms exploiting connectivity and automation, such as
Connected and Automated Vehicles (CAVs) or Advanced Driver Assistance Systems
(ADAS), have the opportunity to improve energy savings. However, lower levels
of automation involve a human-machine interaction stage, where the presence of
a human driver affects the performance of the control algorithm in closed loop.
This occurs for instance in the case of Eco-Driving control algorithms
implemented as a velocity advisory system, where the driver is displayed an
optimal speed trajectory to follow to reduce energy consumption. Achieving the
control objectives relies on the human driver perfectly following the
recommended speed. If the driver is unable to follow the recommended speed, a
decline in energy savings and poor vehicle performance may occur. This warrants
the creation of methods to model and forecast the response of a human driver
when operating in the loop with a speed advisory system.
  This work focuses on developing a sequence to sequence long-short term memory
(LSTM)-based driver behavior model that models the interaction of the human
driver to a suggested desired vehicle speed trajectory in real-world
conditions. A driving simulator is used for data collection and training the
driver model, which is then compared against the driving data and a
deterministic model. Results show close proximity of the LSTM-based model with
the driving data, demonstrating that the model can be adopted as a tool to
design human-centered speed advisory systems.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:37:56 GMT""}]","2022-05-18"
"2205.08446","Eduard Gorbunov","Eduard Gorbunov, Adrien Taylor, Gauthier Gidel","Last-Iterate Convergence of Optimistic Gradient Method for Monotone
  Variational Inequalities","NeurIPS 2022. 21 pages, 2 figures. Changes in v2: few typos were
  fixed, more clarifications were added. Code:
  https://github.com/eduardgorbunov/potentials_and_last_iter_convergence_for_VIPs",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Past Extragradient (PEG) [Popov, 1980] method, also known as the
Optimistic Gradient method, has known a recent gain in interest in the
optimization community with the emergence of variational inequality
formulations for machine learning. Recently, in the unconstrained case,
Golowich et al. [2020] proved that a $O(1/N)$ last-iterate convergence rate in
terms of the squared norm of the operator can be achieved for Lipschitz and
monotone operators with a Lipschitz Jacobian. In this work, by introducing a
novel analysis through potential functions, we show that (i) this $O(1/N)$
last-iterate convergence can be achieved without any assumption on the Jacobian
of the operator, and (ii) it can be extended to the constrained case, which was
not derived before even under Lipschitzness of the Jacobian. The proof is
significantly different from the one known from Golowich et al. [2020], and its
discovery was computer-aided. Those results close the open question of the last
iterate convergence of PEG for monotone variational inequalities.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:39:57 GMT""},{""version"":""v2"",""created"":""Mon, 31 Oct 2022 12:41:55 GMT""}]","2022-11-01"
"2205.08447","Satoya Imai","Satoya Imai, Otfried G\""uhne, and Stefan Nimmrichter","Work fluctuations and entanglement in quantum batteries","16 pages, 3 figures",,"10.1103/PhysRevA.107.022215","Phys. Rev. A 107, 022215 (2023)","quant-ph cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider quantum batteries given by composite interacting quantum systems
in terms of the thermodynamic work cost of local random unitary processes. We
characterize quantum correlations by monitoring the average energy change and
its fluctuations in the high-dimensional bipartite systems. We derive a
hierarchy of bounds on high-dimensional entanglement (the so-called Schmidt
number) from the work fluctuations and thereby show that larger work
fluctuations can verify the presence of stronger entanglement in the system.
Finally, we develop two-point measurement protocols with noisy detectors that
can estimate work fluctuations, showing that the dimensionality of entanglement
can be probed in this manner.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:42:21 GMT""},{""version"":""v2"",""created"":""Thu, 16 Feb 2023 10:42:50 GMT""}]","2023-02-17"
"2205.08448","Qian Hu","Qian Hu and John Veitch","Assessing the model waveform accuracy of gravitational waves","17 pages, 6 figures. Accepted by PRD","Phys. Rev. D 106, 044042 (2022)","10.1103/PhysRevD.106.044042","LIGO-P2200107","gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the improvement in sensitivity of gravitational wave (GW) detectors and
the increasing diversity of GW sources, there is a strong need for accurate GW
waveform models for data analysis. While the current model accuracy assessments
require waveforms generated by numerical relativity (NR) simulations as the
""true waveforms"", in this paper we propose an assessment approach that does not
require NR simulations, which enables us to assess model accuracy everywhere in
the parameter space. By measuring the difference between two waveform models,
we derive a necessary condition for a pair of waveform models to both be
accurate, for a particular set of parameters. We then apply this method to the
parameter estimation samples of the Gravitational-Wave Transient Catalogs
GWTC-3 and GWTC-2.1, and find that the waveform accuracy for high
signal-to-noise ratio events in some cases fails our assessment criterion.
Based on analysis of real events' posterior samples, we discuss the correlation
between our quantified accuracy assessments and systematic errors in parameter
estimation. We find waveform models that perform worse in our assessment are
more likely to give inconsistent estimations. We also investigate waveform
accuracy in different parameter regions, and find the accuracy degrades as the
spin effects go up, the mass ratio deviates from one, or the orbital plane is
near-aligned to the line of sight. Furthermore, we make predictions of waveform
accuracy requirements for future detectors and find the accuracy of current
waveform models should be improved by at least 3 orders of magnitude, which is
consistent with previous works.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:49:54 GMT""},{""version"":""v2"",""created"":""Mon, 1 Aug 2022 16:59:19 GMT""},{""version"":""v3"",""created"":""Wed, 17 Aug 2022 09:25:40 GMT""}]","2022-08-22"
"2205.08449","Sophie Tourret","Fajar Haifani, Patrick Koopmann, Sophie Tourret and Christoph
  Weidenbach","Connection-minimal Abduction in EL via Translation to FOL -- Technical
  Report","This paper is the technical report version, including appendices, of
  an IJCAR 2022 paper (to appear)",,,,"cs.AI cs.LO","http://creativecommons.org/licenses/by-sa/4.0/","  Abduction in description logics finds extensions of a knowledge base to make
it entail an observation. As such, it can be used to explain why the
observation does not follow, to repair incomplete knowledge bases, and to
provide possible explanations for unexpected observations. We consider TBox
abduction in the lightweight description logic EL, where the observation is a
concept inclusion and the background knowledge is a TBox, i.e., a set of
concept inclusions. To avoid useless answers, such problems usually come with
further restrictions on the solution space and/or minimality criteria that help
sort the chaff from the grain. We argue that existing minimality notions are
insufficient, and introduce connection minimality. This criterion follows
Occam's razor by rejecting hypotheses that use concept inclusions unrelated to
the problem at hand. We show how to compute a special class of
connection-minimal hypotheses in a sound and complete way. Our technique is
based on a translation to first-order logic, and constructs hypotheses based on
prime implicates. We evaluate a prototype implementation of our approach on
ontologies from the medical domain.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:50:27 GMT""},{""version"":""v2"",""created"":""Fri, 20 May 2022 13:05:26 GMT""}]","2022-05-23"
"2205.08450","Ngoc Hoang Anh Mai","Ngoc Hoang Anh Mai","On the exactness for polynomial optimization strengthened with Fritz
  John conditions","It has been included in arXiv:2205.04254",,,,"math.OC math.AG","http://creativecommons.org/licenses/by/4.0/","  We utilize the same technique as in [arXiv:2205.04254 (2022)] to provide some
representations of polynomials non-negative on a basic semi-algebraic set,
defined by polynomial inequalities, under more general conditions. Based on
each representation, we obtain semidefinite programs which return a sequence of
values that finitely converges to the optimal value of a given polynomial
optimization problem under generic assumption. Consequently, we can compute
exactly the minimal value of any polynomial over a basic convex semi-algebraic
set which is defined by the inequalities of concave polynomials.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:50:58 GMT""},{""version"":""v2"",""created"":""Tue, 11 Oct 2022 21:47:12 GMT""}]","2022-10-13"
"2205.08452","Scott Cheng-Hsin Yang","Scott Cheng-Hsin Yang, Tomas Folke, Patrick Shafto","A Psychological Theory of Explainability","15 pages, 3 figures, ICML 2022",,,,"cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  The goal of explainable Artificial Intelligence (XAI) is to generate
human-interpretable explanations, but there are no computationally precise
theories of how humans interpret AI generated explanations. The lack of theory
means that validation of XAI must be done empirically, on a case-by-case basis,
which prevents systematic theory-building in XAI. We propose a psychological
theory of how humans draw conclusions from saliency maps, the most common form
of XAI explanation, which for the first time allows for precise prediction of
explainee inference conditioned on explanation. Our theory posits that absent
explanation humans expect the AI to make similar decisions to themselves, and
that they interpret an explanation by comparison to the explanations they
themselves would give. Comparison is formalized via Shepard's universal law of
generalization in a similarity space, a classic theory from cognitive science.
A pre-registered user study on AI image classifications with saliency map
explanations demonstrate that our theory quantitatively matches participants'
predictions of the AI.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:52:24 GMT""},{""version"":""v2"",""created"":""Thu, 9 Jun 2022 17:44:34 GMT""}]","2022-06-10"
"2205.08453","Michael Farber","Michael Farber and Amit Kumar Paul","Sequential Parametrized Motion Planning and its Complexity",,,,,"math.AT","http://creativecommons.org/licenses/by/4.0/","  In this paper we develop theory of sequential parametrized motion planning
which generalises the approach of parametrized motion planning, which was
introduced recently in [3]. A sequential parametrized motion planning algorithm
produced a motion of the system which is required to visit a prescribed
sequence of states, in certain order, at specified moments of time. The
sequential parametrized algorithms are universal as the external conditions are
not fixed in advance but rather constitute part of the input of the algorithm.
The second part of this article consists of a detailed analysis of the
sequential parametrized topological complexity of the Fadell - Neuwirth
fibration. In the language of robotics, sections of the Fadell - Neuwitrh
fibration are algorithms for moving multiple robots avoiding collisions with
other robots and with obstacles in Euclidean space. In the last section of the
paper we introduce the new notion of TC-generating function of a fibration,
examine examples and raise some general questions about its analytic
properties.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:53:06 GMT""},{""version"":""v2"",""created"":""Tue, 31 May 2022 06:35:39 GMT""},{""version"":""v3"",""created"":""Sat, 17 Sep 2022 12:07:19 GMT""}]","2022-09-20"
"2205.08454","Max Spahn","Max Spahn, Martijn Wisse, Javier Alonso-Mora","Dynamic Optimization Fabrics for Motion Generation","Paper submitted to IEEE T-RO on 05/12/2022 Paper accepted to IEEE
  T-RO on 08/03/2023",,,,"cs.RO","http://creativecommons.org/licenses/by-sa/4.0/","  Optimization fabrics are a geometric approach to real-time local motion
generation, where motions are designed by the composition of several
differential equations that exhibit a desired motion behavior. We generalize
this framework to dynamic scenarios and non-holonomic robots and prove that
fundamental properties can be conserved. We show that convergence to desired
trajectories and avoidance of moving obstacles can be guaranteed using simple
construction rules of the components. Additionally, we present the first
quantitative comparisons between optimization fabrics and model predictive
control and show that optimization fabrics can generate similar trajectories
with better scalability, and thus, much higher replanning frequency (up to 500
Hz with a 7 degrees of freedom robotic arm). Finally, we present empirical
results on several robots, including a non-holonomic mobile manipulator with 10
degrees of freedom and avoidance of a moving human, supporting the theoretical
findings.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:55:41 GMT""},{""version"":""v2"",""created"":""Mon, 30 May 2022 09:49:42 GMT""},{""version"":""v3"",""created"":""Wed, 8 Mar 2023 15:36:49 GMT""}]","2023-03-09"
"2205.08455","William Ravenscroft","William Ravenscroft and Stefan Goetze and Thomas Hain","Utterance Weighted Multi-Dilation Temporal Convolutional Networks for
  Monaural Speech Dereverberation","Accepted at IWAENC 2022",,,,"cs.SD cs.LG eess.AS","http://creativecommons.org/licenses/by/4.0/","  Speech dereverberation is an important stage in many speech technology
applications. Recent work in this area has been dominated by deep neural
network models. Temporal convolutional networks (TCNs) are deep learning models
that have been proposed for sequence modelling in the task of dereverberating
speech. In this work a weighted multi-dilation depthwise-separable convolution
is proposed to replace standard depthwise-separable convolutions in TCN models.
This proposed convolution enables the TCN to dynamically focus on more or less
local information in its receptive field at each convolutional block in the
network. It is shown that this weighted multi-dilation temporal convolutional
network (WD-TCN) consistently outperforms the TCN across various model
configurations and using the WD-TCN model is a more parameter efficient method
to improve the performance of the model than increasing the number of
convolutional blocks. The best performance improvement over the baseline TCN is
0.55 dB scale-invariant signal-to-distortion ratio (SISDR) and the best
performing WD-TCN model attains 12.26 dB SISDR on the WHAMR dataset.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:56:31 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jul 2022 11:40:52 GMT""},{""version"":""v3"",""created"":""Fri, 22 Jul 2022 21:11:26 GMT""}]","2022-07-26"
"2205.08456","Kai-Uwe Schmidt","Alena Ernst and Kai-Uwe Schmidt","Intersection theorems for finite general linear groups","34 pages, minor changes",,,,"math.CO math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A subset $Y$ of the general linear group $\operatorname{GL}(n,q)$ is called
$t$-intersecting if $\operatorname{rk}(x-y)\le n-t$ for all $x,y\in Y$, or
equivalently $x$ and $y$ agree pointwise on a $t$-dimensional subspace of
$\mathbb{F}_q^n$ for all $x,y\in Y$. We show that, if $n$ is sufficiently large
compared to $t$, the size of every such $t$-intersecting set is at most that of
the stabiliser of a basis of a $t$-dimensional subspace of $\mathbb{F}_q^n$. In
case of equality, the characteristic vector of $Y$ is a linear combination of
the characteristic vectors of the cosets of these stabilisers. We also give
similar results for subsets of $\operatorname{GL}(n,q)$ that intersect not
necessarily pointwise in $t$-dimensional subspaces of $\mathbb{F}_q^n$ and for
cross-intersecting subsets of $\operatorname{GL}(n,q)$. These results may be
viewed as variants of the classical Erd\H{o}s-Ko-Rado Theorem in extremal set
theory and are $q$-analogs of corresponding results known for the symmetric
group. Our methods are based on eigenvalue techniques to estimate the size of
the largest independent sets in graphs and crucially involve the representation
theory of $\operatorname{GL}(n,q)$.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:56:54 GMT""},{""version"":""v2"",""created"":""Wed, 31 Aug 2022 14:04:42 GMT""},{""version"":""v3"",""created"":""Thu, 2 Feb 2023 09:23:27 GMT""}]","2023-02-03"
"2205.08457","Matthew McBride","Slawomir Klimek, Matt McBride, and John Wilson Peoples","A Note on Quantum Odometers",,,,,"math.OA","http://creativecommons.org/licenses/by/4.0/","  We discuss various aspects of noncommutative geometry of smooth subalgebras
of Bunce-Deddens-Toeplitz Algebras.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:57:23 GMT""}]","2022-05-18"
"2205.08458","Yizhou Zhao","Yizhou Zhao and Hua Sun","Secure Summation: Capacity Region, Groupwise Key, and Feasibility",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The secure summation problem is considered, where $K$ users, each holds an
input, wish to compute the sum of their inputs at a server securely, i.e.,
without revealing any information beyond the sum even if the server may collude
with any set of up to $T$ users. First, we prove a folklore result for secure
summation - to compute $1$ bit of the sum securely, each user needs to send at
least $1$ bit to the server, each user needs to hold a key of at least $1$ bit,
and all users need to hold collectively some key variables of at least $K-1$
bits. Next, we focus on the symmetric groupwise key setting, where every group
of $G$ users share an independent key. We show that for symmetric groupwise
keys with group size $G$, when $G > K-T$, the secure summation problem is not
feasible; when $G \leq K-T$, to compute $1$ bit of the sum securely, each user
needs to send at least $1$ bit to the server and the size of each groupwise key
is at least $(K-T-1)/\binom{K-T}{G}$ bits. Finally, we relax the symmetry
assumption on the groupwise keys and the colluding user sets; we allow any
arbitrary group of users to share an independent key and any arbitrary group of
users to collude with the server. For such a general groupwise key and
colluding user setting, we show that secure summation is feasible if and only
if the hypergraph, where each node is a user and each edge is a group of users
sharing the same key, is connected after removing the nodes corresponding to
any colluding set of users and their incident edges.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:58:20 GMT""}]","2022-05-18"
"2205.08538","Ravo Tokiniaina Ranaivoson","Ravo Tokiniaina Ranaivoson, Voriraza S\'eraphin Hejesoa, Raoelina
  Andriambololona, Nirina Gilbert Rasolofoson, Hanitriarivo Rakotoson,
  Jacqueline Rabesahala Raoelina Andriambololona, Lala Rarivomanantsoa, Naivo
  Rabesiranana","Highlighting relations between Wave-particle duality, Uncertainty
  principle, Phase space and Microstates","22 pages",,,,"quant-ph physics.hist-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The wave-particle duality is often considered as the modern and satisfactory
answer that man found in searching to know the nature of light after more than
2000 years of questioning. It is also the answer given by quantum physics
concerning the nature of matter particles and any other radiations. The aim of
this work is to perform an analysis of this concept of wave-particle duality
from a historical, philosophical and scientific point of view and to study and
discuss about the relations which exist between it, the uncertainty principle
and the concepts of phase space and microstates considered in statistical
mechanics. These relations will be described and analyzed both from a
physico-mathematical and historico-philosophical perspective. It is, in
particular, highlighted that while the concepts of phase space and microstates
were already introduced in classical physics long before the discovery of the
wave-particle duality, a correct understanding of them cannot be achieved
without quantum physics. But conversely, it is also shown that the relations of
the wave-particle duality with uncertainty principle, phase space and
microstates that are highlighted can help in a deeper understanding and more
adequate description of this duality.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 04:20:16 GMT""},{""version"":""v2"",""created"":""Thu, 22 Sep 2022 13:19:48 GMT""},{""version"":""v3"",""created"":""Tue, 23 May 2023 13:29:18 GMT""}]","2023-05-24"
"2205.08539","Gary Gordon","Gary Gordon","Randomness in Relational Quantum Mechanics","4 pages, no figures or equations, Academia Letters, 2021",,"10.20935/AL2764",,"physics.hist-ph quant-ph","http://creativecommons.org/licenses/by/4.0/","  The relational interpretation of quantum mechanics (RQM), introduced in its
present form by Carlo Rovelli in 1996, involves a number of significant
departures from other QM interpretations widely discussed in the literature. We
begin here by summarizing these unique RQM features, with a focus on those that
suggest altered insights into the nature of the randomness exhibited in QM
phenomena. One of these RQM features is the assumption that all objects in the
universe are quantum objects, regardless of their material complexity. And, the
interaction of any two objects can result in new relational quantum states of
each of the objects with the other as reference. But such new states do not
replace relational states corresponding to previous interactions with other
reference objects. In particular, such earlier relational states that include a
variable considered to be random do not collapse to define a determined value
of the variable, but instead simply take on that specific value in the state
relative to the new reference. The concept of randomness associated with
quantum state variables in RQM thus differs from that in other QM
interpretations. Rather than take the usual pedantic approach of elaborate
side-by-side comparisons between the RQM and other common QM interpretations,
we illustrate these differences by describing in some detail the well-known
""dual-slit"" experiment in terms of RQM concepts, pointing out the important
advantages over other interpretations along the way. Of course, we suggest no
change in dual-slit experiment results, but believe that the interpretative
modifications are helpful and profound.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:27:27 GMT""}]","2022-05-19"
"2205.09030","Kshiteej Deshmukh","Kshiteej J. Deshmukh and Graeme W. Milton","An Energy Conserving Mechanism for Temporal Metasurfaces","6 pages, 4 figures",,"10.1063/5.0097591",,"physics.class-ph cond-mat.mtrl-sci physics.optics","http://creativecommons.org/licenses/by/4.0/","  Changing the microstructure properties of a space-time metamaterial while a
wave is propagating through it, in general requires addition or removal of
energy, which can be of exponential form depending on the type of modulation.
This limits the realization and application of space-time metamaterials. We
resolve this issue by introducing a novel mechanism of conserving energy at
temporal metasurfaces in a non-linear setting. The idea is first demonstrated
by considering a wave-packet propagating in a discrete medium of 1-d chain of
springs and masses, where using our energy conserving mechanism we show that
the spring stiffness can be incremented at several time interfaces and the
energy will still be conserved. We then consider an interesting application of
time-reversed imaging in 1-d and 2-d spring-mass systems with a wave packet
traveling in the homogenized regime. Our numerical simulations show that, in
1-d, when the wave packet hits the time-interface two sets of waves are
generated, one traveling forward in time and the other traveling backward. The
time-reversed waves re-converge at the location of the source and we observe
its regeneration. In 2-d, we use more complicated initial shapes and, even
then, we observe regeneration of the original image or source. Thus, we achieve
time-reversed imaging with conservation of energy in a non-linear system. The
energy conserving mechanism can be easily extended to continuum media.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:03:24 GMT""},{""version"":""v2"",""created"":""Mon, 20 Jun 2022 03:31:15 GMT""}]","2022-08-10"
"2205.09031","Marko Kosti\'c","B. Chaouchi, M. Kostic, D. Velinov","Metrical approximations of functions","arXiv admin note: text overlap with arXiv:2202.10521",,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  In this paper, we analyze metrical approximations of functions $F :\Lambda
times X \rightarrow Y$ by trigonometric polynomials and $\rho$-periodic type
functions, where $\emptyset \neq \Lambda \subseteq {\mathbb R}^{n},$ $X$ and $Y
$are complex Banach spaces, and $\rho$ is a general binary relation on $Y .$
Besides the classical concept, we analyze Stepanov,Weyl, Besicovitch and Doss
generalized approaches to metrical approximations. We clarify many structural
properties of introduced spaces of functions and provide several applications
of our theoretical results to the abstract Volterra integro-differential
equations and the partial differential equations.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 00:08:09 GMT""}]","2022-05-19"
"2205.09034","Gonzalo L\'opez","Gonzalo Maximiliano Lopez, Juan Pablo Aparicio","Modelling macroparasitic diseases dynamics",,,,,"q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we present a general framework for the modeling of the
transmission dynamics of macroparasites which do not reproduce within the host
like Ascaris lumbricoides, Trichuris trichiura, Necator americanus y
Ancylostoma duodenale. The basic models are derived from general probabilistic
models for the parasite density-dependent mating probability. Here we
considered the particular, and common case, of a negative binomial distribution
for the number of parasites in hosts. We find the basic reproductive number and
we show that the system exhibit a saddle-node bifurcation at some value of the
basic reproduction number. We also found the equilibria and basic reproduction
number of a model for the more general case of heteregeneous host populations.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 05:18:29 GMT""}]","2022-05-19"
"2205.09044","Alain Thomas","Alain Thomas","Normalized image of a vector by an infinite product of nonnegative
  matrices","27 pages",,,,"math.FA","http://creativecommons.org/publicdomain/zero/1.0/","  Let $\nu$ be a measure on the set $\{0,1,\dots,b-1\}^\mathbb N$, linearly
representable by means of a finite set $\mathcal M$ of square nonnegative
matrices. To prove that $\nu$ has the weak Gibbs property, one generally uses
the uniform convergence on $\mathcal M^\mathbb N$ of the sequence of vectors
$n\mapsto\frac{A_1\cdots A_nc}{\Vert A_1\cdots A_nc\Vert}$, where $c$ is a
positive column-vector. We give a sufficient condition for this convergence to
hold, that we apply to some measures defined by Bernoulli convolution.
Secondarily we prove that the sequence of matrices $n\mapsto\frac{A_1\cdots
A_n}{\Vert A_1\cdots A_n\Vert}$ in general diverges. Both examples we give are
related with the fundamental curves studied for intance by Micchelli,
Prautzsch, Daubechies, Lagarias, Berger, Wang.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:26:00 GMT""},{""version"":""v2"",""created"":""Thu, 10 Nov 2022 17:38:37 GMT""},{""version"":""v3"",""created"":""Sun, 11 Dec 2022 17:19:12 GMT""}]","2022-12-13"
"2205.09045","Renjie Li","Xinyu Chen, Renjie Li, Yueyao Yu, Yuanwen Shen, Wenye Li, Zhaoyu
  Zhang, Yin Zhang","POViT: Vision Transformer for Multi-objective Design and
  Characterization of Nanophotonic Devices","The loss function should have been RMSE, not MSE, in the model
  evaluation section. As a result, the training results are all wrong. We need
  to withdraw this paper until we have come up with a solution to this issue",,,,"cs.LG physics.app-ph physics.optics","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We solve a fundamental challenge in semiconductor IC design: the fast and
accurate characterization of nanoscale photonic devices. Much like the fusion
between AI and EDA, many efforts have been made to apply DNNs such as
convolutional neural networks (CNN) to prototype and characterize next-gen
optoelectronic devices commonly found in photonic integrated circuits (PIC) and
LiDAR. These prior works generally strive to predict the quality factor (Q) and
modal volume (V) of for instance, photonic crystals, with ultra-high accuracy
and speed. However, state-of-the-art models are still far from being directly
applicable in the real-world: e.g. the correlation coefficient of V
($V_{coeff}$ ) is only about 80%, which is much lower than what it takes to
generate reliable and reproducible nanophotonic designs. Recently,
attention-based transformer models have attracted extensive interests and been
widely used in CV and NLP. In this work, we propose the first-ever Transformer
model (POViT) to efficiently design and simulate semiconductor photonic devices
with multiple objectives. Unlike the standard Vision Transformer (ViT), we
supplied photonic crystals as data input and changed the activation layer from
GELU to an absolute-value function (ABS). Our experiments show that POViT
exceeds results reported by previous models significantly. The correlation
coefficient $V_{coeff}$ increases by over 12% (i.e., to 92.0%) and the
prediction errors of Q is reduced by an order of magnitude, among several other
key metric improvements. Our work has the potential to drive the expansion of
EDA to fully automated photonic design. The complete dataset and code will be
released to aid researchers endeavoring in the interdisciplinary field of
physics and computer science.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 01:58:34 GMT""},{""version"":""v2"",""created"":""Tue, 29 Nov 2022 00:42:12 GMT""},{""version"":""v3"",""created"":""Wed, 30 Nov 2022 01:10:56 GMT""}]","2022-12-01"
"2205.09060","Chiara Balestra","Chiara Balestra, Florian Huber, Andreas Mayr, Emmanuel M\""uller","Unsupervised Features Ranking via Coalitional Game Theory for
  Categorical Data","To be published in DaWaK 2022 (accepted). Code available at
  https://github.com/chiarabales/unsupervised_sv @inproceedings{balestraUSV,
  author = {Chiara Balestra and Florian Huber and Andreas Mayr and Emmanuel
  M\""uller}, title = {Unsupervised Features Ranking via Coalitional Game Theory
  for Categorical Data}, booktitle = {DaWaK 2022}, year = {2022}}",,,,"cs.LG cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Not all real-world data are labeled, and when labels are not available, it is
often costly to obtain them. Moreover, as many algorithms suffer from the curse
of dimensionality, reducing the features in the data to a smaller set is often
of great utility. Unsupervised feature selection aims to reduce the number of
features, often using feature importance scores to quantify the relevancy of
single features to the task at hand. These scores can be based only on the
distribution of variables and the quantification of their interactions. The
previous literature, mainly investigating anomaly detection and clusters, fails
to address the redundancy-elimination issue. We propose an evaluation of
correlations among features to compute feature importance scores representing
the contribution of single features in explaining the dataset's structure.
  Based on Coalitional Game Theory, our feature importance scores include a
notion of redundancy awareness making them a tool to achieve redundancy-free
feature selection. We show that the deriving features' selection outperforms
competing methods in lowering the redundancy rate while maximizing the
information contained in the data. We also introduce an approximated version of
the algorithm to reduce the complexity of Shapley values' computations.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:17:36 GMT""}]","2022-05-19"
"2205.09061","Anastasios Gounaris","Konstantinos Varvoutas, Anastasios Gounaris, Georgia Kougka, Hajo A.
  Reijers","Rank-based Heuristics for Optimizing the Execution of Product Data
  Models",,,,,"cs.DB","http://creativecommons.org/licenses/by/4.0/","  The Product Data Model (PDM) is an example of a data-centric approach to
modelling information-intensive business processes, which offers exibility and
facilitates process optimization. Because the approach is declarative in
nature, there may be multiple, alternative execution plans that can produce the
desired end product. To generate such plans, several heuristics have been
proposed in the literature. The contributions of this work are twofold: (i) we
propose new heuristics that capitalize on established techniques for optimizing
data-intensive work ows in terms of execution time and cost and transfer them
to business processes; and (ii) we extensively evaluate the existing solutions.
Our results shed light on the merits of each heuristic and show that our new
heuristics can yield significant benefits.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:19:09 GMT""}]","2022-05-19"
"2205.09064","Jani Jokela","Jani Jokela","General mixed lattices","13 pages. A corrected version with minor changes and an added example
  2.11",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A mixed lattice is a lattice-type structure consisting of a set with two
partial orderings, and generalizing the notion of a lattice. Mixed lattice
theory has previously been studied in various algebraic structures, such as
groups and semigroups, while the more general notion of a mixed lattice remains
unexplored. In this paper, we study the fundamental properties of mixed
lattices and their relationships, and establish the equivalence of the
one-sided associative, distributive and modular laws in mixed lattices. We also
give an alternative definition of mixed lattices and mixed lattice groups as
non-commutative and non-associative algebras satisfying a certain set of
postulates. The algebraic and the order-theoretic definitions are then shown to
be equivalent.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:47:12 GMT""},{""version"":""v2"",""created"":""Fri, 10 Jun 2022 14:02:41 GMT""},{""version"":""v3"",""created"":""Wed, 6 Jul 2022 09:12:18 GMT""}]","2022-07-07"
"2205.09065","Tianshu Hou","Tianshu Hou and Peining Zhen and Ngai Wong and Quan Chen and Guoyong
  Shi and Shuqi Wang and Hai-Bao Chen","Multilayer Perceptron Based Stress Evolution Analysis under DC Current
  Stressing for Multi-segment Wires","The paper will be published in IEEE Transactions on COMPUTER-AIDED
  DESIGN of Integrated Circuits and Systems",,,,"cs.LG eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Electromigration (EM) is one of the major concerns in the reliability
analysis of very large scale integration (VLSI) systems due to the continuous
technology scaling. Accurately predicting the time-to-failure of integrated
circuits (IC) becomes increasingly important for modern IC design. However,
traditional methods are often not sufficiently accurate, leading to undesirable
over-design especially in advanced technology nodes. In this paper, we propose
an approach using multilayer perceptrons (MLP) to compute stress evolution in
the interconnect trees during the void nucleation phase. The availability of a
customized trial function for neural network training holds the promise of
finding dynamic mesh-free stress evolution on complex interconnect trees under
time-varying temperatures. Specifically, we formulate a new objective function
considering the EM-induced coupled partial differential equations (PDEs),
boundary conditions (BCs), and initial conditions to enforce the physics-based
constraints in the spatial-temporal domain. The proposed model avoids meshing
and reduces temporal iterations compared with conventional numerical approaches
like FEM. Numerical results confirm its advantages on accuracy and
computational performance.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:38:20 GMT""}]","2022-05-19"
"2205.09075","Leslie Tiong","Leslie Ching Ow Tiong, Gunjick Lee, Seok Su Sohn, Donghun Kim","Predicting failure characteristics of structural materials via deep
  learning based on nondestructive void topology",,,,,"cond-mat.mtrl-sci cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accurate predictions of the failure progression of structural materials is
critical for preventing failure-induced accidents. Despite considerable
mechanics modeling-based efforts, accurate prediction remains a challenging
task in real-world environments due to unexpected damage factors and defect
evolutions. Here, we report a novel method for predicting material failure
characteristics that uniquely combines nondestructive X-ray computed tomography
(X-CT), persistent homology (PH), and deep multimodal learning (DML). The
combined method exploits the microstructural defect state at the time of
material examination as an input, and outputs the failure-related properties.
Our method is demonstrated to be effective using two types of fracture datasets
(tensile and fatigue datasets) with ferritic low alloy steel as a
representative structural material. The method achieves a mean absolute error
(MAE) of 0.09 in predicting the local strain with the tensile dataset and an
MAE of 0.14 in predicting the fracture progress with the fatigue dataset. These
high accuracies are mainly due to PH processing of the X-CT images, which
transforms complex and noisy three-dimensional X-CT images into compact
two-dimensional persistence diagrams that preserve key topological features
such as the internal void size, density, and distribution. The combined PH and
DML processing of 3D X-CT data is our unique approach enabling reliable failure
predictions at the time of material examination based on void topology
progressions, and the method can be extended to various nondestructive failure
tests for practical use.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 05:59:42 GMT""}]","2022-05-19"
"2205.09114","Justyna P. Zwolak","Amilson R. Fritsch, Shangjie Guo, Sophia M. Koh, I. B. Spielman,
  Justyna P. Zwolak","Dark solitons in Bose-Einstein condensates: a dataset for many-body
  physics research","16 pages, 4 figures","Mach. Learn.: Sci. Technol. 3, 047001 (2022)","10.1088/2632-2153/ac9454",,"cond-mat.quant-gas cs.CV cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish a dataset of over $1.6\times10^4$ experimental images of
Bose--Einstein condensates containing solitonic excitations to enable machine
learning (ML) for many-body physics research. About $33~\%$ of this dataset has
manually assigned and carefully curated labels. The remainder is automatically
labeled using SolDet -- an implementation of a physics-informed ML data
analysis framework -- consisting of a convolutional-neural-network-based
classifier and OD as well as a statistically motivated physics-informed
classifier and a quality metric. This technical note constitutes the definitive
reference of the dataset, providing an opportunity for the data science
community to develop more sophisticated analysis tools, to further understand
nonlinear many-body physics, and even advance cold atom experiments.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:53:16 GMT""},{""version"":""v2"",""created"":""Sat, 11 Feb 2023 21:36:56 GMT""}]","2023-02-14"
"2205.09186","Binghai Wen","Zhangrong Qin, Wenbo Chen, Chunyan Qin, Xin Xu, Binghai Wen","Spurious currents suppression by accurate difference schemes in
  multiphase lattice Boltzmann method",,,,,"physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spurious currents, which are often observed near a curved interface in the
multiphase simulations by diffuse interface methods, are unphysical phenomena
and usually damage the computational accuracy and stability. In this paper, the
origination and suppression of spurious currents are investigated by using the
multiphase lattice Boltzmann method driven by chemical potential. Both the
difference error and insufficient isotropy of discrete gradient operator give
rise to the directional deviations of nonideal force and then originate the
spurious currents. Nevertheless, the high-order finite difference produces far
more accurate results than the high-order isotropic difference. We compare
several finite difference schemes which have different formal accuracy and
resolution. When a large proportional coefficient is used, the transition
region is narrow and steep, and the resolution of finite difference indicates
the computational accuracy more exactly than the formal accuracy. On the
contrary, for a small proportional coefficient, the transition region is wide
and gentle, and the formal accuracy of finite difference indicates the
computational accuracy better than the resolution. Furthermore, numerical
simulations show that the spurious currents calculated in the 3D situation are
highly consistent with those in 2D simulations; especially, the two-phase
coexistence densities calculated by the high-order accuracy finite difference
are in excellent agreement with the theoretical predictions of the Maxwell
equal-area construction till the reduced temperature 0.2.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 00:58:48 GMT""}]","2022-05-20"
"2205.09507","Muhammad Awais Aslam","Muhammad Awais Aslam, Tuan Hoang Tran, Antonio Supina, Olivier Siri,
  Vincent Meunier, Kenji Watanabe, Takashi Taniguchi, Marko Kralj, Christian
  Teichert, Evgeniya Sheremet, Raul D. Rodriguez, and Aleksandar Matkovi\'c","Single Crystalline 2D Material Nanoribbon Networks for Nanoelectronics",,,,,"physics.app-ph cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The last decade has seen a flurry of studies related to graphene nanoribbons
owing to their potential applications in the quantum realm. However, little
experimental work has been reported towards nanoribbons of other 2D materials
due to the absence of synthesis routes. Here, we propose a universal approach
to synthesize high-quality networks of nanoribbons from arbitrary 2D materials
while maintaining high crystallinity, sufficient yield, narrow size
distribution, and straight-forward device integrability. The wide applicability
of this technique is demonstrated by fabricating MoS2, WS2, WSe2, and graphene
nanoribbon field effect transistors that inherently do not suffer from
interconnection resistances. By relying on self-assembled and self-aligned
organic nanostructures as masks, we demonstrate the possibility of controlling
the predominant crystallographic direction of the nanoribbon's edges.
Electrical characterization shows record mobilities and very high ON currents
for various TMDCs despite extreme width scaling. Lastly, we explore decoration
of nanoribbon edges with plasmonic particles paving the way towards the
development of nanoribbon-based plasmonic sensing and opto-electronic devices.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:05:00 GMT""}]","2022-05-20"
"2205.10119","Advait Sarkar","Advait Sarkar","Is explainable AI a race against model complexity?","Workshop on Transparency and Explanations in Smart Systems (TExSS
  2022), at the 27th International Conference on Intelligent User Interfaces
  (IUI 2022)",,,,"cs.AI cs.HC cs.LG","http://creativecommons.org/licenses/by/4.0/","  Explaining the behaviour of intelligent systems will get increasingly and
perhaps intractably challenging as models grow in size and complexity. We may
not be able to expect an explanation for every prediction made by a brain-scale
model, nor can we expect explanations to remain objective or apolitical. Our
functionalist understanding of these models is of less advantage than we might
assume. Models precede explanations, and can be useful even when both model and
explanation are incorrect. Explainability may never win the race against
complexity, but this is less problematic than it seems.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:57:25 GMT""}]","2022-05-23"
"2205.10120","Riccardo Taiello","Riccardo Taiello, Melek \""Onen, Francesco Capano, Olivier Humbert and
  Marco Lorenzi","Privacy Preserving Image Registration",,"Medical Image Computing and Computer Assisted Intervention (2022)
  130-140","10.1007/978-3-031-16446-0_13",,"cs.CV cs.AI cs.CR eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Image registration is a key task in medical imaging applications, allowing to
represent medical images in a common spatial reference frame. Current
approaches to image registration are generally based on the assumption that the
content of the images is usually accessible in clear form, from which the
spatial transformation is subsequently estimated. This common assumption may
not be met in practical applications, since the sensitive nature of medical
images may ultimately require their analysis under privacy constraints,
preventing to openly share the image content.In this work, we formulate the
problem of image registration under a privacy preserving regime, where images
are assumed to be confidential and cannot be disclosed in clear. We derive our
privacy preserving image registration framework by extending classical
registration paradigms to account for advanced cryptographic tools, such as
secure multi-party computation and homomorphic encryption, that enable the
execution of operations without leaking the underlying data. To overcome the
problem of performance and scalability of cryptographic tools in high
dimensions, we propose several techniques to optimize the image registration
operations by using gradient approximations, and by revisiting the use of
homomorphic encryption trough packing, to allow the efficient encryption and
multiplication of large matrices. We demonstrate our privacy preserving
framework in linear and non-linear registration problems, evaluating its
accuracy and scalability with respect to standard, non-private counterparts.
Our results show that privacy preserving image registration is feasible and can
be adopted in sensitive medical imaging applications.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:00:58 GMT""},{""version"":""v2"",""created"":""Mon, 4 Jul 2022 12:00:05 GMT""},{""version"":""v3"",""created"":""Wed, 13 Jul 2022 07:14:16 GMT""},{""version"":""v4"",""created"":""Thu, 14 Jul 2022 09:22:50 GMT""},{""version"":""v5"",""created"":""Sun, 18 Sep 2022 05:54:04 GMT""},{""version"":""v6"",""created"":""Thu, 9 Mar 2023 16:39:58 GMT""}]","2023-03-10"
"2205.10127","Anitha K","R. Aruna Devi and K. Anitha","Construction of Rough graph to handle uncertain pattern from an
  Information System","13 pages, 11 figures",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Rough membership function defines the measurement of relationship between
conditional and decision attribute from an Information system. In this paper we
propose a new method to construct rough graph through rough membership function
$\omega_{G}^F(f)$. Rough graph identifies the pattern between the objects with
imprecise and uncertain information. We explore the operations and properties
of rough graph in various stages of its structure.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 08:41:04 GMT""}]","2022-05-23"
"2205.10128","Zhaocheng Zhu","Zhaocheng Zhu, Mikhail Galkin, Zuobai Zhang, Jian Tang","Neural-Symbolic Models for Logical Queries on Knowledge Graphs","ICML 2022",,,,"cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Answering complex first-order logic (FOL) queries on knowledge graphs is a
fundamental task for multi-hop reasoning. Traditional symbolic methods traverse
a complete knowledge graph to extract the answers, which provides good
interpretation for each step. Recent neural methods learn geometric embeddings
for complex queries. These methods can generalize to incomplete knowledge
graphs, but their reasoning process is hard to interpret. In this paper, we
propose Graph Neural Network Query Executor (GNN-QE), a neural-symbolic model
that enjoys the advantages of both worlds. GNN-QE decomposes a complex FOL
query into relation projections and logical operations over fuzzy sets, which
provides interpretability for intermediate variables. To reason about the
missing links, GNN-QE adapts a graph neural network from knowledge graph
completion to execute the relation projections, and models the logical
operations with product fuzzy logic. Experiments on 3 datasets show that GNN-QE
significantly improves over previous state-of-the-art models in answering FOL
queries. Meanwhile, GNN-QE can predict the number of answers without explicit
supervision, and provide visualizations for intermediate variables.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:39:04 GMT""},{""version"":""v2"",""created"":""Tue, 6 Sep 2022 19:35:29 GMT""}]","2022-09-08"
"2205.10129","Shaohui Liu","Shaohui Liu, Chengyang Wu, Hao Zhu","Topology-aware Graph Neural Networks for Learning Feasible and Adaptive
  ac-OPF Solutions",,,,,"eess.SY cs.LG cs.SY eess.SP math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Solving the optimal power flow (OPF) problem is a fundamental task to ensure
the system efficiency and reliability in real-time electricity grid operations.
We develop a new topology-informed graph neural network (GNN) approach for
predicting the optimal solutions of real-time ac-OPF problem. To incorporate
grid topology to the NN model, the proposed GNN-for-OPF framework innovatively
exploits the locality property of locational marginal prices and voltage
magnitude. Furthermore, we develop a physics-aware (ac-)flow feasibility
regularization approach for general OPF learning. The advantages of our
proposed designs include reduced model complexity, improved generalizability
and feasibility guarantees. By providing the analytical understanding on the
graph subspace stability under grid topology contingency, we show the proposed
GNN can quickly adapt to varying grid topology by an efficient re-training
strategy. Numerical tests on various test systems of different sizes have
validated the prediction accuracy, improved flow feasibility, and topology
adaptivity capability of our proposed GNN-based learning framework.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 23:36:37 GMT""},{""version"":""v2"",""created"":""Tue, 1 Nov 2022 19:51:32 GMT""}]","2022-11-03"
"2205.10130","Adar Kahana","Adar Kahana, Qian Zhang, Leonard Gleyzer, George Em Karniadakis","Spiking Neural Operators for Scientific Machine Learning","16 pages, 6 figures and 4 tables",,,,"cs.NE cs.LG","http://creativecommons.org/licenses/by/4.0/","  The main computational task of Scientific Machine Learning (SciML) is
function regression, required both for inputs as well as outputs of a
simulation. Physics-Informed Neural Networks (PINNs) and neural operators (such
as DeepONet) have been very effective in solving Partial Differential Equations
(PDEs), but they tax computational resources heavily and cannot be readily
adopted for edge computing. Here, we address this issue by considering Spiking
Neural Networks (SNNs), which have shown promise in reducing energy consumption
by two orders of magnitude or more. We present a SNN-based method to perform
regression, which has been a challenge due to the inherent difficulty in
representing a function's input domain and continuous output values as spikes.
We first propose a new method for encoding continuous values into spikes based
on a triangular matrix in space and time, and demonstrate its better
performance compared to the existing methods. Next, we demonstrate that using a
simple SNN architecture consisting of Leaky Integrate and Fire (LIF) activation
and two dense layers, we can achieve relatively accurate function regression
results. Moreover, we can replace the LIF with a trained Multi-Layer Perceptron
(MLP) network and obtain comparable results but three times faster. Then, we
introduce the DeepONet, consisting of a branch (typically a Fully-connected
Neural Network, FNN) for inputs and a trunk (also a FNN) for outputs. We can
build a spiking DeepONet by either replacing the branch or the trunk by a SNN.
We demonstrate this new approach for classification using the SNN in the
branch, achieving results comparable to the literature. Finally, we design a
spiking DeepONet for regression by replacing its trunk with a SNN, and achieve
good accuracy for approximating functions as well as inferring solutions of
differential equations.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 15:22:22 GMT""},{""version"":""v2"",""created"":""Wed, 12 Oct 2022 17:50:40 GMT""}]","2022-10-13"
"2205.10234","Pablo Mosteiro","Thomas Borger, Pablo Mosteiro, Heysem Kaya, Emil Rijcken, Albert Ali
  Salah, Floortje Scheepers, Marco Spruit","Federated learning for violence incident prediction in a simulated
  cross-institutional psychiatric setting",,"Expert Systems with Applications Volume 199, 1 August 2022, 116720","10.1016/j.eswa.2022.116720",,"cs.CL cs.CY cs.LG","http://creativecommons.org/licenses/by/4.0/","  Inpatient violence is a common and severe problem within psychiatry. Knowing
who might become violent can influence staffing levels and mitigate severity.
Predictive machine learning models can assess each patient's likelihood of
becoming violent based on clinical notes. Yet, while machine learning models
benefit from having more data, data availability is limited as hospitals
typically do not share their data for privacy preservation. Federated Learning
(FL) can overcome the problem of data limitation by training models in a
decentralised manner, without disclosing data between collaborators. However,
although several FL approaches exist, none of these train Natural Language
Processing models on clinical notes. In this work, we investigate the
application of Federated Learning to clinical Natural Language Processing,
applied to the task of Violence Risk Assessment by simulating a
cross-institutional psychiatric setting. We train and compare four models: two
local models, a federated model and a data-centralised model. Our results
indicate that the federated model outperforms the local models and has similar
performance as the data-centralised model. These findings suggest that
Federated Learning can be used successfully in a cross-institutional setting
and is a step towards new applications of Federated Learning based on clinical
notes
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:37:12 GMT""}]","2022-05-23"
"2205.10321","Dariush Salami","Cristian J. Vaca-Rubio, Dariush Salami, Petar Popovski, Elisabeth de
  Carvalho, Zheng-Hua Tan, Stephan Sigg","User Localization using RF Sensing: A Performance comparison between LIS
  and mmWave Radars",,,,,"eess.SP cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Since electromagnetic signals are omnipresent, Radio Frequency (RF)-sensing
has the potential to become a universal sensing mechanism with applications in
localization, smart-home, retail, gesture recognition, intrusion detection,
etc. Two emerging technologies in RF-sensing, namely sensing through Large
Intelligent Surfaces (LISs) and mmWave Frequency-Modulated Continuous-Wave
(FMCW) radars, have been successfully applied to a wide range of applications.
In this work, we compare LIS and mmWave radars for localization in real-world
and simulated environments. In our experiments, the mmWave radar achieves 0.71
Intersection Over Union (IOU) and 3cm error for bounding boxes, while LIS has
0.56 IOU and 10cm distance error. Although the radar outperforms the LIS in
terms of accuracy, LIS features additional applications in communication in
addition to sensing scenarios.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:44:56 GMT""}]","2022-05-23"
"2205.10322","Mesfin Asfaw Taye Dr.","Mesfin Taye","Exact time-dependent analytical solutions for entropy production rate
  for a system that operates in a heat bath where its temperature varies
  linearly in space","13 pages,12 figures, published in Phys. Rev. E","Physical Review E, Volume 105, Issue 5, article id. 054126, 2022","10.1103/PhysRevE.105.054126",,"cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  The nonequilibrium thermodynamics feature of a Brownian motor is investigated
by obtaining exact time-dependent solutions. This in turn enables us to
investigate not only the long time property (steady-state) but also the short
time the behavior of the system. The general expressions for the free energy,
entropy production ${\dot e}_{p}(t)$ as well as entropy extraction ${\dot
h}_{d}(t)$ rates are derived for a system that is genuinely driven out of
equilibrium by time-independent force as well as by spatially varying thermal
background. We show that for a system that operates between hot and cold
reservoirs, most of the thermodynamics quantities approach a non-equilibrium
steady state in the long time limit. The change in free energy becomes minimal
at a steady state. However for a system that operates in a heat bath where its
temperature varies linearly in space, the entropy production and extraction
rates approach a non-equilibrium steady state while the change in free energy
varies linearly in space. This reveals that unlike systems at equilibrium, when
systems are driven out of equilibrium, their free energy may not be minimized.
The thermodynamic properties of a system that operates between the hot and cold
baths are further compared and contrasted with a system that operates in a heat
bath where its temperature varies linearly in space along with the reaction
coordinate. We show that the entropy, entropy production, and extraction rates
are considerably larger for linearly varying temperature case than a system
that operates between the hot and cold baths revealing such systems are
inherently irreversible. For both cases, in the presence of load or when a
distinct temperature difference is retained, the entropy $S(t)$ monotonously
increases with time and saturates to a constant value as $t$ further steps up.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 14:03:07 GMT""}]","2022-05-23"
"2205.10355","Florian Kofler","Florian Kofler, Ivan Ezhov, Lucas Fidon, Izabela Horvath, Ezequiel de
  la Rosa, John LaMaster, Hongwei Li, Tom Finck, Suprosanna Shit, Johannes
  Paetzold, Spyridon Bakas, Marie Piraud, Jan Kirschke, Tom Vercauteren, Claus
  Zimmer, Benedikt Wiestler, Bjoern Menze","Deep Quality Estimation: Creating Surrogate Models for Human Quality
  Ratings","10 pages, 5 figures",,,,"cs.CV cs.AI cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Human ratings are abstract representations of segmentation quality. To
approximate human quality ratings on scarce expert data, we train surrogate
quality estimation models. We evaluate on a complex multi-class segmentation
problem, specifically glioma segmentation, following the BraTS annotation
protocol. The training data features quality ratings from 15 expert
neuroradiologists on a scale ranging from 1 to 6 stars for various
computer-generated and manual 3D annotations. Even though the networks operate
on 2D images and with scarce training data, we can approximate segmentation
quality within a margin of error comparable to human intra-rater reliability.
Segmentation quality prediction has broad applications. While an understanding
of segmentation quality is imperative for successful clinical translation of
automatic segmentation quality algorithms, it can play an essential role in
training new segmentation models. Due to the split-second inference times, it
can be directly applied within a loss function or as a fully-automatic dataset
curation mechanism in a federated learning setting.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:32:27 GMT""},{""version"":""v2"",""created"":""Tue, 30 Aug 2022 19:08:26 GMT""}]","2022-09-01"
"2205.11244","Sudeep Pasricha","Febin Sunny, Mahdi Nikdast, and Sudeep Pasricha","A Silicon Photonic Accelerator for Convolutional Neural Networks with
  Heterogeneous Quantization",,,,,"cs.AR cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Parameter quantization in convolutional neural networks (CNNs) can help
generate efficient models with lower memory footprint and computational
complexity. But, homogeneous quantization can result in significant degradation
of CNN model accuracy. In contrast, heterogeneous quantization represents a
promising approach to realize compact, quantized models with higher inference
accuracies. In this paper, we propose HQNNA, a CNN accelerator based on
non-coherent silicon photonics that can accelerate both homogeneously quantized
and heterogeneously quantized CNN models. Our analyses show that HQNNA achieves
up to 73.8x better energy-per-bit and 159.5x better throughput-energy
efficiency than state-of-the-art photonic CNN accelerators.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 03:26:14 GMT""}]","2022-05-24"
"2205.11613","Erik Brockbank","Erik Brockbank, Haoliang Wang, Justin Yang, Suvir Mirchandani, Erdem
  B{\i}y{\i}k, Dorsa Sadigh, Judith E. Fan","How do people incorporate advice from artificial agents when making
  physical judgments?",,,,,"cs.HC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  How do people build up trust with artificial agents? Here, we study a key
component of interpersonal trust: people's ability to evaluate the competence
of another agent across repeated interactions. Prior work has largely focused
on appraisal of simple, static skills; in contrast, we probe competence
evaluations in a rich setting with agents that learn over time. Participants
played a video game involving physical reasoning paired with one of four
artificial agents that suggested moves each round. We measure participants'
decisions to accept or revise their partner's suggestions to understand how
people evaluated their partner's ability. Overall, participants collaborated
successfully with their agent partners; however, when revising their partner's
suggestions, people made sophisticated inferences about the competence of their
partner from prior behavior. Results provide a quantitative measure of how
people integrate a partner's competence into their own decisions and may help
facilitate better coordination between humans and artificial agents.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 22:25:30 GMT""}]","2022-05-25"
"2206.00421","Riad Sonbol","Riad Sonbol, Ghaida Rebdawi, Nada Ghneim","The Use of NLP-Based Text Representation Techniques to Support
  Requirement Engineering Tasks: A Systematic Mapping Review",,,"10.1109/ACCESS.2022.3182372",,"cs.SE cs.AI cs.CL","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Natural Language Processing (NLP) is widely used to support the automation of
different Requirements Engineering (RE) tasks. Most of the proposed approaches
start with various NLP steps that analyze requirements statements, extract
their linguistic information, and convert them to easy-to-process
representations, such as lists of features or embedding-based vector
representations. These NLP-based representations are usually used at a later
stage as inputs for machine learning techniques or rule-based methods. Thus,
requirements representations play a major role in determining the accuracy of
different approaches. In this paper, we conducted a survey in the form of a
systematic literature mapping (classification) to find out (1) what are the
representations used in RE tasks literature, (2) what is the main focus of
these works, (3) what are the main research directions in this domain, and (4)
what are the gaps and potential future directions. After compiling an initial
pool of 2,227 papers, and applying a set of inclusion/exclusion criteria, we
obtained a final pool containing 104 relevant papers. Our survey shows that the
research direction has changed from the use of lexical and syntactic features
to the use of advanced embedding techniques, especially in the last two years.
Using advanced embedding representations has proved its effectiveness in most
RE tasks (such as requirement analysis, extracting requirements from reviews
and forums, and semantic-level quality tasks). However, representations that
are based on lexical and syntactic features are still more appropriate for
other RE tasks (such as modeling and syntax-level quality tasks) since they
provide the required information for the rules and regular expressions used
when handling these tasks. In addition, we identify four gaps in the existing
literature, why they matter, and how future research can begin to address them.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 02:47:26 GMT""}]","2022-06-15"
"2206.00435","Ion Simaciu","Ion Simaciu, Zoltan Borsos, Gheorghe Dumitrescu","Acoustic gravitational interaction revised","9 pages",,,,"physics.gen-ph","http://creativecommons.org/licenses/by/4.0/","  In this paper, we deduce the expression of the gravito-acoustic force between
two oscillating bubbles using the hypothesis that this type of force is a force
of scattering-absorption of the energy of excitatory waves. The expression of
the gravito-acoustic force at resonance highlights the dependence of this force
on the product of the virtual masses of the two bubbles and on an acoustic
gravitational constant. The acoustic gravitational constant depends on the
absorption damping coefficient. We may say also that the expression of the
acoustic gravitational constant is analogous to the expression of the
gravitational constant in the electromagnetic world, that one obtained in the
Einstein-Sciama model and the Dirac-Eddington large numbers hypothesis. The
results obtained for this type of phenomenon in the acoustic world support the
similarity between the acoustic world and the electromagnetic world.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 09:54:53 GMT""}]","2022-06-02"
"2206.00442","Yuriy Akimov","Yuriy Akimov","Light-matter interaction problem in classical and quantum optics","7 pages, 2 figures",,,,"physics.gen-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Understanding of light-matter interaction is a keystone in mastering
classical and quantum optics. This paper gives an overview of the fundamental
principles used in these two fields for description of light-matter
interaction. By exploring the simplest type of matter composed of charge-free
particles bearing magnetic moments only, differences in the fundamental
principles of classical and quantum optics are discussed and clarified.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 22:41:12 GMT""}]","2022-06-02"
"2206.00653","Mauricio Martinez","Syo Kamata, Jakub Jankowski and Mauricio Martinez","Novel features of attractors and transseries in non-conformal Bjorken
  flows","37 pages (main text) + 11 pages (appendices + references), 12
  figures. v2: Improved discussion, added new figure",,,,"physics.flu-dyn cond-mat.stat-mech hep-ph hep-th nucl-th","http://creativecommons.org/licenses/by/4.0/","  In this work we investigate the impact of conformal symmetry breaking on
hydrodynamization of a far-from-equilibrium fluid. We find a new kind of
transseries solutions for the non-conformal hydrodynamic equations of a
longitudinal boost invariant expanding plasma. The new transseries solutions
unveil a rich physical structure which arises due to the interplay of different
physical scales. In the perfect fluid case the non-conformal speed of sound
slows down the cooling of the temperature due to the emergence of logarithmic
corrections that depends on the mass of the particle. These terms propagate
into the perturbative and non-perturbative sectors of the transseries once
viscous corrections are included. The logarithmic mass contributions increase
the asymptotic value of the Knudsen number while decreasing the damping rate of
the transient non-hydrodynamic modes and thus, yielding to an extremely slow
hydrodynamization process where flow lines merge to their forward attractor at
extremely late times. The early time free streaming expansion is modified and
receives logarithmic mass corrections induced by the shear-bulk couplings. The
global flow structure and numerical analyses carried out in our work
demonstrate the existence of the early and late-time attractors for the shear
viscous tensor and bulk viscous pressure.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 06:02:39 GMT""},{""version"":""v2"",""created"":""Mon, 16 Jan 2023 03:23:02 GMT""}]","2023-01-18"
"2206.01531","Nazmi Burak Budanur","George Choueiri and Balachandra Suri and Jack Merrin and Maksym Serbyn
  and Bj\""orn Hof and Nazmi Burak Budanur","Crises and chaotic scattering in hydrodynamic pilot-wave experiments","10 pages, 8 figures","Chaos 32, 093138 (2022)","10.1063/5.0102904",,"physics.flu-dyn nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Theoretical foundations of chaos have have been predominantly laid out for
finite-dimensional dynamical systems, such as the three-body problem in
classical mechanics and the Lorenz model in dissipative systems. In contrast,
many real-world chaotic phenomena, e.g. weather, arise in systems with many
(formally infinite) degrees of freedom, which limits direct quantitative
analysis of such systems using chaos theory. In the present work, we
demonstrate that the hydrodynamic pilot-wave systems offer a bridge between
low- and high-dimensional chaotic phenomena by allowing for a systematic study
of how the former connects to the latter. Specifically, we present experimental
results which show the formation of low-dimensional chaotic attractors upon
destabilization of regular dynamics and a final transition to high-dimensional
chaos via the merging of distinct chaotic regions through a crisis bifurcation.
Moreover, we show that the post-crisis dynamics of the system can be
rationalized as consecutive scatterings from the nonattracting chaotic sets
with lifetimes following exponential distributions.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:44:31 GMT""},{""version"":""v2"",""created"":""Thu, 11 Aug 2022 08:52:58 GMT""}]","2022-11-10"
"2206.02525","Lei Xun","Lei Xun, Bashir M. Al-Hashimi, Jonathon Hare, Geoff V. Merrett","Dynamic DNNs Meet Runtime Resource Management on Mobile and Embedded
  Platforms","Accepted as a presentation at Fourth UK Mobile, Wearable and
  Ubiquitous Systems Research Symposium (MobiUK 2022)",,,,"cs.AR","http://creativecommons.org/licenses/by/4.0/","  Deep neural network (DNN) inference is increasingly being executed on mobile
and embedded platforms due to low latency and better privacy. However,
efficient deployment on these platforms is challenging due to the intensive
computation and memory access. We propose a holistic system design for DNN
performance and energy optimisation, combining the trade-off opportunities in
both algorithms and hardware. The system can be viewed as three abstract
layers: the device layer contains heterogeneous computing resources; the
application layer has multiple concurrent workloads; and the runtime resource
management layer monitors the dynamically changing algorithms' performance
targets as well as hardware resources and constraints, and tries to meet them
by tuning the algorithm and hardware at the same time. Moreover, We illustrate
the runtime approach through a dynamic version of 'once-for-all network'
(namely Dynamic-OFA), which can scale the ConvNet architecture to fit
heterogeneous computing resources efficiently and has good generalisation for
different model architectures such as Transformer. Compared to the
state-of-the-art Dynamic DNNs, our experimental results using ImageNet on a
Jetson Xavier NX show that the Dynamic-OFA is up to 3.5x (CPU), 2.4x (GPU)
faster for similar ImageNet Top-1 accuracy, or 3.8% (CPU), 5.1% (GPU) higher
accuracy at similar latency. Furthermore, compared with Linux governor (e.g.
performance, schedutil), our runtime approach reduces the energy consumption by
16.5% at similar latency.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 11:16:00 GMT""},{""version"":""v2"",""created"":""Tue, 7 Jun 2022 01:16:34 GMT""}]","2022-06-08"
"2206.03227","Shadrokh Samavi","Altanai Bisht, Arielle Wilson, Zachary Jeffreys, Shadrokh Samavi","Does Crypto Kill? Relationship between Electricity Consumption Carbon
  Footprints and Bitcoin Transactions","8 pages, 17 figures",,,,"cs.CY cs.CR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Cryptocurrencies are gaining more popularity due to their security, making
counterfeits impossible. However, these digital currencies have been criticized
for creating a large carbon footprint due to their algorithmic complexity and
decentralized system design for proof of work and mining. We hypothesize that
the carbon footprint of cryptocurrency transactions has a higher dependency on
carbon-rich fuel sources than green or renewable fuel sources. We provide a
machine learning framework to model such transactions and correlate them with
the electricity generation patterns to estimate and analyze their carbon cost.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 18:03:45 GMT""}]","2022-06-08"
"2206.03262","Marvin van Bekkum","Marvin van Bekkum, Frederik Zuiderveen Borgesius","Using sensitive data to prevent discrimination by artificial
  intelligence: Does the GDPR need a new exception?",,"Computer Law & Security Review 48 (2023) 105770","10.1016/j.clsr.2022.105770",,"cs.CY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Organisations can use artificial intelligence to make decisions about people
for a variety of reasons, for instance, to select the best candidates from many
job applications. However, AI systems can have discriminatory effects when used
for decision-making. To illustrate, an AI system could reject applications of
people with a certain ethnicity, while the organisation did not plan such
ethnicity discrimination. But in Europe, an organisation runs into a problem
when it wants to assess whether its AI system accidentally discriminates based
on ethnicity: the organisation may not know the applicants' ethnicity. In
principle, the GDPR bans the use of certain 'special categories of data'
(sometimes called 'sensitive data'), which include data on ethnicity, religion,
and sexual preference. The proposal for an AI Act of the European Commission
includes a provision that would enable organisations to use special categories
of data for auditing their AI systems. This paper asks whether the GDPR's rules
on special categories of personal data hinder the prevention of AI-driven
discrimination. We argue that the GDPR does prohibit such use of special
category data in many circumstances. We also map out the arguments for and
against creating an exception to the GDPR's ban on using special categories of
personal data, to enable preventing discrimination by AI systems. The paper
discusses European law, but the paper can be relevant outside Europe too, as
many policymakers in the world grapple with the tension between privacy and
non-discrimination policy.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 07:39:25 GMT""},{""version"":""v2"",""created"":""Thu, 13 Oct 2022 10:20:30 GMT""},{""version"":""v3"",""created"":""Mon, 28 Nov 2022 11:34:36 GMT""}]","2022-11-29"
"2206.03263","Sudeep Pasricha","Sudeep Pasricha","Embedded Systems Education in the 2020s: Challenges, Reflections, and
  Future Directions",,,,,"cs.CY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Embedded computing systems are pervasive in our everyday lives, imparting
digital intelligence to a variety of electronic platforms used in our vehicles,
smart appliances, wearables, mobile devices, and computers. The need to train
the next generation of embedded systems designers and engineers with relevant
skills across hardware, software, and their co-design remains pressing today.
This paper describes the evolution of embedded systems education over the past
two decades and challenges facing the designers and instructors of embedded
systems curricula in the 2020s. Reflections from over a decade of teaching the
design of embedded computing systems are presented, with insights on strategies
that show promise to address these challenges. Lastly, some important future
directions in embedded systems education are highlighted.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 03:19:57 GMT""}]","2022-06-08"
"2206.03264","Stavros Mischos","Stavros Mischos, Eleanna Dalagdi, Dimitris Vrakas","Intelligent Energy Management Systems -- A Review",,,,,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  Climate change has become a major problem for humanity in the last two
decades. One of the reasons that caused it, is our daily energy waste. People
consume electricity in order to use home/work appliances and devices and also
reach certain levels of comfort while working or being at home. However, even
though the environmental impact of this behavior is not immediately observed,
it leads to increased CO2 emissions coming from energy generation from power
plants. Confronting such a problem efficiently will affect both the environment
and our society. Monitoring energy consumption in real-time, changing energy
wastage behavior of occupants and using automations with incorporated energy
savings scenarios, are ways to decrease global energy footprint. In this
review, we study intelligent systems for energy management in residential,
commercial and educational buildings, classifying them in two major categories
depending on whether they provide direct or indirect control. The article also
discusses what the strengths and weaknesses are, which optimization techniques
do they use and finally, provide insights about how these systems can be
improved in the future.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 20:10:20 GMT""}]","2022-06-08"
"2206.05115","Zijian Hong","Ziyi Hu, Linming Zhou, Dechao Meng, Liyan Zhao, Yihua Li, Yuhui Huang,
  Yongjun Wu, Shikuan Yang, Linsen Li, Zijian Hong","Surface engineering for ultrathin metal anodes enabling high-performance
  Zn-ion batteries","21 Pages 6 Figures",,,,"cond-mat.mtrl-sci physics.app-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Zn metal battery has been considered a promising alternative energy storage
technology in renewable energy storage and grid storage. It is well-known that
the surface orientation of a Zn metal anode is vital to the reversibility of a
Zn metal battery. Herein, the (101)-oriented thin Zn metal anode (down to 2
{\mu}m) is electrodeposited on a Cu surface by adding dimethyl sulfoxide (DMSO)
electrolyte additive in ZnSO4 aqueous solution. Scanning electron microscope
(SEM) observation indicates the formation of flat terrace-like compact
(101)-oriented surfaces. Insitu optical observation confirms that the
(101)-oriented surfaces can be reversibly plated and stripped. DFT calculations
reveal two mechanisms for the nucleation and growth of the Zn-(101) surface:
(1) formation of Zn(101)//Cu(001) could lower the interface energy as compared
to Zn(002)//Cu(001); (2) large reconstruction of the Zn (101) surface with DMSO
and H2O absorption. Raman, XPS, and ToF-SIMS characterizations indicate that
adding DMSO in ZnCl2 could facilitate the formation of ZnO-based SEI on Zn
metal surface, while OH- and S-based SEI can be obtained with DMSO in ZnSO4.
The electrochemical testings are performed, which demonstrates a higher
cyclability for the (101)-oriented Zn in the half cell as well as a lower
charge transfer barrier with respect to the (002)-dominated surface of the same
electrode thickness. Zn||V2O5 full cells are further assembled, showing better
capacity retention for the (101)-Zn as compared to the (002)-Zn with the same
thickness (5 {\mu}m, 3 {\mu}m, and 2 {\mu}m). We hope this study to spur
further interest in the control of Zn metal surface crystallographic
orientation towards ultrathin Zn metal anodes.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 17:13:38 GMT""}]","2022-06-13"
"2206.10299","Ali H\""urriyeto\u{g}lu","F{\i}rat Duru\c{s}an, Ali H\""urriyeto\u{g}lu, Erdem Y\""or\""uk, Osman
  Mutlu, \c{C}a\u{g}r{\i} Yoltar, Burak G\""urel, Alvaro Comin","Global Contentious Politics Database (GLOCON) Annotation Manuals","Annotation manuals of the Emerging Welfare project",,,,"cs.CL cs.CY cs.LG","http://creativecommons.org/licenses/by/4.0/","  The database creation utilized automated text processing tools that detect if
a news article contains a protest event, locate protest information within the
article, and extract pieces of information regarding the detected protest
events. The basis of training and testing the automated tools is the GLOCON
Gold Standard Corpus (GSC), which contains news articles from multiple sources
from each focus country. The articles in the GSC were manually coded by skilled
annotators in both classification and extraction tasks with the utmost accuracy
and consistency that automated tool development demands. In order to assure
these, the annotation manuals in this document lay out the rules according to
which annotators code the news articles. Annotators refer to the manuals at all
times for all annotation tasks and apply the rules that they contain. The
content of the annotation manual is built on the general principles and
standards of linguistic annotation laid out in other prominent annotation
manuals such as ACE, CAMEO, and TimeML. These principles, however, have been
adapted or rather modified heavily to accommodate the social scientific
concepts and variables employed in the EMW project. The manual has been molded
throughout a long trial and error process that accompanied the annotation of
the GSC. It owes much of its current shape to the meticulous work and
invaluable feedback provided by highly specialized teams of annotators, whose
diligence and expertise greatly increased the quality of the corpus.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 13:16:50 GMT""}]","2022-06-22"
"2206.11255","Hui Liu","Yiming Fang, Xuejun Liu, and Hui Liu","Attention-aware contrastive learning for predicting T cell
  receptor-antigen binding specificity",,,,,"q-bio.QM cs.LG","http://creativecommons.org/licenses/by/4.0/","  It has been verified that only a small fraction of the neoantigens presented
by MHC class I molecules on the cell surface can elicit T cells. The limitation
can be attributed to the binding specificity of T cell receptor (TCR) to
peptide-MHC complex (pMHC). Computational prediction of T cell binding to
neoantigens is an challenging and unresolved task. In this paper, we propose an
attentive-mask contrastive learning model, ATMTCR, for inferring TCR-antigen
binding specificity. For each input TCR sequence, we used Transformer encoder
to transform it to latent representation, and then masked a proportion of
residues guided by attention weights to generate its contrastive view.
Pretraining on large-scale TCR CDR3 sequences, we verified that contrastive
learning significantly improved the prediction performance of TCR binding to
peptide-MHC complex (pMHC). Beyond the detection of important amino acids and
their locations in the TCR sequence, our model can also extracted high-order
semantic information underlying the TCR-antigen binding specificity. Comparison
experiments were conducted on two independent datasets, our method achieved
better performance than other existing algorithms. Moreover, we effectively
identified important amino acids and their positional preferences through
attention weights, which indicated the interpretability of our proposed model.
","[{""version"":""v1"",""created"":""Tue, 17 May 2022 10:53:32 GMT""}]","2022-06-24"
