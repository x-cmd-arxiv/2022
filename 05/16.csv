"2205.07321","Hans Rabus","Hans Rabus (1,7), Maria Zankl (2,7), Jose Maria Gomez-Ros (3,7),
  Carmen Villagrasa (4,7), Jonathan Eakins (5,7), Christelle Huet (4,7), Hrvoje
  Brkic (6,7), Rick Tanner (5,7) ((1) Physikalisch-Technische Bundesanstalt
  (PTB), Abbestrasse 2-12, 10587 Berlin, Germany (2) Helmholtz Zentrum Munchen
  German Research Center for Environmental Health (HMGU), Neuherberg, Germany
  (3) Centro de Investigaciones Energeticas, Medioambientales y Tecnologicas
  (CIEMAT), Madrid, Spain (4) Institut de Radioprotection et de Surete
  Nucleaire (IRSN), Fontenay-aux-Roses, France (5) UK Health Security Agency
  (UKHSA), Didcot, United Kingdom (6) J. J. Strossmayer University of Osijek
  (MEFOS), Osijek, Croatia (7) European Radiation Dosimetry Group (EURADOS)
  e.V, Neuherberg, Germany)","Lessons learnt from the recent EURADOS intercomparisons in computational
  dosimetry","17 Pages, 6 Figures, submitted to Radiat. Meas","Radiation Measurements 156, 106822 (2022)","10.1016/j.radmeas.2022.106822",,"physics.med-ph physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  Organized by Working Group 6 ""Computational Dosimetry"" of the European
Radiation Dosimetry Group (EURADOS), a group of intercomparison exercises was
conducted in which participants were asked to solve predefined problems in
computational dosimetry. The results of these comparisons were published in a
series of articles in this virtual special issue of Radiation Measurements.
This paper reviews the experience gained from the various exercises and
highlights the resulting conclusions for future exercises, as well as regarding
the state of the art and the need for development in terms of quality assurance
for computational dosimetry techniques.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 16:02:50 GMT""}]","2022-07-06"
"2205.07322","Tewodros Amdeberhan","Tewodros Amdeberhan, George E. Andrews, Cristina Ballantine","Hook length and symplectic content in partitions","19 pages",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  The dimension of an irreducible representation of $GL(n,\mathbb{C})$,
$Sp(2n)$, or $SO(n)$ is given by the respective hook-length and content
formulas for the corresponding partition. The first author, inspired by the
Nekrasov-Okounkov formula, conjectured combinatorial interpretations of
analogous expressions involving hook-lengths and symplectic/orthogonal
contents. We prove special cases of these conjectures. In the process, we show
that partitions of $n$ with all symplectic contents non-zero are equinumerous
with partitions of $n$ into distinct even parts. We also present Beck-type
companions to this identity. In this context, we give the parity of the number
of partitions into distinct parts with odd (respectively, even) rank. We study
the connection between the sum of hook-lengths and the sum of inversions in the
binary representation of a partition. In addition, we introduce a new partition
statistic, the $x$-ray list of a partition, and explore its connection with
distinct partitions as well as partitions maximally contained in a given
staircase partition.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 16:09:03 GMT""}]","2022-05-17"
"2205.07323","Mircea Andrecut Dr","M. Andrecut","Attack vs Benign Network Intrusion Traffic Classification","8 pages",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Intrusion detection systems (IDS) are used to monitor networks or systems for
attack activity or policy violations. Such a system should be able to
successfully identify anomalous deviations from normal traffic behavior. Here
we discuss the machine learning approach to building an anomaly-based IDS using
the CSE-CIC-IDS2018 dataset. Since the publication of this dataset a relatively
large number of papers have been published, most of them presenting IDS
architectures and results based on complex machine learning methods, like deep
neural networks, gradient boosting classifiers, or hidden Markov models. Here
we show that similar results can be obtained using a very simple nearest
neighbor classification approach, avoiding the inherent complications of
training such complex models. The advantages of the nearest neighbor algorithm
are: (1) it is very simple to implement; (2) it is extremely robust; (3) it has
no parameters, and therefore it cannot overfit the data. This result also shows
that currently there is a trend of developing over-engineered solutions in the
machine learning community. Such solutions are based on complex methods, like
deep learning neural networks, without even considering baseline solutions
corresponding to simple, but efficient methods.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 16:16:08 GMT""}]","2022-05-17"
"2205.07324","Yue Guan","Yue Guan, Zhengyi Li, Jingwen Leng, Zhouhan Lin, Minyi Guo","Transkimmer: Transformer Learns to Layer-wise Skim","Published as a conference paper at ACL 2022",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transformer architecture has become the de-facto model for many machine
learning tasks from natural language processing and computer vision. As such,
improving its computational efficiency becomes paramount. One of the major
computational inefficiency of Transformer-based models is that they spend the
identical amount of computation throughout all layers. Prior works have
proposed to augment the Transformer model with the capability of skimming
tokens to improve its computational efficiency. However, they suffer from not
having effectual and end-to-end optimization of the discrete skimming
predictor. To address the above limitations, we propose the Transkimmer
architecture, which learns to identify hidden state tokens that are not
required by each layer. The skimmed tokens are then forwarded directly to the
final output, thus reducing the computation of the successive layers. The key
idea in Transkimmer is to add a parameterized predictor before each layer that
learns to make the skimming decision. We also propose to adopt
reparameterization trick and add skim loss for the end-to-end training of
Transkimmer. Transkimmer achieves 10.97x average speedup on GLUE benchmark
compared with vanilla BERT-base baseline with less than 1% accuracy
degradation.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 16:23:30 GMT""}]","2022-05-17"
"2205.07325","Athanasios Papaioannou Dr.","Athanasios Papaioannou, Rami Vainio, Osku Raukunen, Piers Jiggens,
  Angels Aran, Mark Dierckxsens, Sotirios A. Mallios, Miikka Paassilta,
  Anastasios Anastasiadis","The Probabilistic Solar Particle Event foRecasting (PROSPER) Model","Submitted to J. Space Weather & Space Climate",,,,"astro-ph.SR physics.space-ph","http://creativecommons.org/licenses/by/4.0/","  The Probabilistic Solar Particle Event foRecasting (PROSPER) model predicts
the probability of occurrence and the expected peak flux of Solar Energetic
Particle (SEP) events. Predictions are derived for a set of integral proton
energies (i.e. E$>$10, $>$30 and $>$100 MeV) from characteristics of solar
flares (longitude, magnitude), coronal mass ejections (width, speed) and
combinations of both. Herein the PROSPER model methodology for deriving the SEP
event forecasts is described and the validation of the model, based on archived
data, is presented for a set of case studies. The PROSPER model has been
incorporated into the new operational Advanced Solar Particle Event Casting
System (ASPECS) tool to provide nowcasting (short term forecasting) of SEP
events as part of ESA's future SEP Advanced Warning System (SAWS). ASPECS also
provides the capability to interrogate PROSPER for historical cases via a run
on demand functionality.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 16:25:07 GMT""}]","2022-05-17"
"2205.07326","Tomas Fullana","Tomas Fullana, Vincent Le Chenadec and Taraneh Sayadi","Adjoint-based optimization of two-dimensional Stefan problems","33 pages, 16 figures, preprint submitted to Journal of Computational
  Physics",,"10.1016/j.jcp.2022.111875",,"math-ph cs.NA math.MP math.NA physics.comp-ph physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A range of optimization cases of two-dimensional Stefan problems, solved
using a tracking-type cost-functional, is presented. A level set method is used
to capture the interface between the liquid and solid phases and an immersed
boundary (cut cell) method coupled with an implicit time-advancement scheme is
employed to solve the heat equation. A conservative implicit-explicit scheme is
then used for solving the level set transport equation. The resulting numerical
framework is validated with respect to existing analytical solutions of the
forward Stefan problem. An adjoint-based algorithm is then employed to
efficiently compute the gradient used in the optimisation algorithm (L-BFGS).
The algorithm follows a continuous adjoint framework, where adjoint equations
are formally derived using shape calculus and transport theorems. A wide range
of control objectives are presented, and the results show that using
parameterised boundary actuation leads to effective control strategies in order
to suppress interfacial instabilities or to maintain a desired crystal shape.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 16:30:24 GMT""},{""version"":""v2"",""created"":""Fri, 24 Jun 2022 13:43:25 GMT""}]","2023-01-25"
"2205.07327","Krzysztof Marciniak","Maciej B{\l}aszak and Krzysztof Marciniak","Systematic construction of non-autonomous Hamiltonian equations of
  Painlev\'e-type. III. Quantization",,,,,"nlin.SI math-ph math.MP quant-ph","http://creativecommons.org/licenses/by/4.0/","  This is the third article in our series of articles exploring connections
between dynamical systems of St\""ackel-type and of Painlev\'e-type. In this
article we present a method of deforming of minimally quantized quasi-St\""ackel
Hamiltonians, considered in Part I to self-adjoint operators satisfying the
quantum Frobenius condition, thus guaranteeing that the corresponding
Schr\""odinger equations posses common, multi-time solutions. As in the
classical case, we obtain here both magnetic and non-magnetic families of
systems. We also show the existence of multitime-dependent quantum canonical
maps between both classes of quantum systems.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 16:35:56 GMT""}]","2022-05-17"
"2205.07328","Claudio Bravo","Claudio Bravo","Quotients of the Bruhat-Tits tree by function field analogs of the Hecke
  congruence subgroups",,,,,"math.GR math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let C be a smooth, projective and geometrically integral curve defined over a
finite field F. For each closed point P of C, let R be the ring of functions
that are regular outside P, and let K be the completion at P of the function
field of C. In order to study groups of the form GL2(R), Serre describes the
quotient graph GL2(R)\t, where t is the Bruhat-Tits tree defined from SL2(K).
In particular, Serre shows that GL2(R)\t is the union of a finite graph and a
finite number of ray shaped subgraphs, which are called cusps. It is not hard
to see that finite index subgroups inherit this property.
  In this work we describe the associated quotient graph H\t for the action on
t of the group H of matrices in GL2(R) that are upper triangular modulo a
certain ideal I of R. More specifically, we give a explicit formula for the
cusp number of H\t. Then, by using Bass-Serre Theory, we describe the
combinatorial structure of H. These groups play, in the function field context,
the same role as the Hecke congruence subgroups of SL2(Z).
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 16:40:33 GMT""}]","2022-05-17"
"2205.07329","Malcolm Kadodwala","Victor Tabouillot, Rahul Kumar, Paula L. Lalaguna, Maryam Hajji,
  Rebecca Clarke, Affar Karimullah, Andrew R. Thomson, Andrew Sutherland,
  Nikolaj Gadegaard, Shun Hashiyada and Malcolm Kadodwala","Near-field Probing of Optical Superchirality for Enhanced Bio-detection",,"ACS Photonics 2022 11 3617","10.1021/acsphotonics.2c01073",,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Nanophotonic platforms in theory uniquely enable < femtomoles of chiral
biological and pharmaceutical molecules to be detected, through the highly
localised changes in the chiral asymmetries of the near-fields that they
induce. However, current chiral nanophotonic based strategies are intrinsically
limited because they rely on far-field optical measurements that are sensitive
to a much larger near-field volume, than that influenced by the chiral
molecules. Consequently, they depend on detecting small changes in far-field
optical response restricting detection sensitivities. Here we exploit an
intriguing phenomenon, plasmonic circularly polarised luminescence (PCPL),
which is an incisive local probe of near-field chirality. This allows chiral
detection of monolayer quantities of a de novo designed peptide, which is not
achieved with a far-field response. Our work demonstrates that by leveraging
the capabilities of nanophotonic platforms with the near-field sensitivity of
PCPL, optimal biomolecular detection performance can be achieved, opening new
avenues for nanometrology.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 16:41:39 GMT""}]","2022-12-08"
"2205.07330","Daniel Lesko","Daniel M. B. Lesko, Kristina F. Chang, Scott A. Diddams","High-sensitivity Frequency Comb Carrier-Envelope-Phase Metrology in
  Solid State High Harmonic Generation","12 pages, 7 figures",,,,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Non-perturbative and phase-sensitive light-matter interactions have led to
the generation of attosecond pulses of light and the control electrical
currents on the same timescale. Traditionally, probing these effects via high
harmonic generation has involved complicated lasers and apparatuses to generate
the few-cycle and high peak power pulses needed to obtain and measure spectra
that are sensitive to the phase of the light wave. Instead, we show that
nonlinear effects dependent on the carrier-envelope phase can be accessed in
solid state crystals with simple low-energy frequency combs that we combine
with high-sensitivity demodulation techniques to measure harmonic spectral
modulations. Central to this advance is the use of a scalable 100 MHz
Erbium-fiber frequency comb at 1550 nm to produce 10 nJ, 20 fs pulses which are
focused to the TW/cm2 level. In a single pass through a 500 {\mu}m ZnO crystal
this yields harmonic spectra as short as 200 nm. With this system, we introduce
a technique of carrier-envelope amplitude modulation spectroscopy (CAMS) and
use it to characterize the phase-sensitive modulation of the ultraviolet
harmonics with 85 dB signal-to-noise ratio. We further verify the
non-perturbative nature of the harmonic generation through polarization gating
of the driving pulse to increase the effects of the carrier-envelope phase. Our
work demonstrates robust and ultra-sensitive methods for generating and
characterizing harmonic generation at 100 MHz rates that should provide
advantages in the study of attosecond nonlinear processes in solid state
systems. Additionally, as a simple and low-noise frequency comb, this broadband
source will be useful for precision dual-comb spectroscopy of a range of
physical systems across the ultraviolet and visible spectral regions (200 - 650
nm).
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 16:55:19 GMT""}]","2022-05-17"
"2205.07331","Yiping Lu","Yiping Lu, Jose Blanchet, Lexing Ying","Sobolev Acceleration and Statistical Optimality for Learning Elliptic
  Equations via Gradient Descent",,,,,"math.NA cs.LG cs.NA math.ST physics.comp-ph stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the statistical limits in terms of Sobolev norms of
gradient descent for solving inverse problem from randomly sampled noisy
observations using a general class of objective functions. Our class of
objective functions includes Sobolev training for kernel regression, Deep Ritz
Methods (DRM), and Physics Informed Neural Networks (PINN) for solving elliptic
partial differential equations (PDEs) as special cases. We consider a
potentially infinite-dimensional parameterization of our model using a suitable
Reproducing Kernel Hilbert Space and a continuous parameterization of problem
hardness through the definition of kernel integral operators. We prove that
gradient descent over this objective function can also achieve statistical
optimality and the optimal number of passes over the data increases with sample
size. Based on our theory, we explain an implicit acceleration of using a
Sobolev norm as the objective function for training, inferring that the optimal
number of epochs of DRM becomes larger than the number of PINN when both the
data size and the hardness of tasks increase, although both DRM and PINN can
achieve statistical optimality.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 17:01:53 GMT""},{""version"":""v2"",""created"":""Tue, 17 May 2022 04:21:52 GMT""},{""version"":""v3"",""created"":""Mon, 19 Sep 2022 09:11:27 GMT""}]","2022-09-20"
"2205.07332","Krzysztof Redlich KR","Bengt Friman (Darmstadt, GSI), Krzysztof Redlich (Wroclaw U.)","Fluctuations in the canonical ensemble of an Abelian charge",,,,,"nucl-th hep-ph","http://creativecommons.org/publicdomain/zero/1.0/","  We study fluctuations in the canonical ensemble, where the net baryon number
is exactly conserved. The focus is on cumulants and factorial cumulants linked
to the baryon and antibaryon multiplicities and their sum or difference in full
phase-space as well as in subsystems. In particular, we connect the
fluctuations of the net baryon number in a subsystem, relevant for fluctuation
studies in nucleus-nucleus collisions, with fluctuations of the baryon and
antibaryon numbers of the total system. We derive analytic expressions for
factorial cumulants of arbitrary order. Compact results are obtained in terms
of cumulants of the baryon number of the total system. Moreover, we derive the
asymptotic forms of the factorial cumulants of baryon and antibaryon
multiplicities in the high- and low-temperature limits and discuss the results
in the context of heavy-ion collision experiments.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 17:06:13 GMT""}]","2022-05-17"
"2205.07333","J.D. Zamfirescu-Pereira","J.D. Zamfirescu-Pereira, Jerry Chen, Emily Wen, Allison Koenecke,
  Nikhil Garg, Emma Pierson","Trucks Don't Mean Trump: Diagnosing Human Error in Image Analysis","To be published in FAccT 2022",,,,"cs.HC cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Algorithms provide powerful tools for detecting and dissecting human bias and
error. Here, we develop machine learning methods to to analyze how humans err
in a particular high-stakes task: image interpretation. We leverage a unique
dataset of 16,135,392 human predictions of whether a neighborhood voted for
Donald Trump or Joe Biden in the 2020 US election, based on a Google Street
View image. We show that by training a machine learning estimator of the Bayes
optimal decision for each image, we can provide an actionable decomposition of
human error into bias, variance, and noise terms, and further identify specific
features (like pickup trucks) which lead humans astray. Our methods can be
applied to ensure that human-in-the-loop decision-making is accurate and fair
and are also applicable to black-box algorithmic systems.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 17:06:51 GMT""}]","2022-05-17"
"2205.07334","Eduardo Ramos","Eduardo Ramos-P\'erez, Pablo J. Alonso-Gonz\'alez and Jos\'e Javier
  N\'u\~nez-Vel\'azquez","Mack-Net model: Blending Mack's model with Recurrent Neural Networks",,"Expert Systems with Applications. Volume 201, 1 September 2022,
  117146","10.1016/j.eswa.2022.117146",,"q-fin.RM q-fin.CP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In general insurance companies, a correct estimation of liabilities plays a
key role due to its impact on management and investing decisions. Since the
Financial Crisis of 2007-2008 and the strengthening of regulation, the focus is
not only on the total reserve but also on its variability, which is an
indicator of the risk assumed by the company. Thus, measures that relate
profitability with risk are crucial in order to understand the financial
position of insurance firms. Taking advantage of the increasing computational
power, this paper introduces a stochastic reserving model whose aim is to
improve the performance of the traditional Mack's reserving model by applying
an ensemble of Recurrent Neural Networks. The results demonstrate that blending
traditional reserving models with deep and machine learning techniques leads to
a more accurate assessment of general insurance liabilities.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 17:09:25 GMT""}]","2022-05-17"
"2205.07335","Martin Strecker","How Khang Lim, Avishkar Mahajan, Martin Strecker, Meng Weng Wong","Automating Defeasible Reasoning in Law",,,,,"cs.AI cs.LO","http://creativecommons.org/licenses/by-sa/4.0/","  The paper studies defeasible reasoning in rule-based systems, in particular
about legal norms and contracts. We identify rule modifiers that specify how
rules interact and how they can be overridden. We then define rule
transformations that eliminate these modifiers, leading in the end to a
translation of rules to formulas. For reasoning with and about rules, we
contrast two approaches, one in a classical logic with SMT solvers as proof
engines, one in a non-monotonic logic with Answer Set Programming solvers.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 17:14:15 GMT""}]","2022-05-17"
"2205.07336","Joseph Howlett","G. Plante, E. Aprile, J. Howlett, Y. Zhang","Liquid-phase purification for multi-tonne xenon detectors",,"Eur. Phys. J. C 82, 860 (2022)","10.1140/epjc/s10052-022-10832-w",,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As liquid xenon detectors grow in scale, novel techniques are required to
maintain sufficient purity for charges to survive across longer drifts. The
Xeclipse test facility at Columbia University was built to test the removal of
electronegative impurities through cryogenic filtration powered by a liquid
xenon pump, enabling a far higher mass flow rate than gas-phase purification
through heated getters. In this paper, we present results from Xeclipse,
including measured oxygen removal rates for two sorbent materials, which were
used to guide the design and commissioning of the XENONnT liquid purification
system. Thanks to this innovation, XENONnT has achieved an electron lifetime
greater than 10 ms in an 8.6 tonne total mass, perhaps the highest purity ever
measured in a liquid xenon detector.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 17:21:10 GMT""},{""version"":""v2"",""created"":""Mon, 3 Oct 2022 19:01:58 GMT""}]","2022-10-05"
"2205.07337","Mahroo Bahreinian","Mahroo Bahreinian and Roberto Tron","Output-Feedback Path Planning with Robustness to State-Dependent Errors","This work has been submitted to the CDC conference 2022. arXiv admin
  note: text overlap with arXiv:2203.04416",,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  We consider the problem of sample-based feedback motion planning from
measurements affected by systematic errors. Our previous work presented output
feedback controllers that use measurements from landmarks in the environment to
navigate through a cell-decomposable environment using duality, Control
Lyapunov and Barrier Functions (CLF, CBF), and Linear Programming. In this
paper, we build on this previous work with a novel strategy that allows the use
of measurements affected by systematic errors in perceived depth (similarly to
what might be generated by vision-based sensors), as opposed to accurate
displacement measurements. As a result, our new method has the advantage of
providing more robust performance (with quantitative guarantees) when
inaccurate sensors are used. We test the proposed algorithm in the simulation
to evaluate the performance limits of our approach predicted by our theoretical
derivations.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 17:22:02 GMT""}]","2022-05-17"
"2205.07338","Thomas Spooner","Thomas Spooner, Rui Silva, Joshua Lockhart, Jason Long, Vacslav
  Glukhov","Reductive MDPs: A Perspective Beyond Temporal Horizons","15 pages, 10 figures, 1 algorithm",,,,"cs.AI cs.CC cs.LG math.PR stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Solving general Markov decision processes (MDPs) is a computationally hard
problem. Solving finite-horizon MDPs, on the other hand, is highly tractable
with well known polynomial-time algorithms. What drives this extreme disparity,
and do problems exist that lie between these diametrically opposed
complexities? In this paper we identify and analyse a sub-class of stochastic
shortest path problems (SSPs) for general state-action spaces whose dynamics
satisfy a particular drift condition. This construction generalises the
traditional, temporal notion of a horizon via decreasing reachability: a
property called reductivity. It is shown that optimal policies can be recovered
in polynomial-time for reductive SSPs -- via an extension of backwards
induction -- with an efficient analogue in reductive MDPs. The practical
considerations of the proposed approach are discussed, and numerical
verification provided on a canonical optimal liquidation problem.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 17:22:52 GMT""}]","2022-05-17"
"2205.07339","Debanjan Sengupta","Debanjan Sengupta, Paul R. Estrada, Jeffrey N. Cuzzi and Munir Humayun","Depletion of Moderately Volatile Elements by Open-System loss in the
  Early Solar Nebula","35 pages, 16 figures, Accepted for publication in The Astrophysical
  Journal",,"10.3847/1538-4357/ac6dcc",,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Rocky bodies of the inner solar system display a systematic depletion of the
""Moderately Volatile Elements"" (MVEs) that correlates with the expected
condensation temperature of their likely host materials under protoplanetary
nebula conditions. In this paper, we present and test a new hypothesis in which
open system loss processes irreversibly remove vaporized MVEs from high nebula
altitudes, leaving behind the more refractory solids residing much closer to
the midplane. The MVEs irreversibly lost from the nebula through these open
system loss processes are then simply unavailable for condensation onto
planetesimals forming even much later, after the nebula cooled, overcoming a
critical difficulty encountered by previous models of this type. We model open
system loss processes operating at high nebula altitudes, such as resulting
from disk winds flowing out of the system entirely, or layered accretion
directly onto the young sun. We find that mass loss rates higher than found in
typical T-Tauri disk winds, lasting short periods of time, are most
satisfactory, pointing to multiple intense early outburst stages. Using our
global nebula model, incorporating realistic particle growth and inward drift
for solids, we constrain how much the MVE depletion signature in the inner
region is diluted by the drift of undepleted material from the outer nebula. We
also find that a significant irreversible loss of the common rock-forming
elements (Fe, Mg, Si) can occur, leading to a new explanation of another
longstanding puzzle of the apparent ""enhancement"" in the relative abundance of
highly refractory elements in chondrites.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 17:28:00 GMT""}]","2022-06-29"
"2205.07340","Koyal Samantaray","Koyal Suman Samantaray, Ruhul Amin, Saniya Ayaz, A. K. Pathak,
  Christopher Hanley, A. Mekki, K. Harrabi, Somaditya Sen","Room Temperature Magneto-dielectric coupling in the CaMnO3 modified NBT
  lead-free ceramics",,,,,"cond-mat.mtrl-sci physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The sol-gel prepared (1-x) Na0.5Bi0.5TiO3- (x) CaMnO3 (x=0, 0.03, 0.06, 0.12)
compositions show a Rhombohedral (R3c) phase for x=0.06 while a mixed
Rhombohedral (R3c) and orthorhombic (Pnma) phases for the x=0.12. The lattice
volume consistently decreased with an increase in the CaMnO3 content. The phase
transition temperature (Tc) decreased with an increase in the CaMnO3
compositions. The room temperature dielectric constant increased, and loss
decreased for the x=0.03 composition due to a decrease in the oxygen vacancy
and Bi loss confirmed by the valence state study (XPS). All the compositions
show a variation of the room temperature dielectric property with an
application of magnetic field confirming a magnetodielectric coupling. The
x=0.06 composition shows the highest negative magnetodielectric constant (MD%)
of 3.69 at 100kHz at an applied field of 5 kG.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 17:28:56 GMT""}]","2022-05-17"
"2205.07341","Ariel Zandivarez","Ariel Zandivarez, Eugenia Diaz-Gimenez, Antonela Taverna (OAC/UNC -
  IATE/CONICET/UNC)","The influence of Hickson-like compact group environment on galaxy
  luminosities","20 pages, 10 figures, 5 tables, accepted for publication in MNRAS",,"10.1093/mnras/stac1374",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Compact groups of galaxies are devised as extreme environments where
interactions may drive galaxy evolution. In this work, we analysed whether the
luminosities of galaxies inhabiting compact groups differ from those of
galaxies in loose galaxy groups. We computed the luminosity functions of galaxy
populations inhabiting a new sample of 1412 Hickson-like compact groups of
galaxies identified in the Sloan Digital Sky Survey Data Release 16. We
observed a characteristic absolute magnitude for galaxies in compact groups
brighter than that observed in the field or loose galaxy systems. We also
observed a deficiency of faint galaxies in compact groups in comparison with
loose systems. Our analysis showed that the brightening is mainly due to
galaxies inhabiting the more massive compact groups. In contrast to what is
observed in loose systems where only the luminosities of Red (and Early)
galaxies show a dependency with group mass, luminosities of Red and Blue (also
Early and Late) galaxies in compact groups are affected similarly as a function
of group virial mass. When using Hubble types, we observed that Elliptical
galaxies in compact groups are the brightest galaxy population, and groups
dominated by an Elliptical galaxy also display the brightest luminosities in
comparison with those dominated by Spiral galaxies. Moreover, we show that the
general luminosity trends can be reproduced using a mock catalogue obtained
from a semi-analytical model of galaxy formation. These results suggest that
the inner extreme environment in compact groups prompts a different
evolutionary history for their galaxies.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 17:31:53 GMT""}]","2022-05-25"
"2205.07342","Thomas Greber J","R. Stania, A.P. Seitsonen, H.Y. Jung, D. Kunhardt, B. Buchner, A.A.
  Popov, M. Muntwiler, and T. Greber","Temperature induced change of conformation of Sc2TbN@C80 on h-BN/Ni(111)","7 pages 6 figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The conformation of molecules on surfaces is decisive for their
functionality. For the case of the endofullerene paramagnet Sc2TbN@C80 the
conformation is linked to an electric and a magnetic dipole moment. Therefore a
workfunction change of a substrate with adsorbed molecules, qualifies the
system to be magnetoelectric. One monolayer of Sc2TbN@C80 has been studied on
h-BN/Ni(111). The molecules assume a hexagonally close packed lattice aligned
with the substrate high symmetry directions. The structure is incommensurate
and arranges at a periodicity of about 4.3x4.3 substrate unit cells. At low
temperatures a (2 x 2) superstructure is observed. Angular resolved valence
band photoemission spectroscopy shows a temperature induced 0.3 eV shift on the
C80 molecular orbitals to lower binding energies that is parallel to a
workfunction increase. From comparison of the molecular orbital angular
photoemission intensity distributions it is conjectured that the molecules
undergo a change in conformation between 30 and 300 K. This phase transition is
centred at 125 K as observed with high resolution x-ray photoelectron
spectroscopy that shows the core levels of the atomic species on the molecules
to shift parallel to the workfunction. The temperature dependence of the
workfunction can be described with a two level model that accounts for the
disordering with an excitation energy of 60 meV into a highly degenerate
ensemble. The experimental findings are backed by density functional theory
calculations for the diamagnetic sibling of Sc2TbN@C80 : Sc2YN@C80 that
rationalize the incommensurate structure, show a permanent dipole moment of
Sc2YN@C80 and a relation between the workfunction and the orientation of the
endohedral cluster.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 17:33:21 GMT""}]","2022-05-17"
"2205.07343","Hengxin Tan","Hengxin Tan, Daniel Kaplan, Binghai Yan","Momentum-inversion symmetry breaking on the Fermi surface of magnetic
  topological insulators","4 pages, 3 figures","Phys. Rev. Materials 6, 104204 (2022)","10.1103/PhysRevMaterials.6.104204",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Magnetic topological insulators (MnBi$_2$Te$_4$)(Bi$_2$Te$_3$)$_n$ were
anticipated to exhibit magnetic energy gaps while recent spectroscopic studies
did not observe them. Thus, magnetism on the surface is under debate. In this
work, we propose another symmetry criterion to probe the surface magnetism.
Because of both time-reversal symmetry-breaking and inversion
symmetry-breaking, we demonstrate that the surface band structure violates
momentum-inversion symmetry and leads to a three-fold rather than six-fold
rotational symmetry on the Fermi surface if corresponding surface states couple
strongly to the surface magnetism. Such a momentum-inversion symmetry violation
is significant along the $\Gamma-K$ direction for surface bands on the (0001)
plane.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 17:34:44 GMT""}]","2022-10-31"
"2205.07344","Yue Wang","Yue Wang, Shaofeng Zou","Policy Gradient Method For Robust Reinforcement Learning","Accepted by ICML 2022",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  This paper develops the first policy gradient method with global optimality
guarantee and complexity analysis for robust reinforcement learning under model
mismatch. Robust reinforcement learning is to learn a policy robust to model
mismatch between simulator and real environment. We first develop the robust
policy (sub-)gradient, which is applicable for any differentiable parametric
policy class. We show that the proposed robust policy gradient method converges
to the global optimum asymptotically under direct policy parameterization. We
further develop a smoothed robust policy gradient method and show that to
achieve an $\epsilon$-global optimum, the complexity is $\mathcal
O(\epsilon^{-3})$. We then extend our methodology to the general model-free
setting and design the robust actor-critic method with differentiable
parametric policy class and value function. We further characterize its
asymptotic convergence and sample complexity under the tabular setting.
Finally, we provide simulation results to demonstrate the robustness of our
methods.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 17:35:17 GMT""}]","2022-05-17"
"2205.07345","Tien Mai","Ngan Ha Duong and Tien Thanh Dam and Thuy Anh Ta and Tien Mai","Joint Location and Cost Planning in Maximum Capture Facility Location
  under Multiplicative Random Utility Maximization",,,,,"math.OC econ.EM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a joint facility location and cost planning problem in a competitive
market under random utility maximization (RUM) models. The objective is to
locate new facilities and make decisions on the costs (or budgets) to spend on
the new facilities, aiming to maximize an expected captured customer demand,
assuming that customers choose a facility among all available facilities
according to a RUM model. We examine two RUM frameworks in the discrete choice
literature, namely, the additive and multiplicative RUM. While the former has
been widely used in facility location problems, we are the first to explore the
latter in the context. We numerically show that the two RUM frameworks can well
approximate each other in the context of the cost optimization problem. In
addition, we show that, under the additive RUM framework, the resultant cost
optimization problem becomes highly non-convex and may have several local
optima. In contrast, the use of the multiplicative RUM brings several
advantages to the competitive facility location problem. For instance, the cost
optimization problem under the multiplicative RUM can be solved efficiently by
a general convex optimization solver or can be reformulated as a conic
quadratic program and handled by a conic solver available in some off-the-shelf
solvers such as CPLEX or GUROBI. Furthermore, we consider a joint location and
cost optimization problem under the multiplicative RUM and propose three
approaches to solve the problem, namely, an equivalent conic reformulation, a
multi-cut outer-approximation algorithm, and a local search heuristic. We
provide numerical experiments based on synthetic instances of various sizes to
evaluate the performances of the proposed algorithms in solving the cost
optimization, and the joint location and cost optimization problems.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 17:45:38 GMT""},{""version"":""v2"",""created"":""Sat, 11 Feb 2023 17:20:42 GMT""}]","2023-02-14"
"2205.07346","Mladen Kova\v{c}evi\'c","Mladen Kova\v{c}evi\'c and Dejan Vukobratovi\'c","Optimal Error-Detecting Codes for General Asymmetric Channels via
  Sperner Theory","To be presented at the IEEE Information Theory Workshop (ITW),
  Mumbai, India, Nov. 2022",,"10.1109/ITW54588.2022.9965829",,"cs.IT cs.DM math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Several communication models that are of relevance in practice are asymmetric
in the way they act on the transmitted ""objects"". Examples include channels in
which the amplitudes of the transmitted pulses can only be decreased, channels
in which the symbols can only be deleted, channels in which non-zero symbols
can only be shifted to the right (e.g., timing channels), subspace channels in
which the dimension of the transmitted vector space can only be reduced,
unordered storage channels in which the cardinality of the stored (multi)set
can only be reduced, etc. We introduce a formal definition of an asymmetric
channel as a channel whose action induces a partial order on the set of all
possible inputs, and show that this definition captures all the above examples.
Such a general approach allows one to treat all these different models in a
unified way, and to obtain a characterization of optimal error-detecting codes
for many interesting asymmetric channels by using Sperner theory.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 17:48:21 GMT""},{""version"":""v2"",""created"":""Mon, 15 Aug 2022 16:18:46 GMT""}]","2022-12-29"
"2205.07347","Utkarsh R. Patel","Utkarsh R. Patel, Yiqian Mao, and Eric Michielssen","Wigner-Smith Time Delay Matrix for Acoustic Scattering: Theory and
  Phenomenology","Submitted to The Journal of Acoustical Society of America",,"10.1121/10.0017826",,"cs.CE","http://creativecommons.org/publicdomain/zero/1.0/","  The Wigner-Smith (WS) time delay matrix relates a lossless system's
scattering matrix to its frequency derivative. First proposed in the realm of
quantum mechanics to characterize time delays experienced by particles during a
collision, this article extends the use of WS time delay techniques to acoustic
scattering problems governed by the Helmholtz equation. Expression for the
entries of the WS time delay matrix involving renormalized volume integrals of
energy densities are derived, and shown to hold true independent of the
scatterer's geometry, boundary condition (sound-soft or sound-hard), and
excitation. Numerical examples show that the eigenmodes of the WS time delay
matrix describe distinct scattering phenomena characterized by well-defined
time delays.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 18:02:07 GMT""}]","2023-05-17"
"2205.07348","Ghalib Tahir","Ghalib Ahmed, Tahir Chu, Kiong Loo","Novel Multicolumn Kernel Extreme Learning Machine for Food Detection via
  Optimal Features from CNN",,,,,"cs.CV cs.LG eess.IV","http://creativecommons.org/licenses/by/4.0/","  Automatic food detection is an emerging topic of interest due to its wide
array of applications ranging from detecting food images on social media
platforms to filtering non-food photos from the users in dietary assessment
apps. Recently, during the COVID-19 pandemic, it has facilitated enforcing an
eating ban by automatically detecting eating activities from cameras in public
places. Therefore, to tackle the challenge of recognizing food images with high
accuracy, we proposed the idea of a hybrid framework for extracting and
selecting optimal features from an efficient neural network. There on, a
nonlinear classifier is employed to discriminate between linearly inseparable
feature vectors with great precision. In line with this idea, our method
extracts features from MobileNetV3, selects an optimal subset of attributes by
using Shapley Additive exPlanations (SHAP) values, and exploits kernel extreme
learning machine (KELM) due to its nonlinear decision boundary and good
generalization ability. However, KELM suffers from the 'curse of dimensionality
problem' for large datasets due to the complex computation of kernel matrix
with large numbers of hidden nodes. We solved this problem by proposing a novel
multicolumn kernel extreme learning machine (MCKELM) which exploited the k-d
tree algorithm to divide data into N subsets and trains separate KELM on each
subset of data. Then, the method incorporates KELM classifiers into parallel
structures and selects the top k nearest subsets during testing by using the
k-d tree search for classifying input instead of the whole network. For
evaluating a proposed framework large food/non-food dataset is prepared using
nine publically available datasets. Experimental results showed the superiority
of our method on an integrated set of measures while solving the problem of
'curse of dimensionality in KELM for large datasets.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 18:07:43 GMT""}]","2022-05-17"
"2205.07349","Rohini Ramadas","Rohini Ramadas","Moduli spaces of quadratic maps: arithmetic and geometry","6 pages, 2 figures, comments welcome",,,,"math.DS math.AG math.NT","http://creativecommons.org/licenses/by/4.0/","  We establish an implication between two long-standing open problems in
complex dynamics. The roots of the $n$-th Gleason polynomial
$G_n\in\mathbb{Q}[c]$ comprise the $0$-dimensional moduli space of quadratic
polynomials with an $n$-periodic critical point. $\mathrm{Per}_n(0)$ is the
$1$-dimensional moduli space of quadratic rational maps on $\mathbb{P}^1$ with
an $n$-periodic critical point. We show that if $G_n$ is irreducible over
$\mathbb{Q}$, then $\mathrm{Per}_n(0)$ is irreducible over $\mathbb{C}$. To do
this, we exhibit a $\mathbb{Q}$-rational smooth point on a projective
completion of $\mathrm{Per}_n(0)$, using the admissible covers completion of a
Hurwitz space. In contrast, the Uniform Boundedness Conjecture in arithmetic
dynamics would imply that for sufficiently large $n$, $\mathrm{Per}_n(0)$
itself has no $\mathbb{Q}$-rational points.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 18:20:36 GMT""}]","2022-05-17"
"2205.07350","Fernando Cornet-Gomez","Francisco J. Botella, Fernando Cornet-Gomez, Carlos Mir\'o and Miguel
  Nebot","Leptonic $g-2$ in 2HDM","Contribution to the 2022 Electroweak session of the 56th Rencontres
  de Moriond",,,,"hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  The experimental observations of the electron and muon anomalous magnetic
moment present discrepancies with respect to the Standard Model predictions. A
class of flavor conserving Two Higgs Doublet model, stable under
renormalization, that is capable of explaining both anomalies simultaneously is
presented. This model can also explain an excess observed by ATLAS in
$\sigma(pp\to S)_{[\text{ggF}]}\times \text{Br}(S\to\tau^+\tau^-)$.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 18:20:41 GMT""}]","2022-05-17"
"2205.07351","Antti K\""aenm\""aki","Antti K\""aenm\""aki and Petteri Nissinen","Non-invertible planar self-affine sets","16 pages",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We compare the dimension of a non-invertible self-affine set to the dimension
of the respective invertible self-affine set. In particular, for generic planar
self-affine sets, we show that the dimensions coincide when they are large and
differ when they are small. Our study relies on thermodynamical formalism
where, for dominated and irreducible matrices, we completely characterize the
behavior of the pressures.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 18:29:06 GMT""}]","2022-05-17"
"2205.07352","Ramya Ramakrishnan","Ramya Ramakrishnan, Hashan Buddhika Narangodage, Mauro Schilman,
  Kilian Q. Weinberger, Ryan McDonald","Long-term Control for Dialogue Generation: Methods and Evaluation",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Current approaches for controlling dialogue response generation are primarily
focused on high-level attributes like style, sentiment, or topic. In this work,
we focus on constrained long-term dialogue generation, which involves more
fine-grained control and requires a given set of control words to appear in
generated responses. This setting requires a model to not only consider the
generation of these control words in the immediate context, but also produce
utterances that will encourage the generation of the words at some time in the
(possibly distant) future. We define the problem of constrained long-term
control for dialogue generation, identify gaps in current methods for
evaluation, and propose new metrics that better measure long-term control. We
also propose a retrieval-augmented method that improves performance of
long-term controlled generation via logit modification techniques. We show
through experiments on three task-oriented dialogue datasets that our metrics
better assess dialogue control relative to current alternatives and that our
method outperforms state-of-the-art constrained generation baselines.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 18:33:37 GMT""}]","2022-05-17"
"2205.07353","Stefan Sandner","Stefan Sandner","Unstable Neutrinos can Relax Cosmological Mass Bounds","Contribution to the 2022 EW session of the 56th Rencontres de Moriond",,,,"hep-ph astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  The light neutrino masses are at present most stringently constraint via
cosmological probes. In particular the Planck collaboration reports $ \sum
m_\nu \leq 0.12\,\mathrm{eV}$ at $95\%$ CL within the standard cosmological
model. This is more than one order of magnitude stronger than the one arising
from laboratory searches. The cosmological bound taken at face value excludes a
plethora of neutrino flavour models which can successfully explain the neutrino
oscillation data. The indirect nature of the cosmological bound, however,
allows to relax the bound to up to $ \sum m_\nu \sim 1\,\mathrm{eV}$ if
neutrinos decay on timescales shorter than the age of the Universe, $\tau_\nu
\leq t_U$. We present how a decay of the type $\nu_i\to\nu_4\phi$ can be
realized within general models of the minimal extended seesaw framework. The
idea is then explicitly realized within the context of a $U(1)_{\mu-\tau}$
flavour model.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 18:37:32 GMT""}]","2022-05-17"
"2205.07354","Yihang Zeng","Yihang Zeng, Zhengchao Xia, Roei Dery, Kenji Watanabe, Takashi
  Taniguchi, Jie Shan, Kin Fai Mak","Exciton density waves in Coulomb-coupled dual moir\'e lattices",,"Nature Materials 2023","10.1038/s41563-022-01454-4",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Strongly correlated bosons in a lattice are a platform to realize rich
bosonic states of matter and quantum phase transitions. While strongly
correlated bosons in a lattice have been studied in cold-atom experiments,
their realization in a solid-state system has remained challenging. Here we
trap interlayer excitons--bosons composed of bound electron-hole pairs--in a
lattice provided by an angle-aligned WS2/bilayer WSe2/WS2 multilayer; the
heterostructure supports Coulomb-coupled triangular moir\'e lattices of nearly
identical period at the top and bottom interfaces. We observe correlated
insulating states when the combined electron filling factor of the two
lattices, with arbitrary partitions, equals to 1/3,2/3,4/3 and 5/3. These new
states can be interpreted as exciton density waves in a Bose-Fermi mixture of
excitons and holes. Because of the strong repulsive interactions between the
constituents, the holes form robust generalized Wigner crystals , which
restrict the exciton fluid to channels that spontaneously break the
translational symmetry of the lattice. Our results demonstrate that
Coulomb-coupled moir\'e lattices are fertile ground for correlated many-boson
phenomena.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 18:38:22 GMT""}]","2023-05-09"
"2205.07355","Hui Xia","Yongxin Wu and Hui Xia","Pinning-depinning transitions in two classes of discrete elastic-string
  models in (2+1)-dimensions",,,,,"cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  The pinning-depinning phase transitions of interfaces for two classes of
discrete elastic-string models are inverstigated numerically. In the
(1+1)-dimensions, we revisit these two elastic-string models with slight
modification on growth rule, and compare with the previous numerical results.
In the (2+1)-dimensional case, we perform extensive simulations on
pinning-depinning transitions in these quenched models. For full comparisons in
the physically relevant spatial dimensions, we also visit numerically two
distinct quenched universality classes, including the quenched
Edwards-Wilkinson (QEW) and the quenched Kardar-Parisi-Zhang (QKPZ) equations
with and without external driving forces. The critical exponents of these
quenched systems are numerically estimated. Our results show that the critical
exponents satisfy scaling relations well, and these two discrete elastic-string
models do not fall into the existing universality classes. In order to visually
comparisons of these quenched systems in (2+1)-dimensional cases, we also
exhibit surface morphologies with various external driving forces during the
saturated time regimes.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 18:39:16 GMT""},{""version"":""v2"",""created"":""Wed, 6 Jul 2022 09:42:30 GMT""}]","2022-07-07"
"2205.07356","Conor Rosato","Conor Rosato, John Harris, Jasmina Panovska-Griffiths, Simon Maskell","Inference of Stochastic Disease Transmission Models Using Particle-MCMC
  and a Gradient Based Proposal","FUSION 2022: 25th International Conference on Information Fusion
  (FUSION 2022), 8 Pages, 16 images",,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  State-space models have been widely used to model the dynamics of
communicable diseases in populations of interest by fitting to time-series
data. Particle filters have enabled these models to incorporate stochasticity
and so can better reflect the true nature of population behaviours. Relevant
parameters such as the spread of the disease, $R_t$, and recovery rates can be
inferred using Particle MCMC. The standard method uses a Metropolis-Hastings
random-walk proposal which can struggle to reach the stationary distribution in
a reasonable time when there are multiple parameters.
  In this paper we obtain full Bayesian parameter estimations using gradient
information and the No U-Turn Sampler (NUTS) when proposing new parameters of
stochastic non-linear Susceptible-Exposed-Infected-Recovered (SEIR) and SIR
models. Although NUTS makes more than one target evaluation per iteration, we
show that it can provide more accurate estimates in a shorter run time than
Metropolis-Hastings.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 18:45:21 GMT""}]","2022-05-17"
"2205.07357","Mao Zeng","Fernando Febres Cordero, Manfred Kraus, Guanda Lin, Michael S. Ruf,
  Mao Zeng","Conservative Binary Dynamics with a Spinning Black Hole at
  $\mathcal{O}(G^3)$ from Scattering Amplitudes","6 pages + references + supplementary material, 1 figure","Phys. Rev. Lett. 130 (2023), 021601","10.1103/PhysRevLett.130.021601",,"hep-th hep-ph","http://creativecommons.org/licenses/by/4.0/","  We compute the conservative two-body Hamiltonian of a compact binary system
with a spinning black hole through $\mathcal{O}(G^3)$ to all orders in
velocity, including linear and quadratic spin terms. To obtain our results we
calculate the classical limit of the two-loop amplitude for the scattering of a
massive scalar particle with a massive spin-1 particle minimally coupled to
gravity. We employ modern scattering amplitude and loop integration techniques,
in particular numerical unitarity, integration-by-parts identities, and the
method of regions. The conservative potential in terms of rest-frame spin
vectors is extracted by matching to a non-relativistic effective field theory.
We also apply the Kosower-Maybee-O'Connell (KMOC) formalism to calculate the
impulse in the covariant spin formalism directly from the amplitude. We work
systematically in conventional dimensional regularization and explicitly
evaluate all divergent integrals that appear in full- and effective-theory
amplitudes, as well as in the phase-space integrals that arise in the KMOC
formalism.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 18:46:18 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jun 2023 11:28:42 GMT""}]","2023-06-08"
"2205.07358","Nikita Moriakov","Nikita Moriakov, Jan-Jakob Sonke, Jonas Teuwen","LIRE: Learned Invertible Reconstruction for Cone Beam CT",,,,,"physics.med-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cone Beam CT (CBCT) is a crucial imaging modality in many fields in medicine.
However, its potential is not fully utilized due to the generally lower imaging
quality than conventional CT, and accurate reconstructions are still a
challenging task. Reconstruction methods relying on deep learning have
attracted a lot of attention recently due to their promising performance for a
variety of medical imaging modalities. There are, however, issues that preclude
direct application of such methods to CBCT in practice. Firstly, deep learning
reconstruction methods become prohibitively memory expensive when working with
fully 3D data such as CBCT. Secondly, deep learning reconstruction methods are
widely criticised for being trained and evaluated on data from a specific
region of interest such as thorax, raising concerns about generalization to
other organs. In this work, we aim to address these shortcomings and propose
LIRE: a fully learned, partially invertible primal-dual iterative scheme for
Cone Beam CT reconstruction. We drastically reduce memory footprint of the
network without sacrificing expressive power by combining reversible residual
primal-dual blocks together with patch-wise computations inside the blocks,
which allows us to train using clinically-relevant resolutions and projection
counts on current consumer hardware. The models are trained on thorax CT scans
and tested using both thorax CT and head \& neck CT data. We demonstrate that
LIRE outperforms the classical methods and the deep learning baseline on both
test sets.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 19:06:24 GMT""}]","2022-05-17"
"2205.07359","Simone Ciani","Simone Ciani, Umberto Guarnotta, Vincenzo Vespri","On a particular scaling for the prototype anisotropic p-Laplacian","13 pages",,,,"math.AP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this brief note we show that under a volume non-preserving scaling it is
possible to recover the basics for a regularity theory regarding local weak
solutions to a parabolic fully anisotropic equation. We characterize
self-similar solutions regarding this particular scaling and we show that
semi-continuity for solutions to this equation is a consequence of a simple
property that is itself invariant under scaling.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 19:10:33 GMT""}]","2022-05-17"
"2205.07360","Aur\'elien Desoeuvres","Aur\'elien Desoeuvres, Peter Szmolyan, Ovidiu Radulescu","Qualitative dynamics of chemical reaction networks: an investigation
  using partial tropical equilibrations","23 pages, 5 figures, submitted to CMSB 2022",,,,"q-bio.MN cs.SC math.DS","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We discuss a method to describe the qualitative dynamics of chemical reaction
networks in terms of symbolic dynamics. The method, that can be applied to
mass-action reaction networks with separated timescales, uses solutions of the
partial tropical equilibration problem as proxies for symbolic states. The
partial tropical equilibration solutions are found algorithmically. These
solutions also provide the scaling needed for slow-fast decomposition and model
reduction. Any trace of the model can thus be represented as a sequence of
local approximations of the full model. We illustrate the method using as case
study a biochemical model of the cell cycle.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 19:19:33 GMT""}]","2022-05-17"
"2205.07361","Runze Li","Xu Guo, Runze Li, Zhe Zhang and Changliang Zou","Model-Free Statistical Inference on High-Dimensional Data",,,,,"stat.ME","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper aims to develop an effective model-free inference procedure for
high-dimensional data. We first reformulate the hypothesis testing problem via
sufficient dimension reduction framework. With the aid of new reformulation, we
propose a new test statistic and show that its asymptotic distribution is
$\chi^2$ distribution whose degree of freedom does not depend on the unknown
population distribution. We further conduct power analysis under local
alternative hypotheses. In addition, we study how to control the false
discovery rate of the proposed $\chi^2$ tests, which are correlated, to
identify important predictors under a model-free framework. To this end, we
propose a multiple testing procedure and establish its theoretical guarantees.
Monte Carlo simulation studies are conducted to assess the performance of the
proposed tests and an empirical analysis of a real-world data set is used to
illustrate the proposed methodology.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 19:20:28 GMT""}]","2022-05-17"
"2205.07362","Lek-Heng Lim","Lek-Heng Lim and Bradley J. Nelson","What is an equivariant neural network?","8 pages, 3 figure",,,,"cs.LG math.RT stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explain equivariant neural networks, a notion underlying breakthroughs in
machine learning from deep convolutional neural networks for computer vision to
AlphaFold 2 for protein structure prediction, without assuming knowledge of
equivariance or neural networks. The basic mathematical ideas are simple but
are often obscured by engineering complications that come with practical
realizations. We extract and focus on the mathematical aspects, and limit
ourselves to a cursory treatment of the engineering issues at the end.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 19:24:12 GMT""},{""version"":""v2"",""created"":""Wed, 16 Nov 2022 20:27:36 GMT""}]","2022-11-18"
"2205.07363","Ruben Campos Delgado","Andrei Ioan Dogaru, Ruben Campos Delgado","Cylinder quantum field theories at small coupling","14 pages; v3: added new sections and comments, corrected typos",,"10.1007/JHEP10(2022)110",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  We show that any 2D scalar field theory compactified on a cylinder and with a
Fourier expandable potential $V$ is equivalent, in the small coupling limit, to
a 1D theory involving a massless particle in a potential $V$ and an infinite
tower of free massive Kaluza-Klein (KK) modes. Moving slightly away from the
deep IR region has the effect of switching on interactions between the zero
mode and the KK modes, whose strength is controlled by powers of the coupling,
hence making the interactions increasingly suppressed. We take the notable
example of Liouville field theory and, starting from its worldline version, we
compute the torus (one-loop) partition function perturbatively in the coupling
constant. The partition function at leading order is invariant under a
T-duality transformation that maps the radius of the cylinder to its inverse
and rescales it by the square of the Schwinger parameter of the cylinder. We
show that this behavior is a universal feature of cylinder QFTs.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 19:29:46 GMT""},{""version"":""v2"",""created"":""Mon, 15 Aug 2022 13:08:05 GMT""},{""version"":""v3"",""created"":""Mon, 26 Sep 2022 15:46:49 GMT""}]","2022-12-20"
"2205.07364","Viacheslav Bunichev","E. E. Boos, V. E. Bunichev, and S. S. Trykov","Prospects for Dark Matter Search at the Super c-tau Factory","6 pages, 7 figures",,"10.1103/PhysRevD.107.075021",,"hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  We present perspectives for searching for light dark matter production
mediated by a leptophilic scalar {\phi} and a dark photon A' in in experiments
at the Super c-tau Factory. Based on the analysis of the associative production
of mediators and {\tau} -leptons at the energies of the future collider, the
possibility of searching in the non-excluded region of the parameter space was
found. The obtained sensitivity curves at the 90% C.L. for the mediators mass
range below 4 GeV demonstrate the power of the SCTF for light dark matter
search.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 19:40:54 GMT""},{""version"":""v2"",""created"":""Sat, 13 Aug 2022 18:53:30 GMT""}]","2023-05-03"
"2205.07365","Thomas Liz\'ee","T. Liz\'ee, B. Vollmer, J. Braine, P. Gratier, F. Bigiel","Predicting HCN, HCO + , multi-transition CO, and dust emission of
  star-forming galaxies: Constraining the properties of resolved gas and dust
  disks of local spiral galaxies","22 pages, 10 figures (without appendix) 44 pages, 27 figures","A&A 663, A152 (2022)","10.1051/0004-6361/202142480",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ISM is a turbulent, multi-phase, and multi-scale medium following scaling
relations. Analytical models of galactic gaseous disks need to take into
account the multi-scale and multi-phase nature of the interstellar medium. They
can be described as clumpy star-forming accretion disks in vertical hydrostatic
equilibrium, with the mid-plane pressure balancing the gravity of the gaseous
and stellar disk. ISM turbulence is taken into account by applying Galactic
scaling relations to the cold atomic and molecular gas phases. Turbulence is
maintained through energy injection by supernovae. With the determination of
the gas mass fraction at a given spatial scale, the equilibrium gas temperature
between turbulent heating and line cooling, the molecular abundances, and the
molecular line emission can be calculated. The resulting model radial profiles
of IR, H{\sc i}, CO, HCN, and HCO$^+$ emission are compared to THINGS,
HERACLES, EMPIRE, SINGS, and GALEX observations of 17 local spiral galaxies.
The Toomre parameter, which measures the stability against star formation
(cloud collapse), exceeds unity in the inner disk of a significant number of
galaxies. In two galaxies it also exceeds unity in the outer disk. Therefore,
in spiral galaxies $Q_{\rm tot}=1$ is not ubiquitous. The model gas velocity
dispersion is consistent with the observed H{\sc i} velocity dispersion where
available. Within our model HCN and HCO$^+$ is already detectable in relatively
low-density gas ($\sim 1000$~cm$^{-3}$). CO and HCN conversion factors and
molecular gas depletion time were derived. Both conversion factors are
consistent with values found in the literature. Whereas in the massive galaxies
the viscous timescale greatly exceeds the star formation timescale, the viscous
timescale is smaller than the star formation timescale within
$\rm{R}~\sim~2~\rm{R}_{\rm d}$, the disk scale length, in the low-mass
galaxies.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 19:41:18 GMT""}]","2022-07-27"
"2205.07366","Masaru Nakanotani","M. Nakanotani, G. P. Zank, L.-L. Zhao","Particle acceleration in an MHD-scale system of multiple current sheets","25 pages, 10 figures, to be submitted to frontiers","Frontiers in Astronomy and Space Sciences, 9 (2022)","10.3389/fspas.2022.954040",,"physics.space-ph physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate particle acceleration in an MHD-scale system of multiple
current sheets by performing 2D and 3D MHD simulations combined with a test
particle simulation. The system is unstable for the tearing-mode instability,
and magnetic islands are produced by magnetic reconnection. Due to the
interaction of magnetic islands, the system turns into a turbulent state. The
2D (3D) case yields both $-5/3$ ($-11/3$ and $-7/3$) power-law spacetra for
magnetic and velocity fluctuations. Particles are efficiently energized by the
generated turbulence, and it forms a power-law tail with an index of $-2.2$ and
$-4.2$ in the energy distribution function for the 2D and 3D case,
respectively. We find more energetic particles outside magnetic islands rather
than inside. We observe super-diffusion in the 2D ($\sim t^{2.27}$) and 3D
($\sim t^{1.2}$) case in the energy space of energetic particles.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 19:52:24 GMT""}]","2022-08-16"
"2205.07367","Quang To","D. Quang To, Zhengtianye Wang, Yongchen Liu, Weipeng Wu, M. Benjamin
  Jungfleisch, John Q. Xiao, Joshua M.O. Zide, Stephanie Law, and Matthew F.
  Doty","Surface plasmon-phonon-magnon polariton in a topological
  insulator-antiferromagnetic bilayer structure","16 pages, 12 figures","Phys. Rev. Materials 6, 085201 (2022)","10.1103/PhysRevMaterials.6.085201",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a robust technique for computationally studying surface polariton
modes in hybrid materials. We use a semi-classical model that allows us to
understand the physics behind the interactions between collective excitations
of the hybrid system and develop a scattering and transfer matrix method that
imposes the proper boundary conditions to solve Maxwell equations and derive a
general equation describing the surface polariton in a heterostructure
consisting of N constituent materials. We apply this method to a test structure
composed of a topological insulator (TI) and an antiferromagnetic material
(AFM) to study the resulting surface Dirac plasmon-phonon-magnon polariton
(DPPMP). We find that interactions between the excitations of the two
constituents result in the formation of hybridized modes and the emergence of
avoided-crossing points in the dispersion relations for the DPPMP. For the
specific case of a Bi2Se3 TI material, the polariton branch with low frequency
below 2 THz redshifts upon increasing the thickness of TI thin film, which
leads to an upper bound on the thickness of the TI layer that will allow an
observable signature of strong coupling and the emergence of hybridized states.
We also find that the strength of the coupling between the TI and the AFM,
which is parameterized by the amplitude of the avoided-crossing splitting
between the two polariton branches at the magnon resonance frequency, depends
on the magnitude of the magnetic dipole and the line width of the magnon in the
AFM material as well as on the Fermi energy of Dirac plasmon in the TI.
Finally, we predict that materials with extremely high quality, i.e. low
scattering loss rate, are essential to achieve an experimentally-observable
strong coupling between a TI and AFM.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 19:53:43 GMT""}]","2022-08-16"
"2205.07368","Peikai Li","Peikai Li and Ipek Ilayda Onur and Scott Dodelson and Shreyas
  Chaudhari","High-Resolution CMB Lensing Reconstruction with Deep Learning","11 pages, 9 figures",,,,"astro-ph.CO cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Next-generation cosmic microwave background (CMB) surveys are expected to
provide valuable information about the primordial universe by creating maps of
the mass along the line of sight. Traditional tools for creating these lensing
convergence maps include the quadratic estimator and the maximum likelihood
based iterative estimator. Here, we apply a generative adversarial network
(GAN) to reconstruct the lensing convergence field. We compare our results with
a previous deep learning approach -- Residual-UNet -- and discuss the pros and
cons of each. In the process, we use training sets generated by a variety of
power spectra, rather than the one used in testing the methods.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 19:58:39 GMT""}]","2022-05-17"
"2205.07369","The Anh Han","The Anh Han","Understanding Emergent Behaviours in Multi-Agent Systems with
  Evolutionary Game Theory",,,,,"cs.AI cs.MA math.DS nlin.AO","http://creativecommons.org/licenses/by/4.0/","  The mechanisms of emergence and evolution of collective behaviours in
dynamical Multi-Agent Systems (MAS) of multiple interacting agents, with
diverse behavioral strategies in co-presence, have been undergoing mathematical
study via Evolutionary Game Theory (EGT). Their systematic study also resorts
to agent-based modelling and simulation (ABM) techniques, thus enabling the
study of aforesaid mechanisms under a variety of conditions, parameters, and
alternative virtual games. This paper summarises some main research directions
and challenges tackled in our group, using methods from EGT and ABM. These
range from the introduction of cognitive and emotional mechanisms into agents'
implementation in an evolving MAS, to the cost-efficient interference for
promoting prosocial behaviours in complex networks, to the regulation and
governance of AI safety development ecology, and to the equilibrium analysis of
random evolutionary multi-player games. This brief aims to sensitize the reader
to EGT based issues, results and prospects, which are accruing in importance
for the modeling of minds with machines and the engineering of prosocial
behaviours in dynamical MAS, with impact on our understanding of the emergence
and stability of collective behaviours. In all cases, important open problems
in MAS research as viewed or prioritised by the group are described.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 20:01:48 GMT""}]","2022-05-17"
"2205.07370","John Farnsworth","Joseph C. Straccia and John A. N. Farnsworth (Ann and H.J. Smead
  Department of Aerospace Engineering Sciences, University of Colorado Boulder)","On the vortex dynamics of synthetic jet -- turbulent boundary layer
  interactions","50 pages, 36 figures, submitted to Journal of Fluid Mechanics",,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The vortex dynamics resulting from the interaction of synthetic jets with
turbulent boundary layers was investigated experimentally using stereoscopic
particle image velocimetry (SPIV). Three aspect ratio 18 rectangular orifice
geometries were tested including spanwise and streamwise-oriented orifices
issuing normal to the wall and a spanwise-oriented orifice pitched $45^\circ$
downstream. Additionally, three actuation conditions were tested to explore the
impact of varying blowing ratio and Strouhal number. SPIV data obtained on an
array of measurement planes was used to reconstruct the three-dimensional mean
and phase-locked velocity fields, enabling detailed analysis of the formation
and development of the vortices. The variations in the orifice geometry and the
flow conditions produced a range of vortex structures including distorted
vortex rings, hairpin vortices, and arch-shaped vortices. The jets from
wall-normal orifices were dominated by vortices that rotated in the same
direction as the boundary layer vorticity which enhanced the near-wall flow
velocity by increasing mixing. Conversely, the dominant structures in the
pitched jets rotated counter to the boundary layer vorticity, and these jets
enhanced the flow velocity near the wall through direct momentum addition. Flow
field analysis revealed that the synthetic jet-boundary layer interaction
caused pitched jets operated at low blowing ratios to produce dominant vortices
which were much weaker than those generated by wall-normal jets at the same
conditions. Finally, at the lowest Strouhal number tested the increased spacing
between the vortices in the wall-normal jets resulted in much higher unsteady
mixing than was observed at higher Strouhal numbers.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 20:06:38 GMT""}]","2022-05-17"
"2205.07371","Zhaofeng Lin","Zhaofeng Lin, Yanqi Qiu and Kai Wang","Truncations of random unitary matrices drawn from Hua-Pickrell
  distribution","20 pages",,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  Let $U$ be a random unitary matrix drawn from the Hua-Pickrell distribution
$\mu_{\mathrm{U}(n+m)}^{(\delta)}$ on the unitary group $\mathrm{U}(n+m)$. We
show that the eigenvalues of the truncated unitary matrix $[U_{i,j}]_{1\leq
i,j\leq n}$ form a determinantal point process $\mathscr{X}_n^{(m,\delta)}$ on
the unit disc $\mathbb{D}$ for any $\delta\in\mathbb{C}$ satisfying
$\mathrm{Re}\,\delta>-1/2$.
  We also prove that the limiting point process taken by $n\to\infty$ of the
determinantal point process $\mathscr{X}_n^{(m,\delta)}$ is always
$\mathscr{X}^{[m]}$, independent of $\delta$. Here $\mathscr{X}^{[m]}$ is the
determinantal point process on $\mathbb{D}$ with weighted Bergman kernel
\begin{equation*}
  \begin{split}
  K^{[m]}(z,w)=\frac{1}{(1-z\overline w)^{m+1}}
  \end{split} \end{equation*} with respect to the reference measure
$d\mu^{[m]}(z)=\frac{m}{\pi}(1-|z|)^{m-1}d\sigma(z)$, where $d\sigma(z)$ is the
Lebesgue measure on $\mathbb{D}$.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 20:06:55 GMT""}]","2022-05-17"
"2205.07372","Omobayode Fagbohungbe","Omobayode Fagbohungbe and Lijun Qian","Effect of Batch Normalization on Noise Resistant Property of Deep
  Learning Models",,,,,"cs.LG cs.AI cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The fast execution speed and energy efficiency of analog hardware has made
them a strong contender for deployment of deep learning model at the edge.
However, there are concerns about the presence of analog noise which causes
changes to the weight of the models, leading to performance degradation of deep
learning model, despite their inherent noise resistant characteristics. The
effect of the popular batch normalization layer on the noise resistant ability
of deep learning model is investigated in this work. This systematic study has
been carried out by first training different models with and without batch
normalization layer on CIFAR10 and CIFAR100 dataset. The weights of the
resulting models are then injected with analog noise and the performance of the
models on the test dataset is obtained and compared. The results show that the
presence of batch normalization layer negatively impacts noise resistant
property of deep learning model and the impact grows with the increase of the
number of batch normalization layers.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 20:10:21 GMT""}]","2022-05-17"
"2205.07373","Michael Dimitriyev","Xueyan Feng, Michael S. Dimitriyev, Edwin L. Thomas","Block Copolymer Double Diamond Twin","27 pages, 9 figures (contains SI)",,,,"cond-mat.soft cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  A twin boundary (TB) is a common low energy planar defect in crystals
including those with the atomic diamond structure (C, Si, Ge, etc.). We study
twins in a self-assembled soft matter block copolymer (BCP) supramolecular
crystal having the double diamond (DD) structure, consisting of 2
translationally shifted, interpenetrating diamond networks of the minority
polydimethyl siloxane block embedded in a polystyrene block matrix. The
coherent, low energy, mirror-symmetric double tubular network twin has one
minority block network with its nodes offset from the (222) TB plane while
nodes of the second network lie in the plane of the boundary. The offset
network, although at a scale about a factor of 103 larger, has precisely the
same geometry and symmetry as a (111) twin in atomic single diamond where the
tetrahedral units spanning the TB retain nearly the same strut (bond) lengths
and strut (bond) angles as in the normal unit cell. In the DD, the second
minority block network undergoes a dramatic restructuring - the tetrahedral
nodes transform into 2 new types of mirror-symmetric nodes (pentahedral and
trihedral) which alternate and link to form a hexagonal mesh in the plane of
the TB. The collective re-organization of the supramolecular packing highlights
the hierarchical structure of ordered BCP phases and emphasizes the remarkable
malleability of soft matter.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 20:23:41 GMT""}]","2022-05-17"
"2205.07374","Lukas Hergt","Lukas T. Hergt, Fruzsina J. Agocs, Will J. Handley, Michael P. Hobson,
  Anthony N. Lasenby","Finite inflation in curved space","46 pages, 32 figures, 3 tables, submitted to PRD, from chapter 5 of
  L. T. Hergt's doctoral thesis at
  https://www.repository.cam.ac.uk/handle/1810/323129, data available at
  https://zenodo.org/record/6547872",,"10.1103/PhysRevD.106.063529",,"astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the effects of non-zero spatial curvature on cosmic inflation
in the light of cosmic microwave background (CMB) anisotropy measurements from
the Planck 2018 legacy release and from the 2015 observing season of BICEP2 and
the Keck Array. Even a small percentage of non-zero curvature today would
significantly limit the total number of e-folds of the scale factor during
inflation, rendering just-enough inflation scenarios with a kinetically
dominated or fast-roll stage prior to slow-roll inflation more likely. Finite
inflation leads to oscillations and a cutoff towards large scales in the
primordial power spectrum and curvature pushes them into the CMB observable
window. Using nested sampling, we carry out Bayesian parameter estimations and
model comparisons taking into account constraints from reheating and horizon
considerations. We confirm the preference of CMB data for closed universes with
Bayesian odds of over $100:1$ and with a posterior on the curvature density
parameter of $\Omega_{K,0}=-0.051\pm0.017$ for a curvature extension of LCDM
and $\Omega_{K,0}=-0.031\pm0.014$ for Starobinsky inflation. Model comparisons
of various inflation models give similar results as for flat universes with the
Starobinsky model outperforming most other models.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 20:34:34 GMT""}]","2022-10-12"
"2205.07375","Alireza Mohammadi","Alireza Mohammadi, Mark W. Spong","Chetaev Instability Framework for Kinetostatic Compliance-Based Protein
  Unfolding","Accepted for Publication in IEEE Control Systems Letters (L-CSS)",,,,"eess.SY cs.SY math.OC q-bio.BM","http://creativecommons.org/licenses/by/4.0/","  Understanding the process of protein unfolding plays a crucial role in
various applications such as design of folding-based protein engines. Using the
well-established kinetostatic compliance (KCM)-based method for modeling of
protein conformation dynamics and a recent nonlinear control theoretic approach
to KCM-based protein folding, this paper formulates protein unfolding as a
destabilizing control analysis/synthesis problem. In light of this formulation,
it is shown that the Chetaev instability framework can be used to investigate
the KCM-based unfolding dynamics. In particular, a Chetaev function for
analysis of unfolding dynamics under the effect of optical tweezers and a class
of control Chetaev functions for synthesizing control inputs that elongate
protein strands from their folded conformations are presented. Based on the
presented control Chetaev function, an unfolding input is derived from the
Artstein-Sontag universal formula and the results are compared against optical
tweezer-based unfolding.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 20:34:36 GMT""}]","2022-05-17"
"2205.07376","Paulo  A. Faria da Veiga","Paulo A. Faria da Veiga and Michael O'Carroll","On Yang-Mills Stability Bounds and Plaquette Field Generating Function","30 pages. arXiv admin note: substantial text overlap with
  arXiv:2005.00899",,,,"math-ph hep-th math.MP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the Yang-Mills (YM) QFT with group $U(N)$. We take a finite
lattice regularization $\Lambda\subset a\mathbb Z^d$, $d = 2,3,4$, with $a\in
(0,1]$ and $L$ (even) sites on a side. Each bond has a gauge variable $U\in
U(N)$. The Wilson partition function is used and the action is a sum of
gauge-invariant plaquette (minimal square) actions times $a^{d-4}/g^2$,
$g^2\in(0,g_0^2]$, $0<g_0^2<\infty$. A plaquette action has the product of its
four variables and the partition function is the integral of the Boltzmann
factor with a product of $U(N)$ Haar measures. Formally, when $a\searrow 0$ our
action gives the usual YM continuum action. For free and periodic b.c., we show
thermodynamic and stability bounds for a normalized partition function of any
YM model defined as before, with bound constants independent of $L,a,g$. The
subsequential thermodynamic and ultraviolet limit of the free energy exist. To
get our bounds, the Weyl integration formula is used and, to obtain the lower
bound, a new quadratic global upper bound on the action is derived. We define
gauge-invariant physical and scaled plaquette fields. Using periodic b.c. and
the multi-reflection method, we bound the generating function of $r-$scaled
plaquette correlations. A normalized generating function for the correlations
of $r$ scaled fields is absolutely bounded, for any $L,a,g$, and location of
the external fields. From the joint analyticity on the field sources,
correlations are bounded. The bounds are new and we get $a^{-d}$ for the
physical two-plaquette correlation at coincident points. Comparing with the
$a\searrow 0$ singularity of the physical derivative massless scalar free field
two-point correlation, this is a measure of ultraviolet asymptotic freedom in
the context of a lattice QFT. Our methods are an alternative and complete the
more traditional ones.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 20:48:10 GMT""}]","2022-05-17"
"2205.07377","Alexei Morozov","V.Dolotin and A.Morozov","The Splendors and Miseries of Heavisidisation","16 pages",,,"ITEP/TH-09/22","hep-th cs.LG","http://creativecommons.org/publicdomain/zero/1.0/","  Machine Learning (ML) is applicable to scientific problems, i.e. to those
which have a well defined answer, only if this answer can be brought to a
peculiar form ${\cal G}: X\longrightarrow Z$ with ${\cal G}(\vec x)$ expressed
as a combination of iterated Heaviside functions. At present it is far from
obvious, if and when such representations exist, what are the obstacles and, if
they are absent, what are the ways to convert the known formulas into this
form. This gives rise to a program of reformulation of ordinary science in such
terms -- which sounds like a strong enhancement of the constructive mathematics
approach, only this time it concerns all natural sciences. We describe the
first steps on this long way.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 21:00:50 GMT""}]","2022-06-01"
"2205.07378","Xinkai Zhou","Xinkai Zhou, Eric C. Chi, Hua Zhou","Proximal MCMC for Bayesian Inference of Constrained and Regularized
  Estimation",,,,,"stat.ME","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper advocates proximal Markov Chain Monte Carlo (ProxMCMC) as a
flexible and general Bayesian inference framework for constrained or
regularized estimation. Originally introduced in the Bayesian imaging
literature, ProxMCMC employs the Moreau-Yosida envelope for a smooth
approximation of the total-variation regularization term, fixes nuisance and
regularization strength parameters as constants, and relies on the Langevin
algorithm for the posterior sampling. We extend ProxMCMC to the full Bayesian
framework with modeling and data adaptive estimation of all parameters
including the regularization strength parameter. More efficient sampling
algorithms such as the Hamiltonian Monte Carlo are employed to scale ProxMCMC
to high-dimensional problems. Analogous to the proximal algorithms in
optimization, ProxMCMC offers a versatile and modularized procedure for the
inference of constrained and non-smooth problems. The power of ProxMCMC is
illustrated on various statistical estimation and machine learning tasks. The
inference in these problems is traditionally considered difficult from both
frequentist and Bayesian perspectives.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 21:10:13 GMT""}]","2022-05-17"
"2205.07379","Alex Rigby","Dmitriy Malovichko and Alex Rigby","Description of seismic sources in underground mines: Dynamic stress
  fracturing around tunnels and strainbursting","40 pages, 24 figures",,,,"physics.geo-ph","http://creativecommons.org/licenses/by/4.0/","  This paper considers dynamic fracturing of the rockmass surrounding a tunnel
statically loaded by compressional stress as a possible source of seismic
events in underground mines. This begins with two-dimensional dynamic modelling
of failure for six plausible scenarios. In each case, the seismic source
derived from these models has significant negative isotropic and negative
compensated linear vector dipole components as well as a P-axis approximately
aligned with the direction of maximum compressional principal stress. These
features indicate that at wavelengths larger than the diameter of the tunnel
and the extent of damage along it, seismic radiation is controlled by the
elastic convergence of the surrounding rockmass rather than by rock fracturing.
An analytical approximation of the source mechanism is suggested that is based
solely on mechanical and geometric properties: the magnitudes
$\sigma_{\mathrm{max}}$ and $\sigma_{\mathrm{min}}$ of the maximum and minimum
principal stresses orthogonal to the tunnel's axis, the Poisson's ratio $\nu$
of the rockmass, the length $L_{3}$ of dynamic fracturing along the tunnel, the
effective tunnel dimension $\bar{L_{A}}$, and the increase in depth of failure
$\triangle d_{f}^{A}$ in the direction of $\sigma_{\mathrm{min}}$. Furthermore,
it is shown that the scalar seismic moment can be approximated as
$|\mathbf{M}|\approx2[(1-\nu)/(1-2\nu)]|\sigma_{max}|L_{3}\bar{L_{A}}\triangle
d_{f}^{A}$. The suggested approximations are considered in the context of
seismic data from a real underground mine. It is shown that many mechanisms
inverted from observed waveforms are consistent with the suggested model and
that the proposed source mechanism approximation can be used for the forensic
analysis of damaging seismic events and quantitative monitoring of the
evolution of fractured zones around tunnels.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 21:13:09 GMT""}]","2022-05-17"
"2205.07380","Jan Verschelde","Jan Verschelde and Kylash Viswanathan","Locating the Closest Singularity in a Polynomial Homotopy","Accepted for the Proceedings of the 24th International Workshop on
  Computer Algebra in Scientific Computing (CASC 2022)",,,,"cs.SC cs.NA math.AG math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A polynomial homotopy is a family of polynomial systems, where the systems in
the family depend on one parameter. If for one value of the parameter we know a
regular solution, then what is the nearest value of the parameter for which the
solution in the polynomial homotopy is singular? For this problem we apply the
ratio theorem of Fabry. Richardson extrapolation is effective to accelerate the
convergence of the ratios of the coefficients of the series expansions of the
solution paths defined by the homotopy. For numerical stability, we recondition
the homotopy. To compute the coefficients of the series we propose the
quaternion Fourier transform. We locate the closest singularity computing at a
regular solution, avoiding numerical difficulties near a singularity.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 21:13:10 GMT""},{""version"":""v2"",""created"":""Sun, 26 Jun 2022 01:49:58 GMT""}]","2022-06-28"
"2205.07381","Jingfeng Yang","Jingfeng Yang, Haoming Jiang, Qingyu Yin, Danqing Zhang, Bing Yin,
  Diyi Yang","SeqZero: Few-shot Compositional Semantic Parsing with Sequential Prompts
  and Zero-shot Models","12 pages, Findings of NAACL 2022",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Recent research showed promising results on combining pretrained language
models (LMs) with canonical utterance for few-shot semantic parsing. The
canonical utterance is often lengthy and complex due to the compositional
structure of formal languages. Learning to generate such canonical utterance
requires significant amount of data to reach high performance. Fine-tuning with
only few-shot samples, the LMs can easily forget pretrained knowledge, overfit
spurious biases, and suffer from compositionally out-of-distribution
generalization errors. To tackle these issues, we propose a novel few-shot
semantic parsing method -- SeqZero. SeqZero decomposes the problem into a
sequence of sub-problems, which correspond to the sub-clauses of the formal
language. Based on the decomposition, the LMs only need to generate short
answers using prompts for predicting sub-clauses. Thus, SeqZero avoids
generating a long canonical utterance at once. Moreover, SeqZero employs not
only a few-shot model but also a zero-shot model to alleviate the overfitting.
In particular, SeqZero brings out the merits from both models via ensemble
equipped with our proposed constrained rescaling. SeqZero achieves SOTA
performance of BART-based models on GeoQuery and EcommerceQuery, which are two
few-shot datasets with compositional data split.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 21:13:15 GMT""}]","2022-05-17"
"2205.07382","Patrick Draper","Tom Banks, Patrick Draper, Bingnan Zhang","JT Gravity Coupled to Fermions","24 pages",,,,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We argue that two-dimensional dilaton gravity models can all be derived from
an analog of Jacobson's covariant version of the first law of thermodynamics.
We then specialize to the JT gravity model and couple it to massless fermions.
This model is exactly soluble in quantum field theory, and we present a new
derivation of that result. The field theory model violates two principles one
might want to impose on a quantum theory of gravity describing the near horizon
region of an extremal charged black hole in four dimensions: finiteness of the
entropy for finite causal diamonds, and the absence of global conservation
laws. It preserves an infinite number of conservation laws that one would have
expected to be violated, since the fermion state on each side of the $AdS_2$
wormhole is unavoidably thermal. We describe a cutoff version of the model,
with extra interactions, which cures these difficulties. Our UV completion of
the model depends on the AKK map of non-relativistic fermions in an inverted
oscillator potential to Weyl fermions in Minkowski space. We argue that gauging
the $Z_2$ symmetry of the oscillator model, using a density matrix with
temperature that depends on the oscillator coordinates, and inserting chaotic
interactions at (almost) infinite oscillator coordinate, we obtain a model with
properties expected of quantum gravity in the near horizon region of an
extremal charged black hole in four dimensions.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 21:22:20 GMT""}]","2022-05-17"
"2205.07383","Bruce Jordan","Bruce W. Jordan and Yevgeny Zaytman","Isogeny complexes of superspecial abelian varieties",,,,,"math.NT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the structures formed by isogenies of abelian varieties with
polarizations that are not necessarily principal, specifically with the
$[\ell]$-polarizations we have previously defined. Our primary interest is in
superspecial abelian varieties, where the isogenies are related to quaternionic
hermitian forms. We first consider isogeny graphs. We show that these
$[\ell]$-isogeny graphs are a generalized Brandt graph and construct them
entirely in terms of definite quaternion algebras. We prove that they are
connected and give examples to show that the regular graphs obtained are
sometimes Ramanujan and sometimes not. Isogenies of $[\ell]$-polarized abelian
varieties can be closed under composition, with the consequence that such
isogenies naturally form semi-simplicial complexes as introduced by Eilenberg
and Zilber in 1950 (later also called $\Delta$-complexes) -- the
higher-dimensional analogues of multigraphs.
  We show that these isogeny complexes can be constructed from the arithmetic
of hermitian forms over definite quaternion algebras and that they are
quotients of the Bruhat-Tits building of the symplectic group by the action of
a quaternionic unitary group. Working with quaternions these isogeny graphs and
complexes are amenable to machine computation and we include many examples,
concluding with a detailed examination of the $[2]$-isogeny complexes of
superspecial abelian surfaces in characteristic $7$.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 21:29:36 GMT""}]","2022-05-17"
"2205.07384","Ziyang Jiang","Ziyang Jiang, Tongshu Zheng, Yiling Liu, and David Carlson","Incorporating Prior Knowledge into Neural Networks through an Implicit
  Composite Kernel","23 pages, 14 figures, 3 tables, 2 algorithms",,,,"cs.LG cs.AI stat.ML","http://creativecommons.org/licenses/by/4.0/","  It is challenging to guide neural network (NN) learning with prior knowledge.
In contrast, many known properties, such as spatial smoothness or seasonality,
are straightforward to model by choosing an appropriate kernel in a Gaussian
process (GP). Many deep learning applications could be enhanced by modeling
such known properties. For example, convolutional neural networks (CNNs) are
frequently used in remote sensing, which is subject to strong seasonal effects.
We propose to blend the strengths of deep learning and the clear modeling
capabilities of GPs by using a composite kernel that combines a kernel
implicitly defined by a neural network with a second kernel function chosen to
model known properties (e.g., seasonality). We implement this idea by combining
a deep network and an efficient mapping based on the Nystrom approximation,
which we call Implicit Composite Kernel (ICK). We then adopt a
sample-then-optimize approach to approximate the full GP posterior
distribution. We demonstrate that ICK has superior performance and flexibility
on both synthetic and real-world data sets. We believe that ICK framework can
be used to include prior information into neural networks in many applications.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 21:32:44 GMT""},{""version"":""v2"",""created"":""Tue, 17 May 2022 20:17:03 GMT""},{""version"":""v3"",""created"":""Sat, 28 May 2022 02:28:28 GMT""},{""version"":""v4"",""created"":""Fri, 14 Oct 2022 15:05:15 GMT""},{""version"":""v5"",""created"":""Thu, 26 Jan 2023 18:39:23 GMT""},{""version"":""v6"",""created"":""Fri, 3 Feb 2023 01:59:38 GMT""}]","2023-02-06"
"2205.07385","Emilio Said","Emilio Said","Market Impact: Empirical Evidence, Theory and Practice",,,,,"q-fin.TR q-fin.MF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a theory of the market impact of metaorders based on a
coarse-grained approach where the microscopic details of supply and demand is
replaced by a single parameter $\rho \in [0,+\infty]$ shaping the supply-demand
equilibrium and the market impact process during the execution of the
metaorder. Our model provides an unified explanation of most of the empirical
observations that have been reported and establishes a strong connection
between the excess volatility puzzle and the order-driven view of the markets
through the square-root law.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 21:45:20 GMT""}]","2022-05-17"
"2205.07386","Yi-Cai Zhang","Yi-Cai Zhang","Bound states in the continuum (BIC) protected by self-sustained
  potential barriers in a flat band system",,"Sci Rep 12, 11670 (2022)","10.1038/s41598-022-15860-w",,"cond-mat.quant-gas cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we investigate the bound states in the continuum (BIC) of a
one-dimensional spin-1 flat band system. It is found that, when the potential
is sufficiently strong, there exists an effective attractive potential well
surrounded by infinitely high self-sustained barriers. Consequently, there
exist some BIC in the effective potential well. These bound states are
protected by the infinitely high potential barriers, which could not decay into
the continuum.} Taking a long-ranged Coulomb potential and a short-ranged
exponential potential as two examples, the bound state energies are obtained.
For a Coulomb potential, there exists a series of critical potential strengths,
near which the bound state energy can go to infinity. For a sufficiently strong
exponential potential, there exists two different bound states with a same
number of wave function nodes. The existence of BIC protected by the
self-sustained potential barriers is quite a universal phenomenon in the flat
band system under a strong potential. A necessary condition for the existence
of BIC is that the maximum value of potential is larger than two times band
gap.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 21:53:14 GMT""}]","2022-07-12"
"2205.07387","Cheng Zhang","Cheng Zhang, Hao Zhang, Jie Wang","Downstream Transformer Generation of Question-Answer Pairs with
  Preprocessing and Postprocessing Pipelines",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  We present a system called TP3 to perform a downstream task of transformers
on generating question-answer pairs (QAPs) from a given article. TP3 first
finetunes pretrained transformers on QAP datasets, then uses a preprocessing
pipeline to select appropriate answers, feeds the relevant sentences and the
answer to the finetuned transformer to generate candidate QAPs, and finally
uses a postprocessing pipeline to filter inadequate QAPs. In particular, using
pretrained T5 models as transformers and the SQuAD dataset as the finetruning
dataset, we show that TP3 generates satisfactory number of QAPs with high
qualities on the Gaokao-EN dataset.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 21:53:45 GMT""}]","2022-05-17"
"2205.07388","Charles Manski","Charles F. Manski","Inference with Imputed Data: The Allure of Making Stuff Up","arXiv admin note: text overlap with arXiv:2102.11334",,,,"econ.EM stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Incomplete observability of data generates an identification problem. There
is no panacea for missing data. What one can learn about a population parameter
depends on the assumptions one finds credible to maintain. The credibility of
assumptions varies with the empirical setting. No specific assumptions can
provide a realistic general solution to the problem of inference with missing
data. Yet Rubin has promoted random multiple imputation (RMI) as a general way
to deal with missing values in public-use data. This recommendation has been
influential to empirical researchers who seek a simple fix to the nuisance of
missing data. This paper adds to my earlier critiques of imputation. It
provides a transparent assessment of the mix of Bayesian and frequentist
thinking used by Rubin to argue for RMI. It evaluates random imputation to
replace missing outcome or covariate data when the objective is to learn a
conditional expectation. It considers steps that might help combat the allure
of making stuff up.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 22:03:45 GMT""}]","2022-05-17"
"2205.07389","Yi-Cai Zhang","Yu-Rong Wu, Xiao-Fei Zhang, Chao-Fei Liu, Wu-Ming Liu, and Yi-Cai
  Zhang","Superfluid density and collective modes of fermion superfluid in dice
  lattice",,"Sci Rep 11, 13572 (2021)","10.1038/s41598-021-93007-z",,"cond-mat.quant-gas cond-mat.str-el cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The superfluid properties of attractive Hubbard model in dice lattice are
investigated. It is found that three superfluid order parameters increase as
the interaction increases. When the filling factor falls into the flat band,
due to the infinite large density of states, the resultant superfluid order
parameters are proportional to interaction strength, which is in striking
contrast with the exponentially small counterparts in usual superfluid (or
superconductor). When the interaction is weak, and the filling factor is near
the bottom of the lowest band (or the top of highest band), the superfluid
density is determined by the effective mass of the lowest (or highest)
single-particle band. When the interaction is strong and filling factor is
small, the superfluid density is inversely proportional to interaction
strength, which is related to effective mass of tightly bound pairs. In the
strong interaction limit and finite filling, the asymptotic behaviors of
superfluid density can be captured by a parabolic function of filling factor.
Furthermore, when the filling is in flat band, the superfluid density shows a
logarithmic singularity as the interaction approaches zero. In addition, there
exist three undamped collective modes for strong interactions. The lowest
excitation is gapless phonon, which is characterized by the total density
oscillations. The two others are gapped Leggett modes, which correspond
relative density fluctuations between sublattices. The collective modes are
also reflected in the two-particle spectral functions by sharp peaks.
Furthermore, it is found that the two-particle spectral functions satisfy an
exact sum-rule, which is directly related to the filling factor (or density of
particle). The sum-rule of the spectral functions may be useful to distinguish
between the hole-doped and particle-doped superfluid (superconductor) in
experiments.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 22:12:37 GMT""}]","2022-06-10"
"2205.07390","Cem Subakan","Zhepei Wang, Cem Subakan, Xilin Jiang, Junkai Wu, Efthymios Tzinis,
  Mirco Ravanelli, Paris Smaragdis","Learning Representations for New Sound Classes With Continual
  Self-Supervised Learning","Accepted to IEEE Signal Processing Letters",,"10.1109/LSP.2022.3229643",,"eess.AS cs.LG cs.SD eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we work on a sound recognition system that continually
incorporates new sound classes. Our main goal is to develop a framework where
the model can be updated without relying on labeled data. For this purpose, we
propose adopting representation learning, where an encoder is trained using
unlabeled data. This learning framework enables the study and implementation of
a practically relevant use case where only a small amount of the labels is
available in a continual learning context. We also make the empirical
observation that a similarity-based representation learning method within this
framework is robust to forgetting even if no explicit mechanism against
forgetting is employed. We show that this approach obtains similar performance
compared to several distillation-based continual learning methods when employed
on self-supervised representation learning methods.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 22:15:21 GMT""},{""version"":""v2"",""created"":""Tue, 13 Dec 2022 17:12:02 GMT""}]","2023-01-11"
"2205.07391","C\'esar Silva","C\'esar M. Silva","Nonuniform $\mu$-dichotomy spectrum and kinematic similarity","24 pages",,,,"math.DS math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For linear nonautonomous differential equations we introduce a new family of
spectrums defined with general nonuniform dichotomies. This family of spectrums
contains the nonuniform dichotomy spectrum as the very particular case of
exponential growth rates. We describe all possible forms of this spectrum for a
general growth rate and obtain a reducibility result for nonautonomous linear
differential equations using the introduced spectrums. We also give an
illustrative example where the spectrum is obtained.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 22:31:38 GMT""}]","2022-05-23"
"2205.07392","Maria-Romina Ivan Miss","Irina {\DJ}ankovi\'c and Maria-Romina Ivan","Saturation for Small Antichains","8 pages",,"10.37236/11262",,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a given positive integer $k$ we say that a family of subsets of $[n]$ is
$k$-antichain saturated if it does not contain $k$ pairwise incomparable sets,
but whenever we add to it a new set, we do find $k$ such sets. The size of the
smallest such family is denoted by $\text{sat}^*(n, \mathcal A_{k})$. Ferrara,
Kay, Kramer, Martin, Reiniger, Smith and Sullivan conjectured that
$\text{sat}^*(n, \mathcal A_{k})=(k-1)n(1+o(1))$, and proved this for $k\leq
4$. In this paper we prove this conjecture for $k=5$ and $k=6$. Moreover, we
give the exact value for $\text{sat}^*(n, \mathcal A_5)$ and $\text{sat}^*(n,
\mathcal A_6)$. We also give some open problems inspired by our analysis.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 22:39:42 GMT""},{""version"":""v2"",""created"":""Fri, 13 Jan 2023 14:03:01 GMT""}]","2023-01-16"
"2205.07393","Xiaobing Feng Dr.","Xiaobing Feng, Akash Ashirbad Panda, and Andreas Prohl","Higher order time discretization for the stochastic semilinear wave
  equation with multiplicative noise","41 pages, 6 figures",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  In this paper, a higher-order time-discretization scheme is proposed, where
the iterates approximate the solution of the stochastic semilinear wave
equation driven by multiplicative noise with general drift and diffusion. We
employ a variational method for its error analysis and prove an improved
convergence order of 3/2 for the approximates of the solution. The core of the
analysis is Holder continuity in time and moment bounds for the solutions of
the continuous and the discrete problem. Computational experiments are also
presented.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 22:49:03 GMT""},{""version"":""v2"",""created"":""Mon, 18 Jul 2022 19:16:20 GMT""}]","2022-07-20"
"2205.07394","Gagandeep Singh","Gagandeep Singh, Rakesh Nadig, Jisung Park, Rahul Bera, Nastaran
  Hajinazar, David Novo, Juan G\'omez-Luna, Sander Stuijk, Henk Corporaal, Onur
  Mutlu","Sibyl: Adaptive and Extensible Data Placement in Hybrid Storage Systems
  Using Online Reinforcement Learning",,,,,"cs.AR cs.AI cs.DC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hybrid storage systems (HSS) use multiple different storage devices to
provide high and scalable storage capacity at high performance. Recent research
proposes various techniques that aim to accurately identify
performance-critical data to place it in a ""best-fit"" storage device.
Unfortunately, most of these techniques are rigid, which (1) limits their
adaptivity to perform well for a wide range of workloads and storage device
configurations, and (2) makes it difficult for designers to extend these
techniques to different storage system configurations (e.g., with a different
number or different types of storage devices) than the configuration they are
designed for. We introduce Sibyl, the first technique that uses reinforcement
learning for data placement in hybrid storage systems. Sibyl observes different
features of the running workload as well as the storage devices to make
system-aware data placement decisions. For every decision it makes, Sibyl
receives a reward from the system that it uses to evaluate the long-term
performance impact of its decision and continuously optimizes its data
placement policy online. We implement Sibyl on real systems with various HSS
configurations. Our results show that Sibyl provides 21.6%/19.9% performance
improvement in a performance-oriented/cost-oriented HSS configuration compared
to the best previous data placement technique. Our evaluation using an HSS
configuration with three different storage devices shows that Sibyl outperforms
the state-of-the-art data placement policy by 23.9%-48.2%, while significantly
reducing the system architect's burden in designing a data placement mechanism
that can simultaneously incorporate three storage devices. We show that Sibyl
achieves 80% of the performance of an oracle policy that has complete knowledge
of future access patterns while incurring a very modest storage overhead of
only 124.4 KiB.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 22:53:36 GMT""}]","2022-05-17"
"2205.07395","Aaron Snoswell","Thomas Krendl Gilbert, Aaron J. Snoswell, Michael Dennis, Rowan
  McAllister, Cathy Wu","Sociotechnical Specification for the Broader Impacts of Autonomous
  Vehicles","Paper accepted for presentation at ICRA 2022 workshop ""Fresh
  Perspectives on the Future of Autonomous Driving""",,,,"cs.CY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Autonomous Vehicles (AVs) will have a transformative impact on society.
Beyond the local safety and efficiency of individual vehicles, these effects
will also change how people interact with the entire transportation system.
This will generate a diverse range of large and foreseeable effects on social
outcomes, as well as how those outcomes are distributed. However, the ability
to control both the individual behavior of AVs and the overall flow of traffic
also provides new affordances that permit AVs to control these effects. This
comprises a problem of sociotechnical specification: the need to distinguish
which essential features of the transportation system are in or out of scope
for AV development. We present this problem space in terms of technical,
sociotechnical, and social problems, and illustrate examples of each for the
transport system components of social mobility, public infrastructure, and
environmental impacts. The resulting research methodology sketches a path for
developers to incorporate and evaluate more transportation system features
within AV system components over time.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 23:03:43 GMT""}]","2022-05-17"
"2205.07396","Jean Carlo Guella","Jean Carlo Guella and Janin J\""ager","Strictly positive definite non-isotropic kernels on two-point
  homogeneous manifolds: The asymptotic approach",,,,,"math.CA cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present sufficient condition for a family of positive definite kernels on
a compact two-point homogeneous space to be strictly positive definite based on
their representation as a series of spherical harmonics. The family analyzed is
a generalization of the isotropic kernels and the case of a real sphere is
analyzed in details.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 23:04:42 GMT""}]","2022-05-17"
"2205.07397","Mehdi Biderang","Mehdi Biderang, Mohammad-Hossein Zare, Jesko Sirker","Topological Superconductivity in Sn/Si(111) driven by non-local Coulomb
  interactions","12 pages, 9 figures, 1 table","Phys. Rev. B 106, 054514 (2022)","10.1103/PhysRevB.106.054514",,"cond-mat.supr-con cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  Superconductivity was recently observed in boron-doped
($\sqrt{3}\times\sqrt{3}$)Sn/Si(111). The material can be described by an
extended Hubbard model on a triangular lattice. Here, we use the random-phase
approximation to investigate the charge and spin fluctuations as well as the
superconducting properties of the system with respect to filling and the
relative strength of the extended versus the on-site Hubbard interactions. Our
calculations reveal that near half-filling and weak extended Hubbard
interactions, the superconducting ground state exhibits chiral $d$-wave
pairing. Far from half-filling and for stronger nearest-neighbor Coulomb
interactions, the system shows chiral $p$-wave (hole-doping) and $f$-wave
(electron-doping) pairings. The dependence of the pairing symmetry on the
extended Hubbard interactions suggests that charge fluctuations play an
important role in the formation of Cooper pairs. Finally, the temperature
dependence of the Knight shift is calculated for all observed superconducting
textures and put forward as an experimental method to examine the symmetry of
the superconducting gap function.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 23:14:21 GMT""}]","2022-08-23"
"2205.07398","Ruyi Liu","Ruyi Liu, Zhen Wu and Detao Zhang","Two Equivalent Families of Linear Fully Coupled Forward Backward
  Stochastic Differential Equations","18 pages",,,,"math.OC","http://creativecommons.org/licenses/by-sa/4.0/","  In this paper, we investigate two families of fully coupled linear
Forward-Backward Stochastic Differential Equations (FBSDE). Within these
families, one could get the same well-posedness of FBSDEs with totally
different structures. The first family of FBSDEs are proved to be equivalent
with respect to the Unified Approach. Thus one could get the well-posedness of
the whole family if one member exists a unique solution. Another equivalent
family of FBSDEs are investigated by introducing a linear transformation
method. By reason of the fully coupling structure between the forward and
backward equations, it leads to a highly interdependence in solutions. We are
able to lower the coupling of FBSDEs, by virtue of the idea of transformation,
without losing the well-posedness. Moreover, owing to the non-degeneracy of the
transformation matrix, the solution to original FBSDE is totally determined by
solutions of FBSDE after transformation. In addition, an example of optimal
Linear Quadratic (LQ) problem is presented to illustrate.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 23:17:12 GMT""}]","2022-05-17"
"2205.07399","Sean I. Young","Sean I. Young, Ya\""el Balbastre, Adrian V. Dalca, William M. Wells,
  Juan Eugenio Iglesias, Bruce Fischl","SuperWarp: Supervised Learning and Warping on U-Net for Invariant
  Subvoxel-Precise Registration",,,,,"cs.CV cs.LG eess.IV","http://creativecommons.org/licenses/by/4.0/","  In recent years, learning-based image registration methods have gradually
moved away from direct supervision with target warps to instead use
self-supervision, with excellent results in several registration benchmarks.
These approaches utilize a loss function that penalizes the intensity
differences between the fixed and moving images, along with a suitable
regularizer on the deformation. In this paper, we argue that the relative
failure of supervised registration approaches can in part be blamed on the use
of regular U-Nets, which are jointly tasked with feature extraction, feature
matching, and estimation of deformation. We introduce one simple but crucial
modification to the U-Net that disentangles feature extraction and matching
from deformation prediction, allowing the U-Net to warp the features, across
levels, as the deformation field is evolved. With this modification, direct
supervision using target warps begins to outperform self-supervision approaches
that require segmentations, presenting new directions for registration when
images do not have segmentations. We hope that our findings in this preliminary
workshop paper will re-ignite research interest in supervised image
registration techniques. Our code is publicly available from
https://github.com/balbasty/superwarp.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 23:17:32 GMT""}]","2022-05-17"
"2205.07400","Fujun Hou","Fujun Hou","Reformulating the Value Restriction and the Not-Strict Value Restriction
  in Terms of Possibility Preference Map","The reformulations of VR and NSVR appear elegant since they all take
  the form of minmax",,,,"econ.TH","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In social choice theory, Sen's value restriction and Pattanaik's not-strict
value restriction are both attractive conditions for testing social preference
transitivity and/or non-empty social choice set existence. This article
introduces a novel mathematical representation tool, called possibility
preference map (PPM), for weak orderings, and then reformulates the value
restriction and the not-strict value restriction in terms of PPM. The
reformulations all appear elegant since they take the form of minmax.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 23:22:18 GMT""}]","2022-05-17"
"2205.07401","Sarnaduti Brahma","Sarnaduti Brahma, Hamid R. Ossareh, and Mads R. Almassalkhi","Statistical Modeling and Forecasting of Automatic Generation Control
  Signals","In proceedings of the 11th Bulk Power Systems Dynamics and Control
  Symposium (IREP 2022), July 25-30, 2022, Banff, Canada",,,"IREP2022-50","eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The performance of frequency regulating units for automatic generation
control (AGC) of power systems depends on their ability to track the AGC signal
accurately. In addition, representative models and advanced analysis and
analytics can yield forecasts of the AGC signal that aids in controller design.
In this paper, time-series analyses are conducted on an AGC signal,
specifically the PJM Reg-D, and using the results, a statistical model is
derived that fairly accurately captures its second moments and saturated
nature, as well as a time-series-based predictive model to provide forecasts.
As an application, the predictive model is used in a model predictive control
framework to ensure optimal tracking performance of a down ramp-limited
distributed energy resource coordination scheme. The results provide valuable
insight into the properties of the AGC signal and indicate the effectiveness of
these models in replicating its behavior.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 23:36:38 GMT""},{""version"":""v2"",""created"":""Sun, 10 Jul 2022 17:06:57 GMT""}]","2022-07-12"
"2205.07402","Navid Anjum Aadit","Navid Anjum Aadit, Andrea Grimaldi, Giovanni Finocchio, and Kerem Y.
  Camsari","Physics-inspired Ising Computing with Ring Oscillator Activated p-bits","To appear in the 22nd IEEE International Conference on Nanotechnology
  (IEEE-NANO 2022)","2022 IEEE 22nd International Conference on Nanotechnology (NANO)","10.1109/NANO54668.2022.9928681",,"cs.AR cs.DC cs.ET cs.NE physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  The nearing end of Moore's Law has been driving the development of
domain-specific hardware tailored to solve a special set of problems. Along
these lines, probabilistic computing with inherently stochastic building blocks
(p-bits) have shown significant promise, particularly in the context of hard
optimization and statistical sampling problems. p-bits have been proposed and
demonstrated in different hardware substrates ranging from small-scale
stochastic magnetic tunnel junctions (sMTJs) in asynchronous architectures to
large-scale CMOS in synchronous architectures. Here, we design and implement a
truly asynchronous and medium-scale p-computer (with $\approx$ 800 p-bits) that
closely emulates the asynchronous dynamics of sMTJs in Field Programmable Gate
Arrays (FPGAs). Using hard instances of the planted Ising glass problem on the
Chimera lattice, we evaluate the performance of the asynchronous architecture
against an ideal, synchronous design that performs parallelized (chromatic)
exact Gibbs sampling. We find that despite the lack of any careful
synchronization, the asynchronous design achieves parallelism with comparable
algorithmic scaling in the ideal, carefully tuned and parallelized synchronous
design. Our results highlight the promise of massively scaled p-computers with
millions of free-running p-bits made out of nanoscale building blocks such as
stochastic magnetic tunnel junctions.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 23:46:58 GMT""}]","2022-11-23"
"2205.07403","Guangsheng Shi","Guangsheng Shi, Ruifeng Li and Chao Ma","PillarNet: Real-Time and High-Performance Pillar-based 3D Object
  Detection","ECCV 2022",,,,"cs.CV","http://creativecommons.org/licenses/by-sa/4.0/","  Real-time and high-performance 3D object detection is of critical importance
for autonomous driving. Recent top-performing 3D object detectors mainly rely
on point-based or 3D voxel-based convolutions, which are both computationally
inefficient for onboard deployment. In contrast, pillar-based methods use
solely 2D convolutions, which consume less computation resources, but they lag
far behind their voxel-based counterparts in detection accuracy. In this paper,
by examining the primary performance gap between pillar- and voxel-based
detectors, we develop a real-time and high-performance pillar-based detector,
dubbed PillarNet.The proposed PillarNet consists of a powerful encoder network
for effective pillar feature learning, a neck network for spatial-semantic
feature fusion and the commonly used detect head. Using only 2D convolutions,
PillarNet is flexible to an optional pillar size and compatible with classical
2D CNN backbones, such as VGGNet and ResNet. Additionally, PillarNet benefits
from our designed orientation-decoupled IoU regression loss along with the
IoU-aware prediction branch. Extensive experimental results on the large-scale
nuScenes Dataset and Waymo Open Dataset demonstrate that the proposed PillarNet
performs well over state-of-the-art 3D detectors in terms of effectiveness and
efficiency. Code is available at \url{https://github.com/agent-sgs/PillarNet}.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 00:14:50 GMT""},{""version"":""v2"",""created"":""Thu, 19 May 2022 07:37:11 GMT""},{""version"":""v3"",""created"":""Tue, 31 May 2022 07:52:07 GMT""},{""version"":""v4"",""created"":""Tue, 14 Jun 2022 14:02:33 GMT""},{""version"":""v5"",""created"":""Fri, 26 Aug 2022 03:21:15 GMT""}]","2022-08-29"
"2205.07404","Pengcheng Wei","Li Yan, Pengcheng Wei, Hong Xie, Jicheng Dai, Hao Wu, Ming Huang","A New Outlier Removal Strategy Based on Reliability of Correspondence
  Graph for Fast Point Cloud Registration","This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible",,"10.1109/TPAMI.2022.3226498",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Registration is a basic yet crucial task in point cloud processing. In
correspondence-based point cloud registration, matching correspondences by
point feature techniques may lead to an extremely high outlier ratio. Current
methods still suffer from low efficiency, accuracy, and recall rate. We use a
simple and intuitive method to describe the 6-DOF (degree of freedom)
curtailment process in point cloud registration and propose an outlier removal
strategy based on the reliability of the correspondence graph. The method
constructs the corresponding graph according to the given correspondences and
designs the concept of the reliability degree of the graph node for optimal
candidate selection and the reliability degree of the graph edge to obtain the
global maximum consensus set. The presented method could achieve fast and
accurate outliers removal along with gradual aligning parameters estimation.
Extensive experiments on simulations and challenging real-world datasets
demonstrate that the proposed method can still perform effective point cloud
registration even the correspondence outlier ratio is over 99%, and the
efficiency is better than the state-of-the-art. Code is available at
https://github.com/WPC-WHU/GROR.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 00:37:57 GMT""}]","2022-12-23"
"2205.07405","Yi Liu","Xiang Zhang, Qi Lu, Yalei Zhu, Jing Zhao, Rostyslav Danylo, Mingwei
  Lei, Hongbing Jiang, Chengyin Wu, Zhedong Zhang, Aur\'elien Houard, Vladimir
  Tikhonchuk, Andr\'e Mysyrowicz, Qihuang Gong, Songlin Zhuang, Zengxiu Zhao,
  Yi Liu","Multiple-Photon Resonance Enabled Quantum Interference in Emission
  Spectroscopy of N_2^+","20 pages, 8 figures",,,,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Quantum interference occurs frequently in the interaction of laser radiation
with materials, leading to a series of fascinating effects such as lasing
without inversion, electromagnetically induced transparency, Fano resonance,
etc. Such quantum interference effects are mostly enabled by single-photon
resonance with transitions in the matter, regardless of how many optical
frequencies are involved. Here, we demonstrate quantum interference driven by
multiple photons in the emission spectroscopy of nitrogen ions that are
resonantly pumped by ultrafast infrared laser pulses. In the spectral domain,
Fano resonance is observed in the emission spectrum, where a laser-assisted
dynamic Stark effect creates the continuum. In the time domain, the
fast-evolving emission is measured, revealing the nature of free-induction
decay (FID) arising from quantum radiation and molecular cooperativity. These
findings clarify the mechanism of coherent emission of nitrogen ions pumped
with MIR pump laser and are likely to be universal. The present work opens a
route to explore the important role of quantum interference during the
interaction of intense laser pulses with materials near multiple photon
resonance.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 00:39:41 GMT""}]","2022-05-17"
"2205.07406","Xiangjing Liu","Xiangjing Liu, Daniel Ebler, Oscar Dahlsten","Thermodynamics of quantum switch information capacity activation","6+7pages,4 figures","Phys. Rev. Lett. 129, 230604(2022)","10.1103/PhysRevLett.129.230604",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We address a new setting where the second law is under question:
thermalizations in a quantum superposition of causal orders, enacted by the
so-called quantum switch. This superposition has been shown to be associated
with an increase in the communication capacity of the channels, yielding an
apparent violation of the data-processing inequality and a possibility to
separate hot from cold. We analyze the thermodynamics of this information
capacity increasing process. We show how the information capacity increase is
compatible with thermodynamics. We show that there may indeed be an information
capacity increase for consecutive thermalizations obeying the first and second
laws of thermodynamics if these are placed in an indefinite order and moreover
that only a significantly bounded increase is possible. The increase comes at
the cost of consuming a thermodynamic resource, the free energy of coherence
associated with the switch.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 00:59:15 GMT""},{""version"":""v2"",""created"":""Fri, 2 Dec 2022 01:59:17 GMT""}]","2022-12-05"
"2205.07407","Xiaohan Yang","Xiaohan Yang, Eduardo Peynetti, Vasco Meerman, Chris Tanner","What GPT Knows About Who is Who","Accepted by ACL 2022 Workshop on Insights from Negative Results in
  NLP",,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Coreference resolution -- which is a crucial task for understanding discourse
and language at large -- has yet to witness widespread benefits from large
language models (LLMs). Moreover, coreference resolution systems largely rely
on supervised labels, which are highly expensive and difficult to annotate,
thus making it ripe for prompt engineering. In this paper, we introduce a
QA-based prompt-engineering method and discern \textit{generative}, pre-trained
LLMs' abilities and limitations toward the task of coreference resolution. Our
experiments show that GPT-2 and GPT-Neo can return valid answers, but that
their capabilities to identify coreferent mentions are limited and
prompt-sensitive, leading to inconsistent results.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 00:59:37 GMT""}]","2022-05-17"
"2205.07408","Stephen Whitelam","Stephen Whitelam, Viktor Selin, Ian Benlolo, Corneel Casert, Isaac
  Tamblyn","Training neural networks using Metropolis Monte Carlo and an adaptive
  variant",,,,,"cs.LG cond-mat.stat-mech cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine the zero-temperature Metropolis Monte Carlo algorithm as a tool
for training a neural network by minimizing a loss function. We find that, as
expected on theoretical grounds and shown empirically by other authors,
Metropolis Monte Carlo can train a neural net with an accuracy comparable to
that of gradient descent, if not necessarily as quickly. The Metropolis
algorithm does not fail automatically when the number of parameters of a neural
network is large. It can fail when a neural network's structure or neuron
activations are strongly heterogenous, and we introduce an adaptive Monte Carlo
algorithm, aMC, to overcome these limitations. The intrinsic stochasticity and
numerical stability of the Monte Carlo method allow aMC to train deep neural
networks and recurrent neural networks in which the gradient is too small or
too large to allow training by gradient descent. Monte Carlo methods offer a
complement to gradient-based methods for training neural networks, allowing
access to a distinct set of network architectures and principles.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 01:01:55 GMT""},{""version"":""v2"",""created"":""Tue, 9 Aug 2022 21:19:36 GMT""}]","2022-08-11"
"2205.07409","William Balderrama","William Balderrama","Total power operations in spectral sequences","41 pages. v4: some corrections to Sections 4 and A.4",,,,"math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe how power operations descend through homotopy limit spectral
sequences. We apply this to describe how norms appear in the $C_2$-equivariant
Adams spectral sequence, to compute norms on $\pi_0$ of the equivariant
$KU$-local sphere, and to compute power operations for the $K(1)$-local sphere.
An appendix contains material on equivariant Bousfield localizations which may
be of independent interest.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 01:03:34 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jul 2022 13:57:27 GMT""},{""version"":""v3"",""created"":""Thu, 28 Jul 2022 12:58:04 GMT""},{""version"":""v4"",""created"":""Tue, 18 Apr 2023 13:07:03 GMT""}]","2023-04-19"
"2205.07410","Harideep Nair","Harideep Nair, Prabhu Vellaisamy, Santha Bhasuthkar, and John Paul
  Shen","TNN7: A Custom Macro Suite for Implementing Highly Optimized Designs of
  Neuromorphic TNNs","To be published in ISVLSI 2022",,,,"cs.AR cs.ET cs.LG cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Temporal Neural Networks (TNNs), inspired from the mammalian neocortex,
exhibit energy-efficient online sensory processing capabilities. Recent works
have proposed a microarchitecture framework for implementing TNNs and
demonstrated competitive performance on vision and time-series applications.
Building on these previous works, this work proposes TNN7, a suite of nine
highly optimized custom macros developed using a predictive 7nm Process Design
Kit (PDK), to enhance the efficiency, modularity and flexibility of the TNN
design framework. TNN prototypes for two applications are used for evaluation
of TNN7. An unsupervised time-series clustering TNN delivering competitive
performance can be implemented within 40 uW power and 0.05 mm^2 area, while a
4-layer TNN that achieves an MNIST error rate of 1% consumes only 18 mW and
24.63 mm^2. On average, the proposed macros reduce power, delay, area, and
energy-delay product by 14%, 16%, 28%, and 45%, respectively. Furthermore,
employing TNN7 significantly reduces the synthesis runtime of TNN designs (by
more than 3x), allowing for highly-scaled TNN implementations to be realized.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 01:03:41 GMT""},{""version"":""v2"",""created"":""Wed, 25 May 2022 20:14:07 GMT""}]","2022-05-27"
"2205.07411","Dinil Mon Divakaran","Dinil Mon Divakaran, Adam Oest","Phishing Detection Leveraging Machine Learning and Deep Learning: A
  Review","Paper accepted for publication at IEEE Security & Privacy",,,,"cs.CR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Phishing attacks trick victims into disclosing sensitive information. To
counter rapidly evolving attacks, we must explore machine learning and deep
learning models leveraging large-scale data. We discuss models built on
different kinds of data, along with their advantages and disadvantages, and
present multiple deployment options to detect phishing attacks.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 01:10:55 GMT""}]","2022-05-17"
"2205.07412","Grigoris Panotopoulos","Grigoris Panotopoulos, \'Angel Rinc\'on, Il\'idio Lopes","Binary X-ray sources in massive Brans-Dicke gravity","11 pages, 4 figures, accepted for publication in Universe. arXiv
  admin note: text overlap with arXiv:2108.12984","Universe 2022, 8(5), 285","10.3390/universe8050285",,"gr-qc astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study focuses on the X-ray emission of low-mass black hole binaries in
massive Brans-Dicke gravity. First, we compute the accretion disk adopting the
well-known Shakura-Sunyaev model for an optically thick, cool, and
geometrically thin disk. Moreover, we assume that the gravitational field
generated by the stellar-mass black hole is an analogue of the Schwarzschild
space-time of Einstein's theory in massive Brans-Dicke gravity. We compute the
most relevant quantities of interest, i.e., i) the radial velocity, ii) the
energy and surface density, and iii) the pressure as a function entirely of the
radial coordinate. We also compute the soft spectral component of the X-ray
emission produced by the disk. Furthermore, we investigate in detail how the
mass of the scalar field modifies the properties of the binary as described by
the more standard Schwarzschild solution.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 01:11:10 GMT""}]","2022-06-07"
"2205.07413","Jaime Marian","Sicong He, Xinran Zhou, Dan Mordehai, Jaime Marian","Thermal super-jogs control high-temperature strength in Nb-Mo-Ta-W
  alloys",,,,,"cond-mat.mtrl-sci physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  Refractory multi-element alloys (RMEA) with body-centered cubic (bcc)
structure have been the object of much research over the last decade due to
their high potential as candidate materials for high-temperature applications.
Most of these alloys display a remarkable strength at high temperatures, which
cannot be explained by the standard model of bcc plasticity dominated by
thermally-activated screw dislocation motion. Recent research on Nb-Mo-Ta-W
alloys points to a heightened role of edge dislocations on deformation, which
is generally attributed to atomic-level chemical fluctuations in the material
and their interactions with dislocation cores during slip. However, while this
model accounts for a strengthening effect due to the chemical complexity of the
alloy, it is not sufficient to explain its strength across the entire thermal
range. Here we propose a new mechanism that captures the existing theories
about enhanced lattice strengthening and a thermally-activated component that
emanates directly from the chemical complexity of the RMEA. This compositional
complexity results in unique vacancy formation energy distributions with tails
that extend into negative energies, leading to spontaneous, i.e., athermal,
vacancy formation at edge dislocation cores. These vacancies relax into
atomic-sized super-jogs on the dislocation line, acting as extra pinning points
that increase the activation stress of the dislocation. At the same time, these
super-jogs can displace diffusively along the glide direction, relieving with
their motion some of the extra stress, thus countering the hardening effect due
to jog-pinning. The interplay between these two processes as a function of
temperature confers an extra strength to edge dislocation at
intermediate-to-high temperatures, in remarkable agreement with experimental
measurements in Nb-Mo-Ta-W and across a number of different RMEA.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 01:11:38 GMT""}]","2022-05-17"
"2205.07414","Daniel Slonim","Daniel J. Slonim","On total weight exiting finite, strongly connected sets in
  shift-invariant weighted directed graphs on $\mathbb{Z}$","12 pages, 2 figures. arXiv admin note: substantial text overlap with
  arXiv:2104.14950",,,,"math.CO math.NT math.PR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  For a shift-invariant weighted directed graph with vertex set $\mathbb{Z}$,
we examine the minimal weight $\kappa_0$ exiting a finite, strongly connected
set of vertices. Although $\kappa_0$ is defined as an infimum, it has been
shown that the infimum is always attained by an actual set of vertices. We show
that for each underlying directed graph (prior to assignment of the weights),
there is a formula for $\kappa_0$ as a minimum of finitely many integer
combinations of the edge weights. We find this formula for several different
directed graphs. Motivation for this problem comes from random walks in
Dirichlet environments (equivalently, directed edge reinforced random walks),
where the size of $\kappa_0$ has been shown to determine the strength of finite
traps where the walk can get stuck for a long time.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 01:14:53 GMT""}]","2022-05-17"
"2205.07415","Rugang Ma","Rugang Ma, Xiaowen Zhou","Explosion of continuous-state branching processes with competition in
  L\'evy environment",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using the Lyapunov criteria arguments, we find sufficient conditions on
explosion/nonexplosion for continuous-state branching processes with
competition in L\'evy random environment. In particular, we identify the
necessary and sufficient conditions on explosion/nonexplosion when the
competition function is a power function and the L\'evy measure of the
associated branching mechanism is stable.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 01:19:43 GMT""},{""version"":""v2"",""created"":""Tue, 23 Aug 2022 14:13:44 GMT""},{""version"":""v3"",""created"":""Wed, 24 Aug 2022 03:54:06 GMT""}]","2022-08-25"
"2205.07416","Mahmoud Gadalla","Mahmoud Gadalla","Implementation of Analytical Jacobian and Chemical Explosive Mode
  Analysis (CEMA) in OpenFOAM","This report is part of the Proceedings of CFD with OpenSource
  Software, 2021, edited by H. Nilsson. See
  http://dx.doi.org/10.17196/OS_CFD#YEAR_2021 for more details",,,,"physics.flu-dyn","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This report presents the implementation details of the chemical explosive
mode analysis (CEMA), using analytical Jacobian formulation, into OpenFOAM.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 01:30:40 GMT""}]","2022-05-17"
"2205.07417","Dening Lu","Dening Lu, Qian Xie, Mingqiang Wei, Kyle Gao, Linlin Xu, Jonathan Li","Transformers in 3D Point Clouds: A Survey","20 pages, 5 figures, 4 tables",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Transformers have been at the heart of the Natural Language Processing (NLP)
and Computer Vision (CV) revolutions. The significant success in NLP and CV
inspired exploring the use of Transformers in point cloud processing. However,
how do Transformers cope with the irregularity and unordered nature of point
clouds? How suitable are Transformers for different 3D representations (e.g.,
point- or voxel-based)? How competent are Transformers for various 3D
processing tasks? As of now, there is still no systematic survey of the
research on these issues. For the first time, we provided a comprehensive
overview of increasingly popular Transformers for 3D point cloud analysis. We
start by introducing the theory of the Transformer architecture and reviewing
its applications in 2D/3D fields. Then, we present three different taxonomies
(i.e., implementation-, data representation-, and task-based), which can
classify current Transformer-based methods from multiple perspectives.
Furthermore, we present the results of an investigation of the variants and
improvements of the self-attention mechanism in 3D. To demonstrate the
superiority of Transformers in point cloud analysis, we present comprehensive
comparisons of various Transformer-based methods for classification,
segmentation, and object detection. Finally, we suggest three potential
research directions, providing benefit references for the development of 3D
Transformers.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 01:32:18 GMT""},{""version"":""v2"",""created"":""Wed, 21 Sep 2022 15:10:21 GMT""}]","2022-09-22"
"2205.07418","Dessislava Kochloukova","Dessislava H. Kochloukova","Higher dimensional algebraic fiberings for pro-$p$ groups",,,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove some conditions for higher dimensional algebraic fibering of pro-$p$
group extensions and we establish corollaries about incoherence of pro-$p$
groups. In particular, if $G = K \rtimes \Gamma$ is a pro-$p$ group, $\Gamma$ a
finitely generated free pro-$p$ group with $d(\Gamma) \geq 2$, $K$ a finitely
presented pro-$p$ group with $N$ a normal pro-$p$ subgroup of $K$ such that $K/
N \simeq \mathbb{Z}_p$ and $N$ not finitely generated as a pro-$p$ group, then
$G$ is incoherent (in the category of pro-$p$ groups). Furthermore we show that
if $K$ is a free pro-$p$ group with $d(K) = 2$ then either $Aut_0(K)$ is
incoherent (in the category of pro-$p$ groups) or there is a finitely presented
pro-$p$ group, without non-procyclic free pro-$p$ subgroups, that has a
metabelian pro-$p$ quotient that is not finitely presented i.e. a pro-$p$
version of a result of Bieri-Strebel does not hold.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 01:41:09 GMT""}]","2022-05-17"
"2205.07419","Kaoru Toko","Takamitsu Ishiyama, Takashi Suemasu, and Kaoru Toko","Image processing-based domain-matching simulation for heteroepitaxy","3 pages",,,,"cond-mat.mtrl-sci physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Heteroepitaxy of functional thin films on single-crystal substrates is one of
the most general themes in electronic materials research. Here, we propose an
algorithm based on image processing for the rapid simulation of heteroepitaxial
relationships. The superposition and rotation of various lattice plane images
of the film and substrate, which were automatically generated from the crystal
structure, rapidly verified all domain matching patterns. Furthermore, the
comprehensive validation allowed us to discuss domain matching from multiple
perspectives, such as mismatch, matching period, and density of matching
lattice points. Therefore, the proposed algorithm will contribute to materials
informatics, streamlining a wide range of materials research for functional
thin films.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 01:45:15 GMT""}]","2022-05-17"
"2205.07420","Zhiwei Guo","Shengyu Hu, Zhiwei Guo, Haitao Jiang, and Hong Chen","Photonic Dirac Nodal Line Semimetals Realized by Hyper-crystal","31 pages, 14 figures","Physical Review RESEARCH (2022)","10.1103/PhysRevResearch.4.023047",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, the gapless Dirac/Weyl nodal semimetals with linear dispersion and
topologically protected modes degeneracy are rapidly growing frontiers of
topological physics. Especially, type-I, type-II, and critical type-III nodal
semimetals are discovered according to the tilt angles of the Dirac/Weyl cones.
Here, by introducing hyperbolic metamaterials into one-dimensional photonic
crystals, we design the ""hyper-crystal"" and study the photonic four-fold
degenerate Dirac nodal line semimetals (DNLSs) with two types of
perpendicularly polarized waves. Moreover, the flexibly controlled photonic
DNLSs using the phase compensation effect of hyperbolic dispersion are studied.
Our results not only demonstrate a new platform to realize the various photonic
DNLSs, where the optical polarization plays the role of electron spin in
electronic DNLSs, but also may pave a novel way to explore the abundant
Dirac/Weyl physics in the simple classical wave systems.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 01:57:31 GMT""}]","2022-05-17"
"2205.07421","Jay Hwan Lee","Jay Hwan Lee, Yeonsoo Kim, Younghyun Ryu, Wasuwee Sodsong, Hyunjun
  Jeon, Jinsik Park, Bernd Burgstaller, Bernhard Scholz","Julia Cloud Matrix Machine: Dynamic Matrix Language Acceleration on
  Multicore Clusters in the Cloud",,,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Matrix computations are widely used in increasing sizes and complexity in
scientific computing and engineering. But current matrix language
implementations lack programmer support to effectively and seamlessly utilize
cloud computing resources. We extend the Julia high-performance compute
language to automatically parallelize matrix computations for the cloud. Users
are shielded from the complexity of explicitly-parallel computations through
the provision of a novel matrix data type with lazy evaluation semantics.
Delayed evaluation aggregates operations into expression trees that are
rewritten on-the-fly to eliminate common subexpressions and apply optimizations
such as exponentiation-by-squaring on matching subtrees. Trees are lowered into
DAGs for which dynamic simulation selects the optimal tile size and execution
schedule for a given cluster of cloud nodes. We employ off-line profiling to
construct a time model for the compute and network capacity of the cluster. The
experimental evaluation of our framework comprises eleven benchmarks on a
cluster of eight nodes (288 vCPUs) in the AWS public cloud and reveals speedups
of up to a factor of 4.11x, with an average 78.36% of the theoretically
possible maximum speedup.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 02:04:07 GMT""},{""version"":""v2"",""created"":""Wed, 4 Jan 2023 02:40:28 GMT""}]","2023-01-05"
"2205.07422","Yang Liu","Yang Liu, Xiaoqi Wang, Xi Wang, Zhen Wang, J\""urgen Kurths","PrEF: Percolation-based Evolutionary Framework for the
  diffusion-source-localization problem in large networks",,,,,"cs.SI cs.NE physics.data-an physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We assume that the state of a number of nodes in a network could be
investigated if necessary, and study what configuration of those nodes could
facilitate a better solution for the diffusion-source-localization (DSL)
problem. In particular, we formulate a candidate set which contains the
diffusion source for sure, and propose the method, Percolation-based
Evolutionary Framework (PrEF), to minimize such set. Hence one could further
conduct more intensive investigation on only a few nodes to target the source.
To achieve that, we first demonstrate that there are some similarities between
the DSL problem and the network immunization problem. We find that the
minimization of the candidate set is equivalent to the minimization of the
order parameter if we view the observer set as the removal node set. Hence,
PrEF is developed based on the network percolation and evolutionary algorithm.
The effectiveness of the proposed method is validated on both model and
empirical networks in regard to varied circumstances. Our results show that the
developed approach could achieve a much smaller candidate set compared to the
state of the art in almost all cases. Meanwhile, our approach is also more
stable, i.e., it has similar performance irrespective of varied infection
probabilities, diffusion models, and outbreak ranges. More importantly, our
approach might provide a new framework to tackle the DSL problem in extreme
large networks.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 02:15:14 GMT""},{""version"":""v2"",""created"":""Thu, 19 May 2022 03:33:51 GMT""}]","2022-05-20"
"2205.07423","Dong Li Dr.","Dong Li and Wei Chen","Quasi-periodic Accelerations of Energetic Particles during a Solar Flare","16 pages, 5 figures, accept for publication in ApJL. Comments are
  welcome",,"10.3847/2041-8213/ac6fd2",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the observation of non-stationary Quasi-Periodic Pulsations (QPPs)
in high-energy particles during the impulsive phase of an X4.8 flare on 2002
July 23 (SOL2002-07-23T00:35). The X4.8 flare was simultaneously measured by
the Reuven Ramaty High Energy Solar Spectroscopic Imager, Nobeyama Radio
Polarimeters, and Nobeyama Radioheliograph. The quasi-period of about 50 s,
determined by the wavelet transform, is detected in the Gamma-ray line
emission. Using the same method, a quasi-period of about 90 s is found in
Gamma-ray continuum, hard X-ray (HXR) and radio emissions during almost the
same time. Our observations suggest that the flare QPPs should be associated
with energetic ions and nonthermal electrons that quasi-periodically
accelerated by the repetitive magnetic reconnection. The different
quasi-periods between Gamma-ray line and continuum/HXR/radio emissions indicate
an apparent difference in acceleration or propagation between energetic ions
and nonthermal electrons of this solar flare.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 02:19:12 GMT""}]","2022-06-08"
"2205.07424","Shirui Pan","He Zhang, Bang Wu, Xingliang Yuan, Shirui Pan, Hanghang Tong, Jian Pei","Trustworthy Graph Neural Networks: Aspects, Methods and Trends","36 pages, 7 tables, 4 figures",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Graph neural networks (GNNs) have emerged as a series of competent graph
learning methods for diverse real-world scenarios, ranging from daily
applications like recommendation systems and question answering to cutting-edge
technologies such as drug discovery in life sciences and n-body simulation in
astrophysics. However, task performance is not the only requirement for GNNs.
Performance-oriented GNNs have exhibited potential adverse effects like
vulnerability to adversarial attacks, unexplainable discrimination against
disadvantaged groups, or excessive resource consumption in edge computing
environments. To avoid these unintentional harms, it is necessary to build
competent GNNs characterised by trustworthiness. To this end, we propose a
comprehensive roadmap to build trustworthy GNNs from the view of the various
computing technologies involved. In this survey, we introduce basic concepts
and comprehensively summarise existing efforts for trustworthy GNNs from six
aspects, including robustness, explainability, privacy, fairness,
accountability, and environmental well-being. Additionally, we highlight the
intricate cross-aspect relations between the above six aspects of trustworthy
GNNs. Finally, we present a thorough overview of trending directions for
facilitating the research and industrialisation of trustworthy GNNs.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 02:21:09 GMT""}]","2022-05-17"
"2205.07425","Christian Pilato","Chiara Muscari Tomajoli, Luca Collini, Jitendra Bhandari, Abdul Khader
  Thalakkattu Moosa, Benjamin Tan, Xifan Tang, Pierre-Emmanuel Gaillardon,
  Ramesh Karri, Christian Pilato","ALICE: An Automatic Design Flow for eFPGA Redaction","Paper accepted for presentation at the IEEE/ACM Design Automation
  Conference (DAC 2022)",,"10.1145/3489517.3530543",,"cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fabricating an integrated circuit is becoming unaffordable for many
semiconductor design houses. Outsourcing the fabrication to a third-party
foundry requires methods to protect the intellectual property of the hardware
designs. Designers can rely on embedded reconfigurable devices to completely
hide the real functionality of selected design portions unless the
configuration string (bitstream) is provided. However, selecting such portions
and creating the corresponding reconfigurable fabrics are still open problems.
We propose ALICE, a design flow that addresses the EDA challenges of this
problem. ALICE partitions the RTL modules between one or more reconfigurable
fabrics and the rest of the circuit, automating the generation of the
corresponding redacted design.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 02:21:52 GMT""}]","2022-05-17"
"2205.07426","Tieliang Gong","Yuxin Dong and Tieliang Gong and Shujian Yu and Chen Li","Optimal Randomized Approximations for Matrix based Renyi's Entropy",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Matrix-based Renyi's entropy enables us to directly measure information
quantities from given data without the costly probability density estimation of
underlying distributions, thus has been widely adopted in numerous statistical
learning and inference tasks. However, exactly calculating this new information
quantity requires access to the eigenspectrum of a semi-positive definite (SPD)
matrix $A$ which grows linearly with the number of samples $n$, resulting in a
$O(n^3)$ time complexity that is prohibitive for large-scale applications. To
address this issue, this paper takes advantage of stochastic trace
approximations for matrix-based Renyi's entropy with arbitrary $\alpha \in R^+$
orders, lowering the complexity by converting the entropy approximation to a
matrix-vector multiplication problem. Specifically, we develop random
approximations for integer order $\alpha$ cases and polynomial series
approximations (Taylor and Chebyshev) for non-integer $\alpha$ cases, leading
to a $O(n^2sm)$ overall time complexity, where $s,m \ll n$ denote the number of
vector queries and the polynomial order respectively. We theoretically
establish statistical guarantees for all approximation algorithms and give
explicit order of s and m with respect to the approximation error
$\varepsilon$, showing optimal convergence rate for both parameters up to a
logarithmic factor. Large-scale simulations and real-world applications
validate the effectiveness of the developed approximations, demonstrating
remarkable speedup with negligible loss in accuracy.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 02:24:52 GMT""}]","2022-05-17"
"2205.07427","Weiyao Zhu","Weiyao Zhu, Ou Wu, Fengguang Su, and Yingjun Deng","Exploring the Learning Difficulty of Data Theory and Measure","Ou Wu is the corresponding author of this work",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  As learning difficulty is crucial for machine learning (e.g.,
difficulty-based weighting learning strategies), previous literature has
proposed a number of learning difficulty measures. However, no comprehensive
investigation for learning difficulty is available to date, resulting in that
nearly all existing measures are heuristically defined without a rigorous
theoretical foundation. In addition, there is no formal definition of easy and
hard samples even though they are crucial in many studies. This study attempts
to conduct a pilot theoretical study for learning difficulty of samples. First,
a theoretical definition of learning difficulty is proposed on the basis of the
bias-variance trade-off theory on generalization error. Theoretical definitions
of easy and hard samples are established on the basis of the proposed
definition. A practical measure of learning difficulty is given as well
inspired by the formal definition. Second, the properties for learning
difficulty-based weighting strategies are explored. Subsequently, several
classical weighting methods in machine learning can be well explained on
account of explored properties. Third, the proposed measure is evaluated to
verify its reasonability and superiority in terms of several main difficulty
factors. The comparison in these experiments indicates that the proposed
measure significantly outperforms the other measures throughout the
experiments.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 02:28:12 GMT""},{""version"":""v2"",""created"":""Sat, 17 Sep 2022 06:00:05 GMT""}]","2022-09-20"
"2205.07428","Xinyi Xu Mr","Lucas Agussurja, Xinyi Xu, Bryan Kian Hsiang Low","On the Convergence of the Shapley Value in Parametric Bayesian Learning
  Games","Accepted to the 39th International Conference on Machine Learning
  (ICML 2022). Extended version with derivations",,,,"cs.LG cs.GT stat.ML","http://creativecommons.org/licenses/by/4.0/","  Measuring contributions is a classical problem in cooperative game theory
where the Shapley value is the most well-known solution concept. In this paper,
we establish the convergence property of the Shapley value in parametric
Bayesian learning games where players perform a Bayesian inference using their
combined data, and the posterior-prior KL divergence is used as the
characteristic function. We show that for any two players, under some
regularity conditions, their difference in Shapley value converges in
probability to the difference in Shapley value of a limiting game whose
characteristic function is proportional to the log-determinant of the joint
Fisher information. As an application, we present an online collaborative
learning framework that is asymptotically Shapley-fair. Our result enables this
to be achieved without any costly computations of posterior-prior KL
divergences. Only a consistent estimator of the Fisher information is needed.
The effectiveness of our framework is demonstrated with experiments using
real-world data.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 02:29:14 GMT""},{""version"":""v2"",""created"":""Tue, 14 Jun 2022 13:50:14 GMT""}]","2022-06-15"
"2205.07429","Chenwei Lv","Chenwei Lv and Qi Zhou","Emergent spacetimes from Hermitian and non-Hermitian quantum dynamics","6+3 pages, 3 figures",,,,"cond-mat.quant-gas quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that quantum dynamics of any systems with $SU(1,1)$ symmetry give
rise to emergent Anti-de Sitter spacetimes in 2+1 dimensions (AdS$_{2+1}$).
Using the continuous circuit depth, a quantum evolution is mapped to a
trajectory in AdS$_{2+1}$. Whereas the time measured in laboratories becomes
either the proper time or the proper distance, quench dynamics follow geodesics
of AdS$_{2+1}$. Such a geometric approach provides a unified interpretation of
a wide range of prototypical phenomena that appear disconnected. For instance,
the light cone of AdS$_{2+1}$ underlies expansions of unitary fermions released
from harmonic traps, the onsite of parametric amplifications, and the
exceptional points that represent the $PT$ symmetry breaking in non-Hermitian
systems. Our work provides a transparent means to optimize quantum controls by
exploiting shortest paths in the emergent spacetimes. It also allows
experimentalists to engineer emergent spacetimes and induce tunnelings between
different AdS$_{2+1}$.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 02:34:07 GMT""}]","2022-05-17"
"2205.07430","John Taylor","John Taylor, Wenyi Wang, Biswajit Bala, Tomasz Bednarz","Optimizing the optimizer for data driven deep neural networks and
  physics informed neural networks","23 page, 12 figures",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  We investigate the role of the optimizer in determining the quality of the
model fit for neural networks with a small to medium number of parameters. We
study the performance of Adam, an algorithm for first-order gradient-based
optimization that uses adaptive momentum, the Levenberg and Marquardt (LM)
algorithm a second order method, Broyden,Fletcher,Goldfarb and Shanno algorithm
(BFGS) a second order method and LBFGS, a low memory version of BFGS. Using
these optimizers we fit the function y = sinc(10x) using a neural network with
a few parameters. This function has a variable amplitude and a constant
frequency. We observe that the higher amplitude components of the function are
fitted first and the Adam, BFGS and LBFGS struggle to fit the lower amplitude
components of the function. We also solve the Burgers equation using a physics
informed neural network(PINN) with the BFGS and LM optimizers. For our example
problems with a small to medium number of weights, we find that the LM
algorithm is able to rapidly converge to machine precision offering significant
benefits over other optimizers. We further investigated the Adam optimizer with
a range of models and found that Adam optimiser requires much deeper models
with large numbers of hidden units containing up to 26x more parameters, in
order to achieve a model fit close that achieved by the LM optimizer. The LM
optimizer results illustrate that it may be possible build models with far
fewer parameters. We have implemented all our methods in Keras and TensorFlow
2.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 02:42:22 GMT""}]","2022-05-17"
"2205.07431","Thang Pham","Ben Lund, Thang Pham, Vu Thi Huong Thu","Radial projection theorems in finite spaces","V2: Proof of Lemma 3.1 is corrected",,,,"math.CA math.CO","http://creativecommons.org/licenses/by/4.0/","  Motivated by recent results on radial projections and applications to the
celebrated Falconer distance problem, we study radial projections in the
setting of finite fields. More precisely, we extend results due to Mattila and
Orponen (2016), Orponen (2018), and Liu (2020) to finite spaces. In some cases,
our results are stronger than the corresponding results in the continuous
setting. In particular, we solve the finite field analog of a conjecture due to
Liu and Orponen on the exceptional set of radial projections of a set of
dimension between $d-2$ and $d-1$.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 02:43:13 GMT""},{""version"":""v2"",""created"":""Mon, 1 Aug 2022 07:54:27 GMT""}]","2022-08-02"
"2205.07432","Derchyi Wu","Derchyi Wu","Stability of Kadomtsev-Petviashvili multi-line solitons","We revise the introduction and add two more sections to complete the
  inverse scattering theory and prove a stability theorem",,,,"math.AP nlin.SI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Building upon Boiti et al's work, a rigorous inverse scattering theory of
perturbed Kadomtsev Petviashvili Grassmannian solitons is completed. It yields
an $L^\infty$-stability theorem of the Kadomtsev Petviashvili multi-line
solitons simultaneously
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 02:46:35 GMT""},{""version"":""v2"",""created"":""Tue, 22 Nov 2022 23:59:17 GMT""}]","2022-11-24"
"2205.07433","Yefei He","Yefei He, Luoming Zhang, Weijia Wu, Hong Zhou","Binarizing by Classification: Is soft function really necessary?","submitted to NeurIPS2022",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Binary neural network leverages the $Sign$ function to binarize real values,
and its non-derivative property inevitably brings huge gradient errors during
backpropagation. Although many hand-designed soft functions have been proposed
to approximate gradients, their mechanism is not clear and there are still huge
performance gaps between binary models and their full-precision counterparts.
To address this, we propose to tackle network binarization as a binary
classification problem and use a multi-layer perceptron (MLP) as the
classifier. The MLP-based classifier can fit any continuous function
theoretically and is adaptively learned to binarize networks and backpropagate
gradients without any specific soft function. With this view, we further prove
experimentally that even a simple linear function can outperform previous
complex soft functions. Extensive experiments demonstrate that the proposed
method yields surprising performance both in image classification and human
pose estimation tasks. Specifically, we achieve 65.7% top-1 accuracy of
ResNet-34 on ImageNet dataset, with an absolute improvement of 2.8%. When
evaluating on the challenging Microsoft COCO keypoint dataset, the proposed
method enables binary networks to achieve a mAP of 60.6 for the first time, on
par with some full-precision methods.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 02:47:41 GMT""},{""version"":""v2"",""created"":""Thu, 11 Aug 2022 06:20:14 GMT""}]","2022-08-12"
"2205.07434","The CMS Collaboration","CMS Collaboration","Search for CP violating top quark couplings in pp collisions at
  $\sqrt{s}$ = 13 TeV","Submitted to the Journal of High Energy Physics. All figures and
  tables can be found at
  http://cms-results.web.cern.ch/cms-results/public-results/publications/TOP-18-007
  (CMS Public Pages)",,,"CMS-TOP-18-007, CERN-EP-2021-143","hep-ex","http://creativecommons.org/licenses/by/4.0/","  Results are presented from a search for CP violation in top quark pair
production, using proton-proton collisions at a center-of-mass energy of 13
TeV. The data used for this analysis consist of final states with two charged
leptons collected by the CMS experiment, and correspond to an integrated
luminosity of 35.9 fb$^{-1}$. The search uses two observables, $\mathcal{O}_1$
and $\mathcal{O}_3$, which are Lorentz scalars. The observable $\mathcal{O}_1$
is constructed from the four-momenta of the charged leptons and the
reconstructed top quarks, while $\mathcal{O}_3$ consists of the four-momenta of
the charged leptons and the b quarks originating from the top quarks.
Asymmetries in these observables are sensitive to CP violation, and their
measurement is used to determine the chromoelectric dipole moment of the top
quark. The results are consistent with the expectation from the standard model.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 02:51:52 GMT""}]","2022-05-17"
"2205.07435","Micha{\l} {\L}asica","Yoshikazu Giga, Hirotoshi Kuroda, Micha{\l} {\L}asica","The fourth-order total variation flow in $\mathbb{R}^n$","39 pages, 6 figures, to appear in Math. Eng",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We define rigorously a solution to the fourth-order total variation flow
equation in $\mathbb{R}^n$. If $n\geq3$, it can be understood as a gradient
flow of the total variation energy in $D^{-1}$, the dual space of $D^1_0$,
which is the completion of the space of compactly supported smooth functions in
the Dirichlet norm. However, in the low dimensional case $n\leq2$, the space
$D^{-1}$ does not contain characteristic functions of sets of positive measure,
so we extend the notion of solution to a larger space. We characterize the
solution in terms of what is called the Cahn-Hoffman vector field, based on a
duality argument. This argument relies on an approximation lemma which itself
is interesting.
  We introduce a notion of calibrability of a set in our fourth-order setting.
This notion is related to whether a characteristic function preserves its form
throughout the evolution. It turns out that all balls are calibrable. However,
unlike in the second-order total variation flow, the outside of a ball is
calibrable if and only if $n\neq2$. If $n\neq2$, all annuli are calibrable,
while in the case $n=2$, if an annulus is too thick, it is not calibrable.
  We compute explicitly the solution emanating from the characteristic function
of a ball. We also provide a description of the solution emanating from any
piecewise constant, radially symmetric datum in terms of a system of ODEs.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 02:52:04 GMT""},{""version"":""v2"",""created"":""Fri, 19 May 2023 15:57:50 GMT""}]","2023-05-22"
"2205.07436","Toshiaki Fujimori","Toshiaki Fujimori, Syo Kamata, Tatsuhiro Misumi, Muneto Nitta,
  Norisuke Sakai","All-order Resurgence from Complexified Path Integral in a Quantum
  Mechanical System with Integrability","36 pages, 7 figures",,"10.1103/PhysRevD.107.105011",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss all-order transseries in one of the simplest quantum mechanical
systems: a U(1) symmetric single-degree-of-freedom system with a first-order
time derivative term. Following the procedure of the Lefschetz thimble method,
we explicitly evaluate the path integral for the generating function of the
Noether charge and derive its exact transseries expression. Using the
conservation law, we find all the complex saddle points of the action, which
are responsible for the non-perturbative effects and the resurgence structure
of the model. The all-order power-series contributions around each saddle point
are generated from the one-loop determinant with the help of the differential
equations obeyed by the generating function. The transseries are constructed by
summing up the contributions from all the relevant saddle points, which we
identify by determining the intersection numbers between the dual thimbles and
the original path integration contour. We confirm that the Borel ambiguities of
the perturbation series are canceled by the non-perturbative ambiguities
originating from the discontinuous jumps of the intersection numbers. The
transseries computed in the path-integral formalism agrees with the exact
generating function, whose explicit form can be obtained in the operator
formalism thanks to the integrable nature of the model. This agreement
indicates the non-perturbative completeness of the transseries obtained by the
semi-classical expansion of the path integral based on the Lefschetz thimble
method.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 02:55:26 GMT""}]","2023-05-31"
"2205.07437","Jiahao Li","Jiahao Li, Alexis Samoylov, Jeeeun Kim, Xiang 'Anthony' Chen","Roman: Making Everyday Objects Robotically Manipulable with 3D-Printable
  Add-on Mechanisms",,,"10.1145/3491102.3501818",,"cs.RO cs.HC","http://creativecommons.org/licenses/by/4.0/","  One important vision of robotics is to provide physical assistance by
manipulating different everyday objects, e.g., hand tools, kitchen utensils.
However, many objects designed for dexterous hand-control are not easily
manipulable by a single robotic arm with a generic parallel gripper.
Complementary to existing research on developing grippers and control
algorithms, we present Roman, a suite of hardware design and software tool
support for robotic engineers to create 3D printable mechanisms attached to
everyday handheld objects, making them easier to be manipulated by conventional
robotic arms. The Roman hardware comes with a versatile magnetic gripper that
can snap on/off handheld objects and drive add-on mechanisms to perform tasks.
Roman also provides software support to register and author control programs.
To validate our approach, we designed and fabricated Roman mechanisms for 14
everyday objects/tasks presented within a design space and conducted expert
interviews with robotic engineers indicating that Roman serves as a practical
alternative for enabling robotic manipulation of everyday objects.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 04:19:43 GMT""}]","2022-05-17"
"2205.07438","Bindu Rani Dr.","B. Rani, S. A. Mundo, R. Mushotzky, A. Y. Lien, M. A. Gurwell, J. Y.
  Kim","Hard X-ray emission in Centaurus A","Accepted for publication in ApJ",,"10.3847/1538-4357/ac6fd4",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We used 13 years of Swift/BAT observations to probe the nature and origin of
hard X-ray (14-195 KeV) emission in Centaurus A. Since the beginning of the
Swift operation in 2004, significant X-ray variability in the 14-195 KeV band
is detected, with mild changes in the source spectrum. Spectral variations
became more eminent after 2013, following a softer-when-brighter trend. Using
the power spectral density method, we found that the observed hard X-ray photon
flux variations are consistent with a red-noise process of slope, $-1.3$ with
no evidence for a break in the PSD. We found a significant correlation between
hard X-ray and 230 GHz radio flux variations, with no time delay longer than 30
days. The temporal and spectral analysis rules out the ADAF
(advection-dominated accretion flow) model, and confirms that the hard X-ray
emission is produced in the inner regions of the radio jet.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 04:22:51 GMT""}]","2022-06-29"
"2205.07439","Yuxin Deng","Yuxin Deng and Jiayi Ma","ReDFeat: Recoupling Detection and Description for Multimodal Feature
  Learning",,,"10.1109/TIP.2022.3231135",,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep-learning-based local feature extraction algorithms that combine
detection and description have made significant progress in visible image
matching. However, the end-to-end training of such frameworks is notoriously
unstable due to the lack of strong supervision of detection and the
inappropriate coupling between detection and description. The problem is
magnified in cross-modal scenarios, in which most methods heavily rely on the
pre-training. In this paper, we recouple independent constraints of detection
and description of multimodal feature learning with a mutual weighting
strategy, in which the detected probabilities of robust features are forced to
peak and repeat, while features with high detection scores are emphasized
during optimization. Different from previous works, those weights are detached
from back propagation so that the detected probability of indistinct features
would not be directly suppressed and the training would be more stable.
Moreover, we propose the Super Detector, a detector that possesses a large
receptive field and is equipped with learnable non-maximum suppression layers,
to fulfill the harsh terms of detection. Finally, we build a benchmark that
contains cross visible, infrared, near-infrared and synthetic aperture radar
image pairs for evaluating the performance of features in feature matching and
image registration tasks. Extensive experiments demonstrate that features
trained with the recoulped detection and description, named ReDFeat, surpass
previous state-of-the-arts in the benchmark, while the model can be readily
trained from scratch.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 04:24:22 GMT""}]","2023-01-18"
"2205.07440","Juzar Thingna Dr","Jeongrak Son and Peter Talkner and Juzar Thingna","Charging quantum batteries via Otto machines: The influence of
  monitoring","13 pages, 11 figures, and comments are welcome","Phys. Rev. A 106, 052202 (2022)","10.1103/PhysRevA.106.052202",,"quant-ph cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  The charging of a quantum battery by a four-stroke quantum machine that works
either as an engine or a refrigerator is investigated. The presented analysis
provides the energetic behavior of the combined system in terms of the heat and
workflows of the machine, the average, and variance of the battery's energy as
well as the coherent and incoherent parts of its ergotropy. To monitor the
battery state its energy is measured either after the completion of any cycle
or after a prescribed number of cycles is carried out. The resulting battery
performances greatly differ for those two cases. During the first charging
epoch with an engine, the regular measurements speed up the charging, whereas
the gain of ergotropy is more pronounced in the absence of measurements. In a
later stage, the engine fails to work as such while it still continues charging
the battery that eventually reaches the maximally charged state in the absence
of intermediate measurements and a suboptimally charged state for a
periodically measured battery. For a refrigerator, the charging of the measured
battery also proceeds faster during the first epoch. Only during the second
stage when the machine fails to extract heat from the cold bath the influence
of the measurements become less pronounced leading to rather similar asymptotic
states for the two measurement scenarios.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 04:24:34 GMT""},{""version"":""v2"",""created"":""Fri, 23 Sep 2022 16:29:56 GMT""}]","2022-11-11"
"2205.07441","Hengwei Zhang","Hengwei Zhang, Hua Yang, Haitao Wang, Zhigang Wang, Shengmin Zhang,
  Ming Chen","Autonomous Electric Vehicle Battery Disassembly Based on NeuroSymbolic
  Computing","Accepted to IntelliSys 2022(Intelligent Systems Conference),15 pages
  with 6 figures",,,"CONF-220910","cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The booming of electric vehicles demands efficient battery disassembly for
recycling to be environment-friendly. Due to the unstructured environment and
high uncertainties, battery disassembly is still primarily done by humans,
probably assisted by robots. It is highly desirable to design autonomous
solutions to improve work efficiency and lower human risks in high voltage and
toxic environments. This paper proposes a novel framework of the NeuroSymbolic
task and motion planning method to disassemble batteries in an unstructured
environment using robots automatically. It enables robots to independently
locate and disassemble battery bolts, with or without obstacles. This study not
only provides a solution for intelligently disassembling electric vehicle
batteries but also verifies its feasibility through a set of test results with
the robot accomplishing the disassembly tasks in a complex and dynamic
environment.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 04:32:53 GMT""}]","2022-05-17"
"2205.07442","Adrian Ioana","Ionut Chifan, Daniel Drimbe and Adrian Ioana","Embedding universality for II$_1$ factors with property (T)",,,,,"math.OA math.DS math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that every separable tracial von Neumann algebra embeds into a
II$_1$ factor with property (T) which can be taken to have trivial outer
automorphism and fundamental groups. We also establish an analogous result for
the trivial extension over a non-atomic probability space of every countable
p.m.p. equivalence relation. These results are obtained by using the class of
wreath-like product groups introduced recently in \cite{CIOS21}.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 04:46:41 GMT""}]","2022-05-17"
"2205.07443","Shakil Khan","Shakil M. Khan","Behaviour Explanation via Causal Analysis of Mental States: A
  Preliminary Report","8 pages",,,,"cs.AI cs.LO cs.MA","http://creativecommons.org/licenses/by/4.0/","  Inspired by a novel action-theoretic formalization of actual cause, Khan and
Lesp\'erance (2021) recently proposed a first account of causal knowledge that
supports epistemic effects, models causal knowledge dynamics, and allows
sensing actions to be causes of observed effects. To date, no other study has
looked specifically at these issues. But their formalization is not
sufficiently expressive enough to model explanations via causal analysis of
mental states as it ignores a crucial aspect of theory of mind, namely
motivations. In this paper, we build on their work to support causal reasoning
about conative effects. In our framework, one can reason about causes of
motivational states, and we allow motivation-altering actions to be causes of
observed effects. We illustrate that this formalization along with a model of
goal recognition can be utilized to explain agent behaviour in communicative
multiagent contexts.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 04:46:50 GMT""}]","2022-05-17"
"2205.07444","Ruck Thawonmas","Thai Van Nguyen, Xincheng Dai, Ibrahim Khan, Ruck Thawonmas, Hai V.
  Pham","A Deep Reinforcement Learning Blind AI in DareFightingICE","2022 IEEE Conference on Games (CoG 2022)",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  This paper presents a deep reinforcement learning agent (AI) that uses sound
as the input on the DareFightingICE platform at the DareFightingICE Competition
in IEEE CoG 2022. In this work, an AI that only uses sound as the input is
called blind AI. While state-of-the-art AIs rely mostly on visual or structured
observations provided by their environments, learning to play games from only
sound is still new and thus challenging. We propose different approaches to
process audio data and use the Proximal Policy Optimization algorithm for our
blind AI. We also propose to use our blind AI in evaluation of sound designs
submitted to the competition and define two metrics for this task. The
experimental results show the effectiveness of not only our blind AI but also
the proposed two metrics.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 04:48:24 GMT""},{""version"":""v2"",""created"":""Thu, 30 Jun 2022 04:26:56 GMT""}]","2022-07-01"
"2205.07445","Youfa Li","Youfa Li, Hongfei Wang, Deguang Han","Phase retrieval of analytic signals from short-time Fourier transform
  measurements",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Analytic signals constitute a class of signals that are widely applied in
time-frequency analysis such as extracting instantaneous frequency (IF) or
phase derivative in the characterization of ultrashort laser pulse. The purpose
of this paper is to investigate the phase retrieval (PR) problem for analytic
signals in $\mathbb{C}^{N}$ by short-time Fourier transform (STFT) measurements
since they enjoy some very nice structures. Since generic analytic signals are
generally not sparse in the time domain, the existing PR results for sparse (in
time domain) signals do not apply to analytic signals. We will use bandlimited
windows that usually have the full support length $N$ which allows us to get
much better resolutions on low frequencies. More precisely, by exploiting the
structure of the STFT for analytic signals, we prove that the STFT based phase
retrieval (STFT-PR for short) of generic analytic signals can be achieved by
their $(3\lfloor\frac{N}{2}\rfloor+1)$ measurements. Since the generic analytic
signals are $(\lfloor \frac{N}{2}\rfloor+1)$-sparse in the Fourier domain, such
a number of measurements is lower than $4N+\hbox{O}(1)$ and $\hbox{O}(k^{3})$
which are required in the literature for STFT-PR of all signals and of
$k^{2}$-sparse (in the Fourier domain) signals in $\mathbb{C}^{N^{2}}$,
respectively. Moreover, we also prove that if the length $N$ is even and the
windows are also analytic, then the number of measurements can be reduced to
$(\frac{3 N}{2}-1)$. As an application of this we get that the instantaneous
frequency (IF) of a generic analytic signal can be exactly recovered from the
STFT measurements.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 04:51:07 GMT""},{""version"":""v2"",""created"":""Sat, 22 Apr 2023 07:01:36 GMT""}]","2023-04-25"
"2205.07446","Yen-Ting Lin","Yen-Ting Lin, Hui-Chi Kuo, Ze-Song Xu, Ssu Chiu, Chieh-Chi Hung,
  Yi-Cheng Chen, Chao-Wei Huang, Yun-Nung Chen","Miutsu: NTU's TaskBot for the Alexa Prize",,,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper introduces Miutsu, National Taiwan University's Alexa Prize
TaskBot, which is designed to assist users in completing tasks requiring
multiple steps and decisions in two different domains -- home improvement and
cooking. We overview our system design and architectural goals, and detail the
proposed core elements, including question answering, task retrieval, social
chatting, and various conversational modules. A dialogue flow is proposed to
provide a robust and engaging conversation when handling complex tasks. We
discuss the faced challenges during the competition and potential future work.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 04:56:55 GMT""}]","2022-05-17"
"2205.07447","T. Karthick","Arnab Char and T. Karthick","Optimal chromatic bound for ($P_2+P_3$, $\bar{P_2+ P_3}$)-free graphs",,,,,"math.CO cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a graph $G$, let $\chi(G)$ ($\omega(G)$) denote its chromatic (clique)
number. A $P_2+P_3$ is the graph obtained by taking the disjoint union of a
two-vertex path $P_2$ and a three-vertex path $P_3$. A $\bar{P_2+P_3}$ is the
complement graph of a $P_2+P_3$. In this paper, we study the class of
($P_2+P_3$, $\bar{P_2+P_3}$)-free graphs and show that every such graph $G$
with $\omega(G)\geq 3$ satisfies $\chi(G)\leq \max \{\omega(G)+3,
\lfloor\frac{3}{2} \omega(G) \rfloor-1 \}$. Moreover, the bound is tight.
Indeed, for any $k\in {\mathbb N}$ and $k\geq 3$, there is a ($P_2+P_3$,
$\bar{P_2+P_3}$)-free graph $G$ such that $\omega(G)=k$ and $\chi(G)=\max\{k+3,
\lfloor\frac{3}{2} k \rfloor-1 \}$.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 05:02:25 GMT""},{""version"":""v2"",""created"":""Wed, 18 May 2022 05:57:43 GMT""}]","2022-05-19"
"2205.07448","Mohamed A. Abd-Elmagid","Mohamed A. Abd-Elmagid and Harpreet S. Dhillon","Joint Distribution of Ages of Information in Networks",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a general setting of status updating systems in which a set of
source nodes provide status updates about some physical process(es) to a set of
monitors. The freshness of information available at each monitor is quantified
in terms of the Age of Information (AoI), and the vector of AoI processes at
the monitors (or equivalently the age vector) models the continuous state of
the system. While the marginal distributional properties of each AoI process
have been studied for a variety of settings using the stochastic hybrid system
(SHS) approach, we lack a counterpart of this approach to systematically study
their joint distributional properties. Developing such a framework is the main
contribution of this paper. In particular, we model the discrete state of the
system as a finite-state continuous-time Markov chain, and describe the coupled
evolution of the continuous and discrete states of the system by a piecewise
linear SHS with linear reset maps. Using the notion of tensors, we first derive
first-order linear differential equations for the temporal evolution of both
the joint moments and the joint moment generating function (MGF) for an
arbitrary set of age processes. We then characterize the conditions under which
the derived differential equations are asymptotically stable. The generality of
our framework is demonstrated by recovering several existing results as special
cases. Finally, we apply our framework to derive closed-form expressions of the
stationary joint MGF in a multi-source updating system under non-preemptive and
source-agnostic/source-aware preemptive in service queueing disciplines.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 05:05:05 GMT""},{""version"":""v2"",""created"":""Mon, 29 Aug 2022 12:32:39 GMT""},{""version"":""v3"",""created"":""Mon, 12 Sep 2022 14:46:09 GMT""}]","2022-09-13"
"2205.07449","Zipeng Wu","Zipeng Wu, Shi-Yao Hou, Chao Zhang, Lvzhou Li and Bei Zeng","Variational learning algorithms for quantum query complexity",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum query complexity plays an important role in studying quantum
algorithms, which captures the most known quantum algorithms, such as search
and period finding. A query algorithm applies $U_tO_x\cdots U_1O_xU_0$ to some
input state, where $O_x$ is the oracle dependent on some input variable $x$,
and $U_i$s are unitary operations that are independent of $x$, followed by some
measurements for readout. In this work, we develop variational learning
algorithms to study quantum query complexity, by formulating $U_i$s as
parameterized quantum circuits and introducing a loss function that is directly
given by the error probability of the query algorithm. We apply our method to
analyze various cases of quantum query complexity, including a new algorithm
solving the Hamming modulo problem with $4$ queries for the case of $5$-bit
modulo $5$, answering an open question raised in arXiv:2112.14682, and the
result is further confirmed by a Semidefinite Programming (SDP) algorithm.
Compared with the SDP algorithm, our method can be readily implemented on the
near-term Noisy Intermediate-Scale Quantum (NISQ) devices and is more flexible
to be adapted to other cases such as the fractional query models.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 05:16:15 GMT""},{""version"":""v2"",""created"":""Thu, 29 Sep 2022 07:54:14 GMT""}]","2022-09-30"
"2205.07450","Siqi Zheng","Siqi Zheng, Hongbin Suo, Qian Chen","PRISM: Pre-trained Indeterminate Speaker Representation Model for
  Speaker Diarization and Speaker Verification","INTERSPEECH 2022",,,,"cs.SD eess.AS","http://creativecommons.org/licenses/by/4.0/","  Speaker embedding has been a fundamental feature for speaker-related tasks
such as verification, clustering, and diarization. Traditionally, speaker
embeddings are represented as fixed vectors in high-dimensional space. This
could lead to biased estimations, especially when handling shorter utterances.
In this paper we propose to represent a speaker utterance as ""floating"" vector
whose state is indeterminate without knowing the context. The state of a
speaker representation is jointly determined by itself, other speech from the
same speaker, as well as other speakers it is being compared to. The content of
the speech also contributes to determining the final state of a speaker
representation. We pre-train an indeterminate speaker representation model that
estimates the state of an utterance based on the context. The pre-trained model
can be fine-tuned for downstream tasks such as speaker verification, speaker
clustering, and speaker diarization. Substantial improvements are observed
across all downstream tasks.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 05:21:11 GMT""},{""version"":""v2"",""created"":""Mon, 27 Jun 2022 12:42:52 GMT""}]","2022-06-28"
"2205.07451","Suik Cheon","Suik Cheon, Gil Young Cho, Ki-Seok Kim, and Hyun-Woo Lee","Chiral anomaly in noncentrosymmetric systems induced by spin-orbit
  coupling","6 pages, 2 figures","Phys. Rev. B 105, L180303 (2022)","10.1103/PhysRevB.105.L180303",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The chiral anomaly may be realized in condensed matter systems with pairs of
Weyl points. Here we show that the chiral anomaly can be realized in diverse
noncentrosymmetric systems even without Weyl point pairs when spin-orbit
coupling induces nonzero Berry curvature flux through Fermi surfaces. This
motivates the condensed matter chiral anomaly to be interpreted as a Fermi
surface property rather than a Weyl point property. The
spin-orbit-coupling-induced anomaly reproduces the well-known charge transport
properties of the chiral anomaly such as the negative longitudinal
magnetoresistance and the planar Hall effect in Weyl semimetals. Since it is of
spin-orbit coupling origin, it also affects the spin transport and gives rise
to anomaly-induced longitudinal spin currents and the magnetic spin Hall
effect, which are absent in conventional Weyl semimetals.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 05:30:05 GMT""},{""version"":""v2"",""created"":""Tue, 24 May 2022 03:04:27 GMT""}]","2022-05-25"
"2205.07452","Mike Wu","Mike Wu, Will McTighe","Constant Power Root Market Makers","16 pages; proofs inline",,,,"cs.CE","http://creativecommons.org/licenses/by/4.0/","  The paper introduces a new type of constant function market maker, the
constant power root market marker. We show that the constant sum (used by
mStable), constant product (used by Uniswap and Balancer), constant reserve
(HOLD-ing), and constant harmonic mean trading functions are special cases of
the constant power root trading function. We derive the value function for
liquidity providers, marginal price function, price impact function,
impermanent loss function, and greeks for constant power root market markers.
In particular, we find that as the power q varies from the range of -infinity
to 1, the power root function interpolates between the harmonic (q=-1),
geometric (q=0), and arithmetic (q=1) means. This provides a toggle that trades
off between price slippage for traders and impermanent loss for liquidity
providers. As the power q approaches 1, slippage is low and impermanent loss is
high. As q approaches to -1, price slippage increases and impermanent loss
decreases.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 05:38:13 GMT""}]","2022-05-17"
"2205.07453","Sidhant Hargunani","Atharv Sardesai, Hatim Piplodwala, Sidhant Hargunani, Swarnim
  Sonawane, Prof. Pranjali Joshi, Vikram Mohite","Regression Test Suite for Payment Switch using jPOS",,,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  The Payment Switch is an integral component of all modern payment and banking
systems in India. The NPCI currently provides a simulator to test payment
switches. However, this system has a few disadvantages viz. it lacks an API, it
requires manual generation of each test case and during high server loads, the
testing process may take a long time. Currently there aren't any open source
alternatives to the NPCI simulator. We propose a system which solves these
shortcomings. Our proposed system simulates the NPCI system. It allows
connection with switches that are to be tested and automates the process of
generation and execution of test cases. It also has the capability to generate
test reports and can be run locally.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 05:39:23 GMT""}]","2022-05-17"
"2205.07454","Masumi Shimojo","Masumi Shimojo and Kazumasa Iwai","Over seven decades of solar microwave data obtained with Toyokawa and
  Nobeyama Radio Polarimeters","29 pages, 12 figures, accepted to Geoscience Data Journal",,"10.1002/gdj3.165",,"astro-ph.IM astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Monitoring observations of solar microwave fluxes and their polarization
began in Japan during the 1950s at Toyokawa and Mitaka. At present (April
2022), monitoring observations continue with the Nobeyama Radio Polarimeters
(NoRP) at the Nobeyama campus of the National Astronomical Observatory of Japan
(NAOJ). In this paper, we present a brief history of the solar microwave
monitoring observations preceding those now carried out by NoRP. We then review
the solar microwave obtained at Toyokawa and Nobeyama and their metadata. The
datasets are publicly provided by the Solar Data Archive System (SDAS) operated
by the Astronomy Data Center of the NAOJ, via http
(https://solar.nro.nao.ac.jp/norp/) and FTP
(ftp://solar-pub.nao.ac.jp/pub/nsro/norp/) protocols.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 05:41:52 GMT""}]","2022-06-30"
"2205.07455","Li Zhang","Li Zhang","Reasoning about Procedures with Natural Language Processing: A Tutorial",,,,,"cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This tutorial provides a comprehensive and in-depth view of the research on
procedures, primarily in Natural Language Processing. A procedure is a sequence
of steps intended to achieve some goal. Understanding procedures in natural
language has a long history, with recent breakthroughs made possible by
advances in technology. First, we discuss established approaches to collect
procedures, by human annotation or extraction from web resources. Then, we
examine different angles from which procedures can be reasoned about, as well
as ways to represent them. Finally, we enumerate scenarios where procedural
knowledge can be applied to the real world.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 05:42:00 GMT""}]","2022-05-17"
"2205.07456","Saumya Chaturvedi","Saumya Chaturvedi, Zilong Liu, Vivek Ashok Bohara, Anand Srivastava,
  Pei Xiao","A Tutorial on Decoding Techniques of Sparse Code Multiple Access","arXiv admin note: text overlap with arXiv:2105.06860",,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  Sparse Code Multiple Access (SCMA) is a disruptive code-domain non-orthogonal
multiple access (NOMA) scheme to enable \color{black}future massive
machine-type communication networks. As an evolved variant of code division
multiple access (CDMA), multiple users in SCMA are separated by assigning
distinctive sparse codebooks (CBs). Efficient multiuser detection is carried
out at the receiver by employing the message passing algorithm (MPA) that
exploits the sparsity of CBs to achieve error performance approaching to that
of the maximum likelihood receiver. In spite of numerous research efforts in
recent years, a comprehensive one-stop tutorial of SCMA covering the
background, the basic principles, and new advances, is still missing, to the
best of our knowledge. To fill this gap and to stimulate more forthcoming
research, we provide a holistic introduction to the principles of SCMA
encoding, CB design, and MPA based decoding in a self-contained manner. As an
ambitious paper aiming to push the limits of SCMA, we present a survey of
advanced decoding techniques with brief algorithmic descriptions as well as
several promising directions.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 05:55:04 GMT""}]","2022-05-17"
"2205.07457","Samira Jamil","Samira Sahar Jamil, P Christopher Staecker, Danish Ali","Computability of digital cubical singular homology of $c_1$-digital
  images",,,,,"math.AT","http://creativecommons.org/licenses/by/4.0/","  Digital cubical singular homology $dH_q(X)$ for digital images $X$ was
developed by the first and third authors, and digital analogues to various
results in classical algebraic topology were proved. Another homology denoted
$H_q^{c_1}(X)$ was developed by the second author for $c_1$-digital images,
which is computationally much simpler than $dH_q(X)$. This paper shows an
isomorphism between $dH_q(X)$ and $H_q^{c_1}(X)$ when $X$ is a $c_1$-digital
image.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 06:00:02 GMT""}]","2022-05-17"
"2205.07458","Chen Bo-Yong","Bo-Yong Chen","An $L^2$ Hartogs-type extension theorem for unbounded domains",,,,,"math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note, we prove an $L^2$ Hartogs-type extension theorem for unbounded
domains.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 06:02:28 GMT""}]","2022-05-17"
"2205.07459","Fei Huang","Fei Huang, Hao Zhou, Yang Liu, Hang Li, Minlie Huang","Directed Acyclic Transformer for Non-Autoregressive Machine Translation","accepted at ICML2022",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Non-autoregressive Transformers (NATs) significantly reduce the decoding
latency by generating all tokens in parallel. However, such independent
predictions prevent NATs from capturing the dependencies between the tokens for
generating multiple possible translations. In this paper, we propose Directed
Acyclic Transfomer (DA-Transformer), which represents the hidden states in a
Directed Acyclic Graph (DAG), where each path of the DAG corresponds to a
specific translation. The whole DAG simultaneously captures multiple
translations and facilitates fast predictions in a non-autoregressive fashion.
Experiments on the raw training data of WMT benchmark show that DA-Transformer
substantially outperforms previous NATs by about 3 BLEU on average, which is
the first NAT model that achieves competitive results with autoregressive
Transformers without relying on knowledge distillation.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 06:02:29 GMT""}]","2022-05-17"
"2205.07460","Weili Nie","Weili Nie, Brandon Guo, Yujia Huang, Chaowei Xiao, Arash Vahdat, Anima
  Anandkumar","Diffusion Models for Adversarial Purification","ICML 2022",,,,"cs.LG cs.CR cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Adversarial purification refers to a class of defense methods that remove
adversarial perturbations using a generative model. These methods do not make
assumptions on the form of attack and the classification model, and thus can
defend pre-existing classifiers against unseen threats. However, their
performance currently falls behind adversarial training methods. In this work,
we propose DiffPure that uses diffusion models for adversarial purification:
Given an adversarial example, we first diffuse it with a small amount of noise
following a forward diffusion process, and then recover the clean image through
a reverse generative process. To evaluate our method against strong adaptive
attacks in an efficient and scalable way, we propose to use the adjoint method
to compute full gradients of the reverse generative process. Extensive
experiments on three image datasets including CIFAR-10, ImageNet and CelebA-HQ
with three classifier architectures including ResNet, WideResNet and ViT
demonstrate that our method achieves the state-of-the-art results,
outperforming current adversarial training and adversarial purification
methods, often by a large margin. Project page: https://diffpure.github.io.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 06:03:00 GMT""}]","2022-05-17"
"2205.07461","Sen Yang","Sen Yang","Bloch-Ogus theorem,cyclic homology and deformation of Chow groups",,,,,"math.AG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Using Bloch-Ogus theorem and Chern character from K-theory to cyclic
homology, we answer a question of Green and Griffiths on extending Bloch
formula. Moreover, we construct a map from local Hilbert functor to local
cohomology. With suitable assumptions, we use this map to answer a question of
Bloch on constructing a natural transformation from local Hilbert functor to
cohomological Chow groups.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 06:04:23 GMT""}]","2022-05-17"
"2205.07462","Daniel Alpay A","Daniel Alpay and Palle Jorgensen","Finitely additive functions in measure theory and applications",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider, and make precise, a certain extension of the Radon-Nikodym
derivative operator, to functions which are additive, but not necessarily
sigma-additive, on a subset of a given sigma-algebra. We give applications to
probability theory; in particular, to the study of $\mu$-Brownian motion, to
stochastic calculus via generalized It\^o-integrals, and their adjoints (in the
form of generalized stochastic derivatives), to systems of transition
probability operators indexed by families of measures $\mu$, and to adjoints of
composition operators.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 06:06:03 GMT""}]","2022-05-17"
"2205.07463","Tianxiang Gao","Tianxiang Gao, Hongyang Gao","Gradient Descent Optimizes Infinite-Depth ReLU Implicit Networks with
  Linear Widths",,,,,"cs.LG math.OC stat.ML","http://creativecommons.org/licenses/by/4.0/","  Implicit deep learning has recently become popular in the machine learning
community since these implicit models can achieve competitive performance with
state-of-the-art deep networks while using significantly less memory and
computational resources. However, our theoretical understanding of when and how
first-order methods such as gradient descent (GD) converge on
\textit{nonlinear} implicit networks is limited. Although this type of problem
has been studied in standard feed-forward networks, the case of implicit models
is still intriguing because implicit networks have \textit{infinitely} many
layers. The corresponding equilibrium equation probably admits no or multiple
solutions during training. This paper studies the convergence of both gradient
flow (GF) and gradient descent for nonlinear ReLU activated implicit networks.
To deal with the well-posedness problem, we introduce a fixed scalar to scale
the weight matrix of the implicit layer and show that there exists a small
enough scaling constant, keeping the equilibrium equation well-posed throughout
training. As a result, we prove that both GF and GD converge to a global
minimum at a linear rate if the width $m$ of the implicit network is
\textit{linear} in the sample size $N$, i.e., $m=\Omega(N)$.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 06:07:56 GMT""}]","2022-05-17"
"2205.07464","Subhankar Bera","Subhankar Bera, Shashank Gupta, A. S. Majumdar","Device-Independent Quantum Key Distribution Using Random Quantum States","12 pages, 6 figures","Quantum Inf. Process 22, 109 (2023)","10.1007/s11128-023-03852-2",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We Haar uniformly generate random states of various ranks and study their
performance in an entanglement-based quantum key distribution (QKD) task. In
particular, we analyze the efficacy of random two-qubit states in realizing
device-independent (DI) QKD. We first find the normalized distribution of
entanglement and Bell-nonlocality which are the key resource for DI-QKD for
random states ranging from rank-1 to rank-4. The number of entangled as well as
Bell-nonlocal states decreases as rank increases. We observe that decrease of
the secure key rate is more pronounced in comparison to that of the quantum
resource with increase in rank. We find that the pure state and Werner state
provide the upper and lower bound, respectively, on the minimum secure key rate
of all mixed two-qubit states possessing the same magnitude of entanglement
under general as well as optimal collective attack strategies.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 06:13:07 GMT""},{""version"":""v2"",""created"":""Mon, 15 Aug 2022 06:04:17 GMT""},{""version"":""v3"",""created"":""Mon, 13 Feb 2023 10:22:01 GMT""}]","2023-02-14"
"2205.07465","Emilian M. Nica","Emilian M. Nica, Sheng Ran, Lin Jiao, Qimiao Si","Multiple superconducting phases in heavy-fermion metals","33 pages, 8 figures; To be published in Frontiers in Electronic
  Materials","Front. Electron. Mater. 2 (2022)","10.3389/femat.2022.944873",,"cond-mat.supr-con cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  Symmetry breaking beyond a global U(1) phase is the key signature of
unconventional superconductors. As prototypical strongly correlated materials,
heavy-fermion metals provide ideal platforms for realizing unconventional
superconductivity. In this article, we review heavy-fermion superconductivity,
with a focus on those materials with multiple superconducting phases. In this
context, we highlight the role of orbital-selective (matrix) pairing functions,
which are defined as matrices in the space of effective orbital degrees of
freedom such as electronic orbitals and sublattices as well as equivalent
descriptions in terms of intra- and inter-band pairing components in the band
basis. The role of quantum criticality and the associated strange-metal physics
in the development of unconventional superconductivity is emphasized
throughout. We discuss in some detail the recent experimental observations and
theoretical perspectives in the illustrative cases of UTe2, CeRh2As2, and
CeCu2Si2, where applied magnetic fields or pressure induce a variety of
superconducting phases. We close by providing a brief overview of overarching
issues and implications for possible future directions.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 06:15:22 GMT""},{""version"":""v2"",""created"":""Wed, 28 Sep 2022 16:46:54 GMT""}]","2022-12-23"
"2205.07466","Haozhe Liu","Haozhe Liu, Haoqin Ji, Yuexiang Li, Nanjun He, Haoqian Wu, Feng Liu,
  Linlin Shen, Yefeng Zheng","Robust Representation via Dynamic Feature Aggregation",,,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep convolutional neural network (CNN) based models are vulnerable to the
adversarial attacks. One of the possible reasons is that the embedding space of
CNN based model is sparse, resulting in a large space for the generation of
adversarial samples. In this study, we propose a method, denoted as Dynamic
Feature Aggregation, to compress the embedding space with a novel
regularization. Particularly, the convex combination between two samples are
regarded as the pivot for aggregation. In the embedding space, the selected
samples are guided to be similar to the representation of the pivot. On the
other side, to mitigate the trivial solution of such regularization, the last
fully-connected layer of the model is replaced by an orthogonal classifier, in
which the embedding codes for different classes are processed orthogonally and
separately. With the regularization and orthogonal classifier, a more compact
embedding space can be obtained, which accordingly improves the model
robustness against adversarial attacks. An averaging accuracy of 56.91% is
achieved by our method on CIFAR-10 against various attack methods, which
significantly surpasses a solid baseline (Mixup) by a margin of 37.31%. More
surprisingly, empirical results show that, the proposed method can also achieve
the state-of-the-art performance for out-of-distribution (OOD) detection, due
to the learned compact feature space. An F1 score of 0.937 is achieved by the
proposed method, when adopting CIFAR-10 as in-distribution (ID) dataset and
LSUN as OOD dataset. Code is available at
https://github.com/HaozheLiu-ST/DynamicFeatureAggregation.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 06:22:15 GMT""}]","2022-05-17"
"2205.07467","Lingwei Zhu","Lingwei Zhu, Zheng Chen, Eiji Uchibe, Takamitsu Matsubara","$q$-Munchausen Reinforcement Learning",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  The recently successful Munchausen Reinforcement Learning (M-RL) features
implicit Kullback-Leibler (KL) regularization by augmenting the reward function
with logarithm of the current stochastic policy. Though significant improvement
has been shown with the Boltzmann softmax policy, when the Tsallis sparsemax
policy is considered, the augmentation leads to a flat learning curve for
almost every problem considered. We show that it is due to the mismatch between
the conventional logarithm and the non-logarithmic (generalized) nature of
Tsallis entropy. Drawing inspiration from the Tsallis statistics literature, we
propose to correct the mismatch of M-RL with the help of
$q$-logarithm/exponential functions. The proposed formulation leads to implicit
Tsallis KL regularization under the maximum Tsallis entropy framework. We show
such formulation of M-RL again achieves superior performance on benchmark
problems and sheds light on more general M-RL with various entropic indices
$q$.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 06:26:10 GMT""}]","2022-05-17"
"2205.07468","Karol Gietka","Karol Gietka","Harnessing the center-of-mass excitations in quantum metrology","10 pages, 7 figures, comments and feedback greatly appreciated",,,,"quant-ph cond-mat.quant-gas","http://creativecommons.org/licenses/by/4.0/","  In quantum metrology, one typically creates correlations among atoms or
photons to enhance measurement precision. Here, we show how one can use other
excitations to perform quantum-enhanced measurements on the example of
center-of-mass excitations of a spin-orbit coupled Bose-Einstein condensate and
a Coulomb crystal. We also present a method to simulate a homodyne detection of
center-of-mass excitations in these systems, which is required for optimal
estimation.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 06:33:51 GMT""}]","2022-05-17"
"2205.07469","Petros Ioannou","B. F. Farrell, P. J. Ioannou and M.-A. Nikolaidis","Mechanism of Roll-Streak Structure Formation and Maintenance in
  Turbulent Shear Flow","32 pages, 23 figures",,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  In wall-bounded shear flow the primary coherent structure is the streamwise
roll and streak (R-S). Absent of an associated instability the R-S has been
ascribed to non-normality mediated interaction between the mean flow and
perturbations. This interaction may occur either directly due to excitation of
a transiently growing perturbation or indirectly due to destabilization of the
R-S by turbulent Reynolds stresses. A fundamental distinction between the
direct and the indirect mechanisms, which is central to understanding the
physics of turbulence, is that in the direct mechanism the R-S is itself the
growing structure while in the indirect mechanism the R-S emerges as a
self-organized structure. In the emergent R-S theory the fundamental mechanism
is organization by the streak of Reynolds stresses configured to support its
associated roll by the lift-up process. This requires that a streak organizes
turbulent perturbations such as to produce Reynolds stresses configured to
reinforce the streak. In this paper we provide detailed analysis explaining
physically why this positive feedback occurs and is a universal property of
turbulence in shear flow. DNS data from the same turbulent flow as that used in
the theoretical study (Poisseullle flow at R=1650) is also analyzed verifying
that this mechanism operates in DNS.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 06:36:11 GMT""}]","2022-05-17"
"2205.07470","Ivan Costa e Silva","Ivan P. Costa e Silva, Jose Luis Flores, Jonatan Herrera","Omniscient foliations and the geometry of cosmological spacetimes","19 pages, no figures",,"10.1007/s10714-022-03033-z",,"gr-qc math.DG","http://creativecommons.org/licenses/by/4.0/","  We identify certain general geometric conditions on a foliation of a
spacetime (M,g) by timelike curves that will impede the existence of null
geodesic lines, especially if (M,g) possesses a compact Cauchy hypersurface.
The absence of such lines, in turn, yields well-known restrictions on the
geometry of cosmological spacetimes, in the context of Bartnik's splitting
conjecture. Since the (non)existence of null lines is actually a conformally
invariant property, such conditions only need to apply for some suitable
conformal rescaling of g.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 06:43:05 GMT""}]","2022-11-30"
"2205.07471","Hong Wang","Hong Wang, Yuexiang Li, Deyu Meng, Yefeng Zheng","Adaptive Convolutional Dictionary Network for CT Metal Artifact
  Reduction","https://github.com/hongwang01/ACDNet","the 31st International Joint Conference on Artificial Intelligence
  2022",,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Inspired by the great success of deep neural networks, learning-based methods
have gained promising performances for metal artifact reduction (MAR) in
computed tomography (CT) images. However, most of the existing approaches put
less emphasis on modelling and embedding the intrinsic prior knowledge
underlying this specific MAR task into their network designs. Against this
issue, we propose an adaptive convolutional dictionary network (ACDNet), which
leverages both model-based and learning-based methods. Specifically, we explore
the prior structures of metal artifacts, e.g., non-local repetitive streaking
patterns, and encode them as an explicit weighted convolutional dictionary
model. Then, a simple-yet-effective algorithm is carefully designed to solve
the model. By unfolding every iterative substep of the proposed algorithm into
a network module, we explicitly embed the prior structure into a deep network,
\emph{i.e.,} a clear interpretability for the MAR task. Furthermore, our ACDNet
can automatically learn the prior for artifact-free CT images via training data
and adaptively adjust the representation kernels for each input CT image based
on its content. Hence, our method inherits the clear interpretability of
model-based methods and maintains the powerful representation ability of
learning-based methods. Comprehensive experiments executed on synthetic and
clinical datasets show the superiority of our ACDNet in terms of effectiveness
and model generalization. {\color{blue}{{\textit{Code is available at
{\url{https://github.com/hongwang01/ACDNet}}.}}}}
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 06:49:36 GMT""},{""version"":""v2"",""created"":""Thu, 16 Jun 2022 09:06:55 GMT""}]","2022-06-17"
"2205.07472","Ilari J. Maasilta","Zhuoran Geng and Ilari J. Maasilta","Acoustic wave tunneling across a vacuum gap between two piezoelectric
  crystals with arbitrary symmetry and orientation",,,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  It is not widely appreciated that an acoustic wave can ""jump"" or ""tunnel""
across a vacuum gap between two piezoelectric solids, nor has the general case
been formulated or studied in detail. Here, we remedy that situation, by
presenting a general formalism and approach to study such an acoustic tunneling
effect between two arbitrarily oriented anisotropic piezoelectric semi-infinite
crystals. The approach allows one to solve for the reflection and transmission
coefficients of all the partial wave modes, and is amenable to practical
numerical or even analytical implementation, as we demonstrate by a few chosen
examples. The formalism can be used in the future for quantitative studies of
the tunneling effect in connection not only with the manipulation of acoustic
waves, but with many other areas of physics of vibrations such as heat
transport, for example.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 06:52:09 GMT""}]","2022-05-17"
"2205.07473","Ziming Wang","Ziming Wang, Shuang Lian, Yuhao Zhang, Xiaoxin Cui, Rui Yan and Huajin
  Tang","Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with
  Dual-Phase Optimization","This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible",,,,"cs.NE cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spiking neural network (SNN) operating with asynchronous discrete events
shows higher energy efficiency. A popular approach to implementing deep SNNs is
ANN-SNN conversion combining both efficient training of ANNs and efficient
inference of SNNs. However, due to the intrinsic difference between ANNs and
SNNs, the accuracy loss is usually non-negligible, especially under low
simulating steps. It restricts the applications of SNN on latency-sensitive
edge devices greatly. In this paper, we identify such performance degradation
stems from the misrepresentation of the negative or overflow residual membrane
potential in SNNs. Inspired by this, we systematically analyze the conversion
error between SNNs and ANNs, and then decompose it into three folds:
quantization error, clipping error, and residual membrane potential
representation error. With such insights, we propose a dual-phase conversion
algorithm to minimize those errors separately. Besides, we show each phase
achieves significant performance gains in a complementary manner. We evaluate
our method on challenging datasets including CIFAR-10, CIFAR-100, and ImageNet
datasets. The experimental results show the proposed method achieves the
state-of-the-art in terms of both accuracy and latency with promising energy
preservation compared to ANNs. For instance, our method achieves an accuracy of
73.20% on CIFAR-100 in only 2 time steps with 15.7$\times$ less energy
consumption.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 06:53:14 GMT""},{""version"":""v2"",""created"":""Mon, 30 Jan 2023 10:40:06 GMT""}]","2023-01-31"
"2205.07474","Josef Pradler","Josef Pradler","Is there a radio excess from the decoupling of pre-recombination
  bremsstrahlung?","3 pages","Res. Notes AAS 6 266 (2022)","10.3847/2515-5172/acab64",,"hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently it has been suggested that thermal bremsstrahlung emission, when it
decouples prior to recombination, creates an excess over the Planck cosmic
microwave background spectrum at sub-GHz frequencies. Remarkable by itself,
this would also explain a long-standing unexplained deficit in the predictions
of the extragalactic radio background. In this brief note we reiterate that no
such non-thermal component can arise by itself when matter and radiation remain
kinetically coupled.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 06:57:52 GMT""}]","2022-12-19"
"2205.07475","Zuheng Xu","Zuheng Xu, Naitong Chen, Trevor Campbell","MixFlows: principled variational inference via mixed flows",,,,,"stat.ML cs.LG stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work presents mixed variational flows (MixFlows), a new variational
family that consists of a mixture of repeated applications of a map to an
initial reference distribution. First, we provide efficient algorithms for
i.i.d. sampling, density evaluation, and unbiased ELBO estimation. We then show
that MixFlows have MCMC-like convergence guarantees when the flow map is
ergodic and measure-preserving, and provide bounds on the accumulation of error
for practical implementations where the flow map is approximated. Finally, we
develop an implementation of MixFlows based on uncorrected discretized
Hamiltonian dynamics combined with deterministic momentum refreshment.
Simulated and real data experiments show that MixFlows can provide more
reliable posterior approximations than several black-box normalizing flows, as
well as samples of comparable quality to those obtained from state-of-the-art
MCMC methods.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 06:57:57 GMT""},{""version"":""v2"",""created"":""Thu, 13 Oct 2022 22:18:15 GMT""},{""version"":""v3"",""created"":""Fri, 27 Jan 2023 22:48:27 GMT""},{""version"":""v4"",""created"":""Sat, 11 Feb 2023 07:44:29 GMT""},{""version"":""v5"",""created"":""Thu, 1 Jun 2023 06:36:29 GMT""}]","2023-06-02"
"2205.07476","J\'an Koloda","J\'an Koloda, J\""urgen Seiler, Andr\'e Kaup, Victoria S\'anchez,
  Antonio M. Peinado","Frequency selective extrapolation with residual filtering for image
  error concealment",,"2014 IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP), 2014, pp. 1976-1980","10.1109/ICASSP.2014.6853944",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The purpose of signal extrapolation is to estimate unknown signal parts from
known samples. This task is especially important for error concealment in image
and video communication. For obtaining a high quality reconstruction,
assumptions have to be made about the underlying signal in order to solve this
underdetermined problem. Among existent reconstruction algorithms, frequency
selective extrapolation (FSE) achieves high performance by assuming that image
signals can be sparsely represented in the frequency domain. However, FSE does
not take into account the low-pass behaviour of natural images. In this paper,
we propose a modified FSE that takes this prior knowledge into account for the
modelling, yielding significant PSNR gains.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 06:59:36 GMT""}]","2022-05-17"
"2205.07477","Ruan Van Der Merwe Mr","Ruan van der Merwe, Gregory Newman, Etienne Barnard","Manifold Characteristics That Predict Downstream Task Performance","Currently under review",,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  Pretraining methods are typically compared by evaluating the accuracy of
linear classifiers, transfer learning performance, or visually inspecting the
representation manifold's (RM) lower-dimensional projections. We show that the
differences between methods can be understood more clearly by investigating the
RM directly, which allows for a more detailed comparison. To this end, we
propose a framework and new metric to measure and compare different RMs. We
also investigate and report on the RM characteristics for various pretraining
methods. These characteristics are measured by applying sequentially larger
local alterations to the input data, using white noise injections and Projected
Gradient Descent (PGD) adversarial attacks, and then tracking each datapoint.
We calculate the total distance moved for each datapoint and the relative
change in distance between successive alterations. We show that self-supervised
methods learn an RM where alterations lead to large but constant size changes,
indicating a smoother RM than fully supervised methods. We then combine these
measurements into one metric, the Representation Manifold Quality Metric
(RMQM), where larger values indicate larger and less variable step sizes, and
show that RMQM correlates positively with performance on downstream tasks.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 06:59:51 GMT""}]","2022-05-17"
"2205.07478","Sebastien Andreina","Sebastien Andreina, Lorenzo Alluminio, Giorgia Azzurra Marson, Ghassan
  Karame","Estimating Patch Propagation Times across (Blockchain) Forks","A short version of this paper will appear at FC23",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The wide success of Bitcoin has led to a huge surge of alternative
cryptocurrencies (altcoins). Most altcoins essentially fork Bitcoin's code with
minor modifications, such as the number of coins to be minted, the block size,
and the block generation time. As such, they are often deemed identical to
Bitcoin in terms of security, robustness, and maturity.
  In this paper, we show that this common conception is misleading. By mining
data retrieved from the GitHub repositories of various altcoin projects, we
estimate the time it took to propagate relevant patches from Bitcoin to the
altcoins. We find that, while the Bitcoin development community is quite active
in fixing security flaws of Bitcoin's code base, forked cryptocurrencies are
not as rigorous in patching the same vulnerabilities (inherited from Bitcoin).
In some cases, we observe that even critical vulnerabilities, discovered and
fixed within the Bitcoin community, have been addressed by the altcoins tens of
months after disclosure. Besides raising awareness of this problem, our work
aims to motivate the need for a proper responsible disclosure of
vulnerabilities to all forked chains prior to reporting them publicly.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 06:59:57 GMT""},{""version"":""v2"",""created"":""Thu, 9 Feb 2023 16:41:40 GMT""}]","2023-02-10"
"2205.07479","Ekta Samani","Ekta U. Samani and Ashis G. Banerjee","Topologically Persistent Features-based Object Recognition in Cluttered
  Indoor Environments","Accepted for presentation in the IEEE International Conference on
  Robotics and Automation (ICRA) 2022 Workshop on Robotic Perception and
  Mapping: Emerging Techniques",,,,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recognition of occluded objects in unseen indoor environments is a
challenging problem for mobile robots. This work proposes a new slicing-based
topological descriptor that captures the 3D shape of object point clouds to
address this challenge. It yields similarities between the descriptors of the
occluded and the corresponding unoccluded objects, enabling object unity-based
recognition using a library of trained models. The descriptor is obtained by
partitioning an object's point cloud into multiple 2D slices and constructing
filtrations (nested sequences of simplicial complexes) on the slices to mimic
further slicing of the slices, thereby capturing detailed shapes through
persistent homology-generated features. We use nine different sequences of
cluttered scenes from a benchmark dataset for performance evaluation. Our
method outperforms two state-of-the-art deep learning-based point cloud
classification methods, namely, DGCNN and SimpleView.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 07:01:16 GMT""}]","2022-05-17"
"2205.07480","Chen-Kai Lin","Chen-Kai Lin and Bow-Yaw Wang","Analyzing FreeRTOS Scheduling Behaviors with the Spin Model Checker",,,,,"cs.FL cs.OS","http://creativecommons.org/licenses/by/4.0/","  FreeRTOS is a real-time operating system with configurable scheduling
policies. Its portability and configurability make FreeRTOS one of the most
popular real-time operating systems for embedded devices. We formally analyze
the FreeRTOS scheduler on ARM Cortex-M4 processor in this work. Specifically,
we build a formal model for the FreeRTOS ARM Cortex-M4 port and apply model
checking to find errors in our models for FreeRTOS example applications.
Intriguingly, several errors are found in our application models under
different scheduling policies. In order to confirm our findings, we modify
application programs distributed by FreeRTOS and reproduce assertion failures
on the STM32F429I-DISC1 board.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 07:04:11 GMT""},{""version"":""v2"",""created"":""Fri, 7 Oct 2022 02:42:58 GMT""}]","2022-10-10"
"2205.07481","Unnikrishnan R. Nair","Unnikrishnan R Nair, Sarthak Sharma, Udit Singh Parihar, Midhun S
  Menon, Srikanth Vidapanakal","Bridging Sim2Real Gap Using Image Gradients for the Task of End-to-End
  Autonomous Driving",,,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  We present the first prize solution to NeurIPS 2021 - AWS Deepracer
Challenge. In this competition, the task was to train a reinforcement learning
agent (i.e. an autonomous car), that learns to drive by interacting with its
environment, a simulated track, by taking an action in a given state to
maximize the expected reward. This model was then tested on a real-world track
with a miniature AWS Deepracer car. Our goal is to train a model that can
complete a lap as fast as possible without going off the track. The Deepracer
challenge is a part of a series of embodied intelligence competitions in the
field of autonomous vehicles, called The AI Driving Olympics (AI-DO). The
overall objective of the AI-DO is to provide accessible mechanisms for
benchmarking progress in autonomy applied to the task of autonomous driving.
The tricky section of this challenge was the sim2real transfer of the learned
skills. To reduce the domain gap in the observation space we did a canny edge
detection in addition to cropping out of the unnecessary background
information. We modeled the problem as a behavioral cloning task and used
MLP-MIXER to optimize for runtime. We made sure our model was capable of
handling control noise by careful filtration of the training data and that gave
us a robust model capable of completing the track even when 50% of the commands
were randomly changed. The overall runtime of the model was only 2-3ms on a
modern CPU.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 07:07:53 GMT""}]","2022-05-17"
"2205.07482","Mazen Alamir Prof","Mazen Alamir","Learning-Based sensitivity analysis and feedback design for drug
  delivery of mixed therapy of cancer in the presence of high model
  uncertainties",,,,,"eess.SY cs.LG cs.SY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this paper, a methodology is proposed that enables to analyze the
sensitivity of the outcome of a therapy to unavoidable high dispersion of the
patient specific parameters on one hand and to the choice of the parameters
that define the drug delivery feedback strategy on the other hand. More
precisely, a method is given that enables to extract and rank the most influent
parameters that determine the probability of success/failure of a given
feedback therapy for a given set of initial conditions over a cloud of
realizations of uncertainties. Moreover predictors of the expectations of the
amounts of drugs being used can also be derived. This enables to design an
efficient stochastic optimization framework that guarantees safe contraction of
the tumor while minimizing a weighted sum of the quantities of the different
drugs being used. The framework is illustrated and validated using the example
of a mixed therapy of cancer involving three combined drugs namely: a
chemotherapy drug, an immunology vaccine and an immunotherapy drug. Finally, in
this specific case, it is shown that dash-boards can be built in the 2D-space
of the most influent state components that summarize the outcomes'
probabilities and the associated drug usage as iso-values curves in the reduced
state space.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 07:08:50 GMT""}]","2022-05-17"
"2205.07483","Marvin Gerlach","Marvin Gerlach","Three-loop topology analysis of neutral B-meson mixing with tapir","6 pages, 1 figure, Contribution to the 20th International Workshop on
  Advanced Computing and Analysis Techniques in Physics Research (ACAT)",,"10.1088/1742-6596/2438/1/012156","TTP22-033, P3H-22-053","hep-ph","http://creativecommons.org/licenses/by-sa/4.0/","  Modern advances in particle physics depend strongly on the usage of reliable
computer programs. In this context two issues become important: The usage of
powerful algorithms to handle the amount of evaluated data properly, and a
software architecture capable to overcome the problems of maintainability and
extendability. We present our approach to such a computer program, called
tapir. This tool assists computations in perturbative quantum field theory in
many ways. Such calculations often involve the evaluation of a large amount of
Feynman diagrams with multiple loops. tapir helps in reducing the number of
diagrams, and the resulting integrals thereof, by identifying and minimizing
their topological structure. We will focus on a three-loop calculation which is
needed for the next-to-next-to leading order predictions of neutral $B$-meson
systems. We show how tapir can be utilized for this kind of calculation.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 07:20:38 GMT""}]","2023-03-01"
"2205.07484","Yuhua Sun","Roberta Filippucci, Yuhua Sun, Yadong Zheng","A priori estimates and Liouville type results for quasilinear elliptic
  equations involving gradient terms",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article we study local and global properties of positive solutions of
$-\Delta_mu=|u|^{p-1}u+M|\nabla u|^q$ in a domain $\Omega$ of $\mathbb R^N$,
with $m>1$, $p,q>0$ and $M\in\mathbb R$. Following some ideas used in
\cite{BV,Vron1}, and by using a direct Bernstein method combined with
Keller-Osserman's estimate, we obtain several a priori estimates as well as
Liouville type theorems. Moreover, we prove a local Harnack inequality with the
help of Serrin's classical results.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 07:30:14 GMT""},{""version"":""v2"",""created"":""Sat, 25 Jun 2022 07:48:13 GMT""}]","2022-06-28"
"2205.07485","Christian Drago","Christian Drago and John Sipe","Aspects of Two-photon Absorption of Squeezed Light: the CW limit","To appear in Phys. Rev. A (2022)",,"10.1103/PhysRevA.106.023115",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We present a theoretical analysis of two-photon absorption of classical and
squeezed light valid when one-photon absorption to an intermediate state is
either resonant or far-detuned from resonance, and in both the low and high
intensity regimes. In this paper we concentrate on continuous-wave excitation,
although the approach we develop is more general. We calculate the energy
removed from an incident field for typical experimental parameters and consider
the limiting cases when the photon pairs are narrowband or broadband compared
to the molecular linewidths. We find an enhancement of the two-photon
absorption due to resonant contributions from the large squeezed light
bandwidth and due to photon bunching in the low intensity regime. However, in
both cases, for the parameters we choose, the one-photon absorption is the
dominant process in the region of parameter space where a large enhancement of
the two-photon absorption is possible.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 07:34:03 GMT""},{""version"":""v2"",""created"":""Tue, 23 Aug 2022 16:11:49 GMT""}]","2022-09-14"
"2205.07486","Ratul Das Chaudhury","Ratul Das Chaudhury, C. Matthew Leister, Birendra Rai","Polarization and Quid Pro Quo: The Role of Party Cohesiveness","Needs updating",,,,"econ.GN math.SP q-fin.EC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  When can an interest group exploit ideological and affective polarization
between political parties to its advantage? We study a model where an interest
group credibly promises payments to legislators conditional on voting for its
favored policy. Legislators value voting as their friends within their party,
and suffer an ideological-disutility upon voting against their party's
ideologically preferred policy. Affective polarization, owing to its
interpersonal nature, is modeled by assuming a legislator values distinguishing
her voting decision from legislators in the opposite party. Our main finding is
that an aggregate measure of relative cohesiveness of social networks in the
two parties determines whether the interest group can profitably exploit
increasing polarization. However, the significance of relative cohesiveness
vanishes if there is no ideological polarization between the two parties.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 07:37:14 GMT""},{""version"":""v2"",""created"":""Wed, 26 Apr 2023 06:47:24 GMT""}]","2023-04-27"
"2205.07487","Simone Warzel","Juan P. Garrahan, Chokri Manai and Simone Warzel","Trajectory phase transitions in non-interacting systems: all-to-all
  dynamics and the random energy model",,,"10.1098/rsta.2021.0415",,"cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  We study the fluctuations of time-additive random observables in the
stochastic dynamics of a system of $N$ non-interacting Ising spins. We mainly
consider the case of all-to-all dynamics where transitions are possible between
any two spin configurations with uniform rates. We show that the cumulant
generating function of the time-integral of a normally distributed quenched
random function of configurations, i.e., the energy function of the random
energy model (REM), has a phase transition in the large $N$ limit for
trajectories of any time extent. We prove this by determining the exact limit
of the scaled cumulant generating function. This is accomplished by connecting
the dynamical problem to a spectral analysis of the all-to-all quantum REM. We
also discuss finite $N$ corrections as observed in numerical simulations.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 07:40:12 GMT""}]","2022-12-28"
"2205.07488","Anand Jerry George","Anand Jerry George and Cl\'ement L. Canonne","Robust Testing in High-Dimensional Sparse Models","Fixed typos, added a figure and discussion section",,,,"cs.IT cs.LG math.IT math.ST stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of robustly testing the norm of a high-dimensional
sparse signal vector under two different observation models. In the first
model, we are given $n$ i.i.d. samples from the distribution
$\mathcal{N}\left(\theta,I_d\right)$ (with unknown $\theta$), of which a small
fraction has been arbitrarily corrupted. Under the promise that
$\|\theta\|_0\le s$, we want to correctly distinguish whether $\|\theta\|_2=0$
or $\|\theta\|_2>\gamma$, for some input parameter $\gamma>0$. We show that any
algorithm for this task requires $n=\Omega\left(s\log\frac{ed}{s}\right)$
samples, which is tight up to logarithmic factors. We also extend our results
to other common notions of sparsity, namely, $\|\theta\|_q\le s$ for any $0 < q
< 2$. In the second observation model that we consider, the data is generated
according to a sparse linear regression model, where the covariates are i.i.d.
Gaussian and the regression coefficient (signal) is known to be $s$-sparse.
Here too we assume that an $\epsilon$-fraction of the data is arbitrarily
corrupted. We show that any algorithm that reliably tests the norm of the
regression coefficient requires at least $n=\Omega\left(\min(s\log
d,{1}/{\gamma^4})\right)$ samples. Our results show that the complexity of
testing in these two settings significantly increases under robustness
constraints. This is in line with the recent observations made in robust mean
testing and robust covariance testing.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 07:47:22 GMT""},{""version"":""v2"",""created"":""Fri, 4 Nov 2022 22:18:50 GMT""}]","2022-11-08"
"2205.07489","Yubo Shi","Y. B. Shi, K. L. Zhang and Z. Song","Dynamic generation of nonequilibrium superconducting states in Kitaev
  chain","8 pages, 7 figures","Phys. Rev. B 106, 184505 (2022)","10.1103/PhysRevB.106.184505",,"cond-mat.supr-con cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Non-equilibrium state can exhibit the same macroscopic properties, such as
conductivity or superconductivity, as a static state when they share the
identical average of an observable over a period of time. We investigate the
quench dynamics of a Kitaev chain by introducing two kinds of order parameters
which relate to two channels of pairing, local pair in real space and BCS-like
pair in momentum space. Based on exact solutions, we find that two order
parameters are identical for the ground state, indicating the balance between
two kinds of pairing channels, and can identify the quantum phase diagram.
However, for a non-equilibrium state obtained by the time evolution from
initially prepared vacuum state, the two are different but both can still
clearly identify the phase diagram. In the topologically non-trivial region,
the non-equilibrium states prefer the BCS-like pairing state. Our finding
provides an alternative way to dynamically generate a superconducting state
from a trivial empty state and sheds light on the mechanism of pairing.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 07:47:44 GMT""},{""version"":""v2"",""created"":""Thu, 17 Nov 2022 13:49:08 GMT""},{""version"":""v3"",""created"":""Wed, 21 Dec 2022 09:15:30 GMT""},{""version"":""v4"",""created"":""Wed, 18 Jan 2023 13:45:17 GMT""}]","2023-01-19"
"2205.07490","Maarten Solleveld","Maarten Solleveld","Graded Hecke algebras and equivariant constructible sheaves on the
  nilpotent cone","This paper contains sections 2 and 3 of ""Graded Hecke algebras and
  equivariant constructible sheaves"" (arXiv:2106.03196v1), which has been
  revised and split",,,,"math.AG math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graded Hecke algebras can be constructed geometrically, with constructible
sheaves and equivariant cohomology. The input consists of a complex reductive
group G (possibly disconnected) and a cuspidal local system on a nilpotent
orbit for a Levi subgroup of G. We prove that every such ""geometric"" graded
Hecke algebra is naturally isomorphic to the endomorphism algebra of a certain
G x C*-equivariant semisimple complex of sheaves on the nilpotent cone $g_N$.
  From there we provide an algebraic description of the G x C*-equivariant
bounded derived category of constructible sheaves on $g_N$. Namely, it is
equivalent with the bounded derived category of finitely generated differential
graded modules of a suitable direct sum of graded Hecke algebras. This can be
regarded as a categorification of graded Hecke algebras.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 07:49:02 GMT""}]","2022-05-17"
"2205.07491","Manuel De La Cruz","Roberto Cartas-Fuentevilla, Manuel de la Cruz, Alfredo
  Herrera-Aguilar, Jhony A. Herrera-Mendoza and Daniel F. Higuita-Borja","Evolution of Lifshitz metric anisotropies in Einstein-Proca theory under
  the Ricci-DeTurck flow","12 pages, 2 figures","Eur. Phys. J. Plus 137, 1379 (2022)","10.1140/epjp/s13360-022-03606-6",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  By starting from a Perelman entropy functional and considering the
Ricci-DeTurck flow equations we analyze the behaviour of Einstein-Hilbert and
Einstein-Proca theories with Lifshitz geometry as functions of a flow
parameter. In the former case, we found one consistent fixed point that
represents flat space-time as the flow parameter tends to infinity. Massive
vector fields in the latter theory enrich the system under study and have the
same fixed point achieved at the same rate as in the former case. The geometric
flow is parametrized by the metric coefficients and represents a change in
anisotropy of the geometry towards an isotropic flat space-time as the flow
parameter evolves. Indeed, the flow of the Proca fields depends on certain
coefficients that vanish when the flow parameter increases, rendering these
fields constant. We have been able to write down the evolving Lifshitz metric
solution with positive, but otherwise arbitrary, critical exponents relevant to
geometries with spatially anisotropic holographic duals. We show that both the
scalar curvature and matter contributions to the Ricci-DeTurck flow vanish
under the flow at a fixed point consistent with flat space-time geometry. Thus,
the behaviour of the scalar curvature always increases, homogenizing the
geometry along the flow. Moreover, the theory under study keeps
positive-definite but decreasing the entropy functional along the Ricci-DeTurck
flow.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 07:50:02 GMT""}]","2023-01-04"
"2205.07492","Michele Graffeo","Michele Graffeo","Moduli spaces of $\mathbb{Z}/k\mathbb{Z}$-constellations over
  $\mathbb{A}^2$","44 pages, 21 figures",,,,"math.AG math.AC math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\rho :\mathbb{Z}/k \mathbb{Z}\rightarrow Sl(2,\mathbb{C})$ be a
representation of a finite abelian group and let $\Theta^{gen}\subset
Hom_\mathbb{Z}(R(\mathbb{Z}/k\mathbb{Z}),\mathbb{Q})$ be the space of generic
stability conditions on the set of $G$-constellations. We provide a
combinatorial description of all the chambers $C\subset\Theta^{gen}$ and prove
that there are $k!$ of them. Moreover, we introduce the notion of simple
chamber and we show that, in order to know all toric $G$-constellations, it is
enough to build all simple chambers. We also prove that there are $k\cdot
2^{k-2} $ simple chambers. Finally, we provide an explicit formula for the
tautological bundles $\mathscr{R}_C$ over the moduli spaces $\mathscr{M}_C$ for
all chambers $C\subset \Theta^{gen}$ which will only depend upon a
combinatorial object, called chamber stair, attached to the chamber $C$.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 07:53:32 GMT""}]","2022-05-18"
"2205.07493","Shibo Feng","Shibo Feng and Ke Xu and Jiaxiang Wu and Pengcheng Wu and Fan Lin and
  Peilin Zhao","Multi-scale Attention Flow for Probabilistic Time Series Forecasting",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The probability prediction of multivariate time series is a notoriously
challenging but practical task. On the one hand, the challenge is how to
effectively capture the cross-series correlations between interacting time
series, to achieve accurate distribution modeling. On the other hand, we should
consider how to capture the contextual information within time series more
accurately to model multivariate temporal dynamics of time series. In this
work, we proposed a novel non-autoregressive deep learning model, called
Multi-scale Attention Normalizing Flow(MANF), where we integrate multi-scale
attention and relative position information and the multivariate data
distribution is represented by the conditioned normalizing flow. Additionally,
compared with autoregressive modeling methods, our model avoids the influence
of cumulative error and does not increase the time complexity. Extensive
experiments demonstrate that our model achieves state-of-the-art performance on
many popular multivariate datasets.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 07:53:42 GMT""},{""version"":""v2"",""created"":""Mon, 10 Oct 2022 08:28:30 GMT""}]","2022-10-11"
"2205.07494","Weifeng Zhu","Weifeng Zhu, Meixia Tao, and Yunfeng Guan","Double-Sided Information Aided Temporal-Correlated Massive Access","6 pages, 5 figures",,,,"eess.SP cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This letter considers temporal-correlated massive access, where each device,
once activated, is likely to transmit continuously over several consecutive
frames. Motivated by that the device activity at each frame is correlated to
not only its previous frame but also its next frame, we propose a double-sided
information (DSI) aided joint activity detection and channel estimation
algorithm based on the approximate message passing (AMP) framework. The DSI is
extracted from the estimation results in a sliding window that contains the
target detection frame and its previous and next frames. The proposed algorithm
demonstrates superior performance over the state-of-the-art methods.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 07:55:35 GMT""}]","2022-05-17"
"2205.07495","Andrew McLeod Dr","Terry Lyons and Andrew D. McLeod","Generalised Recombination Interpolation Method (GRIM)",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we develop the Generalised Recombination Interpolation Method
(GRIM) for finding sparse approximations of functions initially given as linear
combinations of some (large) number of simpler functions. GRIM is a hybrid of
dynamic growth-based interpolation techniques and thinning-based reduction
techniques. We establish that the number of non-zero coefficients in the
approximation returned by GRIM is controlled by the concentration of the data.
In the case that the functions involved are Lip$(\gamma)$ for some $\gamma > 0$
in the sense of Stein, we obtain improved convergence properties for GRIM. In
particular, we prove that the level of data concentration required to guarantee
that GRIM finds a good sparse approximation is decreasing with respect to the
regularity parameter $\gamma > 0$.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 07:58:20 GMT""},{""version"":""v2"",""created"":""Mon, 9 Jan 2023 21:22:09 GMT""},{""version"":""v3"",""created"":""Wed, 25 Jan 2023 16:13:18 GMT""},{""version"":""v4"",""created"":""Thu, 26 Jan 2023 16:00:11 GMT""}]","2023-01-27"
"2205.07496","Rafael Kiesel","Rafael Kiesel, Pietro Totis and Angelika Kimmig","Efficient Knowledge Compilation Beyond Weighted Model Counting","Paper presented at the 38th International Conference on Logic
  Programming (ICLP 2022), 16 pages",,"10.1017/S147106842200014X",,"cs.AI cs.LO","http://creativecommons.org/licenses/by/4.0/","  Quantitative extensions of logic programming often require the solution of so
called second level inference tasks, i.e., problems that involve a third
operation, such as maximization or normalization, on top of addition and
multiplication, and thus go beyond the well-known weighted or algebraic model
counting setting of probabilistic logic programming under the distribution
semantics. We introduce Second Level Algebraic Model Counting (2AMC) as a
generic framework for these kinds of problems. As 2AMC is to (algebraic) model
counting what forall-exists-SAT is to propositional satisfiability, it is
notoriously hard to solve. First level techniques based on Knowledge
Compilation (KC) have been adapted for specific 2AMC instances by imposing
variable order constraints on the resulting circuit. However, those constraints
can severely increase the circuit size and thus decrease the efficiency of such
approaches. We show that we can exploit the logical structure of a 2AMC problem
to omit parts of these constraints, thus limiting the negative effect.
Furthermore, we introduce and implement a strategy to generate a sufficient set
of constraints statically, with a priori guarantees for the performance of KC.
Our empirical evaluation on several benchmarks and tasks confirms that our
theoretical results can translate into more efficient solving in practice.
Under consideration for acceptance in TPLP.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:10:40 GMT""}]","2022-11-14"
"2205.07497","Andrea Lapi","M. Massardi, M. Bonato, M. Lopez-Caniego, V. Galluzzi, G. De Zotti, L.
  Bonavera, J. Gonzalez-Nuevo, A. Lapi, and E. Liuzzo","Selecting a complete sample of blazars in sub-millimetre catalogues","16 pages, 7 figures, accepted by MNRAS",,"10.1093/mnras/stac1262",,"astro-ph.GA astro-ph.CO astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The \textit{Herschel} Astrophysical Terahertz Large Area Survey (H-ATLAS),
that has covered about 642 sq. deg. in 5 bands from 100 to 500 $\mu\rm m$,
allows a blind flux-limited selection of blazars at sub-mm wavelengths.
However, blazars constitute a tiny fraction of H-ATLAS sources and therefore
identifying them is not a trivial task. Using the data on known blazars
detected by the H-ATLAS we have defined a locus for 500\,$\mu$m selected
blazars and exploited it to select blazar candidates in the H-ATLAS fields.
Candidates and known blazars in the H-ATLAS equatorial and South Galactic Pole
fields were followed up with the Australia Telescope Compact Array (ATCA) or
with the Karl G. Jansky Very Large Array (VLA), and matched with existing
radio- and mm-catalogues to reconstruct the spectral behaviour over at least 6
orders of magnitude in frequency. We identified a selection approach that,
combining the information in the sub-mm and radio domains, efficiently singles
out genuine blazars. In this way, we identified a sample of 39 blazars brighter
than $S_{500\mu\rm m} = 35\,$mJy in the H-ATLAS fields. Tests made
cross-matching the H-ATLAS catalogues with large catalogues of blazar
candidates indicate that the sample is complete. The derived counts are
compared with model predictions finding good consistency with the C2Ex model
and with estimates based on ALMA data.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:11:51 GMT""}]","2022-05-25"
"2205.07498","Zden\v{e}k Dvo\v{r}\'ak","Zden\v{e}k Dvo\v{r}\'ak and Bojan Mohar","On density of $Z_3$-flow-critical graphs","24 pages, no figures; updated for the reviewer remarks",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For an abelian group $\Gamma$, a graph $G$ is said to be
$\Gamma$-flow-critical if $G$ does not admit a nowhere-zero $\Gamma$-flow, but
for each edge $e\in E(G)$, the contraction $G/e$ has a nowhere-zero
$\Gamma$-flow. A bound on the density of $Z_3$-flow-critical graphs drawn on a
fixed surface is obtained, generalizing the planar case of the bound on the
density of 4-critical graphs by Kostochka and Yancey.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:14:11 GMT""},{""version"":""v2"",""created"":""Tue, 28 Jun 2022 13:58:49 GMT""},{""version"":""v3"",""created"":""Sun, 4 Dec 2022 10:16:21 GMT""}]","2022-12-06"
"2205.07499","Xinyuan Zhu","Xinyuan Zhu, Yang Zhang, Fuli Feng, Xun Yang, Dingxian Wang and
  Xiangnan He","Mitigating Hidden Confounding Effects for Causal Recommendation",,,,,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recommender systems suffer from confounding biases when there exist
confounders affecting both item features and user feedback (e.g., like or not).
Existing causal recommendation methods typically assume confounders are fully
observed and measured, forgoing the possible existence of hidden confounders in
real applications. For instance, product quality is a confounder since
affecting both item prices and user ratings, but is hidden for the third-party
e-commerce platform due to the difficulty of large-scale quality inspection;
ignoring it could result in the bias effect of over-recommending high-price
items. This work analyzes and addresses the problem from a causal perspective.
The key lies in modeling the causal effect of item features on a user's
feedback. To mitigate hidden confounding effects, it is compulsory but
challenging to estimate the causal effect without measuring the confounder.
Towards this goal, we propose a Hidden Confounder Removal (HCR) framework that
leverages front-door adjustment to decompose the causal effect into two partial
effects, according to the mediators between item features and user feedback.
The partial effects are independent from the hidden confounder and
identifiable. During training, HCR performs multi-task learning to infer the
partial effects from historical interactions. We instantiate HCR for two
scenarios and conduct experiments on three real-world datasets. Empirical
results show that the HCR framework provides more accurate recommendations,
especially for less-active users. We will release the code once accepted.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:21:12 GMT""}]","2022-05-17"
"2205.07500","Giacomo Ortali","Walter Didimo, Michael Kaufmann, Giuseppe Liotta, Giacomo Ortali","Computing Bend-Minimum Orthogonal Drawings of Plane Series-Parallel
  Graphs in Linear Time","arXiv admin note: text overlap with arXiv:2008.03784",,,,"cs.CG cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A planar orthogonal drawing of a planar 4-graph G (i.e., a planar graph with
vertex-degree at most four) is a crossing-free drawing that maps each vertex of
G to a distinct point of the plane and each edge of $G$ to a sequence of
horizontal and vertical segments between its end-points. A longstanding open
question in Graph Drawing, dating back over 30 years, is whether there exists a
linear-time algorithm to compute an orthogonal drawing of a plane 4-graph with
the minimum number of bends. The term ""plane"" indicates that the input graph
comes together with a planar embedding, which must be preserved by the drawing
(i.e., the drawing must have the same set of faces as the input graph). In this
paper, we positively answer the question above for the widely-studied class of
series-parallel graphs. Our linear-time algorithm is based on a
characterization of the planar series-parallel graphs that admit an orthogonal
drawing without bends. This characterization is given in terms of the
orthogonal spirality that each type of triconnected component of the graph can
take; the orthogonal spirality of a component measures how much that component
is ""rolled-up"" in an orthogonal drawing of the graph.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:23:09 GMT""}]","2022-05-17"
"2205.07501","Ilya Klimovskikh","A. M. Shikin, T. P. Makarova, A. V. Eryzhenkov, D. Yu. Usachov, D. A.
  Estyunin, D. A. Glazkova, I. I. Klimovskikh, A. G. Rybkin, and A. V. Tarasov","Factors influencing the energy gap in topological states of
  antiferromagnetic MnBi$_2$Te$_4$",,,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  The experimentally measured angle-resolved photoemission dispersion maps for
MnBi$_{2}$Te$_{4}$ samples, which show different energy gaps at the Dirac point
(DP), are compared with the results of theoretical calculations to find the
conditions for the best agreement between theory and experiment. We have
analyzed different factors which influence the Dirac gap width: (i) the surface
van der Waals (SvdW) distance between the first and second septuple layers
(SLs), (ii) the magnetic moment on Mn atoms, (iii) the spin-orbit coupling
(SOC) strength for the surface Te and Bi atoms and related changes in the
localization of the topological surface states (TSSs). It was shown that all
these factors may change the gap width at the DP in a wide range from 5 to
$\sim$90~meV. We show that the Dirac gap variation is mainly determined by the
corresponding changes in the TSSs spatial distribution. The best agreement
between the presented experimental data (with the Dirac gaps between $\sim$15
and 55~meV) and the calculations takes place for a slightly compressed SvdW
interval (of about -3.5~\% compared to the bulk value) with modified SOC for
surface atoms (that can occur in the presence of various defects in the
near-surface region). We show that upon changing the values of the SvdW
interval and surface SOC strength the TSSs spatial distribution shifts between
the SLs with opposite magnetizations, which leads to a non-monotonic change in
the Dirac gap size.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:28:16 GMT""},{""version"":""v2"",""created"":""Wed, 1 Jun 2022 11:40:51 GMT""}]","2022-06-02"
"2205.07502","Lei Zhang","Lei Zhang, Yu Pan, Yi Liu, Qibin Zheng, Zhisong Pan","KGRGRL: A User's Permission Reasoning Method Based on Knowledge Graph
  Reward Guidance Reinforcement Learning","8 pages, 2 figures",,,,"cs.AI cs.CR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In general, multiple domain cyberspace security assessments can be
implemented by reasoning user's permissions. However, while existing methods
include some information from the physical and social domains, they do not
provide a comprehensive representation of cyberspace. Existing reasoning
methods are also based on expert-given rules, resulting in inefficiency and a
low degree of intelligence. To address this challenge, we create a Knowledge
Graph (KG) of multiple domain cyberspace in order to provide a standard
semantic description of the multiple domain cyberspace. Following that, we
proposed a user's permissions reasoning method based on reinforcement learning.
All permissions in cyberspace are represented as nodes, and an agent is trained
to find all permissions that user can have according to user's initial
permissions and cyberspace KG. We set 10 reward setting rules based on the
features of cyberspace KG in the reinforcement learning of reward information
setting, so that the agent can better locate user's all permissions and avoid
blindly finding user's permissions. The results of the experiments showed that
the proposed method can successfully reason about user's permissions and
increase the intelligence level of the user's permissions reasoning method. At
the same time, the F1 value of the proposed method is 6% greater than that of
the Translating Embedding (TransE) method.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:28:23 GMT""}]","2022-05-17"
"2205.07503","Robert Cardona","Robert Cardona, C\'edric Oms","Morse functions and contact convex surfaces","15 pages, 5 figures. Expository note",,,,"math.SG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $f$ be a Morse function on a closed surface $\Sigma$ such that zero is a
regular value and such that $f$ admits neither positive minima nor negative
maxima. In this expository note, we show that $\Sigma\times \mathbb{R}$ admits
an $\mathbb{R}$-invariant contact form $\alpha=fdt+\beta$ whose characteristic
foliation along the zero section is (negative) weakly gradient-like with
respect to $f$. The proof is self-contained and gives explicit constructions of
any $\mathbb{R}$-invariant contact structure in $\Sigma \times \mathbb{R}$, up
to isotopy. As an application, we give an alternative geometric proof of the
homotopy classification of $\mathbb{R}$-invariant contact structures in terms
of their dividing set.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:30:49 GMT""}]","2022-05-17"
"2205.07504","Stefan Hickel PhD","Mohamad Fathi, Stefan Hickel, Dirk Roekaerts","Large eddy simulations of reacting and non-reacting transcritical fuel
  sprays using multiphase thermodynamics","This paper is part of the Physics of Fluids themed issue Development
  and Validation of Models for Turbulent Reacting Flows in honor of Professor
  Michael Pfitzner on the occasion of his retirement",,"10.1063/5.0099154",,"physics.flu-dyn nlin.AO physics.app-ph physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  Accurate simulations of high-pressure transcritical fuel sprays are essential
for the design and optimization of next-generation gas turbines, internal
combustion engines, and liquid propellant rocket engines. Most important and
challenging is the accurate modelling of complex real-gas effects in
high-pressure environments, especially the hybrid subcritical-to-supercritical
mode of evaporation during the mixing of fuel and oxidizer. In this paper, we
present a novel modeling framework for high-fidelity simulations of reacting
and non-reacting transcritical fuel sprays. In this method, the high-pressure
jet disintegration is modeled using a diffuse interface method with multiphase
thermodynamics, which combines multi-component real-fluid kinetic and caloric
state equations with vapor-liquid equilibrium calculations in order to compute
thermodynamic properties of the mixture at transcritical pressures. All
multiphase thermodynamic formulations are presented for general cubic state
equations coupled with a rapid phase-equilibrium calculation method. The
proposed method represents multiphase turbulent fluid flows at transcritical
pressures without relying on any semi-empirical break-up and evaporation
models. Combustion source terms are evaluated using a finite-rate chemistry
model, including real-gas effects based on the fugacity of the species in the
mixture. The adaptive local deconvolution method (ALDM) is used as a physically
consistent turbulence model for large-eddy simulation (LES). LES results show a
very good agreement with available experimental data for the reacting and
non-reacting ECN Spray A at transcritical operating conditions.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:31:40 GMT""}]","2022-09-21"
"2205.07505","Youxin Wang","Y. X. Wang, J. S. Zhang, Y. T. Yan, J. J. Qiu, J. L. Chen, J. Y. Zhao,
  Y. P. Zou, X. C. Wu, X. L. He, Y. B. Gong, J. H. Cai","Cyanopolyyne line survey towards high-mass star-forming regions with
  TMRT","23 pages, 5 figures, 4 tables, Accepted to A&A","A&A 663, A177 (2022)","10.1051/0004-6361/202142450",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We carried out a cyanopolyyne line survey towards a large sample of HMSFRs
using the Shanghai Tian Ma 65m Radio Telescope (TMRT). Our sample consisted of
123 targets taken from the TMRT C band line survey. It included three kinds of
sources, namely those with detection of the 6.7 GHz CH3OH maser alone, with
detection of the radio recombination line (RRL) alone, and with detection of
both (hereafter referred to as Maser-only, RRL-only, and Maser-RRL sources,
respectively). We detected HC3N in 38 sources, HC5N in 11 sources, and HC7N in
G24.790+0.084, with the highest detection rate being found for Maser-RRL
sources and a very low detection rate found for RRL-only sources. Their column
densities were derived using the rotational temperature measured from the NH3
lines. And we constructed and fitted the far-infrared (FIR) spectral energy
distributions. Based on these, we derive their dust temperatures, H2 column
densities, and abundances of cyanopolyynes relative to H2. The detection rate,
the column density, and the relative abundance of HC3N increase from Maser-only
to Maser-RRL sources and decrease from Maser-RRL to RRL-only sources. This
trend is consistent with the proposed evolutionary trend of HC3N under the
assumption that our Maser-only, Maser-RRL, and RRL-only sources correspond to
massive young stellar objects, ultra-compact HII regions, and normal classical
HII regions, respectively. Furthermore, a statistical analysis of the
integrated line intensity and column density of HC3N and shock-tracing
molecules (SiO, H2CO) enabled us to find positive correlations between them.
This suggests that HC3N may be another tracer of shocks, and should therefore
be the subject of further observations and corresponding chemical simulations.
Our results indirectly support the idea that the neutral--neutral reaction
between C2H2 and CN is the dominant formation pathway of HC3N.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:37:53 GMT""}]","2022-08-03"
"2205.07506","Masayuki Sugeta","Masayuki Sugeta, Takeshi Mizushima, Satoshi Fujimoto","Enhanced $2\pi$-periodic Aharonov-Bohm Effect as a Signature of Majorana
  Zero Modes Probed by Nonlocal Measurements","9 pages, 11 figures","J. Phys. Soc. Jpn. 92, 054701 (2023)","10.7566/JPSJ.92.054701",,"cond-mat.mes-hall cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose the $2\pi$-periodic Aharonov-Bohm (AB) effect as a nonlocal probe
of Majorana zero modes (MZMs) without the restriction of fermion parity. We
demonstrate the enhancement of the AB effect, where the topological protection
of MZMs yields amplified and robust Andreev reflection mediated by MZMs at
multiple superconductor-normal metal junctions. We investigate the influence of
trivial bound states and show that a nonlocal index enables a more explicit
distinction between the trivial and topological bound states than local probes.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:38:00 GMT""},{""version"":""v2"",""created"":""Fri, 11 Nov 2022 07:31:30 GMT""},{""version"":""v3"",""created"":""Tue, 18 Apr 2023 09:34:13 GMT""}]","2023-04-19"
"2205.07507","Stephen DiAdamo","Stephen DiAdamo, Bing Qi, Glen Miller, Ramana Kompella, Alireza
  Shabani","Packet Switching in Quantum Networks: A Path to Quantum Internet",,,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Large-scale quantum networks with thousands of nodes require scalable network
protocols and physical hardware to realize. In this work, we introduce packet
switching as a new paradigm for quantum data transmission in both future and
near-term quantum networks. We propose a classical-quantum data frame structure
and explore methods of frame generation and processing. Further, we present
conceptual designs for a quantum reconfigurable optical add-drop multiplexer to
realize the proposed transmission scheme. Packet switching allows for a
universal design for a next generation Internet where classical and quantum
data share the same network protocols and infrastructure. In this new quantum
networking paradigm, entanglement distribution, as with quantum key
distribution, is an application built on top of the quantum network rather than
as a network designed especially for those purposes. For analysis of the
network model, we simulate the feasibility of quantum packet switching for some
preliminary models of quantum key and entanglement distribution. Finally, we
discuss how our model can be integrated with other network models toward a
realization of a quantum Internet.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:39:05 GMT""}]","2022-05-17"
"2205.07508","Cem Celebi","A. Yanilmaz, M. Fidan, O. Unverdi and C. Celebi","Graphene/SOI-based self-powered Schottky barrier photodiode array",,,"10.1063/5.0092833",,"physics.app-ph cond-mat.other","http://creativecommons.org/licenses/by/4.0/","  We have fabricated 4-element Graphene/Silicon on Insulator (SOI) based
Schottky barrier photodiode array ()PDA and investigated its optoelectronic
device performance. In our device design, monolayer graphene is utilized as
common electrode on lithographically defined linear array of n-type Si channels
on SOI substrate. As revealed by wavelength resolved photocurrent spectroscopy
measurements, each element in the PDA structure exhibited a maximum spectral
responsivity comparable to that of commercially available photodiodes operating
under self-powered operational mode. Time-dependent photocurrent spectroscopy
measurements showed excellent photocurrent reversibility of the device. The
study presented here is expected to offer exciting opportunities in terms of
high value-added graphene/Si based PDA device applications such as
multi-wavelength light measurement, level metering, high-speed photometry,
position/motion detection, and more.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:40:19 GMT""}]","2022-08-24"
"2205.07509","Dong Liu","Munayim Dilxat, Liangyun Chen, Dong Liu","Classification of simple Harish-Chandra modules over the Ovsienko-Roger
  superalgebra","Latex, 12pages","Proceedings of the Royal Society of Edinburgh, page 1 of 11","10.1017/prm.2023.20",,"math.RT math-ph math.MP math.RA","http://creativecommons.org/licenses/by/4.0/","  With the $\Omega$-operators for the Virasoro algebra \cite{BF} and the super
Virasoro algebra in \cite{CL, CLL}, we get the $\Omega$-operators for the
Ovsienko-Roger superalgebras in this paper and then use it to classify all
simple cuspidal modules for the $\bZ$-graded and $\frac12\bZ$-graded
Ovsienko-Roger superalgebras. By this result, we can easily classify all simple
Harish-Chandra modules over some related Lie superalgebras, including the $N=1$
BMS$_3$ algebra, the super $W(2,2)$, etc.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:43:31 GMT""}]","2023-05-29"
"2205.07510","Shoko Wakamiya","Shoko Wakamiya, Toshiki Mera, Eiji Aramaki, Masaki Matsubara, Atsuyuki
  Morishima","Crowdsourced Hypothesis Generation and their Verification: A Case Study
  on Sleep Quality Improvement",,,,,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A clinical study is often necessary for exploring important research
questions; however, this approach is sometimes time and money consuming.
Another extreme approach, which is to collect and aggregate opinions from
crowds, provides a result drawn from the crowds' past experiences and
knowledge. To explore a solution that takes advantage of both the rigid
clinical approach and the crowds' opinion-based approach, we design a framework
that exploits crowdsourcing as a part of the research process, whereby crowd
workers serve as if they were a scientist conducting a ""pseudo"" prospective
study. This study evaluates the feasibility of the proposed framework to
generate hypotheses on a specified topic and verify them in the real world by
employing many crowd workers. The framework comprises two phases of crowd-based
workflow. In Phase 1 - the hypothesis generation and ranking phase - our system
asks workers two types of questions to collect a number of hypotheses and rank
them. In Phase 2 - the hypothesis verification phase - the system asks workers
to verify the top-ranked hypotheses from Phase 1 by implementing one of them in
real life. Through experiments, we explore the potential and limitations of the
framework to generate and evaluate hypotheses about the factors that result in
a good night's sleep. Our results on significant sleep quality improvement show
the basic feasibility of our framework, suggesting that crowd-based research is
compatible with experts' knowledge in a certain domain.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:43:39 GMT""}]","2022-05-17"
"2205.07511","Eugene Churazov","E.Churazov, I.Khabibullin, A.M.Bykov, N.Lyskova, R.Sunyaev","Tempestuous life beyond R500: X-ray view on the Coma cluster with
  SRG/eROSITA. II. Shock & Relic","Replaced with the accepted version","A&A 670, A156 (2023)","10.1051/0004-6361/202244021",,"astro-ph.CO astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  This is the second paper in a series of studies of the Coma cluster using the
SRG/eROSITA X-ray data obtained during the calibration and performance
verification phase of the mission. Here, we focus on the region adjacent to the
radio source 1253+275 (radio relic, RR, hereafter). We show that the X-ray
surface brightness exhibits its steepest gradient at $\sim 79'$ ($\sim
2.2\,{\rm Mpc}\approx R_{200c}$), which is almost co-spatial to the outer edge
of the RR. As in the case of several other relics, the Mach number of the shock
derived from the X-ray surface brightness profile ($M_X\approx 1.9$) appears to
be lower than needed to explain the slope of the integrated radio spectrum in
the diffusive shock acceleration (DSA) model ($M_R\approx 3.5$) if the magnetic
field is uniform and the radiative losses are fast. However, the shock geometry
is plausibly much more complicated than a spherical wedge centered on the
cluster, given the non-trivial correlation between radio, X-ray, and SZ images.
While the complicated shock geometry alone might cause a negative bias in
$M_X$, we speculate on a few other possibilities that may affect the
$M_X$-$M_R$ relation, including the shock substructure that might be modified
by the presence of non-thermal filaments stretching across the shock and the
propagation of relativistic electrons along the non-thermal filaments with a
strong magnetic field. We also discuss the ""history"" of the radio galaxy
NGC4789, which is located ahead of the relic in the context of the Coma-NGC4839
merger scenario.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:45:19 GMT""},{""version"":""v2"",""created"":""Fri, 25 Nov 2022 16:29:42 GMT""},{""version"":""v3"",""created"":""Sat, 10 Dec 2022 17:48:28 GMT""}]","2023-02-22"
"2205.07512","Qi'an Guan","Shijie Bao, Qi'an Guan, Zhitong Mi, Zheng Yuan","Concavity property of minimal $L^{2}$ integrals with Lebesgue measurable
  gain VII -- Negligible weights","89 pages, typos are corrected",,,,"math.CV math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we present characterizations of the concavity property of
minimal $L^2$ integrals with negligible weights degenerating to linearity on
the fibrations over open Riemann surfaces and the fibrations over products of
open Riemann surfaces. As applications, we obtain characterizations of the
holding of equality in optimal jets $L^2$ extension problem with negligible
weights on the fibrations over open Riemann surfaces and the fibrations over
products of open Riemann surfaces.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:45:59 GMT""},{""version"":""v2"",""created"":""Sat, 14 Jan 2023 04:58:10 GMT""}]","2023-01-18"
"2205.07513","Ryoma Inoba","Ryoma Inoba, Kazuki Uchida, Yuto Iwasaki, Takayuki Nagata, Yuta Ozawa,
  Yuji Saito, Taku Nonomura and Keisuke Asai","Optimization of Sparse Sensor Placement for Estimation of Wind Direction
  and Surface Pressure Distribution Using Time-Averaged Pressure-Sensitive
  Paint Data on Automobile Model","to be published in Journal of Wind Engineering & Industrial
  Aerodynamics","Journal of Wind Engineering and Industrial Aerodynamics Volume
  227, August 2022, 105043","10.1016/j.jweia.2022.105043",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study proposes a method for predicting the wind direction against the
simple automobile model (Ahmed model) and the surface pressure distributions on
it by using data-driven optimized sparse pressure sensors. Positions of sparse
pressure sensor pairs on the Ahmed model were selected for estimation of the
yaw angle and reconstruction of pressure distributions based on the
time-averaged surface pressure distributions database of various yaw angles,
whereas the symmetric sensors in the left and right sides of the model were
assumed. The surface pressure distributions were obtained by pressure-sensitive
paint measurements. Three algorithms for sparse sensor selection based on the
greedy algorithm were applied, and the sensor positions were optimized. The
sensor positions and estimation accuracy of yaw angle and pressure
distributions of three algorithms were compared and evaluated. The results show
that a few optimized sensors can accurately predict the yaw angle and the
pressure distributions.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:46:14 GMT""}]","2022-06-27"
"2205.07514","Fangyuan Kong","Fangyuan Kong, Mingxi Li, Songwei Liu, Ding Liu, Jingwen He, Yang Bai,
  Fangmin Chen, Lean Fu","Residual Local Feature Network for Efficient Super-Resolution",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning based approaches has achieved great performance in single image
super-resolution (SISR). However, recent advances in efficient super-resolution
focus on reducing the number of parameters and FLOPs, and they aggregate more
powerful features by improving feature utilization through complex layer
connection strategies. These structures may not be necessary to achieve higher
running speed, which makes them difficult to be deployed to
resource-constrained devices. In this work, we propose a novel Residual Local
Feature Network (RLFN). The main idea is using three convolutional layers for
residual local feature learning to simplify feature aggregation, which achieves
a good trade-off between model performance and inference time. Moreover, we
revisit the popular contrastive loss and observe that the selection of
intermediate features of its feature extractor has great influence on the
performance. Besides, we propose a novel multi-stage warm-start training
strategy. In each stage, the pre-trained weights from previous stages are
utilized to improve the model performance. Combined with the improved
contrastive loss and training strategy, the proposed RLFN outperforms all the
state-of-the-art efficient image SR models in terms of runtime while
maintaining both PSNR and SSIM for SR. In addition, we won the first place in
the runtime track of the NTIRE 2022 efficient super-resolution challenge. Code
will be available at https://github.com/fyan111/RLFN.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:46:34 GMT""}]","2022-05-17"
"2205.07515","Man Ho Chan","Man Ho Chan, Shantanu Desai, Antonino Del Popolo","There is no universal acceleration scale in galaxies",,"PASJ, 74, 1441-1452 (2022)","10.1093/pasj/psac083",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Recently, many studies seem to reveal the existence of some correlations
between dark matter and baryonic matter. In particular, the unexpected tight
Radial Acceleration Relation (RAR) discovered in rotating galaxies has caught
much attention. The RAR suggests the existence of a universal and fundamental
acceleration scale in galaxies, which seems to challenge the $\Lambda$CDM model
and favour some modified gravity theories. A large debate about whether RAR is
compatible with the $\Lambda$CDM model has arisen. Here, by analysing the high
quality velocity dispersion profiles of 13 E0-type elliptical galaxies in the
SDSS-IV MaNGA sample and assuming a power-law function of radius $r$ for the
3-dimensional velocity dispersion in each galaxy, we report the RAR for E0-type
elliptical galaxies and we show that the resultant RAR has more than $5\sigma$
deviations from the RAR in late-type galaxies. This new RAR provides an
independent probe to falsify the existence of any universal acceleration scale
in galaxies. Our result significantly challenges those modified gravity
theories which suggest the existence of any universal acceleration scale.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:48:40 GMT""}]","2022-12-07"
"2205.07516","Tobias Fechter","Tobias Fechter, Ilias Sachpazidis, Dimos Baltas","The use of deep learning in interventional radiotherapy (brachytherapy):
  a review with a focus on open source and open data","31 pages, submitted to ""Zeitschrift f\""ur Medizinische Physik""",,"10.1016/j.zemedi.2022.10.005",,"physics.med-ph cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning advanced to one of the most important technologies in almost
all medical fields. Especially in areas, related to medical imaging it plays a
big role. However, in interventional radiotherapy (brachytherapy) deep learning
is still in an early phase. In this review, first, we investigated and
scrutinised the role of deep learning in all processes of interventional
radiotherapy and directly related fields. Additionally we summarised the most
recent developments. To reproduce results of deep learning algorithms both
source code and training data must be available. Therefore, a second focus of
this work was on the analysis of the availability of open source, open data and
open models. In our analysis, we were able to show that deep learning plays
already a major role in some areas of interventional radiotherapy, but is still
hardly presented in others. Nevertheless, its impact is increasing with the
years, partly self-propelled but also influenced by closely related fields.
Open source, data and models are growing in number but are still scarce and
unevenly distributed among different research groups. The reluctance in
publishing code, data and models limits reproducibility and restricts
evaluation to mono-institutional datasets. Summarised, deep learning will
change positively the workflow of interventional radiotherapy but there is room
for improvement when it comes to reproducible results and standardised
evaluation methods.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:50:51 GMT""},{""version"":""v2"",""created"":""Tue, 27 Sep 2022 09:49:29 GMT""}]","2022-11-15"
"2205.07517","Simon Rey","Jan Maly, Simon Rey, Ulle Endriss and Martin Lackner","Fairness in Participatory Budgeting via Equality of Resources",,,,,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a family of normative principles to assess fairness in the
context of participatory budgeting. These principles are based on the
fundamental idea that budget allocations should be fair in terms of the
resources invested into meeting the wishes of individual voters. This is in
contrast to earlier proposals that are based on specific assumptions regarding
the satisfaction of voters with a given budget allocation. We analyse these new
principles in axiomatic, algorithmic, and experimental terms.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:52:00 GMT""},{""version"":""v2"",""created"":""Mon, 20 Feb 2023 14:28:20 GMT""}]","2023-02-21"
"2205.07518","Fahri Wisnu Murti","Fahri Wisnu Murti, Samad Ali, George Iosifidis, Matti Latva-aho","Learning-Based Orchestration for Dynamic Functional Split and Resource
  Allocation in vRANs","This paper has been accepted in Proc. of The 2022 Joint European
  Conference on Networks and Communications (EuCNC) & 6G Summit",,"10.1109/EuCNC/6GSummit54941.2022.9815815",,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the key benefits of virtualized radio access networks (vRANs) is
network management flexibility. However, this versatility raises
previously-unseen network management challenges. In this paper, a
learning-based zero-touch vRAN orchestration framework (LOFV) is proposed to
jointly select the functional splits and allocate the virtualized resources to
minimize the long-term management cost. First, testbed measurements of the
behaviour between the users' demand and the virtualized resource utilization
are collected using a centralized RAN system. The collected data reveals that
there are non-linear and non-monotonic relationships between demand and
resource utilization. Then, a comprehensive cost model is proposed that takes
resource overprovisioning, declined demand, instantiation and reconfiguration
into account. Moreover, the proposed cost model also captures different routing
and computing costs for each split. Motivated by our measurement insights and
cost model, LOFV is developed using a model-free reinforcement learning
paradigm. The proposed solution is constructed from a combination of deep
Q-learning and a regression-based neural network that maps the network state
and users' demand into split and resource control decisions. Our numerical
evaluations show that LOFV can offer cost savings by up to 69\% of the optimal
static policy and 45\% of the optimal fully dynamic policy.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:52:22 GMT""}]","2022-07-20"
"2205.07519","Moshe Babaioff","Moshe Babaioff and Uriel Feige","Fair Shares: Feasibility, Domination and Incentives",,,,,"econ.TH cs.AI","http://creativecommons.org/licenses/by/4.0/","  We consider fair allocation of a set $M$ of indivisible goods to $n$
equally-entitled agents, with no monetary transfers. Every agent $i$ has a
valuation $v_i$ from some given class of valuation functions. A share $s$ is a
function that maps a pair $(v_i,n)$ to a value, with the interpretation that if
an allocation of $M$ to $n$ agents fails to give agent $i$ a bundle of value at
least equal to $s(v_i,n)$, this serves as evidence that the allocation is not
fair towards $i$. For such an interpretation to make sense, we would like the
share to be feasible, meaning that for any valuations in the class, there is an
allocation that gives every agent at least her share. The maximin share was a
natural candidate for a feasible share for additive valuations. However,
Kurokawa, Procaccia and Wang [2018] show that it is not feasible.
  We initiate a systematic study of the family of feasible shares. We say that
a share is \emph{self maximizing} if truth-telling maximizes the implied
guarantee. We show that every feasible share is dominated by some
self-maximizing and feasible share. We seek to identify those self-maximizing
feasible shares that are polynomial time computable, and offer the highest
share values. We show that a SM-dominating feasible share -- one that dominates
every self-maximizing (SM) feasible share -- does not exist for additive
valuations (and beyond). Consequently, we relax the domination property to that
of domination up to a multiplicative factor of $\rho$ (called
$\rho$-dominating). For additive valuations we present shares that are
feasible, self-maximizing and polynomial-time computable. For $n$ agents we
present such a share that is $\frac{2n}{3n-1}$-dominating. For two agents we
present such a share that is $(1 - \epsilon)$-dominating. Moreover, for these
shares we present poly-time algorithms that compute allocations that give every
agent at least her share.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:52:42 GMT""}]","2022-05-17"
"2205.07520","Baoyi Chen","Liuyuan Wen, Xiaojian Du, Shuzhe Shi, Baoyi Chen","Probe the color screening in proton-nucleus collisions with complex
  potentials","9 pages, 8 figures, accepted by Chinese Physics C","Chin.Phys.C 46 (2022), 114102","10.1088/1674-1137/ac7fe6",,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Color screening and parton inelastic scattering modify the heavy-quark
antiquark potential in the medium that consists of particles from quantum
chromodynamics (QCD), leading to suppression of quarkonium production in
relativistic heavy-ion collisions. Due to small charm/anti-charm ($c\bar{c}$)
pair production number in proton-nucleus (pA) collisions, the correlation
between different $c\bar{c}$ pairs is negligible, which makes the Schr\""odinger
equation viable for tracking the evolution of only one $c\bar{c}$ pair. We
employ the time-dependent Schr\""odinger equation with in-medium $c\bar{c}$
potential to study the evolution of charmonium wave functions in the
hydrodynamic like QCD medium produced in pA collisions. We explore different
parametrizations of real and imaginary parts of $c\bar{c}$ potential and
calculate the nuclear modification factors ($R_{\rm pA}$) of $J/\psi$ and
$\psi(2S)$ in $\sqrt{s_{NN}}=5.02$ TeV energy p-Pb collisions at Large Hadron
Collider (LHC). Comparing a strong and a weak screening scenario with
experimental data in this approach, we arrive at the conclusion that the color
screening is weak at temperature close to deconfined phase transition.
Moreover, the imaginary part of the potential is crucial to describe the
experimental data which is consistent with widely studied semi-classical
approaches where the dissociation rates are essential.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:54:35 GMT""},{""version"":""v2"",""created"":""Thu, 4 Aug 2022 00:53:00 GMT""}]","2022-10-31"
"2205.07521","Wei Wan","Wei Wan, Yuejin Zhang, Chenglong Bao, Bin Dong, Zuoqiang Shi","A scalable deep learning approach for solving high-dimensional dynamic
  optimal transport",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The dynamic formulation of optimal transport has attracted growing interests
in scientific computing and machine learning, and its computation requires to
solve a PDE-constrained optimization problem. The classical Eulerian
discretization based approaches suffer from the curse of dimensionality, which
arises from the approximation of high-dimensional velocity field. In this work,
we propose a deep learning based method to solve the dynamic optimal transport
in high dimensional space. Our method contains three main ingredients: a
carefully designed representation of the velocity field, the discretization of
the PDE constraint along the characteristics, and the computation of high
dimensional integral by Monte Carlo method in each time step. Specifically, in
the representation of the velocity field, we apply the classical nodal basis
function in time and the deep neural networks in space domain with the H1-norm
regularization. This technique promotes the regularity of the velocity field in
both time and space such that the discretization along the characteristic
remains to be stable during the training process. Extensive numerical examples
have been conducted to test the proposed method. Compared to other solvers of
optimal transport, our method could give more accurate results in high
dimensional cases and has very good scalability with respect to dimension.
Finally, we extend our method to more complicated cases such as crowd motion
problem.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:56:05 GMT""}]","2022-05-17"
"2205.07522","Etienne Bachelet","E. Bachelet, Y. Tsapras, Andrew Gould, R.A. Street, David P. Bennett,
  M.P.G. Hundertmark, V. Bozza, D.M. Bramich, A. Cassan, M. Dominik, K. Horne,
  S. Mao, A. Saha, J. Wambsganss, Weicheng Zang, Fumio Abe, Richard Barry,
  Aparna Bhattacharya, Ian A. Bond, Akihiko Fukui, Hirosane Fujii, Yuki Hirao,
  Yoshitaka Itow, Rintaro Kirikawa, Naoki Koshimoto, Yutaka Matsubara, Sho
  Matsumoto, Shota Miyazaki, Yasushi Muraki, Greg Olmschenk, Cl\'ement Ranc,
  Arisa Okamura, Nicholas J. Rattenbury, Yuki Satoh, Takahiro Sumi, Daisuke
  Suzuki, Stela Ishitani Silva, Taiga Toda, Paul . J. Tristram, Aikaterini
  Vandorou, Hibiki Yama, Michael D. Albrow, Sun-Ju Chung, Cheongho Han, Kyu-Ha
  Hwang, Youn Kil Jung, Yoon-Hyun Ryu, In-Gu Shin, Yossi Shvartzvald, Jennifer
  C. Yee, Sang-Mok Cha, Dong-Jin Kim, Seung-Lee Kim, Chung-Uk Lee, Dong-Joo
  Lee, Yongseok Lee, Byeong-Gon Park, Richard W. Pogge, Andrzej Udalski,
  Przemek Mr\'oz, Rados law Poleski, Jan Skowron, Micha l K. Szyma\'nski, Igor
  Soszy\'nski, Pawe l Pietrukowicz, Szymon Kozlowski, Krzysztof Ulaczyk,
  Krzysztof A. Rybicki, Patryk Iwanek, Marcin Wrona, Mariusz Gromadzki","MOA-2019-BLG-008Lb: a new microlensing detection of an object at the
  planet/brown dwarf boundary","Accepted in AJ",,"10.3847/1538-3881/ac78ed",,"astro-ph.EP astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on the observations, analysis and interpretation of the
microlensing event MOA-2019- BLG-008. The observed anomaly in the photometric
light curve is best described through a binary lens model. In this model, the
source did not cross caustics and no finite source effects were observed.
Therefore the angular Einstein ring radius cannot be measured from the light
curve alone. However, the large event duration, t E about 80 days, allows a
precise measurement of the microlensing parallax. In addition to the
constraints on the angular radius and the apparent brightness I s of the
source, we employ the Besancon and GalMod galactic models to estimate the
physical properties of the lens. We find excellent agreement between the
predictions of the two Galactic models: the companion is likely a resident of
the brown dwarf desert with a mass Mp about 30 MJup and the host is a main
sequence dwarf star. The lens lies along the line of sight to the Galactic
Bulge, at a distance of less then4 kpc. We estimate that in about 10 years, the
lens and source will be separated by 55 mas, and it will be possible to confirm
the exact nature of the lensing system by using high-resolution imaging from
ground or space-based observatories.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:56:11 GMT""}]","2022-08-17"
"2205.07523","Xinyin Ma","Xinyin Ma, Xinchao Wang, Gongfan Fang, Yongliang Shen and Weiming Lu","Prompting to Distill: Boosting Data-Free Knowledge Distillation via
  Reinforced Prompt","Accepted by IJCAI2022",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Data-free knowledge distillation (DFKD) conducts knowledge distillation via
eliminating the dependence of original training data, and has recently achieved
impressive results in accelerating pre-trained language models. At the heart of
DFKD is to reconstruct a synthetic dataset by inverting the parameters of the
uncompressed model. Prior DFKD approaches, however, have largely relied on
hand-crafted priors of the target data distribution for the reconstruction,
which can be inevitably biased and often incompetent to capture the intrinsic
distributions. To address this problem, we propose a prompt-based method,
termed as PromptDFD, that allows us to take advantage of learned language
priors, which effectively harmonizes the synthetic sentences to be semantically
and grammatically correct. Specifically, PromptDFD leverages a pre-trained
generative model to provide language priors and introduces a reinforced topic
prompter to control data synthesis, making the generated samples thematically
relevant and semantically plausible, and thus friendly to downstream tasks. As
shown in our experiments, the proposed method substantially improves the
synthesis quality and achieves considerable improvements on distillation
performance. In some cases, PromptDFD even gives rise to results on par with
those from the data-driven knowledge distillation with access to the original
training data.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:56:53 GMT""}]","2022-05-17"
"2205.07524","Mustafa Kaan Topalo\u{g}lu","Mustafa Kaan Topaloglu (1) and Banu Kabakulak (1) ((1) Department of
  Industrial Engineering, Istanbul Bilgi University, Istanbul, Turkey)","A Two-Phase Method for Production Planning and Machine Speed
  Optimization Problem","Corresponding author: Banu Kabakulak, e-mail:
  banu.kabakulak@boun.edu.tr",,,,"cs.CE math.OC","http://creativecommons.org/licenses/by/4.0/","  Textile industry is becoming a highly competitive area with the increase in
demand for textile products. Since expanding the production capacity is not
always feasible, optimizing the existing system is more practical. In
particular, we consider a felt production system of a textile factory operating
in Turkey in this study. We aim to minimize the production costs by optimizing
machine operating speeds as well as building an efficient production lot sizing
plan within the planning horizon. In this direction, we propose the Lot Sizing
and Machine Speed (LSMS) nonlinear model to determine the optimal unit
processing times and production quantities while minimizing the work-in-process
and end item inventories by changing the machine operating speeds dynamically
according to the demands. Since LSMS nonlinear optimization problem is NP-hard,
we design a Two-Phase heuristic which iteratively processes a linear
programming model by utilizing a commercial solver at each phase. We
intensively test our Two-Phase heuristic via randomly generated demand,
planning horizon and machine-hour capacity scenarios. Our computational
experiments show that the introduced Two-Phase heuristic can find the
local-optimal results in acceptable amount of time.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:56:59 GMT""}]","2022-05-17"
"2205.07525","Ercong Zhang","Haowei Wang, Ercong Zhang, Szu Hui Ng, Giulia Pedrielli","A model aggregation approach for high-dimensional large-scale
  optimization",,,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bayesian optimization (BO) has been widely used in machine learning and
simulation optimization. With the increase in computational resources and
storage capacities in these fields, high-dimensional and large-scale problems
are becoming increasingly common. In this study, we propose a model aggregation
method in the Bayesian optimization (MamBO) algorithm for efficiently solving
high-dimensional large-scale optimization problems. MamBO uses a combination of
subsampling and subspace embeddings to collectively address high dimensionality
and large-scale issues; in addition, a model aggregation method is employed to
address the surrogate model uncertainty issue that arises when embedding is
applied. This surrogate model uncertainty issue is largely ignored in the
embedding literature and practice, and it is exacerbated when the problem is
high-dimensional and data are limited. Our proposed model aggregation method
reduces these lower-dimensional surrogate model risks and improves the
robustness of the BO algorithm. We derive an asymptotic bound for the proposed
aggregated surrogate model and prove the convergence of MamBO. Benchmark
numerical experiments indicate that our algorithm achieves superior or
comparable performance to other commonly used high-dimensional BO algorithms.
Moreover, we apply MamBO to a cascade classifier of a machine learning
algorithm for face detection, and the results reveal that MamBO finds settings
that achieve higher classification accuracy than the benchmark settings and is
computationally faster than other high-dimensional BO algorithms.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 08:58:42 GMT""},{""version"":""v2"",""created"":""Wed, 1 Jun 2022 06:22:38 GMT""}]","2022-06-02"
"2205.07526","Edvard Musaev","Edvard T. Musaev and Jeffrey P. Molina","The invariant action for solitonic 5-branes",,,"10.1140/epjc/s10052-022-10946-1",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct the full effective action including DBI and WZ terms for
solitonic 5-branes covariant under T-duality. The result is a completion of
results known in the literature to a full T-duality covariant expression. The
covariant WZ action includes previously omitted R-R terms. The obtained full
covariant effective action reproduces the one obtained by S-duality from the
D5-brane upon the correct choice of the covariant charge.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:00:05 GMT""}]","2022-11-03"
"2205.07527","Anand Sawant","Chetan Balwe, Amit Hogadi, Anand Sawant","Strong $\mathbb A^1$-invariance of $\mathbb A^1$-connected components of
  reductive algebraic groups","15 pages, comments are welcome, v4: final version before page proofs,
  accepted for publication by the Journal of Topology",,,,"math.AG math.AT math.GR math.KT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the sheaf of $\mathbb A^1$-connected components of a reductive
algebraic group over a perfect field is strongly $\mathbb A^1$-invariant. As a
consequence, torsors under such groups give rise to $\mathbb A^1$-fiber
sequences. We also show that sections of $\mathbb A^1$-connected components of
anisotropic, semisimple, simply connected algebraic groups over an arbitrary
field agree with their $R$-equivalence classes, thereby removing the
perfectness assumption in the previously known results about the
characterization of isotropy in terms of affine homotopy invariance of
Nisnevich locally trivial torsors.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:04:13 GMT""},{""version"":""v2"",""created"":""Wed, 29 Jun 2022 09:28:42 GMT""},{""version"":""v3"",""created"":""Tue, 20 Sep 2022 15:54:35 GMT""},{""version"":""v4"",""created"":""Sat, 22 Apr 2023 12:47:52 GMT""}]","2023-04-25"
"2205.07528","Florian Starke","Manuel Bodirsky, Jakub Bul\'in, Florian Starke, Michael Wernthaler","The Smallest Hard Trees",,,"10.1007/s10601-023-09341-8",,"math.RA cs.CC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We find an orientation of a tree with 20 vertices such that the corresponding
fixed-template constraint satisfaction problem (CSP) is NP-complete, and prove
that for every orientation of a tree with fewer vertices the corresponding CSP
can be solved in polynomial time. We also compute the smallest tree that is
NL-hard (assuming L is not NL), the smallest tree that cannot be solved by arc
consistency, and the smallest tree that cannot be solved by Datalog. Our
experimental results also support a conjecture of Bulin concerning a question
of Hell, Nesetril and Zhu, namely that ""easy trees lack the ability to count"".
Most proofs are computer-based and make use of the most recent
universal-algebraic theory about the complexity of finite-domain CSPs. However,
further ideas are required because of the huge number of orientations of trees.
In particular, we use the well-known fact that it suffices to study
orientations of trees that are cores and show how to efficiently decide whether
a given orientation of a tree is a core using the arc-consistency procedure.
Moreover, we present a method to generate orientations of trees that are cores
that works well in practice. In this way we found interesting examples for the
open research problem to classify finite-domain CSPs in NL.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:06:09 GMT""}]","2023-03-28"
"2205.07529","Pedro Antonino","Pedro Antonino and Juliandson Ferreira and Augusto Sampaio and A. W.
  Roscoe","Specification is Law: Safe Creation and Upgrade of Ethereum Smart
  Contracts",,,,,"cs.SE cs.LO","http://creativecommons.org/licenses/by/4.0/","  Smart contracts are the building blocks of the ""code is law"" paradigm: the
smart contract's code indisputably describes how its assets are to be managed -
once it is created, its code is typically immutable. Faulty smart contracts
present the most significant evidence against the practicality of this
paradigm; they are well-documented and resulted in assets worth vast sums of
money being compromised. To address this issue, the Ethereum community proposed
(i) tools and processes to audit/analyse smart contracts, and (ii) design
patterns implementing a mechanism to make contract code mutable. Individually,
(i) and (ii) only partially address the challenges raised by the ""code is law""
paradigm. In this paper, we combine elements from (i) and (ii) to create a
systematic framework that moves away from ""code is law"" and gives rise to a new
""specification is law"" paradigm. It allows contracts to be created and upgraded
but only if they meet a corresponding formal specification. The framework is
centered around \emph{a trusted deployer}: an off-chain service that formally
verifies and enforces this notion of conformance. We have prototyped this
framework, and investigated its applicability to contracts implementing two
widely used Ethereum standards: the ERC20 Token Standard and ERC1155 Multi
Token Standard, with promising results.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:08:48 GMT""}]","2022-05-17"
"2205.07530","Zheng-Wen Long","Yi Yang, Dong Liu, Ali \""Ovg\""un, Zheng-Wen Long, Zhaoyi Xu","Quasinormal modes of Kerr-like black bounce spacetime",,,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The quasinormal modes of the Kerr-like black bounce spacetime under the
scalar field perturbations are studied. We derive the effective potential of
scalar perturbation in Kerr-like black bounce spacetime, and study the
influence of Kerr-like black bounce spacetime parameters on quasinormal modes
by using WKB method and P\""{o}schl-Teller potential approximation. We find that
Kerr-like black bounce spacetime has the analogous double-peaked potential as
Schwarzschild-like black bounce spacetime, and mass of the scalar particle has
a non-negligible effect on quasinormal modes of Kerr-like black bounce
spacetime.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:09:20 GMT""}]","2022-05-17"
"2205.07531","Fynn Bachmann","Fynn Bachmann, Philipp Hennig, Dmitry Kobak","Wasserstein t-SNE","16 pages, 10 figures, to be published at ECML/PKDD 2022",,,,"cs.LG cs.HC stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Scientific datasets often have hierarchical structure: for example, in
surveys, individual participants (samples) might be grouped at a higher level
(units) such as their geographical region. In these settings, the interest is
often in exploring the structure on the unit level rather than on the sample
level. Units can be compared based on the distance between their means, however
this ignores the within-unit distribution of samples. Here we develop an
approach for exploratory analysis of hierarchical datasets using the
Wasserstein distance metric that takes into account the shapes of within-unit
distributions. We use t-SNE to construct 2D embeddings of the units, based on
the matrix of pairwise Wasserstein distances between them. The distance matrix
can be efficiently computed by approximating each unit with a Gaussian
distribution, but we also provide a scalable method to compute exact
Wasserstein distances. We use synthetic data to demonstrate the effectiveness
of our Wasserstein t-SNE, and apply it to data from the 2017 German
parliamentary election, considering polling stations as samples and voting
districts as units. The resulting embedding uncovers meaningful structure in
the data.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:09:24 GMT""},{""version"":""v2"",""created"":""Thu, 23 Jun 2022 08:10:54 GMT""}]","2022-06-24"
"2205.07532","Swagata Duari","Vasudha Bhatnagar, Swagata Duari, S.K. Gupta","Quantitative Discourse Cohesion Analysis of Scientific Scholarly Texts
  using Multilayer Networks","26 pages, 8 figures, 4 tables","IEEE Access, vol. 10, pp. 88538-88557, 2022","10.1109/ACCESS.2022.3198952",,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Discourse cohesion facilitates text comprehension and helps the reader form a
coherent narrative. In this study, we aim to computationally analyze the
discourse cohesion in scientific scholarly texts using multilayer network
representation and quantify the writing quality of the document. Exploiting the
hierarchical structure of scientific scholarly texts, we design section-level
and document-level metrics to assess the extent of lexical cohesion in text. We
use a publicly available dataset along with a curated set of contrasting
examples to validate the proposed metrics by comparing them against select
indices computed using existing cohesion analysis tools. We observe that the
proposed metrics correlate as expected with the existing cohesion indices.
  We also present an analytical framework, CHIAA (CHeck It Again, Author), to
provide pointers to the author for potential improvements in the manuscript
with the help of the section-level and document-level metrics. The proposed
CHIAA framework furnishes a clear and precise prescription to the author for
improving writing by localizing regions in text with cohesion gaps. We
demonstrate the efficacy of CHIAA framework using succinct examples from
cohesion-deficient text excerpts in the experimental dataset.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:10:41 GMT""}]","2022-11-09"
"2205.07533","Romualdo Pastor-Satorras","Jaume Ojer, Romualdo Pastor-Satorras","Flocking dynamics mediated by weighted social networks","12 pages, 9 figures",,"10.1103/PhysRevE.106.044601",,"physics.soc-ph cond-mat.stat-mech physics.bio-ph","http://creativecommons.org/licenses/by/4.0/","  We study the effects of animal social networks with a weighted pattern of
interactions on the flocking transition exhibited by models of self-organized
collective motion. Considering a model representing dynamics on a
one-dimensional substrate, application of a heterogeneous mean-field theory
provides a phase diagram as function of the heterogeneity of the network
connections and the correlations between weights and degree. In this diagram we
observe two phases, one corresponding to the presence of a transition and other
to a transition suppressed in an always ordered system, already observed in the
non-weighted case. Interestingly, a third phase, with no transition in an
always disordered state, is also obtained. These predictions, numerically
recovered in computer simulations, are also fulfilled for the more realistic
Vicsek model, with movement in a two-dimensional space. Additionally, we
observe at finite network sizes the presence of a maximum threshold for
particular weight configurations, indicating that it is possible to tune
weights to achieve a maximum resilience to noise effects. Simulations in real
weighted animal social networks show that, in general, the presence of weights
diminishes the value of the flocking threshold, thus increasing the fragility
of the flocking state. The shift in the threshold is observed to depend on the
heterogeneity of the weight pattern.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:28:28 GMT""}]","2022-10-19"
"2205.07534","Hector Gisbert Mullor","Hector Gisbert","The role of dineutrino modes in the search for new physics","6 pages, 1 figure, contribution to the 2022 Electroweak session of
  the 56th Rencontres de Moriond",,,"DO-TH 22/15","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dineutrino modes offer promising searches for new physics. The potential
aspects of these modes are reviewed in detail. Performing a proper combination
of them, novel tests of the SM symmetries are derived. Different
phenomenological applications are worked out, including charm, beauty and
kaons, which result in novel tests of lepton universality and charged lepton
flavour conservation with flavour-summed dineutrino observables, in addition to
improved bounds on $\tau\,\ell$ couplings with $\ell=e,\mu,\tau$.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:30:17 GMT""}]","2022-05-17"
"2205.07535","Peng Liang","Xiaofeng Han, Amjed Tahir, Peng Liang, Steve Counsell, Kelly Blincoe,
  Bing Li, Yajing Luo","Code Smells Detection via Modern Code Review: A Study of the OpenStack
  and Qt Communities","Preprint accepted for publication in Empirical Software Engineering,
  2022. arXiv admin note: substantial text overlap with arXiv:2103.11446",,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Code review that detects and locates defects and other quality issues plays
an important role in software quality control. One type of issue that may
impact the quality of software is code smells. Yet, little is known about the
extent to which code smells are identified during modern code review. To
investigate the concept behind code smells identified in modern code review and
what actions reviewers suggest and developers take in response to the
identified smells, we conducted a study of code smells in code reviews by
analyzing reviews from four large open source projects from the OpenStack (Nova
and Neutron) and Qt (Qt Base and Qt Creator) communities. We manually checked a
total of 25,415 code review comments obtained by keywords search and random
selection, and identified 1,539 smell-related reviews. Our analysis found that
1) code smells were not commonly identified in code reviews, 2) smells were
usually caused by violation of coding conventions, 3) reviewers usually
provided constructive feedback, including fixing (refactoring) recommendations
to help developers remove smells, 4) developers generally followed those
recommendations and actioned the changes, 5) once identified by reviewers, it
usually takes developers less than one week to fix the smells, and 6) the main
reason why developers chose to ignore the identified smells is not worth fixing
the smell. Our results suggest that: 1) developers should closely follow coding
conventions in their projects to avoid introducing code smells, 2) review-based
detection of code smells is perceived to be a trustworthy approach by
developers, mainly because reviews are context-sensitive (as reviewers are more
aware of the context of the code given that they are part of the project's
development team), and 3) program context needs to be fully considered in order
to make a decision of whether to fix the identified code smell immediately.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:32:03 GMT""}]","2022-05-17"
"2205.07536","Dongjie Yu","Dongjie Yu, Haitong Ma, Shengbo Eben Li, Jianyu Chen","Reachability Constrained Reinforcement Learning","Accepted by ICML 2022",,,,"cs.LG cs.AI cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Constrained reinforcement learning (CRL) has gained significant interest
recently, since safety constraints satisfaction is critical for real-world
problems. However, existing CRL methods constraining discounted cumulative
costs generally lack rigorous definition and guarantee of safety. In contrast,
in the safe control research, safety is defined as persistently satisfying
certain state constraints. Such persistent safety is possible only on a subset
of the state space, called feasible set, where an optimal largest feasible set
exists for a given environment. Recent studies incorporate feasible sets into
CRL with energy-based methods such as control barrier function (CBF), safety
index (SI), and leverage prior conservative estimations of feasible sets, which
harms the performance of the learned policy. To deal with this problem, this
paper proposes the reachability CRL (RCRL) method by using reachability
analysis to establish the novel self-consistency condition and characterize the
feasible sets. The feasible sets are represented by the safety value function,
which is used as the constraint in CRL. We use the multi-time scale stochastic
approximation theory to prove that the proposed algorithm converges to a local
optimum, where the largest feasible set can be guaranteed. Empirical results on
different benchmarks validate the learned feasible set, the policy performance,
and constraint satisfaction of RCRL, compared to CRL and safe control
baselines.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:32:45 GMT""},{""version"":""v2"",""created"":""Tue, 7 Jun 2022 03:28:47 GMT""}]","2022-06-08"
"2205.07537","Mohammed El-Kholany","Mohammed M. S. El-Kholany, Martin Gebser and Konstantin Schekotihin","Problem Decomposition and Multi-shot ASP Solving for Job-shop Scheduling","Paper presented at the 38th International Conference on Logic
  Programming (ICLP 2022), 16 pages",,,,"cs.AI cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Job-shop Scheduling Problem (JSP) is a well-known and challenging
combinatorial optimization problem in which tasks sharing a machine are to be
arranged in a sequence such that encompassing jobs can be completed as early as
possible. In this paper, we propose problem decomposition into time windows
whose operations can be successively scheduled and optimized by means of
multi-shot Answer Set Programming (ASP) solving. Decomposition aims to split
highly complex scheduling tasks into better manageable sub-problems with a
balanced number of operations so that good quality or even optimal partial
solutions can be reliably found in a small fraction of runtime. Problem
decomposition must respect the precedence of operations within their jobs and
partial schedules optimized by time windows should yield better global
solutions than obtainable in similar runtime on the entire instance. We devise
and investigate a variety of decomposition strategies in terms of the number
and size of time windows as well as heuristics for choosing their operations.
Moreover, we incorporate time window overlapping and compression techniques
into the iterative scheduling process to counteract window-wise optimization
limitations restricted to partial schedules. Our experiments on JSP benchmark
sets of several sizes show that successive optimization by multi-shot ASP
solving leads to substantially better schedules within the runtime limit than
global optimization on the full problem, where the gap increases with the
number of operations to schedule. While the obtained solution quality still
remains behind a state-of-the-art Constraint Programming system, our multi-shot
solving approach comes closer the larger the instance size, demonstrating good
scalability by problem decomposition.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:33:00 GMT""},{""version"":""v2"",""created"":""Mon, 23 May 2022 09:32:16 GMT""}]","2022-05-24"
"2205.07538","Chao Niu","Wei Xiong, Peng Liu, Chao Niu, Cheng-Yong Zhang, and Bin Wang","Dynamical spontaneous scalarization in Einstein-Maxwell-scalar theory","17 pages, 17 figures, the version accepted by CPC",,"10.1088/1674-1137/ac70ad",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the linear instability and the nonlinear dynamical evolution of the
Reissner-Nordstr\""om (RN) black hole in the Einstein-Maxwell-scalar theory in
asymptotic flat spacetime. We focus on the coupling function
$f(\phi)=e^{-b\phi^2}$ which allows both the scalar-free RN solution and
scalarized black hole solution. We first present the evolution of system
parameters during dynamic scalarization. For parameter regions where
spontaneous scalarization occurs, we find that the evolution of the scalar
field at the horizon is dominated by the fundamental unstable mode from linear
analysis at early times. At late times, the nonlinear evolution can be viewed
as the perturbation of scalarized black holes.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:34:28 GMT""}]","2022-09-14"
"2205.07539","Takuma Hayashi","Takuma Hayashi","Filtrations on the globalization of twisted D-modules over Dedekind
  schemes","12 pages. Comments welcome",,,,"math.AG math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fabian Januszewski and the author established the theory of twisted D-modules
over general base schemes. In this short note, we construct a $K$-equivariant
positive exhaustive filtration on the globalization of the twisted D-module on
a smooth quasi-compact $K$-scheme over a Dedekind scheme $S$ obtained by the
direct image of a torsion-free and $\mathcal{O}_Y$-coherent $K$-equivariant
twisted D-module along a $K$-equivariant closed immersion from a smooth proper
integral $K$-scheme $Y$ with $K$ a smooth $S$-affine group scheme,, whose $p$th
associated graded $\mathcal{O}_S$-module is finite locally free for every
integer $p$.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:35:13 GMT""}]","2022-05-17"
"2205.07540","Ana\""is Tack","Ana\""is Tack and Chris Piech","The AI Teacher Test: Measuring the Pedagogical Ability of Blender and
  GPT-3 in Educational Dialogues","to be published in the Proceedings of the 15th International
  Conference on Educational Data Mining; 8 pages, 5 figures, 3 tables",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  How can we test whether state-of-the-art generative models, such as Blender
and GPT-3, are good AI teachers, capable of replying to a student in an
educational dialogue? Designing an AI teacher test is challenging: although
evaluation methods are much-needed, there is no off-the-shelf solution to
measuring pedagogical ability. This paper reports on a first attempt at an AI
teacher test. We built a solution around the insight that you can run
conversational agents in parallel to human teachers in real-world dialogues,
simulate how different agents would respond to a student, and compare these
counterpart responses in terms of three abilities: speak like a teacher,
understand a student, help a student. Our method builds on the reliability of
comparative judgments in education and uses a probabilistic model and Bayesian
sampling to infer estimates of pedagogical ability. We find that, even though
conversational agents (Blender in particular) perform well on conversational
uptake, they are quantifiably worse than real teachers on several pedagogical
dimensions, especially with regard to helpfulness (Blender: {\Delta} ability =
-0.75; GPT-3: {\Delta} ability = -0.93).
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:36:30 GMT""}]","2022-05-17"
"2205.07541","Dongge Ma","Dongge Ma, Yuhang Qian, Mingyang Ji, Jiani Li, Jundan Li, Anan Liu and
  Yaohui Zhu","Ferrimagnetism in stable non-metal covalent organic framework","24 pages, 7 figures, 1 table and 33 references",,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We synthesized a pure organic non-metal crystalline covalent organic
framework TAPA-BTD-COF by bottom-up Schiff base chemical reaction. And this
imine-based COF is stable in aerobic condition and room-temperature. We
discovered that this TAPA-BTD-COF exhibited strong magneticity in 300 K
generating magnetic hysteresis loop in M-H characterization and giant chimol up
to 0.028. And we further conducted zero-field cooling and field-cooling
measurement of M-T curves. The as-synthesized materials showed a large chi/mol
up to 0.028 in 300 K and increasing to 0.037 in 4.0 K with 200 Oe measurement
field. The TAPA-BTD-COF 1/chimol~T curve supported its ferrimagnetism, with an
intrinsic delta temperature as -33.03 K by extrapolating the 1/chimol~T curve.
From the continuously increasing slope of 1/chimol~T, we consider that this
TAPA-BTD-COF belongs to ferrimagnetic other than antiferromagnetic materials.
And the large chimol value 0.028 at 300 K and 0.037 at 4.0 K also supported
this, since common antiferromagnetic materials possess chimol in the range of
10-5 to 10-3 as weak magnetics other than strong magnetic materials such as
ferrimagnetics and ferromagnetics. Since this material is purely non-metal
organic polymer, the possibility of d-block and f-block metal with
unpaired-electron induced magnetism can be excluded. Besides, since the COF
does not involve free-radical monomer in the processes of synthesis, we can
also exclude the origin of free-radical induced magnetism. According to recent
emerging flat-band strong correlated exotic electron property, this
unconventional phenomenon may relate to n-type doping on the flat-band locating
in the CBM, thus generating highly-localized electron with infinite effective
mass and exhibiting strong correlation, which accounts for this non-trivial
strong and stable ferrimagneticity at room-temperature and aerobic atmospheric
conditions.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:39:03 GMT""}]","2022-05-17"
"2205.07542","Carolina Charalambous Dr.","C. Charalambous, C.A. Giuppone and O.M. Guilera","Web of resonances and possible path of evolution of the small Uranian
  satellites",,,"10.1007/s10509-022-04083-0",,"astro-ph.EP physics.space-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Satellite systems around giant planets are immersed in a region of complex
resonant configurations. Understanding the role of satellite resonances
contributes to comprehending the dynamical processes in planetary formation and
posterior evolution. Our main goal is to analyse the resonant structure of
small moons around Uranus and propose different scenarios able to describe the
current configuration of these satellites. We focus our study on the external
members of the regular satellites interior to Miranda, namely Rosalind, Cupid,
Belinda, Perdita, Puck, and Mab, respectively. We use N-body integrations to
perform dynamical maps to analyse their dynamics and proximity to two-body and
three-body mean-motion resonances (MMR). We found a complicated web of
low-order resonances amongst them. Employing analytical prescriptions, we
analysed the evolution by gas drag and type-I migration in a circumplanetary
disc (CPD) to explain different possible histories for these moons. We also
model the tidal evolution of these satellites using some crude approximations
and found possible paths that could lead to MMRs crossing between pairs of
moons. Finally, our simulations show that each mechanism can generate
significant satellite radial drift leading to possible resonant capture,
depending on the distances and sizes.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:42:57 GMT""}]","2022-06-08"
"2205.07543","Christoph Rettinger","Christoph Rettinger, Ulrich R\""ude, Stefan Vollmer, Roy M. Frings","Effect of Sediment Form and Form Distribution on Porosity: A Simulation
  Study Based on the Discrete Element Method",,,,,"physics.geo-ph physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  Porosity is one of the key properties of dense particle packings like
sediment deposits and is influenced by a multitude of grain characteristics
such as their size distribution and shape. In the present work, we focus on the
form, a specific aspect of the overall shape, of sedimentary grains in order to
investigate and quantify its effect on porosity, ultimately deriving novel
porosity-prediction models. To this end, we develop a robust and accurate
simulation tool based on the discrete element method which we validate against
laboratory experiments. Utilizing digital representations of actual sediment
from the Rhine river, we first study packings that are composed of particles
with a single form. There, the porosity is found to be mainly determined by the
inverse equancy, i.e., the ratio of the longest to the smallest form-defining
axis. Only for small ratios, additional shape-related properties become
relevant, as revealed by a direct comparison to packings of form-equivalent
ellipsoids. Since sediment naturally features form mixtures, we extend our
simulation tool to study sediment packings with normally-distributed forms. In
agreement with our single form studies, the porosity depends primarily on the
inverse of the mean equancy. By supplying additional information about a second
form factor and the standard deviations, we derive an accurate model for
porosity prediction. Due to its simplicity, it can be readily applied to
sediment packings for which some measurements of flatness and elongation, the
two most common form factors, are available.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:45:00 GMT""}]","2022-05-17"
"2205.07544","Fedor Stonyakin","Boris T. Polyak, Ilia A. Kuruzov and Fedor S. Stonyakin","Stopping Rules for Gradient Methods for Non-Convex Problems with
  Additive Noise in Gradient",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the gradient method under the assumption that an additively inexact
gradient is available for, generally speaking, non-convex problems. The
non-convexity of the objective function, as well as the use of an inexactness
specified gradient at iterations, can lead to various problems. For example,
the trajectory of the gradient method may be far enough away from the starting
point. On the other hand, the unbounded removal of the trajectory of the
gradient method in the presence of noise can lead to the removal of the
trajectory of the method from the desired exact solution. The results of
investigating the behavior of the trajectory of the gradient method are
obtained under the assumption of the inexactness of the gradient and the
condition of gradient dominance. It is well known that such a condition is
valid for many important non-convex problems. Moreover, it leads to good
complexity guarantees for the gradient method. A rule of early stopping of the
gradient method is proposed. Firstly, it guarantees achieving an acceptable
quality of the exit point of the method in terms of the function. Secondly, the
stopping rule ensures a fairly moderate distance of this point from the chosen
initial position. In addition to the gradient method with a constant step, its
variant with adaptive step size is also investigated in detail, which makes it
possible to apply the developed technique in the case of an unknown Lipschitz
constant for the gradient. Some computational experiments have been carried out
which demonstrate effectiveness of the proposed stopping rule for the
investigated gradient methods.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:45:42 GMT""},{""version"":""v2"",""created"":""Sun, 30 Oct 2022 19:27:28 GMT""},{""version"":""v3"",""created"":""Sun, 11 Dec 2022 21:02:02 GMT""}]","2022-12-13"
"2205.07545","Nan Bai","Nan Bai, Pirouz Nourian, Renqian Luo, Ana Pereira Roders","Heri-Graphs: A Workflow of Creating Datasets for Multi-modal Machine
  Learning on Graphs of Heritage Values and Attributes with Social Media","28 pages, 6 figures, 12 tables. The data and models presented in this
  paper can be found in the following GitHub link:
  https://github.com/zzbn12345/Heri_Graphs",,"10.3390/ijgi11090469",,"cs.SI cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Values (why to conserve) and Attributes (what to conserve) are essential
concepts of cultural heritage. Recent studies have been using social media to
map values and attributes conveyed by public to cultural heritage. However, it
is rare to connect heterogeneous modalities of images, texts, geo-locations,
timestamps, and social network structures to mine the semantic and structural
characteristics therein. This study presents a methodological workflow for
constructing such multi-modal datasets using posts and images on Flickr for
graph-based machine learning (ML) tasks concerning heritage values and
attributes. After data pre-processing using state-of-the-art ML models, the
multi-modal information of visual contents and textual semantics are modelled
as node features and labels, while their social relationships and
spatiotemporal contexts are modelled as links in Multi-Graphs. The workflow is
tested in three cities containing UNESCO World Heritage properties - Amsterdam,
Suzhou, and Venice, which yielded datasets with high consistency for
semi-supervised learning tasks. The entire process is formally described with
mathematical notations, ready to be applied in provisional tasks both as ML
problems with technical relevance and as urban/heritage study questions with
societal interests. This study could also benefit the understanding and mapping
of heritage values and attributes for future research in global cases, aiming
at inclusive heritage management practices.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:45:45 GMT""}]","2022-09-02"
"2205.07546","Rui Yan","Rui Yan, Gabriel Santos, Xiaoming Duan, David Parker, Marta
  Kwiatkowska","Finite-horizon Equilibria for Neuro-symbolic Concurrent Stochastic Games","14 pages, 7 figures","Uncertainty in Artificial Intelligence (UAI2022)",,,"cs.GT cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present novel techniques for neuro-symbolic concurrent stochastic games, a
recently proposed modelling formalism to represent a set of probabilistic
agents operating in a continuous-space environment using a combination of
neural network based perception mechanisms and traditional symbolic methods. To
date, only zero-sum variants of the model were studied, which is too
restrictive when agents have distinct objectives. We formalise notions of
equilibria for these models and present algorithms to synthesise them. Focusing
on the finite-horizon setting, and (global) social welfare subgame-perfect
optimality, we consider two distinct types: Nash equilibria and correlated
equilibria. We first show that an exact solution based on backward induction
may yield arbitrarily bad equilibria. We then propose an approximation
algorithm called frozen subgame improvement, which proceeds through iterative
solution of nonlinear programs. We develop a prototype implementation and
demonstrate the benefits of our approach on two case studies: an automated
car-parking system and an aircraft collision avoidance system.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:48:12 GMT""},{""version"":""v2"",""created"":""Sat, 18 Jun 2022 14:34:07 GMT""}]","2022-06-22"
"2205.07547","Yuhta Takida","Yuhta Takida, Takashi Shibuya, WeiHsiang Liao, Chieh-Hsin Lai, Junki
  Ohmura, Toshimitsu Uesaka, Naoki Murata, Shusuke Takahashi, Toshiyuki
  Kumakura, Yuki Mitsufuji","SQ-VAE: Variational Bayes on Discrete Representation with Self-annealed
  Stochastic Quantization","25 pages with 10 figures, accepted for publication in ICML 2022 (Our
  code is available at https://github.com/sony/sqvae)",,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  One noted issue of vector-quantized variational autoencoder (VQ-VAE) is that
the learned discrete representation uses only a fraction of the full capacity
of the codebook, also known as codebook collapse. We hypothesize that the
training scheme of VQ-VAE, which involves some carefully designed heuristics,
underlies this issue. In this paper, we propose a new training scheme that
extends the standard VAE via novel stochastic dequantization and quantization,
called stochastically quantized variational autoencoder (SQ-VAE). In SQ-VAE, we
observe a trend that the quantization is stochastic at the initial stage of the
training but gradually converges toward a deterministic quantization, which we
call self-annealing. Our experiments show that SQ-VAE improves codebook
utilization without using common heuristics. Furthermore, we empirically show
that SQ-VAE is superior to VAE and VQ-VAE in vision- and speech-related tasks.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:49:37 GMT""},{""version"":""v2"",""created"":""Thu, 9 Jun 2022 12:46:05 GMT""}]","2022-06-10"
"2205.07548","Johannes Oetsch","Thomas Eiter, Nelson Higuera, Johannes Oetsch, and Michael Pritz","A Neuro-Symbolic ASP Pipeline for Visual Question Answering","Paper presented at the 38th International Conference on Logic
  Programming (ICLP 2022), 15 pages",,,,"cs.AI cs.CV","http://creativecommons.org/licenses/by/4.0/","  We present a neuro-symbolic visual question answering (VQA) pipeline for
CLEVR, which is a well-known dataset that consists of pictures showing scenes
with objects and questions related to them. Our pipeline covers (i) training
neural networks for object classification and bounding-box prediction of the
CLEVR scenes, (ii) statistical analysis on the distribution of prediction
values of the neural networks to determine a threshold for high-confidence
predictions, and (iii) a translation of CLEVR questions and network predictions
that pass confidence thresholds into logic programs so that we can compute the
answers using an ASP solver. By exploiting choice rules, we consider
deterministic and non-deterministic scene encodings. Our experiments show that
the non-deterministic scene encoding achieves good results even if the neural
networks are trained rather poorly in comparison with the deterministic
approach. This is important for building robust VQA systems if network
predictions are less-than perfect. Furthermore, we show that restricting
non-determinism to reasonable choices allows for more efficient implementations
in comparison with related neuro-symbolic approaches without loosing much
accuracy. This work is under consideration for acceptance in TPLP.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:50:37 GMT""}]","2022-05-17"
"2205.07549","Andreas Michels","Michael P. Adams, Andreas Michels, Hamid Kachkachi","Magnetic neutron scattering from spherical nanoparticles with Neel
  surface anisotropy: Analytical treatment",,,,,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The magnetization profile and the related magnetic small-angle neutron
scattering cross section of a single spherical nanoparticle with Neel surface
anisotropy is analytically investigated. We employ a Hamiltonian that comprises
the isotropic exchange interaction, an external magnetic field, a uniaxial
magnetocrystalline anisotropy in the core of the particle, and the Neel
anisotropy at the surface. Using a perturbation approach, the determination of
the magnetization profile can be reduced to a Helmholtz equation with Neumann
boundary condition, whose solution is represented by an infinite series in
terms of spherical harmonics and spherical Bessel functions. From the resulting
infinite series expansion, we analytically calculate the Fourier transform,
which is algebraically related to the magnetic small-angle neutron scattering
cross section. The approximate analytical solution is compared to the numerical
solution using the Landau-Lifshitz equation, which accounts for the full
nonlinearity of the problem.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:51:47 GMT""}]","2022-05-17"
"2205.07550","Niclas Boehmer","Matthias Bentert, Niclas Boehmer, Klaus Heeger, Tomohiro Koana","Stable Matching with Multilayer Approval Preferences: Approvals can be
  Harder than Strict Preferences",,,,,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study stable matching problems where agents have multilayer preferences:
There are $\ell$ layers each consisting of one preference relation for each
agent. Recently, Chen et al. [EC '18] studied such problems with strict
preferences, establishing four multilayer adaptions of classical notions of
stability. We follow up on their work by analyzing the computational complexity
of stable matching problems with multilayer approval preferences. We consider
eleven stability notions derived from three well-established stability notions
for stable matchings with ties and the four adaptions proposed by Chen et al.
For each stability notion, we show that the problem of finding a stable
matching is either polynomial-time solvable or NP-hard. Furthermore, we examine
the influence of the number of layers and the desired ""degree of stability"" on
the problems' complexity. Somewhat surprisingly, we discover that assuming
approval preferences instead of strict preferences does not considerably
simplify the situation (and sometimes even makes polynomial-time solvable
problems NP-hard).
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:52:24 GMT""}]","2022-05-17"
"2205.07551","Nicolas Cherroret","Thibault Scoquart, Dominique Delande and Nicolas Cherroret","Dynamical emergence of a Kosterlitz-Thouless transition in a disordered
  Bose gas following a quench","10 pages including a supplemental material",,"10.1103/PhysRevA.106.L021301",,"cond-mat.quant-gas quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the dynamical evolution of a two-dimensional Bose gas after a
disorder potential quench. Depending on the initial conditions, the system
evolves either to a thermal or a superfluid state. Using extensive quasi-exact
numerical simulations, we show that the two phases are separated by a
Kosterlitz-Thouless transition. The thermalization time is shown to be longer
in the superfluid phase, but no critical slowing down is observed at the
transition. The long-time phase diagram is well reproduced by a simple
theoretical model. The spontaneous emergence of Kosterlitz-Thouless transitions
following a quench is a generic phenomenon that should arise both in the
context of non-equilibrium quantum gases and nonlinear, classical wave systems.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:58:46 GMT""}]","2022-08-31"
"2205.07552","Andreas Michels","Michael P. Adams, Andreas Michels, Hamid Kachkachi","Magnetic neutron scattering from spherical nanoparticles with Neel
  surface anisotropy: Atomistic simulations",,,,,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  We consider a dilute ensemble of randomly-oriented noninteracting spherical
nanomagnets and investigate its magnetization structure and ensuing
neutron-scattering response by numerically solving the Landau-Lifshitz
equation. Taking into account the isotropic exchange interaction, an external
magnetic field, a uniaxial magnetic anisotropy for the particle core, and in
particular the Neel surface anisotropy, we compute the magnetic small-angle
neutron scattering cross section and pair-distance distribution function from
the obtained equilibrium spin structures. The numerical results are compared to
the well-known analytical expressions for uniformly magnetized particles and
provide guidance to the experimentalist. Moreover, the effect of a
particle-size distribution function is modeled.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:59:15 GMT""}]","2022-05-17"
"2205.07553","Anabelle Wong","Anabelle Wong, Laura Barrero, Elizabeth Goult, Michael Briga, Sarah C.
  Kramer, Aleksandra Kovacevic, Lulla Opatowski, Matthieu Domenech de Cell\`es","The interactions of SARS-CoV-2 with co-circulating pathogens:
  Epidemiological implications and current knowledge gaps","Main text 35 pages including 5 figures. Appendices 1-5 (Table S1-S4,
  Model details). Reason for changes: Revision 1, updated literature search (as
  of 22 Aug 2022)",,,,"q-bio.PE","http://creativecommons.org/licenses/by/4.0/","  Despite the availability of effective vaccines, the persistence of SARS-CoV-2
suggests that co-circulation with other pathogens and resulting multi-epidemics
may become increasingly frequent. To better forecast and control the risk of
such multi-epidemics, it is essential to elucidate the potential interactions
of SARS-CoV-2 with other pathogens; these interactions, however, remain poorly
defined. Here, we aimed to review the current body of evidence about SARS-CoV-2
interactions. To study pathogen interactions in a systematic way, we first
developed a general framework to capture their major components: sign,
strength, symmetry, duration, and mechanism. We then reviewed the experimental
evidence from animal models about SARS-CoV-2 interactions. Of the 14 studies
identified, 11 focused on the outcomes of co-infection with non-attenuated
influenza A viruses and generally demonstrated that co-infection increased
disease severity compared with either mono-infection. By contrast, the effect
of co-infection on the viral load of either virus was variable and inconsistent
across studies. Next, we reviewed the epidemiological evidence about SARS-CoV-2
interactions in human populations. Although numerous studies were identified,
only few were specifically designed to infer interaction and many were prone to
multiple biases, including confounding. Nevertheless, their results suggested
that influenza and pneumococcal conjugate vaccinations were associated with
reduced riskof SARS-CoV-2 infection. Finally, we formulated simple transmission
models of SARS-CoV-2 co-circulation with a viral or a bacterial pathogen,
showing how they can naturally incorporate the proposed framework. More
generally, we argue that such models, when designed with an integrative and
multidisciplinary perspective, will be invaluable tools to resolve the
substantial uncertainties that remain about SARS-CoV-2 interactions.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 10:00:53 GMT""},{""version"":""v2"",""created"":""Wed, 16 Nov 2022 23:08:02 GMT""}]","2022-11-18"
"2205.07554","Jalo Nousiainen","J. Nousiainen, C. Rajani, M. Kasper, T. Helin, S. Y. Haffert, C.
  V\'erinaud, J. R. Males, K. Van Gorkom, L. M. Close, J. D. Long, A. D.
  Hedglen, O. Guyon, L. Schatz, M. Kautz, J. Lumbres, A. Rodack, J.M. Knight,
  K. Miller","Towards on-sky adaptive optics control using reinforcement learning",,"A&A 664, A71 (2022)","10.1051/0004-6361/202243311",,"astro-ph.IM cs.LG cs.RO cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  The direct imaging of potentially habitable Exoplanets is one prime science
case for the next generation of high contrast imaging instruments on
ground-based extremely large telescopes. To reach this demanding science goal,
the instruments are equipped with eXtreme Adaptive Optics (XAO) systems which
will control thousands of actuators at a framerate of kilohertz to several
kilohertz. Most of the habitable exoplanets are located at small angular
separations from their host stars, where the current XAO systems' control laws
leave strong residuals.Current AO control strategies like static matrix-based
wavefront reconstruction and integrator control suffer from temporal delay
error and are sensitive to mis-registration, i.e., to dynamic variations of the
control system geometry. We aim to produce control methods that cope with these
limitations, provide a significantly improved AO correction and, therefore,
reduce the residual flux in the coronagraphic point spread function.
  We extend previous work in Reinforcement Learning for AO. The improved
method, called PO4AO, learns a dynamics model and optimizes a control neural
network, called a policy. We introduce the method and study it through
numerical simulations of XAO with Pyramid wavefront sensing for the 8-m and
40-m telescope aperture cases. We further implemented PO4AO and carried out
experiments in a laboratory environment using MagAO-X at the Steward
laboratory. PO4AO provides the desired performance by improving the
coronagraphic contrast in numerical simulations by factors 3-5 within the
control region of DM and Pyramid WFS, in simulation and in the laboratory. The
presented method is also quick to train, i.e., on timescales of typically 5-10
seconds, and the inference time is sufficiently small (< ms) to be used in
real-time control for XAO with currently available hardware even for extremely
large telescopes.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 10:01:06 GMT""}]","2022-08-26"
"2205.07555","Liwei Wu","Liwei Wu, Dan Huang, Qipeng Ma, Zhiyuan Li, Xuehao Yao","Peridynamic modeling for impact failure of wet concrete considering the
  influence of saturation",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, a modified intermediately homogenized peridynamic (IH-PD)
model for analyzing impact failure of wet concrete has been presented under the
configuration of ordinary state-based peridynamic theory. The meso-structural
properties of concrete are linked to the macroscopic mechanical behavior in the
IH-PD model, where the heterogeneity of concrete is taken into account, and the
calculation cost does not increase. Simultaneously, the porosity of concrete is
considered, which is implemented by deleting the bond between two material
points, as well as the influence of porosity on the mechanical properties of
concrete. Moreover, the effective bulk and shear modulus of cement mortar in
wet concrete (saturated and unsaturated concrete) are calculated respectively.
The dynamic model for wet concrete is described from three aspects: strength,
dynamic increase factor, and equation of state. Validation of the proposed
model is established through analyzing some benchmark tests and comparing with
the corresponding experiment and other available numerical results.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 10:01:09 GMT""},{""version"":""v2"",""created"":""Wed, 18 May 2022 13:51:58 GMT""}]","2022-05-19"
"2205.07556","Yehui Yang","Fangxin Shang, Siqi Wang, Xiaorong Wang, Yehui Yang","An Effective Transformer-based Solution for RSNA Intracranial Hemorrhage
  Detection Competition",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an effective method for Intracranial Hemorrhage Detection (IHD)
which exceeds the performance of the winner solution in RSNA-IHD competition
(2019). Meanwhile, our model only takes quarter parameters and ten percent
FLOPs compared to the winner's solution. The IHD task needs to predict the
hemorrhage category of each slice for the input brain CT. We review the top-5
solutions for the IHD competition held by the Radiological Society of North
America(RSNA) in 2019. Nearly all the top solutions rely on 2D convolutional
networks and sequential models (Bidirectional GRU or LSTM) to extract
intra-slice and inter-slice features, respectively. All the top solutions
enhance the performance by leveraging the model ensemble, and the model number
varies from 7 to 31. In the past years, since much progress has been made in
the computer vision regime especially Transformer-based models, we introduce
the Transformer-based techniques to extract the features in both intra-slice
and inter-slice views for IHD tasks. Additionally, a semi-supervised method is
embedded into our workflow to further improve the performance. The code is
available in the manuscript.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 10:05:39 GMT""},{""version"":""v2"",""created"":""Tue, 17 May 2022 07:53:30 GMT""},{""version"":""v3"",""created"":""Tue, 7 Jun 2022 03:54:32 GMT""}]","2022-06-08"
"2205.07557","Dominik Stammbach","Dominik Stammbach, Maria Antoniak, Elliott Ash","Heroes, Villains, and Victims, and GPT-3: Automated Extraction of
  Character Roles Without Training Data",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  This paper shows how to use large-scale pre-trained language models to
extract character roles from narrative texts without training data. Queried
with a zero-shot question-answering prompt, GPT-3 can identify the hero,
villain, and victim in diverse domains: newspaper articles, movie plot
summaries, and political speeches.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 10:08:11 GMT""},{""version"":""v2"",""created"":""Tue, 17 May 2022 08:09:51 GMT""}]","2022-05-18"
"2205.07558","Martin Blaschke","Martin Blaschke, Zden\v{e}k Stuchl\'ik, Sudipta Hensh","Evolution of Braneworld Kerr-Newman Naked Singularities","14 pages,14 figures","Phys. Rev. D 105, 084069, 29 April 2022","10.1103/PhysRevD.105.084069",,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  We study evolution of the braneworld Kerr--Newman (K-N) naked singularities,
namely their mass $M$ , spin $a$, and tidal charge $b$ characterizing the role
of the bulk space, due to matter in-falling from Keplerian accretion disk. We
construct the evolution in two limiting cases applied to the tidal charge. In
the first case we assume $b$ = const during the evolution, in the second one we
assume that the dimensionless tidal charge $\beta \equiv b/M^2$ = const. For
positive values of the tidal charge the evolution is equivalent to the case of
the standard K-N naked singularity under accretion of electrically neutral
matter. We demonstrate that counter-rotating accretion always converts a K-N
naked singularity into an extreme K-N black hole and that the corotating
accretion leads to variety of outcomes. The conversion to an extreme K-N black
hole is possible for naked singularity with dimensionless tidal charge $\beta <
0.25$, and $\beta \in (0.25, 1)$ with sufficiently low spin. In other cases the
accretion ends in a transcendental state. For $0.25 < \beta < 1$ this is a
mining unstable K-N naked singularity enabling formally unlimited energy
extraction from the naked singularity. In the case of $\beta > 1$, the
corotating accretion creates unlimited torodial structure of mater orbiting the
naked singularity. Both non-standard outcomes of the corotating accretion imply
a transcendence of such naked singularity due to nonlinear gravitational
effects.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 10:08:37 GMT""}]","2022-05-17"
"2205.07559","Daisuke Sato","Dye SK Sato, Yukitoshi Fukahata and Yohei Nozue","Appropriate reduction of the posterior distribution in fully Bayesian
  inversions","70 pages, 10 figures",,"10.1093/gji/ggac231",,"physics.geo-ph math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bayesian inversion generates a posterior distribution of model parameters
from an observation equation and prior information both weighted by
hyperparameters. The prior is also introduced for the hyperparameters in fully
Bayesian inversions and enables us to evaluate both the model parameters and
hyperparameters probabilistically by the joint posterior. However, even in a
linear inverse problem, it is unsolved how we should extract useful information
on the model parameters from the joint posterior. This study presents a
theoretical exploration into the appropriate dimensionality reduction of the
joint posterior in the fully Bayesian inversion. We classify the ways of
probability reduction into the following three categories focused on the
marginalisation of the joint posterior: (1) using the joint posterior without
marginalisation, (2) using the marginal posterior of the model parameters and
(3) using the marginal posterior of the hyperparameters. First, we derive
several analytical results that characterise these categories. One is a suite
of semianalytic representations of the probability maximisation estimators for
respective categories in the linear inverse problem. The mode estimators of
categories (1) and (2) are found asymptotically identical for a large number of
data and model parameters. We also prove the asymptotic distributions of
categories (2) and (3) delta-functionally concentrate on their probability
peaks, which predicts two distinct optimal estimates of the model parameters.
Second, we conduct a synthetic test and find an appropriate reduction is
realised by category (3), typified by Akaike's Bayesian information criterion
(ABIC). The other reduction categories are shown inappropriate for the case of
many model parameters, where the probability concentration of the marginal
posterior of the model parameters is found no longer to mean the central limit
theorem...
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 10:14:47 GMT""}]","2022-07-20"
"2205.07560","Leonardo Scandurra","Leonardo Scandurra","Ensemble Kalman Inversion method for an inverse problem in
  soil-structure interaction",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The interaction between the foundation structures and the soil has been
developed for many engineering applications. For the determination of the
stress in foundation structure it is needed to determine the influence of the
stiffness of soil with respect to the displacement w of the deformable plate
(direct problem), and viceversa, how the stiffness of the foundation structure
affects the resulting subsidence (inverse problem). In this paper, we deal with
the Winkler mathematical model and propose to use an efficient Ensemble Kalman
Inversion scheme (EKI) that regularizes iteratively the ill-posedness of the
inverse problem. It is a regularizing optimizer used in Bayesian inverse
problems that samples particles in pseudo-time introducing a motion due to the
movement of these particles. The EKI algorithm converges to the solution of an
optimization problem that minimizes the objective function. In this context we
show how to reconstruct the Winkler subgrade reaction coefficient of a
rectangular thin plate loaded with an existing building by using the EKI
methodology combined by the finite difference method (FDM) to discretize the
biharmonic operator of the governing equations.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 10:16:45 GMT""}]","2022-05-17"
"2205.07561","Kotub Uddin","Kotub Uddin, James Schofield and W. Dhammika Widanage","State of Health Estimation of Lithium-Ion Batteries in Vehicle-to-Grid
  Applications Using Recurrent Neural Networks for Learning the Impact of
  Degradation Stress Factors","5 pages, 3 figures",,,,"eess.SY cs.SY","http://creativecommons.org/publicdomain/zero/1.0/","  This work presents an effective state of health indicator to indicate
lithium-ion battery degradation based on a long short-term memory (LSTM)
recurrent neural network (RNN) coupled with a sliding-window. The developed
LSTM RNN is able to capture the underlying long-term dependencies of degraded
cell capacity on battery degradation stress factors. The learning performance
was robust when there was sufficient training data, with an error of < 5% if
more than 1.15 years worth of data was supplied for training.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 10:36:39 GMT""}]","2022-05-17"
"2205.07562","Vieri Giuliano Santucci","Alejandro Romero, Gianluca Baldassarre, Richard J. Duro, Vieri
  Giuliano Santucci","Autonomous Open-Ended Learning of Tasks with Non-Stationary
  Interdependencies","Submitted and accepted to ""The Multi-disciplinary Conference on
  Reinforcement Learning and Decision Making"" RLDM 2022",,,,"cs.LG cs.AI cs.RO","http://creativecommons.org/licenses/by/4.0/","  Autonomous open-ended learning is a relevant approach in machine learning and
robotics, allowing the design of artificial agents able to acquire goals and
motor skills without the necessity of user assigned tasks. A crucial issue for
this approach is to develop strategies to ensure that agents can maximise their
competence on as many tasks as possible in the shortest possible time.
Intrinsic motivations have proven to generate a task-agnostic signal to
properly allocate the training time amongst goals. While the majority of works
in the field of intrinsically motivated open-ended learning focus on scenarios
where goals are independent from each other, only few of them studied the
autonomous acquisition of interdependent tasks, and even fewer tackled
scenarios where goals involve non-stationary interdependencies. Building on
previous works, we tackle these crucial issues at the level of decision making
(i.e., building strategies to properly select between goals), and we propose a
hierarchical architecture that treating sub-tasks selection as a Markov
Decision Process is able to properly learn interdependent skills on the basis
of intrinsically generated motivations. In particular, we first deepen the
analysis of a previous system, showing the importance of incorporating
information about the relationships between tasks at a higher level of the
architecture (that of goal selection). Then we introduce H-GRAIL, a new system
that extends the previous one by adding a new learning layer to store the
autonomously acquired sequences of tasks to be able to modify them in case the
interdependencies are non-stationary. All systems are tested in a real robotic
scenario, with a Baxter robot performing multiple interdependent reaching
tasks.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 10:43:01 GMT""}]","2022-05-17"
"2205.07563","Aleksejus Kononovicius dr.","Aleksejus Kononovicius, Rytis Kazakevi\v{c}ius, Bronislovas Kaulakys","Resemblance of the power-law scaling behavior of a non-Markovian and
  nonlinear point processes","10 pages, 4 figures",,"10.1016/j.chaos.2022.112508",,"cond-mat.stat-mech physics.soc-ph q-fin.ST","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze the statistical properties of a temporal point process driven by a
confined fractional Brownian motion. The event count distribution and power
spectral density of this non--Markovian point process exhibit power--law
scaling. We show that a nonlinear Markovian point process can reproduce the
same scaling behavior. This result indicates a possible link between
nonlinearity and apparent non--Markovian behavior.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 10:45:53 GMT""},{""version"":""v2"",""created"":""Fri, 22 Jul 2022 10:42:20 GMT""}]","2022-08-31"
"2205.07564","Julio Bernues","Miguel Angel Crespo and Julio Bernu\'es","El Logaritmo Integral: N\'umeros primos y algo m\'as","in Spanish language",,,,"math.HO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show the relevance of the logarithmic integral function in the development
of mathematics in the first half of the 19th century. Its importance involved
first level mathematicians such as Euler, Gauss, Bessel, Riemann. Our
perspective is the result of a detailed study of the original sources. We
manage to establish the timeline of how the advances took place. In particular,
our study vindicates the contributions of Bessel (in collaboration with Gauss).
The logarithmic integral in Gauss's mind played a fundamental role in several
fields such as complex analysis (Cauchy's theorem), numerical methods (Gaussian
quadrature) as well as its best known relation with the distribution of prime
numbers. We study this last aspect in detail starting from the works by
Legendre and Tchebycheff up to Riemann.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 10:46:16 GMT""}]","2022-05-17"
"2205.07565","Jingwen Zhu","Jingwen Zhu, Suiyi Ling, Yoann Baveye, Patrick Le Callet","A Framework to Map VMAF with the Probability of Just Noticeable
  Difference between Video Encoding Recipes",,,,,"eess.IV","http://creativecommons.org/licenses/by/4.0/","  Just Noticeable Difference (JND) model developed based on Human Vision System
(HVS) through subjective studies is valuable for many multimedia use cases. In
the streaming industries, it is commonly applied to reach a good balance
between compression efficiency and perceptual quality when selecting video
encoding recipes. Nevertheless, recent state-of-the-art deep learning based JND
prediction model relies on large-scale JND ground truth that is expensive and
time consuming to collect. Most of the existing JND datasets contain limited
number of contents and are limited to a certain codec (e.g., H264). As a
result, JND prediction models that were trained on such datasets are normally
not agnostic to the codecs. To this end, in order to decouple encoding recipes
and JND estimation, we propose a novel framework to map the difference of
objective Video Quality Assessment (VQA) scores, i.e., VMAF, between two given
videos encoded with different encoding recipes from the same content to the
probability of having just noticeable difference between them. The proposed
probability mapping model learns from DCR test data, which is significantly
cheaper compared to standard JND subjective test. As we utilize objective VQA
metric (e.g., VMAF that trained with contents encoded with different codecs) as
proxy to estimate JND, our model is agnostic to codecs and computationally
efficient. Throughout extensive experiments, it is demonstrated that the
proposed model is able to estimate JND values efficiently.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 10:48:03 GMT""},{""version"":""v2"",""created"":""Fri, 20 May 2022 12:18:42 GMT""}]","2022-05-23"
"2205.07566","Yan Zhang","Chuanxun Du, Gang Wang, Yan Zhang, and Jin-Hui Wu","Light transfer transitions beyond higher-order exceptional points in
  parity-time and anti-parity-time symmetric waveguide arrays",,"Opt. Express 30, 20088-20099 (2022)","10.1364/OE.457299",,"physics.optics quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose two non-Hermitian arrays consisting of $N=2l+1$ waveguides and
exhibiting parity-time ($\mathcal{PT}$) or anti-$\mathcal{PT}$ symmetry for
investigating light transfer dynamics based on $N$th-order exceptional points
(EPs). The $\mathcal{PT}$-symmetric array supports two $N$th-order EPs
separating an unbroken and a broken phase with real and imaginary eignvalues,
respectively. Light transfer dynamics in this array exhibits radically
different behaviors, i.e. a unidirectional oscillation behavior in the unbroken
phase, an edge-towards localization behavior in the broken phase, and a
center-towards localization behavior just at $N$th-order EPs. The
anti-$\mathcal{PT}$-symmetric array supports also two $N$th-order EPs
separating an unbroken and a broken phase, which refer however to imaginary and
real eigenvalues, respectively. Accordingly, light transfer dynamics in this
array exhibits a center-towards localization behavior in the unbroken phase and
an origin-centered oscillation behavior in the broken phase. These nontrivial
light transfer behaviors and their controlled transitions are not viable for
otherwise split lower-order EPs and depend on the underlying $SU(2)$ symmetry
of spin-$l$ matrices.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 10:51:38 GMT""}]","2022-05-23"
"2205.07567","Qiqi Dai","Qiqi Dai, Yee Hui Lee, Hai-Han Sun, Genevieve Ow, Mohamed Lokman Mohd
  Yusof, and Abdulkadir C. Yucel","DMRF-UNet: A Two-Stage Deep Learning Scheme for GPR Data Inversion under
  Heterogeneous Soil Conditions",,,"10.1109/TAP.2022.3176386",,"eess.SP eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Traditional ground-penetrating radar (GPR) data inversion leverages iterative
algorithms which suffer from high computation costs and low accuracy when
applied to complex subsurface scenarios. Existing deep learning-based methods
focus on the ideal homogeneous subsurface environments and ignore the
interference due to clutters and noise in real-world heterogeneous
environments. To address these issues, a two-stage deep neural network (DNN),
called DMRF-UNet, is proposed to reconstruct the permittivity distributions of
subsurface objects from GPR B-scans under heterogeneous soil conditions. In the
first stage, a U-shape DNN with multi-receptive-field convolutions (MRF-UNet1)
is built to remove the clutters due to inhomogeneity of the heterogeneous soil.
Then the denoised B-scan from the MRF-UNet1 is combined with the noisy B-scan
to be inputted to the DNN in the second stage (MRF-UNet2). The MRF-UNet2 learns
the inverse mapping relationship and reconstructs the permittivity distribution
of subsurface objects. To avoid information loss, an end-to-end training method
combining the loss functions of two stages is introduced. A wide range of
subsurface heterogeneous scenarios and B-scans are generated to evaluate the
inversion performance. The test results in the numerical experiment and the
real measurement show that the proposed network reconstructs the
permittivities, shapes, sizes, and locations of subsurface objects with high
accuracy. The comparison with existing methods demonstrates the superiority of
the proposed methodology for the inversion under heterogeneous soil conditions.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 10:54:17 GMT""}]","2022-09-21"
"2205.07568","Thomas Wendler","Bailiang Jian, Mohammad Farid Azampour, Francesca De Benetti, Johannes
  Oberreuter, Christina Bukas, Alexandra S. Gersing, Sarah C. Foreman,
  Anna-Sophia Dietrich, Jon Rischewski, Jan S. Kirschke, Nassir Navab, Thomas
  Wendler","Weakly-supervised Biomechanically-constrained CT/MRI Registration of the
  Spine","10 pages, 3 figures",,,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  CT and MRI are two of the most informative modalities in spinal diagnostics
and treatment planning. CT is useful when analysing bony structures, while MRI
gives information about the soft tissue. Thus, fusing the information of both
modalities can be very beneficial. Registration is the first step for this
fusion. While the soft tissues around the vertebra are deformable, each
vertebral body is constrained to move rigidly. We propose a weakly-supervised
deep learning framework that preserves the rigidity and the volume of each
vertebra while maximizing the accuracy of the registration. To achieve this
goal, we introduce anatomy-aware losses for training the network. We
specifically design these losses to depend only on the CT label maps since
automatic vertebra segmentation in CT gives more accurate results contrary to
MRI. We evaluate our method on an in-house dataset of 167 patients. Our results
show that adding the anatomy-aware losses increases the plausibility of the
inferred transformation while keeping the accuracy untouched.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 10:59:55 GMT""}]","2022-05-17"
"2205.07569","Zhang Jianlu","Jianlu Zhang","Limit of solutions for semilinear Hamilton-Jacobi equations with
  degenerate viscosity",,,,,"math.AP math.DS math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the paper we prove the convergence of viscosity solutions $u_{\lambda}$ as
$\lambda\rightarrow0_+$ for the parametrized degenerate viscous Hamilton-Jacobi
equation \[ H(x,d_x u, \lambda u)=\alpha(x)\Delta u,\quad \alpha(x)\geq 0,\quad
x\in \mathbb T^n \] under suitable convex and monotonic conditions on $H:
T^*M\times\mathbb R\rightarrow\mathbb R$. Such a limit can be characterized in
terms of stochastic Mather measures associated with the critical equation \[
H(x,d_x u,0)=\alpha(x)\Delta u. \]
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:00:00 GMT""}]","2022-05-17"
"2205.07570","Benjamin Ward","Demi Allen, Benjamin Ward","Weighted approximation in higher-dimensional missing digit sets","19 pages",,,,"math.NT math.DS math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note, we use the mass transference principle for rectangles, recently
obtained by Wang and Wu (Math. Ann., 2021), to study the Hausdorff dimension of
sets of ""weighted $\Psi$-well-approximable"" points in certain self-similar sets
in $\mathbb{R}^{d}$. Specifically, we investigate weighted
$\Psi$-well-approximable points in ""missing digit"" sets in $\mathbb{R}^{d}$.
The sets we consider are natural generalisations of Cantor-type sets in
$\mathbb{R}$ to higher dimensions and include, for example, four corner Cantor
sets (or Cantor dust) in the plane with contraction ratio $\frac{1}{n}$ with $n
\in \mathbb{N}$.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:01:59 GMT""}]","2022-05-17"
"2205.07571","Janko Marovt","Janko Marovt, Dijana Mosi\'c, Insa Cremer","On some generalized inverses and partial orders in $\ast$-rings","The paper is in review. It was submitted for publication on February
  3, 2022",,,,"math.FA math.RA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Let $\mathcal{R}$ be a unital ring with involution. The notions of
1MP-inverse and MP1-inverse are extended from $M_{m,n}(\mathbb{C)}$, the set of
all $m\times n $ matrices over $\mathbb{C}$, to the set $\mathcal{R}%
^{\dagger}$ of all Moore-Penrose invertible elements in $\mathcal{R}$. We study
partial orders on $\mathcal{R}^{\dagger}$ that are induced by 1MP-inverses and
MP1-inverses. We also extend to the setting of Rickart $\ast $-rings the
concept of another partial order, called the plus order, which has been
recently introduced on the set of all bounded linear operators between Hilbert
spaces. Properties of these relations are investigated and some known results
are thus generalized.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:06:51 GMT""}]","2022-05-17"
"2205.07572","Donna Calhoun","Donna Calhoun and Erik Chudzik and Christiane Helzel","The Cartesian Grid Active Flux Method with Adaptive Mesh Refinement",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  We present the first implementation of the Active Flux method on adaptively
refined Cartesian grids. The Active Flux method is a third order accurate
finite volume method for hyperbolic conservation laws, which is based on the
use of point values as well as cell average values of the conserved quantities.
The resulting method has a compact stencil in space and time and good stability
properties.
  The method is implemented as a new solver in ForestClaw, a software for
parallel adaptive mesh refinement of patch-based solvers. On each Cartesian
grid patch the single grid Active Flux method can be applied. The exchange of
data between grid patches is organised via ghost cells. The local stencil in
space and time and the availability of the point values that are used for the
reconstruction, leads to an efficient implementation. The resulting method is
third order accurate, conservative and allows the use of subcycling in time.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:07:41 GMT""},{""version"":""v2"",""created"":""Tue, 7 Jun 2022 11:44:39 GMT""}]","2022-06-08"
"2205.07573","Sean Eberhard","Sean Eberhard and Daniele Garzoni","Probability of generation by random permutations of given cycle type","4 pages",,,,"math.GR math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Suppose $\pi$ and $\pi'$ are two random elements of $S_n$ with constrained
cycle types such that $\pi$ has $x n^{1/2}$ fixed points and $yn/2$ two-cycles,
and likewise $\pi'$ has $x' n^{1/2}$ fixed points and $y'n/2$ two-cycles. We
show that the events that $G = \langle \pi, \pi' \rangle$ is transitive and $G
\geq A_n$ both have probability approximately \[(1 - yy')^{1/2} \exp\left(-
\frac{xx' + \frac12 x^2 y' + \frac12 {x'}^2 y}{1 - yy'}\right),\] provided $(x,
x')$ is not close to $(0, \infty)$ or $(\infty, 0)$. This formula is derived
from some preliminary results in a recent paper (arXiv:1904.12180) of the
authors. As an application, we show that two uniformly random elements of
uniformly random conjugacy classes of $S_n$ generate the group with probability
about 51%.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:08:18 GMT""}]","2022-05-17"
"2205.07574","Jiajun Liao","Zikang Chen, Jiajun Liao, Jiajie Ling, Baobiao Yue","Constraining super-light sterile neutrinos at Borexino and KamLAND","34 pages, 8 figures. Version published in JHEP","JHEP09(2022)004","10.1007/JHEP09(2022)004",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  The presence of a super-light sterile neutrino can lead to a dip in the
survival probability of solar neutrinos, and explain the suppression of the
upturn in the low energy solar neutrino data. In this work, we systematically
study the survival probabilities in the 3+1 framework by taking into account of
the non-adiabatic transitions and the coherence effect. We obtain an analytic
equation that can predict the position of the dip. We also place constraints on
the parameter space of sterile neutrinos by using the latest Borexino and
KamLAND data. We find that the low and high energy neutrino data at Borexino
are sensitive to different regions in the sterile neutrino parameter space. In
the case with only $\theta_{01}$ being nonzero, the $\rm{{}^{8}B}$ data sets
the strongest bounds at $\Delta m_{01}^{2} \approx (1.1\sim2.2)\Delta
m_{21}^{2}$, while the low energy neutrino data is more sensitive to other
mass-squared regions. The lowest bounds on $\Delta m_{01}^{2}$ from the
$\rm{pp}$ data can reach $10^{-12} \ \rm{eV^{2}}$ because of the coherence
effect. Also, due to the presence of non-adiabatic transitions, the bounds in
the range of $10^{-9} \ \textrm{eV}^{2} \lesssim \Delta m_{01}^{2} \lesssim
10^{-5} \ \textrm{eV}^{2}$ become weaker as $\Delta m_{01}^{2}$ or
$\sin^{2}2\theta_{01}$ decreases. We also find that in the case with only
$\theta_{02}$ or $\theta_{03}$ being nonzero, the low energy solar neutrino
data set similar but weaker bounds as compared to the case with only
$\theta_{01}$ being nonzero. However, the bounds from the high energy solar
data and the KamLAND data are largely affected by the sterile mixing angles.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:12:27 GMT""},{""version"":""v2"",""created"":""Mon, 13 Jun 2022 13:04:43 GMT""},{""version"":""v3"",""created"":""Fri, 2 Sep 2022 08:42:32 GMT""}]","2022-09-05"
"2205.07575","Andrea Urru","Urru, Andrea and Nakaki, Ayako and Benkarim, Oualid and Crovetto,
  Francesca and Segales, Laura and Comte, Valentin and Hahner, Nadine and
  Eixarch, Elisenda and Gratac\'os, Eduard and Crispi, F\`atima and Piella,
  Gemma and Gonz\'alez Ballester, Miguel A","An automatic pipeline for atlas-based fetal and neonatal brain
  segmentation and analysis",,,,,"cs.CV q-bio.QM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The automatic segmentation of perinatal brain structures in magnetic
resonance imaging (MRI) is of utmost importance for the study of brain growth
and related complications. While different methods exist for adult and
pediatric MRI data, there is a lack for automatic tools for the analysis of
perinatal imaging. In this work, a new pipeline for fetal and neonatal
segmentation has been developed. We also report the creation of two new fetal
atlases, and their use within the pipeline for atlas-based segmentation, based
on novel registration methods. The pipeline is also able to extract cortical
and pial surfaces and compute features, such as curvature, thickness, sulcal
depth, and local gyrification index. Results show that the introduction of the
new templates together with our segmentation strategy leads to accurate results
when compared to expert annotations, as well as better performances when
compared to a reference pipeline (developing Human Connectome Project (dHCP)),
for both early and late-onset fetal brains.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:15:26 GMT""}]","2022-05-17"
"2205.07576","Ville Laitinen","Ville Laitinen, Leo Lahti","Probabilistic multivariate early warning signals","16 pages, 3 figures, submitted to 20th International Conference on
  Computational Methods in Systems Biology (CMSB 2022)",,,,"stat.AP nlin.AO","http://creativecommons.org/licenses/by/4.0/","  A broad range of natural and social systems from human microbiome to
financial markets can go through critical transitions, where the system
suddenly collapses to another stable configuration. Critical transitions can be
unexpected, with potentially catastrophic consequences. Anticipating them early
and accurately can facilitate controlled system manipulation and mitigation of
undesired outcomes. Obtaining reliable predictions have been difficult,
however, as often only a small fraction of the relevant variables can be
monitored, and even minor perturbations can induce drastic changes in fragile
states of a complex system. Data-driven indicators have been proposed as an
alternative to prediction and signal an increasing risk of forthcoming
transitions. Autocorrelation and variance are examples of generic indicators
that tend to increase at the vicinity of an approaching tipping point across a
range of systems. An important shortcoming in these and other widely studied
indicators is that they deal with simplified one-dimensional representations of
complex systems. Here, we demonstrate that a probabilistic data aggregation
strategy can provide new ways to improve early warning detection by more
efficiently utilizing the available information from multivariate time series.
In particular, we consider a probabilistic variant of a vector autoregression
model as a novel early warning indicator and argue that it has theoretical
advantages related to model regularization, treatment of uncertainties, and
parameter interpretation. We evaluate the performance against alternatives in a
simulation benchmark and show improved sensitivity in EWS detection in a common
ecological model encompassing multiple interacting species.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:17:49 GMT""}]","2022-05-17"
"2205.07577","Pantelis Pnigouras","Pantelis Pnigouras, Fabian Gittins, Amlan Nanda, Nils Andersson, David
  Ian Jones","Rotating Love: The dynamical tides of spinning Newtonian stars","23 pages, 1 figure",,,,"gr-qc astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop the framework required to model the dynamical tidal response of a
spinning neutron star in an inspiralling binary system, in the context of
Newtonian gravity. The tidal perturbation is decomposed in terms of the normal
oscillation modes, used to derive an expression for the effective Love number
which is valid for any rotation rate. Our analysis highlights subtle issues
relating to the orthogonality condition required for the mode-sum
representation of the dynamical tide and shows how the prograde and retrograde
modes combine to provide the overall tidal response. Utilising a slow-rotation
expansion, we show that the dynamical tide (effective Love number) is corrected
at first order in rotation, whereas in the case of the static tide (static Love
number) the rotational corrections do not enter until second order.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:19:44 GMT""}]","2022-05-17"
"2205.07578","Howard E. Haber","Howard E. Haber","A natural mechanism for a SM-like Higgs boson in the 2HDM without
  decoupling","15 pages, 2 figures, 5 tables, contribution to the Proceedings of
  DISCRETE 2020-2021; version 2 updates several references",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The properties of the Higgs boson discovered at the Large Hadron Collider are
very well described by the Standard Model (SM). Thus, any theory that invokes
an extended Higgs sector must explain why the neutral scalar observed at the
LHC so closely resembles the SM Higgs boson. In this talk, I review the Higgs
alignment limit, in which one neutral scalar state of the Higgs sector is
SM-like. An approximate Higgs alignment can be achieved ""naturally"" either via
decoupling or via an approximate symmetry. Using the two-Higgs doublet model as
a prototype for an extended Higgs sector, I examine the symmetries of the
scalar potential and their soft breakings that may be responsible for the
SM-like properties of the observed Higgs boson, and I demonstrate how to extend
such (softly-broken) symmetries to the Yukawa sector of the model.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:20:56 GMT""},{""version"":""v2"",""created"":""Mon, 3 Oct 2022 21:59:44 GMT""}]","2022-10-05"
"2205.07579","Francesco Giancaterini","Francesco Giancaterini, Alain Hecq, Claudio Morana","Is climate change time reversible?",,,,,"econ.EM","http://creativecommons.org/licenses/by/4.0/","  This paper proposes strategies to detect time reversibility in stationary
stochastic processes by using the properties of mixed causal and noncausal
models. It shows that they can also be used for non-stationary processes when
the trend component is computed with the Hodrick-Prescott filter rendering a
time-reversible closed-form solution. This paper also links the concept of an
environmental tipping point to the statistical property of time irreversibility
and assesses fourteen climate indicators. We find evidence of time
irreversibility in $GHG$ emissions, global temperature, global sea levels, sea
ice area, and some natural oscillation indices. While not conclusive, our
findings urge the implementation of correction policies to avoid the worst
consequences of climate change and not miss the opportunity window, which might
still be available, despite closing quickly.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:29:23 GMT""},{""version"":""v2"",""created"":""Tue, 17 May 2022 20:50:13 GMT""},{""version"":""v3"",""created"":""Tue, 22 Nov 2022 09:49:11 GMT""}]","2022-11-23"
"2205.07580","Iskander Gazizov","Iskander Gazizov, Sergei Zenevich, and Alexander Rodin","Low-Resolution Imaging FMCW Lidar","This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible","Applied Optics 61 (2022) 9241-9246","10.1364/AO.472610",,"physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  We demonstrate the imaging capability of a frequency modulated continuous
wave lidar based on a fiber bundle. The lidar constructs velocity and range
images for hard targets at a rate of 60 Hz. The sensing range is up to 30 m
with 20 mW of output power. The instrument employs custom electronics with
seven parallel heterodyne receivers. An example of image recovery is presented
on 6-pixel ""pictures"" of a spinning disk and a drone hovering in the air. In
experiments, we also tested the laser tuning linearity correction with a
phase-locked loop. We see the practicality of such a low-resolution system as a
boost in scanning rate of conventional lidars or for direct target imaging with
a further upgrade of pixel count.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:30:33 GMT""}]","2022-11-11"
"2205.07581","Shaheen Nazir","Shaheen Nazir","On the $f$-vectors of $r$-multichain subdivisions","19 pages",,,,"math.CO","http://creativecommons.org/licenses/by-sa/4.0/","  For a poset $P$ and an integer $r\geq 1$, let $P_r$ be a collection of all
$r$-multichains in $P$. Corresponding to each strictly increasing map
$\i:[r]\rightarrow [2r]$, there is an order $\preceq_{\i}$ on $P_r$. Let
$\D(G_{\i}(P_r))$ be the clique complex of the graph $G_{\i}$ associated to
$P_r$ and $\i$. In a recent paper \cite{NW}, it is shown that $\D(G_{\i}(P_r))$
is a subdivision of $P$ for a class of strictly increasing maps. In this paper,
we show that all these subdivisions have the same $f$-vector. We give an
explicit description of the transformation matrices from the $f$- and
$h$-vectors of $\Delta$ to the $f$- and $h$-vectors of these subdivisions when
$P$ is a poset of faces of $\D$. We study two important subdivisions
Cheeger-M\""{u}ller-Schrader's subdivision and the $r$-colored barycentric
subdivision which fall in our class of $r$-multichain subdivisions.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:32:32 GMT""}]","2022-05-17"
"2205.07582","Yi Yu","Yi Yu and Karl Borjesson","Chemical transformer compression for accelerating both training and
  inference of molecular modeling",,,,,"cs.LG q-bio.BM","http://creativecommons.org/licenses/by/4.0/","  Transformer models have been developed in molecular science with excellent
performance in applications including quantitative structure-activity
relationship (QSAR) and virtual screening (VS). Compared with other types of
models, however, they are large, which results in a high hardware requirement
to abridge time for both training and inference processes. In this work,
cross-layer parameter sharing (CLPS), and knowledge distillation (KD) are used
to reduce the sizes of transformers in molecular science. Both methods not only
have competitive QSAR predictive performance as compared to the original BERT
model, but also are more parameter efficient. Furthermore, by integrating CLPS
and KD into a two-state chemical network, we introduce a new deep lite chemical
transformer model, DeLiCaTe. DeLiCaTe captures general-domains as well as
task-specific knowledge, which lead to a 4x faster rate of both training and
inference due to a 10- and 3-times reduction of the number of parameters and
layers, respectively. Meanwhile, it achieves comparable performance in QSAR and
VS modeling. Moreover, we anticipate that the model compression strategy
provides a pathway to the creation of effective generative transformer models
for organic drug and material design.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:38:31 GMT""}]","2022-05-17"
"2205.07583","Omar Lakkis","Amireh Mousavi and Omar Lakkis and Reza Mokhtari","A least-squares Galerkin approach to gradient recovery for
  Hamilton-Jacobi-Bellman equation with Cordes coefficients",,,,,"math.NA cs.NA math.AP math.OC nlin.AO","http://creativecommons.org/licenses/by-sa/4.0/","  We propose a conforming finite element method to approximate the strong
solution of the second order Hamilton-Jacobi-Bellman equation with Dirichlet
boundary and coefficients satisfying Cordes condition. We show the convergence
of the continuum semismooth Newton method for the fully nonlinear
Hamilton-Jacobi-Bellman equation. Applying this linearization for the equation
yields a recursive sequence of linear elliptic boundary value problems in
nondivergence form. We deal numerically with such BVPs via the least-squares
gradient recovery of Lakkis & Mousavi [2021, arxiv:1909.00491]. We provide an
optimal-rate apriori and aposteriori error bounds for the approximation. The
aposteriori error are used to drive an adaptive refinement procedure. We close
with computer experiments on uniform and adaptive meshes to reconcile the
theoretical findings.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:39:01 GMT""}]","2022-05-17"
"2205.07584","Berent {\AA}nund Str{\o}mnes Lunde","Berent {\AA}nund Str{\o}mnes Lunde, Feda Curic, Sondre Sortland","GraphSPME: Markov Precision Matrix Estimation and Asymptotic Stein-Type
  Shrinkage","17 pages, 6 figures",,,,"stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  GraphSPME is an open source Python, R and C++ header-only package
implement-ing non-parametric sparse precision matrix estimation along with
asymptotic Stein-type shrinkage estimation of the covariance matrix. The user
defines a potential neighbourhood structure and provides data that potentially
are p >> n. This paper introduces a novel approach for finding the optimal
order (that data allows to estimate) of a potential Markov property. The
algorithm is implemented in the package, alleviating the problem of users
making Markov assumptions and implementing corresponding complex higher-order
neighbourhood structures. Estimation is made accurate and stable by
simultaneously utilising both Markov properties and Stein-type shrinkage.
Asymptotic results on Stein-type shrinkage ensure that non-singular well
conditioned matrices are obtained in an automatic manner. Final symmetry
conversion creates symmetric positive definite estimates. Furthermore, the
estimation routine is made efficient and scalable to very high-dimensional
problems (~10^7) by utilising the sparse nature of the precision matrix under
Markov assumptions. Implementation wise, the sparsity is exploited by employing
the sparsity possibilities made available by the Eigen C++ linear-algebra
library. The package and examples are available at
https://github.com/equinor/GraphSPME
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:42:01 GMT""}]","2022-05-17"
"2205.07585","Krzysztof Cichy","Manjunath Bhat, Wojciech Chomicki, Krzysztof Cichy, Martha
  Constantinou, Jeremy R. Green, Aurora Scapellato","Continuum limit of parton distribution functions from the
  pseudo-distribution approach on the lattice","31 pages, 20 figures",,"10.1103/PhysRevD.106.054504",,"hep-lat hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Precise quantification of the structure of nucleons is one of the crucial
aims of hadronic physics for the coming years. The expected progress related to
ongoing and planned experiments should be accompanied by calculations of
partonic distributions from lattice QCD. While key insights from the lattice
are expected to come for distributions that are difficult to access
experimentally, it is important that lattice QCD can reproduce the well-known
unpolarized parton distribution functions (PDFs) with full control over
systematic uncertainties. One of the novel methods for accessing the partonic
$x$-dependence is the pseudo-distribution approach, which employs matrix
elements of a spatially-extended nonlocal Wilson-line operator of length $z$.
In this paper, we address the issue of discretization effects, related to the
necessarily nonzero value of the lattice spacing $a$, which start at first
order in $a$ as a result of the nonlocal operator. We use twisted mass fermions
simulated at three values of the lattice spacing, at a pion mass of 370 MeV,
and extract the continuum limit of isovector unpolarized PDFs. We also test,
for the first time in the pseudo-distribution approach, the effects of the
recently derived two-loop matching. Finally, we address the issue of the
reliability of the extraction with respect to the maximal value of $z$.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:43:33 GMT""}]","2022-10-05"
"2205.07586","Jun He Prof.","Jun-Tao Zhu, Shu-Yi Kong, Lin-Qing Song, Jun He","Systematical study of $\Omega_c$-like molecular states from interactions
  $\Xi_c^{(',*)}\bar{K}^{(*)}$ and $\Xi^{(*)}D^{(*)}$","11 pages, 3 figures",,"10.1103/PhysRevD.105.094036",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, the $\Omega_c$-like molecular states are systematically
investigated in a quasipotential Bethe-Salpeter equation approach. The relevant
interactions $\Xi_c^{(*,')}\bar{K}^{(*)}$, $\Xi^{(*)}D^{(*)}$, and
$\Omega^{(*)}_c(\pi/\eta/\rho/\omega)$ are described by light meson exchanges
with the help of the effective Lagrangians with SU(3), chiral, and heavy quark
symmetries. The obtained potential kernels of considered interactions are
inserted into the quasipotential Bethe-Salpeter equation, and coupled-channel
calculations are performed to find possible molecular states and its couplings
to the channels considered. The results suggest that an isoscalar state can be
produced from the $\Xi^*_c\bar{K}$ interaction with spin parity $3/2^-$, which
can be related to state $\Omega_c(3120)$. And its isoscalar partner is
predicted with a dominant decay in the $\Omega_c^*\pi$ channel. The isoscalar
and isovector states with $1/2^-$ can be produced from the $\Xi'_c\bar{K}$
interaction with a threshold close to the mass of the $\Omega_c(3050)$ and
$\Omega_c(3065)$. Their couplings to the $\Xi_c \bar{K}$ channel are very weak,
and the isovector one has strong coupling to $\Omega_c\pi$. High precision
measurement is helpful to confirm or search such molecular states. Experimental
search of states with higher masses generated from interactions $\Xi^{(*,')}_c
\bar{K}^*$ and $\Xi^* D^{(*)}$ are also suggested by the current results.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:44:06 GMT""},{""version"":""v2"",""created"":""Tue, 24 May 2022 04:56:41 GMT""}]","2022-06-08"
"2205.07587","Antonio Pich","Antonio Pich and Antonio Rodr\'iguez-S\'anchez","Violations of Quark-Hadron Duality in Low-Energy Determinations of
  $\alpha_s$","39 pages, 8 figures. References added. Published version",,"10.1007/JHEP07(2022)145",,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using the spectral functions measured in $\tau$ decays, we investigate the
actual numerical impact of duality violations on the extraction of the strong
coupling. These effects are tiny in the standard $\alpha_s(m_\tau^2)$
determinations from integrated distributions of the hadronic spectrum with
pinched weights, or from the total $\tau$ hadronic width. The pinched-weight
factors suppress very efficiently the violations of duality, making their
numerical effects negligible in comparison with the larger perturbative
uncertainties. However, combined fits of $\alpha_s$ and duality-violation
parameters, performed with non-protected weights, are subject to large
systematic errors associated with the assumed modelling of duality-violation
effects. These uncertainties have not been taken into account in the published
analyses, based on specific models of quark-hadron duality.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:45:12 GMT""},{""version"":""v2"",""created"":""Mon, 11 Jul 2022 15:30:10 GMT""}]","2022-08-10"
"2205.07588","Evagoras Stylianou","Evagoras Stylianou, Charalambos D. Charalambous and Jan H. van
  Schuppen","Characterization of the Gray-Wyner Rate Region for Multivariate Gaussian
  Sources: Optimality of Gaussian Auxiliary RV",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Examined in this paper, is the Gray and Wyner achievable lossy rate region
for a tuple of correlated multivariate Gaussian random variables (RVs) $X_1 :
\Omega \rightarrow {\mathbb R}^{p_1}$ and $X_2 : \Omega \rightarrow {\mathbb
R}^{p_2}$ with respect to square-error distortions at the two decoders. It is
shown that among all joint distributions induced by a triple of RVs $(X_1,X_2,
W)$, such that $W : \Omega \rightarrow {\mathbb W} $ is the auxiliary RV taking
continuous, countable, or finite values, the Gray and Wyner achievable rate
region is characterized by jointly Gaussian RVs $(X_1,X_2, W)$ such that $W $
is an $n$-dimensional Gaussian RV. It then follows that the achievable rate
region is parametrized by the three conditional covariances $Q_{X_1,X_2|W},
Q_{X_1|W}, Q_{X_2|W}$ of the jointly Gaussian RVs. Furthermore, if the RV $W$
makes $X_1$ and $X_2$ conditionally independent, then the corresponding subset
of the achievable rate region, is simpler, and parametrized by only the two
conditional covariances $Q_{X_1|W}, Q_{X_2|W}$. The paper also includes the
characterization of the Pangloss plane of the Gray-Wyner rate region along with
the characterizations of the corresponding rate distortion functions, their
test-channel distributions, and structural properties of the realizations which
induce these distributions.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:47:29 GMT""}]","2022-05-17"
"2205.07589","Denise M. Reeves","Denise M. Reeves","Fundamental Laws of Binary Classification","265 pages, 21 figures: We present a comprehensive treatise on the
  binary classification of random vectors. We formulate the direct problem by
  generalizing a well-posed variant of Bayes' decision rule. We formulate the
  inverse problem by generalizing a well-posed variant of the constrained
  optimization algorithm used by support vector machines to learn nonlinear
  decision boundaries",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Finding discriminant functions of minimum risk binary classification systems
is a novel geometric locus problem -- which requires solving a system of
fundamental locus equations of binary classification -- subject to deep-seated
statistical laws. We show that a discriminant function of a minimum risk binary
classification system is the solution of a locus equation that represents the
geometric locus of the decision boundary of the system, wherein the
discriminant function is connected to the decision boundary by an exclusive
principal eigen-coordinate system -- at which point the discriminant function
is represented by a geometric locus of a novel principal eigenaxis --
structured as a dual locus of likelihood components and principal eigenaxis
components. We demonstrate that a minimum risk binary classification system
acts to jointly minimize its eigenenergy and risk by locating a point of
equilibrium, at which point critical minimum eigenenergies exhibited by the
system are symmetrically concentrated in such a manner that the novel principal
eigenaxis of the system exhibits symmetrical dimensions and densities, so that
counteracting and opposing forces and influences of the system are
symmetrically balanced with each other -- about the geometric center of the
locus of the novel principal eigenaxis -- whereon the statistical fulcrum of
the system is located. Thereby, a minimum risk binary classification system
satisfies a state of statistical equilibrium -- so that the total allowed
eigenenergy and the expected risk exhibited by the system are jointly minimized
within the decision space of the system -- at which point the system exhibits
the minimum probability of classification error.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:50:13 GMT""},{""version"":""v2"",""created"":""Mon, 2 Jan 2023 16:58:18 GMT""}]","2023-01-03"
"2205.07590","Stefano Cresci","Roberto Di Pietro, Stefano Cresci","Metaverse: Security and Privacy Issues","The 3rd IEEE International Conference on Trust, Privacy and Security
  in Intelligent Systems and Applications (TPS'21)",,"10.1109/TPSISA52974.2021.00032",,"cs.CR cs.CY cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The metaverse promises a host of bright opportunities for business,
economics, and society. Though, a number of critical aspects are still to be
considered and the analysis of their impact is almost non-existent. In this
paper, we provide several contributions. We start by analysing the foundations
of the metaverse, later we focus on the novel privacy and security issues
introduced by this new paradigm, and finally we broaden the scope of the
contribution highlighting some of the far-reaching yet logical implications of
the metaverse on a number of domains, not all of them in tech. Throughout the
paper, we also discuss possible research directions. We believe that the
provided holistic view on the foundations, technology, and issues related to
the metaverse-with a focus on security and privacy-, other than being an
interesting contribution on its own, could also pave the way for a few
multidisciplinary research avenues.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:50:14 GMT""}]","2022-05-17"
"2205.07591","Tsutomu Takeuchi T.","Kazuki Y. Nishida, Tsutomu T. Takeuchi, Takuma Nagata, Ryosuke S.
  Asano","A new galaxy spectral energy distribution model consistent with the
  evolution of dust","19 Pages, 19 Figures, accepted for publication in MNRAS",,"10.1093/mnras/stac1355",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  The spectral energy distribution (SED) of galaxies provides fundamental
information on the related physical processes. However, the SED is
significantly affected by dust in its interstellar medium. Dust is mainly
produced by asymptotic giant branch stars and Type II supernovae. In addition,
the dust mass increases through the metal accretion, and the grain size changes
by the collisions between the grains. The contribution of each process and the
extinction depend on the size distribution. Therefore, the SED model should
treat the evolution of the dust mass and size distribution. In spite of the
importance of dust evolution, many previous SED models have not considered the
evolution of the total mass and size distribution in a physically consistent
manner. In this work, we constructed a new radiative transfer SED model, based
on our dust evolution model consistent with the chemical evolution. To reduce
the computational cost, we adopted the mega-grain and the one-dimensional plane
parallel galaxy approximation. As a fiducial case, we calculated Milky Way-like
galaxy SEDs at various ages under the closed-box model. We found that a galaxy
at the age of 100~Myr does not produce small grains such as polycyclic aromatic
hydrocarbons. After 1~Gyr, we observed a drastic increase of infrared emission
and attenuation caused by a rapid increase of dust mass. This phenomenon can be
treated appropriately for the first time by our new model. This model can be
used for the SED fitting to a galaxy at any stage of evolution.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:50:49 GMT""}]","2022-05-25"
"2205.07592","Nicola Milano","Nicola Milano and Stefano Nolfi","Qualitative Differences Between Evolutionary Strategies and
  Reinforcement Learning Methods for Control of Autonomous Agents",,,,,"cs.AI cs.LG cs.NE","http://creativecommons.org/licenses/by/4.0/","  In this paper we analyze the qualitative differences between evolutionary
strategies and reinforcement learning algorithms by focusing on two popular
state-of-the-art algorithms: the OpenAI-ES evolutionary strategy and the
Proximal Policy Optimization (PPO) reinforcement learning algorithm -- the most
similar methods of the two families. We analyze how the methods differ with
respect to: (i) general efficacy, (ii) ability to cope with sparse rewards,
(iii) propensity/capacity to discover minimal solutions, (iv) dependency on
reward shaping, and (v) ability to cope with variations of the environmental
conditions. The analysis of the performance and of the behavioral strategies
displayed by the agents trained with the two methods on benchmark problems
enable us to demonstrate qualitative differences which were not identified in
previous studies, to identify the relative weakness of the two methods, and to
propose ways to ameliorate some of those weakness. We show that the
characteristics of the reward function has a strong impact which vary
qualitatively not only for the OpenAI-ES and the PPO but also for alternative
reinforcement learning algorithms, thus demonstrating the importance of
optimizing the characteristic of the reward function to the algorithm used.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:51:36 GMT""}]","2022-05-17"
"2205.07593","Shreyas Pai","M\'elanie Cambus and Fabian Kuhn and Etna Lindy and Shreyas Pai and
  Jara Uitto","A Single-Pass Semi-Streaming Algorithm for $(3+\varepsilon)$-Approximate
  Correlation Clustering",,,,,"cs.DS cs.DC","http://creativecommons.org/licenses/by/4.0/","  Grouping together similar elements in datasets is a common task in data
mining and machine learning. In this paper, we study streaming and parallel
algorithms for correlation clustering, where each pair of elements is labeled
either similar or dissimilar. The task is to partition the elements and the
objective is to minimize disagreements, that is, the number of dissimilar
elements grouped together and similar items that get separated. Our main
contribution is a semi-streaming algorithm that achieves a $(3 +
\varepsilon)$-approximation to the minimum number of disagreements using a
single pass over the stream. Our approach builds on the analysis of the PIVOT
algorithm by Ailon, Charikar, and Newman [JACM'08] that obtains a
$3$-approximation in the centralized setting. Our design allows us to sparsify
the input graph by ignoring a large portion of the nodes and edges without a
large extra cost as compared to the analysis of PIVOT. This sparsification
makes our technique applicable on several models of massive graph processing,
such as semi-streaming and Massively Parallel Computing (MPC), where sparse
graphs can typically be handled much more efficiently. For the semi-streaming
model, our approach yields a single-pass algorithm that works in the
adaptive-order setting. This improves on the approximation ratio of the recent
single-pass $5$-approximation algorithm and on the number of passes of the
recent $O(1/\varepsilon)$-pass $(3 + \varepsilon)$-approximation algorithm
[Behnezhad, Charikar, Ma, Tan FOCS'22, SODA'23]. For linear-memory MPC, we get
an $O(1)$-round algorithm where the round complexity is independent of
$\varepsilon$, which only appears in the memory demand.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:51:48 GMT""},{""version"":""v2"",""created"":""Tue, 24 May 2022 13:26:59 GMT""},{""version"":""v3"",""created"":""Mon, 24 Oct 2022 13:25:07 GMT""},{""version"":""v4"",""created"":""Tue, 4 Apr 2023 17:50:57 GMT""}]","2023-04-05"
"2205.07594","Corentin Le Bars","Corentin Le Bars","Random walks and rank one isometries on CAT(0) spaces","29 pages, 4 figures",,,,"math.GR","http://creativecommons.org/licenses/by/4.0/","  Let $G$ be a discrete group, $\mu$ a measure on $G$ and $X$ a proper CAT(0)
space. We show that if $G$ acts non-elementarily with a rank one element on
$X$, then the pushforward $\{Z_n o \}_n$ to $X$ of the random walk generated by
$\mu$ converges almost surely to a rank one point of the boundary. We also show
that in this context, there is a unique stationary measure on the visual
boundary $\partial_\infty X$ of $X$, and that the drift of the random walk is
almost surely positive.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:53:36 GMT""}]","2022-05-17"
"2205.07595","Sebastiano Daniel Maximilian von Fellenberg","Sebastiano von Fellenberg, Stefan Gillessen, Julia Stadler, Michi
  Baub\""ock, Reinhard Genzel, Tim de Zeeuw, Oliver Pfuhl, Pau Amaro Seoane,
  Antonia Drescher, Frank Eisenhauer, Maryam Habibi, Thomas Ott, Felix Widmann,
  Alice Young","The young stars in the Galactic Center","Accepted for Publication in APJL",,"10.3847/2041-8213/ac68ef",,"astro-ph.GA astro-ph.HE astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We present a large ${\sim 30"" \times 30""}$ spectroscopic survey of the
Galactic Center using the SINFONI IFU at the VLT. Combining observations of the
last two decades we compile spectra of over $2800$ stars. Using the
Bracket-$\gamma$ absorption lines we identify $195$ young stars, extending the
list of known young stars by $79$. In order to explore the angular momentum
distribution of the young stars, we introduce an isotropic cluster prior. This
prior reproduces an isotropic cluster in a mathematically exact way, which we
test through numerical simulations. We calculate the posterior angular momentum
space as function of projected separation from Sgr~A*. We find that the
observed young star distribution is substantially different from an isotropic
cluster. We identify the previously reported feature of the clockwise disk and
find that its angular momentum changes as function of separation from the black
hole, and thus confirm a warp of the clockwise disk ($p \sim 99.2\%$). At large
separations, we discover three prominent overdensities of angular momentum. One
overdensity has been reported previously, the counter-clockwise disk. The other
two are new. Determining the likely members of these structures, we find that
as many as $75\%$ of stars can be associated with one of these features. Stars
belonging to the warped clockwise-disk show a top heavy K-band luminosity
function, while stars belonging to the larger separation features do not. Our
observations are in good agreement with the predictions of simulations of
in-situ star formation, and argue for common formation of these structures.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:58:49 GMT""}]","2022-06-22"
"2205.07596","Lei Yu","Lei Yu","Exact Exponents for Concentration and Isoperimetry in Product Polish
  Spaces","34 pages. More results and references are added",,,,"math.PR cs.IT math.FA math.IT math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we derive variational formulas for the asymptotic exponents of
the concentration and isoperimetric functions in the product Polish probability
space. These formulas are expressed in terms of relative entropies (which are
from information theory) and optimal transport cost functionals (which are from
optimal transport theory). Our results verify an intimate connection among
information theory, optimal transport, and concentration of measure or
isoperimetric inequalities. In the concentration regime, the corresponding
variational formula is in fact a dimension-free bound on the exponent of the
concentration function. The proofs in this paper are based on
information-theoretic and optimal transport techniques. Our results generalize
Alon, Boppana, and Spencer's in \cite{alon1998asymptotic}, Gozlan and
L\'eonard's \cite{gozlan2007large}, and Ahlswede and Zhang's in
\cite{ahlswede1999asymptotical}.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:02:47 GMT""},{""version"":""v2"",""created"":""Fri, 16 Sep 2022 09:23:04 GMT""}]","2022-09-19"
"2205.07597","Nuno Crokidakis","Nuno Crokidakis","Modeling the impact of civilian firearm ownership in the evolution of
  violent crimes","15 pages, 2 figures, to appear in Applied Mathematics and Computation","Appl Math Comput 429, 127256 (2022)","10.1016/j.amc.2022.127256",,"physics.soc-ph","http://creativecommons.org/publicdomain/zero/1.0/","  We propose a simple mathematical model to describe the evolution of violent
crimes. For such purpose, we built a model based on ordinary differential
equations that take into account the number of violent crimes and the number of
legal and illegal guns. The dynamics is governed by probabilities, modeling for
example the police action, the risk perception regarding crimes that leads to
increase of ownership of legal guns, and so on. Our analytical and numerical
results show that, in addition to the rise of criminality due to the presence
of illegal guns, the increase of legal guns leads to a fast increase of violent
crimes, suggesting that the access of firearms by civilians is not a good
option regarding the control of crimes.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:03:13 GMT""}]","2022-05-20"
"2205.07598","In-Soo Kim","In-soo Kim, Mehdi Bennis, and Junil Choi","Cell-Free MmWave Massive MIMO Systems with Low-Capacity Fronthaul Links
  and Low-Resolution ADC/DACs","to appear in IEEE Transactions on Vehicular Technology","IEEE Transactions on Vehicular Technology, vol. 71, no. 10, pp.
  10512-10526, Oct. 2022","10.1109/TVT.2022.3184172",,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider the uplink channel estimation phase and downlink
data transmission phase of cell-free millimeter wave (mmWave) massive
multiple-input multiple-output (MIMO) systems with low-capacity fronthaul links
and low-resolution analog-to-digital converters/digital-to-analog converters
(ADC/DACs). In cell-free massive MIMO, a control unit dictates the baseband
processing at a geographical scale, while the base stations communicate with
the control unit through fronthaul links. Unlike most of previous works in
cell-free massive MIMO with finite-capacity fronthaul links, we consider the
general case where the fronthaul capacity and ADC/DAC resolution are not
necessarily the same. In particular, the fronthaul compression and ADC/DAC
quantization occur independently where each one is modeled based on the
information theoretic argument and additive quantization noise model (AQNM).
Then, we address the codebook design problem that aims to minimize the channel
estimation error for the independent and identically distributed (i.i.d.) and
colored compression noise cases. Also, we propose an alternating optimization
(AO) method to tackle the max-min fairness problem. In essence, the AO method
alternates between two subproblems that correspond to the power allocation and
codebook design problems. The AO method proposed for the zero-forcing (ZF)
precoder is guaranteed to converge, whereas the one for the maximum ratio
transmission (MRT) precoder has no such guarantee. Finally, the performance of
the proposed schemes is evaluated by the simulation results in terms of both
energy and spectral efficiency. The numerical results show that the proposed
scheme for the ZF precoder yields spectral and energy efficiency 28% and 15%
higher than that of the best baseline.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:04:17 GMT""},{""version"":""v2"",""created"":""Wed, 15 Jun 2022 08:37:42 GMT""}]","2022-11-01"
"2205.07599","Jianjun Jin","Jianjun Jin","Generalized multiplicative Hilbert operators","10 pages",,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  In this note, by introducing some parameters, we define and study some
generalized multiplicative Hilbert operators. We provide a sufficient and
necessary condition for the boundedness of these operators in terms of the
parameters. Also, for certain special cases, we determine the exact values of
the norms of the generalized multiplicative Hilbert operators.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:05:24 GMT""},{""version"":""v2"",""created"":""Tue, 17 May 2022 12:53:47 GMT""},{""version"":""v3"",""created"":""Thu, 19 May 2022 11:03:57 GMT""},{""version"":""v4"",""created"":""Fri, 20 May 2022 12:31:32 GMT""},{""version"":""v5"",""created"":""Wed, 1 Jun 2022 12:56:26 GMT""},{""version"":""v6"",""created"":""Wed, 8 Jun 2022 23:43:02 GMT""}]","2022-06-10"
"2205.07603","Mark Anderson","Mark Anderson and Jose Camacho-Collados","Assessing the Limits of the Distributional Hypothesis in Semantic
  Spaces: Trait-based Relational Knowledge and the Impact of Co-occurrences","Due to appear in the proceedings of *SEM 2022: The 11th Joint
  Conference on Lexical and Computational Semantics",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The increase in performance in NLP due to the prevalence of distributional
models and deep learning has brought with it a reciprocal decrease in
interpretability. This has spurred a focus on what neural networks learn about
natural language with less of a focus on how. Some work has focused on the data
used to develop data-driven models, but typically this line of work aims to
highlight issues with the data, e.g. highlighting and offsetting harmful
biases. This work contributes to the relatively untrodden path of what is
required in data for models to capture meaningful representations of natural
language. This entails evaluating how well English and Spanish semantic spaces
capture a particular type of relational knowledge, namely the traits associated
with concepts (e.g. bananas-yellow), and exploring the role of co-occurrences
in this context.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:09:40 GMT""}]","2022-05-17"
"2205.07605","Javier Sanz","Javier Jim\'enez-Garrido, Ignacio Miguel-Cantero, Javier Sanz and
  Gerhard Schindl","Optimal flat functions in Carleman-Roumieu ultraholomorphic classes in
  sectors","29 pages. Important improvements, mainly in Section 3: a simplified
  concept of optimal flat function is introduced, and their general
  construction is provided for strongly non-quasianalytic weight sequences and
  in narrow enough sectors","Res. Math. 78, art. no. 98, 2023","10.1007/s00025-023-01859-w",,"math.CV math.FA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We construct optimal flat functions in Carleman-Roumieu ultraholomorphic
classes associated to general strongly nonquasianalytic weight sequences, and
defined on sectors of suitably restricted opening. A general procedure is
presented in order to obtain linear continuous extension operators, right
inverses of the Borel map, for the case of regular weight sequences in the
sense of Dyn'kin. Finally, we discuss some examples (including the well-known
$q$-Gevrey case) where such optimal flat functions can be obtained in a more
explicit way.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:10:34 GMT""},{""version"":""v2"",""created"":""Mon, 31 Oct 2022 18:13:15 GMT""}]","2023-06-05"
"2205.07610","Roland Lei{\ss}a","Andr\'e M\""uller and Bertil Schmidt and Richard Membarth and Roland
  Lei{\ss}a and Sebastian Hack","AnySeq/GPU: A Novel Approach for Faster Sequence Alignment on GPUs","published on ICS '22 (2022 International Conference on
  Supercomputing)",,"10.1145/3524059.3532376",,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, the rapidly increasing number of reads produced by
next-generation sequencing (NGS) technologies has driven the demand for
efficient implementations of sequence alignments in bioinformatics. However,
current state-of-the-art approaches are not able to leverage the massively
parallel processing capabilities of modern GPUs with close-to-peak performance.
  We present AnySeq/GPU-a sequence alignment library that augments the AnySeq1
library with a novel approach for accelerating dynamic programming (DP)
alignment on GPUs by minimizing memory accesses using warp shuffles and
half-precision arithmetic. Our implementation is based on the AnyDSL compiler
framework which allows for convenient zero-cost abstractions through guaranteed
partial evaluation. We show that our approach achieves over 80% of the peak
performance on both NVIDIA and AMD GPUs thereby outperforming the GPU-based
alignment libraries AnySeq1, GASAL2, ADEPT, and NVBIO by a factor of at least
3.6 while achieving a median speedup of 19.2x over these tools across different
alignment scenarios and sequence lengths when running on the same hardware.
  This leads to throughputs of up to 1.7 TCUPS (tera cell updates per second)
on an NVIDIA GV100, up to 3.3 TCUPS with half-precision arithmetic on a single
NVIDIA A100, and up to 3.8 TCUPS on an AMD MI100.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:11:57 GMT""}]","2022-05-17"
"2205.07611","Haochen Han","Haochen Han, Qinghua Zheng, Minnan Luo, Kaiyao Miao, Feng Tian and Yan
  Chen","Noise-Tolerant Learning for Audio-Visual Action Recognition","This work is going to be submitted to the IEEE for possible
  publication. Copyright may be transferred without notice, after which this
  version may no longer be accessible",,,,"cs.CV cs.MM","http://creativecommons.org/licenses/by/4.0/","  Recently, video recognition is emerging with the help of multi-modal
learning, which focuses on integrating multiple modalities to improve the
performance or robustness of a model. Although various multi-modal learning
methods have been proposed and offer remarkable recognition results, almost all
of these methods rely on high-quality manual annotations and assume that
modalities among multi-modal data provide relevant semantic information.
Unfortunately, most widely used video datasets are collected from the Internet
and inevitably contain noisy labels and noisy correspondence. To solve this
problem, we use the audio-visual action recognition task as a proxy and propose
a noise-tolerant learning framework to find anti-interference model parameters
to both noisy labels and noisy correspondence. Our method consists of two
phases and aims to rectify noise by the inherent correlation between
modalities. A noise-tolerant contrastive training phase is performed first to
learn robust model parameters unaffected by the noisy labels. To reduce the
influence of noisy correspondence, we propose a cross-modal noise estimation
component to adjust the consistency between different modalities. Since the
noisy correspondence existed at the instance level, a category-level
contrastive loss is proposed to further alleviate the interference of noisy
correspondence. Then in the hybrid supervised training phase, we calculate the
distance metric among features to obtain corrected labels, which are used as
complementary supervision. In addition, we investigate the noisy correspondence
in real-world datasets and conduct comprehensive experiments with synthetic and
real noise data. The results verify the advantageous performance of our method
compared to state-of-the-art methods.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:14:03 GMT""},{""version"":""v2"",""created"":""Fri, 20 May 2022 10:10:55 GMT""}]","2022-05-23"
"2205.07612","Richard Ignace","Richard Ignace, Andrew Fullard, Manisha Shrestha, Yael Naze, Kenneth
  Gayley, Jennifer L Hoffman, Jamie R Lomax, Nicole St-Louis","Modeling the Optical to Ultraviolet Polarimetric Variability from
  Thomson Scattering in Colliding Wind Binaries","accepted for publication in the Astrophysical Journal. arXiv admin
  note: text overlap with arXiv:2111.11552",,"10.3847/1538-4357/ac6fce",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Massive star binaries are critical laboratories for measuring masses and
stellar wind mass-loss rates. A major challenge is inferring viewing
inclination and extracting information about the colliding wind interaction
(CWI) region. Polarimetric variability from electron scattering in the highly
ionized winds provides important diagnostic information about system geometry.
We combine for the first time the well-known generalized treatment of
\citet{brown_polarisation_1978} for variable polarization from binaries with
the semi-analytic solution for the geometry and surface density CWI shock
interface between the winds based on Canto et al 1996. Our calculations include
some simplifications in the form of inverse square-law wind densities and the
assumption of axisymmetry, but in so doing arrive at several robust
conclusions. One is that when the winds are nearly equal (e.g., O\,+\,O
binaries), the polarization has a relatively mild decline with binary
separation. Another is that despite Thomson scattering being a gray opacity,
the continuum polarization can show chromatic effects at ultraviolet
wavelengths but will be mostly constant at longer wavelengths. Finally, when
one wind dominates the other, as for example in WR+OB binaries, the
polarization is expected to be larger at wavelengths where the OB component is
more luminous, and generally smaller at wavelengths where the WR component is
more luminous. This behavior arises because from the perspective of the WR
star, the distortion of the scattering envelope from spherical is a minor
perturbation situated far from the WR star. By contrast, the polarization
contribution from the OB star is dominated by the geometry of the CWI shock.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:14:10 GMT""}]","2022-07-06"
"2205.07613","Pirazh Khorramshahi","Pirazh Khorramshahi, Vineet Shenoy, Rama Chellappa","Scalable Vehicle Re-Identification via Self-Supervision",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  As Computer Vision technologies become more mature for intelligent
transportation applications, it is time to ask how efficient and scalable they
are for large-scale and real-time deployment. Among these technologies is
Vehicle Re-Identification which is one of the key elements in city-scale
vehicle analytics systems. Many state-of-the-art solutions for vehicle re-id
mostly focus on improving the accuracy on existing re-id benchmarks and often
ignore computational complexity. To balance the demands of accuracy and
computational efficiency, in this work we propose a simple yet effective hybrid
solution empowered by self-supervised training which only uses a single network
during inference time and is free of intricate and computation-demanding add-on
modules often seen in state-of-the-art approaches. Through extensive
experiments, we show our approach, termed Self-Supervised and Boosted VEhicle
Re-Identification (SSBVER), is on par with state-of-the-art alternatives in
terms of accuracy without introducing any additional overhead during
deployment. Additionally we show that our approach, generalizes to different
backbone architectures which facilitates various resource constraints and
consistently results in a significant accuracy boost.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:14:42 GMT""}]","2022-05-17"
"2205.07614","Chao Wang","Chao Wang, Chen Chen, Dong Li, Bin Wang","Rethinking Reinforcement Learning based Logic Synthesis","nine pages; one figure;",,,,"cs.LG cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, reinforcement learning has been used to address logic synthesis by
formulating the operator sequence optimization problem as a Markov decision
process. However, through extensive experiments, we find out that the learned
policy makes decisions independent from the circuit features (i.e., states) and
yields an operator sequence that is permutation invariant to some extent in
terms of operators. Based on these findings, we develop a new RL-based method
that can automatically recognize critical operators and generate common
operator sequences generalizable to unseen circuits. Our algorithm is verified
on both the EPFL benchmark, a private dataset and a circuit at industrial
scale. Experimental results demonstrate that it achieves a good balance among
delay, area and runtime, and is practical for industrial usage.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:15:32 GMT""},{""version"":""v2"",""created"":""Sat, 28 May 2022 08:31:10 GMT""},{""version"":""v3"",""created"":""Mon, 27 Jun 2022 11:41:13 GMT""}]","2022-06-28"
"2205.07615","Farzaneh Pourahmadi","Farzaneh Pourahmadi and Trine Krogh Boomsma","Approximate dynamic programming for profit estimation of connected hydro
  reservoirs",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the operational problem of connected hydro power
reservoirs which involves sequential decision-making in an uncertain and
dynamic environment. The problem is traditionally formulated as a stochastic
dynamic program accounting for the uncertainty of electricity prices and
reservoir inflows. This formulation suffers from the curse of dimensionality,
as the state space explodes with the number of reservoirs and the history of
prices and inflows. To avoid computing the expectation of future value
functions, the proposed model takes advantage of the so-called post-decision
state. To further tackle the dimensionality issue, we propose an approximate
dynamic programming approach that estimates the future value of water using a
linear approximation architecture. When the time series of prices and inflows
follow autoregressive processes, our approximation provides an upper bound on
the future value function. We use an offline training algorithm based on the
historical data of prices and inflows and run both in-sample and out-of-sample
simulations. Two realistic test systems of cascade and network connected
reservoirs serve to demonstrate the computational tractability of our approach.
In particular, we provide numerical evidence of convergence and quality of
solutions. For our test systems, our results show that profit estimation is
improved by 20% when including inflows in the linear approximation.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:15:41 GMT""}]","2022-05-17"
"2205.07616","Liam Shaw","Claire Hall, Liam P. Shaw","The logic of planetary combination in Vettius Valens","30 pages, 7 figures",,,,"physics.hist-ph math.HO","http://creativecommons.org/licenses/by/4.0/","  The Anthologies of the second-century astrologer Vettius Valens (120-c.175
CE) is the most extensive surviving practical astrological text from the
period. Despite this, the theoretical underpinnings of the Anthologies have
been understudied; in general, the work has been overshadowed by Ptolemy's
contemporaneous Tetrabiblos. While the Tetrabiblos explicitly aims to present a
systematic account of astrology, Valens' work is often characterised as a
miscellaneous collection, of interest to historians only for the evidence it
preserves about the practical methods used in casting horoscopes. In this
article, we argue that the Anthologies is also an invaluable resource for
engagement with the conceptual basis of astrology. As a case study, we take a
section of Anthologies Book 1 which lists the possible astrological effects of
planets, both alone and in 'combinations' of two and three. We demonstrate that
analysing Valens' descriptions quantitatively with textual analysis reveals a
consistent internal logic of planetary combination. By classifying descriptive
terms as positive or negative, we show that the resulting 'sentiment' of
planetary combinations is well-correlated with their component parts.
Furthermore, we find that the sentiment of three-planet combinations is more
strongly correlated with the average sentiment of their three possible
component pairs than with the average sentiment of individual planets,
suggesting an iterative combinatorial logic. Recognition of this feature of
astrological practice has been neglected compared to the mathematical methods
for calculating horoscopes. We argue that this analysis not only provides
evidence that the astrological lore detailed in Valens is more consistent than
is often assumed, but is also indicative of a wider methodological technique in
practical astrology: combinatorial reasoning from existing astrological lore.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:21:58 GMT""}]","2022-05-18"
"2205.07617","Lam Duc Nguyen","Lam Duc Nguyen, Arne Broering, Massimo Pizzol, Petar Popovski","Analysis of Distributed Ledger Technologies for Industrial Manufacturing","Accepted for publication at Nature Scientific Reports",,,,"cs.DC cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  In recent years, industrial manufacturing has undergone massive technological
changes that embrace digitalization and automation towards the vision of
intelligent manufacturing plants. With the aim of maximizing efficiency and
profitability in production, an important goal is to enable flexible
manufacturing, both, for the customer (desiring more individualized products)
and for the manufacturer (to adjust to market demands).
Manufacturing-as-a-service can support this through manufacturing plants that
are used by different tenants who utilize the machines in the plant, which are
offered by different providers. To enable such pay-per-use business models,
Distributed Ledger Technology (DLT) is a viable option to establish
decentralized trust and traceability. Thus, in this paper, we study potential
DLT technologies for an efficient and intelligent integration of DLT-based
solutions in manufacturing environments. We propose a general framework to
adapt DLT in manufacturing, then we introduce the use case of shared
manufacturing, which we utilize to study the communication and computation
efficiency of selected DLTs in resource-constrained wireless IoT networks.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:22:46 GMT""},{""version"":""v2"",""created"":""Tue, 18 Oct 2022 05:21:42 GMT""}]","2022-10-19"
"2205.07618","Daniel Gomon","Daniel Gomon, Hein Putter, Rob G. H. H. Nelissen, St\'ephanie van der
  Pas","CGR-CUSUM: A Continuous time Generalized Rapid Response Cumulative Sum
  chart","24 pages, 3 figures - The methods described in the article have been
  implemented in the R package success on CRAN, see
  https://cran.r-project.org/package=success",,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Rapidly detecting problems in the quality of care is of utmost importance for
the well-being of patients. Without proper inspection schemes, such problems
can go undetected for years. Cumulative sum (CUSUM) charts have proven to be
useful for quality control, yet available methodology for survival outcomes is
limited. The few available continuous time inspection charts usually require
the researcher to specify an expected increase in the failure rate in advance,
thereby requiring prior knowledge about the problem at hand. Misspecifying
parameters can lead to false positive alerts and large detection delays. To
solve this problem, we take a more general approach to derive the new
Continuous time Generalized Rapid response CUSUM (CGR-CUSUM) chart. We find an
expression for the approximate average run length (average time to detection)
and illustrate the possible gain in detection speed by using the CGR-CUSUM over
other commonly used monitoring schemes on a real life data set from the Dutch
Arthroplasty Register as well as in simulation studies. Besides the inspection
of medical procedures, the CGR-CUSUM can also be used for other real time
inspection schemes such as industrial production lines and quality control of
services.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:29:21 GMT""}]","2022-05-17"
"2205.07619","Sai Peng","Sai Peng and Peng Yu","Wall-induced translation of a rotating particle in viscoelastic fluid",,,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  Shear-thinning and viscoelasticity are two non-Newtonian fluid properties
widely existing in biological fluids. In this study, we found that the
translation motion of a rotating particle near a wall speed up firstly, and
then slows down with enhancement of fluid viscoelasticity, which is different
from the behavior reported in shear thinning fluid (Chen et al. J. Fluid Mech.
2021, 927). Our research is carried out by numerical simulation of
Navier-Stokes equations combined with Oldroyd-B constitutive model. This work
is expected to be helpful to understand the movement of a rotating sphere near
a wall in complex fluids comprehensively.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:31:51 GMT""},{""version"":""v2"",""created"":""Tue, 17 May 2022 04:26:52 GMT""},{""version"":""v3"",""created"":""Wed, 20 Jul 2022 03:21:23 GMT""},{""version"":""v4"",""created"":""Mon, 1 Aug 2022 08:38:56 GMT""},{""version"":""v5"",""created"":""Tue, 2 Aug 2022 23:58:00 GMT""}]","2022-08-04"
"2205.07620","Philipp Sauerteig","Philipp Sauerteig","Bidirectional Optimisation for Load Shaping within Coupled Microgrids","20 pages, 9 figures",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address the problem of load shaping within a network of coupled microgrids
(MGs) in a bilevel optimisation framework. To this end, we consider the
charging/discharging rates of residential energy storage devices within each MG
on the lower level and the power exchange among neighbouring MGs on the upper
level as optimisation variables. We improve a previously developed model such
that the maximal amount of exchanged power does not depend on the power demand,
thus, increasing the flexibility within the network, and adapt the
corresponding bidirectional optimisation scheme accordingly. For efficiency,
standard distributed optimisation routines are used for the optimisation on the
lower level; the power exchange problem on the upper level is replaced by
parallelisable small-scale quadratic programmings. We prove global convergence
of the optimisation scheme and illustrate the potential of the approach in a
numerical case study based on real-world data.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:36:02 GMT""}]","2022-05-17"
"2205.07621","Andreas M\""ori","A. M\""ori (1), B. Lecampion (1) ((1) Geo-Energy Laboratory - Gaznat
  Chair on Geo-Energy, Ecole Polytechnique F\'ed\'erale de Lausanne,
  Switzerland)","Three-dimensional buoyant hydraulic fracture growth: constant release
  from a point source","29 pages, 11 figures, Submitted to the J. Fluid Mech. by the authors
  on May 02, 2022: Revised on Sept. 01, 2022 Typos; The buoyancy contrast
  becomes the effective buoyancy contrast (after eq 2.6); Clarify the use of
  the dimensionless viscosity (around eq 3.8); Naming of the limiting toughness
  solution; Table format; Clarify parameters (sec 7.2); Add sec 7.3; Finite
  volume discussion in conclusion","Journal of Fluid Mechanics, 950, A12 (2022)","10.1017/jfm.2022.800",,"physics.flu-dyn physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hydraulic fractures propagating at depth are subjected to buoyant forces
caused by the density contrast between fluid and solid. This paper is concerned
with the analysis of the transition from an initially radial towards an
elongated buoyant growth -- a critical topic for understanding the extent of
vertical hydraulic fractures in the upper Earth crust. Using fully coupled
numerical simulations and scaling arguments, we show that a single
dimensionless number governs buoyant hydraulic fracture growth: the
dimensionless viscosity of a radial hydraulic fracture at the time when
buoyancy becomes of order one. It quantifies if the transition to buoyancy
occurs when the growth of the radial hydraulic fracture is either still in the
regime dominated by viscous flow dissipation or is already in the regime where
fracture energy dissipation dominates. A family of fracture shapes emerge at
late time from finger-like (toughness regime) to inverted elongated cudgel-like
(viscous regime). 3D toughness dominated buoyant fractures exhibit a
finger-like shape with a constant volume toughness dominated head and a viscous
tail having a constant uniform horizontal breadth: there is no further
horizontal growth past the onset of buoyancy. However, if the transition to
buoyancy occurs while in the viscosity dominated regime, both vertical and
horizontal growths continue to match scaling arguments. As soon as the fracture
toughness is not strictly zero, horizontal growth stops when the dimensionless
horizontal toughness becomes of order one. The horizontal breadth follows the
predicted scaling.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:36:25 GMT""},{""version"":""v2"",""created"":""Fri, 2 Sep 2022 07:26:31 GMT""}]","2022-10-20"
"2205.07622","Karen E. Daniels","Negin Amini, Josh Tuohey, John M. Long, Jun Zhang, David A. V. Morton,
  Karen Daniels, Farnaz Fazelpour, Karen P. Hapgood","Photoelastic Stress Response of Complex 3D-Printed Particle Shapes",,,,,"cond-mat.soft physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While stress visualization within 3-dimensional particles would greatly
advance our understanding of the behaviors of complex particles, traditional
photoelastic methods suffer from a lack of available technology for producing
suitable complex particles. Recently, 3D-printing has created new possibilities
for enhancing the scope of stress analysis within physically representative
granules. Here, we investigate and evaluate opportunities offered by
3D-printing a single particle with a complex external shape with photoelastic
properties. We report the results of X-ray computed tomography and 3D-printing,
combined with traditional photoelastic analysis, to visualize strain for
particles ranging from simple 2D discs to complex 3D printed coffee beans,
including with internal voids. We find that the relative orientation of the
print layers and the loading force affects the optical response of the discs,
but without a significant difference in their mechanical properties.
Furthermore, we present semi-quantitative measurements of stresses within
3D-printed complex particles. The paper outlines the potential limitations and
areas of future interest for stress visualization of 3-dimensional particles.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:41:15 GMT""}]","2022-05-17"
"2205.07623","Andr\'e Artelt","Andr\'e Artelt, Roel Visser, Barbara Hammer","Model Agnostic Local Explanations of Reject","arXiv admin note: text overlap with arXiv:2202.07244",,,,"cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  The application of machine learning based decision making systems in safety
critical areas requires reliable high certainty predictions. Reject options are
a common way of ensuring a sufficiently high certainty of predictions made by
the system. While being able to reject uncertain samples is important, it is
also of importance to be able to explain why a particular sample was rejected.
However, explaining general reject options is still an open problem. We propose
a model agnostic method for locally explaining arbitrary reject options by
means of interpretable models and counterfactual explanations.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:42:34 GMT""}]","2022-05-17"
"2205.07624","Anna Zafeiris Dr.","Anna Zafeiris","Opinion polarization in human communities can emerge as a natural
  consequence of beliefs being interrelated","13 pages, 5 figures + SI","Entropy 2022, 24(9), 1320","10.3390/e24091320",,"physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The emergence of opinion polarization within human communities -- the
phenomenon that individuals within a society tend to develop conflicting
attitudes related to the greatest diversity of topics -- has been a focus of
interest for decades, both from theoretical and modelling points of view.
Regarding modelling attempts, an entire scientific field -- opinion dynamics --
has emerged in order to study this and related phenomena. Within this
framework, agents' opinions are usually represented by a scalar value which
undergoes modification due to interaction with other agents. Under certain
conditions, these models are able to reproduce polarization -- a state
increasingly familiar to our everyday experience. In the present paper, an
alternative explanation is suggested along with its corresponding model. More
specifically, we demonstrate that by incorporating the following two well-known
human characteristics into the representation of agents: (1) in the human brain
beliefs are interconnected, and (2) people strive to maintain a coherent belief
system; polarization immediately occurs under exposure to news and information.
Furthermore, the model accounts for the proliferation of fake news, and shows
how opinion polarization is related to various cognitive biases.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:42:57 GMT""},{""version"":""v2"",""created"":""Tue, 4 Oct 2022 15:50:08 GMT""}]","2022-10-05"
"2205.07625","Max Lamparth","Max Lamparth, Mattis Bestehorn and Bastian M\""arkisch","Gaussian Processes and Bayesian Optimization for High Precision
  Experiments","Updated acknowledgements and changed capitalization style in title",,,,"physics.data-an hep-ex nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High-precision measurements require optimal setups and analysis tools to
achieve continuous improvements. Systematic corrections need to be modeled with
high accuracy and known uncertainty to reconstruct underlying physical
phenomena. To this end, we present Gaussian processes for modeling experiments
and usage with Bayesian optimization, on the example of an electron energy
detector, achieving optimal performance. We demonstrate the method's strengths
and outline stochastic variational Gaussian processes for physics applications
with large data sets, enabling new solutions for current problems.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:17:56 GMT""},{""version"":""v2"",""created"":""Fri, 27 May 2022 18:29:21 GMT""}]","2022-05-31"
"2205.07626","Chao Wang","Chao Wang","Attacking and Defending Deep Reinforcement Learning Policies","nine pages",,,,"cs.LG cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent studies have shown that deep reinforcement learning (DRL) policies are
vulnerable to adversarial attacks, which raise concerns about applications of
DRL to safety-critical systems. In this work, we adopt a principled way and
study the robustness of DRL policies to adversarial attacks from the
perspective of robust optimization. Within the framework of robust
optimization, optimal adversarial attacks are given by minimizing the expected
return of the policy, and correspondingly a good defense mechanism should be
realized by improving the worst-case performance of the policy. Considering
that attackers generally have no access to the training environment, we propose
a greedy attack algorithm, which tries to minimize the expected return of the
policy without interacting with the environment, and a defense algorithm, which
performs adversarial training in a max-min form. Experiments on Atari game
environments show that our attack algorithm is more effective and leads to
worse return of the policy than existing attack algorithms, and our defense
algorithm yields policies more robust than existing defense methods to a range
of adversarial attacks (including our proposed attack algorithm).
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:47:54 GMT""}]","2022-05-17"
"2205.07628","\""Amin Baumeler","\""Amin Baumeler, Carla Rieger, and Stefan Wolf","Thermodynamics as Combinatorics: A Toy Theory","6 pages, 5 figures",,,,"quant-ph cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss a simple toy model which allows, in a natural way, for deriving
central facts from thermodynamics such as its fundamental laws, including
Carnot's version of the second principle. Our viewpoint represents
thermodynamic systems as binary strings, and it links their temperature to
their Hamming weight. From this, we can reproduce the possibility of negative
temperatures, the notion of equilibrium as the co\""incidence of two notions of
temperature - statistical versus structural -, as well as the zeroth law of
thermodynamics (transitivity of the thermal-equilibrium relation), which we
find to be redundant, as other authors, yet at the same time not to be
universally valid.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:48:27 GMT""}]","2022-05-17"
"2205.07631","Miceline Mesidor","Miceline M\'esidor, Caroline Sirois, Marc Simard, Denis Talbot","A bootstrap approach for validating the number of groups identified by
  latent class growth models",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  The use of longitudinal finite mixture models such as group-based trajectory
modeling has seen a sharp increase during the last decades in the medical
literature. However, these methods have been criticized especially because of
the data-driven modelling process which involves statistical decision-making.
In this paper, we propose an approach that uses bootstrap to sample
observations with replacement from the original data to validate the number of
groups identified and to quantify the uncertainty in the number of groups. The
method allows investigating the statistical validity and the uncertainty of the
groups identified in the original data by checking if the same solution is also
found across the bootstrap samples. In a simulation study, we examined whether
the bootstrap-estimated variability in the number of groups reflected the
replication-wise variability. We also compared the replication-wise variability
to the Bayesian posterior probability. We evaluated the ability of three
commonly used adequacy criteria (average posterior probability, odds of correct
classification and relative entropy) to identify uncertainty in the number of
groups. Finally, we illustrated the proposed approach using data from the
Quebec Integrated Chronic Disease Surveillance System to identify longitudinal
medication patterns between 2015 and 2018 in older adults with diabetes.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:49:08 GMT""}]","2022-05-17"
"2205.07633","Patrick Ernst","Marin Vlastelica, Patrick Ernst, Gy\""orgy Szarvas","Taming Continuous Posteriors for Latent Variational Dialogue Policies",,,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Utilizing amortized variational inference for latent-action reinforcement
learning (RL) has been shown to be an effective approach in Task-oriented
Dialogue (ToD) systems for optimizing dialogue success. Until now, categorical
posteriors have been argued to be one of the main drivers of performance. In
this work we revisit Gaussian variational posteriors for latent-action RL and
show that they can yield even better performance than categoricals. We achieve
this by simplifying the training procedure and propose ways to regularize the
latent dialogue policy to retain good response coherence. Using continuous
latent representations our model achieves state of the art dialogue success
rate on the MultiWOZ benchmark, and also compares well to categorical latent
methods in response coherence.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:50:32 GMT""},{""version"":""v2"",""created"":""Wed, 1 Jun 2022 11:03:27 GMT""}]","2022-06-02"
"2205.07634","Csaba Veres","Csaba Veres","A Precis of Language Models are not Models of Language",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Natural Language Processing is one of the leading application areas in the
current resurgence of Artificial Intelligence, spearheaded by Artificial Neural
Networks. We show that despite their many successes at performing linguistic
tasks, Large Neural Language Models are ill-suited as comprehensive models of
natural language. The wider implication is that, in spite of the often
overbearing optimism about AI, modern neural models do not represent a
revolution in our understanding of cognition.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:50:58 GMT""}]","2022-05-17"
"2205.07638","Hannaneh Akrami","Hannaneh Akrami, Noga Alon, Bhaskar Ray Chaudhury, Jugal Garg, Kurt
  Mehlhorn, Ruta Mehta","EFX Allocations: Simplifications and Improvements",,,,,"cs.GT","http://creativecommons.org/licenses/by/4.0/","  The existence of EFX allocations is a fundamental open problem in discrete
fair division. Given a set of agents and indivisible goods, the goal is to
determine the existence of an allocation where no agent envies another
following the removal of any single good from the other agent's bundle. Since
the general problem has been illusive, progress is made on two fronts: $(i)$
proving existence when the number of agents is small, $(ii)$ proving existence
of relaxations of EFX. In this paper, we improve results on both fronts (and
simplify in one of the cases).
  We prove the existence of EFX allocations with three agents, restricting only
one agent to have an MMS-feasible valuation function (a strict generalization
of nice-cancelable valuation functions introduced by Berger et al. which
subsumes additive, budget-additive and unit demand valuation functions). The
other agents may have any monotone valuation functions. Our proof technique is
significantly simpler and shorter than the proof by Chaudhury et al. on
existence of EFX allocations when there are three agents with additive
valuation functions and therefore more accessible.
  Secondly, we consider relaxations of EFX allocations, namely, approximate-EFX
allocations and EFX allocations with few unallocated goods (charity). Chaudhury
et al. showed the existence of $(1-\epsilon)$-EFX allocation with
$O((n/\epsilon)^{\frac{4}{5}})$ charity by establishing a connection to a
problem in extremal combinatorics. We improve their result and prove the
existence of $(1-\epsilon)$-EFX allocations with $\tilde{O}((n/
\epsilon)^{\frac{1}{2}})$ charity. In fact, some of our techniques can be used
to prove improved upper-bounds on a problem in zero-sum combinatorics
introduced by Alon and Krivelevich.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:54:40 GMT""},{""version"":""v2"",""created"":""Fri, 23 Dec 2022 11:10:18 GMT""}]","2022-12-26"
"2205.07640","Mirrelijn van Nee","Mirrelijn M. van Nee, Lodewyk F.A. Wessels and Mark A. van de Wiel","ecpc: An R-package for generic co-data models for high-dimensional
  prediction",,,,,"stat.ME stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High-dimensional prediction considers data with more variables than samples.
Generic research goals are to find the best predictor or to select variables.
Results may be improved by exploiting prior information in the form of co-data,
providing complementary data not on the samples, but on the variables. We
consider adaptive ridge penalised generalised linear and Cox models, in which
the variable specific ridge penalties are adapted to the co-data to give a
priori more weight to more important variables. The R-package ecpc originally
accommodated various and possibly multiple co-data sources, including
categorical co-data, i.e. groups of variables, and continuous co-data.
Continuous co-data, however, was handled by adaptive discretisation,
potentially inefficiently modelling and losing information. Here, we present an
extension to the method and software for generic co-data models, particularly
for continuous co-data. At the basis lies a classical linear regression model,
regressing prior variance weights on the co-data. Co-data variables are then
estimated with empirical Bayes moment estimation. After placing the estimation
procedure in the classical regression framework, extension to generalised
additive and shape constrained co-data models is straightforward. Besides, we
show how ridge penalties may be transformed to elastic net penalties with the
R-package squeezy. In simulation studies we first compare various co-data
models for continuous co-data from the extension to the original method.
Secondly, we compare variable selection performance to other variable selection
methods. Moreover, we demonstrate use of the package in several examples
throughout the paper.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:55:19 GMT""}]","2022-05-17"
"2205.07641","Cade Ribeiro Peters","Asher Klug, Cade Peters and Andrew Forbes","Robust structured light in atmospheric turbulence","11 pages, 9 figures. Submitted to Advanced Photonics",,,,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Structured light is routinely used in free space optical communication
channels, both classical and quantum, where information is encoded in the
spatial structure of the mode for increased bandwidth. Unlike polarisation, the
spatial structure of light is perturbed through such channels by atmospheric
turbulence, and consequently, much attention has focused on whether one mode
type is more robust than another, but with seemingly inconclusive and
contradictory results. Both real-world and experimentally simulated turbulence
conditions have revealed that free-space structured light modes are perturbed
in some manner by turbulence, resulting in both amplitude and phase
distortions. Here, we present complex forms of structured light which are
invariant under propagation through the atmosphere: the true eigenmodes of
atmospheric turbulence. We provide a theoretical procedure for obtaining these
eigenmodes and confirm their invariance both numerically and experimentally.
Although we have demonstrated the approach on atmospheric turbulence, its
generality allows it to be extended to other channels too, such as underwater
and in optical fibre.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:56:41 GMT""}]","2022-05-17"
"2205.07642","Celio Muniz","Marcony S. Cunha, G. Alencar, Celio R. Muniz, Valdir B. Bezerra, and
  Hor\'acio S. Vieira","Black strings from dark matter","16 pages. 9 figures",,"10.1016/j.aop.2023.169324",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we obtain two different static black string solutions by
considering as sources axisymmetric dark matter distributions in 3+1
dimensions. These solutions tend asymptotically to the usual static and
uncharged black string vacuum solution predicted by General Relativity (GR). We
show that both the solutions present an event horizon each, like the vacuum
solution, which is larger than the horizon of the latter. Then, we obtain the
Hawking temperature associated with the black string solutions. Differently
from what occurs with the static black string in the vacuum, we find that there
exists a linear density of mass (or tension) remnant associated with a
vanishing Hawking temperature for the obtained solutions. Thus, we analyze how
the presence of dark matter affects the occurrence of the remnants. Further, we
calculate other thermodynamic quantities, namely entropy, heat capacity, and
free energy per length unit, showing that thermal phase transitions can occur
in the presence of dark matter. We also analyze the weak (and null) energy
conditions and conclude that the dark matter does not behave like an exotic
fluid. Finally, we obtain the corresponding stationary solutions, determining
their tensions as functions of both the mass and angular momentum of the black
strings.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:56:57 GMT""},{""version"":""v2"",""created"":""Thu, 6 Apr 2023 14:50:03 GMT""}]","2023-05-17"
"2205.07643","Xuwen Zhang","Xuwen Zhang","A boundary maximum principle for stationary pair of varifolds with fixed
  contact angle","14 pages, 3 figures; major revision: a weakened boundary maximum
  principle is proved",,,,"math.DG math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note, we establish a boundary maximum principle for stationary pair
of varifolds satisfying fixed contact angle condition in any Riemannian
manifold with smooth boundary.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:59:24 GMT""},{""version"":""v2"",""created"":""Tue, 31 May 2022 01:10:26 GMT""},{""version"":""v3"",""created"":""Wed, 21 Sep 2022 07:08:44 GMT""},{""version"":""v4"",""created"":""Wed, 28 Sep 2022 05:50:11 GMT""}]","2022-09-29"
"2205.07644","Panyue Zhou","Jian He, Jing He and Panyue Zhou","Localization of n-exangulated categories","20 pages. arXiv admin note: text overlap with arXiv:2103.16907,
  arXiv:1709.06689 by other authors",,,,"math.RT math.CT","http://creativecommons.org/licenses/by/4.0/","  Nakaoka-Ogawa-Sakai considered the localization of an extriangulated
category. This construction unified the Serre quotient of abelian categories
and the Verdier quotient of triangulated categories. Recently,
Herschend-Liu-Nakaoka defined $n$-exangulated categories as a higher
dimensional analogue of extriangulated categories. Let $\mathcal C$ be an
$n$-exangulated category and $\mathcal{F}$ be a multiplicative system
satisfying mild assumption. In this article, we give a necessary and sufficient
condition for the localization of $\mathcal C$ be an $n$-exangulated category.
This way gives a new class of $n$-exangulated categories which are neither
$n$-exact nor $(n+2)$-angulated in general. Moreover, our result also
generalizes work by Nakaoka-Ogawa-Sakai.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:03:59 GMT""}]","2022-05-17"
"2205.07645","Feng Tian","Palle E.T. Jorgensen and James Tian","Dual pairs of operators, harmonic analysis of singular non-atomic
  measures and Krein-Feller diffusion",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that a Krein-Feller operator is naturally associated to a fixed
measure $\mu$, assumed positive, $\sigma$-finite, and non-atomic. Dual pairs of
operators are introduced, carried by the two Hilbert spaces,
$L^{2}\left(\mu\right)$ and $L^{2}\left(\lambda\right)$, where $\lambda$
denotes Lebesgue measure. An associated operator pair consists of two specific
densely defined (unbounded) operators, each one contained in the adjoint of the
other. This then yields a rigorous analysis of the corresponding
$\mu$-Krein-Feller operator as a closable quadratic form. As an application,
for a given measure $\mu$, including the case of fractal measures, we compute
the associated diffusion, semigroup, Dirichlet forms, and $\mu$-generalized
heat equation.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:06:14 GMT""}]","2022-05-17"
"2205.07646","Senjie Liang","Liang Huang, Senjie Liang, Feiyang Ye, Nan Gao","A Fast Attention Network for Joint Intent Detection and Slot Filling on
  Edge Devices","9 pages, 4 figures",,,,"cs.CL cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Intent detection and slot filling are two main tasks in natural language
understanding and play an essential role in task-oriented dialogue systems. The
joint learning of both tasks can improve inference accuracy and is popular in
recent works. However, most joint models ignore the inference latency and
cannot meet the need to deploy dialogue systems at the edge. In this paper, we
propose a Fast Attention Network (FAN) for joint intent detection and slot
filling tasks, guaranteeing both accuracy and latency. Specifically, we
introduce a clean and parameter-refined attention module to enhance the
information exchange between intent and slot, improving semantic accuracy by
more than 2%. FAN can be implemented on different encoders and delivers more
accurate models at every speed level. Our experiments on the Jetson Nano
platform show that FAN inferences fifteen utterances per second with a small
accuracy drop, showing its effectiveness and efficiency on edge devices.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:06:51 GMT""}]","2022-05-17"
"2205.07647","Till Kletti","Till Kletti, Jean-Michel Renders, Patrick Loiseau","Pareto-Optimal Fairness-Utility Amortizations in Rankings with a DBN
  Exposure Model","12 pages, 6 figures, published at SIGIR 2022",,"10.1145/3477495.3532036",,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, it has become clear that rankings delivered in many areas
need not only be useful to the users but also respect fairness of exposure for
the item producers. We consider the problem of finding ranking policies that
achieve a Pareto-optimal tradeoff between these two aspects. Several methods
were proposed to solve it; for instance a popular one is to use linear
programming with a Birkhoff-von Neumann decomposition. These methods, however,
are based on a classical Position Based exposure Model (PBM), which assumes
independence between the items (hence the exposure only depends on the rank).
In many applications, this assumption is unrealistic and the community
increasingly moves towards considering other models that include dependences,
such as the Dynamic Bayesian Network (DBN) exposure model. For such models,
computing (exact) optimal fair ranking policies remains an open question.
  We answer this question by leveraging a new geometrical method based on the
so-called expohedron proposed recently for the PBM (Kletti et al., WSDM'22). We
lay out the structure of a new geometrical object (the DBN-expohedron), and
propose for it a Carath\'eodory decomposition algorithm of complexity $O(n^3)$,
where $n$ is the number of documents to rank. Such an algorithm enables
expressing any feasible expected exposure vector as a distribution over at most
$n$ rankings; furthermore we show that we can compute the whole set of
Pareto-optimal expected exposure vectors with the same complexity $O(n^3)$. Our
work constitutes the first exact algorithm able to efficiently find a
Pareto-optimal distribution of rankings. It is applicable to a broad range of
fairness notions, including classical notions of meritocratic and demographic
fairness. We empirically evaluate our method on the TREC2020 and MSLR datasets
and compare it to several baselines in terms of Pareto-optimality and speed.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:07:32 GMT""}]","2022-05-17"
"2205.07648","Jiebin Peng","Yuanyang Du, Jiebin Peng, Zhong Shi, Jie Ren","Twisting the near-field radiative heat switch in hyperbolic
  antiferromagnets",,"Physical Review Applied 2023","10.1103/PhysRevApplied.19.024044",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the twisted control of the near-field radiative heat transfer
between two hyperbolic antiferromagnetic insulators under external magnetic
fields. We show that the near-field heat flux can be affected by both the twist
angle $\theta$ and the magnitude of the applied magnetic field with different
broken symmetries. Irrespective of twist angle, the external magnetic field
causes the radiative heat flux to change nonmonotonically, and the minimum heat
flux can be found with the magnetic fields of about 1.5 T. Such nonmonotonic
behavior is due to the fact that the magnetic field can radically change the
nature of the magnon polaritons with time reversal symmetry breaking. The field
not only affects the topological structure of surface magnon polaritons, but
also induces the volume magnon polaritons that progressively dominate the heat
transfer as the field increases. We further propose a twist-induced thermal
switch device with inversion symmetry breaking, which can severely regulate
radiative heat flux through different magnetic fields. Our findings account for
a characteristic modulation of radiative heat transfer with implications for
applications in dynamic thermal management.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:09:58 GMT""}]","2023-04-14"
"2205.07649","Tiexin Qin","Tiexin Qin and Shiqi Wang and Haoliang Li","Generalizing to Evolving Domains with Latent Structure-Aware Sequential
  Autoencoder","ICML 2022, code is available at https://github.com/WonderSeven/LSSAE",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Domain generalization aims to improve the generalization capability of
machine learning systems to out-of-distribution (OOD) data. Existing domain
generalization techniques embark upon stationary and discrete environments to
tackle the generalization issue caused by OOD data. However, many real-world
tasks in non-stationary environments (e.g. self-driven car system, sensor
measures) involve more complex and continuously evolving domain drift, which
raises new challenges for the problem of domain generalization. In this paper,
we formulate the aforementioned setting as the problem of evolving domain
generalization. Specifically, we propose to introduce a probabilistic framework
called Latent Structure-aware Sequential Autoencoder (LSSAE) to tackle the
problem of evolving domain generalization via exploring the underlying
continuous structure in the latent space of deep neural networks, where we aim
to identify two major factors namely covariate shift and concept shift
accounting for distribution shift in non-stationary environments. Experimental
results on both synthetic and real-world datasets show that LSSAE can lead to
superior performances based on the evolving domain generalization setting.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:11:29 GMT""},{""version"":""v2"",""created"":""Thu, 16 Jun 2022 06:17:15 GMT""}]","2022-06-17"
"2205.07650","Yuya Kanado","Yuya Kanado","The relation between a generalized Fibonacci sequence and the length of
  Cunningham chains","18 pages, 2 figures",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $p$ be a prime number. A chain $\{p,2p+1,4p+3,\cdots,(p+1)2^{l(p)-1}-1\}$
is called the Cunningham chain generated by $p$ if all elements are prime
number and $(p+1)2^{l(p)}-1$ is composite. Then $l(p)$ is called the length of
the Cunningham chain. It is conjectured by Bateman and Horn in 1962 that the
number of prime $p\leq N$ such that $l(p)\geq k$ is asymptotically equal to
$B_k N/(\log N)^k$ with a real $B_k>0$ for all natural number $k$. This
suggests that $l(p)=\Omega(\log p/\log\log p)$. However, so far no good
estimation is known. It has not even been proven whether $\limsup_{p\to\infty}
l(p)$ is infinite or not. All we know is that $l(p)=5$ if $p=2$ and $l(p)<p$
for odd $p$ by Fermat's little theorem. Let $\alpha\geq3$ be an integer. In
this article, a generalized Fibonacci sequence
$\mathcal{F}_\alpha=\{F_n\}_{n=0}^\infty$ is defined as $F_0=0,F_1=1,
F_{n+2}=\alpha F_{n+1}+F_n (n\geq0)$, and
${}_{\mathcal{F}_\alpha}\sigma(n)=\sum_{d\mid n, 0<d\in\mathcal{F}_\alpha}d$ is
called a divisor function on $\mathcal{F}_\alpha$. Then we obtain an
interesting relation between the iteration of ${}_{\mathcal{F}_\alpha}\sigma$
and the length of Cunningham chains. For two primes $p$ and $q$, the fact
$p=2q+1$ or $2q-1$ is equivalent to
${}_{\mathcal{F}_\alpha}\sigma({}_{\mathcal{F}_\alpha}\sigma(F_p))={}_{\mathcal{F}_\alpha}\sigma(F_q)$
for some $\alpha$. By this relation, we get $l(p)\ll\log p$ under a certain
condition. It seems that this sufficient condition is plausible by numerical
test. Furthermore, the condition, written in terms of prime numbers, can be
replaced by the condition written in terms of natural numbers. This implies
that the problem of upper estimation of $l(p)$ is reduced to that on natural
numbers.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:13:43 GMT""},{""version"":""v2"",""created"":""Tue, 17 May 2022 09:53:26 GMT""},{""version"":""v3"",""created"":""Sat, 21 May 2022 13:16:40 GMT""},{""version"":""v4"",""created"":""Tue, 24 May 2022 09:38:55 GMT""}]","2022-05-25"
"2205.07651","Philippe Gris","Philippe Gris, Nicolas Regnault, Humna Awan, Isobel Hook, Saurabh W.
  Jha, Michelle Lochner, Bruno Sanchez, Dan Scolnic, Mark Sullivan, Peter
  Yoachim and the LSST Dark Energy Science Collaboration","Designing an Optimal LSST Deep Drilling Program for Cosmology with Type
  Ia Supernovae","26 pages, 16 figures",,"10.3847/1538-4365/ac9e58",,"astro-ph.CO astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  The Vera C. Rubin Observatory's Legacy Survey of Space and Time is forecast
to collect a large sample of Type Ia supernovae (SNe Ia) that could be
instrumental in unveiling the nature of Dark Energy. The feat, however,
requires measuring the two components of the Hubble diagram - distance modulus
and redshift - with a high degree of accuracy. Distance is estimated from SNe
Ia parameters extracted from light curve fits, where the average quality of
light curves is primarily driven by survey parameters such as the cadence and
the number of visits per band. An optimal observing strategy is thus critical
for measuring cosmological parameters with high accuracy. We present in this
paper a three-stage analysis aiming at quantifying the impact of the Deep
Drilling (DD) strategy parameters on three critical aspects of the survey: the
redshift completeness (originating from the Malmquist cosmological bias), the
number of well-measured SNe Ia, and the cosmological measurements. Analyzing
the current LSST survey simulations, we demonstrate that the current DD survey
plans are characterized by a low completeness ($z~\sim$ 0.55-0.65), and
irregular and low cadences (few days) that dramatically decrease the size of
the well-measured SNe Ia sample. We then propose a modus operandi that provides
the number of visits (per band) required to reach higher redshifts. The results
of this approach are used to design a set of optimized DD surveys for SNe Ia
cosmology. We show that most accurate cosmological measurements are achieved
with Deep Rolling surveys characterized by a high cadence (one day), a rolling
strategy (each field observed at least two seasons), and two sets of fields:
ultra-deep ($z \gtrsim 0.8$) and deep ($z \gtrsim 0.6$) fields. We also
demonstrate that a deterministic scheduler including a gap recovery mechanism
is critical to achieve a high quality DD survey required for SNe Ia cosmology.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:15:56 GMT""}]","2023-01-12"
"2205.07652","Hongxuan Jiang","Hongxuan Jiang, Xuewen Liu and Zhiyong You","Photosphere Recession and Luminosity of Homologous Explosions Revisited","9 pages, 3 figures",,"10.3847/1538-4357/ac6f5b",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  By assuming the photosphere located at the outmost edge of the ejecta, Arnett
et al. (1980, 1982, 1989) presented the light curves of homologous explosions
in supernovae analytically and numerically to include recombination effects.
Actually as homologous expansion proceeds, the photosphere recedes deeper into
the ejecta. In this situation, the photosphere radius increases at early times
and decreases later on which can be described by a simple method proposed by
Liu et al. (2018). To study how the photosphere recession effect the luminosity
evolution, we impose a boundary condition on the photosphere to determine the
spatial and time distribution of the temperature of the ejecta which is
clarified to be reasonable. We find that the photosphere recession reduce the
luminosity compared with the previous result without the recession, which can
be tested with observations of Type-IIP supernovae.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:16:45 GMT""}]","2022-07-06"
"2205.07653","Paul Robin","P. Robin (1), T. Emmerich (1), A. Ismail (2 and 3), A. Nigu\`es (1),
  Y. You (2 and 3), G.-H. Nam (2 and 3), A. Keerthi (2 and 4), A. Siria (1), A.
  K. Geim (2 and 3), B. Radha (2 and 3), L. Bocquet (1) ((1) Laboratoire de
  Physique de l'Ecole normale Sup\'erieure, ENS, Universit\'e PSL, CNRS,
  Sorbonne Universit\'e, Universit\'e de Paris, Paris, France, (2) National
  Graphene Institute, The University of Manchester, Manchester, UK, (3)
  Department of Physics and Astronomy, The University of Manchester,
  Manchester, UK, (4) Department of Chemistry, University of Manchester,
  Manchester, UK)","Long-term memory and synapse-like dynamics in two-dimensional
  nanofluidic channels",,"Science 379, 161-167 (2023)","10.1126/science.adc9931",,"cond-mat.soft cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  Fine-tuned ion transport across nanoscale pores is key to many biological
processes such as neurotransmission. Recent advances have enabled the
confinement of water and ions to two dimensions, unveiling transport properties
unreachable at larger scales and triggering hopes to reproduce the ionic
machinery of biological systems. Here we report experiments demonstrating the
emergence of memory in the transport of aqueous electrolytes across
(sub)nanoscale channels. We unveiled two types of nanofluidic memristors,
depending on channel material and confinement, with memory from minutes to
hours. We explained how large timescales could emerge from interfacial
processes like ionic self-assembly or surface adsorption. Such behavior allowed
us to implement Hebbian learning with nanofluidic systems. This result lays the
ground for biomimetic computations on aqueous electrolytic chips.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:17:07 GMT""},{""version"":""v2"",""created"":""Sat, 11 Jun 2022 22:03:40 GMT""},{""version"":""v3"",""created"":""Wed, 22 Jun 2022 12:31:05 GMT""},{""version"":""v4"",""created"":""Tue, 17 Jan 2023 13:38:02 GMT""}]","2023-01-18"
"2205.07654","Una Pale","Una Pale, Tomas Teijeiro, David Atienza","Hyperdimensional computing encoding for feature selection on the use
  case of epileptic seizure detection",,,,,"cs.NE cs.LG eess.SP","http://creativecommons.org/licenses/by/4.0/","  The healthcare landscape is moving from the reactive interventions focused on
symptoms treatment to a more proactive prevention, from one-size-fits-all to
personalized medicine, and from centralized to distributed paradigms. Wearable
IoT devices and novel algorithms for continuous monitoring are essential
components of this transition. Hyperdimensional (HD) computing is an emerging
ML paradigm inspired by neuroscience research with various aspects interesting
for IoT devices and biomedical applications. Here we explore the not yet
addressed topic of optimal encoding of spatio-temporal data, such as
electroencephalogram (EEG) signals, and all information it entails to the HD
vectors. Further, we demonstrate how the HD computing framework can be used to
perform feature selection by choosing an adequate encoding. To the best of our
knowledge, this is the first approach to performing feature selection using HD
computing in the literature. As a result, we believe it can support the ML
community to further foster the research in multiple directions related to
feature and channel selection, as well as model interpretability.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:18:37 GMT""}]","2022-05-17"
"2205.07655","Vjacheslav Prokopov","Stanislav Alexeyev and Vyacheslav Prokopov","Extended Gravity Constraints at Different Scales",,"Universe 2022, 8(5), 283","10.3390/universe8050283",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We review a set of the possible ways to constrain extended gravity models at
Galaxy clusters scales (the regime of dark energy explanations and comparison
with $\Lambda CDM$), for black hole shadows, gravitational wave astronomy,
binary pulsars, Solar system and Large Hadron Collider (consequences for high
energy physics at TeV scale). The key idea is that modern experimental and
observational precise data gives a chance to go beyond the general relativity.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:19:47 GMT""}]","2022-05-17"
"2205.07656","Hilla De-Leon","Hilla De-Leon and Francesco Pederiva","Using a physical model and aggregate data to estimate the spreading of
  Covid-19 in Israel in the presence of waning immunity and competing variants","9 pages 8 figures",,,,"q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In more than two years since the COVID-19 virus was first detected in China,
hundreds of millions of individuals have been infected, and millions have died.
Aside from the immediate need for medical solutions (such as vaccines and
medications) to treat the epidemic, the Corona pandemic has strengthened the
demand for mathematical models that can predict the spread of the pandemic in
an ever-changing reality. Here, we present a novel, dynamic particle model
based on the basic principles of statistical physics that enables the
prediction of the spreading of Covid-19 in the presence of effective vaccines.
This particle model enables us to accurately examine the effects of the vaccine
on different subgroups of the vaccinated population and the entire population
and to identify the vaccine waning. Furthermore, a particle model can predict
the prevalence of two competing variants over time and their associated
morbidity.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:19:52 GMT""}]","2022-05-17"
"2205.07657","Arren Glover","Luna Gava, Marco Monforte, Massimiliano Iacono, Chiara Bartolozzi,
  Arren Glover","PUCK: Parallel Surface and Convolution-kernel Tracking for Event-Based
  Cameras","submitted to IROS 2022",,,,"cs.RO cs.CV","http://creativecommons.org/licenses/by/4.0/","  Low latency and accuracy are fundamental requirements when vision is
integrated in robots for high-speed interaction with targets, since they affect
system reliability and stability. In such a scenario, the choice of the sensor
and algorithms is important for the entire control loop. The technology of
event-cameras can guarantee fast visual sensing in dynamic environments, but
requires a tracking algorithm that can keep up with the high data rate induced
by the robot ego-motion while maintaining accuracy and robustness to
distractors. In this paper, we introduce a novel tracking method that leverages
the Exponential Reduced Ordinal Surface (EROS) data representation to decouple
event-by-event processing and tracking computation. The latter is performed
using convolution kernels to detect and follow a circular target moving on a
plane. To benchmark state-of-the-art event-based tracking, we propose the task
of tracking the air hockey puck sliding on a surface, with the future aim of
controlling the iCub robot to reach the target precisely and on time.
Experimental results demonstrate that our algorithm achieves the best
compromise between low latency and tracking accuracy both when the robot is
still and when moving.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:23:52 GMT""}]","2022-05-17"
"2205.07658","Jeppe C. Dyre","Ian M. Douglass and Jeppe C. Dyre","Distance-as-time in physical aging",,"Phys. Rev. E 106, 054615 (2022)","10.1103/PhysRevE.106.054615",,"cond-mat.soft cond-mat.mtrl-sci cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  Although it has been known for half a century that the physical aging of
glasses in experiments is described well by a linear thermal-history
convolution integral over the so-called material time, the microscopic
definition and interpretation of the material time remains a mystery. We
propose that the material-time increase over a given time interval reflects the
distance traveled by the system's particles. Different possible distance
measures are discussed, starting from the standard mean-square displacement and
its inherent-state version that excludes the vibrational contribution. The
viewpoint adopted, which is inspired by and closely related to pioneering works
of Cugliandolo and Kurchan of the 1990s, implies a ""geometric reversibility""
and a ""unique-triangle property"" characterizing the system's path in
configuration space during aging. Both of these properties are inherited from
equilibrium; they are confirmed by computer simulations of an aging binary
Lennard-Jones system. Our simulations show that the slow particles control the
material time. This motivates a ""dynamic-rigidity-percolation"" picture of
physical aging. The numerical data show that the material time is dominated by
the slowest particles' inherent mean-square displacement, which is conveniently
quantified by the inherent harmonic mean-square displacement. This distance
measure collapses data for potential-energy aging well in the sense that the
normalized relaxation functions following different temperature jumps are
almost the same function of the material time. Finally, the standard
Tool-Narayanaswamy linear material-time convolution integral description of
physical aging is derived from the assumption that when time is replaced by
distance in the above sense, an aging system is described by the same
expression as that of linear-response theory.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:24:01 GMT""},{""version"":""v2"",""created"":""Tue, 11 Oct 2022 15:42:15 GMT""}]","2022-11-30"
"2205.07659","Xinpeng Huang","Christian Gerhards, Xinpeng Huang, Alexander Kegeles","Relation between Hardy components for locally supported vector fields on
  the sphere",,,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  Given a function in the Hardy space of inner harmonic gradients on the
sphere, H+(S), we consider the problem of finding a corresponding function in
the Hardy space of outer harmonic gradients on the sphere, H-(S), such that the
sum of both functions differs from a locally supported vector field only by a
tangential divergence-free contribution. We characterize the subspace of H+(S)
that allows such a continuation and show that it is dense but not closed within
H+(S). Furthermore, we derive the linear mapping that maps a vector field from
this subspace of H+(S) to the corresponding unique vector field in H-(S). The
explicit construction uses layer potentials but involves unbounded operators.
We indicate some bounded extremal problems supporting a possible numerical
evaluation of this mapping between the Hardy components. The original
motivation to study this problem comes from an inverse magnetization problem
with localization constraints.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:25:01 GMT""}]","2022-05-17"
"2205.07660","Iris Breda","Iris Breda, Jos\'e M. Vilchez, Polychronis Papaderos, Leandro Cardoso,
  Ricardo O. Amorin, Antonio Arroyo-Polonio, Jorge Iglesias-P\'aramo, Carolina
  Kehrig, Enrique P\'erez-Montero","Characterisation of the stellar content of SDSS EELGs through
  self-consistent spectral modelling","14 pages, 13 figures, accepted for publication in A&A","A&A 663, A29 (2022)","10.1051/0004-6361/202142805",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Extreme emission line galaxies (EELGs) are a notable galaxy genus, ultimately
being regarded as local prototypes of early galaxies at the cosmic noon. Robust
characterisation of their stellar content, however, is hindered by the
exceptionally high nebular emission present in their optical spectroscopic
data. This study is dedicated into recovering the stellar properties of a
sample of 414 EELGs as observed by the SDSS Survey. Such is achieved by means
of the spectral synthesis code FADO, which self-consistently considers the
stellar and nebular emission in an optical spectrum. Additionally, a
comparative analysis was carried on, by further processing the EELGs sample
with the purely stellar spectral synthesis code Starlight, and by extending the
analysis to a sample of 697 normal star-forming galaxies, expected to be less
affected by nebular contribution. We find that, for both galaxy samples,
stellar mass and mean age estimates by Starlight are systematically biased
towards higher values, and that an adequate determination of the physical and
evolutionary properties of EELGs via spectral synthesis is only possible when
nebular continuum emission is taken into account. Moreover, the differences
between the two population synthesis codes can be ascribed to the degree of
star-formation activity through the specific star-formation rate and the sum of
the flux of the most prominent emission lines. As expected, on the basis of the
theoretical framework, our results emphasise the importance of considering the
nebular emission while performing spectral synthesis, even for galaxies hosting
typical levels of star-formation activity.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:25:31 GMT""}]","2022-07-13"
"2205.07661","Xiao-Yun Wang","Xiao-Yun Wang, Fancong Zeng, Igor I. Strakovsky","The $\psi^{(\ast)}p$ scattering length based on near-threshold
  charmoniums photoproduction","7 pages, 7 figures","Phys. Rev. C 106, 015202 (2022)","10.1103/PhysRevC.106.015202",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  Under the framework of Vector Meson Dominance model, the value of scattering
length can be expressed as a function of the ratio between total cross section
$\sigma (W)$ and $R (W)$, where $R(W)$ is the ratio between final momentum
$|{\bf p}_3 |$ and initial momentum $|{\bf p}_1|$ and positively correlated
with the center-of-mass energy. Based on the theoretical study of charmoniums
photoproduction within two gluon exchange model and effective pomeron model, we
research the scattering lengths of vector mesons and proton interaction in this
work. Results show that the scattering length $\left|\alpha_{J/\psi p}\right|$
obtained from the two models are close and basically in agreement with the
theoretical prediction of Strakovsky and co-workers. Additionally, we first
calculate the scattering length of $\psi(2S) $-proton interaction in two gluon
exchange model and effective pomeron model as $ 1.31\pm 0.92$ am (1 am =
$10^{-3}$ fm) and $ 3.24 \pm 0.63$ am, respectively. This is a little bit
different from the two models and requires precise measurements from subsequent
experiments. In short, our results will provide a theoretical reference for
future studies on characterizing the vector meson-proton scattering length.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:25:35 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jul 2022 00:59:59 GMT""}]","2022-07-20"
"2205.07662","Xiao-Ping Li","Xiao-Ping Li, Feng Li, Di Zhou, Ying Wu, Zhi-Ming Yu, and Yugui Yao","Observation of Single Pair of Type-III Weyl Points in Sonic Crystals",,,"10.1103/PhysRevB.106.L220302",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In electronics systems, the Weyl points can be classified into three types
based on the geometry of the Fermi surface, and each type exhibits various
unique and intriguing phenomena. While the type-I and type-II Weyl points have
been achieved in both spinful and spinless systems, the realization of type-III
Weyl points remains challenging, and has not been reported in artificial
periodic systems. Here, we for the first time report the experimental
observation of the type-III Weyl points in a sonic crystal. Remarkably, a
single pair of type-III Weyl points are observed as the only band crossings in
a frequency range, experimentally disproving a common belief in the field,
namely, the minimal number of Weyl points in nonmagnetic systems is four. The
consistency between experimental results and theoretical predictions confirms
the existence of type-III Weyl points, noncontractible Fermi arc surface
states, and chiral edge states. Our work not only fill the gap of the type-III
Weyl point in sonic crystal but also stimulate related researches in other
systems, such as photonic, mechanical and cold atom systems.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:25:37 GMT""}]","2022-12-21"
"2205.07663","Matthias Frey","Matthias Frey and Igor Bjelakovi\'c and Janis N\""otzel and S{\l}awomir
  Sta\'nczak","Semantic Security with Infinite Dimensional Quantum Eavesdropping
  Channel",,,,,"cs.IT math.IT quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new proof method for direct coding theorems for wiretap channels
where the eavesdropper has access to a quantum version of the transmitted
signal on an infinite-dimensional Hilbert space and the legitimate parties
communicate through a classical channel or a classical input, quantum output
(cq) channel. The transmitter input can be subject to an additive cost
constraint, which specializes to the case of an average energy constraint. This
method yields errors that decay exponentially with increasing block lengths.
Moreover, it provides a guarantee of a quantum version of semantic security,
which is an established concept in classical cryptography and physical layer
security. Therefore, it complements existing works which either do not prove
the exponential error decay or use weaker notions of security. The main part of
this proof method is a direct coding result on channel resolvability which
states that there is only a doubly exponentially small probability that a
standard random codebook does not solve the channel resolvability problem for
the cq channel. Semantic security has strong operational implications meaning
essentially that the eavesdropper cannot use its quantum observation to gather
any meaningful information about the transmitted signal. We also discuss the
connections between semantic security and various other established notions of
secrecy.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:25:56 GMT""},{""version"":""v2"",""created"":""Mon, 5 Jun 2023 12:54:48 GMT""}]","2023-06-08"
"2205.07664","Mario Rom\'an","Mario Rom\'an","Promonads and String Diagrams for Effectful Categories","15 pages, 28 pages including bibliography and appendix, 28 figures.
  Presented at ACT 2022. Referee's suggestions incorporated, minor fixes, added
  references for related work",,,,"math.CT cs.LO","http://creativecommons.org/licenses/by/4.0/","  Premonoidal and Freyd categories are both generalized by non-cartesian Freyd
categories: effectful categories. We construct string diagrams for effectful
categories in terms of the string diagrams for a monoidal category with a
freely added object. We show that effectful categories are pseudomonoids in a
monoidal bicategory of promonads with a suitable tensor product.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:27:52 GMT""},{""version"":""v2"",""created"":""Tue, 30 Aug 2022 13:47:15 GMT""}]","2022-08-31"
"2205.07665","Hiroyasu  Koizumi","Hiroyasu Koizumi","Schroedinger representation of quantum mechanics, Berry connection, and
  superconductivity",,,"10.1016/j.physleta.2022.128367",,"cond-mat.supr-con physics.chem-ph physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  The standard quantum mechanical electronic state calculations for molecules
and solids uses the Schroedinger representation where the momentum conjugate to
the coordinate $q_r$ is given by $-hbar {partial over {partial q_r}}$. This
formalism contains an extra $U(1)$ phase degree-of-freedom. We show that it can
be regarded as a Berry phase arising from many-electron interaction, and when
it is non-trivial, it gives rise to a current carrying ground state identified
as the superconducting ground state. The connection between this
superconducting state and the BCS one is presented.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:31:11 GMT""}]","2022-09-07"
"2205.07666","Jiebin Peng","Rongqian Wang, Jincheng Lu, Xiaohu Wu, Jiebin Peng, Jian-Hua Jiang","Tuning Topological Transitions in Twisted Thermophotovoltaic Systems",,,,,"cond-mat.mes-hall physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Twisted bilayer two-dimensional electronic systems give rise to many exotic
phenomena and unveil a new frontier for the study of quantum materials. In
photonics, twisted two-dimensional systems coupled via near-field interactions
offer a platform to study localization and lasing. Here, we propose that
twisting can be an unprecedented tool to tune the performance of near-field
thermophotovoltaic systems. Remarkably, through twisting-induced photonic
topological transitions, we achieve significant tuning of the
thermophotovoltaic energy efficiency and power. The underlying mechanism is
related to the change of the photonic iso-frequency contours from elliptical to
hyperbolic geometries in a setup where the hexagonal-boron-nitride metasurface
serves as the heat source and the indium antimonide $p$-$n$ junction serves as
the cell. We find a notably high energy efficiency, nearly 53\% of the Carnot
efficiency, can be achieved in our thermophotovoltaic system, while the output
power can reach to $1.1\times10^4$~W/m$^2$ without requiring a large
temperature difference between the source and the cell. Our results indicate
the promising future of twisted near-field thermophotovoltaics and paves the
way towards tunable, high-performance thermophotovoltaics and infrared
detection.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:32:55 GMT""}]","2022-05-17"
"2205.07667","Tobias Boege","Tobias Boege","Selfadhesivity in Gaussian conditional independence structures","15 pages; v2: minor revision and extension",,,,"cs.IT math.CO math.IT math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Selfadhesivity is a property of entropic polymatroids which can be formulated
as gluability conditions of the polymatroid to an identical copy of itself
along arbitrary restrictions and such that the two pieces are independent given
the common restriction. We show that positive definite matrices satisfy this
condition as well and examine consequences for Gaussian conditional
independence structures. New axioms of Gaussian CI are obtained by applying
selfadhesivity to the previously known axioms of structural semigraphoids and
orientable gaussoids.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:33:01 GMT""},{""version"":""v2"",""created"":""Fri, 27 Jan 2023 16:58:11 GMT""}]","2023-01-30"
"2205.07668","Josep Ingla-Ayn\'es","Josep Ingla-Ayn\'es, Inge Groen, Franz Herling, Nerea Ontoso, C. K.
  Safeer, Fernando de Juan, Luis E. Hueso, Marco Gobbi, F\`elix Casanova","Omnidirectional spin-to-charge conversion in graphene/NbSe$_2$ van der
  Waals heterostructures",,,"10.1088/2053-1583/ac76d1",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The conversion of spin currents polarized in different directions into charge
currents is a keystone for novel spintronic devices. Van der Waals
heterostructures with tailored symmetry are a very appealing platform for such
a goal. Here, by performing nonlocal spin precession experiments, we
demonstrate the spin-to-charge conversion (SCC) of spins oriented in all three
directions (x, y, and z). By analyzing the magnitude and temperature dependence
of the signal in different configurations, we argue that the different SCC
components measured are likely due to spin-orbit proximity and broken symmetry
at the twisted graphene/NbSe$_2$ interface. Such efficient omnidirectional SCC
opens the door to the use of new architectures in spintronic devices, from
spin-orbit torques that can switch any magnetization to the magnetic state
readout of magnetic elements pointing in any direction.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:33:42 GMT""}]","2022-06-28"
"2205.07669","Julia Gonski","Julia Gonski (on behalf of the ATLAS Collaboration)","Highlights from Long-Lived Particle Searches at ATLAS","Contribution to the 2022 QCD session of the 56th Rencontres de
  Moriond",,,,"hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The latest results of long-lived particle (LLP) searches from the ATLAS
Experiment at the Large Hadron Collider are presented. Analyses are presented
with a focus on detector subsystem needed to discern the LLP signature from
Standard Model background, and the custom reconstruction requirements for
sensitivity. Results are contextualized with updated summary plots for key new
physics candidates, along with notes for future LLP searches.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:35:51 GMT""},{""version"":""v2"",""created"":""Tue, 17 May 2022 10:15:09 GMT""}]","2022-05-18"
"2205.07670","Binbin Zhang","B.-B. Zhang, Z. J. Zhang, J.-H. Zou, X. I. Wang, Y.-H. Yang, J.-S.
  Wang, J. Yang, Z.-K. Liu, Z.-K. Peng, Y.-S. Yang, Z.-H. Li, Y.-C. Ma, B.
  Zhang","A hyper flare of a weeks-old magnetar born from a binary-neutron-star
  merger","17 pages, 12 figures, 4 tables",,,,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Magnetars, a population of isolated neutron stars with ultra-strong magnetic
fields of $\sim 10^{14}-10^{15}$ G, have been increasingly accepted to explain
a variety of astrophysical transients. A nascent millisecond-period magnetar
can release its spin-down energy and power bright sources such as Gamma-ray
Bursts (GRBs) and their subsequent X-ray plateaus, Super Luminous Supernovae
(SLSNe), and the fast X-ray transients such as CDF-S XT-2. Magnetars with ages
of $10^3-10^4$ years have been observed within the Milky Way Galaxy, which are
found to power diverse transients with the expense of their magnetic energy, in
the form of giant flares and repeated soft-$\gamma$-ray or hard X-ray bursts
and occasionally fast radio bursts (FRBs). Magnetar giant flares were also
detected as disguised short GRBs from nearby galaxies . Here we report the
identification of a GRB as a hyper flare of magnetar in a nearby galaxy. The
magnitude of the hyper flare is about one thousand times brighter than that of
a typical magnetar giant flare. A significant $\sim 80$ millisecond period is
detected in the decaying light curve. Interpreting this period as the rotation
period and given a magnetic field strength typical for a young magnetar, the
age of the magnetar is constrained to be only a few weeks. The non-detection of
a (superluminous) supernova nor a GRB weeks before the event further constrains
that the magnetar is likely born from an off-axis merger event of two neutron
stars. Our finding bridges the gap between the hypothetical millisecond
magnetars and the observed Galactic magnetars, and points toward a broader
channel of magnetar-powered gamma-ray transients.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:35:58 GMT""}]","2022-05-17"
"2205.07671","George Boateng","George Boateng, Prabhakaran Santhanam, Elgar Fleisch, Janina
  L\""uscher, Theresa Pauly, Urte Scholz, Tobias Kowatsch","Development, Deployment, and Evaluation of DyMand -- An Open-Source
  Smartwatch and Smartphone System for Capturing Couples' Dyadic Interactions
  in Chronic Disease Management in Daily Life","25 pages, Under review at ACM IMWUT",,,,"cs.HC cs.CY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Dyadic interactions of couples are of interest as they provide insight into
relationship quality and chronic disease management. Currently, ambulatory
assessment of couples' interactions entails collecting data at random or
scheduled times which could miss significant couples' interaction/conversation
moments. In this work, we developed, deployed and evaluated DyMand, a novel
open-source smartwatch and smartphone system for collecting self-report and
sensor data from couples based on partners' interaction moments. Our
smartwatch-based algorithm uses the Bluetooth signal strength between two
smartwatches each worn by one partner, and a voice activity detection
machine-learning algorithm to infer that the partners are interacting, and then
to trigger data collection. We deployed the DyMand system in a 7-day field
study and collected data about social support, emotional well-being, and health
behavior from 13 (N=26) Swiss-based heterosexual couples managing diabetes
mellitus type 2 of one partner. Our system triggered 99.1% of the expected
number of sensor and self-report data when the app was running, and 77.6% of
algorithm-triggered recordings contained partners' conversation moments
compared to 43.8% for scheduled triggers. The usability evaluation showed that
DyMand was easy to use. DyMand can be used by social, clinical, or health
psychology researchers to understand the social dynamics of couples in everyday
life, and for developing and delivering behavioral interventions for couples
who are managing chronic diseases.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:37:42 GMT""}]","2022-05-17"
"2205.07672","Tristan Britt","Tristan L. Britt, Qiuyang Li, Laurent P. Ren\'e de Cotret, Nicholas
  Olsen, Martin Otto, Syed Ali Hassan, Marios Zacharias, Fabio Caruso, Xiaoyang
  Zhu, Bradley J. Siwick","Direct view of phonon dynamics in atomically thin MoS$_{2}$",,,"10.1021/acs.nanolett.2c00850",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Transition metal dichalcogenide monolayers and heterostructures are highly
tunable material systems that provide excellent models for physical phenomena
at the two-dimensional (2D) limit. While most studies to date have focused on
electrons and electron-hole pairs, phonons also play essential roles. Here, we
apply ultrafast electron diffraction and diffuse scattering to directly
quantify, with time and momentum resolution, electron-phonon coupling (EPC) in
monolayer molybdenum disulfide (MoS$_{2}$) and phonon transport from the
monolayer to a silicon nitride (Si$_3$N$_4$) substrate. Optically generated hot
carriers result in a profoundly anisotropic distribution of phonons in the
monolayer on the $\sim$ 5 ps time scale. A quantitative comparison with
ab-initio ultrafast dynamics simulations reveals the essential role of
dielectric screening in weakening EPC. Thermal transport from the monolayer to
the substrate occurs with the phonon system far from equilibrium. While
screening in 2D is known to strongly affect equilibrium properties, our
findings extend this understanding to the dynamic regime.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:39:43 GMT""}]","2022-07-13"
"2205.07673","Junkang Wei","Junkang Wei, Jin Xiao, Siyuan Chen, Licheng Zong, Xin Gao, Yu Li","ProNet DB: A proteome-wise database for protein surface property
  representations and RNA-binding profiles","12 pages, 6 figures",,,,"q-bio.QM q-bio.BM q-bio.MN","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The rapid growth in the number of experimental and predicted protein
structures and more complicated protein structures challenge users in
computational biology for utilizing the structural information and protein
surface property representation. Recently, AlphaFold2 released the
comprehensive proteome of various species, and protein surface property
representation plays a crucial role in protein-molecule interaction prediction
such as protein-protein interaction, protein-nucleic acid interaction, and
protein-compound interaction. Here, we propose the first comprehensive
database, namely ProNet DB, which incorporates multiple protein surface
representations and RNA-binding landscape for more than 33,000 protein
structures covering the proteome from AlphaFold Protein Structure Database
(AlphaFold DB) and experimentally validated protein structures deposited in
Protein Data Bank (PDB). For each protein, we provide the original protein
structure, surface property representation including hydrophobicity, charge
distribution, hydrogen bond, interacting face, and RNA-binding landscape such
as RNA binding sites and RNA binding preference. To interpret protein surface
property representation and RNA binding landscape intuitively, we also
integrate Mol* and Online 3D Viewer to visualize the representation on the
protein surface. The pre-computed features are available for the users
instantaneously and their potential applications are including molecular
mechanism exploration, drug discovery, and novel therapeutics development. The
server is now available on https://proj.cse.cuhk.edu.hk/pronet/ and future
releases will expand the species and property coverage.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:40:33 GMT""}]","2022-05-17"
"2205.07674","Oriel Kiss","Oriel Kiss, Michele Grossi, Enrique Kajomovitz and Sofia Vallecorsa","Conditional Born machine for Monte Carlo event generation","12 pages, 9 figures, 6 tables","Physical Review A 106, 022612 (2022)","10.1103/PhysRevA.106.022612",,"quant-ph cs.LG hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generative modeling is a promising task for near-term quantum devices, which
can use the stochastic nature of quantum measurements as a random source. So
called Born machines are purely quantum models and promise to generate
probability distributions in a quantum way, inaccessible to classical
computers. This paper presents an application of Born machines to Monte Carlo
simulations and extends their reach to multivariate and conditional
distributions. Models are run on (noisy) simulators and IBM Quantum
superconducting quantum hardware.
  More specifically, Born machines are used to generate muonic force carrier
(MFC) events resulting from scattering processes between muons and the detector
material in high-energy physics colliders experiments. MFCs are bosons
appearing in beyond-the-standard-model theoretical frameworks, which are
candidates for dark matter. Empirical evidence suggests that Born machines can
reproduce the marginal distributions and correlations of data sets from Monte
Carlo simulations.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:41:03 GMT""},{""version"":""v2"",""created"":""Mon, 22 Aug 2022 16:39:58 GMT""}]","2022-08-23"
"2205.07675","Hector Socas-Navarro","Hector Socas-Navarro","A candidate location for Planet Nine from an interstellar meteoroid: The
  messenger hypothesis","Accepted for publication in ApJ",,"10.3847/1538-4357/acb817",,"astro-ph.EP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The existence of a hypothetical Planet 9 lurkng in the outer solar system has
been invoked as a plausible explanation for the anomalous clustering in the
orbits of trans-Neptunian objects. Here we propose that some meteoroids
arriving at Earth could serve as messengers with the potential of revealing the
presence of a hitherto undiscovered massive object. The peculiar meteor CNEOS
2014-01-08, recently put forward as the first interstellar meteor, might be one
such messenger. The meteor radiant is in the maximum probability region
calculated for the Planet 9 location in previous works. The odds of this
coincidence being due to chance are ~1%. Furthermore, some statistical
anomalies about CNEOS 2014-01-08 are resolved under the hypothesis that it was
flung at Earth by a gravitational encounter. Integrating its trajectory
backwards in time would then lead to the region of the sky where Planet 9 is
more likely to reside. Based on the available data, we propose the region at
coordinates R.A. 53.0 +/- 4.3 deg, declination 9.2 +/- 1.3 deg as a plausible
candidate location for Planet 9.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:41:10 GMT""},{""version"":""v2"",""created"":""Mon, 23 May 2022 14:02:31 GMT""},{""version"":""v3"",""created"":""Sun, 25 Sep 2022 15:48:34 GMT""},{""version"":""v4"",""created"":""Tue, 31 Jan 2023 15:18:34 GMT""}]","2023-03-08"
"2205.07676","Kohei Soga","Kohei Soga","A remark on Tonelli's calculus of variations",,,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper provides a quite simple method of Tonelli's calculus of variations
with positive definite and superlinear Lagrangians. The result complements the
classical literature of calculus of variations before Tonelli's modern
approach. Inspired by Euler's spirit, the proposed method employs finite
dimensional approximation of the exact action functional, whose minimizer is
easily found as a solution of Euler's discretization of the exact
Euler-Lagrange equation. The Euler-Cauchy polygonal line generated by the
approximate minimizer converges to an exact smooth minimizing curve. This
framework yields an elementary proof of the existence and regularity of
minimizers within the family of smooth curves and hence, with a minor
additional step, within the family of Lipschitz curves, without using modern
functional analysis on absolutely continuous curves and lower semicontinuity of
action functionals.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:41:19 GMT""},{""version"":""v2"",""created"":""Wed, 26 Apr 2023 06:52:40 GMT""}]","2023-04-27"
"2205.07677","Luca Verginer","Giacomo Vaccario, Luca Verginer, Antonios Garas, Mario V. Tomasello
  and Frank Schweitzer","Network embeddedness indicates the innovation potential of firms",,,,,"econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Firms' innovation potential depends on their position in the R&D network. But
details on this relation remain unclear because measures to quantify network
embeddedness have been controversially discussed. We propose and validate a new
measure, coreness, obtained from the weighted k-core decomposition of the R&D
network. Using data on R&D alliances, we analyse the change of coreness for
14,000 firms over 25 years and patenting activity. A regression analysis
demonstrates that coreness explains firms' R&D output by predicting future
patenting.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:41:42 GMT""}]","2022-05-17"
"2205.07678","Hidde Vuijk","Hidde D. Vuijk, Sophie Klempahn, Holger Merlitz, Jens-Uwe Sommer, and
  Abhinav Sharma","Active Colloidal Molecules in Activity Gradients",,,"10.1103/PhysRevE.106.014617",,"cond-mat.soft cond-mat.stat-mech physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  We consider a rigid assembly of two active Brownian particles, forming an
active colloidal dimer, in a gradient of activity. We show analytically that
depending on the relative orientation of the two particles the active dimer
accumulates in regions of either high or low activity, corresponding to,
respectively, chemotaxis and antichemotaxis. Certain active dimers show both
chemotactic and antichemotactic behavior, depending on the strength of the
activity. Our coarse-grained Fokker-Planck approach yields an effective
potential, which we use to construct a nonequilibrium phase diagram that
classifies the dimers according to their tactic behavior. Moreover, we show
that for certain dimers a higher persistence of the motion is achieved similar
to the effect of a steering wheel in macroscopic devices. This work could be
useful for designing autonomous active colloidal structures which adjust their
motion depending on the local activity gradients.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:41:57 GMT""},{""version"":""v2"",""created"":""Tue, 17 May 2022 06:36:43 GMT""},{""version"":""v3"",""created"":""Thu, 7 Jul 2022 08:13:37 GMT""}]","2022-08-17"
"2205.07679","Takanori Motoki","Takanori Motoki, Rempei Sasada, Takuma Tomihisa, Masaya Miwa,
  Shin-ichi Nakamura, Jun-ichi Shimoyama","Development of homogeneous and high-performance REBCO bulks with
  flexibility in shapes by the single-direction melt growth (SDMG) method","8 pages, 6 figures, 2 tables",,"10.1088/1361-6668/ac811e",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have developed a single-direction melt growth method in which REBCO
melt-textured bulks grow only vertically from a seed plate utilizing the
difference in peritectic temperatures of REBCO. Entirely c-grown YBCO, DyBCO
and GdBCO bulks with various sizes and shapes were successfully fabricated with
high reproducibility. Disk-shaped bulks showed high trapped fields with almost
concentric field distributions, reflecting homogeneous and boundaryless bulky
crystal. In particular, a YBCO bulk with a 32 mm diameter trapped a high field
more than 1 T at 77 K. Furthermore, rectangular and joined hexagonal REBCO
bulks were successfully fabricated, showing designed field-trapping
distributions reflecting their shapes through well-connected superconducting
joints among bulks.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:43:25 GMT""}]","2022-07-25"
"2205.07680","Bin Liu","Bo Li, Kaitao Xue, Bin Liu, Yu-Kun Lai","BBDM: Image-to-image Translation with Brownian Bridge Diffusion Models","18 pages, 13 figures",,,,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Image-to-image translation is an important and challenging problem in
computer vision and image processing. Diffusion models (DM) have shown great
potentials for high-quality image synthesis, and have gained competitive
performance on the task of image-to-image translation. However, most of the
existing diffusion models treat image-to-image translation as conditional
generation processes, and suffer heavily from the gap between distinct domains.
In this paper, a novel image-to-image translation method based on the Brownian
Bridge Diffusion Model (BBDM) is proposed, which models image-to-image
translation as a stochastic Brownian bridge process, and learns the translation
between two domains directly through the bidirectional diffusion process rather
than a conditional generation process. To the best of our knowledge, it is the
first work that proposes Brownian Bridge diffusion process for image-to-image
translation. Experimental results on various benchmarks demonstrate that the
proposed BBDM model achieves competitive performance through both visual
inspection and measurable metrics.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:47:02 GMT""},{""version"":""v2"",""created"":""Thu, 23 Mar 2023 08:29:12 GMT""}]","2023-03-24"
"2205.07681","Matthew R. Bate","Matthew R. Bate","Dust coagulation during the early stages of star formation: molecular
  cloud collapse and first hydrostatic core evolution","Accepted for publication in MNRAS. 17 pages, 14 figures. 5 animations
  available at: http://www.astro.ex.ac.uk/people/mbate/Research/DustGrowth.html",,"10.1093/mnras/stac1391",,"astro-ph.GA astro-ph.EP astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Planet formation in protoplanetary discs requires dust grains to coagulate
from the sub-micron sizes that are found in the interstellar medium into much
larger objects. For the first time, we study the growth of dust grains during
the earliest phases of star formation using three-dimensional hydrodynamical
simulations. We begin with a typical interstellar dust grain size distribution
and study dust growth during the collapse of a molecular cloud core and the
evolution of the first hydrostatic core, prior to the formation of the stellar
core. We examine how the dust size distribution evolves both spatially and
temporarily. We find that the envelope maintains its initial population of
small dust grains with little growth during these phases, except that in the
inner few hundreds of au the smallest grains are depleted. However, once the
first hydrostatic core forms rapid dust growth to sizes in excess of $100~\mu$m
occurs within the core (before stellar core formation). Progressively larger
grains are produced at smaller distances from the centre of the core. In
rapidly-rotating molecular cloud cores, the `first hydrostatic core' that forms
is better described as a pre-stellar disc that may be gravitationally unstable.
In such cases, grain growth is more rapid in the spiral density waves leading
to the larger grains being preferentially found in the spiral waves even though
there is no migration of grains relative to the gas. Thus, the grain size
distribution can vary substantially in the first core/pre-stellar disc even at
these very early times.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:49:00 GMT""}]","2022-06-01"
"2205.07682","Mattia Giovanni Campana","Mattia Giovanni Campana, Andrea Rovati, Franca Delmastro, Elena Pagani","L3-Net Deep Audio Embeddings to Improve COVID-19 Detection from
  Smartphone Data","accepted for IEEE SMARTCOMP 2022",,,,"cs.SD cs.LG eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Smartphones and wearable devices, along with Artificial Intelligence, can
represent a game-changer in the pandemic control, by implementing low-cost and
pervasive solutions to recognize the development of new diseases at their early
stages and by potentially avoiding the rise of new outbreaks. Some recent works
show promise in detecting diagnostic signals of COVID-19 from voice and coughs
by using machine learning and hand-crafted acoustic features. In this paper, we
decided to investigate the capabilities of the recently proposed deep embedding
model L3-Net to automatically extract meaningful features from raw respiratory
audio recordings in order to improve the performances of standard machine
learning classifiers in discriminating between COVID-19 positive and negative
subjects from smartphone data. We evaluated the proposed model on 3 datasets,
comparing the obtained results with those of two reference works. Results show
that the combination of L3-Net with hand-crafted features overcomes the
performance of the other works of 28.57% in terms of AUC in a set of
subject-independent experiments. This result paves the way to further
investigation on different deep audio embeddings, also for the automatic
detection of different diseases.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:50:22 GMT""}]","2022-05-17"
"2205.07683","Alin Popa","Ionut-Catalin Sandu and Daniel Voinea and Alin-Ionut Popa","CONSENT: Context Sensitive Transformer for Bold Words Classification",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present CONSENT, a simple yet effective CONtext SENsitive Transformer
framework for context-dependent object classification within a fully-trainable
end-to-end deep learning pipeline. We exemplify the proposed framework on the
task of bold words detection proving state-of-the-art results. Given an image
containing text of unknown font-types (e.g. Arial, Calibri, Helvetica), unknown
language, taken under various degrees of illumination, angle distortion and
scale variation, we extract all the words and learn a context-dependent binary
classification (i.e. bold versus non-bold) using an end-to-end
transformer-based neural network ensemble. To prove the extensibility of our
framework, we demonstrate competitive results against state-of-the-art for the
game of rock-paper-scissors by training the model to determine the winner given
a sequence with $2$ pictures depicting hand poses.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:50:33 GMT""}]","2022-05-17"
"2205.07684","Thomas Blomme","Thomas Blomme","Tropical curves in abelian surfaces III: pearl diagrams and multiple
  cover formulas","46 pages, 5 figures, comments welcome",,,,"math.AG math.CO","http://creativecommons.org/licenses/by/4.0/","  This paper is the third installment in a series of papers devoted to the
computation of enumerative invariants of abelian surfaces through the tropical
approach. We develop a pearl diagram algorithm similar to the floor diagram
algorithm used in toric surfaces that concretely solves the tropical problem.
  These diagrams can be used to prove specific cases of Oberdieck's multiple
cover formula that reduce the computation of invariants for non-primitive
classes to the primitive case, getting rid of all diagram considerations and
providing short explicit formulas. The latter can be used to prove the
quasi-modularity of generating series of classical invariants, and the
polynomiality of coefficients of fixed codegree in the refined invariants.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:51:25 GMT""}]","2022-05-17"
"2205.07685","Gestur Olafsson","Karl-Hermann Neeb and Gestur Olafsson","Wedge domains in non-compactly causal symmetric spaces","Minor changes and clarifications",,,,"math-ph math.MP math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article is part of an ongoing project aiming at the connections between
causal structures on homogeneous spaces, Algebraic Quantum Field Theory (AQFT),
modular theory of operator algebras and unitary representations of Lie groups.
In this article we concentrate on non-compactly causal symmetric space $G/H$.
This class contains the de Sitter space but also other spaces with invariant
partial ordering.
  The central ingredient is an Euler element h in the Lie algebra of \fg. We
define three different kinds of wedge domains depending on h and the causal
structure on G/H. Our main result is that the connected component containing
the base point eH of those seemingly different domains all agree. Furthermore
we discuss the connectedness of those wedge domains. We show that each of those
spaces has a natural extension to a non-compactly causal symmetric space of the
form G_\C/G^c where G^c is certain real form of the complexification G_\$ of G.
As G_\C/G^c is non-compactly causal it also comes with the three types of wedge
domains. Our results says that the intersection of those domains with $G/H$
agrees with the wedge domains in G/H.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:52:36 GMT""},{""version"":""v2"",""created"":""Sat, 30 Jul 2022 18:54:51 GMT""},{""version"":""v3"",""created"":""Thu, 27 Oct 2022 15:55:15 GMT""}]","2022-10-28"
"2205.07686","Dongling Xiao","Dongling Xiao, Linzheng Chai, Qian-Wen Zhang, Zhao Yan, Zhoujun Li,
  Yunbo Cao","CQR-SQL: Conversational Question Reformulation Enhanced
  Context-Dependent Text-to-SQL Parsers","Accepted at EMNLP 2022 (findings)",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Context-dependent text-to-SQL is the task of translating multi-turn questions
into database-related SQL queries. Existing methods typically focus on making
full use of history context or previously predicted SQL for currently SQL
parsing, while neglecting to explicitly comprehend the schema and
conversational dependency, such as co-reference, ellipsis and user focus
change. In this paper, we propose CQR-SQL, which uses auxiliary Conversational
Question Reformulation (CQR) learning to explicitly exploit schema and decouple
contextual dependency for SQL parsing. Specifically, we first present a schema
enhanced recursive CQR method to produce domain-relevant self-contained
questions. Secondly, we train CQR-SQL models to map the semantics of multi-turn
questions and auxiliary self-contained questions into the same latent space
through schema grounding consistency task and tree-structured SQL parsing
consistency task, which enhances the abilities of SQL parsing by adequately
contextual understanding. At the time of writing, our CQR-SQL achieves new
state-of-the-art results on two context-dependent text-to-SQL benchmarks SParC
and CoSQL.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:52:42 GMT""},{""version"":""v2"",""created"":""Tue, 17 May 2022 15:44:21 GMT""},{""version"":""v3"",""created"":""Mon, 24 Oct 2022 06:09:52 GMT""}]","2023-01-31"
"2205.07687","Will Yeadon","Will Yeadon","Multiphysics modelling of Gas Tungsten Arc Welding on ultra-thin-walled
  titanium tubing","Final PhD thesis on ATLAS cooling system joinery. 218 Pages, 95
  figures",,,,"physics.flu-dyn hep-ex","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This thesis presents a novel multiphysics solver, named gtawFoam, for Gas
Tungsten Arc Welding (GTAW) that is applied to simulate orbital GTAW on
ultra-thin-walled titanium tubing. In this thesis, ultra-thin-walled tubing
refers to tubing where the wall thicknesses are less than 500 $\mu m$. Orbital
welding of tubing with this wall thickness requires both a sufficient heat
input to weld the tubing and an internal buttressing gas flow to ensure the
tube retains its geometrical integrity. The specific use case is for the
commercially pure grade 2 titanium tubing used in the ATLAS ITk cooling system
which is 2.275 $mm$ outer diameter and 300 $\mu m$ wall thickness at the weld.
The solver is created using the open source computational fluid dynamics
library OpenFOAM and each component of the solver is benchmarked against an
appropriate case. With the solver established, it is used to simulate a series
of welding procedures that were performed experimentally on the aforementioned
titanium tubing. Both the experimental and simulation results show a
`goldilocks' region where the weld heat input and inner buttressing gas flow
are moderated to a level where a fully penetrating weld is created but the
geometric integrity of the tube is not compromised. gtawFoam is then used to
simulate hypothetical tubing with larger and smaller wall thicknesses between
250 $\mu m$ and 350 $\mu m$. The results suggest that the required buttressing
gas pressure once achieved is relatively transferable between wall thickness
changes but applying enough heat so as to achieve full penetration is critical.
These results are then used to predict effective welding procedures for this
hypothetical tubing. gtawFoam is subsequently applied to the welding of turbine
blades. This includes the addition of multiple layers of filler metal to mimic
additive manufacturing.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:52:54 GMT""}]","2022-05-17"
"2205.07688","Mukesh Kumar Choudhary","Mukesh K. Choudhary, H. Fjellv\r{a}g, and P. Ravindran","First principle studies on electronic and thermoelectric properties of
  Fe$_{2}$TiSn based multinary Heusler alloys",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The alloys with 8/18/24 valence electron count (VEC) are promising candidates
for efficient energy conversion and refrigeration applications at low as well
as high temperatures. The full potential linearized augmented plane wave method
as implemented in WIEN2k code was used to investigate electronic structure and
TE transport properties with the PBE$-$GGA and TB$-$mBJ exchange potentials and
Boltzmann transport theory. The calculated single crystal elastic constants,
phonon dispersion and phonon density of states confirm that these systems are
mechanically and dynamically stable. The TE transport properties is calculated
by including the lattice part of thermal conductivity ($\kappa_{L}$) obtained
from two methods one from the calculated elastic properties calculation
($\kappa^{elastic}_{L}$) and the other from phonon dispersion curve
($\kappa^{phonon}_{L}$). The strong phonon$-$phonon scattering by large mass
difference/strain fluctuation of isovalent/aliovalent substitution at Ti/Sn
sites of Fe$_{2}$TiSn reduces the lattice thermal conductivity which results in
high \textit{ZT} value of 0.81 at 900\,K for
Fe$_{2}$Sc$_{0.25}$Ti$_{0.5}$Ta$_{0.25}$Al$_{0.5}$Bi$_{0.5}$. The comparative
analysis of TE transport properties using the band structures calculated with
the PBE$-$GGA and TB$-$mBJ functional shows that the \textit{ZT} value obtained
from TB$-$mBJ scheme is found to be significantly higher than that based on
PBE$-$GGA. The calculated relatively low lattice thermal conductivity and high
\textit{ZT} values suggest that isovalent/aliovalent substituted Fe$_{2}$TiSn
are promising candidates for medium to high temperature waste heat recovery.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:53:31 GMT""}]","2022-05-17"
"2205.07689","Katharina Proksch","Katharina Proksch, Christoph Alexander Weitkamp, Thomas Staudt,
  Beno\^it Lelandais and Christophe Zimmer","From Small Scales to Large Scales: Distance-to-Measure Density based
  Geometric Analysis of Complex Data",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  How can we tell complex point clouds with different small scale
characteristics apart, while disregarding global features? Can we find a
suitable transformation of such data in a way that allows to discriminate
between differences in this sense with statistical guarantees? In this paper,
we consider the analysis and classification of complex point clouds as they are
obtained, e.g., via single molecule localization microscopy. We focus on the
task of identifying differences between noisy point clouds based on small scale
characteristics, while disregarding large scale information such as overall
size. We propose an approach based on a transformation of the data via the
so-called Distance-to-Measure (DTM) function, a transformation which is based
on the average of nearest neighbor distances. For each data set, we estimate
the probability density of average local distances of all data points and use
the estimated densities for classification. While the applicability is
immediate and the practical performance of the proposed methodology is very
good, the theoretical study of the density estimators is quite challenging, as
they are based on i.i.d. observations that have been obtained via a complicated
transformation. In fact, the transformed data are stochastically dependent in a
non-local way that is not captured by commonly considered dependence measures.
Nonetheless, we show that the asymptotic behaviour of the density estimator is
driven by a kernel density estimator of certain i.i.d. random variables by
using theoretical properties of U-statistics, which allows to handle the
dependencies via a Hoeffding decomposition. We show via a numerical study and
in an application to simulated single molecule localization microscopy data of
chromatin fibers that unsupervised classification tasks based on estimated
DTM-densities achieve excellent separation results.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:54:48 GMT""},{""version"":""v2"",""created"":""Wed, 18 May 2022 07:50:56 GMT""}]","2022-05-19"
"2205.07690","Nicol\`o Ghielmetti","Nicol\`o Ghielmetti, Vladimir Loncar, Maurizio Pierini, Marcel Roed,
  Sioni Summers, Thea Aarrestad, Christoffer Petersson, Hampus Linander,
  Jennifer Ngadiuba, Kelvin Lin, Philip Harris","Real-time semantic segmentation on FPGAs for autonomous vehicles with
  hls4ml","11 pages, 6 tables, 5 figures",,,,"cs.CV cs.AR cs.LG physics.ins-det stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we investigate how field programmable gate arrays can serve as
hardware accelerators for real-time semantic segmentation tasks relevant for
autonomous driving. Considering compressed versions of the ENet convolutional
neural network architecture, we demonstrate a fully-on-chip deployment with a
latency of 4.9 ms per image, using less than 30% of the available resources on
a Xilinx ZCU102 evaluation board. The latency is reduced to 3 ms per image when
increasing the batch size to ten, corresponding to the use case where the
autonomous vehicle receives inputs from multiple cameras simultaneously. We
show, through aggressive filter reduction and heterogeneous quantization-aware
training, and an optimized implementation of convolutional layers, that the
power consumption and resource utilization can be significantly reduced while
maintaining accuracy on the Cityscapes dataset.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:55:16 GMT""}]","2022-05-19"
"2205.07691","Jean-Pierre Labesse","Jean-Pierre Labesse","A pleasant exercise",,,,,"math.GR","http://creativecommons.org/licenses/by/4.0/","  In the Proceedings of the AMS Boulder conference in 1965 Langlands states a
combinatorial lemma involving families of characteristic functions attached to
ordered partitions of an obtuse basis in a finite dimensional euclidean vector
space. Langlands does not give any indication about the proof of the lemma
which is said to be a ""pleasant exercise"". Since we did not find a proof in the
literature we decided to give one. We believe it of some interest for the
history of the subject.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:58:49 GMT""},{""version"":""v2"",""created"":""Thu, 19 May 2022 11:34:46 GMT""},{""version"":""v3"",""created"":""Tue, 24 May 2022 15:08:01 GMT""}]","2022-05-25"
"2205.07692","Federica Capellino","F. Capellino, A. Beraudo, A. Dubla, S. Floerchinger, S. Masciocchi, J.
  Pawlowski, I. Selyuzhenkov","A fluid-dynamic approach to heavy-quark diffusion in the quark-gluon
  plasma","8 pages, 4 figures",,"10.1103/PhysRevD.106.034021",,"nucl-th","http://creativecommons.org/publicdomain/zero/1.0/","  A fluid-dynamic approach to the diffusion of heavy quarks in the quark--gluon
plasma (QGP) is presented. Specifically, we analyze the Fokker-Planck equation
for the momentum transport of heavy quarks from a fluid perspective and use a
mapping to second-order fluid-dynamics to determine conductivities and
relaxation times governing their spatial diffusion. By investigating the
relation between the two approaches, we provide new insights concerning the
level of local thermalization of charm and bottom quarks inside the expanding
QGP. Our results indicate that a fluid-dynamic description of diffusion is
feasible for charm quarks at least for the latest stages of the fireball
evolution.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:59:28 GMT""}]","2022-08-31"
"2205.07693","Zixuan Wei","Zixuan Wei, Mara Chiricotto, Joshua D. Elliott, Fausto Martelli, Paola
  Carbone","Wettability of graphite under 2D confinement",,,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The thermodynamics of solid/liquid interfaces under nanoconfinement has
tremendous implications for liquid transport properties. Here using molecular
dynamics, we investigate graphite nanoslits and study how the water/graphite
interfacial tension changes with the degree of confinement. We found that, for
nanochannel heights between 0.7nm and 2.6nm, graphite becomes more hydrophobic
than in bulk, and that the value of the surface tension oscillates before
eventually converging towards a constant value for larger slits. The value of
the surface tension is correlated with the slip length of the fluid and
explained in terms of the effective and interfacial density, hydration pressure
and friction coefficient. The study clearly indicates that there is a critical
channel height of 0.9nm (achievable experimentally1) at which the surface
tension reaches its highest value, but the water diffusion across the channel
is at its minimum. The structural analysis shows that for this pore size a
transition between a 2D and 3D hydrogen bond network is accompanied by an
abrupt increase in conformational entropy. Our results show that the
wettability of solid surfaces can change under nanoconfinement and the data can
be used to interpret the experimental permeability data.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:00:13 GMT""}]","2022-05-17"
"2205.07694","Marcel Dengler","Marcel Dengler","Everywhere regularity results for a polyconvex functional in finite
  elasticity",,,,,"math.AP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Here we develop a regularity theory for a polyconvex functional in
$2\times2-$dimensional compressible finite elasticity. In particular, we
consider energy minimizers/stationary points of the functional
$I(u)=\int\limits_{\Omega}{\frac{1}{2}|\nabla u|^2+\rho(\det\nabla u)\;dx},$
where $\Omega\subset\mathbb{R}^2$ is open and bounded, $u\in
W^{1,2}(\Omega,\mathbb{R}^2)$ and $\rho:\mathbb{R}\rightarrow\mathbb{R}_0^+$
smooth and convex with $\rho(s)=0$ for all $s\le0$ and $\rho$ becomes affine
when $s$ exceeds some value $s_0>0.$ Additionally, we may impose boundary
conditions.
  The first result we show is that every stationary point needs to be locally
H\""older-continuous. Secondly, we prove that if
$\|\rho'\|_{L^\infty(\mathbb{R})}<1$ s.t. the integrand is still uniformly
convex, then all stationary points have to be in $W_{loc}^{2,2}.$ Next, a
higher-order regularity result is shown. Indeed, we show that all stationary
points that are additionally of class $W_{loc}^{2,2}$ and whose Jacobian is
suitably H\""older-continuous are of class $C_{loc}^{\infty}.$ As a consequence,
these results show that in the case when $\|\rho'\|_{L^\infty(\mathbb{R})}<1$
all stationary points have to be smooth.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:00:28 GMT""},{""version"":""v2"",""created"":""Wed, 18 May 2022 15:24:08 GMT""}]","2022-05-19"
"2205.07695","Serban Belinschi","Serban Belinschi (IMT), Mireille Capitaine (IMT)","Strong convergence of tensor products of independent G.U.E. matrices","Preliminary version, comments most welcome!",,,,"math.OA math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given tuples of properly normalized independent $N\times N$ G.U.E. matrices
$(X_N^{(1)},\dots,X_N^{(r_1)})$ and $(Y_N^{(1)},\dots,Y_N^{(r_2)})$, we show
that the tuple $(X_N^{(1)}\otimes I_N,\dots,X_N^{(r_1)}\otimes I_N,I_N\otimes
Y_N^{(1)},\dots,I_N\otimes Y_N^{(r_2)})$ of $N^2\times N^2$ random matrices
converges strongly as $N$ tends to infinity. It was shown by Ben Hayes that
this result implies that the Peterson-Thom conjecture is true.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:02:04 GMT""}]","2022-05-17"
"2205.07696","Joel Scheuner","Joel Scheuner, Simon Eismann, Sacheendra Talluri, Erwin van Eyk,
  Cristina Abad, Philipp Leitner, Alexandru Iosup","Let's Trace It: Fine-Grained Serverless Benchmarking using Synchronous
  and Asynchronous Orchestrated Applications",,,,,"cs.DC cs.SE","http://creativecommons.org/licenses/by/4.0/","  Making serverless computing widely applicable requires detailed performance
understanding. Although contemporary benchmarking approaches exist, they report
only coarse results, do not apply distributed tracing, do not consider
asynchronous applications, and provide limited capabilities for (root cause)
analysis. Addressing this gap, we design and implement ServiBench, a serverless
benchmarking suite. ServiBench (i) leverages synchronous and asynchronous
serverless applications representative of production usage, (ii) extrapolates
cloud-provider data to generate realistic workloads, (iii) conducts
comprehensive, end-to-end experiments to capture application-level performance,
(iv) analyzes results using a novel approach based on (distributed) serverless
tracing, and (v) supports comprehensively serverless performance analysis. With
ServiBench, we conduct comprehensive experiments on AWS, covering five common
performance factors: median latency, cold starts, tail latency, scalability,
and dynamic workloads. We find that the median end-to-end latency of serverless
applications is often dominated not by function computation but by external
service calls, orchestration, or trigger-based coordination. We release
collected experimental data under FAIR principles and ServiBench as a tested,
extensible open-source tool.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:04:30 GMT""}]","2022-05-17"
"2205.07697","Francisco Vega Mr.","Francisco Vega Ib\'a\~nez, Armand B\'ech\'e, Johan Verbeeck","Can a Programmable Phase Plate Serve as an Aberration Corrector in the
  Transmission Electron Microscope (TEM)?",,,"10.1017/S1431927622012260",,"physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Current progress in programmable electrostatic phase plates raises questions
about their usefulness for specific applications. Here, we explore different
designs for such phase plates with the specific goal of correcting spherical
aberration in the Transmission Electron Microscope (TEM). We numerically
investigate whether a phase plate could provide down to 1 $\r{A}$ngstr\""om
spatial resolution on a conventional uncorrected TEM. Different design aspects
(fill-factor, pixel pattern, symmetry) were evaluated to understand their
effect on the electron probe size and current density. Some proposed designs
show a probe size ($d_{50}$) down to 0.66$\r{A}$, proving that it should be
possible to correct spherical aberration well past the 1\AA~ limit using a
programmable phase plate consisting of an array of electrostatic phase shifting
elements.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:05:06 GMT""},{""version"":""v2"",""created"":""Tue, 13 Sep 2022 10:54:32 GMT""}]","2022-09-14"
"2205.07698","Robert Eymard","Robert Eymard (LAMA), David Maltese (LAMA), Alain Prignet (LAMA)","Weighted p--Laplace approximation of linear and quasi-linear elliptic
  problems with measure data",,,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We approximate the solution to some linear and degenerate quasi-linear
problem involving a linear elliptic operator (like the semi-discrete in time
implicit Euler approximation of Richards and Stefan equations) with measure
right-hand side and heterogeneous anisotropic diffusion matrix. This
approximation is obtained through the addition of a weighted p--Laplace term. A
well chosen diffeomorphism between R and (--1, 1) is used for the estimates of
the approximated solution, and is involved in the above weight. We show that
this approximation converges to a weak sense of the problem for general
right-hand-side, and to the entropy solution in the case where the
right-hand-side is in L 1 .
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:05:12 GMT""}]","2022-05-17"
"2205.07699","Ihab Haidar","Yacine Chitour (L2S), Ihab Haidar (QUARTZ), Paolo Mason (L2S, CNRS),
  Mario Sigalotti (Inria, SU, LJLL (UMR\_7598))","Upper and lower bounds for the maximal Lyapunov exponent of singularly
  perturbed linear switching systems",,,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we consider the problem of determining the stability
properties, and in particular assessing the exponential stability, of a
singularly perturbed linear switching system. One of the challenges of this
problem arises from the intricate interplay between the small parameter of
singular perturbation and the rate of switching, as both tend to zero. Our
approach consists in characterizing suitable auxiliary linear systems that
provide lower and upper bounds for the asymptotics of the maximal Lyapunov
exponent of the linear switching system as the parameter of the singular
perturbation tends to zero.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:06:22 GMT""}]","2022-05-17"
"2205.07700","Jean-Philippe Chancelier","Fran\c{c}ois Pacaud (CERMICS), Pierre Carpentier (ENSTA Paris),
  Jean-Philippe Chancelier (CERMICS), Michel de Lara (CERMICS)","Optimization of a domestic microgrid equipped with solar panel and
  battery: Model Predictive Control and Stochastic Dual Dynamic Programming
  approaches","arXiv admin note: substantial text overlap with arXiv:1801.06479",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this study, a microgrid with storage (battery, hot water tank) and solar
panel is considered. We benchmark two algorithms, MPC and SDDP, that yield
online policies to manage the microgrid, and compare them with a rule based
policy. Model Predictive Control (MPC) is a well-known algorithm which models
the future uncertainties with a deterministic forecast. By contrast, Stochastic
Dual Dynamic Programming (SDDP) models the future uncertainties as stagewise
independent random variables with known probability distributions. We present a
scheme, based on out-of-sample validation, to fairly compare the two online
policies yielded by MPC and SDDP. Our numerical studies put to light that MPC
and SDDP achieve significant gains compared to the rule based policy, and that
SDDP overperforms MPC not only on average but on most of the out-of-sample
assessment scenarios.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:07:35 GMT""}]","2022-05-17"
"2205.07701","Daniel Grimmer","Daniel Grimmer","A Discrete Analog of General Covariance -- Part 2: Despite what you've
  heard, a perfectly Lorentzian lattice theory","46 pages, 10 figures. Part 1 (arXiv:2204.02276) Video abstract: see
  https://www.youtube.com/watch?v=dc58WyWX-z4. arXiv admin note: substantial
  text overlap with arXiv:2204.02276",,,,"gr-qc hep-lat physics.hist-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A crucial step in the history of General Relativity was Einstein's adoption
of the principle of general covariance which demands a coordinate independent
formulation for our spacetime theories. General covariance helps us to
disentangle a theory's substantive content from its merely representational
artifacts. It is an indispensable tool for a modern understanding of spacetime
theories. Motivated by quantum gravity, one may wish to extend these notions to
quantum spacetime theories (whatever those are). Relatedly, one might want to
extend these notions to discrete spacetime theories (i.e., lattice theories).
This paper delivers such an extension with surprising consequences, extending
Part 1 (arXiv:2204.02276) to a Lorentzian setting.
  This discrete analog of general covariance reveals that lattice structure is
rather less like a fixed background structure and rather more like a coordinate
system, i.e., merely a representational artifact. This discrete analog is built
upon a rich analogy between the lattice structures appearing in our discrete
spacetime theories and the coordinate systems appearing in our continuum
spacetime theories. I argue that properly understood there are no such things
as lattice-fundamental theories, rather there are only lattice-representable
theories. It is well-noted by the causal set theory community that no theory on
a fixed spacetime lattice is Lorentz invariant, however as I will discuss this
is ultimately a problem of representational capacity, not of physics. There is
no need for the symmetries of our representational tools to latch onto the
symmetries of the thing being represented. Nothing prevents us from using
Cartesian coordinates to describe rotationally invariant states/dynamics. As
this paper shows, the same is true of lattices in a Lorentzian setting: nothing
prevents us from defining a perfectly Lorentzian lattice(-representable)
theory.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:10:09 GMT""},{""version"":""v2"",""created"":""Wed, 18 May 2022 10:42:18 GMT""}]","2022-05-19"
"2205.07702","Chuanhuan Li","Chuanhuan Li, Yi Li, Kairui Xu","Parabolic frequency monotonicity on Ricci flow and Ricci-harmonic flow
  with bounded curvatures","16 pages",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the monotonicity of parabolic frequency motivated by
\cite{frequency on RF} under the Ricci flow and the Ricci-harmonic flow on
manifolds. Here we consider two cases: one is the monotonicity of parabolic
frequency for the solution of linear heat equation with bounded Bakry-\'{E}mery
Ricci curvature, and another case is the monotonicity of parabolic frequency
for the solution of heat equation with bounded Ricci curvature.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:10:47 GMT""}]","2022-05-17"
"2205.07703","Charles Bertucci","Charles Bertucci (CMAP)","Mean field games with incomplete information",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is concerned with mean field games in which the players do not
know the repartition of the other players. First a case in which the players do
not gain information is studied. Results of existence and uniqueness are proved
and discussed. Then, a case in which the players observe the payments is
investigated. A master equation is derived and partial results of uniqueness
are given for this more involved case.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:12:34 GMT""}]","2022-05-17"
"2205.07704","Daniil Tiapkin","Daniil Tiapkin, Denis Belomestny, Eric Moulines, Alexey Naumov, Sergey
  Samsonov, Yunhao Tang, Michal Valko, Pierre Menard","From Dirichlet to Rubin: Optimistic Exploration in RL without Bonuses",,,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  We propose the Bayes-UCBVI algorithm for reinforcement learning in tabular,
stage-dependent, episodic Markov decision process: a natural extension of the
Bayes-UCB algorithm by Kaufmann et al. (2012) for multi-armed bandits. Our
method uses the quantile of a Q-value function posterior as upper confidence
bound on the optimal Q-value function. For Bayes-UCBVI, we prove a regret bound
of order $\widetilde{O}(\sqrt{H^3SAT})$ where $H$ is the length of one episode,
$S$ is the number of states, $A$ the number of actions, $T$ the number of
episodes, that matches the lower-bound of $\Omega(\sqrt{H^3SAT})$ up to
poly-$\log$ terms in $H,S,A,T$ for a large enough $T$. To the best of our
knowledge, this is the first algorithm that obtains an optimal dependence on
the horizon $H$ (and $S$) without the need for an involved Bernstein-like bonus
or noise. Crucial to our analysis is a new fine-grained anti-concentration
bound for a weighted Dirichlet sum that can be of independent interest. We then
explain how Bayes-UCBVI can be easily extended beyond the tabular setting,
exhibiting a strong link between our algorithm and Bayesian bootstrap (Rubin,
1981).
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:13:06 GMT""},{""version"":""v2"",""created"":""Wed, 22 Jun 2022 06:58:54 GMT""}]","2022-06-23"
"2205.07705","Zeyuan Tang","Zeyuan Tang, Frederik Doktor S. Simonsen, Rijutha Jaganathan, Julianna
  Palot\'as, Jos Oomens, Liv Hornek{\ae}r and Bj{\o}rk Hammer","Top-down formation of ethylene from fragmentation of superhydrogenated
  polycyclic aromatic hydrocarbons","11 pages, 6 figures","A&A 663, A150 (2022)","10.1051/0004-6361/202243202",,"astro-ph.GA physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  Fragmentation is an important decay mechanism for polycyclic aromatic
hydrocarbons (PAHs) under harsh interstellar conditions and represents a
possible formation pathway for small molecules such as H2, C2H2, C2H4. Our aim
is to investigate the dissociation mechanism of superhydrogenated PAHs that
undergo energetic processing and the formation pathway of small hydrocarbons.
We obtain, experimentally, the mass distribution of protonated tetrahydropyrene
(C16H15 , py+5H+) and protonated hexahydropyrene (C16H17+, py+7H+) upon
collision induced dissociation (CID). The IR spectra of their main fragments
are recorded by infrared multiple-photon dissociation (IRMPD). Extended
tight-binding (GFN2-xTB) based molecular dynamics simulations are performed in
order to provide the missing structure information in experiment and identify
fragmentation pathways. The pathways for fragmentation are further investigated
at a hybrid-density functional theory (DFT) and dispersion corrected level. A
strong signal for loss of 28 mass units of py+7H+ is observed both in the CID
experiment and the MD simulation, while py+5H+ shows negligible signal for the
product corresponding to a mass loss of 28. The 28 mass loss from py+7H+ is
assigned to the loss of ethylene (C2H4) and a good fit between the calculated
and experimental IR spectrum of the resulting fragment species is obtained.
Further DFT calculations show favorable kinetic pathways for loss of C2H4 from
hydrogenated PAH configurations involving three consecutive CH2 molecular
entities. This joint experimental and theoretical investigation proposes a
chemical pathway of ethylene formation from fragmentation of superhydrogenated
PAHs. This pathway is sensitive to hydrogenated edges (e.g. the degree of
hydrogenation and the hydrogenated positions). The inclusion of this pathway in
astrochemical models may improve the estimated abundance of ethylene.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:13:43 GMT""},{""version"":""v2"",""created"":""Mon, 5 Dec 2022 14:06:48 GMT""}]","2022-12-06"
"2205.07706","Antoine Chaillet","Iasson Karafyllis, Pierdomenico Pepe, Yuan Wang, Antoine Chaillet
  (IUF, L2S)","Growth conditions for global exponential stability and exp-ISS of
  time-delay systems under point-wise dissipation",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For time-delay systems, it is known that global asymptotic stability is
guaranteed by the existence of a Lyapunov-Krasovskii functional that dissipates
in a point-wise manner along solutions, namely whose dissipation rate involves
only the current value of the solution's norm. So far, the extension of this
result to global exponential stability (GES) holds only for systems ruled by a
globally Lipschitz vector field and remains largely open for the input-to-state
stability (ISS) property. In this paper, we rely on the notion of exponential
ISS to extend the class of systems for which GES or ISS can be concluded from a
point-wise dissipation. Our results in turn show that these properties still
hold in the presence of a sufficiently small additional term involving the
whole state history norm. We provide explicit estimates of the tolerable
magnitude of this extra term and show through an example how it can be used to
assess robustness with respect to modeling uncertainties.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:13:57 GMT""}]","2022-05-17"
"2205.07707","Svetlana Puzynina","Val\'erie Berth\'e, Svetlana Puzynina","On the rigidity of Arnoux-Rauzy words",,,,,"cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An infinite word generated by a substitution is rigid if all the
substitutions which fix this word are powers of a same substitution. Sturmian
words as well as characteristic Arnoux-Rauzy words are known to be rigid. In
the present paper, we prove that all Arnoux-Rauzy words are rigid. The proof
relies on two main ingredients: firstly, the fact that the primitive
substitutions that fix an Arnoux-Rauzy word share a common power, and secondly,
the notion of normal form of an episturmian substitution (i.e., a substitution
that fixes an Arnoux-Rauzy word). The main difficulty is then of a
combinatorial nature and relies on the normalization process when taking powers
of episturmian substitutions: the normal form of a square is not necessarily
equal to the square of the normal forms.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:19:55 GMT""},{""version"":""v2"",""created"":""Tue, 12 Jul 2022 16:07:39 GMT""}]","2022-07-13"
"2205.07708","Xun Xu","Zhihao Liang, Xun Xu, Shengheng Deng, Lile Cai, Tao Jiang, Kui Jia","Exploring Diversity-based Active Learning for 3D Object Detection in
  Autonomous Driving",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  3D object detection has recently received much attention due to its great
potential in autonomous vehicle (AV). The success of deep learning based object
detectors relies on the availability of large-scale annotated datasets, which
is time-consuming and expensive to compile, especially for 3D bounding box
annotation. In this work, we investigate diversity-based active learning (AL)
as a potential solution to alleviate the annotation burden. Given limited
annotation budget, only the most informative frames and objects are
automatically selected for human to annotate. Technically, we take the
advantage of the multimodal information provided in an AV dataset, and propose
a novel acquisition function that enforces spatial and temporal diversity in
the selected samples. We benchmark the proposed method against other AL
strategies under realistic annotation cost measurement, where the realistic
costs for annotating a frame and a 3D bounding box are both taken into
consideration. We demonstrate the effectiveness of the proposed method on the
nuScenes dataset and show that it outperforms existing AL strategies
significantly.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:21:30 GMT""}]","2022-05-17"
"2205.07709","Alexander Kulikov","Tatiana Belova, Alexander Golovnev, Alexander S. Kulikov, Ivan
  Mihajlin, Denil Sharipov","Polynomial formulations as a barrier for reduction-based hardness proofs",,,,,"cs.CC cs.DS","http://creativecommons.org/licenses/by/4.0/","  The Strong Exponential Time Hypothesis (SETH) asserts that for every
$\varepsilon>0$ there exists $k$ such that $k$-SAT requires time
$(2-\varepsilon)^n$. The field of fine-grained complexity has leveraged SETH to
prove quite tight conditional lower bounds for dozens of problems in various
domains and complexity classes, including Edit Distance, Graph Diameter,
Hitting Set, Independent Set, and Orthogonal Vectors. Yet, it has been
repeatedly asked in the literature whether SETH-hardness results can be proven
for other fundamental problems such as Hamiltonian Path, Independent Set,
Chromatic Number, MAX-$k$-SAT, and Set Cover.
  In this paper, we show that fine-grained reductions implying even
$\lambda^n$-hardness of these problems from SETH for any $\lambda>1$, would
imply new circuit lower bounds: super-linear lower bounds for Boolean
series-parallel circuits or polynomial lower bounds for arithmetic circuits
(each of which is a four-decade open question).
  We also extend this barrier result to the class of parameterized problems.
Namely, for every $\lambda>1$ we conditionally rule out fine-grained reductions
implying SETH-based lower bounds of $\lambda^k$ for a number of problems
parameterized by the solution size $k$.
  Our main technical tool is a new concept called polynomial formulations. In
particular, we show that many problems can be represented by relatively
succinct low-degree polynomials, and that any problem with such a
representation cannot be proven SETH-hard (without proving new circuit lower
bounds).
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:22:12 GMT""},{""version"":""v2"",""created"":""Sun, 19 Jun 2022 22:51:05 GMT""},{""version"":""v3"",""created"":""Sat, 25 Jun 2022 08:46:37 GMT""},{""version"":""v4"",""created"":""Sun, 18 Sep 2022 11:28:28 GMT""},{""version"":""v5"",""created"":""Tue, 29 Nov 2022 07:40:15 GMT""}]","2022-11-30"
"2205.07710","Ruifang Liu","Jie Xue, Ruifang Liu, Jiaxin Guo, Jinlong Shu","The maximum spectral radius of irregular bipartite graphs","15 pages, 1 figure",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A bipartite graph is subcubic if it is an irregular bipartite graph with
maximum degree three. In this paper, we prove that the asymptotic value of
maximum spectral radius over subcubic bipartite graphs of order $n$ is
$3-\varTheta(\frac{\pi^{2}}{n^{2}})$. Our key approach is taking full advantage
of the eigenvalues of certain tridiagonal matrices, due to Willms [SIAM J.
Matrix Anal. Appl. 30 (2008) 639--656]. Moreover, for large maximum degree,
i.e., the maximum degree is at least $\lfloor n/2 \rfloor$, we characterize
irregular bipartite graphs with maximum spectral radius. For general maximum
degree, we present an upper bound on the spectral radius of irregular bipartite
graphs in terms of the order and maximum degree.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:24:36 GMT""},{""version"":""v2"",""created"":""Sat, 13 Aug 2022 07:52:21 GMT""}]","2022-08-16"
"2205.07711","Diqun Yan","Jiacheng Deng, Shunyi Chen, Li Dong, Diqun Yan, Rangding Wang","Transferability of Adversarial Attacks on Synthetic Speech Detection","5 pages, submit to Interspeech2022",,,,"cs.SD cs.CR eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Synthetic speech detection is one of the most important research problems in
audio security. Meanwhile, deep neural networks are vulnerable to adversarial
attacks. Therefore, we establish a comprehensive benchmark to evaluate the
transferability of adversarial attacks on the synthetic speech detection task.
Specifically, we attempt to investigate: 1) The transferability of adversarial
attacks between different features. 2) The influence of varying extraction
hyperparameters of features on the transferability of adversarial attacks. 3)
The effect of clipping or self-padding operation on the transferability of
adversarial attacks. By performing these analyses, we summarise the weaknesses
of synthetic speech detectors and the transferability behaviours of adversarial
attacks, which provide insights for future research. More details can be found
at https://gitee.com/djc_QRICK/Attack-Transferability-On-Synthetic-Detection.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:24:56 GMT""}]","2022-05-17"
"2205.07712","Zahra Azin","Reza Takhshid, Razieh Shojaei, Zahra Azin, Mohammad Bahrani","Persian Abstract Meaning Representation",,,,,"cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Abstract Meaning Representation (AMR) is an annotation framework representing
the semantic structure of a sentence as a whole. From the beginning, AMR was
not intended to act as an interlingua; however, it has made progress towards
the idea of designing a universal meaning representation framework.
Accordingly, developing AMR annotation guidelines for different languages,
based on language divergences, is of significant importance. In this paper, we
elaborate on Persian Abstract Meaning Representation (PAMR) annotation
specifications, based on which we annotated the Persian translation of ""The
Little Prince"" as the first gold standard for Persian AMR. Moreover, we
describe how some Persian-specific syntactic constructions would result in
different AMR annotations.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:25:43 GMT""}]","2022-05-17"
"2205.07713","Sanchita Pal Dr.","Sanchita Pal, Benjamin J. Lynch, Simon W. Good, Erika Palmerio,
  Eleanna Asvestari, Jens Pomoell, Michael L. Stevens and Emilia K. J. Kilpua","Eruption and Interplanetary Evolution of a Stealthy Streamer-Blowout CME
  Observed by PSP at ${\sim}$0.5~AU","21 pages, 6 figures, 3 videos",,,,"astro-ph.SR physics.space-ph","http://creativecommons.org/licenses/by/4.0/","  Streamer-blowout coronal mass ejections (SBO-CMEs) are the dominant CME
population during solar minimum. Although they are typically slow and lack
clear low-coronal signatures, they can cause geomagnetic storms. With the aid
of extrapolated coronal fields and remote observations of the off-limb low
corona, we study the initiation of an SBO-CME preceded by consecutive CME
eruptions consistent with a multi-stage sympathetic breakout scenario. From
inner-heliospheric Parker Solar Probe (PSP) observations, it is evident that
the SBO-CME is interacting with the heliospheric magnetic field and plasma
sheet structures draped about the CME flux rope. We estimate that $18 \, \pm \,
11\%$ of the CME's azimuthal magnetic flux has been eroded through magnetic
reconnection and that this erosion began after a heliospheric distance of
${\sim}0.35$ AU from the Sun was reached. This observational study has
important implications for understanding the initiation of SBO-CMEs and their
interaction with the heliospheric surroundings.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:26:43 GMT""}]","2022-05-17"
"2205.07714","L\'eo Belzile","L\'eo R. Belzile and Christophe Dutang and Paul J. Northrop and Thomas
  Opitz","A modeler's guide to extreme value software","35 pages, 2 figures",,,,"stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This review paper surveys recent development in software implementations for
extreme value analyses since the publication of Stephenson and Gilleland (2006)
and Gilleland et al. (2013), here with a focus on numerical challenges. We
provide a comparative review by topic and highlight differences in existing
routines, along with listing areas where software development is lacking. The
online supplement contains two vignettes providing a comparison of
implementations of frequentist and Bayesian estimation of univariate extreme
value models.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:29:53 GMT""}]","2022-05-17"
"2205.07715","Andrei Gritsan","A. V. Gritsan, H. Bahl, R. K. Barman, I. Bozovic-Jelisavcic, J. Davis,
  W. Dekens, Y. Gao, D. Goncalves, L. S. Mandacaru Guerra, D. Jeans, K. Kong,
  S. Kyriacou, K. Mohan, R.-Q. Pan, J. Roskes, N. V. Tran, N. Vukasinovic, M.
  Xiao","Snowmass White Paper: Prospects of CP-violation measurements with the
  Higgs boson at future experiments","Snowmass White Paper. 25 pages, 6 figures",,,,"hep-ex hep-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The search for CP violation in interactions of the Higgs boson with either
fermions or bosons provides attractive reference measurements in the Particle
Physics Community Planning Exercise (a.k.a. ""Snowmass""). Benchmark measurements
of CP violation provide a limited and well-defined set of parameters that could
be tested at the proton, electron-positron, photon, and muon colliders, and
compared to those achieved through study of virtual effects in electric dipole
moment measurements. We review the current status of these CP-sensitive studies
and provide projections to future measurements.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:30:03 GMT""},{""version"":""v2"",""created"":""Fri, 15 Jul 2022 05:15:06 GMT""},{""version"":""v3"",""created"":""Tue, 29 Nov 2022 18:45:57 GMT""}]","2022-11-30"
"2205.07716","Xihan Bian","Xihan Bian and Oscar Mendez and Simon Hadfield","Generalizing to New Tasks via One-Shot Compositional Subgoals","Present at ICRA 2022 ""Compositional Robotics: Mathematics and Tools""",,,,"cs.LG cs.RO","http://creativecommons.org/licenses/by-sa/4.0/","  The ability to generalize to previously unseen tasks with little to no
supervision is a key challenge in modern machine learning research. It is also
a cornerstone of a future ""General AI"". Any artificially intelligent agent
deployed in a real world application, must adapt on the fly to unknown
environments. Researchers often rely on reinforcement and imitation learning to
provide online adaptation to new tasks, through trial and error learning.
However, this can be challenging for complex tasks which require many timesteps
or large numbers of subtasks to complete. These ""long horizon"" tasks suffer
from sample inefficiency and can require extremely long training times before
the agent can learn to perform the necessary longterm planning. In this work,
we introduce CASE which attempts to address these issues by training an
Imitation Learning agent using adaptive ""near future"" subgoals. These subgoals
are recalculated at each step using compositional arithmetic in a learned
latent representation space. In addition to improving learning efficiency for
standard long-term tasks, this approach also makes it possible to perform
one-shot generalization to previously unseen tasks, given only a single
reference trajectory for the task in a different environment. Our experiments
show that the proposed approach consistently outperforms the previous
state-of-the-art compositional Imitation Learning approach by 30%.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:30:11 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jul 2022 08:36:17 GMT""}]","2022-07-26"
"2205.07717","Souhaibou Sambou","Eramane Bodian, Souhaibou Sambou, Papa Badiane, Winnie Ossete Ingoba,
  Salomon Sambou","Study of the operator $\partial^{k} \bar{\partial}^{k} + c$ in the
  weighted Hilbert space $L^2(\mathbb{C}, {\rm e}^{-\vert z \vert^2})$",,,,,"math.FA math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  By the H\""ormander's $L^2$-method, we study the operator $\partial^k
\bar{\partial}^{k} + c$ for any order $k$ in the weighted Hilbert space
$L^2(\mathbb{C}, {\rm e}^{-\vert z \vert^2})$. We prove the existence of its
right inverse witch is also a bounded operator.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:31:25 GMT""}]","2022-05-17"
"2205.07718","Steffen Lennart B\""otzel","Steffen B\""otzel, and Ilya M. Eremin","Feedback of non-local $d_{xy}$ nematicity on the magnetic anisotropy in
  FeSe","15 pages, 3 figures. Supplementary is available on request. To be
  published in Frontiers in Physics, Research Topic on Nematicity in Iron-Based
  Superconductors","Frontiers in Physics 10, 919784 (2022)","10.3389/fphy.2022.919784",,"cond-mat.supr-con cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We analyze theoretically the magnetic anisotropy in the nematic phase of FeSe
by computing the spin and the orbital susceptibilities from the microscopic
multiorbital model. In particular, we take into account both the $xz/yz$ and
the recently proposed non-local $xy$ nematic ordering and show that the latter
one could play a crucial role in reproducing the experimentally-measured
temperature dependence of the magnetic anisotropy. This provides a direct
fingerprint of the different nematic scenarios on the magnetic properties of
FeSe.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:31:53 GMT""}]","2022-06-20"
"2205.07719","Rafael Reisenhofer","Rafael Reisenhofer, Xandro Bayer, Nikolaus Hautsch","HARNet: A Convolutional Neural Network for Realized Volatility
  Forecasting",,,,,"econ.EM stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite the impressive success of deep neural networks in many application
areas, neural network models have so far not been widely adopted in the context
of volatility forecasting. In this work, we aim to bridge the conceptual gap
between established time series approaches, such as the Heterogeneous
Autoregressive (HAR) model, and state-of-the-art deep neural network models.
The newly introduced HARNet is based on a hierarchy of dilated convolutional
layers, which facilitates an exponential growth of the receptive field of the
model in the number of model parameters. HARNets allow for an explicit
initialization scheme such that before optimization, a HARNet yields identical
predictions as the respective baseline HAR model. Particularly when considering
the QLIKE error as a loss function, we find that this approach significantly
stabilizes the optimization of HARNets. We evaluate the performance of HARNets
with respect to three different stock market indexes. Based on this evaluation,
we formulate clear guidelines for the optimization of HARNets and show that
HARNets can substantially improve upon the forecasting accuracy of their
respective HAR baseline models. In a qualitative analysis of the filter weights
learnt by a HARNet, we report clear patterns regarding the predictive power of
past information. Among information from the previous week, yesterday and the
day before, yesterday's volatility makes by far the most contribution to
today's realized volatility forecast. Moroever, within the previous month, the
importance of single weeks diminishes almost linearly when moving further into
the past.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:33:32 GMT""}]","2022-05-17"
"2205.07720","Ioannis Dakanalis","I. Dakanalis (1), G. Tsiropoula (1), K. Tziotziou (1) and I.
  Kontogiannis (2) ((1) Institute for Astronomy, Astrophysics, Space
  Applications and Remote Sensing, National Observatory of Athens, 15236,
  Penteli, Greece, (2) Leibniz-Institut f\""ur Astrophysik Potsdam (AIP), An der
  Sternwarte 16, 14482, Potsdam, Germany)","Chromospheric swirls I. Automated detection in H$\alpha$ observations
  and their statistical properties",,"A&A 663, A94 (2022)","10.1051/0004-6361/202243236",,"astro-ph.SR physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Chromospheric swirls are considered to play a significant role in the
dynamics and heating of the upper solar atmosphere. It is important to
automatically detect and track them in chromospheric observations and determine
their properties. We applied a recently developed automated chromospheric swirl
detection method to time-series observations of a quiet region of the solar
chromosphere obtained in the H$\alpha$-0.2 \r{A} wavelength of the H$\alpha$
spectral line by the CRISP instrument at the Swedish 1-m Solar Telescope. The
algorithm exploits the morphological characteristics of swirling events in high
contrast chromospheric observations and results in the detection of these
structures in each frame of the time series and their tracking over time. We
conducted a statistical analysis to determine their various properties,
including a survival analysis for deriving the mean lifetime. A mean number of
146 $\pm$ 9 swirls was detected within the FOV at any given time. The mean
surface density is found equal to $\sim$0.08 swirls$ $Mm$^{-2}$ and the
occurrence rate is $\sim$10$^{-2}$ swirls$ $Mm$^{-2}$ min$^{-1}$. These values
are much higher than those previously reported from chromospheric observations.
The radii of the detected swirls range between 0.5 and 2.5 Mm, with a mean
value equal to 1.3 $\pm$ 0.3 Mm, which is slightly higher than previous
reports. The lifetimes range between 1.5 min and 33.7 min with an arithmetic
mean value of $\sim$8.5 min. A survival analysis of the lifetimes, however,
using the Kaplan-Meier estimator in combination with a parametric model results
in a mean lifetime of 10.3 $\pm$ 0.6 min. An automated method sheds more light
on their abundance than visual inspection, while higher cadence, higher
resolution observations will most probably result in the detection of a higher
number of such features on smaller scales and with shorter lifetimes.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:35:25 GMT""}]","2022-07-20"
"2205.07721","Vasileios Sitokonstantinou","George Choumos, Alkiviadis Koukos, Vasileios Sitokonstantinou,
  Charalampos Kontoes","Towards Space-to-Ground Data Availability for Agriculture Monitoring","Has been accepted for publication in IEEE IVMSP 2022:
  https://2022.ivmsp.org/ Specifically in the special session ""Multimodal
  Analysis, Fusion and Retrieval of satellite images"":
  https://2022.ivmsp.org/wp-content/uploads/2022/02/IVMSP2022-CFP-SpecialSession-4-MultiSat-rev.pdf",,,,"cs.CV cs.LG cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recent advances in machine learning and the availability of free and open
big Earth data (e.g., Sentinel missions), which cover large areas with high
spatial and temporal resolution, have enabled many agriculture monitoring
applications. One example is the control of subsidy allocations of the Common
Agricultural Policy (CAP). Advanced remote sensing systems have been developed
towards the large-scale evidence-based monitoring of the CAP. Nevertheless, the
spatial resolution of satellite images is not always adequate to make accurate
decisions for all fields. In this work, we introduce the notion of
space-to-ground data availability, i.e., from the satellite to the field, in an
attempt to make the best out of the complementary characteristics of the
different sources. We present a space-to-ground dataset that contains
Sentinel-1 radar and Sentinel-2 optical image time-series, as well as
street-level images from the crowdsourcing platform Mapillary, for grassland
fields in the area of Utrecht for 2017. The multifaceted utility of our dataset
is showcased through the downstream task of grassland classification. We train
machine and deep learning algorithms on these different data domains and
highlight the potential of fusion techniques towards increasing the reliability
of decisions.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:35:48 GMT""}]","2022-05-17"
"2205.07722","Maurice Jakesch","Maurice Jakesch, Zana Bu\c{c}inca, Saleema Amershi, Alexandra Olteanu","How Different Groups Prioritize Ethical Values for Responsible AI",,"2022 ACM Conference on Fairness, Accountability, and Transparency
  (FAccT '22), June 21-24, 2022, Seoul, Republic of Korea","10.1145/3531146.3533097",,"cs.HC cs.AI cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Private companies, public sector organizations, and academic groups have
outlined ethical values they consider important for responsible artificial
intelligence technologies. While their recommendations converge on a set of
central values, little is known about the values a more representative public
would find important for the AI technologies they interact with and might be
affected by. We conducted a survey examining how individuals perceive and
prioritize responsible AI values across three groups: a representative sample
of the US population (N=743), a sample of crowdworkers (N=755), and a sample of
AI practitioners (N=175). Our results empirically confirm a common concern: AI
practitioners' value priorities differ from those of the general public.
Compared to the US-representative sample, AI practitioners appear to consider
responsible AI values as less important and emphasize a different set of
values. In contrast, self-identified women and black respondents found
responsible AI values more important than other groups. Surprisingly, more
liberal-leaning participants, rather than participants reporting experiences
with discrimination, were more likely to prioritize fairness than other groups.
Our findings highlight the importance of paying attention to who gets to define
responsible AI.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:39:37 GMT""},{""version"":""v2"",""created"":""Tue, 15 Nov 2022 10:08:35 GMT""}]","2022-11-16"
"2205.07723","Vasileios Sitokonstantinou","Ornela Nanushi and Vasileios Sitokonstantinou and Ilias Tsoumas and
  Charalampos Kontoes","Pest presence prediction using interpretable machine learning","This work has been accepted for publication in IEEE 14th Image,
  Video, and Multidimensional Signal Processing Workshop (IVMSP 2022)",,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Helicoverpa Armigera, or cotton bollworm, is a serious insect pest of cotton
crops that threatens the yield and the quality of lint. The timely knowledge of
the presence of the insects in the field is crucial for effective farm
interventions. Meteo-climatic and vegetation conditions have been identified as
key drivers of crop pest abundance. In this work, we applied an interpretable
classifier, i.e., Explainable Boosting Machine, which uses earth observation
vegetation indices, numerical weather predictions and insect trap catches to
predict the onset of bollworm harmfulness in cotton fields in Greece. The
glass-box nature of our approach provides significant insight on the main
drivers of the model and the interactions among them. Model interpretability
adds to the trustworthiness of our approach and therefore its potential for
rapid uptake and context-based implementation in operational farm management
scenarios. Our results are satisfactory and the importance of drivers, through
our analysis on global and local explainability, is in accordance with the
literature.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:40:03 GMT""}]","2022-05-17"
"2205.07724","Giuseppe Fava","Martino Brambati, Giuseppe Fava, Francesco Ginelli","Signatures of directed and spontaneous flocking","11 pages","Physical Review E, 2022",,,"cond-mat.soft cond-mat.stat-mech nlin.AO","http://creativecommons.org/licenses/by/4.0/","  Collective motion - or flocking - is an emergent phenomena that underlies
many biological processes of relevance, from cellular migrations to animal
groups movement. In this work, we derive scaling relations for the fluctuations
of the mean direction of motion and for the static density structure factor
(which encodes static density fluctuations) in the presence of a homogeneous,
small external field. This allows us to formulate two different and
complementary criteria capable of detecting instances of directed motion
exclusively from easily measurable dynamical and static signatures of the
collective dynamics, without the need to detect correlations with environmental
cues. The static one is informative in large enough systems, while the
dynamical one requires large observation times to be effective. We believe
these criteria may prove useful to detect or confirm the directed nature of
collective motion in in vivo experimental observations, which are typically
conducted in complex and not fully controlled environments.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:43:51 GMT""},{""version"":""v2"",""created"":""Wed, 27 Jul 2022 15:57:27 GMT""},{""version"":""v3"",""created"":""Fri, 10 Feb 2023 11:14:36 GMT""}]","2023-02-13"
"2205.07725","Patrick Underhill","Toluwanimi O. Bello, Sangwoo Lee, and Patrick T. Underhill","Mesoscale Simulation Approach for Assembly of Small Deformable Objects",,,,,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  We adapt Vertex models to understand the physical origin of the formation of
long-range ordered structures in repulsive soft particles. The model
incorporates contributions from the volume and surface area of each particle.
Sampling using Monte Carlo simulations allows the system to naturally select
preferred structures. We observe transitions between a body-centered cubic
ordered state and a disordered state. Constraints to the simulation domain can
suppress or allow the system to follow a path similar to Martensitic
transformations from one ordered state to another ordered state. Finally, we
show that rapid quenches from a disordered state into the ordered region lead
to metastable local particle arrangements instead of a large-scale single
crystal.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:44:16 GMT""},{""version"":""v2"",""created"":""Mon, 27 Jun 2022 14:22:15 GMT""}]","2022-06-28"
"2205.07726","Prosper Ngabonziza","Arnaud P. Nono Tchiomo, Emanuela Carleschi, Aletta R. E. Prinsloo,
  Wilfried Sigle, Peter A. van Aken, Jochen Mannhart, Prosper Ngabonziza, and
  Bryan P. Doyle","Combined Spectroscopy and Electrical Characterization of
  La:BaSnO$_\text{3}$ Thin Films and Heterostructures","7 Figures, 4 Tables in manuscript; and 6 Figures and 1 Table in the
  Supplementary Information","AIP Advances 12, 105019 (2022)","10.1063/5.0105116",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  For La-doped BaSnO$_\text{3}$ thin films grown by pulsed laser deposition, we
combine chemical surface characterization and electronic transport studies to
probe the evolution of electronic states in the band structure for different
La-doping content. Systematic analyses of spectroscopic data based on fitting
the core electron line shapes help to unravel the composition of the surface as
well as the dynamics associated with increasing doping. This dynamics is
observed with a more pronounced signature in the Sn 3d core level, which
exhibits an increasing asymmetry to the high binding energy side of the peak
with increasing electron density. The present results expand the current
understanding of the interplay between the doping concentration, electronic
band structure and transport properties of epitaxial La:BaSnO$_\text{3}$ films.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:44:24 GMT""},{""version"":""v2"",""created"":""Wed, 28 Sep 2022 16:46:00 GMT""}]","2022-10-31"
"2205.07727","Jo\~ao Almeida","Jo\~ao Almeida, Daniel Rebelo dos Santos, Jos\'e Rui Figueira","A Multi-Objective Model for Thesis Defence Scheduling","45 pages, 12 figures",,,,"math.OC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We address the thesis defence scheduling problem, a critical academic
scheduling management process, which has been overshadowed in the literature by
its counterparts, course timetabling and exam scheduling. Specifically, the
single defence assignment type of thesis defence scheduling problems, where
each committee is assigned to a single defence, scheduled for a specific day,
hour and room. We formulate a multi-objective mixed-integer linear programming
model, which aims to be a general representation of the problem mentioned
above, and that can, therefore, be applied to a broader set of cases than other
models present in the literature, which have a focus on the characteristics of
their universities. We introduce a new decision variable, propose constraint
formulations that are not policy specific, and offer new takes on the more
common objectives seen in the literature. We also include new objective
functions based on our experience with the problem at our university. We also
propose a two-stage solution approach. The first stage is employed to find the
number of schedulable defences, enabling the optimisation of instances with
unschedulable defences. The second stage is an implementation of the augmented
e-constraint method, which allows for the search of a set of different and
non-dominated solutions while skipping redundant iterations. A novel instance
generator for thesis scheduling problems is presented. Its main benefit is the
generation of the availability of committee members and rooms in availability
and unavailability blocks, resembling their real-world counterparts. A set of
96 randomly generated instances of varying sizes is solved and analysed. The
proposed method can find the optimal number of schedulable defences and present
non-dominated solutions within the set time limits for every tested instance.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:45:39 GMT""}]","2022-05-17"
"2205.07728","Albert Wu","Albert Wu, Thomas Lew, Kiril Solovey, Edward Schmerling, Marco Pavone","Robust-RRT: Probabilistically-Complete Motion Planning for Uncertain
  Nonlinear Systems","16 pages of main text + 5 pages of appendix, 5 figures, submitted to
  the 2022 International Symposium on Robotics Research",,,,"cs.RO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Robust motion planning entails computing a global motion plan that is safe
under all possible uncertainty realizations, be it in the system dynamics, the
robot's initial position, or with respect to external disturbances. Current
approaches for robust motion planning either lack theoretical guarantees, or
make restrictive assumptions on the system dynamics and uncertainty
distributions. In this paper, we address these limitations by proposing the
robust rapidly-exploring random-tree (Robust-RRT) algorithm, which integrates
forward reachability analysis directly into sampling-based control trajectory
synthesis. We prove that Robust-RRT is probabilistically complete (PC) for
nonlinear Lipschitz continuous dynamical systems with bounded uncertainty. In
other words, Robust-RRT eventually finds a robust motion plan that is feasible
under all possible uncertainty realizations assuming such a plan exists. Our
analysis applies even to unstable systems that admit only short-horizon
feasible plans; this is because we explicitly consider the time evolution of
reachable sets along control trajectories. Thanks to the explicit consideration
of time dependency in our analysis, PC applies to unstabilizable systems. To
the best of our knowledge, this is the most general PC proof for robust
sampling-based motion planning, in terms of the types of uncertainties and
dynamical systems it can handle. Considering that an exact computation of
reachable sets can be computationally expensive for some dynamical systems, we
incorporate sampling-based reachability analysis into Robust-RRT and
demonstrate our robust planner on nonlinear, underactuated, and hybrid systems.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:46:12 GMT""},{""version"":""v2"",""created"":""Tue, 1 Nov 2022 15:22:55 GMT""}]","2022-11-02"
"2205.07729","Mario Hentschel","Mario Hentschel, Kirill Koshelev, Florian Sterl, Steffen Both, Julian
  Karst, Lida Shamsafar, Thomas Weiss, Yuri Kivshar, Harald Giessen","Dielectric Mie Voids: Confining Light in Air",,"Light: Science and Applications 2023","10.1038/s41377-022-01015-z",,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Manipulating light on the nanoscale has become a central challenge in
metadevices, resonant surfaces, nanoscale optical sensors, and many more, and
it is largely based on resonant light confinement in dispersive and lossy
metals and dielectrics. Here, we experimentally implement a novel strategy for
dielectric nanophotonics: Resonant subwavelength confinement of light in air.
We demonstrate that voids created in high-index dielectric host materials
support localized resonant modes with exceptional optical properties. Due to
the confinement in air, the modes do not suffer from the loss and dispersion of
the dielectric host medium. We experimentally realize these resonant Mie voids
by focused ion beam milling into bulk silicon wafers and experimentally
demonstrate resonant light confinement down to the UV spectral range at 265 nm
(4.68 eV). Furthermore, we utilize the bright, intense, and naturalistic
colours for nanoscale colour printing. The combination of resonant dielectric
Mie voids with dielectric nanoparticles will more than double the parameter
space for the future design of metasurfaces and other micro- and nanoscale
optical elements and push their operation into the blue and UV spectral range.
In particular, this extension will enable novel antenna and structure designs
which benefit from the full access to the modal field inside the void as well
as the nearly free choice of the high-index material.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:47:30 GMT""}]","2023-01-03"
"2205.07730","Francesco Plastina","A. Sannia, A. Giordano, N. Lo Gullo, C. Mastroianni, F. Plastina","A hybrid classical-quantum approach to speed-up Q-learning","comments are welcome","Sci Rep 13, 3913 (2023)","10.1038/s41598-023-30990-5",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We introduce a classical-quantum hybrid approach to computation, allowing for
a quadratic performance improvement in the decision process of a learning
agent. In particular, a quantum routine is described, which encodes on a
quantum register the probability distributions that drive action choices in a
reinforcement learning set-up. This routine can be employed by itself in
several other contexts where decisions are driven by probabilities. After
introducing the algorithm and formally evaluating its performance, in terms of
computational complexity and maximum approximation error, we discuss in detail
how to exploit it in the Q-learning context.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:49:16 GMT""}]","2023-03-22"
"2205.07731","Chen Xu","Chen Xu, Ba Trung Cao, Yong Yuan and G\""unther Meschke","Transfer learning based physics-informed neural networks for solving
  inverse problems in engineering structures under different loading scenarios","final version","Computer Methods in Applied Mechanics and Engineering, Volume 405,
  15 February 2023, 115852 Volume 405, 15 February 2023, 115852","10.1016/j.cma.2022.115852",,"cs.CE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, a class of machine learning methods called physics-informed neural
networks (PINNs) has been proposed and gained prevalence in solving various
scientific computing problems. This approach enables the solution of partial
differential equations (PDEs) via embedding physical laws into the loss
function. Many inverse problems can be tackled by simply combining the data
from real life scenarios with existing PINN algorithms. In this paper, we
present a multi-task learning method using uncertainty weighting to improve the
training efficiency and accuracy of PINNs for inverse problems in linear
elasticity and hyperelasticity. Furthermore, we demonstrate an application of
PINNs to a practical inverse problem in structural analysis: prediction of
external loads of diverse engineering structures based on limited displacement
monitoring points. To this end, we first determine a simplified loading
scenario at the offline stage. By setting unknown boundary conditions as
learnable parameters, PINNs can predict the external loads with the support of
measured data. When it comes to the online stage in real engineering projects,
transfer learning is employed to fine-tune the pre-trained model from offline
stage. Our results show that, even with noisy gappy data, satisfactory results
can still be obtained from the PINN model due to the dual regularization of
physics laws and prior knowledge, which exhibits better robustness compared to
traditional analysis methods. Our approach is capable of bridging the gap
between various structures with geometric scaling and under different loading
scenarios, and the convergence of training is also greatly accelerated through
not only the layer freezing but also the multi-task weight inheritance from
pre-trained models, thus making it possible to be applied as surrogate models
in actual engineering projects.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:49:56 GMT""},{""version"":""v2"",""created"":""Tue, 4 Oct 2022 15:20:51 GMT""},{""version"":""v3"",""created"":""Fri, 3 Feb 2023 17:11:12 GMT""}]","2023-02-06"
"2205.07732","Sandro Wimberger","Nikolai Bolik, Caspar Groiseau, Jerry H. Clark, Alexander Gresch,
  Siamak Dadras, Gil S. Summy, Yingmei Liu, and Sandro Wimberger","Light-shift induced behaviors observed in momentum-space quantum walks","experimental and theoretical paper on discrete-time quantum walks","Phys. Rev. A 106, 033307 (2022)","10.1103/PhysRevA.106.033307",,"quant-ph cond-mat.quant-gas","http://creativecommons.org/licenses/by/4.0/","  Over the last decade there have been many advances in studies of quantum
walks (QWs) including a momentum-space QW recently realized in our spinor
Bose-Einstein condensate system. This QW possessed behaviors that generally
agreed with theoretical predictions; however, it also showed momentum
distributions that were not adequately explained by the theory. We present a
theoretical model which proves that the coherent dynamics of the spinor
condensate is sufficient to explain the experimental data without invoking the
presence of a thermal cloud of atoms as in the original theory. Our numerical
findings are supported by an analytical prediction for the momentum
distributions in the limit of zero-temperature condensates. This current model
provides more complete explanations to the momentum-space QWs that can be
applied to study quantum search algorithms and topological phases in
Floquet-driven systems.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:50:05 GMT""},{""version"":""v2"",""created"":""Mon, 26 Sep 2022 11:26:26 GMT""}]","2022-09-27"
"2205.07733","Mario Marietti","Mario Marietti","Bruhat intervals and parabolic cosets in arbitrary Coxeter groups",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In [Journal of Pure and Applied Algebra {224} (2020), no 12, 106449], V.
Mazorchuk and R. Mr{\dj}en (with some help by A. Hultman) prove that, given a
Weyl group, the intersection of a Bruhat interval with a parabolic coset has a
unique maximal element and a unique minimal element. We show that such
intersections are actually Bruhat intervals also in the case of an arbitrary
Coxeter group.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:50:08 GMT""}]","2022-05-17"
"2205.07734","Hao Yu","Shaofei Du, Wenjuan Luo, Hao Yu and Junyang Zhang","Skew-Morphisms of Elementary Abelian p-Groups",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A skew-morphism of a finite group $G$ is a permutation $\sigma$ on $G$ fixing
the identity element, and for which there exists an integer function $\pi$ on
$G$ such that $\sigma(xy)=\sigma(x)\sigma^{\pi(x)}(y)$ for all $x,y\in G$. It
has been known that given a skew-morphism $\sigma $ of $G$, the product of
$\langle \sigma \rangle$ with the left regular representation of $G$ forms a
permutation group on $G$, called the skew-product group of $\sigma$. In this
paper, the skew-product groups of skew-morphisms of finite elementary abelian
$p$-groups are investigated. Some properties, characterizations and
constructions about that are obtained.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:53:47 GMT""},{""version"":""v2"",""created"":""Mon, 3 Oct 2022 03:03:42 GMT""}]","2022-10-04"
"2205.07735","Enrico Skoruppa","Enrico Skoruppa, Enrico Carlon","Equilibrium Fluctuations of DNA Plectonemes","13 pages, 8 figures",,"10.1103/PhysRevE.106.024412",,"cond-mat.soft physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Plectonemes are intertwined helically looped domains which form when a DNA
molecule is supercoiled, i.e. over- or under-wounded. They are ubiquitous in
cellular DNA and their physical properties have attracted significant interest
both from the experimental and modeling side. In this work, we investigate
fluctuations of the end-point distance z of supercoiled linear DNA molecules
subject to external stretching forces. Our analysis is based on a two-phase
model, which describes the supercoiled DNA as composed of a stretched and of a
plectonemic phase. Several different mechanisms are found to contribute to
extension fluctuations, characterized by the extension variance. We find the
dominant contribution to the variance to originate from phase-exchange
fluctuations, the transient shrinking and expansion of plectonemes, which is
accompanied by an exchange of molecular length between the two phases. We
perform Monte Carlo simulations of the Twistable Wormlike Chain and analyze the
fluctuation of various quantities, which are found to agree with the two-phase
model predictions. Furthermore, we show that the extension and its variance at
high forces are very well captured by the two-phase model, provided that one
goes beyond quadratic approximations.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:54:04 GMT""}]","2022-09-14"
"2205.07736","Chih-Hong Cheng","Chih-Hong Cheng, Changshun Wu, Emmanouil Seferis, Saddek Bensalem","Prioritizing Corners in OoD Detectors via Symbolic String Manipulation",,,,,"cs.SE cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For safety assurance of deep neural networks (DNNs), out-of-distribution
(OoD) monitoring techniques are essential as they filter spurious input that is
distant from the training dataset. This paper studies the problem of
systematically testing OoD monitors to avoid cases where an input data point is
tested as in-distribution by the monitor, but the DNN produces spurious output
predictions. We consider the definition of ""in-distribution"" characterized in
the feature space by a union of hyperrectangles learned from the training
dataset. Thus the testing is reduced to finding corners in hyperrectangles
distant from the available training data in the feature space. Concretely, we
encode the abstract location of every data point as a finite-length binary
string, and the union of all binary strings is stored compactly using binary
decision diagrams (BDDs). We demonstrate how to use BDDs to symbolically
extract corners distant from all data points within the training set. Apart
from test case generation, we explain how to use the proposed corners to
fine-tune the DNN to ensure that it does not predict overly confidently. The
result is evaluated over examples such as number and traffic sign recognition.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:56:56 GMT""}]","2022-05-17"
"2205.07737","Santabrata Das","Santabrata Das (IITG), Anuj Nandi (URSC), C. S. Stalin (IIA), Suvendu
  Rakshit (ARIES), Indu Kalpa Dihingia (IITI), Swapnil Singh (URSC), Ramiz
  Aktar (Xiamen University), Samik Mitra (IITG)","On the origin of core radio emissions from black hole sources in the
  realm of relativistic shocked accretion flow","15 pages, 4 figures, and 3 tables; accepted for publication in MNRAS",,"10.1093/mnras/stac1398",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the relativistic, inviscid, advective accretion flow around the
black holes and investigate a key feature of the accretion flow, namely the
shock waves. We observe that the shock-induced accretion solutions are
prevalent and such solutions are commonly obtained for a wide range of the flow
parameters, such as energy (${\cal E}$) and angular momentum ($\lambda$),
around the black holes of spin value $0\le a_{\rm k} < 1$. When the shock is
dissipative in nature, a part of the accretion energy is released through the
upper and lower surfaces of the disc at the location of the shock transition.
We find that the maximum accretion energies that can be extracted at the
dissipative shock ($\Delta{\cal E}^{\rm max}$) are $\sim 1\%$ and $\sim 4.4\%$
for Schwarzschild black holes ($a_{\rm k}\rightarrow 0$) and Kerr black holes
($a_{\rm k}\rightarrow 1$), respectively. Using $\Delta{\cal E}^{\rm max}$, we
compute the loss of kinetic power (equivalently shock luminosity, $L_{\rm
shock}$) that is enabled to comply with the energy budget for generating
jets/outflows from the jet base ($i.e.$, post-shock flow). We compare $L_{\rm
shock}$ with the observed core radio luminosity ($L_R$) of black hole sources
for a wide mass range spanning $10$ orders of magnitude with sub-Eddington
accretion rate and perceive that the present formalism seems to be potentially
viable to account $L_R$ of $16$ Galactic black hole X-ray binaries (BH-XRBs)
and $2176$ active galactic nuclei (AGNs). We further aim to address the core
radio luminosity of intermediate-mass black hole (IMBH) sources and indicate
that the present model formalism perhaps adequate to explain core radio
emission of IMBH sources in the sub-Eddington accretion limit.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:57:29 GMT""}]","2022-06-01"
"2205.07738","Kyle Ballantine","K. E. Ballantine, D. Wilkowski, and J. Ruostekoski","Optical magnetism and wavefront control by arrays of strontium atoms",,"Phys. Rev. Research 4, 033242 (2022)","10.1103/PhysRevResearch.4.033242",,"quant-ph cond-mat.quant-gas physics.atom-ph physics.optics","http://creativecommons.org/licenses/by/4.0/","  By analyzing the parameters of electronic transitions, we show how bosonic Sr
atoms in planar optical lattices can be engineered to exhibit optical magnetism
and other higher-order electromagnetic multipoles that can be harnessed for
wavefront control of incident light. Resonant $\lambda\simeq 2.6\mu$m light for
the $^3D_1\rightarrow {^3}P_0$ transition mediates cooperative interactions
between the atoms while the atoms are trapped in a deeply subwavelength optical
lattice. The atoms then exhibit collective excitation eigenmodes, e.g., with a
strong cooperative magnetic response at optical frequencies, despite individual
atoms having negligible coupling to the magnetic component of light. We provide
a detailed scheme to utilize excitations of such cooperative modes consisting
of arrays of electromagnetic multipoles to form an atomic Huygens' surface,
with complete $2\pi$ phase control of transmitted light and almost no
reflection, allowing nearly arbitrary wavefront shaping. In the numerical
examples, this is achieved by controlling the atomic level shifts of Sr with
off-resonant ${^3P}_J\rightarrow {^3D}_1$ transitions, which results in a
simultaneous excitation of arrays of electric dipoles and electric quadrupoles
or magnetic dipoles. We demonstrate the wavefront engineering for a Sr array by
realizing the steering of an incident beam and generation of a baby-Skyrmion
texture in the transmitted light via a topologically nontrivial transition of a
Gaussian beam to a Poincar\'{e} beam, which contains all possible polarizations
in a single cross-section.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:58:26 GMT""},{""version"":""v2"",""created"":""Tue, 16 Aug 2022 16:52:03 GMT""}]","2022-10-06"
"2205.07739","Takashi Takahashi","Takashi Takahashi","Sharp Asymptotics of Self-training with Linear Classifier","34 pages, 6 figures",,,,"stat.ML cond-mat.dis-nn cond-mat.stat-mech cs.LG math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Self-training (ST) is a straightforward and standard approach in
semi-supervised learning, successfully applied to many machine learning
problems. The performance of ST strongly depends on the supervised learning
method used in the refinement step and the nature of the given data; hence, a
general performance guarantee from a concise theory may become loose in a
concrete setup. However, the theoretical methods that sharply predict how the
performance of ST depends on various details for each learning scenario are
limited. This study develops a novel theoretical framework for sharply
characterizing the generalization abilities of the models trained by ST using
the non-rigorous replica method of statistical physics. We consider the ST of
the linear model that minimizes the ridge-regularized cross-entropy loss when
the data are generated from a two-component Gaussian mixture. Consequently, we
show that the generalization performance of ST in each iteration is sharply
characterized by a small finite number of variables, which satisfy a set of
deterministic self-consistent equations. By numerically solving these
self-consistent equations, we find that ST's generalization performance
approaches to the supervised learning method with a very simple regularization
schedule when the label bias is small and a moderately large number of
iterations are used.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:02:44 GMT""}]","2022-05-17"
"2205.07740","Vera Patricia Bader","Vera P. Bader, Jan Langmann, Philipp Gegenwart, and Alexander A.
  Tsirlin","Deformation of the triangular spin-$\frac{1}{2}$ lattice in
  Na$_2$SrCo(PO$_4$)$_2$",,"Phys. Rev. B 106, 054415 (2022)","10.1103/PhysRevB.106.054415",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  Crystal structure and thermodynamic properties of Na$_2$SrCo(PO$_4$)$_2$, the
chemical sibling of the triangular quantum spin-liquid candidate
Na$_2$BaCo(PO$_4$)$_2$, are reported. From single crystal x-ray diffraction and
high-resolution synchrotron x-ray powder diffraction, the compound was found to
crystallize in the monoclinic space group $P2_1/a$ at room temperature, in
contrast to the trigonal Na$_2$BaCo(PO$_4$)$_2$. Above 650 K, the symmetry of
Na$_2$SrCo(PO$_4$)$_2$ changes to $C2/m$, while around 1025 K a further
transformation toward trigonal symmetry is observed. The monoclinic symmetry
leads to a small deformation of the CoO$_6$ octahedra beyond the trigonal
distortion ubiquitous in this structure type, and results in the stronger
$g$-tensor anisotropy ($g_{\text{z}}/g_{\text{xy}} = 1.6 $) as well as the
increased XXZ anisotropy ($J_{\text{z}}/J_{\text{xy}} = 2.1$) compared to the
Ba compound ($g_{\text{z}}/g_{\text{xy}} = 1.1 $, $J_{\text{z}}/J_{\text{xy}} =
1.5$), while the average coupling strength,
$J_{\text{av}}/k_{\text{B}}=(2J_{\text{xy}}+J_{\text{z}})/3k_\text{B}\simeq
1.3\,\text{K}$, remains unchanged. The N\'{e}el temperature increases from 140
mK (Ba) to 600 mK (Sr), and an uncompensated in-plane moment of
$0.066(4)\mu_{\text{B}}/\text{f.u.}$ appears. We show that the ordering
temperature of a triangular antiferromagnet is capably controlled by its
structural distortions.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:06:55 GMT""},{""version"":""v2"",""created"":""Thu, 11 Aug 2022 09:28:34 GMT""}]","2022-08-12"
"2205.07741","Bardia Najjari Farizhendi","Manuel Drees, Bardia Najjari","Multi-Species Thermalization Cascade of Energetic Particles in the Early
  Universe",,,,,"hep-ph astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Heavy long-lived particles are abundant in BSM physics and will, under
generic circumstances, get to dominate the energy density of the universe. The
resulting matter dominated era has to end before the onset of Big Bang
Nucleosynthesis through the decay of the heavy matter component of mass $M$
into a thermal bath of temperature $T$. The process of thermalization primarily
involves near-collinear splittings of energetic particles into two particles
with lower energy. The correct treatment of these processes requires the
inclusion of coherence effects which suppress the splitting rate. We write down
and numerically solve the resulting coupled Boltzmann equations including all
gauge bosons and fermions of the Standard Model (SM). We then comment on the
dependence of the nonthermal spectra on the ratio $M/T$, as well as on the
matter decay rate and branching ratios into various SM particles.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:07:35 GMT""}]","2022-05-17"
"2205.07742","Nattavudh Powdthavee","George MacKerron and Nattavudh Powdthavee","Predicting Emotional Volatility Using 41,000 Participants in the United
  Kingdom","30 pages, 1 figure, 2 tables",,,,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  Emotional volatility is a human universal. Yet there has been no large-scale
scientific study of predictors of that phenomenon. Building from previous
works, which had been ad hoc and based on tiny samples, this paper reports the
first large-scale estimation of volatility in human emotional experiences. Our
study draws from a large sample of intrapersonal variation in moment-to-moment
happiness from over three million observations by 41,023 UK individuals.
Holding other things constant, we show that emotional volatility is highest
among women with children, the separated, the poor, and the young. Women
without children report substantially greater emotional volatility than men
with and without children. For any given rate of volatility, women with
children also experience more frequent extreme emotional lows than any other
socio-demographic group. Our results, which are robust to different
specification tests, enable researchers and policymakers to quantify and
prioritise different determinants of intrapersonal variability in human
emotions.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:10:56 GMT""},{""version"":""v2"",""created"":""Tue, 17 May 2022 02:12:24 GMT""}]","2022-05-18"
"2205.07743","Lena Katharina Schiffer","Andreas Maletti and Lena Katharina Schiffer (Universit\""at Leipzig)","Strong Equivalence of TAG and CCG","30 pages, 6 figures, revised and extended version of paper appearing
  in Trans. ACL (2021) 9: 707-720","Transactions of the Association for Computational Linguistics
  (2021) 9: 707-720","10.1162/tacl_a_00393",,"cs.FL cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tree-adjoining grammar (TAG) and combinatory categorial grammar (CCG) are two
well-established mildly context-sensitive grammar formalisms that are known to
have the same expressive power on strings (i.e., generate the same class of
string languages). It is demonstrated that their expressive power on trees also
essentially coincides. In fact, CCG without lexicon entries for the empty
string and only first-order rules of degree at most 2 are sufficient for its
full expressive power.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:12:03 GMT""}]","2022-05-17"
"2205.07744","Attila Krasznahorkay","N.J. Sas, A.J. Krasznahorkay, M. Csatl\'os, J. Guly\'as, B. Kert\'esz,
  A. Krasznahorkay, J. Moln\'ar, I. Rajta, J. Tim\'ar, I. Vajda, M.N. Harakeh","Observation of the X17 anomaly in the $^7$Li($p$,$e^+e^-$)$^8$Be direct
  proton-capture reaction",,,,,"nucl-ex","http://creativecommons.org/licenses/by/4.0/","  Angular correlation spectra of $e^+e^-$ pairs produced in the
$^{7}$Li($p$,$\gamma$)$^{8}$Be nuclear reaction have been studied at the sharp
$E_p$= 441 keV resonance as well as at $E_p$= 650 keV, 800 keV and 1100 keV
proton beam energies. The spectra measured at the resonance can be understood
through the M1 internal pair creation process, but in the case of the
off-resonance regions (direct proton capture) significant anomalies were
observed in the $e^+e^-$ angular correlations supporting the X17 hypothetical
particle creation and decay.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:12:55 GMT""}]","2022-05-17"
"2205.07745","Marija Mitrovic Dankulov","Ana Vrani\'c, Aleksandar Toma\v{s}evi\'c, Aleksandra Alori\'c, and
  Marija Mitrovi\'c Dankulov","Sustainability of Stack Exchange Q\&A communities: the role of trust",,,,,"physics.soc-ph cs.SI","http://creativecommons.org/licenses/by/4.0/","  Knowledge-sharing communities are a fundamental element of any
knowledge-based society. Understanding how they emerge, function, and disappear
is thus of crucial importance. Many social and economic factors influence
sustainable knowledge-sharing communities. Here we explore the role of the
structure of social interactions and social trust in the emergence of these
communities. Using tools from complex network theory, we analyze the early
evolution of social structure in four pairs of StackExchange communities, each
corresponding to one active and one closed community on the same topic. We
adapt the dynamical reputation model to quantify the evolution of social trust
in these communities. Our analysis shows that active communities have higher
local cohesiveness and develop stable and more strongly connected cores. The
average reputation is higher in sustainable communities. In these communities,
the trust between core members develops early and remains high over time. Our
results imply that efforts to create a stable and trustworthy core may be
crucial for building a sustainable knowledge-sharing community.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:13:53 GMT""}]","2022-05-17"
"2205.07746","Hugo Roussille","David Langlois, Karim Noui, Hugo Roussille","On the effective metric of axial black hole perturbations in DHOST
  gravity","Version accepted in JCAP","JCAP 08 (2022) 08, 040","10.1088/1475-7516/2022/08/040",,"gr-qc hep-th","http://creativecommons.org/publicdomain/zero/1.0/","  We study axial (or odd-parity) perturbations about static and spherically
symmetric hairy black hole (BH) solutions in shift-symmetric DHOST (Degenerate
Higher-Order Scalar-Tensor) theories. We first extend to the family of DHOST
theories the first-order formulation that we recently developed for Horndeski
theories. Remarkably, we find that the dynamics of DHOST axial perturbations is
equivalent to that of axial perturbations in general relativity (GR) evolving
in a, distinct, effective metric. In the particular case of quadratic DHOST
theories, this effective metric is derived from the background BH metric via a
disformal transformation. We illustrate our general study with three examples
of BH solutions. In some so-called stealth solutions, the effective metric is
Schwarzschild with a shifted horizon. We also give an example of BH solution
for which the effective metric is associated with a naked singularity.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:17:17 GMT""},{""version"":""v2"",""created"":""Wed, 2 Nov 2022 12:08:58 GMT""}]","2022-11-03"
"2205.07747","Micah Chrisman","Micah Chrisman, Sujoy Mukherjee","Hyperbolic Knots and Torsion in Khovanov Homology","10 pages, 8 figures. Comments welcome. v2-typo corrected in ArXiv
  metadata. No change to paper",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note, we show that if there is a knot in $S^3$ having $\mathbb{Z}_m$
torsion in its Khovanov homology, then there are infinitely many hyperbolic
knots and infinitely many prime satellite knots having $\mathbb{Z}_m$ torsion
in their Khovanov homology. As an application, we give the first known examples
of hyperbolic knots and links with odd (and other non-$\mathbb{Z}_2$ torsion)
in their Khovanov homology.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:21:51 GMT""},{""version"":""v2"",""created"":""Tue, 17 May 2022 17:02:19 GMT""}]","2022-05-18"
"2205.07748","Theodoros Papanikolaou","Theodoros Papanikolaou","Toward the primordial black hole formation threshold in a time-dependent
  equation-of-state background","Rescaling of the x-axis of Fig. 2",,"10.1103/PhysRevD.105.124055",,"gr-qc astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The study of the primordial black hole (PBH) gravitational collapse process
requires the determination of a critical energy density perturbation threshold
$\delta_\mathrm{c}$, which depends on the equation of state of the universe at
the time of PBH formation. Up to now, the majority of analytical and numerical
techniques calculate $\delta_\mathrm{c}$ by assuming a constant
equation-of-state (EoS) parameter $w$ at the time of PBH formation. In this
work, after generalizing the constant $w$ prescription of [1] for the
computation of $\delta_\mathrm{c}$ and commenting its limitations we give a
first estimate for the PBH threshold in the case of a time-dependent $w$
background. In particular, we apply our formalism in the case of the QCD phase
transition, where the EoS parameter varies significantly with time and one
expects an enhanced PBH production due to the abrupt softening of $w$. At the
end, we compare our results with analytic and numerical approaches for the
determination of $\delta_\mathrm{c}$ assuming a constant EoS parameter.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:22:32 GMT""},{""version"":""v2"",""created"":""Wed, 22 Jun 2022 16:27:48 GMT""},{""version"":""v3"",""created"":""Fri, 26 Aug 2022 11:18:52 GMT""}]","2022-08-29"
"2205.07749","Nikolai Chugai","Nikolai Chugai and Victor Utrobin","Circumstellar shell and presupernova emission of SN 2020tlf","Accepted by Astronomy Letters",,,,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We address a phenomenon of a confined circumstellar (CS) dense shell and
powerful presupernova emission of SN 2020tlf (type IIP). Modeling the \ha\ line
and the circumstellar interaction implies the CS shell radius of
$\sim$10$^{15}$ cm and the mass of $\sim0.2M_{\odot}$ lost during $\sim$6 yr
prior to the explosion. Spectra and photometry of the supernova after the
explosion do not show apparent signature of the material lost by the
presupernova during its powerful luminosity. This material presumably resided
in the inner zone of the CS shell. We present a hydrodynamic model of the
outcome of a flash with the energy of $5\times10^{48}$ erg in the convective
nuclear burning zone. The model predicts the ejection of outer layers of the
presupernova ($\sim0.1M_{\odot}$) and the luminosity of $10^{40}$ erg s$^{-1}$
during several hundreds days in accord with observations. We propose the
Lighthill mechanism of acoustic waves generation by the turbulence of the
convective nuclear burning zone to account for the phenomenon of a compact CS
shell of supernovae related to the core collapse.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:23:17 GMT""}]","2022-05-17"
"2205.07750","Mikael Brunila","Mikael Brunila and Jack LaViolette","What company do words keep? Revisiting the distributional semantics of
  J.R. Firth & Zellig Harris","Accepted at NAACL 2022 (main track)",,,,"cs.CL cs.AI cs.CY","http://creativecommons.org/licenses/by-sa/4.0/","  The power of word embeddings is attributed to the linguistic theory that
similar words will appear in similar contexts. This idea is specifically
invoked by noting that ""you shall know a word by the company it keeps,"" a quote
from British linguist J.R. Firth who, along with his American colleague Zellig
Harris, is often credited with the invention of ""distributional semantics.""
While both Firth and Harris are cited in all major NLP textbooks and many
foundational papers, the content and differences between their theories is
seldom discussed. Engaging in a close reading of their work, we discover two
distinct and in many ways divergent theories of meaning. One focuses
exclusively on the internal workings of linguistic forms, while the other
invites us to consider words in new company - not just with other linguistic
elements, but also in a broader cultural and situational context. Contrasting
these theories from the perspective of current debates in NLP, we discover in
Firth a figure who could guide the field towards a more culturally grounded
notion of semantics. We consider how an expanded notion of ""context"" might be
modeled in practice through two different strategies: comparative
stratification and syntagmatic extension
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:24:30 GMT""}]","2022-05-17"
"2205.07751","Simon Good","S. W. Good, L. M. Hatakka, M. Ala-Lahti, J. E. Soljento, A. Osmane, E.
  K. J. Kilpua","Cross helicity of interplanetary coronal mass ejections at 1 au","9 pages, 6 figures, accepted for publication in the Monthly Notices
  of the Royal Astronomical Society 2022 May 16",,"10.1093/mnras/stac1388",,"physics.space-ph astro-ph.SR physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Interplanetary coronal mass ejections (ICMEs) contain magnetic field and
velocity fluctuations across a wide range of scales. These fluctuations may be
interpreted as Alfv\'enic wave packets propagating parallel or anti-parallel to
the background magnetic field, with the difference in power between
counter-propagating fluxes quantified by the cross helicity. We have determined
the cross helicity of inertial range fluctuations at $10^{-3}-10^{-2}$ Hz in
226 ICME flux ropes and 176 ICME sheaths observed by the Wind spacecraft at 1
au during 1995-2015. The flux ropes and sheaths had mean, normalised cross
helicities of 0.18 and 0.24, respectively, with positive values here indicating
net anti-sunward fluxes. While still tipped towards the anti-sunward direction
on average, fluxes in ICMEs tend to be more balanced than in the solar wind at
1 au, where the mean cross helicity is larger. Superposed epoch profiles show
cross helicity falling sharply in the sheath and reaching a minimum inside the
flux rope near the leading edge. More imbalanced, solar wind-like cross
helicity was found towards the trailing edge and laterally further from the
rope axis. The dependence of cross helicity on flux rope orientation and the
presence of an upstream shock are considered. Potential origins of the low
cross helicity in ICMEs at 1 au include balanced driving of the closed-loop
flux rope at the Sun and ICME-solar wind interactions in interplanetary space.
We propose that low cross helicity of fluctuations is added to the standard
list of ICME signatures.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:25:46 GMT""}]","2022-05-23"
"2205.07752","Vasileios Sitokonstantinou","Thanassis Drivas, Vasileios Sitokonstantinou, Iason Tsardanidis,
  Alkiviadis Koukos, Charalampos Kontoes, Vassilia Karathanassi","A Data Cube of Big Satellite Image Time-Series for Agriculture
  Monitoring","This work has been accepted for publication in IEEE 14th Image,
  Video, and Multidimensional Signal Processing Workshop (IVMSP 2022)",,,,"cs.CV cs.DB cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The modernization of the Common Agricultural Policy (CAP) requires the large
scale and frequent monitoring of agricultural land. Towards this direction, the
free and open satellite data (i.e., Sentinel missions) have been extensively
used as the sources for the required high spatial and temporal resolution Earth
observations. Nevertheless, monitoring the CAP at large scales constitutes a
big data problem and puts a strain on CAP paying agencies that need to adapt
fast in terms of infrastructure and know-how. Hence, there is a need for
efficient and easy-to-use tools for the acquisition, storage, processing and
exploitation of big satellite data. In this work, we present the Agriculture
monitoring Data Cube (ADC), which is an automated, modular, end-to-end
framework for discovering, pre-processing and indexing optical and Synthetic
Aperture Radar (SAR) images into a multidimensional cube. We also offer a set
of powerful tools on top of the ADC, including i) the generation of
analysis-ready feature spaces of big satellite data to feed downstream machine
learning tasks and ii) the support of Satellite Image Time-Series (SITS)
analysis via services pertinent to the monitoring of the CAP (e.g., detecting
trends and events, monitoring the growth status etc.). The knowledge extracted
from the SITS analyses and the machine learning tasks returns to the data cube,
building scalable country-specific knowledge bases that can efficiently answer
complex and multi-faceted geospatial queries.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:26:23 GMT""}]","2022-05-17"
"2205.07753","Bernd Siebert","Michael Carl, Max Pumperla, Bernd Siebert","A tropical view on Landau-Ginzburg models","53 pages, 17 figures, 2010 version submitted as ancillary file",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper, largely written in 2009/2010, fits Landau-Ginzburg models into
the mirror symmetry program pursued by the last author jointly with Mark Gross
since 2001. This point of view transparently brings in tropical disks of Maslov
index 2 via the notion of broken lines, previously introduced in two dimensions
by Mark Gross in his study of mirror symmetry for $\mathbb{P}^2$.
  A major insight is the equivalence of properness of the Landau-Ginzburg
potential with smoothness of the anticanonical divisor on the mirror side. We
obtain proper superpotentials which agree on an open part with those
classically known for toric varieties. Examples include mirror LG models for
non-singular and singular del Pezzo surfaces, Hirzebruch surfaces and some Fano
threefolds.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:27:38 GMT""}]","2022-05-17"
"2205.07754","Matthew Young","Matthew P Young","On the spectral large sieve inequality for symmetric-squares","16 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We improve on the spectral large sieve inequality for symmetric-squares. We
also prove a lower bound showing that the most optimistic upper bound is not
true for this family.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:30:04 GMT""}]","2022-05-17"
"2205.07755","Zheshen Zhang","Chaohan Cui, William Horrocks, Shuhong Hao, Saikat Guha, N.
  Peyghambarian, Quntao Zhuang, Zheshen Zhang","Quantum Receiver Enhanced by Adaptive Learning","13 pages, 7 figures","Light Sci. Appl. 11, 344 (2022)","10.1038/s41377-022-01039-5",,"quant-ph physics.optics","http://creativecommons.org/licenses/by/4.0/","  Quantum receivers aim to effectively navigate the vast quantum-state space to
endow quantum information processing capabilities unmatched by classical
receivers. To date, only a handful of quantum receivers have been constructed
to tackle the problem of discriminating coherent states. Quantum receivers
designed by analytical approaches, however, are incapable of effectively
adapting to diverse environment conditions, resulting in their quickly
diminishing performance as the operational complexities increase. Here, we
present a general architecture, dubbed the quantum receiver enhanced by
adaptive learning (QREAL), to adapt quantum receiver structures to diverse
operational conditions. QREAL is experimentally implemented in a hardware
platform with record-high efficiency. Combining the QREAL architecture and the
experimental advances, the error rate is reduced up to 40% over the standard
quantum limit in two coherent-state encoding schemes.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:30:16 GMT""}]","2022-12-22"
"2205.07756","Manuel Sorge","Stephen G. Kobourov, Maarten L\""offler, Fabrizio Montecchiani, Marcin
  Pilipczuk, Ignaz Rutter, Raimund Seidel, Manuel Sorge, Jules Wulms","The Influence of Dimensions on the Complexity of Computing Decision
  Trees","13 pages, 8 figures",,,,"cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A decision tree recursively splits a feature space $\mathbb{R}^{d}$ and then
assigns class labels based on the resulting partition. Decision trees have been
part of the basic machine-learning toolkit for decades. A large body of work
treats heuristic algorithms to compute a decision tree from training data,
usually aiming to minimize in particular the size of the resulting tree. In
contrast, little is known about the complexity of the underlying computational
problem of computing a minimum-size tree for the given training data. We study
this problem with respect to the number $d$ of dimensions of the feature space.
We show that it can be solved in $O(n^{2d + 1}d)$ time, but under reasonable
complexity-theoretic assumptions it is not possible to achieve $f(d) \cdot
n^{o(d / \log d)}$ running time, where $n$ is the number of training examples.
The problem is solvable in $(dR)^{O(dR)} \cdot n^{1+o(1)}$ time, if there are
exactly two classes and $R$ is an upper bound on the number of tree leaves
labeled with the first~class.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:30:56 GMT""},{""version"":""v2"",""created"":""Thu, 2 Jun 2022 14:24:33 GMT""}]","2022-06-03"
"2205.07757","Manuel Pino Garc\'ia","Mar\'ia Hita-P\'erez, Pedro Orellana, Juan Jos\'e Garc\'ia-Ripoll,
  Manuel Pino","Bound states in the continuum in a fluxonium qutrit","8 pages",,"10.1103/PhysRevA.106.062602",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  The heavy fluxonium at zero external flux has a long-lived state when coupled
capacitively to any other system. We analyze it by projecting all the fluxonium
relevant operators into the qutrit subspace, as this long-lived configuration
corresponds to the second excited fluxonium level. This state becomes a
bound-state in the continuum (BIC) when the coupling occurs to an extended
state supporting a continuum of modes. In the case without noise, we find BIC
decay times that can be much larger than seconds $T_1\gg {\rm s}$ when the
fluxonium is coupled to superconducting waveguide, while typical device
frequencies are in the order of ${\rm GHz}$. We have also analyzed the noise in
a realistic situation, arguing that the most dangerous noise source is the
well-known 1/f flux noise. Even in its presence, we show that decay times could
reach the range of ${T_1\sim \rm 10 ms}.$
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:31:22 GMT""},{""version"":""v2"",""created"":""Tue, 21 Jun 2022 10:54:51 GMT""}]","2022-12-14"
"2205.07758","Hampus Renberg Nilsson","Hampus Renberg Nilsson, Anita Fadavi Roudsari, Daryoush Shiri, Per
  Delsing, Vitaly Shumeiko","A high gain travelling-wave parametric amplifier based on three-wave
  mixing",,"Phys. Rev. Applied 19, 044056 (2023)","10.1103/PhysRevApplied.19.044056",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We extend the theory for a Josephson junction travelling wave parametric
amplifier (TWPA) operating in the three-wave mixing regime and we propose a
scheme for achieving high gain. The continuous three-mode model [P. K. Tien, J.
Appl. Phys. 29, 1347 (1958)] is on one hand extended to describe a discrete
chain of Josephson junctions at high frequencies close to the spectral cutoff
where there is no up-conversion. On the other hand, we also develop a
continuous multimode theory for the low-frequency region where the frequency
dispersion is close to linear. We find that in both cases the gain is
significantly reduced compared to the prediction by the continuous three-mode
model as the result of increasingly strong dispersion at the high frequencies
and generation of up-converted modes at the low frequencies. The developed
theory is in quantitative agreement with experimental observations. To recover
the high gain, we propose to engineer a chain with dispersive features to form
a two-band frequency spectrum and to place the pump frequency within the upper
band close to the spectral cutoff. We prove that there exists a sweet spot,
where the signal and the pump are phase matched, while the up-conversion is
inhibited. This results in a high gain which grows exponentially with the
length of the TWPA.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:31:45 GMT""}]","2023-05-30"
"2205.07759","Giorgio Di Tizio","Giorgio Di Tizio, Michele Armellini, Fabio Massacci","Software Updates Strategies: a Quantitative Evaluation against Advanced
  Persistent Threats",,,"10.1109/TSE.2022.3176674",,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  Software updates reduce the opportunity for exploitation. However, since
updates can also introduce breaking changes, enterprises face the problem of
balancing the need to secure software with updates with the need to support
operations. We propose a methodology to quantitatively investigate the
effectiveness of software updates strategies against attacks of Advanced
Persistent Threats (APTs). We consider strategies where the vendor updates are
the only limiting factors to cases in which enterprises delay updates from 1 to
7 months based on SANS data. Our manually curated dataset of APT attacks covers
86 APTs and 350 campaigns from 2008 to 2020. It includes information about
attack vectors, exploited vulnerabilities (e.g. 0-days vs public
vulnerabilities), and affected software and versions. Contrary to common
belief, most APT campaigns employed publicly known vulnerabilities. If an
enterprise could theoretically update as soon as an update is released, it
would face lower odds of being compromised than those waiting one (4.9x) or
three (9.1x) months. However, if attacked, it could still be compromised from
14% to 33% of the times. As in practice enterprises must do regression testing
before applying an update, our major finding is that one could perform 12% of
all possible updates restricting oneself only to versions fixing publicly known
vulnerabilities without significant changes to the odds of being compromised
compared to a company that updates for all versions.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:33:36 GMT""},{""version"":""v2"",""created"":""Wed, 25 May 2022 09:30:38 GMT""}]","2022-05-26"
"2205.07760","Titouan Carette","Titouan Carette","Propification and the Scalable Comonad",,,,,"math.CT quant-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  String diagrams can nicely express numerous computations in symmetric strict
monoidal categories (SSMC). To be entirely exact, this is only true for props:
the SSMCs whose monoid of objects are free. In this paper, we show a
propification theorem asserting that any SSMC is monoidally equivalent to a
coloured prop. As a consequence, all SSMCs are within reach of diagrammatical
methods. We introduce a diagrammatical calculus of bureaucracy isomorphisms,
allowing us to handle graphically non-free monoids of objects. We also connect
this construction with the scalable notations previously introduced to tackle
large-scale diagrammatic reasoning.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:35:02 GMT""}]","2022-05-17"
"2205.07761","Mustafa Anwer Al Khafaji","Mustafa A. Al Khafaji, Claire M. Cisowski, Harry Jimbrown, Sarah
  Croke, Sebasti\~ao P\'adua, Sonja Franke-Arnold","Single-shot characterization of vector beams by generalized measurements",,"Optics Express Vol. 30, Issue 13, pp. 22396-22409 (2022)","10.1364/OE.458352",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Vector vortex beams, featuring independent spatial modes in orthogonal
polarization components, offer an increase in information density for emerging
applications in both classical and quantum communication technology. Recent
advances in optical instrumentation have led to the ability of generating and
manipulating such beams. Their tomography is generally accomplished by
projection measurements to identify polarization as well as spatial modes. In
this paper we demonstrate spatially resolved generalized measurements of
arbitrary vector vortex beams. We perform positive operator valued measurements
(POVMs) in an interferometric setup that characterizes the vector light mode in
a single-shot. This offers superior data acquisition speed compared to
conventional Stokes tomography techniques, with potential benefits for
communication protocols as well as dynamic polarization microscopy of
materials.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:37:44 GMT""},{""version"":""v2"",""created"":""Wed, 25 May 2022 15:10:21 GMT""}]","2022-06-08"
"2205.07762","Wubing Qin","Wubing B. Qin, Zhaojian Li","A Nonlinear Lateral Controller Design for Vehicle Path-following with an
  Arbitrary Sensor Location","11 pages, 9 figures, 1 table, submitted to IEEE Transactions on
  Intelligent Vehicles",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper investigates the lateral control problem in vehicular
path-following when the feedback sensor(s) are mounted at an arbitrary location
in the longitudinal symmetric axis. We point out that some existing literature
has abused the kinematic bicycle model describing the motion of rear axle
center for other locations, which may lead to poor performance in practical
implementations. A new nonlinear controller with low-complexity and
high-maneuverability is then designed that takes into account senor mounting
location, driving comfort and transient response with large initial errors.
Design insights and intuitions are also provided in detail. Furthermore,
analysis on stability and tracking performance for the closed-loop system are
studied, and conditions and guidelines are provided on the selection of control
parameters. Comprehensive simulations are performed to demonstrate the efficacy
of the proposed nonlinear controller for arbitrary sensor locations. Meanwhile,
we also show that designing controllers ignoring the sensor location may lead
to unexpected vehicular sway motion in non-straight paths.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:38:19 GMT""}]","2022-05-17"
"2205.07763","Zhenpei Yang","Zhenpei Yang, Zhile Ren, Miguel Angel Bautista, Zaiwei Zhang, Qi Shan,
  Qixing Huang","FvOR: Robust Joint Shape and Pose Optimization for Few-view Object
  Reconstruction","CVPR 2022",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reconstructing an accurate 3D object model from a few image observations
remains a challenging problem in computer vision. State-of-the-art approaches
typically assume accurate camera poses as input, which could be difficult to
obtain in realistic settings. In this paper, we present FvOR, a learning-based
object reconstruction method that predicts accurate 3D models given a few
images with noisy input poses. The core of our approach is a fast and robust
multi-view reconstruction algorithm to jointly refine 3D geometry and camera
pose estimation using learnable neural network modules. We provide a thorough
benchmark of state-of-the-art approaches for this problem on ShapeNet. Our
approach achieves best-in-class results. It is also two orders of magnitude
faster than the recent optimization-based approach IDR. Our code is released at
\url{https://github.com/zhenpeiyang/FvOR/}
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:39:27 GMT""}]","2022-05-17"
"2205.07764","Matteo Giordano","Matteo Giordano and Kolyan Ray and Johannes Schmidt-Hieber","On the inability of Gaussian process regression to optimally learn
  compositional functions","20 pages, to appear in Advances in Neural Information Processing
  Systems 36 (NeurIPS 2022)",,,,"stat.ML cs.LG math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We rigorously prove that deep Gaussian process priors can outperform Gaussian
process priors if the target function has a compositional structure. To this
end, we study information-theoretic lower bounds for posterior contraction
rates for Gaussian process regression in a continuous regression model. We show
that if the true function is a generalized additive function, then the
posterior based on any mean-zero Gaussian process can only recover the truth at
a rate that is strictly slower than the minimax rate by a factor that is
polynomially suboptimal in the sample size $n$.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:42:25 GMT""},{""version"":""v2"",""created"":""Tue, 27 Sep 2022 13:02:49 GMT""}]","2022-09-28"
"2205.07765","Prashanth Ramadoss","Prashanth Ramadoss, Stefano Dafarra, Silvio Traversaro and Daniele
  Pucci","An Experimental Comparison of Floating Base Estimators for Humanoid
  Robots with Flat Feet","Submitted to RA-L",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Extended Kalman filtering is a common approach to achieve floating base
estimation of a humanoid robot. These filters rely on measurements from an
Inertial Measurement Unit (IMU) and relative forward kinematics for estimating
the base position-and-orientation and its linear velocity along with the
augmented states of feet position-and-orientation, thus giving them their name,
flat-foot filters. However, the availability of only partial measurements often
poses the question of consistency in the filter design. In this paper, we
perform an experimental comparison of state-of-the-art flat-foot filters based
on the representation choice of state, observation, matrix Lie group error and
system dynamics evaluated for filter consistency and trajectory errors. The
comparison is performed over simulated and real-world experiments conducted on
the iCub humanoid platform.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:44:37 GMT""}]","2022-05-17"
"2205.07766","Camilla Cecilia Conti Dr.","Camilla C. Conti, Alberto Fusetti, Andrea Spinelli, Paolo Gaetani,
  Alberto Guardone","Pneumatic System for Pressure Probe Measurements in Transient Flows of
  Non-Ideal Vapors Subject to Line Condensation","29 pages, 16 figures. Research was funded by ERC Proof of Concept
  Grant N. 875015, project PROVA: Pitot PRobe for non-ideal compressible flows
  of organic VApors for renewable energy applications under the Horizon 2020
  Framework Programme, call: ERC-2019-PoC","Measurement, Volume 192, 2022, 110802, ISSN 0263-2241","10.1016/j.measurement.2022.110802",,"physics.ins-det physics.flu-dyn","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper presents the design, construction and commissioning of a pneumatic
system for pressure probe measurements in flows of organic vapors in non-ideal
conditions, close to the liquid-vapor saturation curve and the critical point
where the ideal gas law is not applicable. Experiments were performed with
fluid siloxane MM, employed in medium/high temperature Organic Rankine Cycles,
in the TROVA blow-down wind tunnel at Politecnico Milano. Challenges linked to
condensation in pneumatic lines (vapor-liquid menisci, hydrostatic head,
mass-sink), were evaluated with theoretical calculation and experiments, and
were avoided with a nitrogen flushing procedure. Commissioning tests were
performed with a Pitot tube in non-ideal subsonic flows at Mach numbers of 0.2
and 0.5. Measurement delay issues were identified and solved through a dynamic
testing procedure. The correct performance of the complete system was verified
for probe measurements of total, static and dynamic pressure in non-ideal flows
of organic vapors.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:45:46 GMT""},{""version"":""v2"",""created"":""Tue, 17 May 2022 04:41:05 GMT""}]","2022-05-18"
"2205.07767","Hanrui Zhang","Hanrui Zhang, Yu Cheng, Vincent Conitzer","Efficient Algorithms for Planning with Participation Constraints","EC 2022",,,,"cs.GT cs.AI cs.DS cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of planning with participation constraints introduced
in [Zhang et al., 2022]. In this problem, a principal chooses actions in a
Markov decision process, resulting in separate utilities for the principal and
the agent. However, the agent can and will choose to end the process whenever
his expected onward utility becomes negative. The principal seeks to compute
and commit to a policy that maximizes her expected utility, under the
constraint that the agent should always want to continue participating. We
provide the first polynomial-time exact algorithm for this problem for
finite-horizon settings, where previously only an additive
$\varepsilon$-approximation algorithm was known. Our approach can also be
extended to the (discounted) infinite-horizon case, for which we give an
algorithm that runs in time polynomial in the size of the input and
$\log(1/\varepsilon)$, and returns a policy that is optimal up to an additive
error of $\varepsilon$.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:47:41 GMT""}]","2022-05-17"
"2205.07768","Charles Robson","Charles W. Robson and Marco Ornigotti","Rewinding the Void: How One Solution of Einstein's Field Equations
  Describes Both the Birth of a Universe and the End of Time",,,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The type D Kasner vacuum solution of general relativity is reviewed,
highlighting the little-known, intriguing property that it can describe both an
anisotropic cosmology and the spacetime deep within a black hole, these two
descriptions linked by a reversal of the time-ordering of the solution. The
flexible nature of solutions of Einstein's equations is emphasised, and a brief
discussion of the arrow of time in modern physics is presented.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:47:51 GMT""}]","2022-05-17"
"2205.07769","Jianfeng Zhan","Jianfeng Zhan","A BenchCouncil View on Benchmarking Emerging and Future Computing","To appear BenchCouncil Transactions on Benchmarks, Standards and
  Evaluation (TBench)",,,,"cs.ET cs.PF","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The measurable properties of the artifacts or objects in the computer,
management, or finance disciplines are extrinsic, not inherent -- dependent on
their problem definitions and solution instantiations. Only after the
instantiation can the solutions to the problem be measured. The processes of
definition, instantiation, and measurement are entangled, and they have complex
mutual influences. Meanwhile, the technology inertia brings instantiation bias
-- trapped into a subspace or even a point at a high-dimension solution space.
These daunting challenges, which emerging computing aggravates, make metrology
can not work for benchmark communities. It is pressing to establish independent
benchmark science and engineering.
  This article presents a unifying benchmark definition, a conceptual
framework, and a traceable and supervised learning-based benchmarking
methodology, laying the foundation for benchmark science and engineering. I
also discuss BenchCouncil's plans for emerging and future computing. The
ongoing projects include defining the challenges of intelligence, instinct,
quantum computers, Metaverse, planet-scale computers, and reformulating data
centers, artificial intelligence for science, and CPU benchmark suites. Also,
BenchCouncil will collaborate with ComputerCouncil on open-source computer
systems for planet-scale computing, AI for science systems, and Metaverse.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:47:59 GMT""}]","2022-05-17"
"2205.07770","Brayan Monroy","Brayan Monroy, Jorge Bacca, Henry Arguello","JR2net: A Joint Non-Linear Representation and Recovery Network for
  Compressive Spectral Imaging",,,"10.1364/AO.463726",,"eess.IV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning models are state-of-the-art in compressive spectral imaging
(CSI) recovery. These methods use a deep neural network (DNN) as an image
generator to learn non-linear mapping from compressed measurements to the
spectral image. For instance, the deep spectral prior approach uses a
convolutional autoencoder network (CAE) in the optimization algorithm to
recover the spectral image by using a non-linear representation. However, the
CAE training is detached from the recovery problem, which does not guarantee
optimal representation of the spectral images for the CSI problem. This work
proposes a joint non-linear representation and recovery network (JR2net),
linking the representation and recovery task into a single optimization
problem. JR2net consists of an optimization-inspired network following an ADMM
formulation that learns a non-linear low-dimensional representation and
simultaneously performs the spectral image recovery, trained via the end-to-end
approach. Experimental results show the superiority of the proposed method with
improvements up to 2.57 dB in PSNR and performance around 2000 times faster
than state-of-the-art methods.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:48:42 GMT""},{""version"":""v2"",""created"":""Fri, 9 Sep 2022 03:11:06 GMT""}]","2022-09-12"
"2205.07771","Stefan Grisard","S. Grisard, H. Rose, A.V. Trifonov, R. Reichhardt, D.E. Reiter, M.
  Reichelt, C. Schneider, M. Kamp, S. H\""ofling, M. Bayer, T. Meier, I.A.
  Akimov","Multiple Rabi rotations of trions in InGaAs quantum dots observed by
  photon echo spectroscopy with spatially shaped laser pulses",,,"10.1103/PhysRevB.106.205408",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study Rabi rotations arising in intensity-dependent photon echoes from an
ensemble of self-assembled InGaAs quantum dots. To achieve a uniform
distribution of intensities within the excited ensemble, we introduce flattop
intensity profiles of picosecond laser pulses. This allows us to overcome the
damping of Rabi rotations imposed by the spatial inhomogeneity of Rabi
frequencies by a Gaussian laser profile. Using photon echo polarimetry, we
distinguish between the coherent optical responses from exciton and trion
ensembles. Here, we demonstrate that a photo-induced charging of the quantum
dots leads to a significant reduction of the number of neutral quantum dots
under resonant excitation with intensive optical pulses with areas exceeding
$\frac{\pi}{2}$. The trion ensemble shows robust Rabi rotations when the area
of the refocussing pulse is increased up to 5.5$\pi$. We analyze the remaining
attenuation of Rabi rotations by theoretical modeling of excitation induced
dephasing, inhomogeneity of dipole moments, and coupling to acoustic phonons.
The latter is identified as the dominating mechanism resulting in a loss of
optical coherence during the action of the involved optical pulses.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:50:44 GMT""},{""version"":""v2"",""created"":""Mon, 19 Sep 2022 12:32:07 GMT""},{""version"":""v3"",""created"":""Tue, 20 Sep 2022 07:48:10 GMT""}]","2022-11-23"
"2205.07772","Chendi Qu","Chendi Qu, Jianping He, Jialun Li, Chongrong Fang, Yilin Mo","Moving Target Interception Considering Dynamic Environment",,,,,"cs.RO cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The interception of moving targets is a widely studied issue. In this paper,
we propose an algorithm of intercepting the moving target with a wheeled mobile
robot in a dynamic environment. We first predict the future position of the
target through polynomial fitting. The algorithm then generates an interception
trajectory with path and speed decoupling. We use Hybrid A* search to plan a
path and optimize it via gradient decent method. To avoid the dynamic obstacles
in the environment, we introduce ST graph for speed planning. The speed curve
is represented by piecewise B\'ezier curves for further optimization. Compared
with other interception algorithms, we consider a dynamic environment and plan
a safety trajectory which satisfies the kinematic characteristics of the
wheeled robot while ensuring the accuracy of interception. Simulation
illustrates that the algorithm successfully achieves the interception tasks and
has high computational efficiency.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:55:36 GMT""}]","2022-05-17"
"2205.07883","Barak Or","Maxim Freydin and Barak Or","Learning Car Speed Using Inertial Sensors for Dead Reckoning Navigation","4 pages. Accepted to IEEE Sensors Letters (22 August 2022)",,"10.1109/LSENS.2022.3201731",,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A deep neural network (DNN) is trained to estimate the speed of a car driving
in an urban area using as input a stream of measurements from a low-cost
six-axis inertial measurement unit (IMU). Three hours of data was collected by
driving through the city of Ashdod, Israel in a car equipped with a global
navigation satellite system (GNSS) real time kinematic (RTK) positioning device
and a synchronized IMU. Ground truth labels for the car speed were calculated
using the position measurements obtained at the high rate of 50 Hz. A DNN
architecture with long short-term memory layers is proposed to enable
high-frequency speed estimation that accounts for previous inputs history and
the nonlinear relation between speed, acceleration and angular velocity. A
simplified aided dead reckoning localization scheme is formulated to assess the
trained model which provides the speed pseudo-measurement. The trained model is
shown to substantially improve the position accuracy during a 4 minutes drive
without the use of GNSS position updates.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 17:46:59 GMT""},{""version"":""v2"",""created"":""Tue, 23 Aug 2022 09:22:48 GMT""}]","2022-08-29"
"2205.07884","Francisco Fern\'andez Dr.","Francisco M. Fern\'andez","On the misinterpretation of conditionally-solvable quantum-mechanical
  problems",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We apply the Frobenius (power-series) method to some simple exactly-solvable
and conditionally-solvable quantum-mechanical models with supposed physical
interest. We show that the supposedly exact solutions to radial eigenvalue
equations derived in recent papers are not correct because they do not satisfy
some well-known theorems. We also discuss the origin of the mistake by means of
the approach indicated above.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 18:13:45 GMT""},{""version"":""v2"",""created"":""Wed, 18 May 2022 22:14:04 GMT""}]","2022-05-20"
"2205.07885","Lingwei Zhu","Lingwei Zhu, Zheng Chen, Eiji Uchibe, Takamitsu Matsubara","Enforcing KL Regularization in General Tsallis Entropy Reinforcement
  Learning via Advantage Learning",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Maximum Tsallis entropy (MTE) framework in reinforcement learning has gained
popularity recently by virtue of its flexible modeling choices including the
widely used Shannon entropy and sparse entropy. However, non-Shannon entropies
suffer from approximation error and subsequent underperformance either due to
its sensitivity or the lack of closed-form policy expression. To improve the
tradeoff between flexibility and empirical performance, we propose to
strengthen their error-robustness by enforcing implicit Kullback-Leibler (KL)
regularization in MTE motivated by Munchausen DQN (MDQN). We do so by drawing
connection between MDQN and advantage learning, by which MDQN is shown to fail
on generalizing to the MTE framework. The proposed method Tsallis Advantage
Learning (TAL) is verified on extensive experiments to not only significantly
improve upon Tsallis-DQN for various non-closed-form Tsallis entropies, but
also exhibits comparable performance to state-of-the-art maximum Shannon
entropy algorithms.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 04:47:50 GMT""}]","2022-05-18"
"2205.07886","Xin Chen","Xin Chen, Sam Toyer, Cody Wild, Scott Emmons, Ian Fischer, Kuang-Huei
  Lee, Neel Alex, Steven H Wang, Ping Luo, Stuart Russell, Pieter Abbeel, Rohin
  Shah","An Empirical Investigation of Representation Learning for Imitation","Accepted to NeurIPS2021 Datasets and Benchmarks Track",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Imitation learning often needs a large demonstration set in order to handle
the full range of situations that an agent might find itself in during
deployment. However, collecting expert demonstrations can be expensive. Recent
work in vision, reinforcement learning, and NLP has shown that auxiliary
representation learning objectives can reduce the need for large amounts of
expensive, task-specific data. Our Empirical Investigation of Representation
Learning for Imitation (EIRLI) investigates whether similar benefits apply to
imitation learning. We propose a modular framework for constructing
representation learning algorithms, then use our framework to evaluate the
utility of representation learning for imitation across several environment
suites. In the settings we evaluate, we find that existing algorithms for
image-based representation learning provide limited value relative to a
well-tuned baseline with image augmentations. To explain this result, we
investigate differences between imitation learning and other settings where
representation learning has provided significant benefit, such as image
classification. Finally, we release a well-documented codebase which both
replicates our findings and provides a modular framework for creating new
representation learning algorithms out of reusable components.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:23:42 GMT""}]","2022-05-18"
"2205.07888","Emilien Valat","Emilien Valat, Katayoun Farrahi, Thomas Blumensath","Data-Driven Interpolation for Super-Scarce X-Ray Computed Tomography",,,,,"eess.IV cs.CV cs.LG physics.med-ph","http://creativecommons.org/licenses/by/4.0/","  We address the problem of reconstructing X-Ray tomographic images from scarce
measurements by interpolating missing acquisitions using a self-supervised
approach. To do so, we train shallow neural networks to combine two
neighbouring acquisitions into an estimated measurement at an intermediate
angle. This procedure yields an enhanced sequence of measurements that can be
reconstructed using standard methods, or further enhanced using regularisation
approaches.
  Unlike methods that improve the sequence of acquisitions using an initial
deterministic interpolation followed by machine-learning enhancement, we focus
on inferring one measurement at once. This allows the method to scale to 3D,
the computation to be faster and crucially, the interpolation to be
significantly better than the current methods, when they exist. We also
establish that a sequence of measurements must be processed as such, rather
than as an image or a volume. We do so by comparing interpolation and
up-sampling methods, and find that the latter significantly under-perform.
  We compare the performance of the proposed method against deterministic
interpolation and up-sampling procedures and find that it outperforms them,
even when used jointly with a state-of-the-art projection-data enhancement
approach using machine-learning. These results are obtained for 2D and 3D
imaging, on large biomedical datasets, in both projection space and image
space.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:42:41 GMT""}]","2022-05-18"
"2205.08277","David Callan","David Callan","A Note on Generalized Narayana Numbers","4 pages",,,,"math.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We give a simple proof that the the number of Dyck paths of semilength $n$
with $i$ returns to ground level and $j$ peaks is the generalized Narayana
number $\frac{i}{n} \binom{n}{j} \binom{n - i - 1}{j - i}$.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 05:51:07 GMT""}]","2022-05-18"
"2205.08278","Pengcheng Yan","Pengcheng Yan, Qizhi Teng, Xiaohai He, Zhenchuan Ma, Ningning Zhang","Multiscale reconstruction of porous media based on multiple dictionaries
  learning",,,"10.1016/j.cageo.2023.105356",,"eess.IV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Digital modeling of the microstructure is important for studying the physical
and transport properties of porous media. Multiscale modeling for porous media
can accurately characterize macro-pores and micro-pores in a large-FoV (field
of view) high-resolution three-dimensional pore structure model. This paper
proposes a multiscale reconstruction algorithm based on multiple dictionaries
learning, in which edge patterns and micro-pore patterns from homology
high-resolution pore structure are introduced into low-resolution pore
structure to build a fine multiscale pore structure model. The qualitative and
quantitative comparisons of the experimental results show that the results of
multiscale reconstruction are similar to the real high-resolution pore
structure in terms of complex pore geometry and pore surface morphology. The
geometric, topological and permeability properties of multiscale reconstruction
results are almost identical to those of the real high-resolution pore
structures. The experiments also demonstrate the proposal algorithm is capable
of multiscale reconstruction without regard to the size of the input. This work
provides an effective method for fine multiscale modeling of porous media.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 07:09:24 GMT""}]","2023-05-03"
"2205.08279","Yuchen Xing","Yuchen Xing and Keping Qiu","Revisiting The Mass-Size Relation Of Structures In Molecular Clouds","14 pages, 9 figures. Accepted by Research in Astron. Astrophys",,"10.1088/1674-4527/ac6fb7",,"astro-ph.GA astro-ph.SR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We revisit the mass-size relation of molecular cloud structures based on the
column density map of the Cygnus-X molecular cloud complex. We extract 135
column density peaks in Cygnus-X and analyze the column density distributions
around these peaks. The averaged column density profiles, $N(R)$, around all
the peaks can be well fitted with broken power-laws, which are described by an
inner power-law index $n$, outer power-law index $m$, and the radius $R_{\rm
TP}$ and column density $N_{\rm TP}$ at the transition point. We then explore
the $M-R$ relation with different samples of cloud structures by varying the
$N(R)$ parameters and the column density threshold, $N_0$, which determines the
boundary of a cloud structure. We find that only when $N_0$ has a wide range of
values, the $M - R$ relation may largely probe the density distribution, and
the fitted power-law index of the $M-R$ relation is related to the power-law
index of $N(R)$. On the contrary, with a constant $N_0$, the $M - R$ relation
has no direct connection with the density distribution; in this case, the
fitted power-law index of the $M - R$ relation is equal to 2 (when $N_0\ge
N_{\rm TP}$ and $n$ has a narrow range of values), larger than 2 (when $N_0\ge
N_{\rm TP}$ and $n$ has a wide range of values), or slightly less than 2 (when
$N_0< N_{\rm TP}$).
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:11:21 GMT""}]","2022-05-18"
"2205.08280","Hung  Viet Chu Mr","Hung Viet Chu","On a Relation between Schreier-type Sets and a Modification of Tur\'{a}n
  Graphs","9 pages, 6 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, a relation between Schreier-type sets and Tur\'{a}n graphs was
discovered. In this note, we give a combinatorial proof and obtain a
generalization of the relation. Specifically, for $p, q\ge 1$, let
$$\mathcal{A}_q := \{F\subset\mathbb{N}: |F| = 1 \mbox{ or }F\mbox{ is an
arithmetic progression with difference } q\}$$ and $$Sr(n, p, q)\ :=\
\#\{F\subset \{1, \ldots, n\}\,:\, p\min F\ge |F|\mbox{ and }F\in
\mathcal{A}_q\}.$$ We show that $$Sr(n, p, q) \ =\ T(n+1, pq+1, q),$$ where
$T(\cdot, \cdot, \cdot)$ is the number of edges of an $n$-vertex graph that is
a modification of Tur\'{a}n graphs. We also prove that $Sr(n,p,q)$ is the
partial sum of certain sequences.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:47:17 GMT""}]","2022-05-18"
"2205.08281","Xue Jie Liu","Xuejie Liu, Yue Tan, Dianyong Chen, Hongxia Huang, Jialun Ping","Possible triply heavy tetraquark states",,,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the present work, the triply heavy tetraquarks states $QQ\bar{Q}\bar{q}$
with $Q=(c, b)$ and $q=(u, d, s)$ with all possible quantum numbers are
systematically investigated in the framework of the chiral quark model with the
resonance ground method. Two kinds of structures, including the meson-meson
configuration (the color-singlet channels and the hidden-color channels) and
the diquark-antidiquark configuration (the color sextet-antisextet and the
color triplet-antitriplet), are considered. In the considered system, several
bound states are obtained for the $cc\bar{c}\bar{q^{'}}$,
$bb\bar{c}\bar{q^{'}}$ and $bc\bar{c}\bar{q}$ tetraquarks. From the present
estimations, we find that the coupled channel effect is of great significance
for forming the below thresholds tetraquark states, which are stable for strong
decays.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:12:25 GMT""},{""version"":""v2"",""created"":""Thu, 8 Dec 2022 14:21:46 GMT""},{""version"":""v3"",""created"":""Tue, 14 Mar 2023 14:07:30 GMT""}]","2023-03-15"
"2205.08332","Mengjia Xu","Khemraj Shukla, Mengjia Xu, Nathaniel Trask and George Em Karniadakis","Scalable algorithms for physics-informed neural and graph networks","26 pages, 13 figures. arXiv admin note: text overlap with
  arXiv:2104.10013",,,,"cs.LG cs.AI cs.DC math.AP math.DS","http://creativecommons.org/licenses/by/4.0/","  Physics-informed machine learning (PIML) has emerged as a promising new
approach for simulating complex physical and biological systems that are
governed by complex multiscale processes for which some data are also
available. In some instances, the objective is to discover part of the hidden
physics from the available data, and PIML has been shown to be particularly
effective for such problems for which conventional methods may fail. Unlike
commercial machine learning where training of deep neural networks requires big
data, in PIML big data are not available. Instead, we can train such networks
from additional information obtained by employing the physical laws and
evaluating them at random points in the space-time domain. Such
physics-informed machine learning integrates multimodality and multifidelity
data with mathematical models, and implements them using neural networks or
graph networks. Here, we review some of the prevailing trends in embedding
physics into machine learning, using physics-informed neural networks (PINNs)
based primarily on feed-forward neural networks and automatic differentiation.
For more complex systems or systems of systems and unstructured data, graph
neural networks (GNNs) present some distinct advantages, and here we review how
physics-informed learning can be accomplished with GNNs based on graph exterior
calculus to construct differential operators; we refer to these architectures
as physics-informed graph networks (PIGNs). We present representative examples
for both forward and inverse problems and discuss what advances are needed to
scale up PINNs, PIGNs and more broadly GNNs for large-scale engineering
problems.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 15:46:11 GMT""}]","2022-05-18"
"2205.08335","Wenying Wei","Ming Fan, Wenying Wei, Wuxia Jin, Zijiang Yang, Ting Liu","Explanation-Guided Fairness Testing through Genetic Algorithm",,,"10.1145/1122445.1122456",,"cs.NE cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The fairness characteristic is a critical attribute of trusted AI systems. A
plethora of research has proposed diverse methods for individual fairness
testing. However, they are suffering from three major limitations, i.e., low
efficiency, low effectiveness, and model-specificity. This work proposes ExpGA,
an explanationguided fairness testing approach through a genetic algorithm
(GA). ExpGA employs the explanation results generated by interpretable methods
to collect high-quality initial seeds, which are prone to derive discriminatory
samples by slightly modifying feature values. ExpGA then adopts GA to search
discriminatory sample candidates by optimizing a fitness value. Benefiting from
this combination of explanation results and GA, ExpGA is both efficient and
effective to detect discriminatory individuals. Moreover, ExpGA only requires
prediction probabilities of the tested model, resulting in a better
generalization capability to various models. Experiments on multiple real-world
benchmarks, including tabular and text datasets, show that ExpGA presents
higher efficiency and effectiveness than four state-of-the-art approaches.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 02:40:48 GMT""}]","2022-05-18"
"2205.08409","Antonio Bevilacqua Mr.","Antonio Bevilacqua, Lisa Alcock, Brian Caulfield, Eran Gazit, Clint
  Hansen, Neil Ireson, Georgiana Ifrim","Automated Mobility Context Detection with Inertial Signals",,,,,"eess.SP cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Remote monitoring of motor functions is a powerful approach for health
assessment, especially among the elderly population or among subjects affected
by pathologies that negatively impact their walking capabilities. This is
further supported by the continuous development of wearable sensor devices,
which are getting progressively smaller, cheaper, and more energy efficient.
The external environment and mobility context have an impact on walking
performance, hence one of the biggest challenges when remotely analysing gait
episodes is the ability to detect the context within which those episodes
occurred. The primary goal of this paper is the investigation of context
detection for remote monitoring of daily motor functions. We aim to understand
whether inertial signals sampled with wearable accelerometers, provide reliable
information to classify gait-related activities as either indoor or outdoor. We
explore two different approaches to this task: (1) using gait descriptors and
features extracted from the input inertial signals sampled during walking
episodes, together with classic machine learning algorithms, and (2) treating
the input inertial signals as time series data and leveraging end-to-end
state-of-the-art time series classifiers. We directly compare the two
approaches through a set of experiments based on data collected from 9 healthy
individuals. Our results indicate that the indoor/outdoor context can be
successfully derived from inertial data streams. We also observe that time
series classification models achieve better accuracy than any other
feature-based models, while preserving efficiency and ease of use.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 09:34:43 GMT""}]","2022-05-18"
"2205.08491","Veli Safak","Veli Safak and Aniish Sridhar","Elon Musk's Twitter Takeover: Politician Accounts",,,,,"cs.SI","http://creativecommons.org/licenses/by/4.0/","  We provided quantitative data supporting significant changes between the time
Twitter acceptance the offer on April 25 and the time the agreement was
finalized on October 27. Republican politicians saw significant increases in
their follower counts, while Democrat politicians saw significant decreases.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:11:49 GMT""},{""version"":""v2"",""created"":""Sun, 4 Dec 2022 13:36:05 GMT""},{""version"":""v3"",""created"":""Tue, 6 Dec 2022 02:57:59 GMT""}]","2022-12-07"
"2205.08567","Yiming Huo","Yiming Huo","Internet of Spacecraft for Multi-planetary Defense and Prosperity","28 pages, 19 figures, submitted to a journal as an invited paper",,,,"astro-ph.IM astro-ph.EP cs.CR eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent years have seen unprecedentedly fast-growing prosperity in the
commercial space industry. Several privately funded aerospace manufacturers,
such as Space Exploration Technologies Corporation (SpaceX) and Blue Origin
have innovated what we used to know about this capital-intense industry and
gradually reshaped the future of human civilization. As private spaceflight and
multi-planetary immigration gradually become realities from science fiction
(sci-fi) and theory, both opportunities and challenges are presented. In this
article, a review of the progress in space exploration and the underlying space
technologies is firstly provided. For the next, a revisit and a prediction are
paid and made to the K-Pg extinction event, the Chelyabinsk event,
extra-terrestrialization, terraforming, planetary defense, including the
emerging near-Earth object (NEO) observation and NEO impact avoidance
technologies and strategies. Furthermore, a framework of the Solar
Communication and Defense Networks (SCADN) with advanced algorithms and high
efficacy is proposed to enable an internet of distributed deep-space sensing,
communications, and defense to cope with disastrous incidents such as
asteroid/comet impacts. Furthermore, the perspectives on the legislation,
management, and supervision of founding the proposed SCADN are also discussed
in depth.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 01:46:41 GMT""}]","2022-05-19"
"2205.09506","Gengbo Wu","Geng-Bo Wu, Ka Fai Chan, Chi Hou Chan","Holographic Amplitude-Modulated (AM) Leaky-Wave Antennas for Near-Field
  and Far-Field Applications","9 pages, 17 figures",,,,"physics.app-ph physics.optics","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Amplitude-modulated (AM) leaky-wave antenna (LWA), a concept following
amplitude modulation technique from classical communications theory, is a
promising structure that enables transforming traveling wave into the radiating
wave. In this paper, we provide a different perspective based on the classical
holographic theory to gain insight into the physical mechanism of AM LWA and
design novel LWAs. In analogy to the classical optical Gabor hologram, we
demonstrate that only the amplitude variation of the traveling wave is needed
to record both the amplitude and phase information of the object wave. The
consistency between the holography theory and previous spatial spectrum
approach for explaining AM LWA operating mechanism is also demonstrated. For
validation purpose, two novel millimeter-wave (mmW) holographic AM LWAs based
on the substrate integrated inset dielectric waveguide (IDW) are designed. The
first one is for far-field high-gain applications while the second is for
near-field focusing (NFF) applications. Both simulated and measured results
demonstrate the effectiveness of the AM holography theory for AM LWAs analysis
and design.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:05:53 GMT""}]","2022-05-20"
"2205.10118","Geoffroy Berthelot","Fabien Furfaro and Avner Bar-Hen and Geoffroy Berthelot","An Artificial Neural Network Functionalized by Evolution",,,,,"cs.NE cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The topology of artificial neural networks has a significant effect on their
performance. Characterizing efficient topology is a field of promising research
in Artificial Intelligence. However, it is not a trivial task and it is mainly
experimented on through convolutional neural networks. We propose a hybrid
model which combines the tensor calculus of feed-forward neural networks with
Pseudo-Darwinian mechanisms. This allows for finding topologies that are well
adapted for elaboration of strategies, control problems or pattern recognition
tasks. In particular, the model can provide adapted topologies at early
evolutionary stages, and 'structural convergence', which can found applications
in robotics, big-data and artificial life.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:49:58 GMT""}]","2022-05-23"
"2205.10354","Juhwan Lee","Yazan Gharaibeh, Juhwan Lee, Vladislav N. Zimin, Chaitanya Kolluru,
  Luis A. P. Dallan, Gabriel T. R. Pereira, Armando Vergara-Martel, Justin N.
  Kim, Ammar Hoori, Pengfei Dong, Peshala T. Gamage, Linxia Gu, Hiram G.
  Bezerra, Sadeer Al-Kindi, and David L. Wilson","Prediction of stent under-expansion in calcified coronary arteries using
  machine-learning on intravascular optical coherence tomography","25 pages, 7 figures, 1 table, 6 supplemental figures, 3 supplemental
  tables",,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  BACKGROUND Careful evaluation of the risk of stent under-expansions before
the intervention will aid treatment planning, including the application of a
pre-stent plaque modification strategy.
  OBJECTIVES It remains challenging to achieve a proper stent expansion in the
presence of severely calcified coronary lesions. Building on our work in deep
learning segmentation, we created an automated machine learning approach that
uses lesion attributes to predict stent under-expansion from pre-stent images,
suggesting the need for plaque modification.
  METHODS Pre- and post-stent intravascular optical coherence tomography image
data were obtained from 110 coronary lesions. Lumen and calcifications in
pre-stent images were segmented using deep learning, and numerous features per
lesion were extracted. We analyzed stent expansion along the lesion, enabling
frame, segmental, and whole-lesion analyses. We trained regression models to
predict the poststent lumen area and then to compute the stent expansion index
(SEI). Stents with an SEI < or >/= 80% were classified as ""under-expanded"" and
""well-expanded,"" respectively.
  RESULTS Best performance (root-mean-square-error = 0.04+/-0.02 mm2, r =
0.94+/-0.04, p < 0.0001) was achieved when we used features from both the lumen
and calcification to train a Gaussian regression model for a segmental analysis
over a segment length of 31 frames. Under-expansion classification results
(AUC=0.85+/-0.02) were significantly improved over other approaches.
  CONCLUSIONS We used calcifications and lumen features to identify lesions at
risk of stent under-expansion. Results suggest that the use of pre-stent images
can inform physicians of the need to apply plaque modification approaches.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 14:28:51 GMT""}]","2022-05-24"
"2205.11233","Xiaolei Liu","Naicheng Guo, Xiaolei Liu, Shaoshuai Li, Qiongxu Ma, Kaixin Gao, Bing
  Han, Lin Zheng, Xiaobo Guo","Poincar\'{e} Heterogeneous Graph Neural Networks for Sequential
  Recommendation","32 pages, 12 figuews",,,,"cs.IR cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Sequential recommendation (SR) learns users' preferences by capturing the
sequential patterns from users' behaviors evolution. As discussed in many
works, user-item interactions of SR generally present the intrinsic power-law
distribution, which can be ascended to hierarchy-like structures. Previous
methods usually handle such hierarchical information by making user-item
sectionalization empirically under Euclidean space, which may cause distortion
of user-item representation in real online scenarios. In this paper, we propose
a Poincar\'{e}-based heterogeneous graph neural network named PHGR to model the
sequential pattern information as well as hierarchical information contained in
the data of SR scenarios simultaneously. Specifically, for the purpose of
explicitly capturing the hierarchical information, we first construct a
weighted user-item heterogeneous graph by aliening all the user-item
interactions to improve the perception domain of each user from a global view.
Then the output of the global representation would be used to complement the
local directed item-item homogeneous graph convolution. By defining a novel
hyperbolic inner product operator, the global and local graph representation
learning are directly conducted in Poincar\'{e} ball instead of commonly used
projection operation between Poincar\'{e} ball and Euclidean space, which could
alleviate the cumulative error issue of general bidirectional translation
process. Moreover, for the purpose of explicitly capturing the sequential
dependency information, we design two types of temporal attention operations
under Poincar\'{e} ball space. Empirical evaluations on datasets from the
public and financial industry show that PHGR outperforms several comparison
methods.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:30:25 GMT""}]","2022-05-24"
"2205.11242","Anselmo Ferreira","Anselmo Ferreira, Changcheng Chen and Mauro Barni","Fusing Multiscale Texture and Residual Descriptors for Multilevel 2D
  Barcode Rebroadcasting Detection",,,"10.1109/WIFS53200.2021.9648391",,"cs.CV cs.AI cs.CR","http://creativecommons.org/licenses/by/4.0/","  Nowadays, 2D barcodes have been widely used for advertisement, mobile
payment, and product authentication. However, in applications related to
product authentication, an authentic 2D barcode can be illegally copied and
attached to a counterfeited product in such a way to bypass the authentication
scheme. In this paper, we employ a proprietary 2D barcode pattern and use
multimedia forensics methods to analyse the scanning and printing artefacts
resulting from the copy (rebroadcasting) attack. A diverse and complementary
feature set is proposed to quantify the barcode texture distortions introduced
during the illegal copying process. The proposed features are composed of
global and local descriptors, which characterize the multi-scale texture
appearance and the points of interest distribution, respectively. The proposed
descriptors are compared against some existing texture descriptors and deep
learning-based approaches under various scenarios, such as cross-datasets and
cross-size. Experimental results highlight the practicality of the proposed
method in real-world settings.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 06:26:20 GMT""}]","2022-05-24"
"2205.13386","Arun Kenath Dr","Kiren O V (1), Kenath Arun (1), C Sivaram (2) ((1) Department of
  Physics and Electronics, CHRIST (Deemed to be University), Bengaluru, (2)
  Indian Institute of Astrophysics, Bangalore)","Evolution of Primordial Dark Matter Planets in the Early Universe","14 pages, 6 tables, 2 figures, 24 equations","Advances in Space Research, vol. 68, pp. 2050-2056, 2021","10.1016/j.asr.2021.04.016",,"physics.gen-ph astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  In a recent paper we had discussed possibility of DM at high redshifts
forming primordial planets composed entirely of DM to be one of the reasons for
not detecting DM (as the flux of ambient DM particles would be consequently
reduced). In this paper we discuss the evolution of these DM objects as the
Universe expands. As Universe expands there will be accretion of DM, helium and
hydrogen layers (discussed in detail) on these objects. As they accumulate more
and more mass, the layers get heated up leading to nuclear reactions which burn
H and He when a critical thickness is reached. In the case of heavier masses of
these DM objects, matter can be ejected explosively. It is found that the time
scale of ejection is smaller than those from other compact objects like neutron
stars (that lead to x-ray bursts). These flashes of energy could be a possible
observational signature for these dense DM objects.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:26:55 GMT""}]","2022-05-27"
"2205.14010","Arun Kenath Dr","C Sivaram (1), Kenath Arun (2), Louise Rebecca (2,3) ((1) Indian
  Institute of Astrophysics, Bangalore, (2) Department of Physics and
  Electronics, CHRIST (Deemed to be University), Bangalore (3) Christ Junior
  College, Bangalore)","The Hubble tension: Change in dark energy or a case for modified
  gravity?","8 pages, 1 table, 11 equations","Indian Journal of Physics, vol. 96, pp. 1289-1292, 2022","10.1007/s12648-021-02080-7",,"physics.gen-ph","http://creativecommons.org/licenses/by/4.0/","  Recently much controversy has been raised about the cosmological conundrum
involving the discrepancy in the value of the Hubble constant as implied by
Planck satellite observations of the CMBR in the early Universe and that
deduced from other distance indicators (for instance using standard candles
like supernovae, tip of the Red Giant branch, etc.) in the present epoch. The
Planck estimate is about 67 km/s/Mpc, while that deduced from distance
indicators at the present epoch is around 73-74 km/s/Mpc. Also the independent
determination of the local value of the Hubble constant based on a calibration
of the Tip of the Red Giant Branch (TRGB) and applied to Type Ia supernovae
found a value of 69.8 km/s/Mpc. Here we propose a modification of the
gravitational field on large scales as an alternate explanation for this
discrepancy in the value of the Hubble constant as implied in the
above-mentioned method, i.e., by Planck observations of the CMBR in the early
Universe and that deduced from other distance indicators in the present epoch.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:17:22 GMT""}]","2022-05-30"
"2205.14144","Mayank Goswami","Kajal Kumari, Mayank Goswami","Noise analysis, error estimates, and Gamma Radiation Measurement for
  limited detector computerized tomography application","6 pages, 6 figures, 1 Table",,,,"eess.IV physics.data-an physics.ins-det","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Computed Tomography is one of the efficient and vital modalities of
non-destructive techniques (NDT). Various factors influence the CT
reconstruction result, including limited projection data, detector electronics
optimization, background noise, detection noise, discretized nature of
projection data, and many more. Radiation hardening and other aging factors
that affect the operational settings may require recalibration of electronics
parameters. Two well-known exercises are utilized with the motivation to
improve reliability and accuracy in inverse recovery. The first exercise
brute-forces an optimal candidate from the set of calibration methods for
minimum error in inverse recovery. The second exercise, Kanpur Theorem-1 (KT-1)
examines if optimal calibration sets electronics to impart minimum noise. The
mutual conformity between statistics-derived CLT and Riemann integral
transform-based KT-1 is shown first time using gamma radiation measurement. The
analysis shows that measurement data with normal distribution inflicts the
least noise in inverse recovery.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 10:09:59 GMT""}]","2022-05-31"
"2205.14145","Zolt\'an Filus","Zolt\'an Filus (1), Peng Ye (1), Tam\'as Csizmadia (1), T\'imea
  Gr\'osz (1), L\'en\'ard Guly\'as Oldal (1 and 2), Massimo De Marco (1),
  Mikl\'os F\""ule (1 and 3), Subhendu Kahaly (1 and 2), Katalin Varj\'u (1 and
  4) and Bal\'azs Major (1) ((1) ELI ALPS, ELI-HU Non-Profit Ltd (2) Institute
  of Physics, University of Szeged (3) Department of Experimental Physics,
  University of Szeged (4) Department of Optics and Quantum Electronics,
  University of Szeged)","Liquid-cooled modular gas cell system for high-order harmonic generation
  using high average power laser systems",,,"10.1063/5.0097788",,"physics.ins-det physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the design and implementation of a new, modular gas target
suitable for high-order harmonic generation using high average power lasers. To
ensure thermal stability in this high heat load environment, we implement an
appropriate liquid cooling system. The system can be used in multiple-cell
configurations allowing to control the cell length and aperture size. The cell
design was optimized with heat and flow simulations for thermal
characteristics, vacuum compatibility and generation medium properties.
Finally, the cell system was experimentally validated by conducting high-order
harmonic generation measurements using the 100 kHz high average power HR-1
laser system at the Extreme Light Infrastructure Attosecond Light Pulse Source
(ELI ALPS) facility. Such a robust, versatile and stackable gas cell
arrangement can easily be adapted to different experimental geometries in both
table-top laboratory systems and user-oriented facilities, such as ELI ALPS.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 12:36:02 GMT""}]","2022-07-27"
"2205.15038","Daniel Torrent","Marc Mart\'i-Sabat\'e, S\'ebastien Guenneau and Dani Torrent","High-Quality Resonances in Quasi-Periodic Clusters of Scatterers for
  Flexural Waves",,,,,"physics.class-ph nlin.PS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multiple scattering theory is applied to the study of clusters of point-like
scatterers attached to a thin elastic plate and arranged in quasi-periodic
distributions. Two type of structures are specifically considered: the twisted
bilayer and the quasi-periodic line. The former consists in a couple of
two-dimensional lattices rotated a relative angle, so that the cluster forms a
moir\'e pattern. The latter can be seen as a periodic one-dimensional lattice
where an incommensurate modulation is superimposed. Multiple scattering theory
allows for the fast an efficient calculation of the resonant modes of these
structures as well as for their quality factor, which is thoroughly analyzed in
this work. The results show that quasi-periodic structures present a large
density of states with high quality factors, being therefore a promising way
for the design of high quality wave-localization devices.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 11:29:52 GMT""}]","2022-05-31"
"2206.00044","Nickos Papadatos D","Nickos Papadatos","Order statistics from exchangeable random variables are always
  sufficient","2 pages",,,,"math.ST math.PR stat.ME stat.TH","http://creativecommons.org/publicdomain/zero/1.0/","  Let $(X_1,\ldots,X_n)$ be an exchangeable random vector with distribution
function $F$, and denote by $Y_1\leq \cdots\leq Y_n$ the corresponding order
statistics. We show that the conditional distribution of $(X_1,\ldots,X_n)$
given $(Y_1,\ldots,Y_n)$ does not depend on $F$.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 00:35:30 GMT""}]","2022-06-02"
"2206.00766","Donna Calhoun","Hannah Spero and Donna Calhoun and Michael Schubert","Simulating the 1976 Teton Dam Failure using Geoclaw and HEC-RAS and
  comparing with Historical Observations",,,,,"physics.geo-ph cs.CE","http://creativecommons.org/licenses/by/4.0/","  Dam failures occur worldwide, often from factors including aging structures,
extreme hydrologic loading, and design oversights related to the changing
climate. Understanding and mitigating risk to downstream inhabited areas
require developing and improving low-cost high-fidelity tools, such as
numerical models, which allow emergency managers to predict the consequences of
dam failures better. Two-dimensional (2D) depth-averaged hydraulic models can
provide valuable insights into the importance of breach parameters or
downstream flow characteristics, but historical studies considering historic
failures using real topographies are less common in literature. This study
compares Geoclaw, a 2D hydraulic model with adaptive mesh refinement
capabilities, to an industry-standard software HEC-RAS (Hydrologic Engineering
Center - River Analysis System) using the 1976 Teton Dam failure as a case
study. The suitability of Geoclaw for dam failure modeling is determined based
on its capability to resolve inundation extent and flood wave arrival times.
This study performs sensitivity analyses of the HEC-RAS model to compare an
instantaneous dam breach assumption with a time-dependent breach formation for
quantifying the model uncertainty. We find the 2D Geoclaw dam-break model
results compare reasonably with historical gauge and field observational data
and HEC-RAS results. The model demonstrates stability and relatively low
computational costs. Our findings highlight opportunities for future work, with
the Geoclaw software performance supporting continued studies to evaluate
performance. Outcomes of this study will assist dam owners, floodplain
managers, and emergency managers by providing an additional tool for estimating
the impacts of dam failures to protect lives and infrastructure downstream.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 22:10:24 GMT""},{""version"":""v2"",""created"":""Sun, 17 Jul 2022 13:48:49 GMT""}]","2022-07-19"
"2206.01530","Takeharu Matsuda","Takeharu Matsuda, Kohsuke Tsukui, and Satoshi Ii","A particle-based method using the mesh-constrained discrete point
  approach for two-dimensional Stokes flows",,,,,"physics.flu-dyn physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Meshless methods inherently do not require mesh topologies and are
practically used for solving continuum equations. However, these methods
generally tend to have a higher computational load than conventional mesh-based
methods because calculation stencils for spatial discretization become large.
In this study, a novel approach for the use of compact stencils in meshless
methods is proposed, called the mesh-constrained discrete point (MCD) approach.
The MCD approach introduces a Cartesian mesh system to the background of a
domain. And the approach rigorously constrains the distribution of discrete
points (DPs) in each mesh by solving a dynamic problem with nonlinear
constraints. This can avoid the heterogeneity of the DP distribution at the
mesh-size level and impose compact stencils with a fixed degree of freedom for
derivative evaluations. A fundamental formulation for arrangements of DPs and
an application to unsteady Stokes flows are presented in this paper. Numerical
tests were performed for the distribution of DPs and flow problems in co-axial
and eccentric circular channels. The proposed MCD approach achieved a
reasonable distribution of DPs independently of the spatial resolution with a
few iterations in pre-processing. Additionally, solutions using the obtained DP
distributions in Stokes flow problems were in good agreement with theoretical
and reference solutions. The results also confirmed that the numerical
accuracies of velocity and pressure achieved the expected convergence order,
even when compact stencils were used.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 05:26:06 GMT""},{""version"":""v2"",""created"":""Sun, 28 Aug 2022 08:06:11 GMT""}]","2022-08-30"
"2206.05019","Vyacheslav Dokuchaev","Vyacheslav I. Dokuchaev","Physical origin of the dark spot at the image of supermassive black hole
  SgrA* revealed by the EHT collaboration","8 pages, 1 figure","Astronomy 2022, 1(2), 93-98","10.3390/astronomy1020009",,"astro-ph.HE gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We elucidate the physical origin of the dark spot in the image of
supermassive black hole SgrA* presented very recently by the EHT collaboration.
It is argued that this dark spot, which is noticeably smaller than the
classical black hole shadow, is the northern hemisphere of the event horizon
globe. The classical black hole shadow is unseen in the image of SgrA*. The
dark spot in the image of SgrA* is projected within the position of the
classical black hole shadow on the celestial sphere. The outer boundary of this
dark spot is an equator on the event horizon globe.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 20:00:52 GMT""},{""version"":""v2"",""created"":""Tue, 23 Aug 2022 12:43:15 GMT""}]","2022-08-24"
"2206.07114","Shijie Song","Mengwei Yuan, Gang Yang, Shijie Song, Luping Zhou, Robert Minasian,
  and Xiaoke Yi","Inverse design of nano-photonic wavelength demultiplexer with a deep
  neural network approach",,,"10.1364/OE.462038",,"physics.optics cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a pre-trained-combined neural network (PTCN) as a
comprehensive solution to the inverse design of an integrated photonic circuit.
By utilizing both the initially pre-trained inverse and forward model with a
joint training process, our PTCN model shows remarkable tolerance to the
quantity and quality of the training data. As a proof of concept demonstration,
the inverse design of a wavelength demultiplexer is used to verify the
effectiveness of the PTCN model. The correlation coefficient of the prediction
by the presented PTCN model remains greater than 0.974 even when the size of
training data is decreased to 17%. The experimental results show a good
agreement with predictions, and demonstrate a wavelength demultiplexer with an
ultra-compact footprint, a high transmission efficiency with a transmission
loss of -2dB, a low reflection of -10dB, and low crosstalk around -7dB
simultaneously.
","[{""version"":""v1"",""created"":""Sun, 15 May 2022 22:43:39 GMT""}]","2022-07-20"
"2206.07658","Mehran Soltani","Mehran Soltani, Francesco Da Ros, Andrea Carena, Darko Zibar","Experimental Validation of Spectral-Spatial Power Evolution Design Using
  Raman Amplifiers","4 pages, 5 figures",,,,"cs.LG eess.SP physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We experimentally validate a machine learning-enabled Raman amplification
framework, capable of jointly shaping the signal power evolution in two
domains: frequency and fiber distance. The proposed experiment addresses the
amplification in the whole C-band, by optimizing four first-order
counter-propagating Raman pumps.
","[{""version"":""v1"",""created"":""Mon, 16 May 2022 13:55:50 GMT""}]","2022-06-16"
